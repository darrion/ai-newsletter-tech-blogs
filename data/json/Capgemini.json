{
  "company": "Capgemini",
  "title": "Capgemini",
  "xmlUrl": "https://capgemini.github.io/feed.xml",
  "htmlUrl": "https://capgemini.github.io/",
  "content": "\n\n\n\n\nHow to (maybe) replace your HR department in 3 easy steps\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow menu\n\n\n\n\n\n\n\nHide menu\n\n\n\n\n\n\n\nAbout\n\n\nPresentations\n\n\nCategories\n\n\nTags\n\n\nBloggers\n\n\nGrade Ladder\n\nJobs\n\n\nSearch\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n\nHow to (maybe) replace your HR department in 3 easy steps\n\nby Sarah Saunders\non \n  AI, \n  \n  Chatbot, \n  \n  Cloud, \n  \n  Azure\n\n19 January 2024\nEstimated reading time 11 minutes\n\n\n\n\n\n\nI recently had the privilege of judging an internal Capgemini hackathon. It was an open brief, but the focus was to be on technology and its application to solve a real-world business problem. The entries were varied and excellent, from a dashboard to assess how warm/busy/accessible the office was so you could decide whether or not it was worth going in, to gamification of training, to improvements for mountain search and rescue teams. \nOne of the major commonalities across many of the entries was the use of \u201cAI\u201d, where, given our common use of the Azure platform, AI tended to be defined as Azure cognitive search (recently renamed Azure AI) indexing a set of business documents, with a natural language processing unit on top to act as a chatbot. This made me want to have a go myself, and see what I could build!\nIs it AI?\nThis architecture, for me, isn\u2019t really using the \u201cAI\u201d bits of AI - despite the fact that if you use ChatGPT (which is available as a product in Azure since Microsoft\u2019s purchase of OpenAI) there can be some non-deterministic, generative functionality, but it sure is useful and could probably ease the burden of the HR and support departments of many organisations - and could possibly even replace a lot of the staff in these departments. I set out to see if I could build a HR chatbot to replace the kinds of queries a typical HR department employee might need to deal with. Why HR? Just because everybody hates them?? No\u2026! - it\u2019s because of the remit of HR, dealing with the employee lifecycle and needing to prove that a company acts without bias it must be a heavily process-driven department. These processes must be documented, and most of the workload of the department is in dealing with queries regarding the process. The incoming questions are probably not phrased in the same way as the process documentation, so some sort of fuzzy search is required in order to automate the question-answering process; for example, translating \u201chow much paid time off do I get when my baby is born?\u201d to \u201cpaternity leave allowances\u201d is not a straightforward mapping. This is the reason that previous attempts to automate such departments have failed. Language is too complex for simple mappings and decision trees to replace a person on the end of a line - as anyone who has tried to navigate an automated telephone call will tell you. Who hasn\u2019t ended up shouting \u201cI WANT TO SPEAK TO A PERSON\u201d down the line? But at the end of the day, the workload is simply regurgitating content from a document repository and the hard bit comes in finding the relevant sections - a process that is better automated as it\u2019s a pretty unrewarding job acting as a knowledge base for people who can\u2019t be bothered to read swathes of documentation.\nThe Architecture\nAs mentioned, the hackathon had been playing with the Azure cloud, so we\u2019ll keep to this and use Azure\u2019s concepts. These are pretty simply translated to any hyperscaler though, or to open-source alternatives if you want to host your own. For example, on AWS you could use Textract and Amazon Comprehend, and in the OSS world you\u2019d perhaps use NLTK and Lucene.\nAzure AI Search is a nice tool - a little more than document search, a little less than AI. It can be a bit clunky to get used to, and the price policy is per GB storage which is pretty bizarre - but this can be beneficial if you have query-intensive applications and a small-ish data set of documents. We use it as an exotic database view for one of our applications, and it took us a while to get used to the fuzzy query syntax - it\u2019s not really designed for logical queries, it\u2019s much better at giving you best-guess matches for loose search terms - and as such is well positioned to be the back-end of our HR chatbot.\nThe Method\nI found a couple of tutorials and quick-starts to create chatbots on my documentation - \nAzure Search OpenAI demo\nor Query your documentation using Langchain\nThe issue I found is that it\u2019s all moving quite fast - faster than the tutorials can keep up with. All mention of Langchain has now gone from the Azure portal (although you can still write your own Langchain chatbot), and QnA maker has now moved on and we have Azure AI Language Studio where you can add in your documents via a \u201cCustom Question Answering\u201d project, which is a type of Azure \u201cLanguage\u201d and can be created via the LoCode/NoCode Language Studio homepage. The tutorial speedily guides you through a simply-configured web form although it\u2019s not quite clear what you are actually going to create - looking at what was deployed after the configuration steps, this sets up an Azure cognitive search (AI search) repository and then enables custom text classification / custom named entity recognition on the repository. The default behaviour for this appears to be breaking down the content in your referenced documents into paragraphs and pulling out likely titles/subjects. You can then modify this classification by adding in new questions and answers, or choosing the best answer for given terms.\nThe free trial only allows you to upload three sources into your AI search repository. So, for our HR example, I\u2019ve downloaded three HR policy documents from this handy online repository and added them into my Custom Question Answering repository. This generates a \u201cKnowledge Base\u201d that I can then publish.\n\nHere we can see the way that the content has been divided up into major terms and paragraphs that may address those terms. I can edit here, and once it\u2019s published I can generate a Bot to act as the user interface to it.\n\nOK so now onto creating this Bot. As Bots go, OpenAI\u2019s ChatGPT is the real deal. Generative AI, pre-trained to recognise vast arrays of English language. For most use cases we would have to \u201cturn off\u201d all the fun, generative stuff for our application (see Guardrails below) and it\u2019s probably overkill to use ChatGPT for this demo - plus, it isn\u2019t included in the Azure Free Trial tier so I will be experimenting with the Azure AI Bot Service instead. It should be sufficient for this fairly small and simple demo.\nCost-wise, the Azure AI Bot has a free tier, but it must be hosted via an Azure Web App whose service plan is defaulted to S1 (Standard). This plan, at \u00a375/month to keep it running, is eating rapidly into my free credit!\nConfiguring the Bot online is pretty straightforward. The web GUI provides you with a customised template for creating the resources that you will need, creating an App Service Plan to launch an Azure WebApp that will host your Bot. The only config you have to do is enter the key of your Language Resource so that you can create a secure connection between the AI service knowledge base and the chatbot. This isn\u2019t documented, but you can find the key by going back to the Azure Portal home and clicking the green squares \u201cAll Resources\u201d view, then selecting your Language resource (the resource where Type = Language) and then selecting the Keys and Endpoint menu item. (There are two keys, so that you can refresh them by rotating them individually and hence avoid downtime. Either one is fine.)\nTesting\nOnce your Bot is deployed, you can test it by finding it under All Resources and choosing \u201cTest in Web Chat\u201d from the right hand menu.\nI tried with a simple question, that I know is answerable with the content in the documents:\n\nSo far so good. The Bot has successfully found the right bit of my documentation and returned a comprehensive and understandable answer. How about another:\n\nOh dear. \u201ccannot\u201d is not exactly a strong English sentence! Although it has found the relevant section of the documentation, it has not been able to pull out a contextual answer. \nI am not sure if it is the Language Service or the Bot which is struggling with this question. Enabling and examining the logs on the Bot Service isn\u2019t that helpful - it just shows HTTP POST requests going to the Bot framework. The Bot framework should be responsible for breaking down the user\u2019s entered text into logical \u201cintentions\u201d that the back-end question-answerer can respond to, and then delivering the back-end response in a human readable form.\nI eventually figure out how to enable logging on my Language Service and discover the query and response that the Bot has sent to the language service:\n\nI can see that the language service has actually done a reasonable job. It\u2019s identified the right paragraph for the query, but returned just a 38.97% certainty rating that this is the right data. Fair enough. So it seems that the issue is with the Bot being able to pull the right piece of text out of the response. This makes me start to wonder about the \u201cBot\u201d I have deployed. What is it actually based on? There isn\u2019t much documentation I can find, but you can download the source code, which shows that I have deployed something created by the BotBuilder SDK. I should be able to run this locally, but weirdly the Bot JavaScript code in my download seems totally out-of-date with the latest Language Studio API. I have to go back to the drawing board and use one of the later samples and update the code to correctly declare a method asynchronous to get the Bot running locally using the Bot Framework Emulator.\nTo get it to work using Node.js v18.16.0 and restify ^11.1.0, I had to edit the sample code index.js line 91 to declare the method async or it would not start:\n// Listen for incoming requests.\nserver.post('/api/messages', async (req, res) => {\n    adapter.processActivity(req, res, async (turnContext) => {\n        // Route the message to the bot's main handler.\n        await bot.run(turnContext);\n    });\n});\n\nI was then able to run the Bot locally connecting to my Azure-hosted Language via the Azure Bot Framework Emulator. And of course as luck would have it, the latest sample doesn\u2019t return such a poor response! It\u2019s still not perfect, but it\u2019s at least a sentence. See below.\n\nIt does also prove that the poor response here was the chatbot interpreting the data from the Language Service. The Language Service will return a field called an AnswerSpan which lists, with a confidence score, the section of the documentation it considers most relevant to the question. In the case of my \u201cdismissal\u201d question, the AnswerSpan returned was:\nAn employee whose appointment is terminated for any reason will be provided with a written statement of the reasons for the dismissal\nThis text was paired with a confidence score of 0.2880999999999997, or circa 29%. Fair enough. So how the cloud-deployed bot extracted the answer \u201ccannot\u201d from this is a bit of a mystery! The new version of my Bot prints the whole AnswerSpan and is, whilst still not exactly accurate, at least better. So how do I fix it?\nCustomisation\nIt seems the way to fix up these simple Bots is to go and add a custom question/answer into the Language Service knowledge base. I try adding a specific answer to the question, \u201cCan I appeal against my dismissal?\u201d. I re-publish the knowledge base and try again.\n\nThis looks much better. But it does imply that quite a lot of user testing and customisation will have to take place before this Bot is ready to replace its human counterparts.\nGuardrails\nOne of the things that surprised people about ChatGPT, particularly in its earlier iterations, was that it was not trained to be accurate. It was trained to please the user. This would mean it would return inaccurate answers above telling you that it didn\u2019t know the answer, as it had gauged higher satisfaction from \u201clying\u201d! You don\u2019t want your HR chatbot to lie, so you must use the guardrail settings to ensure that it does not. With ChatGPT, guardrails can be set using natural language, for example you can state:\n{\"role\": \"system\", \"content\": \"Assistant is an intelligent chatbot designed to help users answer their tax related questions.`\n\nInstructions:\n- Only answer questions related to taxes.\n\n- If you're unsure of an answer, you can say \"I don't know\" or \"I'm not sure\" and recommend users go to the IRS website for more information. \"},\n{\"role\": \"user\", \"content\": \"When are my taxes due?\u201d}\n\nThis configuration will prevent the chatbot from \u201cmaking up\u201d an answer if it cannot find a decent response in its repository.\nConfiguring Azure\u2019s ChatGPT chatbot via the GUI, to achieve the above you turn the setting known as \u201ctemperature\u201d down to 0. The temperature represents how creative the chatbot can be in getting you an answer. A low temperature results in more \u201cI\u2019m sorry I don\u2019t know\u201d type answers, but increases the chances you\u2019ll get an accurate answer, and that you\u2019ll get the same answer when you ask the same question twice!\nThe Cost\nSo what does this cost to run in Azure? Depending on your Bot type, the cost can vary wildly. As mentioned, I am running my Language instance and my Bot instance in the free trial tier, so I am only paying for the app service to host them and this is around \u00a375/month. If you were to use an enterprise ChatGPT Bot, costs are over \u00a3800/month fixed rate for 40 users, plus 80p per \u201cusage unit\u201d and \u00a320 for any extra users over and above the plan. Still considerably cheaper than making your HR staff deal with these queries, I suppose..\nAs mentioned, Azure AI search is priced per GB of data indexed, the free tier runs up to 50 GB, Standard tier gives you 25 GB  for 27p/hour.\nIn Conclusion\nI am impressed with the Azure AI search offering - it\u2019s powerful and useful - there are so many scenarios whereby we end up awash with documentation and cannot find the content we need. The chatbots are a varied bunch but I liked the way you could download the code and run/edit it locally with relative ease. In all, I feel this will be a very common architecture for the business problems of the next year or so.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelated Posts\n\n\n\n\n      Preparing for Devoxx\n      \n        How the Cloud Development team gets inspired by preparing to host a conference stall\n\n\nMay 10, 2023\n\n\n\n\n\n\n      Platforms to support Product Oriented Teams\n      \n        How to create a truly usable accelerator to allow dev teams to focus on business needs\n\n\nDecember 2, 2022\n\n\n\n\n\n\n      The Efficient Cloud Era\n      \n        The latest developments in Java and Cloud Hosting are allowing tech teams to make an impact on sustainability\n\n\nMay 20, 2022\n\n\n\n\n\n\n      My experience with the new AWS SysOps Certification exam (SOA-C02)\n      \n        Some thoughts on the Taking the AWS Certified SysOps Administrator - Associate Certification exam (SOA-C02) while it was in Beta.\n\n\nMay 21, 2021\n\n\n\n\n\n\n      Rafael: A Developers Story\n      \n        The personal story of the developers that assembled and brought you Rafael\n\n\nJuly 14, 2020\n\n\n\n\n\n\n\n\n\n\nJoin our team\n\nIf you like the sound of what you've read and would like to join our team, we're hiring!\nFind out more about working with Capgemini\n\n\n\n\n\n\n\n\n\n\n        Sarah Saunders\n      \n\nSarah is a Senior Java Developer and Agile Evangelist at Capgemini\n\n\n\n\n\n\n\u00a0Follow @sasaunde on Twitter\n        \n\n\n\n\n\n\u00a0Meet Sarah on LinkedIn\n        \n\n\n\n\n\n\nPosts by Sarah\n\n\n\n\n      Preparing for Devoxx\n      \n        How the Cloud Development team gets inspired by preparing to host a conference stall\n\n\nMay 10, 2023\n\n\n\n\n\n\n      Platforms to support Product Oriented Teams\n      \n        How to create a truly usable accelerator to allow dev teams to focus on business needs\n\n\nDecember 2, 2022\n\n\n\n\n\n\n      The Efficient Cloud Era\n      \n        The latest developments in Java and Cloud Hosting are allowing tech teams to make an impact on sustainability\n\n\nMay 20, 2022\n\n\n\n\n\n\n      Ten Steps towards Cloud Native\n      \n    \n\nMarch 5, 2020\n\n\n\n\n\n\n      It's OK Not to be Agile\n      \n    \n\nOctober 22, 2018\n\n\n\n\n\n\n      Building for Alexa at Devoxx UK\n      \n    \n\nMay 18, 2018\n\n\n\n\n\n\n      Ways to Skin a Cat\n      \n        Redux and React from a Java developer's perspective\n\n\nSeptember 15, 2017\n\n\n\n\n\n\n      Hacking Blockchain\n      \n    \n\nJune 30, 2017\n\n\n\n\n\n\n      Throwing stones at Clouds\n      \n    \n\nJuly 8, 2016\n\n\n\n\n\n\n      The Thing about Things\n      \n    \n\nFebruary 25, 2016\n\n\n\n\n\n\n      Delivering at Devoxx\n      \n    \n\nSeptember 18, 2015\n\n\n\n\n\n\n      Agile Analogies for Software Development\n      \n    \n\nNovember 18, 2014\n\n\n\n\n\n\nPresentations by Sarah\n\n\n\n\n      Technical Archaeology\n      \n        Unearthing Antipatterns in Modern Distributed Systems\n\n\nJuly 18, 2015\n\n\n\n\n\n\n\n\n\nComments\n\n\nPlease enable JavaScript to view the comments powered by Disqus.\n\n\n\n\n\nOpinions expressed on this blog reflect the writer\u2019s views and not the position of the Capgemini Group.\nAll content copyright Capgemini \u00a9 2024 \u2022 All rights reserved \u2022 Privacy Policy\nProudly published with Jekyll\n\n\n\n\n\n\nFeed\n\n\n\n\n\n\nTwitter\n\n\n\n\n\n\n\nGithub\n\n\n\n\n\n\n\nFacebook\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "latestPost": {
    "title": "How to (maybe) replace your HR department in 3 easy steps",
    "title_detail": {
      "type": "text/html",
      "language": "en",
      "base": "https://capgemini.github.io/feed.xml",
      "value": "How to (maybe) replace your HR department in 3 easy steps"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://capgemini.github.io/cloud/create-ai-bot-in-azure/"
      }
    ],
    "link": "https://capgemini.github.io/cloud/create-ai-bot-in-azure/",
    "id": "https://capgemini.github.io/cloud/create-ai-bot-in-azure",
    "guidislink": false,
    "published": "2024-01-19T00:00:00+00:00",
    "published_parsed": [
      2024,
      1,
      19,
      0,
      0,
      0,
      4,
      19,
      0
    ],
    "updated": "2024-01-19T00:00:00+00:00",
    "updated_parsed": [
      2024,
      1,
      19,
      0,
      0,
      0,
      4,
      19,
      0
    ],
    "authors": [
      {
        "name": "Sarah Saunders",
        "href": "https://capgemini.github.io/authors#author-sarah-saunders"
      }
    ],
    "author_detail": {
      "name": "Sarah Saunders",
      "href": "https://capgemini.github.io/authors#author-sarah-saunders"
    },
    "href": "https://capgemini.github.io/authors#author-sarah-saunders",
    "author": "Sarah Saunders",
    "tags": [
      {
        "term": "AI",
        "scheme": "https://capgemini.github.io/tags/#AI",
        "label": null
      },
      {
        "term": "Chatbot",
        "scheme": "https://capgemini.github.io/tags/#Chatbot",
        "label": null
      },
      {
        "term": "Cloud",
        "scheme": "https://capgemini.github.io/tags/#Cloud",
        "label": null
      },
      {
        "term": "Azure",
        "scheme": "https://capgemini.github.io/tags/#Azure",
        "label": null
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": "en",
        "base": "https://capgemini.github.io/feed.xml",
        "value": "<p>I recently had the privilege of judging an internal Capgemini hackathon. It was an open brief, but the focus was to be on technology and its application to solve a real-world business problem. The entries were varied and excellent, from a dashboard to assess how warm/busy/accessible the office was so you could decide whether or not it was worth going in, to gamification of training, to improvements for mountain search and rescue teams. \nOne of the major commonalities across many of the entries was the use of \u201cAI\u201d, where, given our common use of the Azure platform, AI tended to be defined as Azure cognitive search (recently renamed <a href=\"https://azure.microsoft.com/en-us/products/ai-services/ai-search\">Azure AI</a>) indexing a set of business documents, with a natural language processing unit on top to act as a chatbot. This made me want to have a go myself, and see what I could build!</p>\n\n<h2 id=\"is-it-ai\">Is it AI?</h2>\n\n<p>This architecture, for me, isn\u2019t really using the \u201cAI\u201d bits of AI - despite the fact that if you use ChatGPT (which is <a href=\"https://learn.microsoft.com/en-us/azure/ai-services/openai/\">available as a product in Azure</a> since Microsoft\u2019s purchase of OpenAI) there can be some non-deterministic, generative functionality, but it sure is useful and could probably ease the burden of the HR and support departments of many organisations - and could possibly even replace a lot of the staff in these departments. I set out to see if I could build a HR chatbot to replace the kinds of queries a typical HR department employee might need to deal with. Why HR? Just because everybody hates them?? No\u2026! - it\u2019s because of the remit of HR, dealing with the employee lifecycle and needing to prove that a company acts without bias it must be a heavily process-driven department. These processes must be documented, and most of the workload of the department is in dealing with queries regarding the process. The incoming questions are probably not phrased in the same way as the process documentation, so some sort of fuzzy search is required in order to automate the question-answering process; for example, translating \u201chow much paid time off do I get when my baby is born?\u201d to \u201cpaternity leave allowances\u201d is not a straightforward mapping. This is the reason that previous attempts to automate such departments have failed. Language is too complex for simple mappings and decision trees to replace a person on the end of a line - as anyone who has tried to navigate an automated telephone call will tell you. Who hasn\u2019t ended up shouting \u201cI WANT TO SPEAK TO A PERSON\u201d down the line? But at the end of the day, the workload is simply regurgitating content from a document repository and the hard bit comes in finding the relevant sections - a process that is better automated as it\u2019s a pretty unrewarding job acting as a knowledge base for people who can\u2019t be bothered to read swathes of documentation.</p>\n\n<h2 id=\"the-architecture\">The Architecture</h2>\n\n<p>As mentioned, the hackathon had been playing with the Azure cloud, so we\u2019ll keep to this and use Azure\u2019s concepts. These are pretty simply translated to any hyperscaler though, or to open-source alternatives if you want to host your own. For example, on AWS you could use <a href=\"https://aws.amazon.com/blogs/machine-learning/building-an-nlp-powered-search-index-with-amazon-textract-and-amazon-comprehend/\">Textract and Amazon Comprehend</a>, and in the OSS world you\u2019d perhaps use <a href=\"https://www.nltk.org/\">NLTK</a> and <a href=\"https://lucene.apache.org/\">Lucene</a>.</p>\n\n<p>Azure AI Search is a nice tool - a little more than document search, a little less than AI. It can be a bit clunky to get used to, and the price policy is per GB storage which is pretty bizarre - but this can be beneficial if you have query-intensive applications and a small-ish data set of documents. We use it as an exotic database view for one of our applications, and it took us a while to get used to the fuzzy query syntax - it\u2019s not really designed for logical queries, it\u2019s much better at giving you best-guess matches for loose search terms - and as such is well positioned to be the back-end of our HR chatbot.</p>\n\n<h2 id=\"the-method\">The Method</h2>\n\n<p>I found a couple of tutorials and quick-starts to create chatbots on my documentation - \n<a href=\"https://github.com/Azure-Samples/azure-search-openai-demo\">Azure Search OpenAI demo</a>\nor <a href=\"https://techcommunity.microsoft.com/t5/startups-at-microsoft/build-a-chatbot-to-query-your-documentation-using-langchain-and/ba-p/3833134\">Query your documentation using Langchain</a></p>\n\n<p>The issue I found is that it\u2019s all moving quite fast - faster than the tutorials can keep up with. All mention of <a href=\"https://www.langchain.com/\">Langchain</a> has now gone from the Azure portal (although you can still <a href=\"https://towardsdatascience.com/talk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2\">write your own</a> Langchain chatbot), and QnA maker has now moved on and we have <a href=\"https://language.cognitive.azure.com/\">Azure AI Language Studio</a> where you can add in your documents via a \u201cCustom Question Answering\u201d project, which is a type of Azure \u201cLanguage\u201d and can be created via the LoCode/NoCode <a href=\"https://language.cognitive.azure.com/\">Language Studio homepage</a>. The tutorial speedily guides you through a simply-configured web form although it\u2019s not quite clear what you are actually going to create - looking at what was deployed after the configuration steps, this sets up an Azure cognitive search (AI search) repository and then enables custom text classification / custom named entity recognition on the repository. The default behaviour for this appears to be breaking down the content in your referenced documents into paragraphs and pulling out likely titles/subjects. You can then modify this classification by adding in new questions and answers, or choosing the best answer for given terms.</p>\n\n<p>The free trial only allows you to upload three sources into your AI search repository. So, for our HR example, I\u2019ve downloaded three HR policy documents from <a href=\"https://staffsquared.com/free-hr-documents/\">this handy online repository</a> and added them into my Custom Question Answering repository. This generates a \u201cKnowledge Base\u201d that I can then publish.</p>\n\n<p><img alt=\"Upload documents into your language knowledge base\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/upload-docs.jpg\" /></p>\n\n<p>Here we can see the way that the content has been divided up into major terms and paragraphs that may address those terms. I can edit here, and once it\u2019s published I can generate a Bot to act as the user interface to it.</p>\n\n<p><img alt=\"knowledge base parsed from documents\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/knowledge-base.jpg\" /></p>\n\n<p>OK so now onto creating this Bot. As Bots go, OpenAI\u2019s <a href=\"https://chat.openai.com\">ChatGPT</a> is the real deal. Generative AI, pre-trained to recognise vast arrays of English language. For most use cases we would have to \u201cturn off\u201d all the fun, generative stuff for our application (see Guardrails below) and it\u2019s probably overkill to use ChatGPT for this demo - plus, it isn\u2019t included in the Azure Free Trial tier so I will be experimenting with the <a href=\"https://azure.microsoft.com/en-gb/products/ai-services/ai-bot-service\">Azure AI Bot Service</a> instead. It should be sufficient for this fairly small and simple demo.\nCost-wise, the Azure AI Bot has a free tier, but it must be hosted via an Azure Web App whose service plan is defaulted to S1 (Standard). This plan, at \u00a375/month to keep it running, is eating rapidly into my free credit!</p>\n\n<p>Configuring the Bot online is pretty straightforward. The web GUI provides you with a customised template for creating the resources that you will need, creating an App Service Plan to launch an Azure WebApp that will host your Bot. The only config you have to do is enter the key of your Language Resource so that you can create a secure connection between the AI service knowledge base and the chatbot. This isn\u2019t documented, but you can find the key by going back to the Azure Portal home and clicking the green squares \u201cAll Resources\u201d view, then selecting your Language resource (the resource where Type = Language) and then selecting the Keys and Endpoint menu item. (There are two keys, so that you can refresh them by rotating them individually and hence avoid downtime. Either one is fine.)</p>\n\n<h2 id=\"testing\">Testing</h2>\n\n<p>Once your Bot is deployed, you can test it by finding it under All Resources and choosing \u201cTest in Web Chat\u201d from the right hand menu.</p>\n\n<p>I tried with a simple question, that I know is answerable with the content in the documents:\n<img alt=\"Trial question\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/good-answer.jpg\" /></p>\n\n<p>So far so good. The Bot has successfully found the right bit of my documentation and returned a comprehensive and understandable answer. How about another:</p>\n\n<p><img alt=\"Second question\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/bad-answer.jpg\" /></p>\n\n<p>Oh dear. \u201ccannot\u201d is not exactly a strong English sentence! Although it has found the relevant section of the documentation, it has not been able to pull out a contextual answer. \nI am not sure if it is the Language Service or the Bot which is struggling with this question. Enabling and examining the logs on the Bot Service isn\u2019t that helpful - it just shows HTTP POST requests going to the Bot framework. The Bot framework should be responsible for breaking down the user\u2019s entered text into logical \u201cintentions\u201d that the back-end question-answerer can respond to, and then delivering the back-end response in a human readable form.\nI eventually figure out how to <a href=\"https://learn.microsoft.com/en-us/azure/ai-services/diagnostic-logging\">enable logging on my Language Service</a> and discover the query and response that the Bot has sent to the language service:</p>\n\n<p><img alt=\"Bot query to language service\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/backend-query.jpg\" /></p>\n\n<p>I can see that the language service has actually done a reasonable job. It\u2019s identified the right paragraph for the query, but returned just a 38.97% certainty rating that this is the right data. Fair enough. So it seems that the issue is with the Bot being able to pull the right piece of text out of the response. This makes me start to wonder about the \u201cBot\u201d I have deployed. What is it actually based on? There isn\u2019t much documentation I can find, but you can download the source code, which shows that I have deployed something created by the <a href=\"https://github.com/microsoft/botbuilder-js\">BotBuilder SDK</a>. I should be able to run this locally, but weirdly the Bot JavaScript code in my download seems totally out-of-date with the latest Language Studio API. I have to go back to the drawing board and use one of the <a href=\"https://github.com/microsoft/BotBuilder-Samples/tree/main/samples/javascript_nodejs/48.customQABot-all-features\">later samples</a> and update the code to correctly declare a method asynchronous to get the Bot running locally using the Bot Framework Emulator.</p>\n\n<p>To get it to work using Node.js v18.16.0 and restify ^11.1.0, I had to edit the sample code <a href=\"https://github.com/microsoft/BotBuilder-Samples/pull/3939/files\">index.js line 91</a> to declare the method async or it would not start:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>// Listen for incoming requests.\nserver.post('/api/messages', async (req, res) =&gt; {\n    adapter.processActivity(req, res, async (turnContext) =&gt; {\n        // Route the message to the bot's main handler.\n        await bot.run(turnContext);\n    });\n});\n</code></pre></div></div>\n\n<p>I was then able to run the Bot locally connecting to my Azure-hosted Language via the Azure <a href=\"https://github.com/Microsoft/BotFramework-Emulator/blob/master/README.md\">Bot Framework Emulator</a>. And of course as luck would have it, the latest sample doesn\u2019t return such a poor response! It\u2019s still not perfect, but it\u2019s at least a sentence. See below.</p>\n\n<p><img alt=\"Local Bot Service running in emulator\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/via-emulator.jpg\" /></p>\n\n<p>It does also prove that the poor response here was the chatbot interpreting the data from the Language Service. The Language Service will return a field called an AnswerSpan which lists, with a confidence score, the section of the documentation it considers most relevant to the question. In the case of my \u201cdismissal\u201d question, the AnswerSpan returned was:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">An employee whose appointment is terminated for any reason will be provided with a written statement of the reasons for the dismissal</code></p>\n\n<p>This text was paired with a confidence score of 0.2880999999999997, or circa 29%. Fair enough. So how the cloud-deployed bot extracted the answer \u201ccannot\u201d from this is a bit of a mystery! The new version of my Bot prints the whole AnswerSpan and is, whilst still not exactly accurate, at least better. So how do I fix it?</p>\n\n<h2 id=\"customisation\">Customisation</h2>\n\n<p>It seems the way to fix up these simple Bots is to go and add a custom question/answer into the Language Service knowledge base. I try adding a specific answer to the question, \u201cCan I appeal against my dismissal?\u201d. I re-publish the knowledge base and try again.</p>\n\n<p><img alt=\"Adding a custom question\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/fixed-question.jpg\" /></p>\n\n<p>This looks much better. But it does imply that quite a lot of user testing and customisation will have to take place before this Bot is ready to replace its human counterparts.</p>\n\n<h2 id=\"guardrails\">Guardrails</h2>\n\n<p>One of the things that surprised people about ChatGPT, particularly in its earlier iterations, was that it was not trained to be accurate. It was trained to please the user. This would mean it would return inaccurate answers above telling you that it didn\u2019t know the answer, as it had gauged higher satisfaction from \u201clying\u201d! You don\u2019t want your HR chatbot to lie, so you must use the guardrail settings to ensure that it does not. With ChatGPT, guardrails can be set using natural language, for example you can state:</p>\n<pre><code class=\"language-\u2028\">{\"role\": \"system\", \"content\": \"Assistant is an intelligent chatbot designed to help users answer their tax related questions.`\n\nInstructions:\n- Only answer questions related to taxes.\n\n- If you're unsure of an answer, you can say \"I don't know\" or \"I'm not sure\" and recommend users go to the IRS website for more information. \"},\n{\"role\": \"user\", \"content\": \"When are my taxes due?\u201d}\n</code></pre>\n\n<p>This configuration will prevent the chatbot from \u201cmaking up\u201d an answer if it cannot find a decent response in its repository.\nConfiguring Azure\u2019s ChatGPT chatbot via the GUI, to achieve the above you turn the setting known as \u201ctemperature\u201d down to 0. The temperature represents how creative the chatbot can be in getting you an answer. A low temperature results in more \u201cI\u2019m sorry I don\u2019t know\u201d type answers, but increases the chances you\u2019ll get an accurate answer, and that you\u2019ll get the same answer when you ask the same question twice!</p>\n\n<h2 id=\"the-cost\">The Cost</h2>\n\n<p>So what does this cost to run in Azure? Depending on your Bot type, the cost can vary wildly. As mentioned, I am running my Language instance and my Bot instance in the free trial tier, so I am only paying for the app service to host them and this is around \u00a375/month. If you were to use an enterprise ChatGPT Bot, costs are over \u00a3800/month fixed rate for 40 users, plus 80p per \u201cusage unit\u201d and \u00a320 for any extra users over and above the plan. Still considerably cheaper than making your HR staff deal with these queries, I suppose..\nAs mentioned, Azure AI search is priced per GB of data indexed, the free tier runs up to 50 GB, Standard tier gives you 25 GB  for 27p/hour.</p>\n\n<h2 id=\"in-conclusion\">In Conclusion</h2>\n\n<p>I am impressed with the Azure AI search offering - it\u2019s powerful and useful - there are so many scenarios whereby we end up awash with documentation and cannot find the content we need. The chatbots are a varied bunch but I liked the way you could download the code and run/edit it locally with relative ease. In all, I feel this will be a very common architecture for the business problems of the next year or so.</p>\n\n    \n    <p><a href=\"https://capgemini.github.io/cloud/create-ai-bot-in-azure/\">How to (maybe) replace your HR department in 3 easy steps</a> was originally published by Capgemini at <a href=\"https://capgemini.github.io\">Capgemini Software Engineering</a> on January 19, 2024.</p>"
      }
    ],
    "summary": "<p>I recently had the privilege of judging an internal Capgemini hackathon. It was an open brief, but the focus was to be on technology and its application to solve a real-world business problem. The entries were varied and excellent, from a dashboard to assess how warm/busy/accessible the office was so you could decide whether or not it was worth going in, to gamification of training, to improvements for mountain search and rescue teams. \nOne of the major commonalities across many of the entries was the use of \u201cAI\u201d, where, given our common use of the Azure platform, AI tended to be defined as Azure cognitive search (recently renamed <a href=\"https://azure.microsoft.com/en-us/products/ai-services/ai-search\">Azure AI</a>) indexing a set of business documents, with a natural language processing unit on top to act as a chatbot. This made me want to have a go myself, and see what I could build!</p>\n\n<h2 id=\"is-it-ai\">Is it AI?</h2>\n\n<p>This architecture, for me, isn\u2019t really using the \u201cAI\u201d bits of AI - despite the fact that if you use ChatGPT (which is <a href=\"https://learn.microsoft.com/en-us/azure/ai-services/openai/\">available as a product in Azure</a> since Microsoft\u2019s purchase of OpenAI) there can be some non-deterministic, generative functionality, but it sure is useful and could probably ease the burden of the HR and support departments of many organisations - and could possibly even replace a lot of the staff in these departments. I set out to see if I could build a HR chatbot to replace the kinds of queries a typical HR department employee might need to deal with. Why HR? Just because everybody hates them?? No\u2026! - it\u2019s because of the remit of HR, dealing with the employee lifecycle and needing to prove that a company acts without bias it must be a heavily process-driven department. These processes must be documented, and most of the workload of the department is in dealing with queries regarding the process. The incoming questions are probably not phrased in the same way as the process documentation, so some sort of fuzzy search is required in order to automate the question-answering process; for example, translating \u201chow much paid time off do I get when my baby is born?\u201d to \u201cpaternity leave allowances\u201d is not a straightforward mapping. This is the reason that previous attempts to automate such departments have failed. Language is too complex for simple mappings and decision trees to replace a person on the end of a line - as anyone who has tried to navigate an automated telephone call will tell you. Who hasn\u2019t ended up shouting \u201cI WANT TO SPEAK TO A PERSON\u201d down the line? But at the end of the day, the workload is simply regurgitating content from a document repository and the hard bit comes in finding the relevant sections - a process that is better automated as it\u2019s a pretty unrewarding job acting as a knowledge base for people who can\u2019t be bothered to read swathes of documentation.</p>\n\n<h2 id=\"the-architecture\">The Architecture</h2>\n\n<p>As mentioned, the hackathon had been playing with the Azure cloud, so we\u2019ll keep to this and use Azure\u2019s concepts. These are pretty simply translated to any hyperscaler though, or to open-source alternatives if you want to host your own. For example, on AWS you could use <a href=\"https://aws.amazon.com/blogs/machine-learning/building-an-nlp-powered-search-index-with-amazon-textract-and-amazon-comprehend/\">Textract and Amazon Comprehend</a>, and in the OSS world you\u2019d perhaps use <a href=\"https://www.nltk.org/\">NLTK</a> and <a href=\"https://lucene.apache.org/\">Lucene</a>.</p>\n\n<p>Azure AI Search is a nice tool - a little more than document search, a little less than AI. It can be a bit clunky to get used to, and the price policy is per GB storage which is pretty bizarre - but this can be beneficial if you have query-intensive applications and a small-ish data set of documents. We use it as an exotic database view for one of our applications, and it took us a while to get used to the fuzzy query syntax - it\u2019s not really designed for logical queries, it\u2019s much better at giving you best-guess matches for loose search terms - and as such is well positioned to be the back-end of our HR chatbot.</p>\n\n<h2 id=\"the-method\">The Method</h2>\n\n<p>I found a couple of tutorials and quick-starts to create chatbots on my documentation - \n<a href=\"https://github.com/Azure-Samples/azure-search-openai-demo\">Azure Search OpenAI demo</a>\nor <a href=\"https://techcommunity.microsoft.com/t5/startups-at-microsoft/build-a-chatbot-to-query-your-documentation-using-langchain-and/ba-p/3833134\">Query your documentation using Langchain</a></p>\n\n<p>The issue I found is that it\u2019s all moving quite fast - faster than the tutorials can keep up with. All mention of <a href=\"https://www.langchain.com/\">Langchain</a> has now gone from the Azure portal (although you can still <a href=\"https://towardsdatascience.com/talk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2\">write your own</a> Langchain chatbot), and QnA maker has now moved on and we have <a href=\"https://language.cognitive.azure.com/\">Azure AI Language Studio</a> where you can add in your documents via a \u201cCustom Question Answering\u201d project, which is a type of Azure \u201cLanguage\u201d and can be created via the LoCode/NoCode <a href=\"https://language.cognitive.azure.com/\">Language Studio homepage</a>. The tutorial speedily guides you through a simply-configured web form although it\u2019s not quite clear what you are actually going to create - looking at what was deployed after the configuration steps, this sets up an Azure cognitive search (AI search) repository and then enables custom text classification / custom named entity recognition on the repository. The default behaviour for this appears to be breaking down the content in your referenced documents into paragraphs and pulling out likely titles/subjects. You can then modify this classification by adding in new questions and answers, or choosing the best answer for given terms.</p>\n\n<p>The free trial only allows you to upload three sources into your AI search repository. So, for our HR example, I\u2019ve downloaded three HR policy documents from <a href=\"https://staffsquared.com/free-hr-documents/\">this handy online repository</a> and added them into my Custom Question Answering repository. This generates a \u201cKnowledge Base\u201d that I can then publish.</p>\n\n<p><img alt=\"Upload documents into your language knowledge base\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/upload-docs.jpg\" /></p>\n\n<p>Here we can see the way that the content has been divided up into major terms and paragraphs that may address those terms. I can edit here, and once it\u2019s published I can generate a Bot to act as the user interface to it.</p>\n\n<p><img alt=\"knowledge base parsed from documents\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/knowledge-base.jpg\" /></p>\n\n<p>OK so now onto creating this Bot. As Bots go, OpenAI\u2019s <a href=\"https://chat.openai.com\">ChatGPT</a> is the real deal. Generative AI, pre-trained to recognise vast arrays of English language. For most use cases we would have to \u201cturn off\u201d all the fun, generative stuff for our application (see Guardrails below) and it\u2019s probably overkill to use ChatGPT for this demo - plus, it isn\u2019t included in the Azure Free Trial tier so I will be experimenting with the <a href=\"https://azure.microsoft.com/en-gb/products/ai-services/ai-bot-service\">Azure AI Bot Service</a> instead. It should be sufficient for this fairly small and simple demo.\nCost-wise, the Azure AI Bot has a free tier, but it must be hosted via an Azure Web App whose service plan is defaulted to S1 (Standard). This plan, at \u00a375/month to keep it running, is eating rapidly into my free credit!</p>\n\n<p>Configuring the Bot online is pretty straightforward. The web GUI provides you with a customised template for creating the resources that you will need, creating an App Service Plan to launch an Azure WebApp that will host your Bot. The only config you have to do is enter the key of your Language Resource so that you can create a secure connection between the AI service knowledge base and the chatbot. This isn\u2019t documented, but you can find the key by going back to the Azure Portal home and clicking the green squares \u201cAll Resources\u201d view, then selecting your Language resource (the resource where Type = Language) and then selecting the Keys and Endpoint menu item. (There are two keys, so that you can refresh them by rotating them individually and hence avoid downtime. Either one is fine.)</p>\n\n<h2 id=\"testing\">Testing</h2>\n\n<p>Once your Bot is deployed, you can test it by finding it under All Resources and choosing \u201cTest in Web Chat\u201d from the right hand menu.</p>\n\n<p>I tried with a simple question, that I know is answerable with the content in the documents:\n<img alt=\"Trial question\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/good-answer.jpg\" /></p>\n\n<p>So far so good. The Bot has successfully found the right bit of my documentation and returned a comprehensive and understandable answer. How about another:</p>\n\n<p><img alt=\"Second question\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/bad-answer.jpg\" /></p>\n\n<p>Oh dear. \u201ccannot\u201d is not exactly a strong English sentence! Although it has found the relevant section of the documentation, it has not been able to pull out a contextual answer. \nI am not sure if it is the Language Service or the Bot which is struggling with this question. Enabling and examining the logs on the Bot Service isn\u2019t that helpful - it just shows HTTP POST requests going to the Bot framework. The Bot framework should be responsible for breaking down the user\u2019s entered text into logical \u201cintentions\u201d that the back-end question-answerer can respond to, and then delivering the back-end response in a human readable form.\nI eventually figure out how to <a href=\"https://learn.microsoft.com/en-us/azure/ai-services/diagnostic-logging\">enable logging on my Language Service</a> and discover the query and response that the Bot has sent to the language service:</p>\n\n<p><img alt=\"Bot query to language service\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/backend-query.jpg\" /></p>\n\n<p>I can see that the language service has actually done a reasonable job. It\u2019s identified the right paragraph for the query, but returned just a 38.97% certainty rating that this is the right data. Fair enough. So it seems that the issue is with the Bot being able to pull the right piece of text out of the response. This makes me start to wonder about the \u201cBot\u201d I have deployed. What is it actually based on? There isn\u2019t much documentation I can find, but you can download the source code, which shows that I have deployed something created by the <a href=\"https://github.com/microsoft/botbuilder-js\">BotBuilder SDK</a>. I should be able to run this locally, but weirdly the Bot JavaScript code in my download seems totally out-of-date with the latest Language Studio API. I have to go back to the drawing board and use one of the <a href=\"https://github.com/microsoft/BotBuilder-Samples/tree/main/samples/javascript_nodejs/48.customQABot-all-features\">later samples</a> and update the code to correctly declare a method asynchronous to get the Bot running locally using the Bot Framework Emulator.</p>\n\n<p>To get it to work using Node.js v18.16.0 and restify ^11.1.0, I had to edit the sample code <a href=\"https://github.com/microsoft/BotBuilder-Samples/pull/3939/files\">index.js line 91</a> to declare the method async or it would not start:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>// Listen for incoming requests.\nserver.post('/api/messages', async (req, res) =&gt; {\n    adapter.processActivity(req, res, async (turnContext) =&gt; {\n        // Route the message to the bot's main handler.\n        await bot.run(turnContext);\n    });\n});\n</code></pre></div></div>\n\n<p>I was then able to run the Bot locally connecting to my Azure-hosted Language via the Azure <a href=\"https://github.com/Microsoft/BotFramework-Emulator/blob/master/README.md\">Bot Framework Emulator</a>. And of course as luck would have it, the latest sample doesn\u2019t return such a poor response! It\u2019s still not perfect, but it\u2019s at least a sentence. See below.</p>\n\n<p><img alt=\"Local Bot Service running in emulator\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/via-emulator.jpg\" /></p>\n\n<p>It does also prove that the poor response here was the chatbot interpreting the data from the Language Service. The Language Service will return a field called an AnswerSpan which lists, with a confidence score, the section of the documentation it considers most relevant to the question. In the case of my \u201cdismissal\u201d question, the AnswerSpan returned was:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">An employee whose appointment is terminated for any reason will be provided with a written statement of the reasons for the dismissal</code></p>\n\n<p>This text was paired with a confidence score of 0.2880999999999997, or circa 29%. Fair enough. So how the cloud-deployed bot extracted the answer \u201ccannot\u201d from this is a bit of a mystery! The new version of my Bot prints the whole AnswerSpan and is, whilst still not exactly accurate, at least better. So how do I fix it?</p>\n\n<h2 id=\"customisation\">Customisation</h2>\n\n<p>It seems the way to fix up these simple Bots is to go and add a custom question/answer into the Language Service knowledge base. I try adding a specific answer to the question, \u201cCan I appeal against my dismissal?\u201d. I re-publish the knowledge base and try again.</p>\n\n<p><img alt=\"Adding a custom question\" src=\"https://capgemini.github.io/images/2024-01-08-create-ai-bot-in-azure/fixed-question.jpg\" /></p>\n\n<p>This looks much better. But it does imply that quite a lot of user testing and customisation will have to take place before this Bot is ready to replace its human counterparts.</p>\n\n<h2 id=\"guardrails\">Guardrails</h2>\n\n<p>One of the things that surprised people about ChatGPT, particularly in its earlier iterations, was that it was not trained to be accurate. It was trained to please the user. This would mean it would return inaccurate answers above telling you that it didn\u2019t know the answer, as it had gauged higher satisfaction from \u201clying\u201d! You don\u2019t want your HR chatbot to lie, so you must use the guardrail settings to ensure that it does not. With ChatGPT, guardrails can be set using natural language, for example you can state:</p>\n<pre><code class=\"language-\u2028\">{\"role\": \"system\", \"content\": \"Assistant is an intelligent chatbot designed to help users answer their tax related questions.`\n\nInstructions:\n- Only answer questions related to taxes.\n\n- If you're unsure of an answer, you can say \"I don't know\" or \"I'm not sure\" and recommend users go to the IRS website for more information. \"},\n{\"role\": \"user\", \"content\": \"When are my taxes due?\u201d}\n</code></pre>\n\n<p>This configuration will prevent the chatbot from \u201cmaking up\u201d an answer if it cannot find a decent response in its repository.\nConfiguring Azure\u2019s ChatGPT chatbot via the GUI, to achieve the above you turn the setting known as \u201ctemperature\u201d down to 0. The temperature represents how creative the chatbot can be in getting you an answer. A low temperature results in more \u201cI\u2019m sorry I don\u2019t know\u201d type answers, but increases the chances you\u2019ll get an accurate answer, and that you\u2019ll get the same answer when you ask the same question twice!</p>\n\n<h2 id=\"the-cost\">The Cost</h2>\n\n<p>So what does this cost to run in Azure? Depending on your Bot type, the cost can vary wildly. As mentioned, I am running my Language instance and my Bot instance in the free trial tier, so I am only paying for the app service to host them and this is around \u00a375/month. If you were to use an enterprise ChatGPT Bot, costs are over \u00a3800/month fixed rate for 40 users, plus 80p per \u201cusage unit\u201d and \u00a320 for any extra users over and above the plan. Still considerably cheaper than making your HR staff deal with these queries, I suppose..\nAs mentioned, Azure AI search is priced per GB of data indexed, the free tier runs up to 50 GB, Standard tier gives you 25 GB  for 27p/hour.</p>\n\n<h2 id=\"in-conclusion\">In Conclusion</h2>\n\n<p>I am impressed with the Azure AI search offering - it\u2019s powerful and useful - there are so many scenarios whereby we end up awash with documentation and cannot find the content we need. The chatbots are a varied bunch but I liked the way you could download the code and run/edit it locally with relative ease. In all, I feel this will be a very common architecture for the business problems of the next year or so.</p>\n\n    \n    <p><a href=\"https://capgemini.github.io/cloud/create-ai-bot-in-azure/\">How to (maybe) replace your HR department in 3 easy steps</a> was originally published by Capgemini at <a href=\"https://capgemini.github.io\">Capgemini Software Engineering</a> on January 19, 2024.</p>"
  }
}