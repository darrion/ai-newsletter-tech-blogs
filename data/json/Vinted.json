{
  "company": "Vinted",
  "title": "Vinted",
  "xmlUrl": "http://engineering.vinted.com//atom.xml",
  "htmlUrl": "http://engineering.vinted.com/",
  "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdopting the Vespa search engine for serving personalized second-hand fashion recommendations at Vinted | Vinted Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVinted Engineering\nThese are the voyages of code tailors that help\u00a0create\u00a0Vinted\n\n\nHome\nOpen Source\nJoin Us\n\n\n\n\n\n\nAdopting the Vespa search engine for serving personalized second-hand fashion recommendations at Vinted\n\n        October  9, 2023\n        \n  \n    \n    \n      by  Aleksas Kateiva\n    \n  \n    \n    \n      and  Dainius Jocas\n\n\n\nIn today\u2019s digital landscape, recommender systems have become ubiquitous, curating user experiences across a wide array of online platforms, including Vinted - Europe\u2019s largest online second-hand fashion marketplace. In this blog post, we outline our journey of adopting the Vespa search engine to serve personalized homepage listing recommendations, helping our members find deals they will enjoy. We are excited to share our story as we have found Vespa to be a great solution combining the now trendy vector search with more traditional sparse search techniques, as well as offering a great engineering experience.\nAt Vinted, we\u2019ve implemented a 3-stage recommender system that leverages both explicit and implicit user preferences to offer users a curated list of items presented on the homepage. Explicit preferences are inputted by users on the app, allowing them to specify details such as the clothing sizes they are interested in. Meanwhile, implicit preferences are extracted from historical user interactions on the platform, including clicks and purchases, via the use of machine learning models. This system distills a tailored selection from millions of available listings, presenting users with options most aligned with their tastes and behaviors.\n\n\n\nFigure 1. 3-stage recommender system\n\nThe goal of the first stage of the system is to quickly ( < 100 ms ) recall the most relevant content based on historical user behavior. This is done by utilizing the approximate nearest neighbor (ANN) search with embeddings obtained from an in-house two-tower recommendation model. The listing \u201ctower\u201d of this model is responsible for generating vector representations of listings based on various metadata such as brand, price, size as well as other unstructured data such as photos. The second \u201ctower\u201d is responsible for generating embeddings of user\u2019s preferences characterized by a sequence of past interactions (clicks, favorites & purchases) with listings on the platform. The model is trained in such a way that the distance between a user\u2019s and listing\u2019s embedding represents the affinity or relevance for the given user-item pair. This score can then be used to rank listings based on relevance for a given user and select a smaller list of candidates for the next stage.\n\n\nFigure 2. Two-tower recommendation retrieval model\n\nWhen implementing the first iteration of this system we have chosen to use the Facebook AI Similarity Search (Faiss) library for performing ANN searches. While Faiss served us well in the first iterations of this system to prove value, it is not a complete database solution, and we found the following drawbacks:\n\nWe used Faiss as a read-only index in a stateless Kubernetes service that would have to be periodically rebuilt and redeployed to include newly uploaded items and remove sold or deleted content.\nFaiss has no capability for approximate nearest neighbor searches with pre-filtering based on metadata. You can only retrieve the top-k scoring items from this index, and any filtering would have to be performed as a post-processing step on the fixed-length list of retrieved items. This was especially problematic for us, as our product allows users to specify custom filters. Therefore, if the top-scoring items retrieved did not pass these filters, our users would see no recommendations at all.\n\nSo we set out in search of a database system that would take care of managing the data and indices, as well as allow us to filter items based on metadata such as brand, size, and so on such that we could always retrieve recommendations for our users, no matter what filters they have set.\nIn search for a vector search database\nAs alternative technologies that could satisfy the constraints mentioned above, in the summer of 2022, we\u2019ve evaluated Vespa and Elasticsearch. More systems that support ANN with prefiltering were researched but eventually rejected either because of licensing concerns ( Vinted prefers truly open-source licensed software ) or due to overall lack of maturity of the project.\nVespa\nVespa is an application platform for low-latency computations over large datasets. It is used to solve problems such as search, vector search, real-time recommendation, personalization, ad targeting, etc. The platform is open source under the Apache 2.0 license. One particular aspect that drew us to Vespa was its first-class support for machine learning based search and ranking. On top of that, the real-time data update capability is appealing. The main complicating factor for adoption was that Vinted had no experience with Vespa.\nElasticsearch\nElasticsearch is a mature and popular system for search and analytics use cases. Elasticsearch is built on top of the Lucene library. The seemingly endless list of features makes it a trusty and future-proof technology. Elasticsearch supports ANN with prefiltering from version 8.0.\nEven though the license is not open-source, Elasticsearch was a strong contender because Vinted was already using it for search and had solid engineering competencies to operate it at scale.\nBenchmarking\nTo understand how these technologies would perform for our use case, we implemented benchmarks using real data. The goal of these benchmarks was to measure peak document indexing throughput as well as query throughput and latency.\nSetup\nBenchmarks were performed on a single Google Cloud Platform n1-standard-64 VM instance (64 vCPUs, 236 GB). The dataset consisted of ~1M  documents, each document contained 12 fields and a 256 dimension float32 embedding. Both Elasticsearch (8.2.2) and Vespa (8.17.19) were deployed as Docker containers, and we\u2019ve made sure to keep the ANN index (HNSW) hyperparameters consistent across both platforms for a fair comparison.\nResults\nIn our benchmarks, we found that  Vespa had a 3.8x higher document indexing throughput. Furthermore, querying benchmarks have shown that  Vespa was able to handle 8x more RPS before saturating the CPU, and at this throughput had a P99 latency of 26ms. Elasticsearch, even at just 250 RPS had a P99 latency of 110ms (4.23 times higher).\nOf course, if the benchmarks were run today with up-to-date versions then the numbers would be different.\nGiven these results, we have decided to move forward with setting up Vespa for an AB test.\nSystem setup\nHaving the numbers from the load testing, we\u2019ve estimated that to achieve high-availability (HA), 3 servers with 56 CPU cores each were needed to handle the expected load for the AB test. Deploying Vespa was as easy as setting an environment variable\nVESPA_CONFIGSERVERS=server1.vinted.com,server2.vinted.com,server3.vinted.com\n\nand then running a Docker container with Vespa on each server.\nThe application package was mostly the same as the one used for the load testing. The only change was that we\u2019ve set up the content cluster with 3 groups. That made each server store a complete copy of the dataset and having more groups helped to scale the query throughput.\nOperations\nWe\u2019ve found that Vespa is generally easy to operate. One reason is that after the initial setup there is no need to touch the running servers: all the configuration is controlled by deploying the application package. On top of that, Vespa out-of-the-box exposes an extensive set of metrics in Prometheus format that makes creating detailed Grafana dashboards an easy task.\nWe consider the performance to be good enough:  the P99 latency of first stage retrieval handled by Vespa is around ~50 ms. However, there was a small portion of problematic queries that took much longer to execute than the set query timeout of 150ms. Vespa has an excellent tool for debugging problematic queries: tracing. With the hints from the traces, we\u2019ve sought help in the Vespa Slack which led to a GitHub issue. The Vespa team was quick to respond and fixed the root cause of the issue in subsequent Vespa releases. So far so good.\nApproximate Search vs Exact Search\nAs mentioned previously, the first-stage of our recommendation system utilizes an approximate nearest neighbor search algorithm to balance the trade-off between accuracy and speed. When dealing with large datasets, finding exact nearest neighbors can be computationally expensive, as it requires a linear scan across the entire corpus. Approximate search algorithms such as HNSW aim to find neighbors that are \u201cclose enough\u201d, which makes the search faster at the cost of accuracy. Additionally, ANN search algorithms often allow for fine tuning of the accuracy vs speed trade-off via parameters such as the \u201cmax-links-per-node\u201d.\nWe were curious to quantify exactly how much accuracy was traded off by our choice of the HNSW parameters we\u2019ve set in our Vespa deployment. Initially, we started by measuring recall - the proportion of matching documents retrieved between approximate and exact searches. We\u2019ve found that with our choice of parameters the recall was around 60-70%. However, visually the retrieved results and scores were very similar, and we were wondering if our users could perceive this difference and if that difference would affect their engagement and satisfaction. To test this hypothesis, we performed an AB test where half of our users received recommendations retrieved using approximate search, and the other half received exact search results.\nTo accommodate such an experiment we needed some spare hardware resources. Luckily, we\u2019ve recently set up a bigger Vespa deployment and until other features were deployed the resources were readily available. When it comes to Vespa, it is easy to switch from ANN to exact search just by changing a query parameter, i.e. approximate:true was changed to approximate:false, e.g.\nselect * from doc where {targetHits: 100, approximate:true}nearestNeighbor(user_embeddings)\n// to\nselect * from doc where {targetHits: 100, approximate:false}nearestNeighbor(user_embeddings)\n\nThe change in algorithm caused the latency at P99 to jump from a stable ~50ms to a more bumpy ~70ms (+40%).\n\n\nFigure 3. Vespa P99 search latency after starting the exact search experiment\n\nThe CPU load on Vespa search nodes increased slightly, however, we found that the user satisfaction with the exact search had not increased enough to justify the higher resource usage and query latency.\nMember testimonies\nThe implementation of our recommender system on Vespa was a pleasant experience from an engineering point of view. While we were able to measure increased member satisfaction via a sequence of AB tests along the way, we were pleasantly surprised to hear member feedback about improvements that we were able to deliver by utilizing the new capabilities provided by Vespa:\n\nI don\u2019t know why I hadn\u2019t looked at this or used this before as much as I do now.\n\n\nActually, Vinted is I think the only app that I use to just browse the main page because the stuff that comes up there is personalized to the user and based probably on my recent searches and recent buys and finds.\n\n\nI\u2019ve recently found that I do find myself overnight time scrolling through. Actually, the matches are pretty good, you know, often where I put quite a lot of stuff in my favorites by just looking at that.\n\nA cherry on top is when we hear anecdotal feedback from random people mentioning that they only use the recommendations feature on Vinted because for them it seems that Vinted has a better understanding of their taste now.\nSummary and future work\nBy leveraging ANN with prefiltering we\u2019ve significantly improved the relevance of recommendations on our homepage. Also, the broader adoption of Vespa for item recommendation use cases enables numerous other product improvements and paves the way to simplify our system architecture.\nOur team is excited about what we\u2019ve achieved so far, and we can\u2019t wait until we release new features for Vinted members that leverage the blend of dense and sparse retrieval techniques. Stay tuned!\n\n\n\n\n\nHome\nOpen Source\nJoin Us\nRSS\nTwitter\n\n\n\n\n\n\n\n",
  "latestPost": {
    "title": "Adopting the Vespa search engine for serving personalized second-hand fashion recommendations at Vinted",
    "title_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://vinted.engineering/atom.xml",
      "value": "Adopting the Vespa search engine for serving personalized second-hand fashion recommendations at Vinted"
    },
    "links": [
      {
        "href": "https://vinted.engineering//2023/10/09/adopting-vespa-for-recommendation-retrieval/",
        "rel": "alternate",
        "type": "text/html",
        "title": "Adopting the Vespa search engine for serving personalized second-hand fashion recommendations at Vinted"
      }
    ],
    "link": "https://vinted.engineering//2023/10/09/adopting-vespa-for-recommendation-retrieval/",
    "published": "2023-10-09T00:00:00+00:00",
    "published_parsed": [
      2023,
      10,
      9,
      0,
      0,
      0,
      0,
      282,
      0
    ],
    "updated": "2023-10-09T00:00:00+00:00",
    "updated_parsed": [
      2023,
      10,
      9,
      0,
      0,
      0,
      0,
      282,
      0
    ],
    "id": "https://vinted.engineering//2023/10/09/adopting-vespa-for-recommendation-retrieval",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://vinted.engineering//2023/10/09/adopting-vespa-for-recommendation-retrieval/",
        "value": "<p>In today\u2019s digital landscape, recommender systems have become ubiquitous, curating user experiences across a wide array of online platforms, including Vinted - Europe\u2019s largest online second-hand fashion marketplace. In this blog post, we outline our journey of adopting the Vespa search engine to serve personalized homepage listing recommendations, helping our members find deals they will enjoy. We are excited to share our story as we have found Vespa to be a great solution combining the now trendy vector search with more traditional sparse search techniques, as well as offering a great engineering experience.</p>\n\n<p>At Vinted, we\u2019ve implemented a 3-stage recommender system that leverages both explicit and implicit user preferences to offer users a curated list of items presented on the homepage. Explicit preferences are inputted by users on the app, allowing them to specify details such as the clothing sizes they are interested in. Meanwhile, implicit preferences are extracted from historical user interactions on the platform, including clicks and purchases, via the use of machine learning models. This system distills a tailored selection from millions of available listings, presenting users with options most aligned with their tastes and behaviors.</p>\n\n<!--truncate-->\n\n<figure class=\"image\" style=\"text-align: center; margin-bottom: 1em;\">\n  <img alt=\"Vinted multi-stage recommender system\" src=\"https://vinted.engineering/static/2023/10/recommender_stages.png?style=centered\" />\n  <figcaption>Figure 1. 3-stage recommender system</figcaption>\n</figure>\n\n<p>The goal of the first stage of the system is to quickly ( &lt; 100 ms ) recall the most relevant content based on historical user behavior. This is done by utilizing the approximate nearest neighbor (ANN) search with embeddings obtained from an in-house two-tower recommendation model. The listing \u201ctower\u201d of this model is responsible for generating vector representations of listings based on various metadata such as brand, price, size as well as other unstructured data such as photos. The second \u201ctower\u201d is responsible for generating embeddings of user\u2019s preferences characterized by a sequence of past interactions (clicks, favorites &amp; purchases) with listings on the platform. The model is trained in such a way that the distance between a user\u2019s and listing\u2019s embedding represents the affinity or relevance for the given user-item pair. This score can then be used to rank listings based on relevance for a given user and select a smaller list of candidates for the next stage.</p>\n\n<figure class=\"image\" style=\"text-align: center; margin-bottom: 1em;\">\n  <img alt=\"A diagram of a two-tower recommender model\" src=\"https://vinted.engineering/static/2023/10/recommender_towers.png?style=centered\" />\n  <figcaption>Figure 2. Two-tower recommendation retrieval model</figcaption>\n</figure>\n\n<p>When implementing the first iteration of this system we have chosen to use the <a href=\"https://github.com/facebookresearch/faiss\">Facebook AI Similarity Search (Faiss)</a> library for performing ANN searches. While Faiss served us well in the first iterations of this system to prove value, it is not a complete database solution, and we found the following drawbacks:</p>\n<ol>\n  <li>We used Faiss as a read-only index in a stateless Kubernetes service that would have to be periodically rebuilt and redeployed to include newly uploaded items and remove sold or deleted content.</li>\n  <li>Faiss has no capability for approximate nearest neighbor searches with pre-filtering based on metadata. You can only retrieve the top-k scoring items from this index, and any filtering would have to be performed as a post-processing step on the fixed-length list of retrieved items. This was especially problematic for us, as our product allows users to specify custom filters. Therefore, if the top-scoring items retrieved did not pass these filters, our users would see no recommendations at all.</li>\n</ol>\n\n<p>So we set out in search of a database system that would take care of managing the data and indices, as well as allow us to filter items based on metadata such as brand, size, and so on such that we could always retrieve recommendations for our users, no matter what filters they have set.</p>\n\n<h1 id=\"in-search-for-a-vector-search-database\">In search for a vector search database</h1>\n\n<p>As alternative technologies that could satisfy the constraints mentioned above, in the summer of 2022, we\u2019ve evaluated Vespa and Elasticsearch. More systems that support ANN with prefiltering were researched but eventually rejected either because of licensing concerns ( Vinted prefers truly open-source licensed software ) or due to overall lack of maturity of the project.</p>\n\n<h3 id=\"vespa\">Vespa</h3>\n\n<p><a href=\"https://vespa.ai\">Vespa</a> is an application platform for low-latency computations over large datasets. It is used to solve problems such as search, vector search, real-time recommendation, personalization, ad targeting, etc. The platform is open source under the Apache 2.0 license. One particular aspect that drew us to Vespa was its first-class support for machine learning based search and ranking. On top of that, the real-time data update capability is appealing. The main complicating factor for adoption was that Vinted had no experience with Vespa.</p>\n\n<h3 id=\"elasticsearch\">Elasticsearch</h3>\n\n<p><a href=\"https://www.elastic.co\">Elasticsearch</a> is a mature and popular system for search and analytics use cases. Elasticsearch is built on top of the Lucene library. The seemingly endless list of <a href=\"https://www.elastic.co/elasticsearch/features#vector-search-ann\">features</a> makes it a trusty and future-proof technology. Elasticsearch supports <a href=\"https://www.elastic.co/blog/introducing-approximate-nearest-neighbor-search-in-elasticsearch-8-0\">ANN</a> with prefiltering from version 8.0.</p>\n\n<p>Even though the license is not open-source, Elasticsearch was a strong contender because Vinted was already using it for search and had solid engineering competencies to operate it at scale.</p>\n\n<h1 id=\"benchmarking\">Benchmarking</h1>\n\n<p>To understand how these technologies would perform for our use case, we implemented benchmarks using real data. The goal of these benchmarks was to measure peak document indexing throughput as well as query throughput and latency.</p>\n\n<h3 id=\"setup\">Setup</h3>\n\n<p>Benchmarks were performed on a single Google Cloud Platform n1-standard-64 VM instance (64 vCPUs, 236 GB). The dataset consisted of ~1M  documents, each document contained 12 fields and a 256 dimension float32 embedding. Both Elasticsearch (8.2.2) and Vespa (8.17.19) were deployed as Docker containers, and we\u2019ve made sure to keep the ANN index (HNSW) hyperparameters consistent across both platforms for a fair comparison.</p>\n\n<h3 id=\"results\">Results</h3>\n\n<p>In our benchmarks, we found that  Vespa had a 3.8x higher document indexing throughput. Furthermore, querying benchmarks have shown that  Vespa was able to handle 8x more RPS before saturating the CPU, and at this throughput had a P99 latency of 26ms. Elasticsearch, even at just 250 RPS had a P99 latency of 110ms (4.23 times higher).</p>\n\n<p>Of course, if the benchmarks were run today with up-to-date versions then the numbers would be different.</p>\n\n<p>Given these results, we have decided to move forward with setting up Vespa for an AB test.</p>\n\n<h1 id=\"system-setup\">System setup</h1>\n\n<p>Having the numbers from the load testing, we\u2019ve estimated that to achieve high-availability (HA), 3 servers with 56 CPU cores each were needed to handle the expected load for the AB test. Deploying Vespa was as easy as setting an environment variable</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>VESPA_CONFIGSERVERS=server1.vinted.com,server2.vinted.com,server3.vinted.com\n</code></pre></div></div>\n<p>and then running a Docker container with Vespa on each server.</p>\n\n<p>The application package was mostly the same as the one used for the load testing. The only change was that we\u2019ve set up the content cluster with 3 groups. That made each server store a complete copy of the dataset and having more groups helped to scale the query throughput.</p>\n<h3 id=\"operations\">Operations</h3>\n<p>We\u2019ve found that Vespa is generally easy to operate. One reason is that after the initial setup there is no need to touch the running servers: all the configuration is controlled by deploying the application package. On top of that, Vespa out-of-the-box exposes an extensive set of metrics in Prometheus format that makes creating detailed Grafana dashboards an easy task.</p>\n\n<p>We consider the performance to be good enough:  the P99 latency of first stage retrieval handled by Vespa is around ~50 ms. However, there was a small portion of problematic queries that took much longer to execute than the set query timeout of 150ms. Vespa has an excellent tool for debugging problematic queries: <a href=\"https://docs.vespa.ai/en/reference/query-api-reference.html#trace.level\">tracing</a>. With the hints from the traces, we\u2019ve sought help in the Vespa Slack which led to a GitHub <a href=\"https://github.com/vespa-engine/vespa/issues/26663\">issue</a>. The Vespa team was quick to respond and fixed the root cause of the issue in subsequent Vespa releases. So far so good.</p>\n\n<h3 id=\"approximate-search-vs-exact-search\">Approximate Search vs Exact Search</h3>\n\n<p>As mentioned previously, the first-stage of our recommendation system utilizes an approximate nearest neighbor search algorithm to balance the trade-off between accuracy and speed. When dealing with large datasets, finding exact nearest neighbors can be computationally expensive, as it requires a linear scan across the entire corpus. Approximate search algorithms such as HNSW aim to find neighbors that are \u201cclose enough\u201d, which makes the search faster at the cost of accuracy. Additionally, ANN search algorithms often allow for fine tuning of the accuracy vs speed trade-off via parameters such as the \u201c<a href=\"https://blog.vespa.ai/billion-scale-knn-part-two/#:~:text=max%2Dlinks%2Dper%2Dnode,value%20in%20Vespa%20is%2016\">max-links-per-node</a>\u201d.</p>\n\n<p>We were curious to quantify exactly how much accuracy was traded off by our choice of the HNSW parameters we\u2019ve set in our Vespa deployment. Initially, we started by measuring recall - the proportion of matching documents retrieved between approximate and exact searches. We\u2019ve found that with our choice of parameters the recall was around 60-70%. However, visually the retrieved results and scores were very similar, and we were wondering if our users could perceive this difference and if that difference would affect their engagement and satisfaction. To test this hypothesis, we performed an AB test where half of our users received recommendations retrieved using approximate search, and the other half received exact search results.</p>\n\n<p>To accommodate such an experiment we needed some spare hardware resources. Luckily, we\u2019ve recently set up a bigger Vespa deployment and until other features were deployed the resources were readily available. When it comes to Vespa, it is easy to switch from ANN to exact search just by changing a query parameter, i.e. <code class=\"language-plaintext highlighter-rouge\">approximate:true</code> was changed to <code class=\"language-plaintext highlighter-rouge\">approximate:false</code>, e.g.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>select * from doc where {targetHits: 100, approximate:true}nearestNeighbor(user_embeddings)\n// to\nselect * from doc where {targetHits: 100, approximate:false}nearestNeighbor(user_embeddings)\n</code></pre></div></div>\n\n<p>The change in algorithm caused the latency at P99 to jump from a stable ~50ms to a more bumpy ~70ms (+40%).</p>\n\n<figure class=\"image\" style=\"text-align: center; margin-bottom: 1em;\">\n  <img alt=\"A chart showing latency increase from 50ms to 70ms.\" src=\"https://vinted.engineering/static/2023/10/recommender_latency.png?style=centered\" />\n  <figcaption>Figure 3. Vespa P99 search latency after starting the exact search experiment</figcaption>\n</figure>\n\n<p>The CPU load on Vespa search nodes increased slightly, however, we found that the user satisfaction with the exact search had not increased enough to justify the higher resource usage and query latency.</p>\n\n<h3 id=\"member-testimonies\">Member testimonies</h3>\n\n<p>The implementation of our recommender system on Vespa was a pleasant experience from an engineering point of view. While we were able to measure increased member satisfaction via a sequence of AB tests along the way, we were pleasantly surprised to hear member feedback about improvements that we were able to deliver by utilizing the new capabilities provided by Vespa:</p>\n\n<blockquote>\n  <p>I don\u2019t know why I hadn\u2019t looked at this or used this before as much as I do now.</p>\n</blockquote>\n\n<blockquote>\n  <p>Actually, Vinted is I think the only app that I use to just browse the main page because the stuff that comes up there is personalized to the user and based probably on my recent searches and recent buys and finds.</p>\n</blockquote>\n\n<blockquote>\n  <p>I\u2019ve recently found that I do find myself overnight time scrolling through. Actually, the matches are pretty good, you know, often where I put quite a lot of stuff in my favorites by just looking at that.</p>\n</blockquote>\n\n<p>A cherry on top is when we hear anecdotal feedback from random people mentioning that they only use the recommendations feature on Vinted because for them it seems that Vinted has a better understanding of their taste now.</p>\n\n<h1 id=\"summary-and-future-work\">Summary and future work</h1>\n<p>By leveraging ANN with prefiltering we\u2019ve significantly improved the relevance of recommendations on our homepage. Also, the broader adoption of Vespa for item recommendation use cases enables numerous other product improvements and paves the way to simplify our system architecture.</p>\n\n<p>Our team is excited about what we\u2019ve achieved so far, and we can\u2019t wait until we release new features for Vinted members that leverage the blend of dense and sparse retrieval techniques. Stay tuned!</p>"
      }
    ],
    "summary": "In today\u2019s digital landscape, recommender systems have become ubiquitous, curating user experiences across a wide array of online platforms, including Vinted - Europe\u2019s largest online second-hand fashion marketplace. In this blog post, we outline our journey of adopting the Vespa search engine to serve personalized homepage listing recommendations, helping our members find deals they will enjoy. We are excited to share our story as we have found Vespa to be a great solution combining the now trendy vector search with more traditional sparse search techniques, as well as offering a great engineering experience. At Vinted, we\u2019ve implemented a 3-stage recommender system that leverages both explicit and implicit user preferences to offer users a curated list of items presented on the homepage. Explicit preferences are inputted by users on the app, allowing them to specify details such as the clothing sizes they are interested in. Meanwhile, implicit preferences are extracted from historical user interactions on the platform, including clicks and purchases, via the use of machine learning models. This system distills a tailored selection from millions of available listings, presenting users with options most aligned with their tastes and behaviors.",
    "authors": [
      {
        "name": "Aleksas Kateiva",
        "href": "https://github.com/akateiva"
      }
    ],
    "author_detail": {
      "name": "Aleksas Kateiva",
      "href": "https://github.com/akateiva"
    },
    "href": "https://github.com/akateiva",
    "author": "Aleksas Kateiva",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://vinted.engineering/atom.xml",
      "value": "In today\u2019s digital landscape, recommender systems have become ubiquitous, curating user experiences across a wide array of online platforms, including Vinted - Europe\u2019s largest online second-hand fashion marketplace. In this blog post, we outline our journey of adopting the Vespa search engine to serve personalized homepage listing recommendations, helping our members find deals they will enjoy. We are excited to share our story as we have found Vespa to be a great solution combining the now trendy vector search with more traditional sparse search techniques, as well as offering a great engineering experience. At Vinted, we\u2019ve implemented a 3-stage recommender system that leverages both explicit and implicit user preferences to offer users a curated list of items presented on the homepage. Explicit preferences are inputted by users on the app, allowing them to specify details such as the clothing sizes they are interested in. Meanwhile, implicit preferences are extracted from historical user interactions on the platform, including clicks and purchases, via the use of machine learning models. This system distills a tailored selection from millions of available listings, presenting users with options most aligned with their tastes and behaviors."
    }
  }
}