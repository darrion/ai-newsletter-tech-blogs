{
  "company": "Hashnode",
  "title": "Hashnode",
  "xmlUrl": "https://engineering.hashnode.com/rss.xml",
  "htmlUrl": "https://engineering.hashnode.com/",
  "content": "EventBridge Scheduler & CDK: Post Schedule SetupFollowFollowSetting Up Post Schedules with EventBridge Scheduler & CDKSandro Volpicella\u00b7Jan 16, 2024\u00b76 min readFeatured on HashnodeOne essential feature of any blogging platform is the ability to schedule posts for publication. Hashnode introduced this functionality in June 2022.\nAt that time, the entire feature was based on a CRON job. This CRON job managed all various states and published the post. The CRON job was running every minute to ensure that scheduled posts were published.\nThere were certain cons associated with the CRON job:\n\nUnnecessary computation: The CRON job ran even if no posts were scheduled at that time.\n\nObservability: Each execution of the CRON job produced logs and traces. It was quite hard to understand if and how many posts were scheduled at a certain time.\n\nError Handling: Error handling was quite hard. If one post failed to be published we couldn't let the whole processing Lambda fail. Alerting needed special functionalities to handle that.\n\n\nWith the launch of EventBridge Scheduler in 2022 we instantly knew that scheduling posts is a perfect use-case for that.\nEventBridge Scheduler\n\nEventBridge scheduler is a feature of EventBridge that allows users to schedule tasks at precise times. You can schedule a task that will be executed once at an exact time.\nThe same targets are supported as for EventBridge, such as:\n\nLambda\n\nSQS\n\nSNS\n\nStep Functions\n\n... and many more!\n\n\nScheduling Posts with EventBridge Scheduler\n\nLet's see how we have implemented the scheduling of posts with the scheduler.\nEventBridge Scheduling Basics\nBefore we worked on any API integrations we first created a few resources we needed to share with our API:\n\nEventBridge Scheduling Group\n\nLambda Consumer with DLQ (consumer errors)\n\nSQS Dead-Letter-Queue (server-side errors)\n\nIAM Role\n\n\n\n\u261d\nHashnode uses two different CDK apps. One for all asynchronous workloads in plain CDK. And another one with SST for our synchronous APIs. Data needs to be shared via SSM parameters.\n\nEventBridge Scheduling Group\nFor improving the overview of schedules it is recommended to create schedule groups. It is easier to filter your schedules based on these. We have created one group with the name: SchedulePublishDraft.\nnew CfnScheduleGroup(this, 'SchedulePublishDraft');\n\nThis group needs to be supplied once the schedule is created.\nLambda Consumer\n\nNext, we need a Consumer for our EventBridge Schedule. The schedule is scheduled for a specific time. Once this time is reached a target consumer is called.\nWe use AWS Lambda for that. The Lambda function will be called asynchronously. The asynchronous call gives us the ability to use Lambda Destinations. You have two types of Lambda Destinations:\n\nonSuccess: This is called once the Lambda succeeds\n\nonFailure: This is called once the Lambda fails\n\n\nWe make use of the onFailure destination. Once the Lambda function encounters some error and fails, we retry the event two times. If it still fails we send it to a Dead-Letter-Queue (DLQ).\nThe Lambda function executes the business logic (publishing the post, and updating some database states).\n\n\ud83d\udea7\nRemember: Your EventBridge consumer needs to be idempotent. If not it can (and will happen) that your consumer is executed twice. Which could result in duplicated post publishes.\n\nScheduling DLQ (server-side errors)\n\nThere is a second DLQ we need to supply in our creation of the EventBridge schedule. This DLQ handles all server-side errors like missing IAM permissions or Lambda API outages.\nWe now have two DLQs in place:\n\nThe first one is for server-side errors. For example: Missing IAM policies or when the Lambda API is down\n\nThe second one is for consumer errors. In case the Lambda function fails, the event will be retried two times and after that sent to a DLQ.\n\n\nIn this section, we are talking about the first one. This one is needed to supply while creating the schedule.\nWe create this DLQ with CDK as well and share it via a parameter:\n\nconst dlqScheduler = new MonitoredDeadLetterQueue(this, 'SchedulerDlq');\n\nthis.scheduleDeadLetterArn = dlqScheduler.queueArn;\n\nnew StringParameter(this, 'EventBridgeSchedulerDLQArn', {\n  stringValue: this.scheduleDeadLetterArn,\n  parameterName: `/${envName}/infra/schedulePublishDraft/schedulerDeadLetterQueueArn`\n});\n\nThis gives us the ability to use the parameter in the second API CDK app.\nIAM Role\nWhile creating the schedule you need to supply an IAM Role ARN. This role is used for executing the schedule.\nThis is the CDK code we are using:\nthis.role = new Role(this, 'RevokeProAccessPublicationRole', {\n  assumedBy: new ServicePrincipal('scheduler.amazonaws.com')\n});\n\nthis.postPublishLambda.grantInvoke(this.role);\n\n\nnew StringParameter(this, 'TargetRoleArn', {\n  stringValue: this.role.roleArn,\n  parameterName: `/${envName}/infra/schedulePublishDraft/targetRoleArn`\n});\n\nWe create a role that can be assumed by the scheduler service. We then grant the invoke permissions for one Lambda to this role and save it as a string parameter in SSM.\nCRUD Operations\nOne of the main things we needed to think about is how we want to Create, Update, and Delete the schedules. Hashnode uses a GraphQL API. We have had several mutations for handling schedules already (yes the naming can be quite hard with posts and drafts...):\n\nscheduleDraft\n\nreschedulePost\n\ncancelScheduledPost\n\n\nThese operations handled the creation of documents in our database. Each of these mutation need to handle the EventBridge schedule CRUD operation.\nSchedule Drafts\nScheduling a draft needs to create the EventBridge schedule. We have our own package in our monorepo called @hashnode/scheduling. This package abstracts the calls to EventBridge and allows us to type it more precisely for our needs.\nFor publishing a draft we only need to call the function schedulePublishDraftScheduler() and everything else is abstracted. The function will\n\nParse incoming data with zod\n\nCreates the CreateScheduleCommand\n\nSends the command to EventBridge to create the schedule\n\n\nThe create command looks like this:\nconst command = new CreateScheduleCommand({\n  Name: createName({\n    draftId\n  }),\n  GroupName: groupName,\n  ScheduleExpression: `at(${formattedDate})`,\n  ScheduleExpressionTimezone: 'UTC',\n  Target: {\n    Arn: targetArn,\n    RoleArn: targetRoleArn,\n    Input: JSON.stringify(schedulerPayload),\n    DeadLetterConfig: {\n      Arn: deadLetterArn\n    }\n  },\n  FlexibleTimeWindow: { Mode: 'OFF' },\n  ActionAfterCompletion: 'DELETE'\n});\n\nThe name of each schedule should be unique (no drafts can be scheduled twice). The name follows this pattern:\n`SchedulePublishDraft-${draftId.toString()}`\n\nThe Target input object shows you all the data we have created before:\n\nArn: ARN of the Lambda function that executes the business logic\n\nRoleArn: The ARN of the Role\n\nDeadLetterConfig.Arn: The ARN of the DLQ for server-side errors\n\n\nWe also set the flag ActionAfterCompletion to DELETE to make sure each schedule is removed after it runs successfully.\nReschedule Drafts & Cancel Schedules\nRescheduling and canceling scheduled drafts follows the same procedure as creating them. In rescheduling, we make sure that the date is valid. We update the schedule.\nFor canceling schedules we simply remove the schedule from EventBridge.\nResults after that\nWe've deployed everything on production without any issues. A very minimal migration was needed to create schedules for all existing drafts.\nNow, if one post publish fails we get alerted immediately with exactly the post that failed.\nThe development and integration of using EventBridge Schedules for use cases like this are straightforward. The benefits of simplicity we have are immense.\nSummary\nThis post should show you how easy it can be to leverage the managed services of AWS for features like that. The scheduling stack costs 1ct per month at the moment.\n\nOne alternative approach for tackling this issue of the CRON job would have been to use SQS and partial batch failures. However, the EventBridge scheduling approach is much more simple. And simple is king.\nResources\nHashnode\nJoin our Discord Server\nAWSevent-driven-architectureHashnodeCloudStartups",
  "latestPost": {
    "title": "Setting Up Post Schedules with EventBridge Scheduler & CDK",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.hashnode.com/rss.xml",
      "value": "Setting Up Post Schedules with EventBridge Scheduler & CDK"
    },
    "summary": "<p>One essential feature of any blogging platform is the ability to schedule posts for publication. Hashnode <a href=\"https://townhall.hashnode.com/introducing-article-scheduling-feature-for-all-hashnode-blogs\" target=\"_blank\">introduced</a> this functionality in June 2022.</p><p>At that time, the entire feature was based on a CRON job. This CRON job managed all various states and published the post. The CRON job was running every minute to ensure that scheduled posts were published.</p><p>There were certain cons associated with the CRON job:</p><ul><li><p><strong>Unnecessary computation</strong>: The CRON job ran even if no posts were scheduled at that time.</p></li><li><p><strong>Observability</strong>: Each execution of the CRON job produced logs and traces. It was quite hard to understand if and how many posts were scheduled at a certain time.</p></li><li><p><strong>Error Handling</strong>: Error handling was quite hard. If one post failed to be published we couldn't let the whole processing Lambda fail. Alerting needed special functionalities to handle that.</p></li></ul><p>With the <a href=\"https://aws.amazon.com/blogs/compute/introducing-amazon-eventbridge-scheduler/\" target=\"_blank\">launch of EventBridge Scheduler</a> in 2022 we instantly knew that scheduling posts is a perfect use-case for that.</p><h2 id=\"heading-eventbridge-scheduler\">EventBridge Scheduler</h2><p><img alt=\"eventbridge scheduler example\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1704987466311/ce7b0d1a-b34a-4b14-b42f-8184e7e94136.png\" /></p><p>EventBridge scheduler is a feature of EventBridge that allows users to schedule tasks at precise times. You can schedule a task that will be executed once at an exact time.</p><p>The same targets are supported as for EventBridge, such as:</p><ul><li><p>Lambda</p></li><li><p>SQS</p></li><li><p>SNS</p></li><li><p>Step Functions</p></li><li><p>... and many more!</p></li></ul><h2 id=\"heading-scheduling-posts-with-eventbridge-scheduler\">Scheduling Posts with EventBridge Scheduler</h2><p><img alt=\"scheduling posts with eventbridge\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1705318104814/2df1d43f-f273-469f-916b-71c410841539.png\" /></p><p>Let's see how we have implemented the scheduling of posts with the scheduler.</p><h3 id=\"heading-eventbridge-scheduling-basics\">EventBridge Scheduling Basics</h3><p>Before we worked on any API integrations we first created a few resources we needed to share with our API:</p><ol><li><p>EventBridge Scheduling Group</p></li><li><p>Lambda Consumer with DLQ (consumer errors)</p></li><li><p>SQS Dead-Letter-Queue (server-side errors)</p></li><li><p>IAM Role</p></li></ol><div><div></div><div>Hashnode uses two different CDK apps. One for all asynchronous workloads in plain <strong>CDK</strong>. And another one with <a href=\"https://sst.dev\" target=\"_blank\"><strong>SST</strong></a> for our synchronous APIs. Data needs to be shared via SSM parameters.</div></div><h4 id=\"heading-eventbridge-scheduling-group\">EventBridge Scheduling Group</h4><p>For improving the overview of schedules it is recommended to create schedule groups. It is easier to filter your schedules based on these. We have created one group with the name: <code>SchedulePublishDraft</code>.</p><pre><code class=\"lang-typescript\"><span class=\"hljs-keyword\">new</span> CfnScheduleGroup(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'SchedulePublishDraft'</span>);</code></pre><p>This group needs to be supplied once the schedule is created.</p><h4 id=\"heading-lambda-consumer\">Lambda Consumer</h4><p><img alt=\"alt\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1704878313368/5b6495a6-219b-4d57-b9a9-738f2631fcc0.png\" /></p><p>Next, we need a Consumer for our EventBridge Schedule. The schedule is scheduled for a specific time. Once this time is reached a target consumer is called.</p><p>We use AWS Lambda for that. The Lambda function will be called <strong>asynchronously</strong>. The asynchronous call gives us the ability to use Lambda Destinations. You have two types of Lambda Destinations:</p><ul><li><p><code>onSuccess</code>: This is called once the Lambda succeeds</p></li><li><p><code>onFailure</code>: This is called once the Lambda fails</p></li></ul><p>We make use of the <code>onFailure</code> destination. Once the Lambda function encounters some error and fails, we retry the event two times. If it still fails we send it to a Dead-Letter-Queue (DLQ).</p><p>The Lambda function executes the business logic (publishing the post, and updating some database states).</p><div><div>\ud83d\udea7</div><div><strong>Remember:</strong> Your EventBridge consumer needs to be idempotent. If not it can (and will happen) that your consumer is executed twice. Which could result in duplicated post publishes.</div></div><h4 id=\"heading-scheduling-dlq-server-side-errors\">Scheduling DLQ (server-side errors)</h4><p><img alt=\"DLQ for EventBridge errors\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1704878120894/877ce59a-c6b4-44d8-b5ad-d3da86c63e78.png\" /></p><p>There is a second DLQ we need to supply in our creation of the EventBridge schedule. This DLQ handles all <strong>server-side errors</strong> like missing IAM permissions or Lambda API outages.</p><p>We now have two DLQs in place:</p><ol><li><p>The first one is for server-side errors. For example: Missing IAM policies or when the Lambda API is down</p></li><li><p>The second one is for consumer errors. In case the Lambda function fails, the event will be retried two times and after that sent to a DLQ.</p></li></ol><p>In this section, we are talking about the <strong>first</strong> <strong>one</strong>. This one is needed to supply while creating the schedule.</p><p>We create this DLQ with CDK as well and share it via a parameter:</p><pre><code class=\"lang-typescript\"><span class=\"hljs-keyword\">const</span> dlqScheduler = <span class=\"hljs-keyword\">new</span> MonitoredDeadLetterQueue(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'SchedulerDlq'</span>);<span class=\"hljs-built_in\">this</span>.scheduleDeadLetterArn = dlqScheduler.queueArn;<span class=\"hljs-keyword\">new</span> StringParameter(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'EventBridgeSchedulerDLQArn'</span>, {  stringValue: <span class=\"hljs-built_in\">this</span>.scheduleDeadLetterArn,  parameterName: <span class=\"hljs-string\">`/<span class=\"hljs-subst\">${envName}</span>/infra/schedulePublishDraft/schedulerDeadLetterQueueArn`</span>});</code></pre><p>This gives us the ability to use the parameter in the second API CDK app.</p><h4 id=\"heading-iam-role\">IAM Role</h4><p>While creating the schedule you need to supply an IAM Role ARN. This role is used for executing the schedule.</p><p>This is the CDK code we are using:</p><pre><code class=\"lang-typescript\"><span class=\"hljs-built_in\">this</span>.role = <span class=\"hljs-keyword\">new</span> Role(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'RevokeProAccessPublicationRole'</span>, {  assumedBy: <span class=\"hljs-keyword\">new</span> ServicePrincipal(<span class=\"hljs-string\">'scheduler.amazonaws.com'</span>)});<span class=\"hljs-built_in\">this</span>.postPublishLambda.grantInvoke(<span class=\"hljs-built_in\">this</span>.role);<span class=\"hljs-keyword\">new</span> StringParameter(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'TargetRoleArn'</span>, {  stringValue: <span class=\"hljs-built_in\">this</span>.role.roleArn,  parameterName: <span class=\"hljs-string\">`/<span class=\"hljs-subst\">${envName}</span>/infra/schedulePublishDraft/targetRoleArn`</span>});</code></pre><p>We create a role that can be assumed by the scheduler service. We then grant the invoke permissions for one Lambda to this role and save it as a string parameter in SSM.</p><h3 id=\"heading-crud-operations\">C<s>R</s>UD Operations</h3><p>One of the main things we needed to think about is how we want to <strong>C</strong>reate, <strong>U</strong>pdate, and <strong>D</strong>elete the schedules. Hashnode uses a <a href=\"https://gql.hashnode.com\" target=\"_blank\">GraphQL API</a>. We have had several mutations for handling schedules already (yes the naming can be quite hard with posts and drafts...):</p><ul><li><p><code>scheduleDraft</code></p></li><li><p><code>reschedulePost</code></p></li><li><p><code>cancelScheduledPost</code></p></li></ul><p>These operations handled the creation of documents in our database. Each of these mutation need to handle the EventBridge schedule CRUD operation.</p><h3 id=\"heading-schedule-drafts\">Schedule Drafts</h3><p>Scheduling a draft needs to create the EventBridge schedule. We have our own package in our monorepo called <code>@hashnode/scheduling</code>. This package abstracts the calls to EventBridge and allows us to type it more precisely for our needs.</p><p>For publishing a draft we only need to call the function <code>schedulePublishDraftScheduler()</code> and everything else is abstracted. The function will</p><ul><li><p>Parse incoming data with <code>zod</code></p></li><li><p>Creates the <code>CreateScheduleCommand</code></p></li><li><p>Sends the command to EventBridge to create the schedule</p></li></ul><p>The create command looks like this:</p><pre><code class=\"lang-typescript\"><span class=\"hljs-keyword\">const</span> command = <span class=\"hljs-keyword\">new</span> CreateScheduleCommand({  Name: createName({    draftId  }),  GroupName: groupName,  ScheduleExpression: <span class=\"hljs-string\">`at(<span class=\"hljs-subst\">${formattedDate}</span>)`</span>,  ScheduleExpressionTimezone: <span class=\"hljs-string\">'UTC'</span>,  Target: {    Arn: targetArn,    RoleArn: targetRoleArn,    Input: <span class=\"hljs-built_in\">JSON</span>.stringify(schedulerPayload),    DeadLetterConfig: {      Arn: deadLetterArn    }  },  FlexibleTimeWindow: { Mode: <span class=\"hljs-string\">'OFF'</span> },  ActionAfterCompletion: <span class=\"hljs-string\">'DELETE'</span>});</code></pre><p>The name of each schedule should be unique (no drafts can be scheduled twice). The name follows this pattern:</p><pre><code class=\"lang-typescript\"><span class=\"hljs-string\">`SchedulePublishDraft-<span class=\"hljs-subst\">${draftId.toString()}</span>`</span></code></pre><p>The <code>Target</code> input object shows you all the data we have created before:</p><ol><li><p><code>Arn:</code> ARN of the Lambda function that executes the business logic</p></li><li><p><code>RoleArn:</code> The ARN of the Role</p></li><li><p><code>DeadLetterConfig.Arn:</code> The ARN of the DLQ for server-side errors</p></li></ol><p>We also set the flag <code>ActionAfterCompletion</code> to <code>DELETE</code> to make sure each schedule is removed after it runs successfully.</p><h3 id=\"heading-reschedule-drafts-amp-cancel-schedules\">Reschedule Drafts &amp; Cancel Schedules</h3><p>Rescheduling and canceling scheduled drafts follows the same procedure as creating them. In rescheduling, we make sure that the date is valid. We update the schedule.</p><p>For canceling schedules we simply remove the schedule from EventBridge.</p><h2 id=\"heading-results-after-that\">Results after that</h2><p>We've deployed everything on production without any issues. A very minimal migration was needed to create schedules for all existing drafts.</p><p>Now, if one post publish fails we get alerted immediately with exactly the post that failed.</p><p>The development and integration of using EventBridge Schedules for use cases like this are straightforward. The benefits of simplicity we have are immense.</p><h2 id=\"heading-summary\">Summary</h2><p>This post should show you how easy it can be to leverage the managed services of AWS for features like that. The scheduling stack costs 1ct per month at the moment.</p><p><img alt=\"Costs for scheduling stack\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1704879242633/7505d1dc-fffc-49af-b3dc-b1e376ffe03a.png\" /></p><p>One alternative approach for tackling this issue of the CRON job would have been to use SQS and partial batch failures. However, the EventBridge scheduling approach is much more simple. <strong>And simple is king.</strong></p><h2 id=\"heading-resources\">Resources</h2><p><a href=\"https://hashnode.com\" target=\"_blank\">Hashnode</a></p><p><a href=\"https://discord.gg/hashnode\" target=\"_blank\">Join our Discord Server</a></p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.hashnode.com/rss.xml",
      "value": "<p>One essential feature of any blogging platform is the ability to schedule posts for publication. Hashnode <a href=\"https://townhall.hashnode.com/introducing-article-scheduling-feature-for-all-hashnode-blogs\" target=\"_blank\">introduced</a> this functionality in June 2022.</p><p>At that time, the entire feature was based on a CRON job. This CRON job managed all various states and published the post. The CRON job was running every minute to ensure that scheduled posts were published.</p><p>There were certain cons associated with the CRON job:</p><ul><li><p><strong>Unnecessary computation</strong>: The CRON job ran even if no posts were scheduled at that time.</p></li><li><p><strong>Observability</strong>: Each execution of the CRON job produced logs and traces. It was quite hard to understand if and how many posts were scheduled at a certain time.</p></li><li><p><strong>Error Handling</strong>: Error handling was quite hard. If one post failed to be published we couldn't let the whole processing Lambda fail. Alerting needed special functionalities to handle that.</p></li></ul><p>With the <a href=\"https://aws.amazon.com/blogs/compute/introducing-amazon-eventbridge-scheduler/\" target=\"_blank\">launch of EventBridge Scheduler</a> in 2022 we instantly knew that scheduling posts is a perfect use-case for that.</p><h2 id=\"heading-eventbridge-scheduler\">EventBridge Scheduler</h2><p><img alt=\"eventbridge scheduler example\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1704987466311/ce7b0d1a-b34a-4b14-b42f-8184e7e94136.png\" /></p><p>EventBridge scheduler is a feature of EventBridge that allows users to schedule tasks at precise times. You can schedule a task that will be executed once at an exact time.</p><p>The same targets are supported as for EventBridge, such as:</p><ul><li><p>Lambda</p></li><li><p>SQS</p></li><li><p>SNS</p></li><li><p>Step Functions</p></li><li><p>... and many more!</p></li></ul><h2 id=\"heading-scheduling-posts-with-eventbridge-scheduler\">Scheduling Posts with EventBridge Scheduler</h2><p><img alt=\"scheduling posts with eventbridge\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1705318104814/2df1d43f-f273-469f-916b-71c410841539.png\" /></p><p>Let's see how we have implemented the scheduling of posts with the scheduler.</p><h3 id=\"heading-eventbridge-scheduling-basics\">EventBridge Scheduling Basics</h3><p>Before we worked on any API integrations we first created a few resources we needed to share with our API:</p><ol><li><p>EventBridge Scheduling Group</p></li><li><p>Lambda Consumer with DLQ (consumer errors)</p></li><li><p>SQS Dead-Letter-Queue (server-side errors)</p></li><li><p>IAM Role</p></li></ol><div><div></div><div>Hashnode uses two different CDK apps. One for all asynchronous workloads in plain <strong>CDK</strong>. And another one with <a href=\"https://sst.dev\" target=\"_blank\"><strong>SST</strong></a> for our synchronous APIs. Data needs to be shared via SSM parameters.</div></div><h4 id=\"heading-eventbridge-scheduling-group\">EventBridge Scheduling Group</h4><p>For improving the overview of schedules it is recommended to create schedule groups. It is easier to filter your schedules based on these. We have created one group with the name: <code>SchedulePublishDraft</code>.</p><pre><code class=\"lang-typescript\"><span class=\"hljs-keyword\">new</span> CfnScheduleGroup(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'SchedulePublishDraft'</span>);</code></pre><p>This group needs to be supplied once the schedule is created.</p><h4 id=\"heading-lambda-consumer\">Lambda Consumer</h4><p><img alt=\"alt\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1704878313368/5b6495a6-219b-4d57-b9a9-738f2631fcc0.png\" /></p><p>Next, we need a Consumer for our EventBridge Schedule. The schedule is scheduled for a specific time. Once this time is reached a target consumer is called.</p><p>We use AWS Lambda for that. The Lambda function will be called <strong>asynchronously</strong>. The asynchronous call gives us the ability to use Lambda Destinations. You have two types of Lambda Destinations:</p><ul><li><p><code>onSuccess</code>: This is called once the Lambda succeeds</p></li><li><p><code>onFailure</code>: This is called once the Lambda fails</p></li></ul><p>We make use of the <code>onFailure</code> destination. Once the Lambda function encounters some error and fails, we retry the event two times. If it still fails we send it to a Dead-Letter-Queue (DLQ).</p><p>The Lambda function executes the business logic (publishing the post, and updating some database states).</p><div><div>\ud83d\udea7</div><div><strong>Remember:</strong> Your EventBridge consumer needs to be idempotent. If not it can (and will happen) that your consumer is executed twice. Which could result in duplicated post publishes.</div></div><h4 id=\"heading-scheduling-dlq-server-side-errors\">Scheduling DLQ (server-side errors)</h4><p><img alt=\"DLQ for EventBridge errors\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1704878120894/877ce59a-c6b4-44d8-b5ad-d3da86c63e78.png\" /></p><p>There is a second DLQ we need to supply in our creation of the EventBridge schedule. This DLQ handles all <strong>server-side errors</strong> like missing IAM permissions or Lambda API outages.</p><p>We now have two DLQs in place:</p><ol><li><p>The first one is for server-side errors. For example: Missing IAM policies or when the Lambda API is down</p></li><li><p>The second one is for consumer errors. In case the Lambda function fails, the event will be retried two times and after that sent to a DLQ.</p></li></ol><p>In this section, we are talking about the <strong>first</strong> <strong>one</strong>. This one is needed to supply while creating the schedule.</p><p>We create this DLQ with CDK as well and share it via a parameter:</p><pre><code class=\"lang-typescript\"><span class=\"hljs-keyword\">const</span> dlqScheduler = <span class=\"hljs-keyword\">new</span> MonitoredDeadLetterQueue(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'SchedulerDlq'</span>);<span class=\"hljs-built_in\">this</span>.scheduleDeadLetterArn = dlqScheduler.queueArn;<span class=\"hljs-keyword\">new</span> StringParameter(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'EventBridgeSchedulerDLQArn'</span>, {  stringValue: <span class=\"hljs-built_in\">this</span>.scheduleDeadLetterArn,  parameterName: <span class=\"hljs-string\">`/<span class=\"hljs-subst\">${envName}</span>/infra/schedulePublishDraft/schedulerDeadLetterQueueArn`</span>});</code></pre><p>This gives us the ability to use the parameter in the second API CDK app.</p><h4 id=\"heading-iam-role\">IAM Role</h4><p>While creating the schedule you need to supply an IAM Role ARN. This role is used for executing the schedule.</p><p>This is the CDK code we are using:</p><pre><code class=\"lang-typescript\"><span class=\"hljs-built_in\">this</span>.role = <span class=\"hljs-keyword\">new</span> Role(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'RevokeProAccessPublicationRole'</span>, {  assumedBy: <span class=\"hljs-keyword\">new</span> ServicePrincipal(<span class=\"hljs-string\">'scheduler.amazonaws.com'</span>)});<span class=\"hljs-built_in\">this</span>.postPublishLambda.grantInvoke(<span class=\"hljs-built_in\">this</span>.role);<span class=\"hljs-keyword\">new</span> StringParameter(<span class=\"hljs-built_in\">this</span>, <span class=\"hljs-string\">'TargetRoleArn'</span>, {  stringValue: <span class=\"hljs-built_in\">this</span>.role.roleArn,  parameterName: <span class=\"hljs-string\">`/<span class=\"hljs-subst\">${envName}</span>/infra/schedulePublishDraft/targetRoleArn`</span>});</code></pre><p>We create a role that can be assumed by the scheduler service. We then grant the invoke permissions for one Lambda to this role and save it as a string parameter in SSM.</p><h3 id=\"heading-crud-operations\">C<s>R</s>UD Operations</h3><p>One of the main things we needed to think about is how we want to <strong>C</strong>reate, <strong>U</strong>pdate, and <strong>D</strong>elete the schedules. Hashnode uses a <a href=\"https://gql.hashnode.com\" target=\"_blank\">GraphQL API</a>. We have had several mutations for handling schedules already (yes the naming can be quite hard with posts and drafts...):</p><ul><li><p><code>scheduleDraft</code></p></li><li><p><code>reschedulePost</code></p></li><li><p><code>cancelScheduledPost</code></p></li></ul><p>These operations handled the creation of documents in our database. Each of these mutation need to handle the EventBridge schedule CRUD operation.</p><h3 id=\"heading-schedule-drafts\">Schedule Drafts</h3><p>Scheduling a draft needs to create the EventBridge schedule. We have our own package in our monorepo called <code>@hashnode/scheduling</code>. This package abstracts the calls to EventBridge and allows us to type it more precisely for our needs.</p><p>For publishing a draft we only need to call the function <code>schedulePublishDraftScheduler()</code> and everything else is abstracted. The function will</p><ul><li><p>Parse incoming data with <code>zod</code></p></li><li><p>Creates the <code>CreateScheduleCommand</code></p></li><li><p>Sends the command to EventBridge to create the schedule</p></li></ul><p>The create command looks like this:</p><pre><code class=\"lang-typescript\"><span class=\"hljs-keyword\">const</span> command = <span class=\"hljs-keyword\">new</span> CreateScheduleCommand({  Name: createName({    draftId  }),  GroupName: groupName,  ScheduleExpression: <span class=\"hljs-string\">`at(<span class=\"hljs-subst\">${formattedDate}</span>)`</span>,  ScheduleExpressionTimezone: <span class=\"hljs-string\">'UTC'</span>,  Target: {    Arn: targetArn,    RoleArn: targetRoleArn,    Input: <span class=\"hljs-built_in\">JSON</span>.stringify(schedulerPayload),    DeadLetterConfig: {      Arn: deadLetterArn    }  },  FlexibleTimeWindow: { Mode: <span class=\"hljs-string\">'OFF'</span> },  ActionAfterCompletion: <span class=\"hljs-string\">'DELETE'</span>});</code></pre><p>The name of each schedule should be unique (no drafts can be scheduled twice). The name follows this pattern:</p><pre><code class=\"lang-typescript\"><span class=\"hljs-string\">`SchedulePublishDraft-<span class=\"hljs-subst\">${draftId.toString()}</span>`</span></code></pre><p>The <code>Target</code> input object shows you all the data we have created before:</p><ol><li><p><code>Arn:</code> ARN of the Lambda function that executes the business logic</p></li><li><p><code>RoleArn:</code> The ARN of the Role</p></li><li><p><code>DeadLetterConfig.Arn:</code> The ARN of the DLQ for server-side errors</p></li></ol><p>We also set the flag <code>ActionAfterCompletion</code> to <code>DELETE</code> to make sure each schedule is removed after it runs successfully.</p><h3 id=\"heading-reschedule-drafts-amp-cancel-schedules\">Reschedule Drafts &amp; Cancel Schedules</h3><p>Rescheduling and canceling scheduled drafts follows the same procedure as creating them. In rescheduling, we make sure that the date is valid. We update the schedule.</p><p>For canceling schedules we simply remove the schedule from EventBridge.</p><h2 id=\"heading-results-after-that\">Results after that</h2><p>We've deployed everything on production without any issues. A very minimal migration was needed to create schedules for all existing drafts.</p><p>Now, if one post publish fails we get alerted immediately with exactly the post that failed.</p><p>The development and integration of using EventBridge Schedules for use cases like this are straightforward. The benefits of simplicity we have are immense.</p><h2 id=\"heading-summary\">Summary</h2><p>This post should show you how easy it can be to leverage the managed services of AWS for features like that. The scheduling stack costs 1ct per month at the moment.</p><p><img alt=\"Costs for scheduling stack\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1704879242633/7505d1dc-fffc-49af-b3dc-b1e376ffe03a.png\" /></p><p>One alternative approach for tackling this issue of the CRON job would have been to use SQS and partial batch failures. However, the EventBridge scheduling approach is much more simple. <strong>And simple is king.</strong></p><h2 id=\"heading-resources\">Resources</h2><p><a href=\"https://hashnode.com\" target=\"_blank\">Hashnode</a></p><p><a href=\"https://discord.gg/hashnode\" target=\"_blank\">Join our Discord Server</a></p>"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.hashnode.com/setting-up-post-schedules-with-eventbridge-scheduler-cdk"
      }
    ],
    "link": "https://engineering.hashnode.com/setting-up-post-schedules-with-eventbridge-scheduler-cdk",
    "id": "https://engineering.hashnode.com/setting-up-post-schedules-with-eventbridge-scheduler-cdk",
    "guidislink": false,
    "authors": [
      {
        "name": "Sandro Volpicella"
      }
    ],
    "author": "Sandro Volpicella",
    "author_detail": {
      "name": "Sandro Volpicella"
    },
    "published": "Tue, 16 Jan 2024 13:14:14 GMT",
    "published_parsed": [
      2024,
      1,
      16,
      13,
      14,
      14,
      1,
      16,
      0
    ],
    "cover_image": "https://cdn.hashnode.com/res/hashnode/image/upload/v1705398436877/326e3f9d-8632-4949-be8c-13657e8b4fe3.png"
  }
}