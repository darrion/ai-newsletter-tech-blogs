{
  "company": "Confluent",
  "title": "Confluent",
  "xmlUrl": "https://www.confluent.io/feed/",
  "htmlUrl": "https://www.confluent.io/blog",
  "content": "Automate Dynamic CLI Workflows With Custom Plugins[Webinar] How to Build a Data Mesh in Confluent Cloud | Register Today!Login\nContact UsWhy ConfluentConfluent vs. OSS Kafka\u00ae Reinventing Kafka Streaming Data Pipelines Our Customers Partners ProductsChoose Your deploymentConfluent Cloud \nPricing\nLogin\nSoftware: Confluent Platform \nSubscription\nConnectors Apache Flink ksqlDB Stream Designer Stream Governance Confluent vs. Kafka: Why you need Confluent Reinventing Kafka for the Data Streaming Era Streaming Data Pipelines SolutionsData workloadsStreaming Data Pipelines \nDatabase Pipelines\nData Warehouse Pipelines\nMainframe Integration\nStreaming Applications Use Case Architectures See All  IndustriesFinancial Services Retail & Ecommerce Manufacturing Public Sector All Industries Read the Streaming Data Pipelines eBook LearnBlog Resources Training Professional Services Data Glossary Careers Events \nMeetups\nKafka Summit\nCurrent: Data Streaming Event\nWebinars\nStreaming data pipelines demo Microservices with Confluent DevelopersConfluent Developer Docs Apache Kafka Quick Start Ask the Community Watch DemoGet Started FreeUS EnglishWatch DemoGet Started FreeWatch DemoGet Started FreeWhy ConfluentConfluent vs. OSS Kafka\u00ae Reinventing Kafka Streaming Data Pipelines Our Customers Partners ProductsChoose Your deploymentConfluent Cloud \nPricing\nLogin\nSoftware: Confluent Platform \nSubscription\nConnectors Apache Flink ksqlDB Stream Designer Stream Governance Confluent vs. Kafka: Why you need Confluent Reinventing Kafka for the Data Streaming Era Streaming Data Pipelines SolutionsData workloadsStreaming Data Pipelines \nDatabase Pipelines\nData Warehouse Pipelines\nMainframe Integration\nStreaming Applications Use Case Architectures See All  IndustriesFinancial Services Retail & Ecommerce Manufacturing Public Sector All Industries Read the Streaming Data Pipelines eBook LearnBlog Resources Training Professional Services Data Glossary Careers Events \nMeetups\nKafka Summit\nCurrent: Data Streaming Event\nWebinars\nStreaming data pipelines demo Microservices with Confluent DevelopersConfluent Developer Docs Apache Kafka Quick Start Ask the Community Jan 18, 2024Read Time: 4 minExtending the Confluent CLI With Custom PluginsTechnologyConfluentThe DevX NewsletterGet Apache Kafka and Flink news delivered to your inbox biweekly or read the latest editions on Confluent Developer!Read the LatestDocs: Extend the Confluent CLI with PluginsRead the DocumentationWritten ByBill BejeckStaff DevX EngineerJan 18, 2024Read Time: 4 minA good command line interface is essential for developer productivity. If you look at any of the major cloud providers, they all have a robust CLI API that enables you to achieve high productivity. The key benefits of a CLI include:Increased productivity: You can execute complex workflows faster than if you were using a UI. Additionally, you can chain commands together to accomplish complex tasks quickly.Automation with scripting: Developers can script CLI commands to automate repetitive tasks for even more significant gains in productivity\u00a0Flexibility: With a CLI, you have complete flexibility in performing any task since you can specify many parameters simultaneously.Confluent offers a powerful CLI that lets you quickly create and manage Apache Kafka\u00ae clusters and Apache Flink\u00ae compute pools and all associated operations with both.The mark of a great CLI API design is that each function does one thing only, and there\u2019s only one command to do any one thing. In that respect, the CLI is a collection of building blocks you can assemble for more complex situations.For example, consider deleting API keys. There is a command to delete a single API key. \u00a0 But to clean up all API keys you\u2019ll need to list them all and then remove each one with a single command. Automation with scripting will quickly solve this issue. A user could write a script that uses the CLI to list each API key, then execute the delete command for each one. While this approach will solve the problem, there are a couple of drawbacks.First, an automated script exists outside the CLI and involves a context switch to locate and execute it. Second, for any problem you encounter, you can rest assured others on your team will face the same issue. You could share your script, but that\u2019s outside the CLI. A better solution is to put custom commands directly in the CLI. By providing the ability to use custom commands, they are immediately discoverable to all users of the CLI.The solution for allowing custom commands is plugins. Plugins can use existing CLI commands as building blocks to produce more complex behavior and provide users with an elegant means to execute dynamic workflows within the CLI.The Confluent CLI now offers a framework for extending functionality with plugins. What\u2019s a plugin? Plugins are standalone executable files that begin with confluent- and can be written in any supported language, which currently are Go, Python, and Bash. Because of this, plugins open the door for simple and very complex scripting of CLI workflows, conveniently available with one command. For help with writing your first plugin, see the documentation.How to install a pluginTo install a plugin, place your executable file (its name starting with confluent-) on your $PATH. You can run confluent plugin list, which searches your $PATH for plugin executables and lists them. Confluent also maintains a repository of publicly available plugins. Running the command confluent plugin search lists all plugins available for installation from the Confluent CLI plugin repository. The search command presents results like this:Then, to install the plugin, run the command confluent plugin install <PLUGIN NAME>.The Confluent plugin repo also contains instructions for contributing a plugin.A concrete exampleWe\u2019ve discussed the benefits of using plugins for developing a complex CLI workflow, but let\u2019s look at a concrete example. Confluent Cloud for Apache Flink is currently available for preview. Confluent Cloud for Apache Flink provides a cloud-native experience for Flink. This means you can entirely focus on your business logic, encapsulated in SQL statements.To use Flink in Confluent Cloud from the CLI, here\u2019s a summary of the steps you\u2019ll take:Create a Flink compute poolSpecify the number of Confluent Flink unitsEnable Schema Registry in the environment containing the Flink compute poolCreate a Kafka cluster, which is a Flink database\u2014Flink can query and join data that are in different clusters/databasesGet the API-Key and password for the clusterSpecify the database to use for your Flink queriesTopics that are tables. Note that creating tables in Flink creates a topic and associated schemaStart a Flink shell sessionOptionally create one or more Confluent datagen connectors that will provide sample data for you to experiment with in Flink SQLWhile simple enough, you must execute a series of commands to get going, sometimes using the output of one command as the input of another (e.g., API keys). But by using the confluent-flink-quickstart plugin, it will seamlessly handle all of these steps for you with one command like this:     confluent flink quickstart \\\n   --name quickstart \\\n   --datagen-quickstarts shoe_orders shoe\nIn summary, the Confluent CLI is a powerful tool enabling Kafka and Flink developers and administrators to accomplish their tasks quickly. The Confluent CLI plugin framework helps those developers and administrators to extend the CLI functionality and share those productivity gains.ResourcesGitHub: Stream Processing with Confluent Cloud for Apache Flink\u00a0Documentation: Install the Confluent CLI\u00a0Documentation: Getting Started with Confluent CLI \u00a0GitHub: Confluent CLI plugins\u00a0\n\n\nThe DevX NewsletterGet Apache Kafka and Flink news delivered to your inbox biweekly or read the latest editions on Confluent Developer!Read the LatestDocs: Extend the Confluent CLI with PluginsRead the DocumentationWritten ByBill BejeckStaff DevX EngineerBill has been a software engineer for over 18 years. Currently, he is working at Confluent on the DevX team. Previously, Bill was an engineer on the Kafka Streams team for three-plus years. Before Confluent, he worked on various ingest applications as a U.S. Government contractor using distributed software such as Apache Kafka, Spark, and Hadoop. Bill has also written a book about Kafka Streams titled \"Kafka Streams in Action\" and is working on a 2nd edition that should be available Spring 2024.The DevX NewsletterGet Apache Kafka and Flink news delivered to your inbox biweekly or read the latest editions on Confluent Developer!Read the LatestDocs: Extend the Confluent CLI with PluginsRead the DocumentationDid you like this blog post? Share it nowTechnologyConfluentSubscribe to the Confluent blogSubscribeAnnouncing the Source Available Confluent CLIJan 26, 2023Confluent is pleased to announce that the Confluent CLI\u2014the leading command-line tool for managing enterprise Kafka deployments and modern data flow\u2014is now source available under the Confluent Community License.Muwei HeBrian StrauchDavid HydeTop 7 Free Apache Kafka Tutorials and Courses for Beginners in 2023Nov 27, 2023Stepping into the world of Apache Kafka\u00ae can feel a bit daunting at first. Get started with the top resources for beginners to start building your first Kafka application!Peter MoskovitsFeedbackProductConfluent PlatformConnectorsksqlDBStream GovernanceConfluent HubSubscriptionProfessional ServicesTrainingCustomersCloudConfluent CloudSupportSign UpLog InCloud FAQSolutionsFinancial ServicesInsuranceRetail and eCommerceAutomotiveGovernmentGamingCommunication Service ProvidersTechnologyManufacturingFraud DetectionCustomer 360Messaging ModernizationStreaming Data PipelinesEvent-driven MicroservicesMainframe IntegrationSIEM OptimizationHybrid and MulticloudInternet of ThingsData WarehouseDatabaseDevelopersConfluent DeveloperWhat is Kafka?ResourcesEventsOnline TalksMeetupsCurrent: Data Streaming EventTutorialsDocsBlogAboutInvestor RelationsStartupsCompanyCareersPartnersNewsContactTrust and SecurityTerms & Conditions | Privacy Policy | Do Not Sell My Information | Modern Slavery Policy | Cookie SettingsCopyright \u00a9 Confluent, Inc. 2014-2024. Apache, Apache Kafka, Kafka, Apache Flink, Flink, and associated open source project names are trademarks of the Apache Software Foundation\n",
  "latestPost": {
    "title": "Extending the Confluent CLI With Custom Plugins",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.confluent.io/rss.xml",
      "value": "Extending the Confluent CLI With Custom Plugins"
    },
    "summary": "The Confluent CLI now supports custom plugins to simplify CLI commands, execute dynamic workflows, and boost efficiency. Read a step-by-step guide on how to get started.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.confluent.io/rss.xml",
      "value": "The Confluent CLI now supports custom plugins to simplify CLI commands, execute dynamic workflows, and boost efficiency. Read a step-by-step guide on how to get started."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.confluent.io/blog/automate-cli-workflows-with-custom-plugins/"
      }
    ],
    "link": "https://www.confluent.io/blog/automate-cli-workflows-with-custom-plugins/",
    "id": "https://www.confluent.io/blog/automate-cli-workflows-with-custom-plugins/",
    "guidislink": false,
    "tags": [
      {
        "term": "Confluent",
        "scheme": null,
        "label": null
      }
    ],
    "published": "Thu, 18 Jan 2024 17:30:02 GMT",
    "published_parsed": [
      2024,
      1,
      18,
      17,
      30,
      2,
      3,
      18,
      0
    ],
    "authors": [
      {
        "name": "Bill Bejeck"
      }
    ],
    "author": "Bill Bejeck",
    "author_detail": {
      "name": "Bill Bejeck"
    }
  }
}