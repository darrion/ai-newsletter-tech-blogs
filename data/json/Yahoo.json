{
  "company": "Yahoo",
  "title": "Yahoo",
  "xmlUrl": "https://yahooeng.tumblr.com/rss",
  "htmlUrl": "https://yahooeng.tumblr.com/",
  "content": "\n\n\n\n\n  \n\n\nBullet Updates - Windowing, Apache Pulsar PubSub,... | Yahoo Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Engineering\nA peek under the purple rug!\n\n\n\n\n\n\n\n\n\n\n\n\nArchive\n\n\n\n\n\n\n\n\nDevelopers\n\nYDN Blog\nResearch\n\n\n\n\n\n\n\n\nBullet Updates - Windowing, Apache Pulsar PubSub, Configuration-based Data Ingestion, and More\n\n\nyahoodevelopers:By\u00a0Akshay Sarma, Principal Engineer, Verizon Media &\u00a0Brian Xiao, Software Engineer, Verizon MediaThis is the first of an ongoing series of blog posts sharing releases and announcements for Bullet, an open-sourced lightweight, scalable, pluggable, multi-tenant query system.Bullet allows you to query any data flowing through a streaming system without having to store it first through its UI or API. The queries are injected into the running system and have minimal overhead. Running hundreds of queries generally fit into the overhead of just reading the streaming data. Bullet requires running an instance of its backend on your data. This backend runs on common stream processing frameworks (Storm and Spark Streaming currently supported).The data on which Bullet sits determines what it is used for. For example, our team runs an instance of Bullet on user engagement data (~1M events/sec) to let developers find their own events to validate their code that produces this data. We also use this instance to interactively explore data, throw up quick dashboards to monitor live releases, count unique users, debug issues, and more.Since open sourcing Bullet in 2017, we\u2019ve been hard at work adding many new features! We\u2019ll highlight some of these here and continue sharing update posts for future releases.WindowingBullet used to operate in a request-response fashion - you would submit a query and wait for the query to meet its termination conditions (usually duration) before receiving results. For short-lived queries, say, a few seconds, this was fine. But as we started fielding more interactive and iterative queries, waiting even a minute for results became too cumbersome.Enter windowing! Bullet now supports time and record-based windowing. With time windowing, you can break up your query into chunks of time over its duration and retrieve results for each chunk. \u00a0For example, you can calculate the average of a field, and stream back results every second:In the above example, the aggregation is operating on all the data since the beginning of the query, but you can also do aggregations on just the windows themselves. This is often called a Tumbling window:With record windowing, you can get the intermediate aggregation for each record that matches your query (a Sliding window). Or you can do a Tumbling window on records rather than time. For example, you could get results back every three records:Overlapping windows in other ways (Hopping windows) or windows that reset based on different criteria (Session windows, Cascading windows) are currently being worked on. Stay tuned! Apache Pulsar support as a native PubSubBullet uses a PubSub (publish-subscribe) message queue to send queries and results between the Web Service and Backend. As with everything else in Bullet, the PubSub is pluggable. You can use your favorite pubsub by implementing a few interfaces if you don\u2019t want to use the ones we provide. Until now, we\u2019ve maintained and supported a REST-based PubSub and an Apache Kafka PubSub. Now we are excited to announce supporting Apache Pulsar as well! Bullet Pulsar will be useful to those users who want to use Pulsar as their underlying messaging service.If you aren\u2019t familiar with Pulsar, setting up a local standalone is very simple, and by default, any Pulsar topics written to will automatically be created. Setting up an instance of Bullet with Pulsar instead of REST or Kafka is just as easy. You can refer to our documentation for more details.Plug your data into Bullet without codeWhile Bullet worked on any data source located in any persistence layer, you still had to implement an interface to connect your data source to the Backend and convert it into a record container format that Bullet understands. For instance, your data might be located in Kafka and be in the Avro format. If you were using Bullet on Storm, you would perhaps write a Storm Spout to read from Kafka, deserialize, and convert the Avro data into the Bullet record format. This was the only interface in Bullet that required our customers to write their own code. Not anymore! Bullet DSL is a text/configuration-based format for users to plug in their data to the Bullet Backend without having to write a single line of code.Bullet DSL abstracts away the two major components for plugging data into the Bullet Backend. A Connector piece to read from arbitrary data-sources and a Converter piece to convert that read data into the Bullet record container. We currently support and maintain a few of these - Kafka and Pulsar for Connectors and\u00a0Avro, Maps and arbitrary Java POJOs for Converters. The Converters understand typed data and can even do a bit of minor ETL (Extract, Transform and Load) if you need to change your data around before feeding it into Bullet. As always, the DSL components are pluggable and you can write your own (and contribute it back!) if you need one that we don\u2019t support.We appreciate your feedback and contributions! Explore Bullet on GitHub, use and help contribute to the project, and chat with us on Google Groups. To get started, try our Quickstarts on Spark or Storm to set up an instance of Bullet on some fake data and play around with it.\n\n\n\nopen source big data javascript java\n\n\nBy  rosaliebeevm\nReblogged from Yahoo Developer Network\n\n\n\n\n\n\n\n\n\n\nMar 8th, 2019\n8\n\n\n\nShare\n\n\n\nNotes\nsamexplores liked this                                    yahooeng reblogged this from yahoodevelopers saewookkangboy liked this                                    yahoodevelopers posted this                                                                        \n\n\n\n\n\n\nPrev post\n\n\n\n\nFollow Yahoo Engineering On\n\nGithub\nTwitter\nWebsite\n\n\n\n\n\u00a9 Copyright 2013\u20132024. Yahoo Engineering - All Rights Reserved.\nYahoo Theme created by Style Hatch\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n",
  "latestPost": {
    "title": "Bullet Updates - Windowing, Apache Pulsar PubSub, Configuration-based Data Ingestion, and More",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://yahooeng.tumblr.com/rss",
      "value": "Bullet Updates - Windowing, Apache Pulsar PubSub, Configuration-based Data Ingestion, and More"
    },
    "summary": "<p><a class=\"tumblr_blog\" href=\"https://yahoodevelopers.tumblr.com/post/183271418613/bullet-updates-windowing-apache-pulsar-pubsub\">yahoodevelopers</a>:</p><blockquote>\n<p>By\u00a0<a href=\"https://www.linkedin.com/in/akshai-sarma-9029b011/\">Akshay Sarma</a>, Principal Engineer, Verizon Media &amp;\u00a0<a href=\"https://www.linkedin.com/in/brian-xiao-77276450/\">Brian Xiao</a>, Software Engineer, Verizon Media<br /></p>\n<p>This is the first of an ongoing series of blog posts sharing releases and announcements for <a href=\"https://bullet-db.github.io/\">Bullet</a>, an open-sourced lightweight, scalable, pluggable, multi-tenant query system.<b><br /></b></p>\n<p>Bullet allows you to query any data flowing through a streaming system without having to store it first through its UI or API. The queries are injected into the running system and have minimal overhead. Running hundreds of queries generally fit into the overhead of just reading the streaming data. Bullet requires running an instance of its backend on your data. This backend runs on common stream processing frameworks (Storm and Spark Streaming currently supported).</p>\n<p>The data on which Bullet sits determines what it is used for. For example, our team runs an instance of Bullet on user engagement data (~1M events/sec) to let developers find their own events to validate their code that produces this data. We also use this instance to interactively explore data, throw up quick dashboards to monitor live releases, count unique users, debug issues, and more.</p>\n<p>Since <a href=\"https://yahooeng.tumblr.com/post/161855616651/open-sourcing-bullet-yahoos-forward-looking\">open sourcing Bullet in 2017</a>, we\u2019ve been hard at work adding many new features! We\u2019ll highlight some of these here and continue sharing update posts for future releases.</p>\n<p><b>Windowing</b></p>\n<p>Bullet used to operate in a request-response fashion - you would submit a query and wait for the query to meet its termination conditions (usually duration) before receiving results. For short-lived queries, say, a few seconds, this was fine. But as we started fielding more interactive and iterative queries, waiting even a minute for results became too cumbersome.</p>\n<p>Enter windowing! Bullet now supports time and record-based windowing. With time windowing, you can break up your query into chunks of time over its duration and retrieve results for each chunk. \u00a0For example, you can calculate the average of a field, and stream back results every second:</p>\n<div style=\"text-align: center;\"><figure class=\"tmblr-embed tmblr-full\"></figure></div>\n<p>In the above example, the aggregation is operating on all the data since the beginning of the query, but you can also do aggregations on just the windows themselves. This is often called a <i>Tumbling</i> window:<br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/e20d505ff2dddf5e646f126523ea4f9a/tumblr_inline_pnyky3M0Gi1wxhpzr_540.png\" /></figure><p>With record windowing, you can get the intermediate aggregation for each record that matches your query (a <i>Sliding</i> window). Or you can do a <i>Tumbling </i>window on records rather than time. For example, you could get results back every three records:<br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/a4c9350a85b8a29345ce92fe1498f91f/tumblr_inline_pnykzfHVar1wxhpzr_540.png\" /></figure><p>Overlapping windows in other ways (Hopping windows) or windows that reset based on different criteria (Session windows, Cascading windows) are currently being worked on. Stay tuned! <br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/0e341961272f73dd68c0570ed3e9ac07/tumblr_inline_pnyl3nZiUB1wxhpzr_540.png\" /></figure><figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/7c6699716b3e92703e23a9ef6cc1b3a3/tumblr_inline_pnyl47zEuK1wxhpzr_540.png\" /></figure><p><b>Apache Pulsar support as a native PubSub</b><br /></p>\n<p>Bullet uses a PubSub (publish-subscribe) message queue to send queries and results between the Web Service and Backend. As with everything else in Bullet, the PubSub is pluggable. You can use your favorite pubsub by implementing a few interfaces if you don\u2019t want to use the ones we provide. Until now, we\u2019ve maintained and supported a REST-based PubSub and an<a href=\"https://kafka.apache.org/\"> Apache Kafka</a> PubSub. Now we are excited to announce supporting <a href=\"http://pulsar.apache.org/\">Apache Pulsar</a> as well! <a href=\"https://bullet-db.github.io/pubsub/pulsar/\">Bullet Pulsar</a> will be useful to those users who want to use Pulsar as their underlying messaging service.<br /></p>\n<p>If you aren\u2019t familiar with Pulsar, setting up a local standalone is very simple, and by default, any Pulsar topics written to will automatically be created. Setting up an instance of Bullet with Pulsar instead of REST or Kafka is just as easy. You can refer to <a href=\"https://bullet-db.github.io/pubsub/pulsar/\">our documentation</a> for more details.</p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/b89986b095cee04c79d62c6425c09db2/aa61dd2f27cdffc3-22/s540x810/1961af5bb2ad5d8f0d43770c99543618a0ecf453.png\" /></figure><p><b>Plug your data into Bullet without code</b></p>\n<p>While Bullet worked on any data source located in any persistence layer, you still had to implement an interface to connect your data source to the Backend and convert it into a record container format that Bullet understands. For instance, your data might be located in Kafka and be in the Avro format. If you were using Bullet on Storm, you would perhaps write a Storm Spout to read from Kafka, deserialize, and convert the Avro data into the Bullet record format. This was the only interface in Bullet that required our customers to write their own code. Not anymore! Bullet DSL is a text/configuration-based format for users to plug in their data to the Bullet Backend without having to write a single line of code.</p>\n<p><a href=\"https://bullet-db.github.io/backend/dsl/\">Bullet DSL</a> abstracts away the two major components for plugging data into the Bullet Backend. A Connector piece to read from arbitrary data-sources and a Converter piece to convert that read data into the Bullet record container. We currently support and maintain a few of these - Kafka and Pulsar for Connectors and\u00a0Avro, Maps and arbitrary Java POJOs for Converters. The Converters understand typed data and can even do a bit of minor ETL (Extract, Transform and Load) if you need to change your data around before feeding it into Bullet. As always, the DSL components are pluggable and you can write your own (and contribute it back!) if you need one that we don\u2019t support.</p>\n<p>We appreciate your feedback and contributions! Explore Bullet on <a href=\"https://github.com/bullet-db\">GitHub</a>, use and help contribute to the project, and chat with us on <a href=\"https://groups.google.com/forum/#!forum/bullet-users\">Google Groups</a>. To get started, try our Quickstarts on <a href=\"https://bullet-db.github.io/quick-start/spark/\">Spark</a> or <a href=\"https://bullet-db.github.io/quick-start/storm/\">Storm</a> to set up an instance of Bullet on some fake data and play around with it.</p>\n</blockquote>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://yahooeng.tumblr.com/rss",
      "value": "<p><a class=\"tumblr_blog\" href=\"https://yahoodevelopers.tumblr.com/post/183271418613/bullet-updates-windowing-apache-pulsar-pubsub\">yahoodevelopers</a>:</p><blockquote>\n<p>By\u00a0<a href=\"https://www.linkedin.com/in/akshai-sarma-9029b011/\">Akshay Sarma</a>, Principal Engineer, Verizon Media &amp;\u00a0<a href=\"https://www.linkedin.com/in/brian-xiao-77276450/\">Brian Xiao</a>, Software Engineer, Verizon Media<br /></p>\n<p>This is the first of an ongoing series of blog posts sharing releases and announcements for <a href=\"https://bullet-db.github.io/\">Bullet</a>, an open-sourced lightweight, scalable, pluggable, multi-tenant query system.<b><br /></b></p>\n<p>Bullet allows you to query any data flowing through a streaming system without having to store it first through its UI or API. The queries are injected into the running system and have minimal overhead. Running hundreds of queries generally fit into the overhead of just reading the streaming data. Bullet requires running an instance of its backend on your data. This backend runs on common stream processing frameworks (Storm and Spark Streaming currently supported).</p>\n<p>The data on which Bullet sits determines what it is used for. For example, our team runs an instance of Bullet on user engagement data (~1M events/sec) to let developers find their own events to validate their code that produces this data. We also use this instance to interactively explore data, throw up quick dashboards to monitor live releases, count unique users, debug issues, and more.</p>\n<p>Since <a href=\"https://yahooeng.tumblr.com/post/161855616651/open-sourcing-bullet-yahoos-forward-looking\">open sourcing Bullet in 2017</a>, we\u2019ve been hard at work adding many new features! We\u2019ll highlight some of these here and continue sharing update posts for future releases.</p>\n<p><b>Windowing</b></p>\n<p>Bullet used to operate in a request-response fashion - you would submit a query and wait for the query to meet its termination conditions (usually duration) before receiving results. For short-lived queries, say, a few seconds, this was fine. But as we started fielding more interactive and iterative queries, waiting even a minute for results became too cumbersome.</p>\n<p>Enter windowing! Bullet now supports time and record-based windowing. With time windowing, you can break up your query into chunks of time over its duration and retrieve results for each chunk. \u00a0For example, you can calculate the average of a field, and stream back results every second:</p>\n<div style=\"text-align: center;\"><figure class=\"tmblr-embed tmblr-full\"></figure></div>\n<p>In the above example, the aggregation is operating on all the data since the beginning of the query, but you can also do aggregations on just the windows themselves. This is often called a <i>Tumbling</i> window:<br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/e20d505ff2dddf5e646f126523ea4f9a/tumblr_inline_pnyky3M0Gi1wxhpzr_540.png\" /></figure><p>With record windowing, you can get the intermediate aggregation for each record that matches your query (a <i>Sliding</i> window). Or you can do a <i>Tumbling </i>window on records rather than time. For example, you could get results back every three records:<br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/a4c9350a85b8a29345ce92fe1498f91f/tumblr_inline_pnykzfHVar1wxhpzr_540.png\" /></figure><p>Overlapping windows in other ways (Hopping windows) or windows that reset based on different criteria (Session windows, Cascading windows) are currently being worked on. Stay tuned! <br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/0e341961272f73dd68c0570ed3e9ac07/tumblr_inline_pnyl3nZiUB1wxhpzr_540.png\" /></figure><figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/7c6699716b3e92703e23a9ef6cc1b3a3/tumblr_inline_pnyl47zEuK1wxhpzr_540.png\" /></figure><p><b>Apache Pulsar support as a native PubSub</b><br /></p>\n<p>Bullet uses a PubSub (publish-subscribe) message queue to send queries and results between the Web Service and Backend. As with everything else in Bullet, the PubSub is pluggable. You can use your favorite pubsub by implementing a few interfaces if you don\u2019t want to use the ones we provide. Until now, we\u2019ve maintained and supported a REST-based PubSub and an<a href=\"https://kafka.apache.org/\"> Apache Kafka</a> PubSub. Now we are excited to announce supporting <a href=\"http://pulsar.apache.org/\">Apache Pulsar</a> as well! <a href=\"https://bullet-db.github.io/pubsub/pulsar/\">Bullet Pulsar</a> will be useful to those users who want to use Pulsar as their underlying messaging service.<br /></p>\n<p>If you aren\u2019t familiar with Pulsar, setting up a local standalone is very simple, and by default, any Pulsar topics written to will automatically be created. Setting up an instance of Bullet with Pulsar instead of REST or Kafka is just as easy. You can refer to <a href=\"https://bullet-db.github.io/pubsub/pulsar/\">our documentation</a> for more details.</p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/b89986b095cee04c79d62c6425c09db2/aa61dd2f27cdffc3-22/s540x810/1961af5bb2ad5d8f0d43770c99543618a0ecf453.png\" /></figure><p><b>Plug your data into Bullet without code</b></p>\n<p>While Bullet worked on any data source located in any persistence layer, you still had to implement an interface to connect your data source to the Backend and convert it into a record container format that Bullet understands. For instance, your data might be located in Kafka and be in the Avro format. If you were using Bullet on Storm, you would perhaps write a Storm Spout to read from Kafka, deserialize, and convert the Avro data into the Bullet record format. This was the only interface in Bullet that required our customers to write their own code. Not anymore! Bullet DSL is a text/configuration-based format for users to plug in their data to the Bullet Backend without having to write a single line of code.</p>\n<p><a href=\"https://bullet-db.github.io/backend/dsl/\">Bullet DSL</a> abstracts away the two major components for plugging data into the Bullet Backend. A Connector piece to read from arbitrary data-sources and a Converter piece to convert that read data into the Bullet record container. We currently support and maintain a few of these - Kafka and Pulsar for Connectors and\u00a0Avro, Maps and arbitrary Java POJOs for Converters. The Converters understand typed data and can even do a bit of minor ETL (Extract, Transform and Load) if you need to change your data around before feeding it into Bullet. As always, the DSL components are pluggable and you can write your own (and contribute it back!) if you need one that we don\u2019t support.</p>\n<p>We appreciate your feedback and contributions! Explore Bullet on <a href=\"https://github.com/bullet-db\">GitHub</a>, use and help contribute to the project, and chat with us on <a href=\"https://groups.google.com/forum/#!forum/bullet-users\">Google Groups</a>. To get started, try our Quickstarts on <a href=\"https://bullet-db.github.io/quick-start/spark/\">Spark</a> or <a href=\"https://bullet-db.github.io/quick-start/storm/\">Storm</a> to set up an instance of Bullet on some fake data and play around with it.</p>\n</blockquote>"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://yahooeng.tumblr.com/post/183315480351"
      }
    ],
    "link": "https://yahooeng.tumblr.com/post/183315480351",
    "id": "https://yahooeng.tumblr.com/post/183315480351",
    "guidislink": false,
    "published": "Fri, 08 Mar 2019 09:12:50 -0800",
    "published_parsed": [
      2019,
      3,
      8,
      17,
      12,
      50,
      4,
      67,
      0
    ],
    "tags": [
      {
        "term": "open source",
        "scheme": null,
        "label": null
      },
      {
        "term": "big data",
        "scheme": null,
        "label": null
      },
      {
        "term": "javascript",
        "scheme": null,
        "label": null
      },
      {
        "term": "java",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "rosaliebeevm"
      }
    ],
    "author": "rosaliebeevm",
    "author_detail": {
      "name": "rosaliebeevm"
    }
  }
}