{
  "Postman": {
    "title": "Powering home automation with WebSocket APIs",
    "xmlUrl": "https://medium.com/feed/better-practices",
    "htmlUrl": "https://medium.com/better-practices",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/better-practices",
      "value": "Powering home automation with WebSocket APIs"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/better-practices/powering-home-automation-with-websocket-apis-8885a7601523?source=rss----410f2fbc015d---4"
      }
    ],
    "link": "https://medium.com/better-practices/powering-home-automation-with-websocket-apis-8885a7601523?source=rss----410f2fbc015d---4",
    "id": "https://medium.com/p/8885a7601523",
    "guidislink": false,
    "tags": [
      {
        "term": "home-assistant",
        "scheme": null,
        "label": null
      },
      {
        "term": "websocket",
        "scheme": null,
        "label": null
      },
      {
        "term": "api",
        "scheme": null,
        "label": null
      },
      {
        "term": "iot",
        "scheme": null,
        "label": null
      },
      {
        "term": "software-development",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Joyce Lin"
      }
    ],
    "author": "Joyce Lin",
    "author_detail": {
      "name": "Joyce Lin"
    },
    "published": "Thu, 06 Jul 2023 17:04:32 GMT",
    "published_parsed": [
      2023,
      7,
      6,
      17,
      4,
      32,
      3,
      187,
      0
    ],
    "updated": "2023-07-06T17:04:32.168Z",
    "updated_parsed": [
      2023,
      7,
      6,
      17,
      4,
      32,
      3,
      187,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/better-practices",
        "value": "<h4>Get started with the Home Assistant WebSocket API</h4><p>In Part 1 of this series, we learned about the <a href=\"https://learning.postman.com/docs/sending-requests/websocket/websocket/\">WebSocket</a> protocol and how to <a href=\"https://blog.postman.com/set-up-a-websockets-server-in-node-js-postman/\">set up our own WebSocket server in Node.js</a>. Next, let\u2019s explore how to use a public WebSocket API to access smart devices around a connected home.</p><h3>REST and WebSockets for a connected home</h3><p>When it comes to transmitting data in a connected home environment, both <a href=\"https://blog.postman.com/rest-api-examples/\">REST</a> and WebSockets are commonly used protocols, but they have different characteristics and use\u00a0cases.</p><p>REST follows a request-response pattern, where a client sends a request to a server, and the server responds with the requested data. This is useful for accessing and controlling smart devices and services, and works well for scenarios where data updates are not required in real-time. For example, you could use a REST API to turn on a smart\u00a0light.</p><p>On the other hand, WebSockets enables bidirectional communication between a client and server, enabling real-time data transmission. This is useful for applications that require continuous data updates, such as real-time monitoring of sensor data and displaying live dashboards. For example, you could use a WebSocket API to continuously monitor the temperature in a room over a persistent connection.</p><p>In the next section, let\u2019s take a look at a popular home automation platform that provides both REST and WebSocket APIs.</p><h3>Home Assistant for home automation</h3><p><a href=\"https://www.home-assistant.io/\">Home Assistant</a> is a popular open-source home automation platform that lets you control and monitor smart devices from different brands using a unified interface. Instead of using separate applications to control the kitchen lights, thermostat, and other connected devices all manufactured by different producers, you can manage almost everything from a single Home Assistant web dashboard running on a Raspberry Pi or other dedicated server within your local\u00a0network.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/0*SV-NQW6-Sz2D9Buh.png\" /></figure><p>Home Assistant is ideal for DIY smart-home tinkerers because it supports a wide range of integrations and protocols, allowing you to customize automation scenarios based on events, schedules, and sensor readings.</p><p>Next, let\u2019s take a look at Home Assistant\u2019s WebSocket API.</p><h3>Home Assistant WebSocket API</h3><p>In addition to a <a href=\"https://developers.home-assistant.io/docs/api/rest/\">REST API</a><a href=\"https://blog.postman.com/rest-api-examples\">,</a> Home Assistant also contains a <a href=\"https://developers.home-assistant.io/docs/api/websocket\">WebSocket API</a> to stream information. To learn how to authenticate the WebSockets connection and send saved messages to the Home Assistant server, follow along with this <a href=\"https://quickstarts.postman.com/guide/home-assistant/index.html?index=..%2F..index#0\">step-by-step tutorial</a>, watch the <a href=\"https://youtu.be/Qk9A0QbG5-I\">video</a>, and reference <a href=\"https://www.postman.com/postman/workspace/program-smart-lights/collection/6481ed9afe7f1bdfaa732408\">the sample collection</a>.</p><a href=\"https://medium.com/media/34e673bfe1fdf0fed8db3e10614f1fad/href\">https://medium.com/media/34e673bfe1fdf0fed8db3e10614f1fad/href</a><p>Using a long-lived token, you can use Postman to establish a connection with our Home Assistant server running locally, and then send and receive messages using the WebSocket API.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/0*xkZhl3eyC8CuvhnJ.png\" /></figure><p>You can also configure your own <strong>Saved Messages</strong> to create your own customized themes and sequences.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/0*yxsGpbMOjjNpSBpT.png\" /></figure><p>Home Assistant also provides a <a href=\"https://developers.home-assistant.io/docs/api/rest\">REST API</a>. Explore Home Assistant\u2019s WebSocket and REST APIs side-by-side in Postman to better understand the differences between the two protocols.</p><h3>Additional resources</h3><p>You can work in Postman using different API patterns and protocols. Check out these Postman resources to learn more about WebSockets:</p><ul><li><a href=\"https://www.postman.com/postman/workspace/websockets/documentation/14057978-712d684f-c252-4bd9-a7a6-6a893e41adea\">Guide to Postman WebSockets</a> collection</li><li><a href=\"https://learning.postman.com/docs/sending-requests/websocket/websocket/\">Using WebSocket requests</a>\u00a0docs</li><li><a href=\"https://youtu.be/H-7EZVj9D-k\">WebSocket requests</a>\u00a0video</li></ul><p>Browse the <a href=\"https://www.postman.com/postman/workspace/program-smart-lights/overview\">Program smart lights</a> public workspace for APIs from other providers, such as Philips Hue and Elgato, to automatically control smart lights in your home or office. And let us know in the comments below what kind of projects you want to learn about, and what you\u2019re doing with WebSockets.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8885a7601523\" width=\"1\" /><hr /><p><a href=\"https://medium.com/better-practices/powering-home-automation-with-websocket-apis-8885a7601523\">Powering home automation with WebSocket APIs</a> was originally published in <a href=\"https://medium.com/better-practices\">Better Practices</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h4>Get started with the Home Assistant WebSocket API</h4><p>In Part 1 of this series, we learned about the <a href=\"https://learning.postman.com/docs/sending-requests/websocket/websocket/\">WebSocket</a> protocol and how to <a href=\"https://blog.postman.com/set-up-a-websockets-server-in-node-js-postman/\">set up our own WebSocket server in Node.js</a>. Next, let\u2019s explore how to use a public WebSocket API to access smart devices around a connected home.</p><h3>REST and WebSockets for a connected home</h3><p>When it comes to transmitting data in a connected home environment, both <a href=\"https://blog.postman.com/rest-api-examples/\">REST</a> and WebSockets are commonly used protocols, but they have different characteristics and use\u00a0cases.</p><p>REST follows a request-response pattern, where a client sends a request to a server, and the server responds with the requested data. This is useful for accessing and controlling smart devices and services, and works well for scenarios where data updates are not required in real-time. For example, you could use a REST API to turn on a smart\u00a0light.</p><p>On the other hand, WebSockets enables bidirectional communication between a client and server, enabling real-time data transmission. This is useful for applications that require continuous data updates, such as real-time monitoring of sensor data and displaying live dashboards. For example, you could use a WebSocket API to continuously monitor the temperature in a room over a persistent connection.</p><p>In the next section, let\u2019s take a look at a popular home automation platform that provides both REST and WebSocket APIs.</p><h3>Home Assistant for home automation</h3><p><a href=\"https://www.home-assistant.io/\">Home Assistant</a> is a popular open-source home automation platform that lets you control and monitor smart devices from different brands using a unified interface. Instead of using separate applications to control the kitchen lights, thermostat, and other connected devices all manufactured by different producers, you can manage almost everything from a single Home Assistant web dashboard running on a Raspberry Pi or other dedicated server within your local\u00a0network.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/0*SV-NQW6-Sz2D9Buh.png\" /></figure><p>Home Assistant is ideal for DIY smart-home tinkerers because it supports a wide range of integrations and protocols, allowing you to customize automation scenarios based on events, schedules, and sensor readings.</p><p>Next, let\u2019s take a look at Home Assistant\u2019s WebSocket API.</p><h3>Home Assistant WebSocket API</h3><p>In addition to a <a href=\"https://developers.home-assistant.io/docs/api/rest/\">REST API</a><a href=\"https://blog.postman.com/rest-api-examples\">,</a> Home Assistant also contains a <a href=\"https://developers.home-assistant.io/docs/api/websocket\">WebSocket API</a> to stream information. To learn how to authenticate the WebSockets connection and send saved messages to the Home Assistant server, follow along with this <a href=\"https://quickstarts.postman.com/guide/home-assistant/index.html?index=..%2F..index#0\">step-by-step tutorial</a>, watch the <a href=\"https://youtu.be/Qk9A0QbG5-I\">video</a>, and reference <a href=\"https://www.postman.com/postman/workspace/program-smart-lights/collection/6481ed9afe7f1bdfaa732408\">the sample collection</a>.</p><a href=\"https://medium.com/media/34e673bfe1fdf0fed8db3e10614f1fad/href\">https://medium.com/media/34e673bfe1fdf0fed8db3e10614f1fad/href</a><p>Using a long-lived token, you can use Postman to establish a connection with our Home Assistant server running locally, and then send and receive messages using the WebSocket API.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/0*xkZhl3eyC8CuvhnJ.png\" /></figure><p>You can also configure your own <strong>Saved Messages</strong> to create your own customized themes and sequences.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/0*yxsGpbMOjjNpSBpT.png\" /></figure><p>Home Assistant also provides a <a href=\"https://developers.home-assistant.io/docs/api/rest\">REST API</a>. Explore Home Assistant\u2019s WebSocket and REST APIs side-by-side in Postman to better understand the differences between the two protocols.</p><h3>Additional resources</h3><p>You can work in Postman using different API patterns and protocols. Check out these Postman resources to learn more about WebSockets:</p><ul><li><a href=\"https://www.postman.com/postman/workspace/websockets/documentation/14057978-712d684f-c252-4bd9-a7a6-6a893e41adea\">Guide to Postman WebSockets</a> collection</li><li><a href=\"https://learning.postman.com/docs/sending-requests/websocket/websocket/\">Using WebSocket requests</a>\u00a0docs</li><li><a href=\"https://youtu.be/H-7EZVj9D-k\">WebSocket requests</a>\u00a0video</li></ul><p>Browse the <a href=\"https://www.postman.com/postman/workspace/program-smart-lights/overview\">Program smart lights</a> public workspace for APIs from other providers, such as Philips Hue and Elgato, to automatically control smart lights in your home or office. And let us know in the comments below what kind of projects you want to learn about, and what you\u2019re doing with WebSockets.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8885a7601523\" width=\"1\" /><hr /><p><a href=\"https://medium.com/better-practices/powering-home-automation-with-websocket-apis-8885a7601523\">Powering home automation with WebSocket APIs</a> was originally published in <a href=\"https://medium.com/better-practices\">Better Practices</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Facebook": {
    "title": "How Meta is advancing GenAI",
    "xmlUrl": "https://code.fb.com/feed/",
    "htmlUrl": "https://code.facebook.com/posts/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.fb.com/feed/",
      "value": "How Meta is advancing GenAI"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/"
      }
    ],
    "link": "https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/",
    "authors": [
      {}
    ],
    "author": "",
    "published": "Thu, 11 Jan 2024 17:00:17 +0000",
    "published_parsed": [
      2024,
      1,
      11,
      17,
      0,
      17,
      3,
      11,
      0
    ],
    "tags": [
      {
        "term": "AI Research",
        "scheme": null,
        "label": null
      },
      {
        "term": "ML Applications",
        "scheme": null,
        "label": null
      },
      {
        "term": "meta tech podcast",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.fb.com/?p=20873",
    "guidislink": false,
    "summary": "<p>What\u2019s going on with generative AI (GenAI) at Meta? And what does the future have in store? In this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (@passy) speaks with\u00a0Devi Parikh, an AI research director at Meta.\u00a0They cover a wide range of topics, including the history and future of GenAI and the most [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\">Read More...</a></p>\n<p>The post <a href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\" rel=\"nofollow\">How Meta is advancing GenAI</a> appeared first on <a href=\"https://engineering.fb.com\" rel=\"nofollow\">Engineering at Meta</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.fb.com/feed/",
      "value": "<p>What\u2019s going on with generative AI (GenAI) at Meta? And what does the future have in store? In this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (@passy) speaks with\u00a0Devi Parikh, an AI research director at Meta.\u00a0They cover a wide range of topics, including the history and future of GenAI and the most [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\">Read More...</a></p>\n<p>The post <a href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\" rel=\"nofollow\">How Meta is advancing GenAI</a> appeared first on <a href=\"https://engineering.fb.com\" rel=\"nofollow\">Engineering at Meta</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.fb.com/feed/",
        "value": "<p>What\u2019s going on with generative AI (GenAI) at Meta? And what does the future have in store?</p>\n<p>In this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (<a href=\"https://www.threads.net/@passy_\">@passy</a>) speaks with\u00a0Devi Parikh, an AI research director at Meta.\u00a0They cover a wide range of topics, including the history and future of GenAI and the most interesting research papers that have come out recently.</p>\n<p>And, of course, they discuss some of Meta\u2019s latest GenAI innovations, including:</p>\n<ul>\n<li><a href=\"https://ai.meta.com/blog/audiobox-generating-audio-voice-natural-language-prompts/\" rel=\"noopener\" target=\"_blank\">Audiobox</a>, a foundational model for generating sound and soundscapes using natural language prompts.</li>\n<li><a href=\"https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/\" rel=\"noopener\" target=\"_blank\">Emu</a>, Meta\u2019s first foundational model for image generation.</li>\n<li><a href=\"https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/\" rel=\"noopener\" target=\"_blank\">Purple Llama</a>, a suite of tools to help developers safely and responsibly deploy GenAI models.</li>\n</ul>\n<p>Download or listen to the episode below:</p>\n<p></p>\n<p>You can also find the episode on various podcast platforms:</p>\n<p><a href=\"https://open.spotify.com/episode/417ZV5wibSU7rJYOofFANB\" rel=\"noopener\" target=\"_blank\">Spotify</a><br />\n<a href=\"https://pca.st/ot14urbh\" rel=\"noopener\" target=\"_blank\">PocketCasts</a><br />\n<a href=\"https://podcasts.apple.com/gb/podcast/advancing-genai-at-meta/id1370910331?i=1000639340717\" rel=\"noopener\" target=\"_blank\">Apple Podcasts</a><br />\n<a href=\"https://podcasts.google.com/feed/aHR0cHM6Ly9pbnNpZGVmYWNlYm9va21vYmlsZS5saWJzeW4uY29tL3Jzcw/episode/OGNiMTMwOTktYWY2Ny00YzkxLTgxNDgtMjZiMWM0OGQ1MWYx?sa=X&amp;ved=0CAgQuIEEahcKEwiA9NbNvL6DAxUAAAAAHQAAAAAQLA\" rel=\"noopener\" target=\"_blank\">Google\u00a0Podcasts</a></p>\n<p>The\u00a0<a href=\"https://insidefacebookmobile.libsyn.com/\" rel=\"noopener\" target=\"_blank\">Meta Tech Podcast</a>\u00a0is a podcast, brought to you by Meta, where we highlight the work Meta\u2019s engineers are doing at every level \u2013 from low-level frameworks to end-user features.</p>\n<p>Send us feedback on <a href=\"https://instagram.com/metatechpod\" rel=\"noopener\" target=\"_blank\">Instagram</a>, <a href=\"https://threads.net/@metatechpod\" rel=\"noopener\" target=\"_blank\">Threads</a>, or <a href=\"https://twitter.com/metatechpod\" rel=\"noopener\" target=\"_blank\">X</a>.</p>\n<p>And if you\u2019re interested in AI career opportunities at Meta visit the <a href=\"https://www.metacareers.com/\" rel=\"noopener\" target=\"_blank\">Meta Careers</a> page.</p>\n<p>The post <a href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\" rel=\"nofollow\">How Meta is advancing GenAI</a> appeared first on <a href=\"https://engineering.fb.com\" rel=\"nofollow\">Engineering at Meta</a>.</p>"
      }
    ],
    "post-id": "20873"
  },
  "Codelitt": {
    "title": "Staff Augmentation: The Game Changer in the Tech Industry",
    "xmlUrl": "https://www.codelitt.com/blog/rss",
    "htmlUrl": "https://www.codelitt.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.codelitt.com/rss/",
      "value": "Staff Augmentation: The Game Changer in the Tech Industry"
    },
    "summary": "In this blog, we're breaking down staff augmentation and how it's a game changer for tech. Could staff augmentation be your next game changing move?",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.codelitt.com/rss/",
      "value": "In this blog, we're breaking down staff augmentation and how it's a game changer for tech. Could staff augmentation be your next game changing move?"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.codelitt.com/staff-augmentation-the-game-changer-in-the-tech-industry/"
      }
    ],
    "link": "https://blog.codelitt.com/staff-augmentation-the-game-changer-in-the-tech-industry/",
    "id": "64fb70871a53b9001b500be1",
    "guidislink": false,
    "tags": [
      {
        "term": "strategy",
        "scheme": null,
        "label": null
      },
      {
        "term": "Codelitt",
        "scheme": null,
        "label": null
      },
      {
        "term": "Innovation",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Omar Altoubah"
      }
    ],
    "author": "Omar Altoubah",
    "author_detail": {
      "name": "Omar Altoubah"
    },
    "published": "Mon, 11 Sep 2023 17:09:00 GMT",
    "published_parsed": [
      2023,
      9,
      11,
      17,
      9,
      0,
      0,
      254,
      0
    ],
    "media_content": [
      {
        "url": "https://res-2.cloudinary.com/hepw4b4yn/image/upload/q_auto/v1/ghost-blog-images/designthinking-codelitt.jpg",
        "medium": "image"
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.codelitt.com/rss/",
        "value": "<img alt=\"Staff Augmentation: The Game Changer in the Tech Industry\" src=\"https://res-2.cloudinary.com/hepw4b4yn/image/upload/q_auto/v1/ghost-blog-images/designthinking-codelitt.jpg\" /><p><em>Your Secret Weapon for a Competitive Edge in the Fast-Paced World of Tech</em></p><p>In the fast-paced world of tech, keeping up with the latest trends and staying on top of projects can feel like an Olympic sprint, but what if you could tap into a secret weapon that gives you an edge? In this blog, we're breaking down what staff augmentation is, when to use it, and why it's a game changer for the tech industry.</p><p><strong>What's the Buzz About Staff Augmentation?</strong><br /><em>Your \"Rent-a-Pro\" Service for Tech Projects</em></p><p>Bringing in outside experts on a temporary basis to join your team can be a game-changer. This approach allows you to find developers, designers, and other specialists to tackle specific tasks without committing to full-time hires.</p><blockquote>\u201cThink of staff augmentation as assembling your own Avengers team of tech experts for a limited time mission.\u201d - <strong>Kaio Magalh\u00e3es,</strong> CTO at Codelitt</blockquote><p><strong>When is Staff Augmentation Right for Your Business?</strong><br /><em>Pinpointing the Exact Moments Your Business Needs Help</em></p><ul><li>Project Scalability: Is your company navigating through a period of rapid expansion or contraction? It might be grappling with fluctuating work demands, varying from extensive projects, to smaller tasks that do not justify a full-time role.</li><li>Specialized Skill Set: Does your current project require a set of skills that are not represented in your existing team? This can occur when venturing into new technological territories or experimenting with the latest tools in the ever-evolving market.</li><li>Budget Constraints: Are you facing budgetary restrictions that limit the scope of permanent hires? Oftentimes, firms operate under strict financial constraints, resulting in the need to optimize budget allocation across various departments.</li><li>Short-Term Engagements: Do you have projects with clearly defined timelines that don\u2019t require long-term engagements? Sometimes, projects are short-lived, and hiring full-time employees isn\u2019t the most feasible option.</li></ul><p><strong>Where does Staff Augmentation Shine?</strong><br /><em>Highlighting the Strengths of Staff Augmentation</em></p><ul><li>Handling Work Overflows: Staff augmentation shines in situations where there\u2019s an abrupt increase in workload, stepping in to absorb the overflow efficiently, allowing your core team to focus without being overwhelmed.</li><li>Rare Skill Acquisition: It stands out when there's a need for a specific skill set that is rare and not commonly found in the market. Staff augmentation can provide you with experts who are well-versed in those rare skills, helping you to keep the project on track.</li><li>Meeting Stringent Deadlines: The staff augmentation approach is your ally when the clock is ticking, helping ramp up the team quickly to meet tight deadlines, and ensuring timely project delivery.</li><li>Cost-Effective Approach: In scenarios where budget optimization is a priority, staff augmentation proves to be a cost-effective strategy, allowing you to hire experts on an as-needed basis, without taking on long-term financial commitments.</li></ul><p><strong>How does Staff Augmentation Fill Your Needs?</strong><br /><em>Bridging Your Current Gaps with Tailored Solutions</em></p><ul><li>Agile Workforce: Given the fluctuating demands outlined in section one, staff augmentation responds by offering a workforce that is agile, able to swiftly adapt to varying project scales and requirements.</li><li>Ready-to-Deploy Experts: When there is a clear lack of specific skill sets in your team, staff augmentation fills this gap by providing experts who are ready to be deployed, placing the necessary expertise on your project.</li><li>Budget-friendly Solutions: Addressing the budget constraints mentioned earlier, staff augmentation offers a solution that is both economical and efficient, allowing you to maintain a balance between the quality of work and the budget available.</li><li>Solutions for Short-Term Projects: Taking into account short-term projects, staff augmentation provides professionals on a temporary basis, ensuring that you have the expertise required to successfully complete short-term engagements without any long-term commitments.</li></ul><p><strong>In Closing: The Future with Staff Augmentation</strong><br /><em>Finding the Missing Piece in your Tech Projects</em></p><p>Staff augmentation is the missing puzzle piece that can perfectly complete your tech projects. It can be the secret weapon that offers flexibility, access to expert skills, and budget-friendly options to stay ahead in the competitive tech industry.</p><blockquote>\"Hit your goals and deadlines without compromising on quality by leveraging people on our team.\" - <strong>Vincent Hendrickx,</strong> CEO at Codelitt</blockquote><p>As you forge paths in your upcoming projects, remember this dynamic tool is available to optimize your processes and outcomes. Could staff augmentation be your next game-changing move? We're just a message away if you want to explore the possibilities.</p>"
      }
    ]
  },
  "GameChanger": {
    "title": "Every Camera, Every Angle on Android",
    "xmlUrl": "http://tech.gc.com/atom.xml",
    "htmlUrl": "http://tech.gc.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.gc.com/atom.xml",
      "value": "Every Camera, Every Angle on Android"
    },
    "links": [
      {
        "href": "http://tech.gc.com/every-camera-every-angle-on-android/",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "link": "http://tech.gc.com/every-camera-every-angle-on-android/",
    "updated": "2021-09-20T14:49:50+00:00",
    "updated_parsed": [
      2021,
      9,
      20,
      14,
      49,
      50,
      0,
      263,
      0
    ],
    "id": "http://tech.gc.com/every-camera-every-angle-on-android",
    "guidislink": false,
    "authors": [
      {
        "name": "GameChanger",
        "href": "http://tech.gc.com/"
      }
    ],
    "author_detail": {
      "name": "GameChanger",
      "href": "http://tech.gc.com/"
    },
    "href": "http://tech.gc.com/",
    "author": "GameChanger",
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://tech.gc.com/atom.xml",
        "value": "<p>At GameChanger, video streaming has become a huge part of our business and thus our tech stack. But as a small company that practices shipping often, we can\u2019t ship everything feature complete from day one and thus video streaming launched with the ability to only stream from your default rear camera lens.</p>\n\n<p>But as we know, ultrawide lenses on phones have become common place and sure enough, customers began writing in, asking to be able to use their ultrawide cameras to stream their event. Baseball and softball fields are actually quite wide and it makes a lot of sense to be able to capture more of the field. So in time, ultrawide streaming became our priority and thus we engaged in battle with one of the most brittle Android APIs we have seen\u2026</p>\n\n<h1 id=\"streaming-in-the-olden-days\">Streaming in the olden days</h1>\n\n<p>Well, not really in the olden days, because we are using the most up to date APIs, but before we implemented ultrawide streaming, selecting the camera we wanted to stream with was generally pretty simple:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nc\">CameraManager</span><span class=\"p\">.</span><span class=\"nf\">chooseCamera</span><span class=\"p\">(</span><span class=\"n\">teamId</span><span class=\"p\">:</span> <span class=\"nc\">TeamId</span><span class=\"p\">)</span> <span class=\"p\">=</span> <span class=\"n\">cameraIdList</span><span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">id</span> <span class=\"p\">-&gt;</span>\n    <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">id</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">capabilities</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES</span><span class=\"p\">)</span><span class=\"o\">!!</span>\n\n    <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">LENS_FACING</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"nc\">CameraMetadata</span><span class=\"p\">.</span><span class=\"nc\">LENS_FACING_BACK</span> <span class=\"p\">&amp;&amp;</span>\n        <span class=\"n\">capabilities</span><span class=\"p\">.</span><span class=\"nf\">contains</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">mapNotNull</span> <span class=\"p\">{</span> <span class=\"n\">id</span> <span class=\"p\">-&gt;</span>\n        <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">id</span><span class=\"p\">)</span>\n        <span class=\"kd\">val</span> <span class=\"py\">cameraConfig</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">SCALER_STREAM_CONFIGURATION_MAP</span><span class=\"p\">)</span><span class=\"o\">!!</span>\n\n        <span class=\"kd\">val</span> <span class=\"p\">(</span><span class=\"py\">width</span><span class=\"p\">,</span> <span class=\"py\">height</span><span class=\"p\">)</span> <span class=\"p\">=</span> <span class=\"nf\">arrayOf</span><span class=\"p\">(</span><span class=\"mi\">1280</span><span class=\"p\">,</span> <span class=\"mi\">720</span><span class=\"p\">)</span>\n        <span class=\"n\">cameraConfig</span><span class=\"p\">.</span><span class=\"nf\">getOutputSizes</span><span class=\"p\">(</span><span class=\"nc\">MediaRecorder</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">.</span><span class=\"n\">java</span><span class=\"p\">)</span>\n            <span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">width</span> <span class=\"p\">&lt;=</span> <span class=\"n\">width</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">height</span> <span class=\"p\">&lt;=</span> <span class=\"n\">height</span> <span class=\"p\">}</span>\n            <span class=\"p\">.</span><span class=\"nf\">maxByOrNull</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">width</span> <span class=\"p\">*</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">height</span> <span class=\"p\">}</span><span class=\"o\">?.</span><span class=\"nf\">let</span> <span class=\"p\">{</span> <span class=\"n\">id</span> <span class=\"n\">to</span> <span class=\"n\">it</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"p\">(</span><span class=\"n\">id</span><span class=\"p\">,</span> <span class=\"n\">resolution</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">CameraArgs</span><span class=\"p\">(</span><span class=\"n\">cameraId</span> <span class=\"p\">=</span> <span class=\"n\">id</span><span class=\"p\">,</span> <span class=\"n\">width</span> <span class=\"p\">=</span> <span class=\"n\">resolution</span><span class=\"p\">.</span><span class=\"n\">width</span><span class=\"p\">,</span> <span class=\"n\">height</span> <span class=\"p\">=</span> <span class=\"n\">resolution</span><span class=\"p\">.</span><span class=\"n\">height</span><span class=\"p\">,</span> <span class=\"n\">fps</span> <span class=\"p\">=</span> <span class=\"mi\">30</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">firstOrNull</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><strong>TL;DR:</strong> Basically, get the first rear camera that supports 720p. Note the <code class=\"language-plaintext highlighter-rouge\">cameraId</code>\u2014an ID corresponds to each camera on the device\u2026right?</p>\n\n<p>Nope. Well sometimes, it depends.</p>\n\n<h2 id=\"enter-multi-camera-api\">Enter Multi-Camera API</h2>\n\n<p>At the time of writing, the not-deprecated API for accessing cameras on Android is <code class=\"language-plaintext highlighter-rouge\">camera2</code>. <code class=\"language-plaintext highlighter-rouge\">camera1</code> is deprecated. <code class=\"language-plaintext highlighter-rouge\">cameraX</code> is built on top of <code class=\"language-plaintext highlighter-rouge\">camera2</code>. Obviously.</p>\n\n<p><a href=\"https://developer.android.com/training/camera2\">Here</a> are some references for <code class=\"language-plaintext highlighter-rouge\">camera2</code>. We are going to focus on the multi-camera training <a href=\"https://developer.android.com/training/camera2/multi-camera\">here</a> as a jumping off point.</p>\n\n<p>The multi-camera training page does a great job of explaining the differences between logical and physical camera setups, when it was introduced and why but for the purposes of this article here\u2019s what you need to know:</p>\n<ul>\n  <li>An Android device running above API level 28 runs either a logical or physical camera setup. Below 28 is strictly a physical camera setup.</li>\n  <li>Physical camera setups expose each camera sensor individually with <code class=\"language-plaintext highlighter-rouge\">cameraId</code>s through <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code>. If you are lucky, you will have one camera id per physical sensor and be able to choose any id you want to stream with.</li>\n  <li>Logical camera setups hide the details of the different physical cameras sensors on the back side of the phone, giving you just one id for the front and back of the device in the <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code>. However, if you continue to poke the camera API, you can get those physical sensor ids, but you still can\u2019t use them to open a camera session. You must use ids from <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code>. Thus, to actually stream with an ultrawide sensor on a logical camera setup, you have to do more\u2026things.</li>\n</ul>\n\n<p>Okay, doesn\u2019t sound too bad. It\u2019s easy enough to figure out if a device is a physical or logical camera setup:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nc\">CameraManager</span><span class=\"p\">.</span><span class=\"nf\">getRearCameraIds</span><span class=\"p\">():</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span> <span class=\"n\">cameraIdList</span><span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">capabilities</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES</span><span class=\"p\">)</span>\n\n    <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">LENS_FACING</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"nc\">CameraMetadata</span><span class=\"p\">.</span><span class=\"nc\">LENS_FACING_BACK</span> <span class=\"p\">&amp;&amp;</span>\n        <span class=\"n\">capabilities</span><span class=\"o\">?.</span><span class=\"nf\">contains</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"k\">true</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nc\">CameraManager</span><span class=\"p\">.</span><span class=\"nf\">hasRearLogicalCameras</span><span class=\"p\">():</span> <span class=\"nc\">Boolean</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">getRearCameraIds</span><span class=\"p\">().</span><span class=\"nf\">any</span> <span class=\"p\">{</span>\n    <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">).</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES</span><span class=\"p\">)</span>\n        <span class=\"o\">?.</span><span class=\"nf\">contains</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"k\">true</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>So let\u2019s start with the easy one.</p>\n\n<h1 id=\"supporting-physical-camera-setups\">Supporting physical camera setups</h1>\n\n<p>Once we know that we are dealing with a physical camera setup, it\u2019s simply a matter of iterating over rear ids and calculating the widest one. Our camera feature only exposes the default and the widest sensor to the user, so this is the logic that works for us:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">getWidestPhysicalCamera</span><span class=\"p\">(</span><span class=\"n\">streamingResolution</span><span class=\"p\">:</span> <span class=\"nc\">StreamingResolution</span><span class=\"p\">):</span> <span class=\"nc\">CameraInfo</span><span class=\"p\">?</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">cameraManager</span>\n        <span class=\"p\">.</span><span class=\"nf\">getRearCameraIds</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">getWidestCameraId</span><span class=\"p\">()</span>\n        <span class=\"o\">?.</span><span class=\"nf\">mapNotNull</span> <span class=\"p\">{</span> <span class=\"n\">cameraId</span> <span class=\"p\">-&gt;</span>\n            <span class=\"n\">cameraId</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">().</span><span class=\"nf\">getMaxSupportedResolution</span><span class=\"p\">(</span><span class=\"n\">streamingResolution</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n        <span class=\"o\">?.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"p\">(</span><span class=\"n\">cameraId</span><span class=\"p\">,</span> <span class=\"n\">resolution</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span>\n            <span class=\"nc\">CameraInfo</span><span class=\"p\">(</span><span class=\"n\">cameraId</span><span class=\"p\">,</span> <span class=\"nc\">CameraLensType</span><span class=\"p\">.</span><span class=\"nc\">WidePhysical</span><span class=\"p\">,</span> <span class=\"nc\">StreamingResolution</span><span class=\"p\">(</span><span class=\"n\">resolution</span><span class=\"p\">.</span><span class=\"n\">width</span><span class=\"p\">,</span> <span class=\"n\">resolution</span><span class=\"p\">.</span><span class=\"n\">height</span><span class=\"p\">,</span> <span class=\"n\">streamingResolution</span><span class=\"p\">.</span><span class=\"n\">fps</span><span class=\"p\">))</span>\n        <span class=\"p\">}</span>\n        <span class=\"o\">?.</span><span class=\"nf\">firstOrNull</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;.</span><span class=\"nf\">getWidestCameraId</span><span class=\"p\">():</span> <span class=\"nc\">CameraId</span><span class=\"p\">?</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">maxByOrNull</span> <span class=\"p\">{</span>\n    <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">computeCameraWidth</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nc\">CameraId</span><span class=\"p\">.</span><span class=\"nf\">computeCameraWidth</span><span class=\"p\">():</span> <span class=\"nc\">Float</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">activeSize</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">SENSOR_INFO_ACTIVE_ARRAY_SIZE</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">physicalSize</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">SENSOR_INFO_PHYSICAL_SIZE</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">pixelSize</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">SENSOR_INFO_PIXEL_ARRAY_SIZE</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">focalLengths</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">LENS_INFO_AVAILABLE_FOCAL_LENGTHS</span><span class=\"p\">)</span>\n\n    <span class=\"kd\">var</span> <span class=\"py\">cameraWidth</span> <span class=\"p\">=</span> <span class=\"nc\">Float</span><span class=\"p\">.</span><span class=\"nc\">MIN_VALUE</span>\n\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">activeSize</span> <span class=\"p\">!=</span> <span class=\"k\">null</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">physicalSize</span> <span class=\"p\">!=</span> <span class=\"k\">null</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">pixelSize</span> <span class=\"p\">!=</span> <span class=\"k\">null</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">focalLengths</span> <span class=\"p\">!=</span> <span class=\"k\">null</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">fractionX</span> <span class=\"p\">=</span> <span class=\"n\">activeSize</span><span class=\"p\">.</span><span class=\"nf\">width</span><span class=\"p\">().</span><span class=\"nf\">toFloat</span><span class=\"p\">()</span> <span class=\"p\">/</span> <span class=\"n\">pixelSize</span><span class=\"p\">.</span><span class=\"n\">width</span><span class=\"p\">.</span><span class=\"nf\">toFloat</span><span class=\"p\">()</span>\n\n        <span class=\"kd\">val</span> <span class=\"py\">firstFocalLength</span> <span class=\"p\">=</span> <span class=\"n\">focalLengths</span><span class=\"p\">.</span><span class=\"nf\">firstOrNull</span><span class=\"p\">()</span>\n\n        <span class=\"n\">firstFocalLength</span><span class=\"o\">?.</span><span class=\"nf\">let</span> <span class=\"p\">{</span>\n            <span class=\"n\">cameraWidth</span> <span class=\"p\">=</span> <span class=\"nc\">Math</span><span class=\"p\">.</span><span class=\"nf\">toDegrees</span><span class=\"p\">(</span><span class=\"mf\">2.0</span> <span class=\"p\">*</span> <span class=\"nf\">atan2</span><span class=\"p\">((</span><span class=\"n\">physicalSize</span><span class=\"p\">.</span><span class=\"n\">width</span> <span class=\"p\">*</span> <span class=\"n\">fractionX</span><span class=\"p\">).</span><span class=\"nf\">toDouble</span><span class=\"p\">(),</span> <span class=\"mf\">2.0</span> <span class=\"p\">*</span> <span class=\"n\">firstFocalLength</span><span class=\"p\">)).</span><span class=\"nf\">toFloat</span><span class=\"p\">()</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">cameraWidth</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Note that we basically ripped the widest calculation logic from various SO posts. <a href=\"https://stackoverflow.com/questions/39965408/what-is-the-android-camera2-api-equivalent-of-camera-parameters-gethorizontalvie/39983168\">Here\u2019s</a> one that offers a good explanation of what\u2019s going on there.</p>\n\n<p>This logic along with the original logic to fetch the default rear camera yields two camera ids. Switching between them is just restarting your preview/capture session with the new id.</p>\n\n<h1 id=\"supporting-logical-camera-setups\">Supporting logical camera setups</h1>\n\n<p>Okay, we have to jump through a few more hoops when supporting logical camera setups. Once we have determined we do have a logical camera setup present, we have to determine which rear camera id has the logical cameras behind it:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"nd\">@RequiresApi</span><span class=\"p\">(</span><span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">P</span><span class=\"p\">)</span>\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;.</span><span class=\"nf\">getLogicalCameras</span><span class=\"p\">():</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">capabilities</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES</span><span class=\"p\">)</span>\n    <span class=\"n\">capabilities</span><span class=\"o\">?.</span><span class=\"nf\">contains</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"k\">true</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Now we have a list of rear camera ids that have logical multi camera capabilities. This means that this camera id is a <em>logical</em> camera id. This means that this <em>logical</em> camera id has 2 or more <em>physical</em> camera ids behind it. We need those to address individual lenses. This is how we get them:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"nd\">@RequiresApi</span><span class=\"p\">(</span><span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">P</span><span class=\"p\">)</span>\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;.</span><span class=\"nf\">getAllLogicalPhysicalPairs</span><span class=\"p\">():</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">Pair</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">,</span> <span class=\"nc\">CameraId</span><span class=\"p\">&gt;&gt;</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">flatMap</span> <span class=\"p\">{</span> <span class=\"n\">logicalCameraId</span> <span class=\"p\">-&gt;</span>\n    <span class=\"kd\">val</span> <span class=\"py\">physicalCameraIds</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">logicalCameraId</span><span class=\"p\">).</span><span class=\"n\">physicalCameraIds</span><span class=\"p\">.</span><span class=\"nf\">toList</span><span class=\"p\">()</span>\n    <span class=\"n\">physicalCameraIds</span><span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span>\n        <span class=\"nc\">Pair</span><span class=\"p\">(</span><span class=\"n\">logicalCameraId</span><span class=\"p\">,</span> <span class=\"n\">it</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Now we have <em>physical</em> ids paired up with their logical id. Now we need to figure out the widest lens of the physical ones. This is easier than the physical setup, because now we have <code class=\"language-plaintext highlighter-rouge\">LENS_INFO_AVAILABLE_FOCAL_LENGTHS</code> available to us:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">Pair</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">,</span> <span class=\"nc\">CameraId</span><span class=\"p\">&gt;&gt;.</span><span class=\"nf\">getWidestLogicalCamera</span><span class=\"p\">():</span> <span class=\"nc\">CameraId</span><span class=\"p\">?</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">minByOrNull</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">cameraCharacteristics</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">second</span><span class=\"p\">)</span>\n    <span class=\"n\">cameraCharacteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">LENS_INFO_AVAILABLE_FOCAL_LENGTHS</span><span class=\"p\">)</span><span class=\"o\">?.</span><span class=\"nf\">minOrNull</span><span class=\"p\">()</span> <span class=\"o\">?:</span> <span class=\"nc\">Float</span><span class=\"p\">.</span><span class=\"nc\">MAX_VALUE</span>\n<span class=\"p\">}</span><span class=\"o\">?.</span><span class=\"n\">first</span></code></pre></figure>\n\n<p>Exhausted yet? Finally, logical camera setups require you to set a zoom ratio to get the widest focal length. We get the number like so:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"nd\">@RequiresApi</span><span class=\"p\">(</span><span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">R</span><span class=\"p\">)</span>\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">getMinimumControlZoomRatio</span><span class=\"p\">(</span><span class=\"n\">logicalCameraId</span><span class=\"p\">:</span> <span class=\"nc\">CameraId</span><span class=\"p\">):</span> <span class=\"nc\">Float</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">cameraCharacteristics</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">logicalCameraId</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">cameraCharacteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">CONTROL_ZOOM_RATIO_RANGE</span><span class=\"p\">)</span><span class=\"o\">?.</span><span class=\"n\">lower</span> <span class=\"o\">?:</span> <span class=\"mf\">1F</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Putting it all together:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"nd\">@RequiresApi</span><span class=\"p\">(</span><span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">R</span><span class=\"p\">)</span>\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">getWidestLogicalRearCamera</span><span class=\"p\">():</span> <span class=\"nc\">CameraLensType</span><span class=\"p\">.</span><span class=\"nc\">WideLogical</span><span class=\"p\">?</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">cameraManager</span>\n        <span class=\"p\">.</span><span class=\"nf\">getRearCameraIds</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">getLogicalCameras</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">getAllLogicalPhysicalPairs</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">getWidestLogicalCamera</span><span class=\"p\">()</span>\n        <span class=\"o\">?.</span><span class=\"nf\">let</span> <span class=\"p\">{</span>\n            <span class=\"nc\">CameraLensType</span><span class=\"p\">.</span><span class=\"nc\">WideLogical</span><span class=\"p\">(</span><span class=\"nf\">getMinimumControlZoomRatio</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">))</span>\n        <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>So we have the correct id to open the rear camera session with and a control zoom ratio. The capture request is built the same but now we use the control zoom ratio:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">cameraLensType</span> <span class=\"k\">is</span> <span class=\"nc\">CameraLensType</span><span class=\"p\">.</span><span class=\"nc\">WideLogical</span> <span class=\"p\">&amp;&amp;</span> <span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION</span><span class=\"p\">.</span><span class=\"nc\">SDK_INT</span> <span class=\"p\">&gt;=</span> <span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">R</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">captureRequestBuilder</span><span class=\"p\">.</span><span class=\"k\">set</span><span class=\"p\">(</span><span class=\"nc\">CaptureRequest</span><span class=\"p\">.</span><span class=\"nc\">CONTROL_ZOOM_RATIO</span><span class=\"p\">,</span> <span class=\"n\">cameraLensType</span><span class=\"p\">.</span><span class=\"n\">controlZoomRatio</span><span class=\"p\">)</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Note that you don\u2019t use <code class=\"language-plaintext highlighter-rouge\">physicalCameraIds</code> to actually open a camera session. With logical camera setups, you still use a camera id found in <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code> to open a camera session. You then just give it a minimum zoom control ratio. Then the OS itself takes care of selecting the widest lens to reach the desired zoom control.</p>\n\n<h2 id=\"gotcha\">Gotcha!</h2>\n\n<p>Okay, so code stuff out of the way. Figuring all the correct ways of doing this was tough as there are not a lot of code samples out there. But there is one\u2026</p>\n\n<p><a href=\"https://sourceforge.net/projects/opencamera/\">OpenCamera</a>. OpenCamera is a highly featured, open source camera app. And it includes support for physical and logical multi camera setups! Great, a perfect reference.</p>\n\n<p>So I install OpenCamera on my OnePlus 7 Pro and it seamlessly switches between wide and ultrawide lenses. So a couple cmd+c, cmd+v strokes from the OpenCamera source later I had the multi-camera implementation inside the TeamManager app. And\u2026it didn\u2019t work. <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code> showed only the front camera and the rear standard lenses in my app (Note this is a physical setup). But in the OpenCamera app, the same API call <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code> showed the front camera, rear standard and rear ultrawide.</p>\n\n<p>This really threw us for a loop. For whatever reason, the OpenCamera package name was white listed and thus allowed to access more camera ids.* Why? We aren\u2019t sure. Just OnePlus things, amirite? But what it means is that our app can not support wide angle streaming for OnePlus devices.</p>\n\n<p>*I can\u2019t find where I found this anymore, but it was buried deep in a SO post. Took us a couple of days at least to find out.</p>\n\n<p>And this was just the tip of the iceberg for dealing with manufacturers\u2019 implementation\u2026</p>\n\n<h2 id=\"at-the-mercy-of-the-manufacturers\">At the mercy of the manufacturers</h2>\n\n<p>Reading this whole article, you may ask, how do we know which phones support which setup? Well, the short answer is that we have no idea. Here\u2019s a short list of what we have found so far, if the device has an ultrawide rear lens:</p>\n\n<p><strong>OnePlus devices:</strong> Physical setup that doesn\u2019t expose ultrawide to our app, does expose ultrawide to OpenCamera. Ultrawide works in native camera app.</p>\n\n<p><strong>Motorola devices:</strong> Physical setup that doesn\u2019t expose ultrawide to <em>any</em> app. Ultrawide works in native camera app.</p>\n\n<p><strong>Samsung devices:</strong> Physical setup that exposes standard rear and ultrawide. Ultrawide works in native camera app and OpenCamera. We were able to support Samsung devices.</p>\n\n<p><strong>Pixel devices:</strong> Logical setup, but only the Pixel 5 has an ultrawide. The Pixel 4 has a standard and telephoto. So we needed to check if the device has a logical rear camera that is <em>wider</em> than the default camera. Pixels are the only devices we have found that support logical setups.</p>\n\n<p>And these are just the ones we know about! We don\u2019t have every device in the world and this can change with software updates and new devices.</p>\n\n<p>As you can see, how each manufacturer decides to implement the multi-camera API is completely random and illogical. We ended not being able to support as many devices as we thought when the project was conceived. It is very disappointing to see the state of the multi camera API as manufacturers implement it. Especially considering how many devices are being built with multiple lenses.</p>\n\n<p>But hey, I think we are \u201cfuture-proofed\u201d, whatever that means. Until the multi-camera API is deprecated anyway\u2026</p>"
      }
    ],
    "summary": "<p>At GameChanger, video streaming has become a huge part of our business and thus our tech stack. But as a small company that practices shipping often, we can\u2019t ship everything feature complete from day one and thus video streaming launched with the ability to only stream from your default rear camera lens.</p>\n\n<p>But as we know, ultrawide lenses on phones have become common place and sure enough, customers began writing in, asking to be able to use their ultrawide cameras to stream their event. Baseball and softball fields are actually quite wide and it makes a lot of sense to be able to capture more of the field. So in time, ultrawide streaming became our priority and thus we engaged in battle with one of the most brittle Android APIs we have seen\u2026</p>\n\n<h1 id=\"streaming-in-the-olden-days\">Streaming in the olden days</h1>\n\n<p>Well, not really in the olden days, because we are using the most up to date APIs, but before we implemented ultrawide streaming, selecting the camera we wanted to stream with was generally pretty simple:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nc\">CameraManager</span><span class=\"p\">.</span><span class=\"nf\">chooseCamera</span><span class=\"p\">(</span><span class=\"n\">teamId</span><span class=\"p\">:</span> <span class=\"nc\">TeamId</span><span class=\"p\">)</span> <span class=\"p\">=</span> <span class=\"n\">cameraIdList</span><span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">id</span> <span class=\"p\">-&gt;</span>\n    <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">id</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">capabilities</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES</span><span class=\"p\">)</span><span class=\"o\">!!</span>\n\n    <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">LENS_FACING</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"nc\">CameraMetadata</span><span class=\"p\">.</span><span class=\"nc\">LENS_FACING_BACK</span> <span class=\"p\">&amp;&amp;</span>\n        <span class=\"n\">capabilities</span><span class=\"p\">.</span><span class=\"nf\">contains</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">mapNotNull</span> <span class=\"p\">{</span> <span class=\"n\">id</span> <span class=\"p\">-&gt;</span>\n        <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">id</span><span class=\"p\">)</span>\n        <span class=\"kd\">val</span> <span class=\"py\">cameraConfig</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">SCALER_STREAM_CONFIGURATION_MAP</span><span class=\"p\">)</span><span class=\"o\">!!</span>\n\n        <span class=\"kd\">val</span> <span class=\"p\">(</span><span class=\"py\">width</span><span class=\"p\">,</span> <span class=\"py\">height</span><span class=\"p\">)</span> <span class=\"p\">=</span> <span class=\"nf\">arrayOf</span><span class=\"p\">(</span><span class=\"mi\">1280</span><span class=\"p\">,</span> <span class=\"mi\">720</span><span class=\"p\">)</span>\n        <span class=\"n\">cameraConfig</span><span class=\"p\">.</span><span class=\"nf\">getOutputSizes</span><span class=\"p\">(</span><span class=\"nc\">MediaRecorder</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">.</span><span class=\"n\">java</span><span class=\"p\">)</span>\n            <span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">width</span> <span class=\"p\">&lt;=</span> <span class=\"n\">width</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">height</span> <span class=\"p\">&lt;=</span> <span class=\"n\">height</span> <span class=\"p\">}</span>\n            <span class=\"p\">.</span><span class=\"nf\">maxByOrNull</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">width</span> <span class=\"p\">*</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">height</span> <span class=\"p\">}</span><span class=\"o\">?.</span><span class=\"nf\">let</span> <span class=\"p\">{</span> <span class=\"n\">id</span> <span class=\"n\">to</span> <span class=\"n\">it</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"p\">(</span><span class=\"n\">id</span><span class=\"p\">,</span> <span class=\"n\">resolution</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">CameraArgs</span><span class=\"p\">(</span><span class=\"n\">cameraId</span> <span class=\"p\">=</span> <span class=\"n\">id</span><span class=\"p\">,</span> <span class=\"n\">width</span> <span class=\"p\">=</span> <span class=\"n\">resolution</span><span class=\"p\">.</span><span class=\"n\">width</span><span class=\"p\">,</span> <span class=\"n\">height</span> <span class=\"p\">=</span> <span class=\"n\">resolution</span><span class=\"p\">.</span><span class=\"n\">height</span><span class=\"p\">,</span> <span class=\"n\">fps</span> <span class=\"p\">=</span> <span class=\"mi\">30</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">firstOrNull</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><strong>TL;DR:</strong> Basically, get the first rear camera that supports 720p. Note the <code class=\"language-plaintext highlighter-rouge\">cameraId</code>\u2014an ID corresponds to each camera on the device\u2026right?</p>\n\n<p>Nope. Well sometimes, it depends.</p>\n\n<h2 id=\"enter-multi-camera-api\">Enter Multi-Camera API</h2>\n\n<p>At the time of writing, the not-deprecated API for accessing cameras on Android is <code class=\"language-plaintext highlighter-rouge\">camera2</code>. <code class=\"language-plaintext highlighter-rouge\">camera1</code> is deprecated. <code class=\"language-plaintext highlighter-rouge\">cameraX</code> is built on top of <code class=\"language-plaintext highlighter-rouge\">camera2</code>. Obviously.</p>\n\n<p><a href=\"https://developer.android.com/training/camera2\">Here</a> are some references for <code class=\"language-plaintext highlighter-rouge\">camera2</code>. We are going to focus on the multi-camera training <a href=\"https://developer.android.com/training/camera2/multi-camera\">here</a> as a jumping off point.</p>\n\n<p>The multi-camera training page does a great job of explaining the differences between logical and physical camera setups, when it was introduced and why but for the purposes of this article here\u2019s what you need to know:</p>\n<ul>\n  <li>An Android device running above API level 28 runs either a logical or physical camera setup. Below 28 is strictly a physical camera setup.</li>\n  <li>Physical camera setups expose each camera sensor individually with <code class=\"language-plaintext highlighter-rouge\">cameraId</code>s through <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code>. If you are lucky, you will have one camera id per physical sensor and be able to choose any id you want to stream with.</li>\n  <li>Logical camera setups hide the details of the different physical cameras sensors on the back side of the phone, giving you just one id for the front and back of the device in the <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code>. However, if you continue to poke the camera API, you can get those physical sensor ids, but you still can\u2019t use them to open a camera session. You must use ids from <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code>. Thus, to actually stream with an ultrawide sensor on a logical camera setup, you have to do more\u2026things.</li>\n</ul>\n\n<p>Okay, doesn\u2019t sound too bad. It\u2019s easy enough to figure out if a device is a physical or logical camera setup:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nc\">CameraManager</span><span class=\"p\">.</span><span class=\"nf\">getRearCameraIds</span><span class=\"p\">():</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span> <span class=\"n\">cameraIdList</span><span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">capabilities</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES</span><span class=\"p\">)</span>\n\n    <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">LENS_FACING</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"nc\">CameraMetadata</span><span class=\"p\">.</span><span class=\"nc\">LENS_FACING_BACK</span> <span class=\"p\">&amp;&amp;</span>\n        <span class=\"n\">capabilities</span><span class=\"o\">?.</span><span class=\"nf\">contains</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"k\">true</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nc\">CameraManager</span><span class=\"p\">.</span><span class=\"nf\">hasRearLogicalCameras</span><span class=\"p\">():</span> <span class=\"nc\">Boolean</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">getRearCameraIds</span><span class=\"p\">().</span><span class=\"nf\">any</span> <span class=\"p\">{</span>\n    <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">).</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES</span><span class=\"p\">)</span>\n        <span class=\"o\">?.</span><span class=\"nf\">contains</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"k\">true</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>So let\u2019s start with the easy one.</p>\n\n<h1 id=\"supporting-physical-camera-setups\">Supporting physical camera setups</h1>\n\n<p>Once we know that we are dealing with a physical camera setup, it\u2019s simply a matter of iterating over rear ids and calculating the widest one. Our camera feature only exposes the default and the widest sensor to the user, so this is the logic that works for us:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">getWidestPhysicalCamera</span><span class=\"p\">(</span><span class=\"n\">streamingResolution</span><span class=\"p\">:</span> <span class=\"nc\">StreamingResolution</span><span class=\"p\">):</span> <span class=\"nc\">CameraInfo</span><span class=\"p\">?</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">cameraManager</span>\n        <span class=\"p\">.</span><span class=\"nf\">getRearCameraIds</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">getWidestCameraId</span><span class=\"p\">()</span>\n        <span class=\"o\">?.</span><span class=\"nf\">mapNotNull</span> <span class=\"p\">{</span> <span class=\"n\">cameraId</span> <span class=\"p\">-&gt;</span>\n            <span class=\"n\">cameraId</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">().</span><span class=\"nf\">getMaxSupportedResolution</span><span class=\"p\">(</span><span class=\"n\">streamingResolution</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n        <span class=\"o\">?.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"p\">(</span><span class=\"n\">cameraId</span><span class=\"p\">,</span> <span class=\"n\">resolution</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span>\n            <span class=\"nc\">CameraInfo</span><span class=\"p\">(</span><span class=\"n\">cameraId</span><span class=\"p\">,</span> <span class=\"nc\">CameraLensType</span><span class=\"p\">.</span><span class=\"nc\">WidePhysical</span><span class=\"p\">,</span> <span class=\"nc\">StreamingResolution</span><span class=\"p\">(</span><span class=\"n\">resolution</span><span class=\"p\">.</span><span class=\"n\">width</span><span class=\"p\">,</span> <span class=\"n\">resolution</span><span class=\"p\">.</span><span class=\"n\">height</span><span class=\"p\">,</span> <span class=\"n\">streamingResolution</span><span class=\"p\">.</span><span class=\"n\">fps</span><span class=\"p\">))</span>\n        <span class=\"p\">}</span>\n        <span class=\"o\">?.</span><span class=\"nf\">firstOrNull</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;.</span><span class=\"nf\">getWidestCameraId</span><span class=\"p\">():</span> <span class=\"nc\">CameraId</span><span class=\"p\">?</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">maxByOrNull</span> <span class=\"p\">{</span>\n    <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">computeCameraWidth</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nc\">CameraId</span><span class=\"p\">.</span><span class=\"nf\">computeCameraWidth</span><span class=\"p\">():</span> <span class=\"nc\">Float</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">activeSize</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">SENSOR_INFO_ACTIVE_ARRAY_SIZE</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">physicalSize</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">SENSOR_INFO_PHYSICAL_SIZE</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">pixelSize</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">SENSOR_INFO_PIXEL_ARRAY_SIZE</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">focalLengths</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">LENS_INFO_AVAILABLE_FOCAL_LENGTHS</span><span class=\"p\">)</span>\n\n    <span class=\"kd\">var</span> <span class=\"py\">cameraWidth</span> <span class=\"p\">=</span> <span class=\"nc\">Float</span><span class=\"p\">.</span><span class=\"nc\">MIN_VALUE</span>\n\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">activeSize</span> <span class=\"p\">!=</span> <span class=\"k\">null</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">physicalSize</span> <span class=\"p\">!=</span> <span class=\"k\">null</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">pixelSize</span> <span class=\"p\">!=</span> <span class=\"k\">null</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">focalLengths</span> <span class=\"p\">!=</span> <span class=\"k\">null</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">fractionX</span> <span class=\"p\">=</span> <span class=\"n\">activeSize</span><span class=\"p\">.</span><span class=\"nf\">width</span><span class=\"p\">().</span><span class=\"nf\">toFloat</span><span class=\"p\">()</span> <span class=\"p\">/</span> <span class=\"n\">pixelSize</span><span class=\"p\">.</span><span class=\"n\">width</span><span class=\"p\">.</span><span class=\"nf\">toFloat</span><span class=\"p\">()</span>\n\n        <span class=\"kd\">val</span> <span class=\"py\">firstFocalLength</span> <span class=\"p\">=</span> <span class=\"n\">focalLengths</span><span class=\"p\">.</span><span class=\"nf\">firstOrNull</span><span class=\"p\">()</span>\n\n        <span class=\"n\">firstFocalLength</span><span class=\"o\">?.</span><span class=\"nf\">let</span> <span class=\"p\">{</span>\n            <span class=\"n\">cameraWidth</span> <span class=\"p\">=</span> <span class=\"nc\">Math</span><span class=\"p\">.</span><span class=\"nf\">toDegrees</span><span class=\"p\">(</span><span class=\"mf\">2.0</span> <span class=\"p\">*</span> <span class=\"nf\">atan2</span><span class=\"p\">((</span><span class=\"n\">physicalSize</span><span class=\"p\">.</span><span class=\"n\">width</span> <span class=\"p\">*</span> <span class=\"n\">fractionX</span><span class=\"p\">).</span><span class=\"nf\">toDouble</span><span class=\"p\">(),</span> <span class=\"mf\">2.0</span> <span class=\"p\">*</span> <span class=\"n\">firstFocalLength</span><span class=\"p\">)).</span><span class=\"nf\">toFloat</span><span class=\"p\">()</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">cameraWidth</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Note that we basically ripped the widest calculation logic from various SO posts. <a href=\"https://stackoverflow.com/questions/39965408/what-is-the-android-camera2-api-equivalent-of-camera-parameters-gethorizontalvie/39983168\">Here\u2019s</a> one that offers a good explanation of what\u2019s going on there.</p>\n\n<p>This logic along with the original logic to fetch the default rear camera yields two camera ids. Switching between them is just restarting your preview/capture session with the new id.</p>\n\n<h1 id=\"supporting-logical-camera-setups\">Supporting logical camera setups</h1>\n\n<p>Okay, we have to jump through a few more hoops when supporting logical camera setups. Once we have determined we do have a logical camera setup present, we have to determine which rear camera id has the logical cameras behind it:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"nd\">@RequiresApi</span><span class=\"p\">(</span><span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">P</span><span class=\"p\">)</span>\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;.</span><span class=\"nf\">getLogicalCameras</span><span class=\"p\">():</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">characteristics</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">capabilities</span> <span class=\"p\">=</span> <span class=\"n\">characteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES</span><span class=\"p\">)</span>\n    <span class=\"n\">capabilities</span><span class=\"o\">?.</span><span class=\"nf\">contains</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA</span><span class=\"p\">)</span> <span class=\"p\">==</span> <span class=\"k\">true</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Now we have a list of rear camera ids that have logical multi camera capabilities. This means that this camera id is a <em>logical</em> camera id. This means that this <em>logical</em> camera id has 2 or more <em>physical</em> camera ids behind it. We need those to address individual lenses. This is how we get them:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"nd\">@RequiresApi</span><span class=\"p\">(</span><span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">P</span><span class=\"p\">)</span>\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">&gt;.</span><span class=\"nf\">getAllLogicalPhysicalPairs</span><span class=\"p\">():</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">Pair</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">,</span> <span class=\"nc\">CameraId</span><span class=\"p\">&gt;&gt;</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">flatMap</span> <span class=\"p\">{</span> <span class=\"n\">logicalCameraId</span> <span class=\"p\">-&gt;</span>\n    <span class=\"kd\">val</span> <span class=\"py\">physicalCameraIds</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">logicalCameraId</span><span class=\"p\">).</span><span class=\"n\">physicalCameraIds</span><span class=\"p\">.</span><span class=\"nf\">toList</span><span class=\"p\">()</span>\n    <span class=\"n\">physicalCameraIds</span><span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span>\n        <span class=\"nc\">Pair</span><span class=\"p\">(</span><span class=\"n\">logicalCameraId</span><span class=\"p\">,</span> <span class=\"n\">it</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Now we have <em>physical</em> ids paired up with their logical id. Now we need to figure out the widest lens of the physical ones. This is easier than the physical setup, because now we have <code class=\"language-plaintext highlighter-rouge\">LENS_INFO_AVAILABLE_FOCAL_LENGTHS</code> available to us:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">Pair</span><span class=\"p\">&lt;</span><span class=\"nc\">CameraId</span><span class=\"p\">,</span> <span class=\"nc\">CameraId</span><span class=\"p\">&gt;&gt;.</span><span class=\"nf\">getWidestLogicalCamera</span><span class=\"p\">():</span> <span class=\"nc\">CameraId</span><span class=\"p\">?</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nf\">minByOrNull</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">cameraCharacteristics</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">second</span><span class=\"p\">)</span>\n    <span class=\"n\">cameraCharacteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">LENS_INFO_AVAILABLE_FOCAL_LENGTHS</span><span class=\"p\">)</span><span class=\"o\">?.</span><span class=\"nf\">minOrNull</span><span class=\"p\">()</span> <span class=\"o\">?:</span> <span class=\"nc\">Float</span><span class=\"p\">.</span><span class=\"nc\">MAX_VALUE</span>\n<span class=\"p\">}</span><span class=\"o\">?.</span><span class=\"n\">first</span></code></pre></figure>\n\n<p>Exhausted yet? Finally, logical camera setups require you to set a zoom ratio to get the widest focal length. We get the number like so:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"nd\">@RequiresApi</span><span class=\"p\">(</span><span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">R</span><span class=\"p\">)</span>\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">getMinimumControlZoomRatio</span><span class=\"p\">(</span><span class=\"n\">logicalCameraId</span><span class=\"p\">:</span> <span class=\"nc\">CameraId</span><span class=\"p\">):</span> <span class=\"nc\">Float</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">cameraCharacteristics</span> <span class=\"p\">=</span> <span class=\"n\">cameraManager</span><span class=\"p\">.</span><span class=\"nf\">getCameraCharacteristics</span><span class=\"p\">(</span><span class=\"n\">logicalCameraId</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">cameraCharacteristics</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"nc\">CameraCharacteristics</span><span class=\"p\">.</span><span class=\"nc\">CONTROL_ZOOM_RATIO_RANGE</span><span class=\"p\">)</span><span class=\"o\">?.</span><span class=\"n\">lower</span> <span class=\"o\">?:</span> <span class=\"mf\">1F</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Putting it all together:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"nd\">@RequiresApi</span><span class=\"p\">(</span><span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">R</span><span class=\"p\">)</span>\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">getWidestLogicalRearCamera</span><span class=\"p\">():</span> <span class=\"nc\">CameraLensType</span><span class=\"p\">.</span><span class=\"nc\">WideLogical</span><span class=\"p\">?</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">cameraManager</span>\n        <span class=\"p\">.</span><span class=\"nf\">getRearCameraIds</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">getLogicalCameras</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">getAllLogicalPhysicalPairs</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">getWidestLogicalCamera</span><span class=\"p\">()</span>\n        <span class=\"o\">?.</span><span class=\"nf\">let</span> <span class=\"p\">{</span>\n            <span class=\"nc\">CameraLensType</span><span class=\"p\">.</span><span class=\"nc\">WideLogical</span><span class=\"p\">(</span><span class=\"nf\">getMinimumControlZoomRatio</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">))</span>\n        <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>So we have the correct id to open the rear camera session with and a control zoom ratio. The capture request is built the same but now we use the control zoom ratio:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-kotlin\"><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">cameraLensType</span> <span class=\"k\">is</span> <span class=\"nc\">CameraLensType</span><span class=\"p\">.</span><span class=\"nc\">WideLogical</span> <span class=\"p\">&amp;&amp;</span> <span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION</span><span class=\"p\">.</span><span class=\"nc\">SDK_INT</span> <span class=\"p\">&gt;=</span> <span class=\"nc\">Build</span><span class=\"p\">.</span><span class=\"nc\">VERSION_CODES</span><span class=\"p\">.</span><span class=\"nc\">R</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">captureRequestBuilder</span><span class=\"p\">.</span><span class=\"k\">set</span><span class=\"p\">(</span><span class=\"nc\">CaptureRequest</span><span class=\"p\">.</span><span class=\"nc\">CONTROL_ZOOM_RATIO</span><span class=\"p\">,</span> <span class=\"n\">cameraLensType</span><span class=\"p\">.</span><span class=\"n\">controlZoomRatio</span><span class=\"p\">)</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>Note that you don\u2019t use <code class=\"language-plaintext highlighter-rouge\">physicalCameraIds</code> to actually open a camera session. With logical camera setups, you still use a camera id found in <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code> to open a camera session. You then just give it a minimum zoom control ratio. Then the OS itself takes care of selecting the widest lens to reach the desired zoom control.</p>\n\n<h2 id=\"gotcha\">Gotcha!</h2>\n\n<p>Okay, so code stuff out of the way. Figuring all the correct ways of doing this was tough as there are not a lot of code samples out there. But there is one\u2026</p>\n\n<p><a href=\"https://sourceforge.net/projects/opencamera/\">OpenCamera</a>. OpenCamera is a highly featured, open source camera app. And it includes support for physical and logical multi camera setups! Great, a perfect reference.</p>\n\n<p>So I install OpenCamera on my OnePlus 7 Pro and it seamlessly switches between wide and ultrawide lenses. So a couple cmd+c, cmd+v strokes from the OpenCamera source later I had the multi-camera implementation inside the TeamManager app. And\u2026it didn\u2019t work. <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code> showed only the front camera and the rear standard lenses in my app (Note this is a physical setup). But in the OpenCamera app, the same API call <code class=\"language-plaintext highlighter-rouge\">cameraManager.cameraIdList</code> showed the front camera, rear standard and rear ultrawide.</p>\n\n<p>This really threw us for a loop. For whatever reason, the OpenCamera package name was white listed and thus allowed to access more camera ids.* Why? We aren\u2019t sure. Just OnePlus things, amirite? But what it means is that our app can not support wide angle streaming for OnePlus devices.</p>\n\n<p>*I can\u2019t find where I found this anymore, but it was buried deep in a SO post. Took us a couple of days at least to find out.</p>\n\n<p>And this was just the tip of the iceberg for dealing with manufacturers\u2019 implementation\u2026</p>\n\n<h2 id=\"at-the-mercy-of-the-manufacturers\">At the mercy of the manufacturers</h2>\n\n<p>Reading this whole article, you may ask, how do we know which phones support which setup? Well, the short answer is that we have no idea. Here\u2019s a short list of what we have found so far, if the device has an ultrawide rear lens:</p>\n\n<p><strong>OnePlus devices:</strong> Physical setup that doesn\u2019t expose ultrawide to our app, does expose ultrawide to OpenCamera. Ultrawide works in native camera app.</p>\n\n<p><strong>Motorola devices:</strong> Physical setup that doesn\u2019t expose ultrawide to <em>any</em> app. Ultrawide works in native camera app.</p>\n\n<p><strong>Samsung devices:</strong> Physical setup that exposes standard rear and ultrawide. Ultrawide works in native camera app and OpenCamera. We were able to support Samsung devices.</p>\n\n<p><strong>Pixel devices:</strong> Logical setup, but only the Pixel 5 has an ultrawide. The Pixel 4 has a standard and telephoto. So we needed to check if the device has a logical rear camera that is <em>wider</em> than the default camera. Pixels are the only devices we have found that support logical setups.</p>\n\n<p>And these are just the ones we know about! We don\u2019t have every device in the world and this can change with software updates and new devices.</p>\n\n<p>As you can see, how each manufacturer decides to implement the multi-camera API is completely random and illogical. We ended not being able to support as many devices as we thought when the project was conceived. It is very disappointing to see the state of the multi camera API as manufacturers implement it. Especially considering how many devices are being built with multiple lenses.</p>\n\n<p>But hey, I think we are \u201cfuture-proofed\u201d, whatever that means. Until the multi-camera API is deprecated anyway\u2026</p>"
  },
  "Confluent": {
    "title": "Getting Started with OAuth for Confluent Cloud Using Azure AD DS",
    "xmlUrl": "https://www.confluent.io/feed/",
    "htmlUrl": "https://www.confluent.io/blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.confluent.io/rss.xml",
      "value": "Getting Started with OAuth for Confluent Cloud Using Azure AD DS"
    },
    "summary": "In this comprehensive guide, learn how to configure Azure AD DS and OAuth for Confluent Cloud to enable authentication and authorization for apps.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.confluent.io/rss.xml",
      "value": "In this comprehensive guide, learn how to configure Azure AD DS and OAuth for Confluent Cloud to enable authentication and authorization for apps."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.confluent.io/blog/configuring-azure-ad-ds-with-oauth-for-confluent/"
      }
    ],
    "link": "https://www.confluent.io/blog/configuring-azure-ad-ds-with-oauth-for-confluent/",
    "id": "https://www.confluent.io/blog/configuring-azure-ad-ds-with-oauth-for-confluent/",
    "guidislink": false,
    "tags": [
      {
        "term": "Confluent",
        "scheme": null,
        "label": null
      }
    ],
    "published": "Fri, 12 Jan 2024 18:07:48 GMT",
    "published_parsed": [
      2024,
      1,
      12,
      18,
      7,
      48,
      4,
      12,
      0
    ],
    "authors": [
      {
        "name": "Coran Stow"
      }
    ],
    "author": "Coran Stow",
    "author_detail": {
      "name": "Coran Stow"
    }
  },
  "Medium": {
    "title": "Building a ChatGPT Plugin for Medium",
    "xmlUrl": "https://medium.engineering/feed",
    "htmlUrl": "https://medium.com/medium-eng",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.engineering/feed",
      "value": "Building a ChatGPT Plugin for Medium"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.engineering/building-a-chatgpt-plugin-for-medium-6813b59e4b24?source=rss----2817475205d3---4"
      }
    ],
    "link": "https://medium.engineering/building-a-chatgpt-plugin-for-medium-6813b59e4b24?source=rss----2817475205d3---4",
    "id": "https://medium.com/p/6813b59e4b24",
    "guidislink": false,
    "tags": [
      {
        "term": "go",
        "scheme": null,
        "label": null
      },
      {
        "term": "chatgpt-plugins",
        "scheme": null,
        "label": null
      },
      {
        "term": "medium",
        "scheme": null,
        "label": null
      },
      {
        "term": "artificial-intelligence",
        "scheme": null,
        "label": null
      },
      {
        "term": "chatgpt",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Thomas Ricouard"
      }
    ],
    "author": "Thomas Ricouard",
    "author_detail": {
      "name": "Thomas Ricouard"
    },
    "published": "Thu, 20 Apr 2023 13:50:58 GMT",
    "published_parsed": [
      2023,
      4,
      20,
      13,
      50,
      58,
      3,
      110,
      0
    ],
    "updated": "2023-04-20T13:50:58.171Z",
    "updated_parsed": [
      2023,
      4,
      20,
      13,
      50,
      58,
      3,
      110,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.engineering/feed",
        "value": "<h4>Technical exploration &amp; capabilities of our proof of\u00a0concept</h4><p>OpenAI recently announced the support of <a href=\"https://openai.com/blog/chatgpt-plugins\">plugins for ChatGPT</a>. Plugins are a groundbreaking feature for ChatGPT as they solve one of the platform\u2019s biggest problems, which is its lack of access to the internet and up to date content. ChatGPT was trained on a dataset from 2021 and does not have direct access to the internet. Plugins provide a solution to this limitation. Content platforms like Medium can expose their content to ChatGPT, based on the user prompt and installed plugins, ChatGPT can trigger the correct API of your plugins to retrieve a piece of content and do some manipulation on\u00a0it.</p><p>Plugin support for Chat GPT is still in private alpha, we got early access at Medium, so we could explore the possibilities for our content to be retrievable by\u00a0ChatGPT</p><p><strong>I want to point out this is a technical exploration, as of now, we don\u2019t yet have a plan about releasing this plugin.</strong><br />This article oriented around the technical demonstration side of things, how we built it, how a ChatGPT plugin work and what our plugin can\u00a0do.</p><h4>\ud83e\udd16 Our\u00a0setup</h4><p>Building a ChatGPT plugin is fairly simple, you need to expose a\u00a0.well-known/ai-plugin.json on your domain. It provides the basic information so that ChatGPT can understand that your domain support plugin, and can link the appropriate description, icons, link etc.. to the end user when installing the\u00a0plugin.</p><pre>{<br />&quot;schema_version&quot;: &quot;v1&quot;,<br />&quot;name_for_human&quot;: &quot;Medium plugin&quot;,<br />&quot;name_for_model&quot;: &quot;MediumGPTPlugin&quot;,<br />&quot;description_for_human&quot;: &quot;Plugin for accessing, browsing and extracting Medium content.&quot;,<br />&quot;description_for_model&quot;: &quot;Requests Medium posts, stories, to do manipulation and queries on the content.&quot;,<br />&quot;auth&quot;: {<br />&quot;type&quot;: &quot;none&quot;<br />},<br />&quot;api&quot;: {<br />&quot;type&quot;: &quot;openapi&quot;,<br />&quot;url&quot;: &quot;https://medium.com/_/gpt/openapi.yaml&quot;,<br />&quot;is_user_authenticated&quot;: false<br />},<br />&quot;logo_url&quot;: &quot;https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png&quot;,<br />&quot;contact_email&quot;: &quot;support@medium.com&quot;,<br />&quot;legal_info_url&quot;: &quot;https://policy.medium.com/medium-terms-of-service-9db0094a1e0f&quot;<br />}</pre><p>The most important part is the OpenAPI YAML file you\u2019ll expose, you can see ours in the url field in the code snippet above. This is a spec that will allow ChatGPT to understand your API. It use the <a href=\"https://swagger.io/specification/\">OpenAPI</a> specification, you can actually get started by writing your spec there and you can then export the spec into a server interface in various languages. There is also a linter over there so you can make sure your API spec is\u00a0correct.</p><p>On my side, I was actually writing the MediumGPT service in Go (most of our microservices are in Go at Medium), what I did to actually write the OpenAPI specification? I pasted my Go code into ChatGPT and asked it to output the OpenAPI specification. With(out) surprises, it was perfect, a few changes and it was basically ready.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*IKbVdOyyyn9c_esJz2AyQg.png\" /></figure><p>Why do we need a new service you might ask? We have an internal API in GraphQL, but ChatGPT can\u2019t really talk to a GraphQL API (maybe in the future, a well documented schema sound very powerful), so I needed to make a middleware in Go that expose parts of it as a standard REST\u00a0API.</p><p>The MediumGPT microservice is a simple middleware that convert hardcoded GraphQL queries and expose them in a REST API as JSON results. Straightforward, simple enough for a proof of concept. Also simple enough for me as it was the first time I was actually writing Go code for our backend\u00a0\ud83d\ude0e.</p><p>To give you an idea here is what one of our bridge function that serve the trending posts looks\u00a0like:</p><pre>type Post struct {<br /> ID              string `json:&quot;id&quot;`<br /> Title           string `json:&quot;title&quot;`<br /> // ... More Post object fields<br />}<br /><br />func (a *App) Trending(ctx context.Context) ([]*model.Post, error) {<br /> req := graphql.NewRequest(`<br />  query trending {<br />    ... GQL Query<br />  }<br /> `)<br /> var respData struct {<br />  Trending struct {<br />   Posts []*model.Post `json:&quot;posts&quot;`<br />  } `json:&quot;trending&quot;`<br /> }<br /> if err := a.client.Run(ctx, req, &amp;respData); err != nil {<br />  return nil, errors.Wrap(err, &quot;fetching trending from rito&quot;)<br /> }<br /><br /> return respData.Trending.Posts, nil<br />}</pre><p>And what the OpenAPI spec for this endpoint look\u00a0like:</p><pre>openapi: 3.0.3<br />paths:<br />  /v1/trending:<br />    get:<br />      summary: Get trending stories<br />      description: Returns a list of stories that are currently trending on Medium<br />      operationId: getTrendingStories<br />      responses:<br />        &quot;200&quot;:<br />          description: A list of trending stories<br />          content:<br />            application/json:<br />              schema:<br />                type: array<br />                items:<br />                  $ref: &quot;#/components/schemas/Story&quot;<br />components:<br />  schemas:<br />    Story:<br />      type: object<br />      properties:<br />        id:<br />          type: string<br />          description: The unique ID of the story<br />        title:<br />          type: string<br />          description: The title of the story</pre><p>The most important part is indeed your OpenAPI documentation. This is what ChatGPT will parse to understand what your plugin can do, what API to trigger and when. Your summary and description need to be simple, the OpenAI documentation is very clear about it in the \u201c<a href=\"https://platform.openai.com/docs/plugins/getting-started/writing-descriptions\">Writing description</a>\u201d part of their documentation.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*RwcoPtG6W1hua1FyIjj8Hg.png\" /></figure><p>You might feel like you would need to provide complexe description of your API with all the trigger possible etc\u2026 but this is not how ChatGPT will understand it. Description of your schema objects is also important, be simple &amp; clear about what each field is about, and ChatGPT will make sense of it altogether.</p><p>For the proof of concept we exposed 4 API to\u00a0ChatGPT</p><ul><li>Get a list of the trending posts. (Contain the post title, subtitle, author info, link, topics, etc\u2026 but not the actual content).</li><li>Query one specific post to get its full content (if not behind the paywall).</li><li>Query one topic to get trending, latest posts in this topics, alongside related\u00a0topics.</li><li>Search posts using a specific\u00a0query.</li></ul><p>Once all that was built and deployed, this is when the fun truly\u00a0began.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*msTyX97Hr6gHGKh38so1bg.png\" /><figcaption>Installing the MediumGPT plugin on ChatGPT interface</figcaption></figure><p>Let\u2019s go!</p><h4>\ud83d\udc7e Debugging the\u00a0plugin</h4><p>Now I hope you\u2019re ready to get your \ud83e\udde0 explode! Debugging the plugin was probably the best part for me. Why? Because I debugged the plugin directly on ChatGPT\u00a0itself.</p><p>First, let\u2019s ask ChatGPT if it understand our plugin API\u00a0surface</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5fKpA4aIAkGGfU8-lZJ2gQ.png\" /></figure><p>The answer is definitely yes, this is the stage where I first read what it understood of some API and went back to the documentation to adjust them a bit. It\u2019s important that you look at each API description and see if it\u2019s fit what you had in\u00a0mind.</p><p>One of the top question we had on our mind was \u201cDoes the user needs to specifically ask for Medium in their prompt in order for ChatGPT to trigger our\u00a0plugin\u201d</p><p>So let\u2019s ask\u00a0ChatGPT</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*O0rXabOthJ5_zkbXnSywug.png\" /></figure><p>The answer is Yes and also no. Right now we can run ChatGPT only with one plugin installed. So it\u2019s quite biased toward using the Medium plugin anyway. We can imagine that if multiple platforms expose stories / posts API, then adding Medium to the prompt will be important to target our plugin specifically.</p><p>For example I can definitely trigger it by asking what are the 3 trending articles, ChatGPT will trigger the Medium plugin and use the trending API correctly. And then give me the 3 first articles of the response.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*L2YaiYhZ4z6nL6di-UGwZQ.png\" /></figure><p>We even get nice little card at the end of the\u00a0message</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*J1I7NP5f2CEngAjPmnEYDA.png\" /></figure><p>Let\u2019s do one more test to see if it\u2019s really understand our API and schema. In the post model, we have one attribute, isLocked, and it\u2019s documented like\u00a0so</p><pre>isLocked:<br /> type: boolean<br /> description: Whether the story is locked behind the paywall</pre><p>Let\u2019s try some query to see if ChatGPT understand which posts are behind the paywall vs not behind the\u00a0paywall.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eKSllzkFwNDaAGshP24uew.png\" /></figure><p>And indeed it\u2019s right! Those 3 stories are not behind the\u00a0paywall.</p><p>Notice also how it doens\u2019t trigger a call to our plugin because it already have the previous response in its context\u00a0already.</p><p>Now, that we know that our plugin work correctly and that ChatGPT understand our API, we can start to make some more complexe (and useful) queries. I would also like to see if it can chain queries together to form a\u00a0result.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*B2-neClfQd5FBEGu6vvILQ.png\" /></figure><p>And it works! It correctly first fetch our trending API and then fetch the content of the first story. And then give me a summary of the\u00a0story.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vfOirVfAdJm1hcBCyP1bsg.png\" /></figure><p>Oh and you can actually read the full post\u00a0here</p><p><a href=\"https://medium.com/@health_bytes/the-gut-feeling-are-your-bacteria-calling-the-shots-on-your-mental-health-98e96f68f333\">The Gut Feeling: Are Your Bacteria Calling the Shots on Your Mental Health?</a></p><p>Let\u2019s get a little bit further and get some related posts because I want to dig further into this\u00a0topic</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SEVfopQ3eii86BtDAlNZKA.png\" /></figure><p>\ud83e\udd2f It triggered our search API with a not too bad query, and we get some related\u00a0results</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-PWZp3yFHv9eFkmjuVdORA.png\" /></figure><p>Another example of chaining queries, I\u2019ve asked to get the latest post in the topic of the story because I was interested in it. Sure enough it first fetched the topic and then fetched the content of the first post in\u00a0there.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*uSazDZlCELYhYk4N75f11g.png\" /></figure><p>You can also be much more natural in your question of course. Below I ask to get general opinion and a summary of a heated tech debate: SwiftUI VS\u00a0UIkit.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TDS8moXVQCQfIUNBx8nknA.png\" /></figure><p>It successfully extracted my query to make a search\u00a0query.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*r8-Tnugz1et7e96zYvBGKQ.png\" /></figure><p>And then went to fetch the content of a relevant post to make me a summary of that post with a link to the full story at the\u00a0bottom.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*wv4vFP-mTVkMmLbH43Tgpg.png\" /></figure><p>For a last example, I wanted to see if it could be smart about our API. You see we have one hole in the API. Our getTopic call require a topic ID to get the actual topics data. So I\u2019ve asked ChatGPT how it could get topic info without its\u00a0ID:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aTz6oiLW03nUtdNnllYaMg.png\" /></figure><p>And it correctly understood that you would have first to use the search API to get story related to Artificial Intelligence, and from there you can grab the topic ID from the post topic object to then to a query on our Topic API. I was a bit mind blown that it could come up with this chain of\u00a0thought.</p><p>For the practical use of this plugin, with some more API exposed to ChatGPT, the possibilities could be limitless. I see it as a natural query language for browsing and doing manipulation on any Medium content (once again, for content not behind the paywall). We\u2019re not yet at a stage where we know where we\u2019ll go with this plugin. But building and playing with it was a very fun experience.</p><p>I hope you enjoyed this article and feel free to reach out if you have any questions.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6813b59e4b24\" width=\"1\" /><hr /><p><a href=\"https://medium.engineering/building-a-chatgpt-plugin-for-medium-6813b59e4b24\">Building a ChatGPT Plugin for Medium</a> was originally published in <a href=\"https://medium.engineering\">Medium Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h4>Technical exploration &amp; capabilities of our proof of\u00a0concept</h4><p>OpenAI recently announced the support of <a href=\"https://openai.com/blog/chatgpt-plugins\">plugins for ChatGPT</a>. Plugins are a groundbreaking feature for ChatGPT as they solve one of the platform\u2019s biggest problems, which is its lack of access to the internet and up to date content. ChatGPT was trained on a dataset from 2021 and does not have direct access to the internet. Plugins provide a solution to this limitation. Content platforms like Medium can expose their content to ChatGPT, based on the user prompt and installed plugins, ChatGPT can trigger the correct API of your plugins to retrieve a piece of content and do some manipulation on\u00a0it.</p><p>Plugin support for Chat GPT is still in private alpha, we got early access at Medium, so we could explore the possibilities for our content to be retrievable by\u00a0ChatGPT</p><p><strong>I want to point out this is a technical exploration, as of now, we don\u2019t yet have a plan about releasing this plugin.</strong><br />This article oriented around the technical demonstration side of things, how we built it, how a ChatGPT plugin work and what our plugin can\u00a0do.</p><h4>\ud83e\udd16 Our\u00a0setup</h4><p>Building a ChatGPT plugin is fairly simple, you need to expose a\u00a0.well-known/ai-plugin.json on your domain. It provides the basic information so that ChatGPT can understand that your domain support plugin, and can link the appropriate description, icons, link etc.. to the end user when installing the\u00a0plugin.</p><pre>{<br />&quot;schema_version&quot;: &quot;v1&quot;,<br />&quot;name_for_human&quot;: &quot;Medium plugin&quot;,<br />&quot;name_for_model&quot;: &quot;MediumGPTPlugin&quot;,<br />&quot;description_for_human&quot;: &quot;Plugin for accessing, browsing and extracting Medium content.&quot;,<br />&quot;description_for_model&quot;: &quot;Requests Medium posts, stories, to do manipulation and queries on the content.&quot;,<br />&quot;auth&quot;: {<br />&quot;type&quot;: &quot;none&quot;<br />},<br />&quot;api&quot;: {<br />&quot;type&quot;: &quot;openapi&quot;,<br />&quot;url&quot;: &quot;https://medium.com/_/gpt/openapi.yaml&quot;,<br />&quot;is_user_authenticated&quot;: false<br />},<br />&quot;logo_url&quot;: &quot;https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png&quot;,<br />&quot;contact_email&quot;: &quot;support@medium.com&quot;,<br />&quot;legal_info_url&quot;: &quot;https://policy.medium.com/medium-terms-of-service-9db0094a1e0f&quot;<br />}</pre><p>The most important part is the OpenAPI YAML file you\u2019ll expose, you can see ours in the url field in the code snippet above. This is a spec that will allow ChatGPT to understand your API. It use the <a href=\"https://swagger.io/specification/\">OpenAPI</a> specification, you can actually get started by writing your spec there and you can then export the spec into a server interface in various languages. There is also a linter over there so you can make sure your API spec is\u00a0correct.</p><p>On my side, I was actually writing the MediumGPT service in Go (most of our microservices are in Go at Medium), what I did to actually write the OpenAPI specification? I pasted my Go code into ChatGPT and asked it to output the OpenAPI specification. With(out) surprises, it was perfect, a few changes and it was basically ready.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*IKbVdOyyyn9c_esJz2AyQg.png\" /></figure><p>Why do we need a new service you might ask? We have an internal API in GraphQL, but ChatGPT can\u2019t really talk to a GraphQL API (maybe in the future, a well documented schema sound very powerful), so I needed to make a middleware in Go that expose parts of it as a standard REST\u00a0API.</p><p>The MediumGPT microservice is a simple middleware that convert hardcoded GraphQL queries and expose them in a REST API as JSON results. Straightforward, simple enough for a proof of concept. Also simple enough for me as it was the first time I was actually writing Go code for our backend\u00a0\ud83d\ude0e.</p><p>To give you an idea here is what one of our bridge function that serve the trending posts looks\u00a0like:</p><pre>type Post struct {<br /> ID              string `json:&quot;id&quot;`<br /> Title           string `json:&quot;title&quot;`<br /> // ... More Post object fields<br />}<br /><br />func (a *App) Trending(ctx context.Context) ([]*model.Post, error) {<br /> req := graphql.NewRequest(`<br />  query trending {<br />    ... GQL Query<br />  }<br /> `)<br /> var respData struct {<br />  Trending struct {<br />   Posts []*model.Post `json:&quot;posts&quot;`<br />  } `json:&quot;trending&quot;`<br /> }<br /> if err := a.client.Run(ctx, req, &amp;respData); err != nil {<br />  return nil, errors.Wrap(err, &quot;fetching trending from rito&quot;)<br /> }<br /><br /> return respData.Trending.Posts, nil<br />}</pre><p>And what the OpenAPI spec for this endpoint look\u00a0like:</p><pre>openapi: 3.0.3<br />paths:<br />  /v1/trending:<br />    get:<br />      summary: Get trending stories<br />      description: Returns a list of stories that are currently trending on Medium<br />      operationId: getTrendingStories<br />      responses:<br />        &quot;200&quot;:<br />          description: A list of trending stories<br />          content:<br />            application/json:<br />              schema:<br />                type: array<br />                items:<br />                  $ref: &quot;#/components/schemas/Story&quot;<br />components:<br />  schemas:<br />    Story:<br />      type: object<br />      properties:<br />        id:<br />          type: string<br />          description: The unique ID of the story<br />        title:<br />          type: string<br />          description: The title of the story</pre><p>The most important part is indeed your OpenAPI documentation. This is what ChatGPT will parse to understand what your plugin can do, what API to trigger and when. Your summary and description need to be simple, the OpenAI documentation is very clear about it in the \u201c<a href=\"https://platform.openai.com/docs/plugins/getting-started/writing-descriptions\">Writing description</a>\u201d part of their documentation.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*RwcoPtG6W1hua1FyIjj8Hg.png\" /></figure><p>You might feel like you would need to provide complexe description of your API with all the trigger possible etc\u2026 but this is not how ChatGPT will understand it. Description of your schema objects is also important, be simple &amp; clear about what each field is about, and ChatGPT will make sense of it altogether.</p><p>For the proof of concept we exposed 4 API to\u00a0ChatGPT</p><ul><li>Get a list of the trending posts. (Contain the post title, subtitle, author info, link, topics, etc\u2026 but not the actual content).</li><li>Query one specific post to get its full content (if not behind the paywall).</li><li>Query one topic to get trending, latest posts in this topics, alongside related\u00a0topics.</li><li>Search posts using a specific\u00a0query.</li></ul><p>Once all that was built and deployed, this is when the fun truly\u00a0began.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*msTyX97Hr6gHGKh38so1bg.png\" /><figcaption>Installing the MediumGPT plugin on ChatGPT interface</figcaption></figure><p>Let\u2019s go!</p><h4>\ud83d\udc7e Debugging the\u00a0plugin</h4><p>Now I hope you\u2019re ready to get your \ud83e\udde0 explode! Debugging the plugin was probably the best part for me. Why? Because I debugged the plugin directly on ChatGPT\u00a0itself.</p><p>First, let\u2019s ask ChatGPT if it understand our plugin API\u00a0surface</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5fKpA4aIAkGGfU8-lZJ2gQ.png\" /></figure><p>The answer is definitely yes, this is the stage where I first read what it understood of some API and went back to the documentation to adjust them a bit. It\u2019s important that you look at each API description and see if it\u2019s fit what you had in\u00a0mind.</p><p>One of the top question we had on our mind was \u201cDoes the user needs to specifically ask for Medium in their prompt in order for ChatGPT to trigger our\u00a0plugin\u201d</p><p>So let\u2019s ask\u00a0ChatGPT</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*O0rXabOthJ5_zkbXnSywug.png\" /></figure><p>The answer is Yes and also no. Right now we can run ChatGPT only with one plugin installed. So it\u2019s quite biased toward using the Medium plugin anyway. We can imagine that if multiple platforms expose stories / posts API, then adding Medium to the prompt will be important to target our plugin specifically.</p><p>For example I can definitely trigger it by asking what are the 3 trending articles, ChatGPT will trigger the Medium plugin and use the trending API correctly. And then give me the 3 first articles of the response.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*L2YaiYhZ4z6nL6di-UGwZQ.png\" /></figure><p>We even get nice little card at the end of the\u00a0message</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*J1I7NP5f2CEngAjPmnEYDA.png\" /></figure><p>Let\u2019s do one more test to see if it\u2019s really understand our API and schema. In the post model, we have one attribute, isLocked, and it\u2019s documented like\u00a0so</p><pre>isLocked:<br /> type: boolean<br /> description: Whether the story is locked behind the paywall</pre><p>Let\u2019s try some query to see if ChatGPT understand which posts are behind the paywall vs not behind the\u00a0paywall.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eKSllzkFwNDaAGshP24uew.png\" /></figure><p>And indeed it\u2019s right! Those 3 stories are not behind the\u00a0paywall.</p><p>Notice also how it doens\u2019t trigger a call to our plugin because it already have the previous response in its context\u00a0already.</p><p>Now, that we know that our plugin work correctly and that ChatGPT understand our API, we can start to make some more complexe (and useful) queries. I would also like to see if it can chain queries together to form a\u00a0result.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*B2-neClfQd5FBEGu6vvILQ.png\" /></figure><p>And it works! It correctly first fetch our trending API and then fetch the content of the first story. And then give me a summary of the\u00a0story.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vfOirVfAdJm1hcBCyP1bsg.png\" /></figure><p>Oh and you can actually read the full post\u00a0here</p><p><a href=\"https://medium.com/@health_bytes/the-gut-feeling-are-your-bacteria-calling-the-shots-on-your-mental-health-98e96f68f333\">The Gut Feeling: Are Your Bacteria Calling the Shots on Your Mental Health?</a></p><p>Let\u2019s get a little bit further and get some related posts because I want to dig further into this\u00a0topic</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SEVfopQ3eii86BtDAlNZKA.png\" /></figure><p>\ud83e\udd2f It triggered our search API with a not too bad query, and we get some related\u00a0results</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-PWZp3yFHv9eFkmjuVdORA.png\" /></figure><p>Another example of chaining queries, I\u2019ve asked to get the latest post in the topic of the story because I was interested in it. Sure enough it first fetched the topic and then fetched the content of the first post in\u00a0there.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*uSazDZlCELYhYk4N75f11g.png\" /></figure><p>You can also be much more natural in your question of course. Below I ask to get general opinion and a summary of a heated tech debate: SwiftUI VS\u00a0UIkit.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TDS8moXVQCQfIUNBx8nknA.png\" /></figure><p>It successfully extracted my query to make a search\u00a0query.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*r8-Tnugz1et7e96zYvBGKQ.png\" /></figure><p>And then went to fetch the content of a relevant post to make me a summary of that post with a link to the full story at the\u00a0bottom.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*wv4vFP-mTVkMmLbH43Tgpg.png\" /></figure><p>For a last example, I wanted to see if it could be smart about our API. You see we have one hole in the API. Our getTopic call require a topic ID to get the actual topics data. So I\u2019ve asked ChatGPT how it could get topic info without its\u00a0ID:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aTz6oiLW03nUtdNnllYaMg.png\" /></figure><p>And it correctly understood that you would have first to use the search API to get story related to Artificial Intelligence, and from there you can grab the topic ID from the post topic object to then to a query on our Topic API. I was a bit mind blown that it could come up with this chain of\u00a0thought.</p><p>For the practical use of this plugin, with some more API exposed to ChatGPT, the possibilities could be limitless. I see it as a natural query language for browsing and doing manipulation on any Medium content (once again, for content not behind the paywall). We\u2019re not yet at a stage where we know where we\u2019ll go with this plugin. But building and playing with it was a very fun experience.</p><p>I hope you enjoyed this article and feel free to reach out if you have any questions.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6813b59e4b24\" width=\"1\" /><hr /><p><a href=\"https://medium.engineering/building-a-chatgpt-plugin-for-medium-6813b59e4b24\">Building a ChatGPT Plugin for Medium</a> was originally published in <a href=\"https://medium.engineering\">Medium Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "DigitalOcean": {
    "title": "Partnering with DigitalOcean: Unleashing Growth Opportunities for ISVs",
    "xmlUrl": "https://blog.digitalocean.com/rss/",
    "htmlUrl": "https://blog.digitalocean.com/tag/engineering/",
    "title_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.digitalocean.com/blog.atom",
      "value": "Partnering with DigitalOcean: Unleashing Growth Opportunities for ISVs"
    },
    "id": "tag:www.digitalocean.com,2005:/blog/partnering-with-digitalocean-isvs",
    "guidislink": true,
    "link": "https://www.digitalocean.com/blog/partnering-with-digitalocean-isvs",
    "links": [
      {
        "href": "https://www.digitalocean.com/blog/partnering-with-digitalocean-isvs",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "updated": "2023-12-20T15:58:23.243Z",
    "updated_parsed": [
      2023,
      12,
      20,
      15,
      58,
      23,
      2,
      354,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.digitalocean.com/blog.atom",
        "value": "<p>Independent Software Vendors (ISVs) develop specialized software applications that cater to various markets and industries. Unlike in-house development teams that build custom software tailored to specific organizational needs, ISVs must engineer products with a broader appeal, ensuring reliability and scalability across different environments and customer bases. As a result, ISVs face unique challenges in product development, deployment, and management. They require cloud infrastructure that is not only robust and secure but also flexible and efficient to accommodate the rapid pace of software iterations and the diverse needs of their clientele.</p>\n<p>DigitalOcean provides a fertile ground for ISVs to expand their operations and accelerate their growth trajectory by prioritizing simplicity, cost-effectiveness, and high performance. For instance, <a href=\"https://www.digitalocean.com/customers/pionect\">Pionect</a>, a software development agency, uses DigitalOcean to build and maintain robust, high-traffic e-commerce platforms for a diverse European clientele:</p>\n<p><em>\u201cAs a software builder, our ambition is always to write good code and host our code on good infrastructure so that we can give our clients the best possible experience. We are excited to be a DigitalOcean partner and look forward to continuing our work with them,\u201d says Egbert Wietses, the CEO of Pionect.</em></p>\n<p>This article explores how a partnership with DigitalOcean can address the specific needs of ISVs, fostering an environment where they can thrive by leveraging powerful cloud capabilities and resources.</p>\n<h2 id=\"key-benefits-of-partnering-with-digitalocean-for-isvs\"><a href=\"https://www.digitalocean.com/blog.atom#key-benefits-of-partnering-with-digitalocean-for-isvs\">Key benefits of partnering with DigitalOcean for ISVs</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#key-benefits-of-partnering-with-digitalocean-for-isvs\"></a></h2>\n<p>A range of ISVs use our platform to deploy, manage, and scale their applications easily, leveraging our cloud tools and services suite to heighten performance, improve customer satisfaction, and drive innovation. Here are the specific advantages our platform offers to ISVs:</p>\n<h3 id=\"1-cost-effective-cloud-infrastructure\"><a href=\"https://www.digitalocean.com/blog.atom#1-cost-effective-cloud-infrastructure\">1. Cost-effective cloud infrastructure</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#1-cost-effective-cloud-infrastructure\"></a></h3>\n<p>Partnering with DigitalOcean offers ISVs a cost-effective cloud infrastructure with a <a href=\"https://www.digitalocean.com/pricing\">transparent pricing model</a>. This starkly contrasts the often opaque and unpredictable billing practices of larger cloud providers; it\u2019s not uncommon for companies to experience <a href=\"https://www.digitalocean.com/resources/article/avoid-aws-bill-shock\">AWS bill shock</a>. DigitalOcean\u2019s straightforward cost structure eliminates surprises, with predictable billing ensuring ISVs can budget and plan confidently.</p>\n<p>Our platform\u2019s <a href=\"https://www.digitalocean.com/pricing/calculator\">pricing calculator</a> enables software vendors to forecast expenses by simulating different usage scenarios and service configurations before deployment. This transparency in pricing is complemented by a range of scalable services that allow ISVs to start small and grow their resources without exponential increases in costs. As a result, ISVs can optimize their investment in cloud services, directing funds toward innovation and growth rather than unexpected infrastructure expenses.</p>\n<h3 id=\"2-cloud-solutions-to-scale-with-simplicity\"><a href=\"https://www.digitalocean.com/blog.atom#2-cloud-solutions-to-scale-with-simplicity\">2. Cloud solutions to scale with simplicity</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#2-cloud-solutions-to-scale-with-simplicity\"></a></h3>\n<p>At the core of <a href=\"https://www.digitalocean.com/products\">DigitalOcean\u2019s product offerings</a> is a commitment to simplicity, allowing ISVs to scale their applications effortlessly. The intuitive setup of <a href=\"https://www.digitalocean.com/products/droplets\">Droplets</a> enables quick scaling of virtual machines without complex configurations. <a href=\"https://www.digitalocean.com/products/managed-databases\">Managed Databases</a> simplify the process of scaling database storage and performance, and they come with the convenience of a managed service to reduce administrative burden. DigitalOcean <a href=\"https://www.digitalocean.com/products/kubernetes\">Kubernetes</a> allows for easy orchestration of containerized applications, automating deployment and scaling with a developer-friendly approach. With <a href=\"https://www.digitalocean.com/products/load-balancer\">Load Balancers</a>, ISVs can distribute traffic across their infrastructure to maintain performance, all managed through a straightforward interface that prioritizes ease of use.</p>\n<p>This focus on simplicity ensures that ISVs can scale their solutions with minimal effort, freeing them to focus on their core product development. <a href=\"https://www.digitalocean.com/customers/nixa\">Nixa</a>, a Canadian web development agency catering to businesses and nonprofits, leverages DigitalOcean\u2019s predictable pricing and straightforward cloud tools to deliver cost-effective and efficient software, websites, and applications.</p>\n<p><em>\u201cDigitalOcean is intuitive and powerful. Using hyperscalers setting up something like a load balancer can be complex, but using DigitalOcean setting it up is very simple\u2013you just click and add it. We can keep our team of DevOps and SysAdmins lean to manage our 200+ customers because of the ease of use of DigitalOcean,\u201d says the team at Nixa.</em></p>\n<h3 id=\"3-expanded-market-reach\"><a href=\"https://www.digitalocean.com/blog.atom#3-expanded-market-reach\">3. Expanded market reach</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#3-expanded-market-reach\"></a></h3>\n<p>By partnering with DigitalOcean, ISVs connect to a broad and ever-expanding customer base spanning many industries and locations. This partnership allows ISVs to showcase their solutions to over <a href=\"https://www.digitalocean.com/blog/ten-reasons-startups-should-adopt-digitalocean\">630,000+ SMBs, startups, and mid-market businesses</a> already using DigitalOcean\u2019s infrastructure, bypassing the initial barrier to entry of building trust.</p>\n<p>This integration into DigitalOcean\u2019s ecosystem allows for organic brand recognition and user adoption growth. ISVs can effectively co-market to a ready-made audience looking for complementary tools and services. The increased visibility from this direct access can lead to enhanced market penetration, driving revenue and market share for your brand.</p>\n<h3 id=\"4-access-to-digitalocean-s-marketplace\"><a href=\"https://www.digitalocean.com/blog.atom#4-access-to-digitalocean-s-marketplace\">4. Access to DigitalOcean\u2019s Marketplace</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#4-access-to-digitalocean-s-marketplace\"></a></h3>\n<p><a href=\"https://marketplace.digitalocean.com/\">DigitalOcean\u2019s Marketplace</a> is a software innovation hub, attracting a dedicated audience of developers and small to mid-sized businesses searching for cutting-edge tools. By featuring their solutions in the Marketplace, ISVs benefit from increased visibility within a community that values and actively seeks out new technology. This exposure is a gateway to a broader audience, offering ISVs the potential to amplify their customer base significantly.</p>\n<p>Unlike other crowded marketplaces, DigitalOcean\u2019s Marketplace offers ISVs a distinct advantage. The platform not only facilitates the discovery of ISV solutions but also streamlines the process of co-selling to this ready-made market. A presence in DigitalOcean\u2019s Marketplace can be a powerful driver for ISV growth, potentially boosting revenue and expanding market share through strategic positioning and easy access to a large pool of prospective customers. <a href=\"https://marketplace.digitalocean.com/vendors\">Learn how to become a vendor</a> and list on the DigitalOcean Marketplace.</p>\n<h3 id=\"5-premier-partnership-experience-for-isvs\"><a href=\"https://www.digitalocean.com/blog.atom#5-premier-partnership-experience-for-isvs\">5. Premier partnership experience for ISVs</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#5-premier-partnership-experience-for-isvs\"></a></h3>\n<p>DigitalOcean is committed to the success of ISVs, offering them a supportive and beneficial partnership. When ISVs team up with DigitalOcean, they receive tailored support to help them navigate and make the most of the platform\u2019s features. This partnership is enriched with co-marketing initiatives, allowing ISVs to boost their visibility.</p>\n<p>They also receive access to a wealth of resources to speed up their development cycle and go-to-market efforts. DigitalOcean provides ISVs with a practical and supportive experience focused on their growth and success in the cloud ecosystem.</p>\n<h2 id=\"partnering-with-digitalocean-is-a-strategic-decision-that-empowers-isvs\"><a href=\"https://www.digitalocean.com/blog.atom#partnering-with-digitalocean-is-a-strategic-decision-that-empowers-isvs\">Partnering with DigitalOcean is a strategic decision that empowers ISVs</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#partnering-with-digitalocean-is-a-strategic-decision-that-empowers-isvs\"></a></h2>\n<p>Striving to keep the technological overhead to a minimum, DigitalOcean offers an accessible cloud solution that aligns with the needs of developers focused on their craft:</p>\n<p><em>\u201cWe want to focus on creating beautiful software, and hyperscalers are often too complex for what our customers need. DigitalOcean makes it simple for us to manage a lot of customers under one account,\u201d says Egbert Wietses, the CEO of Pionect.</em></p>\n<p>Here\u2019s what ISVs can expect with DigitalOcean:</p>\n<ul>\n<li>\n<p>Build software solutions cost-effectively across dev, test, and production environments</p>\n</li>\n<li>\n<p>Reach a global audience of over 630,000 SMBs, startups, and midmarket customers</p>\n</li>\n<li>\n<p>Showcase your solutions in DigitalOcean\u2019s Marketplace, gaining visibility and attracting potential customers</p>\n</li>\n<li>\n<p>Operate in an uncrowded marketplace, maximizing your exposure to potential customers</p>\n</li>\n<li>\n<p>Enjoy a premier partnership experience, receiving dedicated support, co-marketing opportunities, and access to resources</p>\n</li>\n</ul>\n<p>We invite ISVs relying on multicloud portfolios or those unsure about their expansion strategy, to request a personalized assessment from our cloud experts in support of their cloud journey <a href=\"https://www.digitalocean.com/landing/cut-your-cloud-bill\">here.</a></p>\n<p>Join the DigitalOcean Partner Pod Program today and elevate your business through a collaborative partnership designed for mutual growth. With support at every level of our company, we\u2019re committed to a long-term relationship that helps us achieve more, together. <a href=\"https://www.digitalocean.com/channel-partners\">Become a DigitalOcean partner</a> and unleash your growth potential!</p>"
      }
    ],
    "summary": "<p>Independent Software Vendors (ISVs) develop specialized software applications that cater to various markets and industries. Unlike in-house development teams that build custom software tailored to specific organizational needs, ISVs must engineer products with a broader appeal, ensuring reliability and scalability across different environments and customer bases. As a result, ISVs face unique challenges in product development, deployment, and management. They require cloud infrastructure that is not only robust and secure but also flexible and efficient to accommodate the rapid pace of software iterations and the diverse needs of their clientele.</p>\n<p>DigitalOcean provides a fertile ground for ISVs to expand their operations and accelerate their growth trajectory by prioritizing simplicity, cost-effectiveness, and high performance. For instance, <a href=\"https://www.digitalocean.com/customers/pionect\">Pionect</a>, a software development agency, uses DigitalOcean to build and maintain robust, high-traffic e-commerce platforms for a diverse European clientele:</p>\n<p><em>\u201cAs a software builder, our ambition is always to write good code and host our code on good infrastructure so that we can give our clients the best possible experience. We are excited to be a DigitalOcean partner and look forward to continuing our work with them,\u201d says Egbert Wietses, the CEO of Pionect.</em></p>\n<p>This article explores how a partnership with DigitalOcean can address the specific needs of ISVs, fostering an environment where they can thrive by leveraging powerful cloud capabilities and resources.</p>\n<h2 id=\"key-benefits-of-partnering-with-digitalocean-for-isvs\"><a href=\"https://www.digitalocean.com/blog.atom#key-benefits-of-partnering-with-digitalocean-for-isvs\">Key benefits of partnering with DigitalOcean for ISVs</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#key-benefits-of-partnering-with-digitalocean-for-isvs\"></a></h2>\n<p>A range of ISVs use our platform to deploy, manage, and scale their applications easily, leveraging our cloud tools and services suite to heighten performance, improve customer satisfaction, and drive innovation. Here are the specific advantages our platform offers to ISVs:</p>\n<h3 id=\"1-cost-effective-cloud-infrastructure\"><a href=\"https://www.digitalocean.com/blog.atom#1-cost-effective-cloud-infrastructure\">1. Cost-effective cloud infrastructure</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#1-cost-effective-cloud-infrastructure\"></a></h3>\n<p>Partnering with DigitalOcean offers ISVs a cost-effective cloud infrastructure with a <a href=\"https://www.digitalocean.com/pricing\">transparent pricing model</a>. This starkly contrasts the often opaque and unpredictable billing practices of larger cloud providers; it\u2019s not uncommon for companies to experience <a href=\"https://www.digitalocean.com/resources/article/avoid-aws-bill-shock\">AWS bill shock</a>. DigitalOcean\u2019s straightforward cost structure eliminates surprises, with predictable billing ensuring ISVs can budget and plan confidently.</p>\n<p>Our platform\u2019s <a href=\"https://www.digitalocean.com/pricing/calculator\">pricing calculator</a> enables software vendors to forecast expenses by simulating different usage scenarios and service configurations before deployment. This transparency in pricing is complemented by a range of scalable services that allow ISVs to start small and grow their resources without exponential increases in costs. As a result, ISVs can optimize their investment in cloud services, directing funds toward innovation and growth rather than unexpected infrastructure expenses.</p>\n<h3 id=\"2-cloud-solutions-to-scale-with-simplicity\"><a href=\"https://www.digitalocean.com/blog.atom#2-cloud-solutions-to-scale-with-simplicity\">2. Cloud solutions to scale with simplicity</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#2-cloud-solutions-to-scale-with-simplicity\"></a></h3>\n<p>At the core of <a href=\"https://www.digitalocean.com/products\">DigitalOcean\u2019s product offerings</a> is a commitment to simplicity, allowing ISVs to scale their applications effortlessly. The intuitive setup of <a href=\"https://www.digitalocean.com/products/droplets\">Droplets</a> enables quick scaling of virtual machines without complex configurations. <a href=\"https://www.digitalocean.com/products/managed-databases\">Managed Databases</a> simplify the process of scaling database storage and performance, and they come with the convenience of a managed service to reduce administrative burden. DigitalOcean <a href=\"https://www.digitalocean.com/products/kubernetes\">Kubernetes</a> allows for easy orchestration of containerized applications, automating deployment and scaling with a developer-friendly approach. With <a href=\"https://www.digitalocean.com/products/load-balancer\">Load Balancers</a>, ISVs can distribute traffic across their infrastructure to maintain performance, all managed through a straightforward interface that prioritizes ease of use.</p>\n<p>This focus on simplicity ensures that ISVs can scale their solutions with minimal effort, freeing them to focus on their core product development. <a href=\"https://www.digitalocean.com/customers/nixa\">Nixa</a>, a Canadian web development agency catering to businesses and nonprofits, leverages DigitalOcean\u2019s predictable pricing and straightforward cloud tools to deliver cost-effective and efficient software, websites, and applications.</p>\n<p><em>\u201cDigitalOcean is intuitive and powerful. Using hyperscalers setting up something like a load balancer can be complex, but using DigitalOcean setting it up is very simple\u2013you just click and add it. We can keep our team of DevOps and SysAdmins lean to manage our 200+ customers because of the ease of use of DigitalOcean,\u201d says the team at Nixa.</em></p>\n<h3 id=\"3-expanded-market-reach\"><a href=\"https://www.digitalocean.com/blog.atom#3-expanded-market-reach\">3. Expanded market reach</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#3-expanded-market-reach\"></a></h3>\n<p>By partnering with DigitalOcean, ISVs connect to a broad and ever-expanding customer base spanning many industries and locations. This partnership allows ISVs to showcase their solutions to over <a href=\"https://www.digitalocean.com/blog/ten-reasons-startups-should-adopt-digitalocean\">630,000+ SMBs, startups, and mid-market businesses</a> already using DigitalOcean\u2019s infrastructure, bypassing the initial barrier to entry of building trust.</p>\n<p>This integration into DigitalOcean\u2019s ecosystem allows for organic brand recognition and user adoption growth. ISVs can effectively co-market to a ready-made audience looking for complementary tools and services. The increased visibility from this direct access can lead to enhanced market penetration, driving revenue and market share for your brand.</p>\n<h3 id=\"4-access-to-digitalocean-s-marketplace\"><a href=\"https://www.digitalocean.com/blog.atom#4-access-to-digitalocean-s-marketplace\">4. Access to DigitalOcean\u2019s Marketplace</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#4-access-to-digitalocean-s-marketplace\"></a></h3>\n<p><a href=\"https://marketplace.digitalocean.com/\">DigitalOcean\u2019s Marketplace</a> is a software innovation hub, attracting a dedicated audience of developers and small to mid-sized businesses searching for cutting-edge tools. By featuring their solutions in the Marketplace, ISVs benefit from increased visibility within a community that values and actively seeks out new technology. This exposure is a gateway to a broader audience, offering ISVs the potential to amplify their customer base significantly.</p>\n<p>Unlike other crowded marketplaces, DigitalOcean\u2019s Marketplace offers ISVs a distinct advantage. The platform not only facilitates the discovery of ISV solutions but also streamlines the process of co-selling to this ready-made market. A presence in DigitalOcean\u2019s Marketplace can be a powerful driver for ISV growth, potentially boosting revenue and expanding market share through strategic positioning and easy access to a large pool of prospective customers. <a href=\"https://marketplace.digitalocean.com/vendors\">Learn how to become a vendor</a> and list on the DigitalOcean Marketplace.</p>\n<h3 id=\"5-premier-partnership-experience-for-isvs\"><a href=\"https://www.digitalocean.com/blog.atom#5-premier-partnership-experience-for-isvs\">5. Premier partnership experience for ISVs</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#5-premier-partnership-experience-for-isvs\"></a></h3>\n<p>DigitalOcean is committed to the success of ISVs, offering them a supportive and beneficial partnership. When ISVs team up with DigitalOcean, they receive tailored support to help them navigate and make the most of the platform\u2019s features. This partnership is enriched with co-marketing initiatives, allowing ISVs to boost their visibility.</p>\n<p>They also receive access to a wealth of resources to speed up their development cycle and go-to-market efforts. DigitalOcean provides ISVs with a practical and supportive experience focused on their growth and success in the cloud ecosystem.</p>\n<h2 id=\"partnering-with-digitalocean-is-a-strategic-decision-that-empowers-isvs\"><a href=\"https://www.digitalocean.com/blog.atom#partnering-with-digitalocean-is-a-strategic-decision-that-empowers-isvs\">Partnering with DigitalOcean is a strategic decision that empowers ISVs</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#partnering-with-digitalocean-is-a-strategic-decision-that-empowers-isvs\"></a></h2>\n<p>Striving to keep the technological overhead to a minimum, DigitalOcean offers an accessible cloud solution that aligns with the needs of developers focused on their craft:</p>\n<p><em>\u201cWe want to focus on creating beautiful software, and hyperscalers are often too complex for what our customers need. DigitalOcean makes it simple for us to manage a lot of customers under one account,\u201d says Egbert Wietses, the CEO of Pionect.</em></p>\n<p>Here\u2019s what ISVs can expect with DigitalOcean:</p>\n<ul>\n<li>\n<p>Build software solutions cost-effectively across dev, test, and production environments</p>\n</li>\n<li>\n<p>Reach a global audience of over 630,000 SMBs, startups, and midmarket customers</p>\n</li>\n<li>\n<p>Showcase your solutions in DigitalOcean\u2019s Marketplace, gaining visibility and attracting potential customers</p>\n</li>\n<li>\n<p>Operate in an uncrowded marketplace, maximizing your exposure to potential customers</p>\n</li>\n<li>\n<p>Enjoy a premier partnership experience, receiving dedicated support, co-marketing opportunities, and access to resources</p>\n</li>\n</ul>\n<p>We invite ISVs relying on multicloud portfolios or those unsure about their expansion strategy, to request a personalized assessment from our cloud experts in support of their cloud journey <a href=\"https://www.digitalocean.com/landing/cut-your-cloud-bill\">here.</a></p>\n<p>Join the DigitalOcean Partner Pod Program today and elevate your business through a collaborative partnership designed for mutual growth. With support at every level of our company, we\u2019re committed to a long-term relationship that helps us achieve more, together. <a href=\"https://www.digitalocean.com/channel-partners\">Become a DigitalOcean partner</a> and unleash your growth potential!</p>",
    "authors": [
      {
        "name": "fer-oliveira"
      }
    ],
    "author_detail": {
      "name": "fer-oliveira"
    },
    "author": "fer-oliveira",
    "tags": [
      {
        "term": "cloud-education",
        "scheme": null,
        "label": "cloud-education"
      }
    ],
    "published": "2023-12-20T15:58:23.243Z",
    "published_parsed": [
      2023,
      12,
      20,
      15,
      58,
      23,
      2,
      354,
      0
    ]
  },
  "Sift Science": {
    "title": "Sift\u2019s innovative journey: 40 patents and counting in the fight against evolving online fraud through AI, machine learning, and Workflows",
    "xmlUrl": "https://blog.siftscience.com/feed/",
    "htmlUrl": "https://blog.siftscience.com/?category=Engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.sift.com/feed/",
      "value": "Sift\u2019s innovative journey: 40 patents and counting in the fight against evolving online fraud through AI, machine learning, and Workflows"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.sift.com/sifts-innovative-journey-40-patents-and-counting/?utm_source=rss&utm_medium=rss&utm_campaign=sifts-innovative-journey-40-patents-and-counting"
      }
    ],
    "link": "https://blog.sift.com/sifts-innovative-journey-40-patents-and-counting/?utm_source=rss&utm_medium=rss&utm_campaign=sifts-innovative-journey-40-patents-and-counting",
    "comments": "https://blog.sift.com/sifts-innovative-journey-40-patents-and-counting/#respond",
    "authors": [
      {
        "name": "Neeraj Gupta"
      }
    ],
    "author": "Neeraj Gupta",
    "author_detail": {
      "name": "Neeraj Gupta"
    },
    "published": "Fri, 12 Jan 2024 17:00:00 +0000",
    "published_parsed": [
      2024,
      1,
      12,
      17,
      0,
      0,
      4,
      12,
      0
    ],
    "tags": [
      {
        "term": "Fraud",
        "scheme": null,
        "label": null
      },
      {
        "term": "Technology",
        "scheme": null,
        "label": null
      },
      {
        "term": "AI",
        "scheme": null,
        "label": null
      },
      {
        "term": "artificial intelligence",
        "scheme": null,
        "label": null
      },
      {
        "term": "fraud prevention",
        "scheme": null,
        "label": null
      },
      {
        "term": "machine learning",
        "scheme": null,
        "label": null
      },
      {
        "term": "sift patents",
        "scheme": null,
        "label": null
      },
      {
        "term": "workflows",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://blog.sift.com/?p=5488",
    "guidislink": false,
    "summary": "<p>Sift has been granted 40 patents by the United States Patent and Trademark Office, protecting digital businesses and their customers from evolving fraud.</p>\n<p>The post <a href=\"https://blog.sift.com/sifts-innovative-journey-40-patents-and-counting/\">Sift\u2019s innovative journey: 40 patents and counting in the fight against evolving online fraud through AI, machine learning, and Workflows</a> appeared first on <a href=\"https://blog.sift.com\">Sift Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.sift.com/feed/",
      "value": "<p>Sift has been granted 40 patents by the United States Patent and Trademark Office, protecting digital businesses and their customers from evolving fraud.</p>\n<p>The post <a href=\"https://blog.sift.com/sifts-innovative-journey-40-patents-and-counting/\">Sift\u2019s innovative journey: 40 patents and counting in the fight against evolving online fraud through AI, machine learning, and Workflows</a> appeared first on <a href=\"https://blog.sift.com\">Sift Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.sift.com/feed/",
        "value": "<p>The landscape of online fraud has undergone a profound transformation since the early days of the internet. Initially, simple rule-based systems were sufficient to thwart most fraud attempts. However, as fraudsters evolved their tactics, relying solely on rule-based systems became inadequate. Techniques such as card testing, fraudulent gift card purchases, and sophisticated attack vectors like account takeovers and user-generated content scams emerged, challenging the security of consumers and businesses alike, casting a shadow of distrust over the internet.</p>\n\n\n\n<p>In 2011, Sift embarked on a mission to combat innovative and ever-evolving fraud patterns by harnessing the power of machine learning. What began as a focus on payment fraud has evolved into a comprehensive approach covering the entire consumer journey. Our commitment to constant innovation stems from the evolving nature of fraud, driving us to protect our customers&#8217; revenue streams and empower them to seize growth opportunities.</p>\n\n\n\n<p>Long before machine learning became a buzzword, Sift embraced the technology\u2019s potential. Beyond the hype, the authenticity of a company&#8217;s machine learning claims lies in its intellectual property and patent portfolio, which serves as the backbone of its product offerings.</p>\n\n\n\n<p>As we step into 2024, I am thrilled to announce a significant milestone in our innovation journey. Sift has been granted or allowed an impressive 40 patents by the United States Patent and Trademark Office (USPTO), with several more patents currently under evaluation.</p>\n\n\n\n<p>In 2023, Sift directed key investments towards our core machine learning and AI innovations, notably enhancing our powerful Workflows capabilities. <a href=\"https://blog.sift.com/sift-workflow-best-practices/\">Sift Workflows</a>, a no-code engine, empowers fraud teams to automate business processes and make real-time risk decisions. This critical component of our offering allows teams of all sizes to manage digital risk with transparency, control, and unparalleled efficiency.</p>\n\n\n\n<p>Building on the success of Workflows, we introduced <a href=\"https://blog.sift.com/introducing-workflow-simulation/\">Workflow Simulation</a>. This feature provides risk teams with on-demand, drill-down insights to guide automation improvements based on historical traffic and fraud patterns.</p>\n\n\n\n<p>Our most recent patents are centered around revolutionary AI, machine learning, and automation technologies, including:</p>\n\n\n\n<ul>\n<li><strong>Connected Components for Botnet Detection</strong>: Identifying coordinated bot attacks by analyzing connections between fraudulent accounts and activities.</li>\n\n\n\n<li><strong>Anomaly Detection in Risk Models</strong>: Explaining shifts and drifts in customer risk models to identify issues and take corrective actions.</li>\n\n\n\n<li><strong>Real-time Bot Detection and Intelligence</strong>: Generating unique signatures for detecting and mitigating bot threats in real-time.</li>\n</ul>\n\n\n\n<p>Sift remains committed to a customer-focused approach to innovation. Our vision is to provide the most accurate fraud prevention platform in the industry, and the 40 patents granted or allowed by the USPTO underscore our dedication to achieving this goal. As the online landscape continues to evolve, Sift stands at the forefront, empowering businesses to navigate the complex terrain of digital fraud with confidence.</p>\n\n\n\n<p>Explore the full list of Sift&#8217;s patents at <a href=\"https://sift.com/intellectual-property\">https://sift.com/intellectual-property</a>.</p>\n<p>The post <a href=\"https://blog.sift.com/sifts-innovative-journey-40-patents-and-counting/\">Sift\u2019s innovative journey: 40 patents and counting in the fight against evolving online fraud through AI, machine learning, and Workflows</a> appeared first on <a href=\"https://blog.sift.com\">Sift Blog</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://blog.sift.com/sifts-innovative-journey-40-patents-and-counting/feed/",
    "slash_comments": "0",
    "post-id": "5488"
  },
  "Spotify": {
    "title": "Q&A with the Maintainers of the Spotify FOSS Fund",
    "xmlUrl": "https://labs.spotify.com/feed/",
    "htmlUrl": "https://labs.spotify.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.atspotify.com/feed/",
      "value": "Q&A with the Maintainers of the Spotify FOSS Fund"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.atspotify.com/2024/01/qa-with-the-maintainers-of-the-spotify-foss-fund/"
      }
    ],
    "link": "https://engineering.atspotify.com/2024/01/qa-with-the-maintainers-of-the-spotify-foss-fund/",
    "authors": [
      {
        "name": "alexandrawei"
      }
    ],
    "author": "alexandrawei",
    "author_detail": {
      "name": "alexandrawei"
    },
    "published": "Thu, 04 Jan 2024 15:16:52 +0000",
    "published_parsed": [
      2024,
      1,
      4,
      15,
      16,
      52,
      3,
      4,
      0
    ],
    "tags": [
      {
        "term": "Open Source",
        "scheme": null,
        "label": null
      },
      {
        "term": "People",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering leadership",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.atspotify.com/?p=6812",
    "guidislink": false,
    "summary": "<p>TL;DR Let\u2019s cap the year by putting a spotlight on some of the valuable work people outside of Spotify are [...]</p>\n<p>The post <a href=\"https://engineering.atspotify.com/2024/01/qa-with-the-maintainers-of-the-spotify-foss-fund/\">Q&amp;A with the Maintainers of the Spotify FOSS Fund</a> appeared first on <a href=\"https://engineering.atspotify.com\">Spotify Engineering</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.atspotify.com/feed/",
      "value": "<p>TL;DR Let\u2019s cap the year by putting a spotlight on some of the valuable work people outside of Spotify are [...]</p>\n<p>The post <a href=\"https://engineering.atspotify.com/2024/01/qa-with-the-maintainers-of-the-spotify-foss-fund/\">Q&amp;A with the Maintainers of the Spotify FOSS Fund</a> appeared first on <a href=\"https://engineering.atspotify.com\">Spotify Engineering</a>.</p>"
    }
  },
  "Databricks": {
    "title": "Manufacturing Insights: Calculating Streaming Integrals on Low-Latency Sensor Data",
    "xmlUrl": "https://databricks.com/feed",
    "htmlUrl": "https://databricks.com/blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.databricks.com/feed",
      "value": "Manufacturing Insights: Calculating Streaming Integrals on Low-Latency Sensor Data"
    },
    "published": "Wed, 10 Jan 2024 10:18:28 GMT",
    "published_parsed": [
      2024,
      1,
      10,
      10,
      18,
      28,
      2,
      10,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.databricks.com/blog/manufacturing-insights-calculating-streaming-integrals-low-latency-sensor-data"
      }
    ],
    "link": "https://www.databricks.com/blog/manufacturing-insights-calculating-streaming-integrals-low-latency-sensor-data",
    "summary": "<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Data engineers rely on math and statistics to coax insights out of complex, noisy data. Among the most important domains is calculus, which...</div>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.databricks.com/feed",
      "value": "<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Data engineers rely on math and statistics to coax insights out of complex, noisy data. Among the most important domains is calculus, which...</div>"
    },
    "tags": [
      {
        "term": "Industries",
        "scheme": null,
        "label": null
      },
      {
        "term": "Manufacturing",
        "scheme": null,
        "label": null
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.databricks.com/feed",
        "value": "<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Data engineers rely on math and statistics to coax insights out of complex, noisy data. Among the most important domains is calculus, which...</div>"
      }
    ],
    "id": "https://www.databricks.com/node/8052",
    "guidislink": false
  },
  "Mozilla Automation Team": {
    "title": "Digging into regressions",
    "xmlUrl": "http://planet.mozilla.org/ateam/atom.xml",
    "htmlUrl": "https://planet.mozilla.org/ateam/",
    "id": "http://elvis314.wordpress.com/?p=1875",
    "guidislink": true,
    "link": "https://elvis314.wordpress.com/2019/08/23/digging-into-regressions/",
    "links": [
      {
        "href": "https://elvis314.wordpress.com/2019/08/23/digging-into-regressions/",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "title_detail": {
      "type": "text/plain",
      "language": "en",
      "base": "https://planet.mozilla.org/ateam/atom.xml",
      "value": "Digging into regressions"
    },
    "summary": "Whenever a patch is landed on autoland, it will run many builds and tests to make sure there are no regressions.\u00a0 Unfortunately many times we find a regression and 99% of the time backout the changes so they can be \u2026 <a href=\"https://elvis314.wordpress.com/2019/08/23/digging-into-regressions/\">Continue reading <span class=\"meta-nav\">\u2192</span></a>",
    "summary_detail": {
      "type": "application/xhtml+xml",
      "language": "en",
      "base": "https://planet.mozilla.org/ateam/atom.xml",
      "value": "Whenever a patch is landed on autoland, it will run many builds and tests to make sure there are no regressions.\u00a0 Unfortunately many times we find a regression and 99% of the time backout the changes so they can be \u2026 <a href=\"https://elvis314.wordpress.com/2019/08/23/digging-into-regressions/\">Continue reading <span class=\"meta-nav\">\u2192</span></a>"
    },
    "content": [
      {
        "type": "application/xhtml+xml",
        "language": "en",
        "base": "https://planet.mozilla.org/ateam/atom.xml",
        "value": "<p>Whenever a patch is landed on <a href=\"https://treeherder.mozilla.org/#/jobs?repo=autoland\">autoland</a>, it will run many builds and tests to make sure there are no regressions.\u00a0 Unfortunately many times we find a regression and 99% of the time backout the changes so they can be fixed.\u00a0 This work is done by the Sheriff team at Mozilla- they monitor the trees and when something is wrong, they work to fix it (sometimes by a quick fix, usually by a backout).\u00a0 A quick fact, there were 1228 regressions in H1 (January-June) 2019.</p>\n<p>My goal in writing is not to recommend change, but instead to start conversations and figure out what data we should be collecting in order to have data driven discussions.\u00a0 Only then would I expect that recommendations for changes would come forth.</p>\n<p>What got me started in looking at regressions was trying to answer a question: <em><strong>\u201cHow many regressions did X catch?\u201d</strong></em>\u00a0 This alone is a tough question, instead I think the question should be <em><strong>\u201cIf we were not running X, how many regressions would our end users see?\u201d\u00a0 </strong></em>This is a much different question and has two distinct parts:</p>\n<ul>\n<li><em>Unique Regressions</em>: Only look at regressions found that only X found, not found on both X and Y</li>\n<li><em>Product Fixes</em>: did the regression result in changing code that we ship to users? (i.e. not editing the test)</li>\n<li><em>Final Fix</em>: many times a patch [set] lands and is backed out multiple times, in this case do we look at each time it was backed out, or only the change from initial landing to final landing?</li>\n</ul>\n<p>These can be more difficult to answer.\u00a0 For example, Product Fixes- maybe by editing the test case we are preventing a regression in the future because the test is more accurate.</p>\n<p>In addition we need to understand how accurate the data we are using is.\u00a0 As the sheriffs do a great job, they are human and humans make judgement calls.\u00a0 In this case once a job is marked as \u201cfixed_by_commit\u201d, then we cannot go back in and edit it, so a typo or bad data will result in incorrect data.\u00a0 To add to it, often times multiple patches are backed out at the same time, so is it correct to say that changes from bug A and bug B should be considered?</p>\n<p>This year I have looked at this data many times to answer:</p>\n<ul>\n<li>how many unique regressions did <a href=\"https://groups.google.com/forum/#!searchin/mozilla.dev.platform/linux32|sort:date/mozilla.dev.platform/82cCNuWcXCk/fA_gxdOTCwAJ\">linux32</a> catch?</li>\n<li>how many unique regressions did <a href=\"https://groups.google.com/forum/#!searchin/mozilla.dev.platform/opt$20pgo%7Csort:date/mozilla.dev.platform/0dYGajwXCBc/zzgeaJeqBQAJ\">opt tests catch vs pgo</a>?</li>\n<li>how many regressions did <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1572820\">web-platform-tests</a> catch?\n<ul>\n<li><em>In H1 \u2013 90 regressions, 17 product changes</em></li>\n</ul>\n</li>\n</ul>\n<p>This data is important to harvest because if we were to turn off a set of jobs or run them as tier-2 we would end up missing regressions.\u00a0 But if all we miss is editing manifests to disable failing tests, then we are getting no value from the test jobs- so it is important to look at what the regression outcome was.</p>\n<p>In fact every time I did this I would run an <a href=\"https://github.com/mozilla/active-data-recipes\">active-data-recipe</a> (<a href=\"https://github.com/jmaher/active-data-recipes/tree/hacking\">fbc recipe in my repo</a>) and have a large pile of data I needed to sort through and manually check.\u00a0 I spent some time every day for a few weeks looking at regressions and now I have looked at 700 (bugs/changesets).\u00a0 I found that in manually checking regressions, the end results fell into buckets:</p>\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" dir=\"ltr\">\n<colgroup>\n<col width=\"136\" />\n<col width=\"100\" />\n<col width=\"100\" /></colgroup>\n<tbody>\n<tr>\n<td>test</td>\n<td>196</td>\n<td>28.00%</td>\n</tr>\n<tr>\n<td>product</td>\n<td>272</td>\n<td>38.86%</td>\n</tr>\n<tr>\n<td>manifest</td>\n<td>134</td>\n<td>19.14%</td>\n</tr>\n<tr>\n<td>unknown</td>\n<td>48</td>\n<td>6.86%</td>\n</tr>\n<tr>\n<td>backout</td>\n<td>27</td>\n<td>3.86%</td>\n</tr>\n<tr>\n<td>infra</td>\n<td>23</td>\n<td>3.29%</td>\n</tr>\n</tbody>\n</table>\n<p>Keep in mind that many of the changes which end up in mozilla-central are not only product bugs, but infrastructure bugs, test editing, etc.</p>\n<p>After looking at many of these bugs, I found that ~80% of the time things are straightforward (single patch [set] landed, backed out once, relanded with clear comments).\u00a0 Data I would like to have easily available via a query:</p>\n<ul>\n<li>Files that are changed between backout and relanding (even if it is a new patch).</li>\n<li>A reason as part of phabricator that when we reland, it is required to have a few pre canned fields</li>\n</ul>\n<p>Ideally this set of data would exist for not only backouts, but for anything that is landed to fix a regression (linting, build, manifest, typo).</p>"
      }
    ],
    "updated": "2019-08-23T20:53:47Z",
    "updated_parsed": [
      2019,
      8,
      23,
      20,
      53,
      47,
      4,
      235,
      0
    ],
    "published": "2019-08-23T20:53:47Z",
    "published_parsed": [
      2019,
      8,
      23,
      20,
      53,
      47,
      4,
      235,
      0
    ],
    "tags": [
      {
        "term": "data",
        "scheme": null,
        "label": null
      },
      {
        "term": "testdev",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "elvis314"
      }
    ],
    "author_detail": {
      "name": "elvis314"
    },
    "author": "elvis314",
    "source": {
      "id": "https://elvis314.wordpress.com",
      "guidislink": true,
      "link": "https://elvis314.wordpress.com",
      "logo": "https://s0.wp.com/i/buttonw-com.png",
      "links": [
        {
          "href": "https://elvis314.wordpress.com/feed/",
          "rel": "self",
          "type": "application/rss+xml"
        },
        {
          "href": "https://elvis314.wordpress.com",
          "rel": "alternate",
          "type": "text/html"
        },
        {
          "href": "https://elvis314.wordpress.com/osd.xml",
          "rel": "search",
          "title": "3.1415926535897932384626433...",
          "type": "application/opensearchdescription+xml"
        },
        {
          "href": "https://elvis314.wordpress.com/?pushpress=hub",
          "rel": "hub",
          "type": "text/html"
        }
      ],
      "subtitle": "PI, pie, and py",
      "subtitle_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://planet.mozilla.org/ateam/atom.xml",
        "value": "PI, pie, and py"
      },
      "title": "3.1415926535897932384626433\u2026",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://planet.mozilla.org/ateam/atom.xml",
        "value": "3.1415926535897932384626433\u2026"
      },
      "updated": "2019-08-23T21:28:01Z",
      "updated_parsed": [
        2019,
        8,
        23,
        21,
        28,
        1,
        4,
        235,
        0
      ]
    }
  },
  "VersionEye": {
    "title": "Adding Python Support",
    "xmlUrl": "https://blog.versioneye.com/feed/",
    "htmlUrl": "https://blog.versioneye.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.versioneye.com/feed/",
      "value": "Adding Python Support"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.versioneye.com/2021/04/20/adding-python-support/"
      }
    ],
    "link": "https://blog.versioneye.com/2021/04/20/adding-python-support/",
    "comments": "https://blog.versioneye.com/2021/04/20/adding-python-support/#respond",
    "authors": [
      {
        "name": "versioneye"
      }
    ],
    "author": "versioneye",
    "author_detail": {
      "name": "versioneye"
    },
    "published": "Tue, 20 Apr 2021 09:46:48 +0000",
    "published_parsed": [
      2021,
      4,
      20,
      9,
      46,
      48,
      1,
      110,
      0
    ],
    "tags": [
      {
        "term": "Continuous Updating",
        "scheme": null,
        "label": null
      },
      {
        "term": "AppSec",
        "scheme": null,
        "label": null
      },
      {
        "term": "OpenSource",
        "scheme": null,
        "label": null
      },
      {
        "term": "PIP",
        "scheme": null,
        "label": null
      },
      {
        "term": "python",
        "scheme": null,
        "label": null
      }
    ],
    "id": "http://blog.versioneye.com/?p=4488",
    "guidislink": false,
    "summary": "VersionEye 2.0 started with only 3 languages. Ruby, NodeJS and PHP. Now Python was added as well! VersionEye supports the package manger PIP. You can simply upload your requirements.txt file to get a BOM (Bill of Materials). By default the &#8216;requirements.txt&#8217; file contains only the direct dependencies. I would recommend to use Pips freeze feature &#8230; <a class=\"more-link\" href=\"https://blog.versioneye.com/2021/04/20/adding-python-support/\">Continue reading <span class=\"screen-reader-text\">Adding Python Support</span></a>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.versioneye.com/feed/",
      "value": "VersionEye 2.0 started with only 3 languages. Ruby, NodeJS and PHP. Now Python was added as well! VersionEye supports the package manger PIP. You can simply upload your requirements.txt file to get a BOM (Bill of Materials). By default the &#8216;requirements.txt&#8217; file contains only the direct dependencies. I would recommend to use Pips freeze feature &#8230; <a class=\"more-link\" href=\"https://blog.versioneye.com/2021/04/20/adding-python-support/\">Continue reading <span class=\"screen-reader-text\">Adding Python Support</span></a>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.versioneye.com/feed/",
        "value": "<p><a href=\"https://www.versioneye.com/\" rel=\"noreferrer noopener\" target=\"_blank\">VersionEye 2.0</a> started with only 3 languages. Ruby, NodeJS and PHP. Now Python was added as well! </p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><a href=\"https://versioneye.files.wordpress.com/2021/04/python.png\"><img alt=\"\" class=\"wp-image-4491\" height=\"100\" src=\"https://versioneye.files.wordpress.com/2021/04/python.png?w=100\" width=\"100\" /></a></figure></div>\n\n\n\n<p>VersionEye supports the package manger <a href=\"https://pypi.org/project/pip/\" rel=\"noreferrer noopener\" target=\"_blank\">PIP</a>. You can simply upload your requirements.txt file to get a BOM (Bill of Materials). By default the &#8216;requirements.txt&#8217; file contains only the direct dependencies. I would recommend to use Pips freeze feature to lock down all transitive dependencies. That can be achieved with this command: </p>\n\n\n\n<pre class=\"wp-block-code\"><code>python -m pip freeze &gt; frozen-requirements.txt</code></pre>\n\n\n\n<p>That command will take all direct dependencies from the <code>requirements.txt</code> file, resolve all transitive dependencies and create a new file <code>frozen-requirements.txt</code> which contains ALL (direct &amp; transitive) dependencies with fixed versions. That&#8217;s much better then the pure <code>requirements.txt</code> file because the frozen version contains all dependencies which are shipped to production. That contains ALL dependencies which are necessary to run the application. </p>\n\n\n\n<p>Here is an example for a Python VersionEye scan: </p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://versioneye.files.wordpress.com/2021/04/screenshot-2021-04-20-at-11.35.47.png\"><img alt=\"\" class=\"wp-image-4494\" height=\"684\" src=\"https://versioneye.files.wordpress.com/2021/04/screenshot-2021-04-20-at-11.35.47.png?w=1024\" width=\"1024\" /></a></figure>\n\n\n\n<p>Try it out and let me know how you like it! Would love to hear your feedback. <br /></p>\n\n\n\n<p>If you don&#8217;t have an account yet, signup with this promotion code &#8220;<a href=\"https://www.versioneye.com/en/signups/new?promo_code=Ve2Python\" rel=\"noreferrer noopener\" target=\"_blank\">Ve2Python</a>&#8220;. That code is valid until 4th of June and gives you a 50% discount on the monthly subscription! </p>"
      }
    ],
    "wfw_commentrss": "https://blog.versioneye.com/2021/04/20/adding-python-support/feed/",
    "slash_comments": "0",
    "media_content": [
      {
        "url": "https://2.gravatar.com/avatar/2b00b4f53aaed85b3a213bfd1ca1441b36a8960c6f4656519edc99bb43bdbac0?s=96&d=identicon&r=G",
        "medium": "image"
      },
      {
        "url": "https://versioneye.files.wordpress.com/2021/04/python.png?w=100",
        "medium": "image"
      },
      {
        "url": "https://versioneye.files.wordpress.com/2021/04/screenshot-2021-04-20-at-11.35.47.png?w=1024",
        "medium": "image"
      }
    ]
  },
  "Vena Solutions": {
    "title": "The dreaded enjoyable technical interview",
    "xmlUrl": "https://engineering.vena.io/rss/",
    "htmlUrl": "https://engineering.vena.io/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.vena.io/feed/",
      "value": "The dreaded enjoyable technical interview"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.vena.io/the-dreaded-enjoyable-technical-interview/"
      }
    ],
    "link": "https://engineering.vena.io/the-dreaded-enjoyable-technical-interview/",
    "authors": [
      {
        "name": "Saiid Douaihy"
      }
    ],
    "author": "Saiid Douaihy",
    "author_detail": {
      "name": "Saiid Douaihy"
    },
    "published": "Mon, 13 Jun 2022 16:01:15 +0000",
    "published_parsed": [
      2022,
      6,
      13,
      16,
      1,
      15,
      0,
      164,
      0
    ],
    "tags": [
      {
        "term": "Vena Engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "culture",
        "scheme": null,
        "label": null
      },
      {
        "term": "interview",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.vena.io/?p=235",
    "guidislink": false,
    "summary": "<p>It sounds like an oxymoron; give me a chance to explain. Like almost everybody who has ever worked in software development, I have had my fair share of bad technical interviews. Almost everybody agrees they are necessary. I say <em>almost </em>&#8230;</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.vena.io/feed/",
      "value": "<p>It sounds like an oxymoron; give me a chance to explain. Like almost everybody who has ever worked in software development, I have had my fair share of bad technical interviews. Almost everybody agrees they are necessary. I say <em>almost </em>&#8230;</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.vena.io/feed/",
        "value": "<p>It sounds like an oxymoron; give me a chance to explain. Like almost everybody who has ever worked in software development, I have had my fair share of bad technical interviews. Almost everybody agrees they are necessary. I say <em>almost </em>&hellip;</p>"
      }
    ],
    "post-id": "235"
  },
  "Salesforce": {
    "title": "Moving on from the Ant Migration Tool to sf CLI (v2)",
    "xmlUrl": "https://developer.salesforce.com/blogs/feed",
    "htmlUrl": "https://developer.salesforce.com/blogs/engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://developer.salesforce.com/blogs/feed",
      "value": "Moving on from the Ant Migration Tool to sf CLI (v2)"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://developer.salesforce.com/blogs/2024/01/moving-on-from-the-ant-migration-tool-to-sf-cli-v2.html"
      }
    ],
    "link": "https://developer.salesforce.com/blogs/2024/01/moving-on-from-the-ant-migration-tool-to-sf-cli-v2.html",
    "comments": "https://developer.salesforce.com/blogs/2024/01/moving-on-from-the-ant-migration-tool-to-sf-cli-v2.html#respond",
    "published": "Thu, 11 Jan 2024 16:00:26 +0000",
    "published_parsed": [
      2024,
      1,
      11,
      16,
      0,
      26,
      3,
      11,
      0
    ],
    "authors": [
      {
        "name": "Neha Ahlawat"
      }
    ],
    "author": "Neha Ahlawat",
    "author_detail": {
      "name": "Neha Ahlawat"
    },
    "tags": [
      {
        "term": "App Development",
        "scheme": null,
        "label": null
      },
      {
        "term": "Tutorials",
        "scheme": null,
        "label": null
      },
      {
        "term": "ant",
        "scheme": null,
        "label": null
      },
      {
        "term": "ANT migration tool",
        "scheme": null,
        "label": null
      },
      {
        "term": "cli",
        "scheme": null,
        "label": null
      },
      {
        "term": "Salesforce CLI",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://developer.salesforce.com/blogs/?p=200768",
    "guidislink": false,
    "summary": "<p>It is time to move on from the Ant Migration Tool to the latest and officially-supported developer experience using the Salesforce CLI.</p>\n<p>The post <a href=\"https://developer.salesforce.com/blogs/2024/01/moving-on-from-the-ant-migration-tool-to-sf-cli-v2.html\">Moving on from the Ant Migration Tool to sf CLI (v2)</a> appeared first on <a href=\"https://developer.salesforce.com/blogs\">Salesforce Developers Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://developer.salesforce.com/blogs/feed",
      "value": "<p>It is time to move on from the Ant Migration Tool to the latest and officially-supported developer experience using the Salesforce CLI.</p>\n<p>The post <a href=\"https://developer.salesforce.com/blogs/2024/01/moving-on-from-the-ant-migration-tool-to-sf-cli-v2.html\">Moving on from the Ant Migration Tool to sf CLI (v2)</a> appeared first on <a href=\"https://developer.salesforce.com/blogs\">Salesforce Developers Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://developer.salesforce.com/blogs/feed",
        "value": "<p><span>With the Spring \u201924 release, Salesforce is retiring the </span><span> </span><a href=\"https://developer.salesforce.com/docs/atlas.en-us.daas.meta/daas/meta_development.htm\">Ant Migration Tool</a>, a Java/Ant-based command-line utility for moving Salesforce metadata between a local directory and a Salesforce org. The retirement of the Ant Migration Tool makes the <a href=\"https://developer.salesforce.com/tools/sfdxcli\">Salesforce CLI</a> the primary tool for using the Salesforce metadata services.</p>\n<p><span>The </span>Salesforce CLI is<span> the flagship development tool in our ecosystem; it facilitates building, testing, deployment, and several other application development tasks for Salesforce Developers. Our strategy is to move toward a single tool that is frequently updated, maintained, and supported by Salesforce and avoid the redundancy of two tools that do the same thing. Hence, the decision to retire the Ant Migration Tool was made based on the Salesforce CLI\u2019s adoption, maturity, and capabilities to provide command-line support for a wide range of Salesforce functionalities beyond metadata management. </span></p>\n<p><span>In this blog post, you will learn about the implications of using the retired Ant Migration Tool and how to set up and use the Salesforce CLI, the preferred Salesforce standard, to automate your development workflows.</span></p>\n<h2>Implications of using the retired Ant Migration Tool</h2>\n<p><span>The Ant Migration Tool will continue to function for future API versions, but it will not be updated with any new functionality. However, if you continue to use it, you do run the risk of not being able to access any new functionality that was added to the API or any new metadata types released after API v59.0. Furthermore, if a major change is made to the backend APIs, then without any active maintenance and support, the tool may even be rendered broken. In this case, you would no longer be able to execute services from it, and your CI/CD pipelines would also break.</span></p>\n<h2>Simplify your workflow with Salesforce CLI</h2>\n<p><a href=\"https://developer.salesforce.com/docs/atlas.en-us.sfdx_dev.meta/sfdx_dev/sfdx_dev_intro.htm\">The Salesforce CLI</a> is a powerful and versatile open-source tool that can automate not just metadata service-related tasks but also various actions all across the Salesforce Platform to build a truly modern CI/CD pipeline. With command-line support via built-in Visual Studio Code plugins for several products across the platform, it does much more than the Ant Migration Tool can provide.</p>\n<p><a href=\"https://developer.salesforce.com/blogs/2022/12/big-improvements-coming-to-the-salesforce-cli\">The latest CLI developments</a> with the release of <code>sf</code> (v2) have made it extremely easy to set up and use the tool. In fact, if you\u2019re using <a href=\"https://developer.salesforce.com/tools/vscode/en/codebuilder/about\">Salesforce Code Builder</a>, you don\u2019t even need to set up the Salesforce CLI. Code Builder is a web-based integrated development environment that has all the power and flexibility of Visual Studio Code, Salesforce Extensions for VS Code, and the Salesforce CLI in your web browser. Regardless of your expertise level, whether you are an admin or a developer, you can easily experience the capabilities of the Salesforce Platform and its customizability via the Salesforce CLI using Code Builder.</p>\n<p>You can authenticate and connect multiple orgs (scratch orgs, sandboxes, or production orgs) to your IDE via the CLI and seamlessly switch between them as you run commands. Using the concept of aliases, you don\u2019t need to edit the properties file several times to connect to different orgs and run the metadata operations between them. Using the CLI, you have the flexibility of creating scratch orgs mimicking your production org on the go and connecting several orgs to the IDE. You also can enable pilot and beta features in the scratch orgs as you create them to develop new features or test them.</p>\n<p>The <code>project</code> commands can be used to execute Metadata API operations from the Salesforce CLI. One of the highlights of the several options in this command is <code>project generate manifest</code>. Yes, you read it right. You can now generate the <code>package.xml</code> file by using a command without having to type it out.</p>\n<p>Therefore, we recommend the <code>sf</code> CLI over the Ant Migration Tool due to wider support for commands and products, the option to connect multiple orgs simultaneously to the IDE, easier ways to authenticate orgs without the need to store credentials on file, and support for team collaboration via source tracking of metadata.</p>\n<h2>Development workflow with the Salesforce CLI</h2>\n<h3>Installation and authentication</h3>\n<p>Download the CLI and set it up as per instructions on the<a href=\"https://developer.salesforce.com/docs/atlas.en-us.sfdx_setup.meta/sfdx_setup/sfdx_setup_install_cli.htm#sfdx_setup_install_cli_macos\"> Salesforce CLI Setup </a>page. Once it is ready to go, verify that you have the latest version by running the <code>sf version</code> command.</p>\n<pre>sf version\n<span>@salesforce/cli/2.21.8 darwin-x64 node-v20.10.0</span></pre>\n<h3>Org management</h3>\n<p>You can choose either a scratch org-based or sandbox-based development model based on your business setup, and the Salesforce CLI coherently supports both. Once you have logged in to your dev hub, you can create a new scratch org for development and testing using the <code>org create scratch</code> command. To connect sandboxes or any other orgs, you can authenticate and log in to them using the <code>org login web</code> command and add aliases to easily identify and switch between these different types of orgs using the <code>alias</code> commands. Furthermore, you can set the shape of your org by enabling permissions via scratch org features in the scratch org definition file when creating the org.</p>\n<pre><span>sf org login web </span><span>--</span><span>set</span><span>-</span><span>default</span><span>-</span><span>dev</span><span>-</span><span>hub </span><span>--</span><span>alias</span><span> dev</span><span>-</span><span>hub</span>\nsf org create scratch --edition developer --alias my-scratch-org\n<span>sf org open --target-org my-scratch-org</span></pre>\n<p>\n\t\t\t  <span class=\"postimagessection_specify alignnone wp-image-200769\">\n\t\t\t    <img alt=\"Org login and scratch org creation using sf CLI\" class=\"postimages\" height=\"373\" src=\"https://d259t2jj6zp7qm.cloudfront.net/images/20240111083939/Screenshot-2023-12-21-at-1.10.58%E2%80%AFPM-1.png\" width=\"906\" />\n\t\t\t  </span>\n\t\t\t</p>\n<h3>Generate application manifest</h3>\n<p>You can use the <code>project generate manifest</code> command to create the <code>package.xml</code> manifest file to be able to use Metadata API operations.</p>\n<pre><span>sf project generate manifest --source-dir myapp</span></pre>\n<p>\n\t\t\t  <span class=\"postimagessection_specify alignnone wp-image-200770\">\n\t\t\t    <img alt=\"Generate manifest using sf CLI\" class=\"postimages\" height=\"81\" src=\"https://d259t2jj6zp7qm.cloudfront.net/images/20240111084026/Screenshot-2023-12-21-at-5.53.59%E2%80%AFPM.png\" width=\"905\" />\n\t\t\t  </span>\n\t\t\t</p>\n<h3>Metadata management</h3>\n<p>Once you have the application manifest, you can use the plethora of <code>project</code> commands to move metadata between orgs. You can retrieve, deploy, validate deploy, quickly deploy a recently validated deploy zip, cancel a deploy, etc. You can use all of the operations that you could with the Ant Migration Tool and more. Note that if your org supports source tracking, then <code>project deploy start</code> and <code>project retrieve start</code> commands track only the changed metadata instead of all metadata.</p>\n<p>Preview changes in your org by using the <code>retrieve preview</code> option, and then retrieve them to your local org with the <code>retrieve start</code> option.</p>\n<pre><span>sf project retrieve preview </span><span>--</span><span>target</span><span>-</span><span>org </span><span>my</span><span>-</span><span>scratch</span><span>-</span><span>org</span>\n<span>sf project retrieve </span>start<span> </span><span>--target-org my-scratch-org</span></pre>\n<p>\n\t\t\t  <span class=\"postimagessection_specify alignnone wp-image-200771\">\n\t\t\t    <img alt=\"Retrieve using sf CLI\" class=\"postimages\" height=\"387\" src=\"https://d259t2jj6zp7qm.cloudfront.net/images/20240111084203/Screenshot-2023-12-21-at-6.05.16%E2%80%AFPM-1.png\" width=\"904\" />\n\t\t\t  </span>\n\t\t\t</p>\n<p>Similarly, preview changes in your local org using the <code>deploy preview</code> option, and deploy them to the org using the <code>deploy start</code> option.</p>\n<pre><span>sf project deploy preview </span><span>--</span><span>target</span><span>-</span><span>org </span><span>my</span><span>-</span><span>scratch</span><span>-</span><span>org\nsf project deploy start --target-org my-scratch-org</span></pre>\n<p>\n\t\t\t  <span class=\"postimagessection_specify alignnone wp-image-200772\">\n\t\t\t    <img alt=\"Deploy using sf CLI\" class=\"postimages\" height=\"333\" src=\"https://d259t2jj6zp7qm.cloudfront.net/images/20240111084330/Screenshot-2023-12-21-at-6.16.19%E2%80%AFPM-1.png\" width=\"908\" />\n\t\t\t  </span>\n\t\t\t</p>\n<h2>Conclusion</h2>\n<p>The Ant Migration Tool, as useful as it might have been when it was first released, has run its course. It is time to move on to the modern, latest, and officially supported developer experience using the Salesforce CLI. As you explore the latest version of the Salesforce CLI, <code>sf</code> (v2), remember to report any bugs, feature requests, or unexpected behaviors via the<span> </span><a href=\"https://github.com/forcedotcom/cli/issues\">CLI GitHub repository</a><span>. </span>We look forward to receiving your feedback and appreciate your ongoing support.</p>\n<h2>Resources</h2>\n<ul>\n<li><a href=\"https://help.salesforce.com/s/articleView?id=release-notes.rn_deployment_ant_migration_tool_eol.htm&amp;release=248&amp;type=5\">Spring \u201924 Release Notes</a></li>\n<li><a href=\"https://developer.salesforce.com/docs/atlas.en-us.sfdx_setup.meta/sfdx_setup/sfdx_setup_intro.htm\">Salesforce CLI Setup</a> and <a href=\"https://developer.salesforce.com/docs/atlas.en-us.sfdx_cli_reference.meta/sfdx_cli_reference/cli_reference_project_commands_unified.htm\">command reference for Metadata API</a></li>\n<li>Video: <a href=\"https://www.youtube.com/watch?v=WpdL8bAlIbY&amp;ab_channel=SalesforceDevelopers\">codeLive &#8211; How to work with sf CLI (v2)</a></li>\n<li>Video: <a href=\"https://www.youtube.com/watch?v=2EwZY5UX7fo&amp;ab_channel=SalesforceDevelopers\">Exploring the SF CLI</a></li>\n<li>Blog post: <a href=\"https://developer.salesforce.com/blogs/2022/03/demystifying-the-salesforce-metadata-api\">Demystifying the Salesforce Metadata API</a></li>\n<li>Blog post: The Salesforce CLI sf v2 Is Here (<a href=\"https://developer.salesforce.com/blogs/2023/07/salesforce-cli-sf-v2-is-here\">Part 1</a> &amp; <a href=\"https://developer.salesforce.com/blogs/2023/07/the-salesforce-cli-sf-v2-is-here-part-2\">Part 2</a>)</li>\n</ul>\n<h2>About the Author</h2>\n<p><b>Neha Ahlawat</b> is a Senior Product Manager in the Platform Services organization at Salesforce, where she is focused on the product areas of Metadata API, source tracking, and change sets. Follow her on <a href=\"https://twitter.com/ahlawat_neha\">X</a> and <a href=\"https://www.linkedin.com/in/ahlawatneha/\">LinkedIn</a>.</p>\n<p>The post <a href=\"https://developer.salesforce.com/blogs/2024/01/moving-on-from-the-ant-migration-tool-to-sf-cli-v2.html\">Moving on from the Ant Migration Tool to sf CLI (v2)</a> appeared first on <a href=\"https://developer.salesforce.com/blogs\">Salesforce Developers Blog</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://developer.salesforce.com/blogs/2024/01/moving-on-from-the-ant-migration-tool-to-sf-cli-v2.html/feed",
    "slash_comments": "0",
    "media_thumbnail": [
      {
        "url": "https://d259t2jj6zp7qm.cloudfront.net/images/20240111084600/Codey-1.png"
      }
    ],
    "href": "",
    "media_content": [
      {
        "url": "https://d259t2jj6zp7qm.cloudfront.net/images/20240111084600/Codey-1.png",
        "medium": "image"
      }
    ]
  },
  "Square": {
    "title": "The Corner Round-up June 2020",
    "xmlUrl": "https://medium.com/feed/square-corner-blog",
    "htmlUrl": "https://corner.squareup.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/square-corner-blog",
      "value": "The Corner Round-up June 2020"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/square-corner-blog/the-corner-round-up-june-2020-5f0eaa1d341e?source=rss----3650599ae4e2---4"
      }
    ],
    "link": "https://medium.com/square-corner-blog/the-corner-round-up-june-2020-5f0eaa1d341e?source=rss----3650599ae4e2---4",
    "id": "https://medium.com/p/5f0eaa1d341e",
    "guidislink": false,
    "authors": [
      {
        "name": "Richard Moot"
      }
    ],
    "author": "Richard Moot",
    "author_detail": {
      "name": "Richard Moot"
    },
    "published": "Tue, 30 Jun 2020 22:59:20 GMT",
    "published_parsed": [
      2020,
      6,
      30,
      22,
      59,
      20,
      1,
      182,
      0
    ],
    "updated": "2020-06-30T22:59:20.026Z",
    "updated_parsed": [
      2020,
      6,
      30,
      22,
      59,
      20,
      1,
      182,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/square-corner-blog",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*8tPJ-hZqW1ygCpzx\" /></figure><p>In order to keep some of the followers still here on Medium, we wanted to provide a quick recap on some of the things that have been published over at The Corner Blog\u2019s new home <a href=\"https://developer.squareup.com/blog\">https://developer.squareup.com/blog</a> (in case you didn\u2019t know that already). We\u2019ll just be doing a quick summary of each new thing, but you can check out each topic in detail over at our new\u00a0home.</p><p><a href=\"https://developer.squareup.com/blog/manage-team-data-from-any-platform-with-square-team-api\">Manage Team Data from Any Platform with Square Team API</a></p><p>We released a new Team API to allow managing Team data from any platform. You can track and edit large volumes of team member data automatically and synchronize data with any third-party platform in real\u00a0time!</p><p><a href=\"https://developer.squareup.com/blog/introducing-hephaestus\">Introducing Hephaestus</a></p><p>In order to make dependency injection with Dagger 2 easier, we had created Hephaestus. It is an open source compiler plugin that automatically merges Dagger modules and component interfaces to make development more enjoyable.</p><p><a href=\"https://developer.squareup.com/blog/api-explorer-moves-to-general-availability\">API Explorer Moves to General Availability</a></p><p>The Square Developer team also transitioned the API Explorer from Beta to GA, bringing with it a lot of improvements to make testing Square APIs much more enjoyable and\u00a0easy.</p><p><a href=\"https://developer.squareup.com/blog/kubernetes-pod-security-policies\">Kubernetes - Pod Security Policies</a></p><p>The cloud team at Square also did a write-up that provides some useful guidance and examples for handling Pod Security in Kubernetes.</p><p><a href=\"https://developer.squareup.com/blog/reward-customers-wherever-they-shop-with-loyalty-api-and-customers-api\">Reward Customers Wherever They Shop with Loyalty API and Customers API</a></p><p>Additionally, Square Loyalty now has an API to make providing rewards to customers on other platforms. Using the Customers API and Loyalty API in combination can allow any developer to create a great rewards system, no matter where their customers are.</p><p><a href=\"https://developer.squareup.com/blog/announcing-square-terminal-api-beta\">Announcing Square Terminal API Beta</a></p><p>Finally, we also released Terminal API, which lets you programmatically take payments using Square Terminal. This API allows developers to connect <a href=\"https://squareup.com/us/en/hardware/terminal\">Square Terminal</a>, an all-in-one card payments device, to their custom-built POS systems, no matter which platforms or operating systems they\u2019re developed on.</p><p>Now that isn\u2019t <em>everything</em> that we\u2019ve published since you\u2019ve last heard from us, but should give some good highlights of what has been going on at Square. If you want to learn more or stay up-to-date on everything we\u2019re working on, make sure to check out the blog at <a href=\"https://developer.squareup.com/blog\">https://developer.squareup.com/blog</a> or follow up on twitter at <a href=\"https://twitter.com/squaredev\">https://twitter.com/squaredev</a>!</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5f0eaa1d341e\" width=\"1\" /><hr /><p><a href=\"https://medium.com/square-corner-blog/the-corner-round-up-june-2020-5f0eaa1d341e\">The Corner Round-up June 2020</a> was originally published in <a href=\"https://medium.com/square-corner-blog\">Square Corner Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*8tPJ-hZqW1ygCpzx\" /></figure><p>In order to keep some of the followers still here on Medium, we wanted to provide a quick recap on some of the things that have been published over at The Corner Blog\u2019s new home <a href=\"https://developer.squareup.com/blog\">https://developer.squareup.com/blog</a> (in case you didn\u2019t know that already). We\u2019ll just be doing a quick summary of each new thing, but you can check out each topic in detail over at our new\u00a0home.</p><p><a href=\"https://developer.squareup.com/blog/manage-team-data-from-any-platform-with-square-team-api\">Manage Team Data from Any Platform with Square Team API</a></p><p>We released a new Team API to allow managing Team data from any platform. You can track and edit large volumes of team member data automatically and synchronize data with any third-party platform in real\u00a0time!</p><p><a href=\"https://developer.squareup.com/blog/introducing-hephaestus\">Introducing Hephaestus</a></p><p>In order to make dependency injection with Dagger 2 easier, we had created Hephaestus. It is an open source compiler plugin that automatically merges Dagger modules and component interfaces to make development more enjoyable.</p><p><a href=\"https://developer.squareup.com/blog/api-explorer-moves-to-general-availability\">API Explorer Moves to General Availability</a></p><p>The Square Developer team also transitioned the API Explorer from Beta to GA, bringing with it a lot of improvements to make testing Square APIs much more enjoyable and\u00a0easy.</p><p><a href=\"https://developer.squareup.com/blog/kubernetes-pod-security-policies\">Kubernetes - Pod Security Policies</a></p><p>The cloud team at Square also did a write-up that provides some useful guidance and examples for handling Pod Security in Kubernetes.</p><p><a href=\"https://developer.squareup.com/blog/reward-customers-wherever-they-shop-with-loyalty-api-and-customers-api\">Reward Customers Wherever They Shop with Loyalty API and Customers API</a></p><p>Additionally, Square Loyalty now has an API to make providing rewards to customers on other platforms. Using the Customers API and Loyalty API in combination can allow any developer to create a great rewards system, no matter where their customers are.</p><p><a href=\"https://developer.squareup.com/blog/announcing-square-terminal-api-beta\">Announcing Square Terminal API Beta</a></p><p>Finally, we also released Terminal API, which lets you programmatically take payments using Square Terminal. This API allows developers to connect <a href=\"https://squareup.com/us/en/hardware/terminal\">Square Terminal</a>, an all-in-one card payments device, to their custom-built POS systems, no matter which platforms or operating systems they\u2019re developed on.</p><p>Now that isn\u2019t <em>everything</em> that we\u2019ve published since you\u2019ve last heard from us, but should give some good highlights of what has been going on at Square. If you want to learn more or stay up-to-date on everything we\u2019re working on, make sure to check out the blog at <a href=\"https://developer.squareup.com/blog\">https://developer.squareup.com/blog</a> or follow up on twitter at <a href=\"https://twitter.com/squaredev\">https://twitter.com/squaredev</a>!</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5f0eaa1d341e\" width=\"1\" /><hr /><p><a href=\"https://medium.com/square-corner-blog/the-corner-round-up-june-2020-5f0eaa1d341e\">The Corner Round-up June 2020</a> was originally published in <a href=\"https://medium.com/square-corner-blog\">Square Corner Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Timescale": {
    "title": "Understanding PostgreSQL Aggregation and Hyperfunctions\u2019 Design",
    "xmlUrl": "https://blog.timescale.com/feed",
    "htmlUrl": "https://blog.timescale.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.timescale.com/blog/rss/",
      "value": "Understanding PostgreSQL Aggregation and Hyperfunctions\u2019 Design"
    },
    "summary": "A discussion of aggregation in PostgreSQL and how it integrates with the design of Timescale\u2019s hyperfunctions.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.timescale.com/blog/rss/",
      "value": "A discussion of aggregation in PostgreSQL and how it integrates with the design of Timescale\u2019s hyperfunctions."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.timescale.com/blog/how-postgresql-aggregation-works-and-how-it-inspired-our-hyperfunctions-design/"
      }
    ],
    "link": "https://www.timescale.com/blog/how-postgresql-aggregation-works-and-how-it-inspired-our-hyperfunctions-design/",
    "id": "65a00c1e0d3dd40001dbf779",
    "guidislink": false,
    "tags": [
      {
        "term": "Product & Engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "PostgreSQL",
        "scheme": null,
        "label": null
      },
      {
        "term": "Blog",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "David Kohn"
      }
    ],
    "author": "David Kohn",
    "author_detail": {
      "name": "David Kohn"
    },
    "published": "Thu, 11 Jan 2024 17:06:03 GMT",
    "published_parsed": [
      2024,
      1,
      11,
      17,
      6,
      3,
      3,
      11,
      0
    ],
    "media_content": [
      {
        "url": "https://www.timescale.com/blog/content/images/2024/01/PostgreSQL-Aggregation-and-Hyperfunctions-Design--1-.png",
        "medium": "image"
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.timescale.com/blog/rss/",
        "value": "<img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" src=\"https://www.timescale.com/blog/content/images/2024/01/PostgreSQL-Aggregation-and-Hyperfunctions-Design--1-.png\" /><p>At Timescale, our goal is to always focus on the developer experience, and we take great care to design our products and APIs to be developer-friendly. This focus on developer experience is why we made the decision <a href=\"https://www.timescale.com/blog/blog/when-boring-is-awesome-building-a-scalable-time-series-database-on-postgresql-2900ea453ee2/\">early in the design of TimescaleDB to build on top of PostgreSQL</a>. We believed then, as we do now, that building on the world&#x2019;s fastest-growing database would have numerous benefits for our users.</p><p>The same logic applies to a lot of our features, and one of them is <a href=\"https://www.timescale.com/learn/time-series-data-analysis-hyperfunctions?ref=timescale.com\" rel=\"noreferrer\">hyperfunctions</a>. Timescale&apos;s hyperfunctions are designed to enhance PostgreSQL&apos;s native aggregation capabilities&#x2014;<a href=\"https://www.timescale.com/blog/introducing-hyperfunctions-new-sql-functions-to-simplify-working-with-time-series-data-in-postgresql/\" rel=\"noreferrer\">a series of SQL functions within TimescaleDB that make it easier to manipulate and analyze time-series data in PostgreSQL with fewer lines of code</a>.</p><p>So, let&apos;s have a closer look at how PostgreSQL aggregation works and how it&apos;s influenced the design of Timescale&apos;s hyperfunctions.</p><h2 id=\"a-primer-on-postgresql-aggregation\">A Primer on PostgreSQL Aggregation</h2><p>We&apos;ll start by going over PostgreSQL aggregates. But first, a little backstory.</p><p>When I first started learning about PostgreSQL five or six years ago (I was an electrochemist and was dealing with lots of battery data, as mentioned in <a href=\"https://www.timescale.com/blog/blog/what-time-weighted-averages-are-and-why-you-should-care/\">my last post on time-weighted averages</a>), I ran into some performance issues. I was trying to understand better what was happening inside the database to improve its performance&#x2014;and that&#x2019;s when I found <a href=\"https://momjian.us/?ref=timescale.com\">Bruce Momjian</a>&#x2019;s talks on <a href=\"https://momjian.us/main/presentations/internals.html?ref=timescale.com\">PostgreSQL Internals Through Pictures</a>. Bruce is well-known in the community for his insightful talks (and his penchant for bow ties); his sessions were a revelation for me. </p><p>They&#x2019;ve served as a foundation for my understanding of how PostgreSQL works ever since. He explained things so clearly, and I&#x2019;ve always learned best when I can visualize what&#x2019;s going on, so the &#x201c;through pictures&#x201d; part really helped&#x2014;and stuck with&#x2014;me. </p><p>So, this next bit is my attempt to channel Bruce by explaining some PostgreSQL internals through pictures. Cinch up your bow ties and get ready for some learnin&apos;.</p>\n<!--kg-card-begin: html-->\n<figure>\n\t\n\t\n    <figcaption class=\"gif-caption\">The author pays homage to Bruce Momjian (and looks rather pleased with himself because he&#x2019;s managed to tie a bow tie on the first try).\n    </figcaption>\n</figure>\n\n<!--kg-card-end: html-->\n<h3 id=\"postgresql-aggregates-vs-functions\">PostgreSQL aggregates vs. functions</h3><p>We have written about <a href=\"https://www.timescale.com/blog/blog/introducing-hyperfunctions-new-sql-functions-to-simplify-working-with-time-series-data-in-postgresql/\">how we use custom functions and aggregates to extend SQL</a>, but we haven&#x2019;t exactly explained the difference<em> between</em> them.</p><p>The fundamental difference between an aggregate function and a &#x201c;regular&#x201d; function in SQL is that an <strong>aggregate</strong> produces a single result from a <em>group</em> of related rows, while a regular <strong>function </strong>produces a result for <em>each</em> row:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"752\" src=\"https://www.timescale.com/blog/content/images/2021/08/Aggregate-vs.-Function-2.jpg\" width=\"1804\" /><figcaption><span style=\"white-space: pre-wrap;\">In SQL, aggregates produce a result from multiple rows, while functions produce a result per row.</span></figcaption></figure><p>This is not to say that a function can&#x2019;t have inputs from multiple columns; they just have to come from the same row. </p><p>Another way to think about it is that functions often act on rows, whereas aggregates act on columns. To illustrate this, let&#x2019;s consider a theoretical table <code>foo</code> with two columns:</p><pre><code class=\"language-SQL\">CREATE TABLE foo(\n\tbar DOUBLE PRECISION,\n\tbaz DOUBLE PRECISION);\n</code></pre><p>And just a few values so we can easily see what&#x2019;s going on:</p><pre><code class=\"language-SQL\">INSERT INTO foo(bar, baz) VALUES (1.0, 2.0), (2.0, 4.0), (3.0, 6.0);\n</code></pre><p>The function <a href=\"https://www.postgresql.org/docs/13/functions-conditional.html?ref=timescale.com#FUNCTIONS-GREATEST-LEAST\"><code>greatest()</code></a> will produce the largest of the values in columns <code>bar</code> and <code>baz</code> for each row:</p><p></p><pre><code class=\"language-SQL\">SELECT greatest(bar, baz) FROM foo; \n greatest \n----------\n        2\n        4\n        6\n</code></pre><p>Whereas the aggregate <a href=\"https://www.postgresql.org/docs/current/functions-aggregate.html?ref=timescale.com\"><code>max()</code></a> will produce the largest value from each column:</p><pre><code class=\"language-SQL\">SELECT max(bar) as bar_max, max(baz) as baz_max FROM foo;\n\n bar_max | baz_max \n---------+---------\n       3 |       6\n</code></pre><p>Using the above data, here&#x2019;s a picture of what happens when we aggregate something:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"600\" src=\"https://www.timescale.com/blog/content/images/2021/08/Aggregate-vs.-Function-1-1.jpg\" width=\"1804\" /><figcaption><span style=\"white-space: pre-wrap;\">The </span><code style=\"white-space: pre-wrap;\"><span>max()</span></code><span style=\"white-space: pre-wrap;\"> aggregate gets the largest value from multiple rows.</span></figcaption></figure><p>The aggregate takes inputs from multiple rows and produces a single result. That&#x2019;s the main difference between it and a function, but how does it do that? Let&#x2019;s look at what it&#x2019;s doing under the hood.</p><h3 id=\"aggregate-internals-row-by-row\">Aggregate internals: Row-by-row</h3><p>Under the hood, aggregates in PostgreSQL work row-by-row. But then, how does an aggregate know anything about the previous rows?</p><p>An aggregate stores some state about the rows it has previously seen, and as the database sees new rows, it updates that internal state.</p><p>For the <code>max()</code> aggregate we&#x2019;ve been discussing, the internal state is simply the largest value we&#x2019;ve collected so far. </p><p>Let&#x2019;s take this step-by-step.</p><p>When we start, our internal state is <code>NULL</code> because we haven&#x2019;t seen any rows yet:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/1-2.jpg\" width=\"1600\" /></figure><p>Then, we get our first row in:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/2-2.jpg\" width=\"1600\" /></figure><p>Since our state is <code>NULL</code>, we initialize it to the first value we see:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/3-1.jpg\" width=\"1600\" /></figure><p>Now, we get our second row:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/4-2.jpg\" width=\"1600\" /></figure><p>And we see that the value of bar (2.0) is greater than our current state (1.0), so we update the state:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/5-2.jpg\" width=\"1600\" /></figure><p>Then, the next row comes into the aggregate:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/6-1.jpg\" width=\"1600\" /></figure><p>We compare it to our current state, take the greatest value, and update our state:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/7-1.jpg\" width=\"1600\" /></figure><p>Finally, we don&#x2019;t have any more rows to process, so we output our result:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/8-1.jpg\" width=\"1600\" /></figure><p>So, to summarize, each row comes in, gets compared to our current state, and then the state gets updated to reflect the new greatest value. Then the next row comes in, and we repeat the process until we&#x2019;ve processed all our rows and output the result.</p>\n<!--kg-card-begin: html-->\n    <video loop=\"loop\">\n      <source id=\"player\" src=\"https://s3.amazonaws.com/blog.timescale.com/gifs/how-postgres-works/how_postgres_works_1.mp4\" type=\"video/mp4\" />\n    </video>\n    <figcaption class=\"gif-caption\">The max aggregate aggregation process, told in GIFs. \n    </figcaption>\n<!--kg-card-end: html-->\n<p></p><p>There&#x2019;s a name for the function that processes each row and updates the internal state: the <a href=\"https://www.postgresql.org/docs/current/sql-createaggregate.html?ref=timescale.com\"><strong>state transition function</strong></a> (or just &#x201c;transition function&#x201d; for short.) The transition function for an aggregate takes the current state and the value from the incoming row as arguments and produces a new state. </p><p>It&#x2019;s defined like this, where <code>current_value</code> represents values from the incoming row, <code>current_state</code> represents the current aggregate state built up over the previous rows (or NULL if we haven&#x2019;t yet gotten any), and <code>next_state</code> represents the output after analyzing the incoming row:</p><pre><code class=\"language-SQL\">next_state = transition_func(current_state, current_value)</code></pre><h3 id=\"aggregate-internals-composite-state\">Aggregate internals: Composite state</h3><p>So, the <code>max()</code> aggregate has a straightforward state that contains just one value (the largest we&#x2019;ve seen). But not all aggregates in PostgreSQL have such a simple state.</p><p>Let&#x2019;s consider the aggregate for average (<code>avg</code>):</p><pre><code class=\"language-SQL\">SELECT avg(bar) FROM foo;</code></pre><p>To refresh, an average is defined as:</p><p>\\begin{equation} avg(x) = \\frac{sum(x)}{count(x)}  \\end{equation}</p>\n<p>To calculate it, we store the sum and the count as our internal state and update our state as we process rows:</p>\n<!--kg-card-begin: html-->\n    <video loop=\"loop\">\n      <source id=\"player\" src=\"https://s3.amazonaws.com/blog.timescale.com/gifs/how-postgres-works/how_postgres_works_2.mp4\" type=\"video/mp4\" />\n    </video>\n    <figcaption class=\"gif-caption\">The `avg()` aggregation process, told in GIFs. For `avg()`, the transition function must update a more complex state since the sum and count are stored separately at each aggregation step. \n    </figcaption>\n<!--kg-card-end: html-->\n<p>But, when we&#x2019;re ready to output our result for <code>avg</code>, we need to divide <code>sum</code> by <code>count</code>:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"904\" src=\"https://www.timescale.com/blog/content/images/2021/08/9-1.jpg\" width=\"1600\" /><figcaption><span style=\"white-space: pre-wrap;\">For some aggregates, we can output the state directly &#x2013; but for others, we need to perform an operation on the state before calculating our final result.</span></figcaption></figure><p>There&#x2019;s another function inside the aggregate that performs this calculation: the <a href=\"https://www.postgresql.org/docs/current/sql-createaggregate.html?ref=timescale.com\"><strong>final function</strong></a>. Once we&#x2019;ve processed all the rows, the final function takes the state and does whatever it needs to produce the result. </p><p>It&#x2019;s defined like this, where <code>final_state</code> represents the output of the transition function after it has processed all the rows:</p><pre><code class=\"language-SQL\">result = final_func(final_state)\n</code></pre><p>And, through pictures:</p>\n<!--kg-card-begin: html-->\n    <video loop=\"loop\">\n      <source id=\"player\" src=\"https://s3.amazonaws.com/blog.timescale.com/gifs/how-postgres-works/how_postgres_works_3.mp4\" type=\"video/mp4\" />\n    </video>\n    <figcaption class=\"gif-caption\">How the average aggregate works, told in GIFs. Here, we&#x2019;re highlighting the role of the final function.\n    </figcaption>\n<!--kg-card-end: html-->\n<p>To summarize, as an aggregate scans over rows, its <strong>transition function</strong> updates its internal state. Once the aggregate has scanned all of the rows, its <strong>final function</strong> produces a result, which is returned to the user.</p><h3 id=\"improving-the-performance-of-aggregate-functions\">Improving the performance of aggregate functions</h3><p>One interesting thing to note here: the transition function is called many, many more times than the final function: once for each row, whereas the final function is called once per <em>group</em> of rows. </p><p>Now, the transition function isn&#x2019;t inherently more expensive than the final function on a per-call basis&#x2014;but because there are usually orders of magnitude more rows going into the aggregate than coming out, the transition function step becomes the most expensive part very quickly. This is especially true when you have high-volume time-series data being ingested at high rates; optimizing aggregate transition function calls is important for improving performance.</p><p>Luckily, PostgreSQL already has ways to optimize aggregates.</p><h3 id=\"parallelization-and-the-combine-function\">Parallelization and the combine function</h3><p>Because the transition function is run on each row, <a href=\"https://www.postgresql.org/message-id/flat/CA%2BTgmoYSL_97a--qAvdOa7woYamPFknXsXX17m0t2Pwc%2BFOvYw%40mail.gmail.com?ref=timescale.com#fb9f2ae2a52ac605a4439a1879ff3c10\">some enterprising PostgreSQL developers</a> asked: <em>what if we parallelized the transition function calculation?</em> </p><p>Let&#x2019;s revisit our definitions for transition functions and final functions:</p><pre><code class=\"language-SQL\">next_state = transition_func(current_state, current_value)\n\nresult = final_func(final_state)</code></pre><p>We can run this in parallel by instantiating multiple copies of the transition function and handing a subset of rows to each instance. Then, each parallel aggregate will run the transition function over the subset of rows it sees, producing multiple (partial) states, one for each parallel aggregate. But, since we need to aggregate over the <em>entire</em> data set, we can&#x2019;t run the final function on each parallel aggregate separately because they only have some of the rows. </p><p>So, now we&#x2019;ve ended up in a bit of a pickle: we have multiple partial aggregate states, and the final function is only meant to work on the single, final state&#x2014;right before we output the result to the user. </p><p>To solve this problem, we need a new type of function that combines two partial states into one so that the final function can do its work. This is (aptly) called the <a href=\"https://www.postgresql.org/docs/current/sql-createaggregate.html?ref=timescale.com\"><strong>combine function</strong></a>. </p><p>We can run the combine function iteratively over all of the partial states that are created when we parallelize the aggregate.</p><pre><code class=\"language-SQL\">combined_state = combine_func(partial_state_1, partial_state_2)</code></pre><p>For instance, in <code>avg</code>, the combine function will add up the counts and sums.</p>\n<!--kg-card-begin: html-->\n    <video loop=\"loop\">\n      <source id=\"player\" src=\"https://s3.amazonaws.com/blog.timescale.com/gifs/how-postgres-works/how_postgres_works_4.mp4\" type=\"video/mp4\" />\n    </video>\n    <figcaption class=\"gif-caption\">How parallel aggregation works, told in GIFs. Here, we&#x2019;re highlighting the combine function (We&#x2019;ve added a couple more rows to illustrate parallel aggregation.)\n    </figcaption>\n<!--kg-card-end: html-->\n<p>Then, after we have the combined state from all of our parallel aggregates, we run the final function and get our result.</p><h3 id=\"deduplication\">Deduplication</h3><p>Parallelization and the combined function are one way to reduce the cost of calling an aggregate, but they&#x2019;re not the only way. </p><p>One other built-in PostgreSQL optimization that reduces an aggregate&#x2019;s cost occurs in a statement like this:</p><pre><code class=\"language-SQL\">SELECT avg(bar), avg(bar) / 2 AS half_avg FROM foo;</code></pre><p>PostgreSQL will optimize this statement to evaluate the <code>avg(bar)</code> calculation only once and then use that result twice. </p><p>And what if we have different aggregates with the same transition function but different final functions? PostgreSQL further optimizes by calling the transition function (the expensive part) on all the rows and then doing both final functions! Pretty neat!</p><p>That&#x2019;s not all that PostgreSQL aggregates can do, but it&#x2019;s a pretty good tour, and it&#x2019;s enough to get us where we need to go today.</p><h2 id=\"two-step-aggregation-in-timescaledb-hyperfunctions\">Two-step Aggregation in TimescaleDB Hyperfunctions</h2><p>In TimescaleDB, we&#x2019;ve implemented the two-step aggregation design pattern for our aggregate functions. This generalizes the PostgreSQL internal aggregation API and exposes it to the user via our aggregates, accessors, and rollup functions. (In other words, each internal PostgreSQL function has an equivalent function in TimescaleDB hyperfunctions.)</p><p>As a refresher, when we talk about the two-step aggregation design pattern, we mean the following convention, where we have an inner aggregate call:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"230\" src=\"https://www.timescale.com/blog/content/images/2021/08/Inner-aggregate-call-1.jpg\" width=\"1232\" /></figure><p>And an outer accessor call:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"230\" src=\"https://www.timescale.com/blog/content/images/2021/08/Outer-accessor-call-1.jpg\" width=\"1232\" /></figure><p>The inner aggregate call returns the internal state, just like the transition function does in PostgreSQL aggregates. </p><p>The outer accessor call takes the internal state and returns a result to the user, just like the final function does in PostgreSQL. </p><p>We also have special <a href=\"https://docs.timescale.com/api/latest/hyperfunctions/percentile-approximation/rollup-percentile/?ref=timescale.com#sample-usage\"><code>rollup</code></a> functions <a href=\"https://docs.timescale.com/api/latest/hyperfunctions/time-weighted-averages/rollup-timeweight/?ref=timescale.com\">defined for each of our aggregates</a> that work much like PostgreSQL combine functions.</p>\n<!--kg-card-begin: html-->\n<span id=\"agg-table\">\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"466\" src=\"https://www.timescale.com/blog/content/images/2021/08/table-pg-two-step-comparison-1.jpg\" width=\"1109\" /><figcaption><span style=\"white-space: pre-wrap;\">PostgreSQL internal aggregation APIs and their TimescaleDB hyperfunctions&#x2019; equivalent</span></figcaption></figure><h3 id=\"why-we-use-the-two-step-aggregate-design-pattern\">Why we use the two-step aggregate design pattern</h3><p>There are four basic reasons we expose the two-step aggregate design pattern to users rather than leave it as an internal structure (and the last two helped us build our continuous aggregates): </p><ol><li>Allow multi-parameter aggregates to re-use state, making them more efficient.</li><li>Cleanly distinguish between parameters that affect aggregates vs. accessors, making performance implications easier to understand and predict.</li><li>Enable easy-to-understand rollups, with logically consistent results, in continuous aggregates and window functions (one of our most common requests on continuous aggregates).</li><li>Allow easier <em>retrospective analysis</em> of downsampled data in continuous aggregates as requirements change, but the data is already gone.</li></ol><p>That&#x2019;s a little theoretical, so let&#x2019;s dive in and explain each one.</p><h2 id=\"efficiency-of-two-step-aggregates\">Efficiency of Two-Step Aggregates<br /></h2><h3 id=\"re-using-state\"><strong>Re-using state</strong></h3><p>PostgreSQL is very good at optimizing statements (as we saw earlier in this post through pictures &#x1f64c;), but you have to give it things in a way it can understand. </p><p>For instance, <a href=\"https://www.timescale.com/blog/blog/how-postgresql-aggregation-works-and-how-it-inspired-our-hyperfunctions-design-2/#deduplication\">when we talked about deduplication</a>, we saw that PostgreSQL could &#x201c;figure out&#x201d; when a statement occurs more than once in a query (i.e., <code>avg(bar)</code>) and only run the statement a single time to avoid redundant work:</p><pre><code class=\"language-SQL\">SELECT avg(bar), avg(bar) / 2 AS half_avg FROM foo;</code></pre><p>This works because the <code>avg(bar)</code> occurs multiple times without variation. </p><p>However, if I write the equation in a slightly different way and move the division<em> inside</em> the parentheses so that the expression <code>avg(bar)</code> doesn&#x2019;t repeat so neatly, PostgreSQL <em>can&#x2019;t</em> figure out how to optimize it:</p><pre><code class=\"language-SQL\">SELECT avg(bar), avg(bar / 2) AS half_avg FROM foo;</code></pre><p>It doesn&#x2019;t know that the division is commutative or that those two queries are equivalent. </p><p>This is a complicated problem for database developers to solve, and thus, as a PostgreSQL user, you need to make sure to write your query in a way that the database can understand. </p><p>Performance problems caused by equivalent statements that the database doesn&#x2019;t understand are equal (or that are equal in the specific case you wrote but not in the general case) can be some of the trickiest SQL optimizations to figure out as a user. </p><p>Therefore, <strong>when we design our APIs, we try to make it hard for users to write low-performance code unintentionally: in other words, the default option should be the high-performance option</strong>.</p><p>For the next bit, it&#x2019;ll be useful to have a simple table defined as:</p><pre><code class=\"language-SQL\">CREATE TABLE foo(\n\tts timestamptz, \n\tval DOUBLE PRECISION);</code></pre><p>Let&#x2019;s look at an example of how we use two-step aggregation in the <a href=\"https://docs.timescale.com/api/latest/hyperfunctions/percentile-approximation/?ref=timescale.com\">percentile approximation hyperfunction</a> to allow PostgreSQL to optimize performance.</p><pre><code class=\"language-SQL\">SELECT \n    approx_percentile(0.1, percentile_agg(val)) as p10, \n    approx_percentile(0.5, percentile_agg(val)) as p50, \n    approx_percentile(0.9, percentile_agg(val)) as p90 \nFROM foo;</code></pre><p>...is treated as the same as:</p><pre><code class=\"language-SQL\">SELECT \n    approx_percentile(0.1, pct_agg) as p10, \n    approx_percentile(0.5, pct_agg) as p50, \n    approx_percentile(0.9, pct_agg) as p90 \nFROM \n(SELECT percentile_agg(val) as pct_agg FROM foo) pct;\n</code></pre><p>This calling convention allows us to use identical aggregates so that, under the hood, PostgreSQL can deduplicate calls to the identical aggregates (and is faster as a result).</p><p>Now, let&#x2019;s compare this to the one-step aggregate approach. </p><p>PostgreSQL can&#x2019;t deduplicate aggregate calls here because the extra parameter in the <code>approx_percentile</code> aggregate changes with each call:</p><figure class=\"kg-card kg-image-card\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"368\" src=\"https://www.timescale.com/blog/content/images/2021/08/Approx_percentile.jpg\" width=\"1232\" /></figure><p>So, even though all of those functions could use the same approximation built up over all the rows, PostgreSQL has no way of knowing that. The two-step aggregation approach enables us to structure our calls so that PostgreSQL can optimize our code, and it enables developers to understand when things will be more expensive and when they won&apos;t. Multiple different aggregates with different inputs will be expensive, whereas multiple accessors to the same aggregate will be much less expensive.</p><h3 id=\"cleanly-distinguishing-between-aggregateaccessor-parameters\">Cleanly distinguishing between aggregate/accessor parameters</h3><p>We also chose the two-step aggregate approach because some of our aggregates can take multiple parameters or options themselves, and their accessors can also take options:</p><pre><code class=\"language-SQL\">SELECT\n    approx_percentile(0.5, uddsketch(1000, 0.001, val)) as median,--1000 buckets, 0.001 target err\n    approx_percentile(0.9, uddsketch(1000, 0.001, val)) as p90, \n    approx_percentile(0.5, uddsketch(100, 0.01, val)) as less_accurate_median -- modify the terms for the aggregate get a new approximation\nFROM foo;</code></pre><p><br />That&#x2019;s an example of <a href=\"https://docs.timescale.com/api/latest/hyperfunctions/percentile-approximation/percentile-aggregation-methods/uddsketch/?ref=timescale.com\"><code>uddsketch</code></a>, an <a href=\"https://docs.timescale.com/api/latest/hyperfunctions/percentile-approximation/percentile-aggregation-methods/?ref=timescale.com#choosing-the-right-algorithm-for-your-use-case\">advanced aggregation method</a> for percentile approximation that can take its own parameters. </p><p>Imagine if the parameters were jumbled together in one aggregate:</p><pre><code class=\"language-SQL\">-- NB: THIS IS AN EXAMPLE OF AN API WE DECIDED NOT TO USE, IT DOES NOT WORK\nSELECT\n    approx_percentile(0.5, 1000, 0.001, val) as median\nFROM foo;\n</code></pre><p><br />It&#x2019;d be pretty difficult to understand which argument is related to which part of the functionality.</p><p>Conversely, the two-step approach separates the arguments to the accessor vs. aggregate very cleanly, where the aggregate function is defined in parenthesis within the inputs of our final function:</p><pre><code class=\"language-SQL\">SELECT\n    approx_percentile(0.5, uddsketch(1000, 0.001, val)) as median\nFROM foo;\n</code></pre><p>By making it clear which is which, users can know that if they change the inputs to the aggregate, they will get more (costly) aggregate nodes, =while inputs to the accessor are cheaper to change. </p><p>So, those are the first two reasons we expose the API&#x2014;and what it allows developers to do as a result. The last two reasons involve continuous aggregates and how they relate to hyperfunctions, so first, a quick refresher on what they are.</p><h2 id=\"continuous-aggregates-and-two-step-design-in-timescaledb\">Continuous Aggregates and Two-Step Design in TimescaleDB</h2><p>TimescaleDB includes a feature called <a href=\"https://docs.timescale.com/timescaledb/latest/how-to-guides/continuous-aggregates/?ref=timescale.com\">continuous aggregates</a>, which are designed to make queries on very large datasets run faster. TimescaleDB&apos;s continuous aggregates continuously and incrementally store the results of an aggregation query in the background, so when you run the query, only the data that has changed needs to be computed, not the entire dataset. </p><p>In our discussion of the combine function <a href=\"https://www.timescale.com/blog/blog/how-postgresql-aggregation-works-and-how-it-inspired-our-hyperfunctions-design-2/#deduplication\">above,</a> we covered how you could take the expensive work of computing the transition function over every row and split the rows over multiple parallel aggregates to speed up the calculation.</p><p>TimescaleDB continuous aggregates do something similar, except they spread the computation work over<em> time</em> rather than between parallel processes running simultaneously. The continuous aggregate computes the transition function over a subset of rows inserted some time in the past, stores the result, and then, at query time, we only need to compute over the raw data for a small section of recent time that we haven&#x2019;t yet calculated. </p><p>When we designed TimescaleDB hyperfunctions, we wanted them to work well within continuous aggregates and even open new possibilities for users.  </p><p>Let&#x2019;s say I create a continuous aggregate from the simple table above to compute the sum, average, and percentile (the latter using a hyperfunction) in 15-minute increments:</p><pre><code class=\"language-SQL\">CREATE MATERIALIZED VIEW foo_15_min_agg\nWITH (timescaledb.continuous)\nAS SELECT id,\n    time_bucket(&apos;15 min&apos;::interval, ts) as bucket,\n    sum(val),\n    avg(val),\n    percentile_agg(val)\nFROM foo\nGROUP BY id, time_bucket(&apos;15 min&apos;::interval, ts);</code></pre><p>And then what if I come back and I want to re-aggregate it to hours or days rather than 15-minute buckets&#x2014;or need to aggregate my data across all IDs? Which aggregates can I do that for, and which can&#x2019;t I?</p><h3 id=\"logically-consistent-rollups\">Logically consistent rollups</h3><p>One of the problems we wanted to solve with two-step aggregation was how to convey to the user when it is &#x201c;okay&#x201d; to re-aggregate and when it&#x2019;s not. (By &#x201c;okay,&#x201d; I mean you would get the same result from the re-aggregated data as you would running the aggregate on the raw data directly.) </p><p>For instance:</p><pre><code class=\"language-SQL\">SELECT sum(val) FROM tab;\n-- is equivalent to:\nSELECT sum(sum) \nFROM \n    (SELECT id, sum(val) \n    FROM tab\n    GROUP BY id) s;</code></pre><p>But:</p><pre><code class=\"language-SQL\">SELECT avg(val) FROM tab;\n-- is NOT equivalent to:\nSELECT avg(avg) \nFROM \n    (SELECT id, avg(val) \n    FROM tab\n    GROUP BY id) s;\n</code></pre><p>Why is re-aggregation okay for <code>sum</code> but not for <code>avg</code>? </p><p>Technically, it&#x2019;s logically consistent to re-aggregate when:</p><ul><li>The aggregate returns the internal aggregate state. The internal aggregate state for sum is <code>(sum)</code>, whereas for average, it is <code>(sum, count)</code>. </li><li>The aggregate&#x2019;s combine and transition functions are equivalent. For <code>sum()</code>, the states and the operations are the same. For <code>count()</code>, the <em>states</em> are the same, but the transition and combine functions <em>perform different operations </em>on them. <code>sum()</code>&#x2019;s transition function adds the incoming value to the state, and its combine function adds two states together or a sum of sums.  Conversely, <code>count()</code>s transition function increments the state for each incoming value, but its combine function adds two states together, or a sum of counts.</li></ul><p>But, you have to have in-depth (and sometimes rather arcane) knowledge about each aggregate&#x2019;s internals to know which ones meet the above criteria&#x2014;and, therefore, which ones you can re-aggregate.</p><p><strong>With the two-step aggregate approach, we can convey when it is logically consistent to re-aggregate by exposing our equivalent of the combine function when the aggregate allows it.</strong></p><p>We call that function <code>rollup()</code>. <code>Rollup()</code> takes multiple inputs from the aggregate and combines them into a single value. </p><p>All of our aggregates that can be combined have <code>rollup</code> functions that will combine the output of the aggregate from two different groups of rows. (Technically, <code>rollup()</code> is an aggregate function because it acts on multiple rows. For clarity, I&#x2019;ll call them rollup functions to distinguish them from the base aggregate).  Then you can call the accessor on the combined output! </p><p>So using that continuous aggregate we created to get a 1-day re-aggregation of our <code>percentile_agg</code> becomes as simple as:</p><pre><code class=\"language-SQL\">SELECT id, \n    time_bucket(&apos;1 day&apos;::interval, bucket) as bucket, \n    approx_percentile(0.5, rollup(percentile_agg)) as median\nFROM foo_15_min_agg\nGROUP BY id, time_bucket(&apos;1 day&apos;::interval, bucket);</code></pre><p>(We actually suggest that you create your continuous aggregates without calling the accessor function for this very reason. Then, you can just create views over top or put the accessor call in your query). </p><p>This brings us to our final reason.</p><h3 id=\"retrospective-analysis-using-continuous-aggregates\">Retrospective analysis using continuous aggregates</h3><p>When we create a continuous aggregate, we&#x2019;re defining a view of our data that we could then be stuck with for a very long time. </p><p>For example, we might have a data retention policy that deletes the underlying data after X time period. If we want to go back and re-calculate anything, it can be challenging, if not impossible, since we&#x2019;ve &#x201c;dropped&#x201d; the data. </p><p>But we understand that in the real world, you don&#x2019;t always know what you&#x2019;re going to need to analyze ahead of time. </p><p>Thus, we designed hyperfunctions to use the two-step aggregate approach so they would better integrate with continuous aggregates. As a result, users store the aggregate state in the continuous aggregate view and modify accessor functions <em>without</em> requiring them to recalculate old states that might be difficult (or impossible) to reconstruct (because the data is archived, deleted, etc.). </p><p>The two-step aggregation design also allows for much greater flexibility with continuous aggregates. For instance, let&#x2019;s take a continuous aggregate where we do the aggregate part of the two-step aggregation like this:</p><pre><code class=\"language-SQL\">CREATE MATERIALIZED VIEW foo_15_min_agg\nWITH (timescaledb.continuous)\nAS SELECT id,\n    time_bucket(&apos;15 min&apos;::interval, ts) as bucket,\n    percentile_agg(val)\nFROM foo\nGROUP BY id, time_bucket(&apos;15 min&apos;::interval, ts);\n</code></pre><p>When we first create the aggregate, we might only want to get the median:</p><pre><code class=\"language-SQL\">SELECT\n    approx_percentile(0.5, percentile_agg) as median\nFROM foo_15_min_agg;\n</code></pre><p>But then, later, we decided we wanted to know the 95th percentile as well. </p><p>Luckily, we don&#x2019;t have to modify the continuous aggregate; we<strong> just modify the parameters to the accessor function in our original query to return the data we want from the aggregate state</strong>:</p><pre><code class=\"language-SQL\">SELECT\n    approx_percentile(0.5, percentile_agg) as median,\n    approx_percentile(0.95, percentile_agg) as p95\nFROM foo_15_min_agg;</code></pre><p>And then, if a year later, we want the 99th percentile as well, we can do that too:</p><pre><code class=\"language-SQL\">SELECT\n    approx_percentile(0.5, percentile_agg) as median,\n    approx_percentile(0.95, percentile_agg) as p95,\n    approx_percentile(0.99, percentile_agg) as p99\nFROM foo_15_min_agg;\n</code></pre><p>That&#x2019;s just scratching the surface. Ultimately, our goal is to provide a high level of developer productivity that enhances other PostgreSQL and TimescaleDB features, like aggregate deduplication and continuous aggregates.</p><h2 id=\"example-time-weighted-average\">Example: Time-Weighted Average</h2><p>To illustrate how the two-step aggregate design pattern impacts how we think about and code hyperfunctions, let&#x2019;s look at the<a href=\"https://docs.timescale.com/api/latest/hyperfunctions/time-weighted-averages/?ref=timescale.com\"> time-weighted average family of functions</a>. (Our<a href=\"https://www.timescale.com/blog/blog/what-time-weighted-averages-are-and-why-you-should-care/\"> What Time-Weighted Averages Are and Why You Should Care</a> post provides a lot of context for this next bit, so if you haven&#x2019;t read it, we recommend doing so. You can also skip this next bit for now.)</p><p>The equation for the time-weighted average is as follows:</p><p>\\begin{equation}  time\\_weighted\\_average = \\frac{area\\_under\\_curve}{ \\Delta T}   \\end{equation}</p>\n<p>As we noted in the <a href=\"https://www.timescale.com/blog/blog/how-postgresql-aggregation-works-and-how-it-inspired-our-hyperfunctions-design-2/#agg-table\">table above</a>:</p><ul><li><code>time_weight()</code> is TimescaleDB hyperfunctions&#x2019; aggregate and corresponds to the transition function in PostgreSQL&#x2019;s internal API.</li><li><code>average()</code> is the accessor, which corresponds to the PostgreSQL final function.</li><li><code>rollup()</code> for re-aggregation corresponds to the PostgreSQL combine function.</li></ul><p>The <code>time_weight()</code> function returns an aggregate type that has to be usable by the other functions in the family.</p><p>In this case, we decided on a <code>TimeWeightSummary</code> type that is defined like so (in pseudocode):</p><pre><code class=\"language-SQL\">TimeWeightSummary = (w_sum, first_pt, last_pt)</code></pre><p><code>w_sum</code> is the weighted sum (another name for the area under the curve), and <code>first_pt</code> and <code>last_pt</code> are the first and last (time, value) pairs in the rows that feed into the <code>time_weight()</code> aggregate. </p><p>Here&#x2019;s a graphic depiction of those elements, which builds on our <a href=\"https://www.timescale.com/blog/blog/what-time-weighted-averages-are-and-why-you-should-care/#mathy-bits-how-to-derive-a-time-weighted-average\">how to derive a time-weighted average theoretical description</a>:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"589\" src=\"https://www.timescale.com/blog/content/images/2021/08/example-graph1-1.jpg\" width=\"692\" /><figcaption><span style=\"white-space: pre-wrap;\">Depiction of the values we store in the </span><code style=\"white-space: pre-wrap;\"><span>TimeWeightSummary</span></code><span style=\"white-space: pre-wrap;\"> representation.</span></figcaption></figure><p></p><p>So, the <code>time_weight()</code> aggregate does all of the calculations as it receives each of the points in our graph and builds a weighted sum for the time period (&#x394;T) between the first and last points it &#x201c;sees.&#x201d; It then outputs the <code>TimeWeightSummary</code>.</p><p>The <code>average()</code> accessor function performs simple calculations to return the time-weighted average from the <code>TimeWeightSummary</code> (in pseudocode where <code>pt.time()</code> returns the time from the point):</p><pre><code class=\"language-SQL\">func average(TimeWeightSummary tws) \n\t-&gt; float {\n\t\tdelta_t = tws.last_pt.time - tws.first_pt.time;\n\t\ttime_weighted_average = tws.w_sum / delta_t;\n\t\treturn time_weighted_average;\n\t}</code></pre><p><br />But, as we built the <code>time_weight</code> hyperfunction, ensuring the <code>rollup()</code> function worked as expected was a little more difficult &#x2013; and introduced constraints that impacted the design of our <code>TimeWeightSummary</code> data type. </p><p>To understand the rollup function, let&#x2019;s use our graphical example and imagine the <code>time_weight()</code> function returns two <code>TimeWeightSummaries</code> from different regions of time like so:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"511\" src=\"https://www.timescale.com/blog/content/images/2021/08/Example-graph-2-1.jpg\" width=\"672\" /><figcaption><span style=\"white-space: pre-wrap;\">What happens when we have multiple TimeWeightSummaries representing different regions of the graph</span></figcaption></figure><p>The <code>rollup()</code> function needs to take in and return the same <code>TimeWeightSummary</code> data type so that our <code>average()</code> accessor can understand it. (This mirrors how PostgreSQL&#x2019;s combined function takes in two states from the transition function and then returns a single state for the final function to process.)</p><p>We also want the <code>rollup()</code> output to be the same as if we had computed the <code>time_weight()</code> over all the underlying data. The output should be a <code>TimeWeightSummary</code> representing the full region.  </p><p>The <code>TimeWeightSummary</code> we output should also account for the area in the gap between these two weighted sum states:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"501\" src=\"https://www.timescale.com/blog/content/images/2021/08/example-graph-3-1.jpg\" width=\"663\" /><figcaption><span style=\"white-space: pre-wrap;\">Mind the gap! (between one </span><code style=\"white-space: pre-wrap;\"><span>TimeWeightSummary</span></code><span style=\"white-space: pre-wrap;\"> and the next).</span></figcaption></figure><p>The gap area is easy to get because we have the last<sub>1</sub> and first<sub>2</sub> points&#x2014;and it&#x2019;s the same as the <code>w_sum</code> we&#x2019;d get by running the <code>time_weight()</code> aggregate on them.</p><p>Thus, the overall <code>rollup()</code> function needs to do something like this (where <code>w_sum()</code> extracts the weighted sum from the <code>TimeWeightSummary</code>):</p><pre><code class=\"language-SQL\">func rollup(TimeWeightSummary tws1, TimeWeightSummary tws2) \n\t-&gt; TimeWeightSummary {\n\t\tw_sum_gap = time_weight(tws1.last_pt, tws2.first_pt).w_sum;\n\t\tw_sum_total = w_sum_gap + tws1.w_sum + tws2.w_sum;\n\t\treturn TimeWeightSummary(w_sum_total, tws1.first_pt, tws2.last_pt);\n\t}\n</code></pre><p>Graphically, that means we&#x2019;d end up with a single <code>TimeWeightSummary</code> representing the whole area:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Understanding PostgreSQL Aggregation and Hyperfunctions&#x2019; Design\" class=\"kg-image\" height=\"505\" src=\"https://www.timescale.com/blog/content/images/2021/08/example-graph-4-1.jpg\" width=\"672\" /><figcaption><span style=\"white-space: pre-wrap;\">The combined </span><code style=\"white-space: pre-wrap;\"><span>TimeWeightSummary</span></code></figcaption></figure><p>So that&#x2019;s how the two-step aggregate design approach ends up affecting the real-world implementation of our time-weighted average hyperfunctions. The above explanations are a bit condensed, but they should give you a more concrete look at how <code>time_weight()</code> aggregate, <code>average()</code> accessor, and <code>rollup()</code> functions work.</p><h2 id=\"summing-it-up\">Summing It Up</h2><p>Now that you&#x2019;ve gotten a tour of the PostgreSQL aggregate API, how it inspired us to make the TimescaleDB hyperfunctions two-step aggregate API, and a few examples of how this works in practice, we hope you&apos;ll try it out yourself and tell us what you think :). </p><p>If you&apos;re currently dealing with gigantic databases, remember that you can always tier your older, infrequently accessed data to keep things running smoothly without breaking the bank&#x2014;we built the perfect solution for this with our <a href=\"https://docs.timescale.com/use-timescale/latest/data-tiering/?ref=timescale.com\" rel=\"noreferrer\">Tiered Storage architecture backend</a>. Check it out!</p><p>If you&apos;d like to keep learning about Postgres and its community, visit our <a href=\"https://www.timescale.com/state-of-postgres/2023?ref=timescale.com\" rel=\"noreferrer\"><em>State of PostgreSQL 2023</em> </a>report, which is full of insights on how people around the world use PostgreSQL.</p><p><strong>Going back to hyperfunctions, to get started right away, </strong><a href=\"https://console.cloud.timescale.com/signup?ref=timescale.com\"><strong>spin up a fully managed Timescale service and try it for free</strong></a><strong>. </strong>Hyperfunctions are pre-loaded on each new database service on Timescale, so after you create a new service, you&#x2019;re all set to use them!</p></span>"
      }
    ]
  },
  "Elastic": {
    "title": "Diana Todea pivoted from political philosophy to engineering. Here\u2019s how she broke into tech.",
    "xmlUrl": "https://www.elastic.co/blog/feed",
    "htmlUrl": "https://www.elastic.co/blog/category/engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.elastic.co/blog/feed",
      "value": "Diana Todea pivoted from political philosophy to engineering. Here\u2019s how she broke into tech."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.elastic.co/blog/culture-pivoting-philosophy-engineering"
      }
    ],
    "link": "https://www.elastic.co/blog/culture-pivoting-philosophy-engineering",
    "id": "https://www.elastic.co/blog/culture-pivoting-philosophy-engineering",
    "guidislink": false,
    "authors": [
      {
        "name": "Elastic Culture"
      }
    ],
    "author": "Elastic Culture",
    "author_detail": {
      "name": "Elastic Culture"
    },
    "published": "Thu, 11 Jan 2024 00:00:00 GMT",
    "published_parsed": [
      2024,
      1,
      11,
      0,
      0,
      0,
      3,
      11,
      0
    ]
  },
  "Target": {
    "title": "REDstack",
    "xmlUrl": "https://target.github.io/feed.xml",
    "htmlUrl": "https://target.github.io/",
    "title_detail": {
      "type": "text/html",
      "language": "en",
      "base": "https://target.github.io/feed.xml",
      "value": "REDstack"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://target.github.io/big%20data%20infrastructure/REDstack-Hadoop-as-a-Service"
      }
    ],
    "link": "https://target.github.io/big%20data%20infrastructure/REDstack-Hadoop-as-a-Service",
    "id": "https://target.github.io/big%20data%20infrastructure/REDstack-Hadoop-as-a-Service",
    "guidislink": false,
    "updated": "2017-12-07T00:00:00-00:00",
    "updated_parsed": [
      2017,
      12,
      7,
      0,
      0,
      0,
      3,
      341,
      0
    ],
    "published": "2017-12-07T00:00:00-06:00",
    "published_parsed": [
      2017,
      12,
      7,
      6,
      0,
      0,
      3,
      341,
      0
    ],
    "authors": [
      {
        "name": "Target Brands, Inc",
        "href": "https://target.github.io",
        "email": ""
      }
    ],
    "author_detail": {
      "name": "Target Brands, Inc",
      "href": "https://target.github.io",
      "email": ""
    },
    "href": "https://target.github.io",
    "author": "Target Brands, Inc",
    "content": [
      {
        "type": "text/html",
        "language": "en",
        "base": "https://target.github.io/feed.xml",
        "value": "<h2 id=\"redstack-is-now-open-source\">REDstack is Now Open Source!</h2>\n<p>We are officially open sourcing REDstack, our sandbox tool for Big Data development at Target.</p>\n\n<h3 id=\"what-is-redstack\">What is REDstack?</h3>\n<p>REDstack is a tool for provisioning kerberized clusters on OpenStack.  We created it with four goals in mind:</p>\n\n<ul>\n  <li>Provide a secured environment, with the ability to leverage preconfigured LDAP and Kerberos servers.</li>\n  <li>Out of the box usability, allowing you to log in with preconfigured user accounts.</li>\n  <li>Custom user management utilities to administer the cluster.</li>\n  <li>Provide a fully customizable experience, everything is a configuration option in your build files:\n    <ul>\n      <li>Cluster size, node sizes, types of nodes and node roles,</li>\n      <li>Hadoop configurations, heap sizes, and components,</li>\n      <li>All users, passwords, and secure assets.</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"components\">Components</h3>\n<p>REDstack is made up of two major components:</p>\n\n<ol>\n  <li><a href=\"https://supermarket.chef.io/cookbooks/hdp-cloud\">hdp-cloud</a> - The cookbook\n    <ul>\n      <li>The cookbook is used by the application itself to install components and lay down cluster configuration.</li>\n      <li>The cookbook can be used independently of REDstack to manually provision a cluster.</li>\n    </ul>\n  </li>\n  <li><a href=\"https://github.com/target/redstack\">REDstack</a> - The orchestration component\n    <ul>\n      <li>REDstack is a python application that performs all of the high-level complexities and timings associated with a full Hadoop installation:\n        <ul>\n          <li>Orchestrates the provisioning of resources over OpenStack APIs,</li>\n          <li>Controls and monitors parallel Chef deployment across the cluster,</li>\n          <li>Manages and monitors cluster component install over HTTPS requests.</li>\n        </ul>\n      </li>\n    </ul>\n\n    <p>REDstack is bundled with a Docker image, where the configs are set up locally before an installation, and all of the dependencies are updated and configured.</p>\n  </li>\n</ol>\n\n<h3 id=\"how-to-get-started\">How to Get Started</h3>\n<p>Head over to the repository at https://github.com/target/redstack and follow along. The repo has instructions on how to build and configure the clusters using the included Docker image.</p>\n\n<h2 id=\"history-of-the-project\">History of the Project</h2>\n<p>Target\u2019s Big Data Platform Team manages multiple Big Data environments, with hundreds of nodes and many PB\u2019s of data.  As mentioned in our prior blog posts, we depend heavily on Chef as a core part of our CI/CD pipeline.  During our testing a couple of years ago, we identified a large opportunity to provide a way to do full integration testing with our Chef cookbooks. This opportunity opened the door for a new product.</p>\n\n<h3 id=\"origins\">Origins</h3>\n<p>Early on, we released a product internally called Pushbutton. This was a three-node cluster that ran on a standard issue laptop at Target. It was kerberized, and it worked well as a Sandbox environment for developers because it had the same security setup. PushButton, however, did not use the same cookbooks as the main cluster. We wanted something that could do what PushButton did, but with our real cookbooks in a larger environment. By creating a full cluster from scratch, we would be able to understand exactly how the cookbooks would function when applied to new nodes and make sure the cookbooks were in a constant working state. We also needed a little bit larger of a sandbox, otherwise we would have difficulty testing high availability (HA) components, or those that run across multiple nodes, like Apache Zookeeper.</p>\n\n<h3 id=\"toward-redstack\">Toward REDStack</h3>\n<p>Our early exploration started out by trying to adapt the existing PushButton work onto OpenStack. We used shell scripts to automate creation of instances, Knife to bootstrap the nodes with the Chef recipes, and cURL requests to automate and monitor the install process. We got it working, but we still had to face our biggest challenge yet, integrating the cookbooks meant for physical hardware onto virtualized nodes. They were expecting particular configurations such as physical drive formatting and partitioning, or where master services are already defined and running. Instead, we had to get them working with our minimum 1x50GB virtual volumes, and anything we changed would have to still be working on the physical nodes. After some difficult work, and with some clever tricks with attributes and Chef injection, we were able to preconfigure the nodes to be recognized by the recipes and were able to slowly commit our changes back to the ecosystem without impact on the main cluster\u2019s health.</p>\n\n<h3 id=\"a-product-is-born\">A Product is Born</h3>\n<p>By this point, we had written the entire process as a Python application and set it up on a nightly loop. Every night, it would build an entire Hadoop cluster, from scratch, smoke test it, and report the results to the team. And it worked! Word started to spread among the organization and we were suddenly getting requests from users of our production cluster. They wanted to use REDstack to spin up a sandbox for them to use for Hadoop. Not only would it be more powerful, and sharable by multiple people on a team, it would look exactly like our production cluster because it uses all of the same configurations and assets.</p>\n\n<h3 id=\"opportunity\">Opportunity!</h3>\n<p>As a data engineer, wouldn\u2019t it be nice if I could have a kerberized sandbox environment that looked similar to a production cluster, was easy to work with and user friendly? This is what was possible with these environments, so we started to try and provide them to teams. It didn\u2019t work very well initially, users cloned the repo and ran it on their laptops and ran into all sorts of issues with dependencies and versions with Chef versions, ruby versions, gem versions, and python versions. There were simply too many dependencies to manage on on different environments, even with existing dependency management tools. We needed a way to hide all of the complexity and eliminate the need for users run anything on their computer.</p>\n\n<h3 id=\"the-full-stack-service\">The Full-Stack Service</h3>\n<p>This led us to the development of our full-stack cluster delivery service, Stacker. Stacker is an API running on top of a database, orchestrating REDstack deploys in threads and listening for requests over a front-end web page. Users simply submit a request on the website and a cluster will be delivered to them in about an hour. At this time, there have been more than 500 unique cluster requests and at least 30 teams are actively using REDstack as a part of their development process.</p>\n\n<h3 id=\"ongoing-development\">Ongoing Development</h3>\n<p>Over time, REDstack has evolved to include multiple types of Big Data clusters. We now provide Elasticsearch clusters as well as Druid in addition to the original Hadoop clusters. Our service continues to evolve with new releases and versions of the software, and additional ease-of-user work on our build in functions for user management and cluster administration.</p>\n\n<h4 id=\"about-the-author\">About the Author</h4>\n<p>Eric Krenz is a Senior Data Engineer on the Big Data Platform Team at Target.</p>\n\n  <p><a href=\"https://target.github.io/big%20data%20infrastructure/REDstack-Hadoop-as-a-Service\">REDstack</a> was originally published by Target Brands, Inc at <a href=\"https://target.github.io\">target tech</a> on December 07, 2017.</p>"
      }
    ],
    "summary": "<h2 id=\"redstack-is-now-open-source\">REDstack is Now Open Source!</h2>\n<p>We are officially open sourcing REDstack, our sandbox tool for Big Data development at Target.</p>\n\n<h3 id=\"what-is-redstack\">What is REDstack?</h3>\n<p>REDstack is a tool for provisioning kerberized clusters on OpenStack.  We created it with four goals in mind:</p>\n\n<ul>\n  <li>Provide a secured environment, with the ability to leverage preconfigured LDAP and Kerberos servers.</li>\n  <li>Out of the box usability, allowing you to log in with preconfigured user accounts.</li>\n  <li>Custom user management utilities to administer the cluster.</li>\n  <li>Provide a fully customizable experience, everything is a configuration option in your build files:\n    <ul>\n      <li>Cluster size, node sizes, types of nodes and node roles,</li>\n      <li>Hadoop configurations, heap sizes, and components,</li>\n      <li>All users, passwords, and secure assets.</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"components\">Components</h3>\n<p>REDstack is made up of two major components:</p>\n\n<ol>\n  <li><a href=\"https://supermarket.chef.io/cookbooks/hdp-cloud\">hdp-cloud</a> - The cookbook\n    <ul>\n      <li>The cookbook is used by the application itself to install components and lay down cluster configuration.</li>\n      <li>The cookbook can be used independently of REDstack to manually provision a cluster.</li>\n    </ul>\n  </li>\n  <li><a href=\"https://github.com/target/redstack\">REDstack</a> - The orchestration component\n    <ul>\n      <li>REDstack is a python application that performs all of the high-level complexities and timings associated with a full Hadoop installation:\n        <ul>\n          <li>Orchestrates the provisioning of resources over OpenStack APIs,</li>\n          <li>Controls and monitors parallel Chef deployment across the cluster,</li>\n          <li>Manages and monitors cluster component install over HTTPS requests.</li>\n        </ul>\n      </li>\n    </ul>\n\n    <p>REDstack is bundled with a Docker image, where the configs are set up locally before an installation, and all of the dependencies are updated and configured.</p>\n  </li>\n</ol>\n\n<h3 id=\"how-to-get-started\">How to Get Started</h3>\n<p>Head over to the repository at https://github.com/target/redstack and follow along. The repo has instructions on how to build and configure the clusters using the included Docker image.</p>\n\n<h2 id=\"history-of-the-project\">History of the Project</h2>\n<p>Target\u2019s Big Data Platform Team manages multiple Big Data environments, with hundreds of nodes and many PB\u2019s of data.  As mentioned in our prior blog posts, we depend heavily on Chef as a core part of our CI/CD pipeline.  During our testing a couple of years ago, we identified a large opportunity to provide a way to do full integration testing with our Chef cookbooks. This opportunity opened the door for a new product.</p>\n\n<h3 id=\"origins\">Origins</h3>\n<p>Early on, we released a product internally called Pushbutton. This was a three-node cluster that ran on a standard issue laptop at Target. It was kerberized, and it worked well as a Sandbox environment for developers because it had the same security setup. PushButton, however, did not use the same cookbooks as the main cluster. We wanted something that could do what PushButton did, but with our real cookbooks in a larger environment. By creating a full cluster from scratch, we would be able to understand exactly how the cookbooks would function when applied to new nodes and make sure the cookbooks were in a constant working state. We also needed a little bit larger of a sandbox, otherwise we would have difficulty testing high availability (HA) components, or those that run across multiple nodes, like Apache Zookeeper.</p>\n\n<h3 id=\"toward-redstack\">Toward REDStack</h3>\n<p>Our early exploration started out by trying to adapt the existing PushButton work onto OpenStack. We used shell scripts to automate creation of instances, Knife to bootstrap the nodes with the Chef recipes, and cURL requests to automate and monitor the install process. We got it working, but we still had to face our biggest challenge yet, integrating the cookbooks meant for physical hardware onto virtualized nodes. They were expecting particular configurations such as physical drive formatting and partitioning, or where master services are already defined and running. Instead, we had to get them working with our minimum 1x50GB virtual volumes, and anything we changed would have to still be working on the physical nodes. After some difficult work, and with some clever tricks with attributes and Chef injection, we were able to preconfigure the nodes to be recognized by the recipes and were able to slowly commit our changes back to the ecosystem without impact on the main cluster\u2019s health.</p>\n\n<h3 id=\"a-product-is-born\">A Product is Born</h3>\n<p>By this point, we had written the entire process as a Python application and set it up on a nightly loop. Every night, it would build an entire Hadoop cluster, from scratch, smoke test it, and report the results to the team. And it worked! Word started to spread among the organization and we were suddenly getting requests from users of our production cluster. They wanted to use REDstack to spin up a sandbox for them to use for Hadoop. Not only would it be more powerful, and sharable by multiple people on a team, it would look exactly like our production cluster because it uses all of the same configurations and assets.</p>\n\n<h3 id=\"opportunity\">Opportunity!</h3>\n<p>As a data engineer, wouldn\u2019t it be nice if I could have a kerberized sandbox environment that looked similar to a production cluster, was easy to work with and user friendly? This is what was possible with these environments, so we started to try and provide them to teams. It didn\u2019t work very well initially, users cloned the repo and ran it on their laptops and ran into all sorts of issues with dependencies and versions with Chef versions, ruby versions, gem versions, and python versions. There were simply too many dependencies to manage on on different environments, even with existing dependency management tools. We needed a way to hide all of the complexity and eliminate the need for users run anything on their computer.</p>\n\n<h3 id=\"the-full-stack-service\">The Full-Stack Service</h3>\n<p>This led us to the development of our full-stack cluster delivery service, Stacker. Stacker is an API running on top of a database, orchestrating REDstack deploys in threads and listening for requests over a front-end web page. Users simply submit a request on the website and a cluster will be delivered to them in about an hour. At this time, there have been more than 500 unique cluster requests and at least 30 teams are actively using REDstack as a part of their development process.</p>\n\n<h3 id=\"ongoing-development\">Ongoing Development</h3>\n<p>Over time, REDstack has evolved to include multiple types of Big Data clusters. We now provide Elasticsearch clusters as well as Druid in addition to the original Hadoop clusters. Our service continues to evolve with new releases and versions of the software, and additional ease-of-user work on our build in functions for user management and cluster administration.</p>\n\n<h4 id=\"about-the-author\">About the Author</h4>\n<p>Eric Krenz is a Senior Data Engineer on the Big Data Platform Team at Target.</p>\n\n  <p><a href=\"https://target.github.io/big%20data%20infrastructure/REDstack-Hadoop-as-a-Service\">REDstack</a> was originally published by Target Brands, Inc at <a href=\"https://target.github.io\">target tech</a> on December 07, 2017.</p>"
  },
  "Yelp": {
    "title": "Coordinator - The Gateway For Nrtsearch",
    "xmlUrl": "https://engineeringblog.yelp.com/feed.xml",
    "htmlUrl": "https://engineeringblog.yelp.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineeringblog.yelp.com/feed.xml",
      "value": "Coordinator - The Gateway For Nrtsearch"
    },
    "summary": "While we once used Elasticsearch at Yelp, we have since built a replacement called Nrtsearch. The benefits and motivations of this switch can be found in our blog post: Nrtsearch: Yelp\u2019s Fast, Scalable and Cost Effective Search Engine. However in this blog post, we will discuss the motivations behind building Nrtsearch Coordinator - a gateway for Nrtsearch clusters. We will also go over how Nrtsearch Coordinator adds sharding logic to Nrtsearch, handles scatter-gather queries, and adds support for dark/live launching cluster improvements. Motivations We traditionally used a gateway to call Elasticsearch, which provides metrics, isolation rate-limiting per client, and geo...",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineeringblog.yelp.com/feed.xml",
      "value": "While we once used Elasticsearch at Yelp, we have since built a replacement called Nrtsearch. The benefits and motivations of this switch can be found in our blog post: Nrtsearch: Yelp\u2019s Fast, Scalable and Cost Effective Search Engine. However in this blog post, we will discuss the motivations behind building Nrtsearch Coordinator - a gateway for Nrtsearch clusters. We will also go over how Nrtsearch Coordinator adds sharding logic to Nrtsearch, handles scatter-gather queries, and adds support for dark/live launching cluster improvements. Motivations We traditionally used a gateway to call Elasticsearch, which provides metrics, isolation rate-limiting per client, and geo..."
    },
    "published": "Fri, 06 Oct 2023 00:00:00 +0000",
    "published_parsed": [
      2023,
      10,
      6,
      0,
      0,
      0,
      4,
      279,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineeringblog.yelp.com/2023/10/coordinator-the-gateway-for-nrtsearch.html"
      }
    ],
    "link": "https://engineeringblog.yelp.com/2023/10/coordinator-the-gateway-for-nrtsearch.html",
    "id": "https://engineeringblog.yelp.com/2023/10/coordinator-the-gateway-for-nrtsearch.html",
    "guidislink": false,
    "authors": [
      {
        "name": "Luana Fragoso, Sarthak Nandi and Swetha Kannan, Software Engineers"
      }
    ],
    "author": "Luana Fragoso, Sarthak Nandi and Swetha Kannan, Software Engineers",
    "author_detail": {
      "name": "Luana Fragoso, Sarthak Nandi and Swetha Kannan, Software Engineers"
    },
    "previewimage": "http://engineeringblog.yelp.com/images/previews/coordinator-the-gateway-for-nrtsearch-preview.png",
    "authorimage": "http://engineeringblog.yelp.com/images/authors/darwin.png"
  },
  "HireArt": {
    "title": "Developing our first iOS App with React Native (pt 2) - User Auth",
    "xmlUrl": "http://code.hireart.com/feed.xml",
    "htmlUrl": "http://code.hireart.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://code.hireart.com/feed.xml",
      "value": "Developing our first iOS App with React Native (pt 2) - User Auth"
    },
    "links": [
      {
        "rel": "alternate",
        "href": "http://code.hireart.com/2016/03/22/react-native-user-login-and-fb-login/",
        "type": "text/html"
      }
    ],
    "link": "http://code.hireart.com/2016/03/22/react-native-user-login-and-fb-login/",
    "id": "http://code.hireart.com/2016/03/22/react-native-user-login-and-fb-login/",
    "guidislink": false,
    "published": "2016-03-22T00:00:00+00:00",
    "published_parsed": [
      2016,
      3,
      22,
      0,
      0,
      0,
      1,
      82,
      0
    ],
    "updated": "2016-03-23T18:51:12+00:00",
    "updated_parsed": [
      2016,
      3,
      23,
      18,
      51,
      12,
      2,
      83,
      0
    ],
    "summary": "<p>In this post, I will be going through how we setup Authentication for our HireArt Mobile App.  If you've missed our first post about why we chose React Native to develop our first iOS app, you can read about it <a href=\"http://code.hireart.com/2016/02/24/react-native-ios-app/\">here</a></p>\n\n<p>Before jumping in, I just want...</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "http://code.hireart.com/feed.xml",
      "value": "<p>In this post, I will be going through how we setup Authentication for our HireArt Mobile App.  If you've missed our first post about why we chose React Native to develop our first iOS app, you can read about it <a href=\"http://code.hireart.com/2016/02/24/react-native-ios-app/\">here</a></p>\n\n<p>Before jumping in, I just want...</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "http://code.hireart.com/feed.xml",
        "value": "<p>In this post, I will be going through how we setup Authentication for our HireArt Mobile App.  If you've missed our first post about why we chose React Native to develop our first iOS app, you can read about it <a href=\"http://code.hireart.com/2016/02/24/react-native-ios-app/\">here</a></p>\n\n<p>Before jumping in, I just want to address how we're handling saving to the local device and how we handle API calls.  We looked at a bunch of options including flux and redux, but found that they felt like overkill or didn't seem to solve our particular problem.  So we went with our own approach of a super simple API/Store.  The details of that implementation will be in another post, but for now we'll just assume that there's a module to handle API/Store which we can interact with, and the module is capable of making API calls to our Rails endpoints.</p>\n\n<p><img src=\"http://code.hireart.com/images/20160322/simple-diagram.png\" /></p>\n\n<p>You'll notice right away that this appears to break React's uni-directional flow of data.  However, I assure you that it does not.  When a view calls an action, that action may interact with the store, server, or both.  After which it can either update the state of the view that called it, store the return value to the device, or navigate to a different view.  At no point does the Action return a value to the View.</p>\n\n<p>We'll start with an overview of the views we use, the methods that support these views, and the react-native npm packages we use to make things easier.</p>\n\n<h2 id=\"views\">Views</h2>\n\n<p>We have 4 views dedicated to authentication:</p>\n\n<ol>\n<li><p><strong>Welcome.js</strong> - This is the main welcome page which conditionally displays login links if the user is not found/authenticated yet.</p></li>\n<li><p><strong>Authentication.js</strong> - The Sign In/Sign Up form lives here along with the FB Login button</p></li>\n<li><p><strong>FbRequirePassword.js</strong> - This view, if authenticated from FB and is an existing user, will prompt the user to enter their HireArt password to link to their FB account.</p></li>\n<li><p><strong>ForgotPassword.js</strong> - For users who forgot their passwords.  Prompts them to enter their email.</p></li>\n</ol>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>We've implemented 3 methods to make our authentication work:</p>\n\n<ol>\n<li><p><strong>getUser()</strong> - Checks local storeage for a user object, returns user if it exists</p></li>\n<li><p><strong>authenticate(userForm)</strong> - Invoked after SignIn or SignUp, will send the user info to our Rails endpoint.  If it gets a valid user in return, it calls <code>HandleAfterAuth()</code> with the user.</p></li>\n<li><p><strong>handleAfterAuth(user)</strong> -\nHandles navigation after successful authentication.  There are three possible outcomes:</p>\n\n<ul>\n<li>Existing User - navigate to Dashboard</li>\n<li>New User - navigate to Onboarding</li>\n<li>Facebook Login for Existing User - navigate to FbRequirePassword to link their FB account to their existing HA account.</li>\n</ul></li>\n</ol>\n\n<h2 id=\"npm-packages\">NPM Packages</h2>\n\n<ol>\n<li><p><strong>tcomb-form-native</strong> - really helpful in building forms with some basic validation and keyboard controls.  <a href=\"https://www.npmjs.com/package/tcomb-form-native\">https://www.npmjs.com/package/tcomb-form-native</a></p></li>\n<li><p><strong>react-native-router-flux</strong> - Greatly simplified navigation.  <a href=\"https://github.com/aksonov/react-native-router-flux\">https://github.com/aksonov/react-native-router-flux</a></p></li>\n<li><p><strong>react-native-simple-store</strong> - Saving and loading user data to the device was super easy with Simple Store.  <a href=\"https://www.npmjs.com/package/react-native-simple-store\">https://www.npmjs.com/package/react-native-simple-store</a></p></li>\n</ol>\n\n<h2 id=\"overall-diagram\">Overall Diagram</h2>\n\n<p>Now that we have a broad overview of the system, I've put together a diagram that shows how it all comes together.</p>\n\n<p>Here is an overly complicated diagram showing our authentication process:</p>\n\n<p><img src=\"http://code.hireart.com/images/20160322/login-diagram.png\" /></p>\n\n<p>The dotted lines indicate view navigation sequence, blues are JS modules, green indicates servers.</p>\n\n<h2 id=\"load-user\">Load User</h2>\n\n<p>Using Simple Store, this is quite trivial, just look for the user and if it exists, check to see if it has a valid auth token.</p>\n<pre class=\"highlight javascript\"><code><span class=\"nx\">Store</span><span class=\"p\">.</span><span class=\"nx\">get</span><span class=\"p\">(</span><span class=\"s1\">'user'</span><span class=\"p\">).</span><span class=\"nx\">then</span><span class=\"p\">((</span><span class=\"nx\">user</span><span class=\"p\">)</span><span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nx\">_isUserValid</span><span class=\"p\">(</span><span class=\"nx\">user</span><span class=\"p\">)</span>\n<span class=\"p\">})</span>\n</code></pre>\n\n<h2 id=\"sign-up/sign-in-form\">Sign Up/Sign In Form</h2>\n\n<p>In the even there is no user, we setup a form using tcomb form</p>\n\n<p>requiring tcomb form</p>\n<pre class=\"highlight javascript\"><code><span class=\"kd\">var</span> <span class=\"nx\">t</span> <span class=\"o\">=</span> <span class=\"nx\">require</span><span class=\"p\">(</span><span class=\"s1\">'tcomb-form-native'</span><span class=\"p\">)</span>\n</code></pre>\n\n<p>setting up form structure</p>\n<pre class=\"highlight javascript\"><code><span class=\"kd\">var</span> <span class=\"nx\">signInUser</span> <span class=\"o\">=</span> <span class=\"nx\">t</span><span class=\"p\">.</span><span class=\"nx\">struct</span><span class=\"p\">({</span>\n  <span class=\"na\">email</span><span class=\"p\">:</span> <span class=\"nx\">t</span><span class=\"p\">.</span><span class=\"nx\">Str</span><span class=\"p\">,</span>\n  <span class=\"na\">password</span><span class=\"p\">:</span> <span class=\"nx\">t</span><span class=\"p\">.</span><span class=\"nx\">Str</span><span class=\"p\">,</span>\n<span class=\"p\">})</span>\n\n<span class=\"kd\">var</span> <span class=\"nx\">signUpUser</span> <span class=\"o\">=</span> <span class=\"nx\">t</span><span class=\"p\">.</span><span class=\"nx\">struct</span><span class=\"p\">({</span>\n  <span class=\"na\">first_name</span><span class=\"p\">:</span> <span class=\"nx\">t</span><span class=\"p\">.</span><span class=\"nx\">Str</span><span class=\"p\">,</span>\n  <span class=\"na\">last_name</span><span class=\"p\">:</span> <span class=\"nx\">t</span><span class=\"p\">.</span><span class=\"nx\">Str</span><span class=\"p\">,</span>\n  <span class=\"na\">email</span><span class=\"p\">:</span> <span class=\"nx\">t</span><span class=\"p\">.</span><span class=\"nx\">Str</span><span class=\"p\">,</span>\n  <span class=\"na\">password</span><span class=\"p\">:</span> <span class=\"nx\">t</span><span class=\"p\">.</span><span class=\"nx\">Str</span><span class=\"p\">,</span>\n<span class=\"p\">})</span>\n</code></pre>\n\n<p>setting form options and keyboard restrictions</p>\n<pre class=\"highlight javascript\"><code><span class=\"kd\">var</span> <span class=\"nx\">options</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n  <span class=\"na\">auto</span><span class=\"p\">:</span> <span class=\"s1\">'placeholders'</span><span class=\"p\">,</span>\n  <span class=\"na\">stylesheet</span><span class=\"p\">:</span> <span class=\"nx\">LoginFormStyle</span><span class=\"p\">,</span>\n  <span class=\"na\">fields</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"na\">password</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"na\">password</span><span class=\"p\">:</span> <span class=\"kc\">true</span><span class=\"p\">,</span>\n      <span class=\"na\">secureTextEntry</span><span class=\"p\">:</span> <span class=\"kc\">true</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"na\">email</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"na\">keyboardType</span><span class=\"p\">:</span> <span class=\"s1\">'email-address'</span><span class=\"p\">,</span>\n      <span class=\"na\">autoCorrect</span><span class=\"p\">:</span> <span class=\"kc\">false</span><span class=\"p\">,</span>\n      <span class=\"na\">autoCapitalize</span><span class=\"p\">:</span> <span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"na\">first_name</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"na\">autoCorrect</span><span class=\"p\">:</span> <span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"na\">last_name</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"na\">autoCorrect</span><span class=\"p\">:</span> <span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n  <span class=\"p\">},</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n<p>The form itself in <code>render()</code></p>\n<pre class=\"highlight html\"><code><span class=\"nt\">&lt;Form</span>\n  <span class=\"na\">ref=</span><span class=\"s\">\"form\"</span>\n  <span class=\"na\">type=</span><span class=\"s\">{formType}</span>\n  <span class=\"na\">options=</span><span class=\"s\">{options}</span>\n  <span class=\"na\">value=</span><span class=\"s\">{this.state.formValue}</span>\n  <span class=\"na\">onChange=</span><span class=\"s\">{this.onChange.bind(this)}</span>\n  <span class=\"nt\">/&gt;</span>\n<span class=\"nt\">&lt;TouchableHighlight</span>\n  <span class=\"na\">style=</span><span class=\"s\">{[Styles.buttonInset,</span> <span class=\"err\">{</span><span class=\"na\">marginTop:</span> <span class=\"na\">7</span><span class=\"err\">}]}</span>\n  <span class=\"na\">onPress=</span><span class=\"s\">{this.handleSubmit.bind(this)}</span>\n  <span class=\"na\">underlayColor=</span><span class=\"s\">'#E3A90C'</span><span class=\"nt\">&gt;</span>\n  <span class=\"nt\">&lt;Text</span> <span class=\"na\">style=</span><span class=\"s\">{Styles.buttonText}</span><span class=\"nt\">&gt;</span>{submitText}<span class=\"nt\">&lt;/Text&gt;</span>\n<span class=\"nt\">&lt;/TouchableHighlight&gt;</span>\n</code></pre>\n\n<p>When the form is submitted</p>\n<pre class=\"highlight javascript\"><code><span class=\"nx\">handleSubmit</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"kd\">var</span> <span class=\"nx\">value</span> <span class=\"o\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nx\">refs</span><span class=\"p\">.</span><span class=\"nx\">form</span><span class=\"p\">.</span><span class=\"nx\">getValue</span><span class=\"p\">()</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">value</span> <span class=\"o\">&amp;&amp;</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nx\">passwordLengthCheck</span><span class=\"p\">())</span> <span class=\"p\">{</span>\n    <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nx\">setState</span><span class=\"p\">({</span>\n      <span class=\"na\">isLoading</span><span class=\"p\">:</span> <span class=\"kc\">true</span><span class=\"p\">,</span>\n    <span class=\"p\">})</span>\n    <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nx\">_authenticate</span><span class=\"p\">()</span>\n  <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"k\">this</span><span class=\"p\">.</span><span class=\"nx\">passwordLengthCheck</span><span class=\"p\">())</span> <span class=\"p\">{</span>\n      <span class=\"nx\">AlertIOS</span><span class=\"p\">.</span><span class=\"nx\">alert</span><span class=\"p\">(</span><span class=\"s1\">'Your password needs to be at least 8 characters long.'</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n<p>Handling authentication</p>\n<pre class=\"highlight javascript\"><code><span class=\"nx\">_authenticate</span><span class=\"p\">(</span><span class=\"nx\">parent</span><span class=\"p\">,</span> <span class=\"nx\">user</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">var</span> <span class=\"nx\">obj</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"na\">method</span><span class=\"p\">:</span> <span class=\"s1\">'POST'</span><span class=\"p\">,</span>\n    <span class=\"na\">headers</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"s1\">'Accept'</span><span class=\"p\">:</span> <span class=\"s1\">'application/json'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'Content-Type'</span><span class=\"p\">:</span> <span class=\"s1\">'application/json'</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"na\">body</span><span class=\"p\">:</span> <span class=\"nx\">JSON</span><span class=\"p\">.</span><span class=\"nx\">stringify</span><span class=\"p\">({</span>\n      <span class=\"na\">user</span><span class=\"p\">:</span> <span class=\"nx\">user</span><span class=\"p\">,</span>\n    <span class=\"p\">}),</span>\n  <span class=\"p\">}</span>\n  <span class=\"kd\">var</span> <span class=\"nx\">url</span> <span class=\"o\">=</span> <span class=\"c1\">// YOUR ENDPOINT</span>\n  <span class=\"nx\">fetch</span><span class=\"p\">(</span><span class=\"nx\">url</span><span class=\"p\">,</span> <span class=\"nx\">obj</span><span class=\"p\">)</span>\n    <span class=\"p\">.</span><span class=\"nx\">then</span><span class=\"p\">((</span><span class=\"nx\">res</span><span class=\"p\">)</span><span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n      <span class=\"k\">return</span> <span class=\"nx\">res</span><span class=\"p\">.</span><span class=\"nx\">json</span><span class=\"p\">()</span>\n    <span class=\"p\">}).</span><span class=\"nx\">then</span><span class=\"p\">((</span><span class=\"nx\">json</span><span class=\"p\">)</span><span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n      <span class=\"nx\">_handleAfterAuthenticate</span><span class=\"p\">(</span><span class=\"nx\">parent</span><span class=\"p\">,</span> <span class=\"nx\">json</span><span class=\"p\">,</span> <span class=\"nx\">user</span><span class=\"p\">)</span>\n    <span class=\"p\">}).</span><span class=\"k\">catch</span><span class=\"p\">((</span><span class=\"nx\">error</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n      <span class=\"nx\">console</span><span class=\"p\">.</span><span class=\"nx\">warn</span><span class=\"p\">(</span><span class=\"nx\">error</span><span class=\"p\">)</span>\n    <span class=\"p\">})</span>\n    <span class=\"p\">.</span><span class=\"nx\">done</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n<p>The <code>handleAfterAuthenticate()</code> method simply saves the user data to the Store and decides which view to show next and navigates to it:  Dashboard if existing user, OnBoarding if new user.</p>\n\n<h2 id=\"facebook-login-integration\">Facebook Login Integration</h2>\n\n<p>We used <a href=\"https://github.com/magus/react-native-facebook-login\">react-native-facebook-login</a> which worked great.  It took a few tries to get it setup properly and there are a lot of steps which I won't repeat here.  Just make sure you follow every step and if it didn't work, start from the beginning.</p>\n\n<p>Thanks for reading and keep an eye out for my next entry on Fetch/API!</p>\n\n<hr />\n\n<p><img src=\"http://code.hireart.com/images/tom-profile.png\" /></p>\n\n<p>Tom Tang leads mobile development at HireArt.  Feel free to reach out: <a href=\"mailto:tom@hireart.com\">tom@hireart.com</a></p>"
      }
    ]
  },
  "Dropbox": {
    "title": "From AI to sustainability, why our latest data centers use 400G networking",
    "xmlUrl": "https://blogs.dropbox.com/tech/feed/",
    "htmlUrl": "https://blogs.dropbox.com/tech/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://dropbox.tech/feed",
      "value": "From AI to sustainability, why our latest data centers use 400G networking"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://dropbox.tech/infrastructure/from-ai-to-sustainability-why-our-latest-data-centers-use-400g-networking"
      }
    ],
    "link": "https://dropbox.tech/infrastructure/from-ai-to-sustainability-why-our-latest-data-centers-use-400g-networking",
    "authors": [
      {
        "name": "Daniel Parker and Amit Chudasma"
      }
    ],
    "author": "Daniel Parker and Amit Chudasma",
    "author_detail": {
      "name": "Daniel Parker and Amit Chudasma"
    },
    "tags": [
      {
        "term": "Hardware",
        "scheme": null,
        "label": null
      },
      {
        "term": "Traffic",
        "scheme": null,
        "label": null
      },
      {
        "term": "AI",
        "scheme": null,
        "label": null
      },
      {
        "term": "Infrastructure",
        "scheme": null,
        "label": null
      },
      {
        "term": "data center",
        "scheme": null,
        "label": null
      },
      {
        "term": "Networking",
        "scheme": null,
        "label": null
      },
      {
        "term": "400G",
        "scheme": null,
        "label": null
      },
      {
        "term": "sustainability",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://dropbox.tech/infrastructure/from-ai-to-sustainability-why-our-latest-data-centers-use-400g-networking",
    "guidislink": false,
    "summary": "",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://dropbox.tech/feed",
      "value": ""
    },
    "published": "Tue, 14 Nov 2023 06:00:00 -0800",
    "published_parsed": [
      2023,
      11,
      14,
      14,
      0,
      0,
      1,
      318,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://dropbox.tech/feed",
        "value": "<div class=\"aem-Grid aem-Grid--12 aem-Grid--default--12 \">\n    \n    <div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>At Dropbox, AI-powered tools and features are quickly transforming the way our customers find, organize, and understand their data. <a href=\"https://dropbox.com/dash\" target=\"_blank\">Dropbox Dash</a> brings AI-powered universal search to all your apps, browser tabs, and cloud docs, while Dropbox AI can summarize and answer questions about the content of your files. To meet the bandwidth requirements of <a href=\"https://blog.dropbox.com/topics/company/updated-tools-new-plans-and-web-redesign\" target=\"_blank\">new and future AI workloads</a>?and stay committed to our <a href=\"https://blog.dropbox.com/topics/company/dropbox-sets-sustainability-goals-for-2030\" target=\"_blank\">sustainability goals</a>?the Dropbox networking team recently designed and launched our first data center architecture using highly efficient, cutting edge 400 gigabit per second (400G) ethernet technology.</p>\n<p>400G uses a combination of advanced technologies?such as digital signal processing chips capable of pulse-amplitude modulation and forward error correction?to achieve four times the data rate of its predecessor, 100G, through a single link. Because a single 400G port along with optics is more cost efficient and consumes less power than four individual 100G ports, adopting 400G has enabled us to effectively quadruple the bandwidth in our newest data center while significantly reducing our power usage and cabling footprint. Our new design also streamlines the way our data centers connect to the network backbone, allowing us to realize further cost and energy savings by consolidating what was previously three separate data center interconnect device roles into one.</p>\n<p>400G is a relatively new technology, and has not been as widely adopted by the industry as 100G?though that?s beginning to change. In this story, we?ll discuss why we chose to embark on our 400G journey ahead of the pack, review the design requirements and architectural details of our first 400G datacenter, and touch on some of the challenges faced as early adopters and lessons learned. We?ll conclude with our future plans for continuing to build with this exciting new technology.</p>\n\n</div>\n<div class=\"image c04-image aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-image image cq-dd-image  \">\n    <figure class=\"dr-margin-0 dr-display-inline-block\">\n        \n            \n    \n\n        \n\n        \n        \n        \n\n        \n        \n        \n\n        <!--optimized image webp-->\n        \n\n        \n        <!-- <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram1.jpg 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram1.jpg\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1263\"\n             data-sly-attribute.height=\"578\"\n             data-aem-asset-id=\"31f12ffb-19f4-4629-8b80-6bc85d69fb08:Diagram1.jpg\"\n             data-trackable=\"true\" />\n        <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram1.jpg 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram1.jpg\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1263\"\n             data-sly-attribute.height=\"578\"\n             data-aem-asset-id=\"31f12ffb-19f4-4629-8b80-6bc85d69fb08:Diagram1.jpg\"\n             data-trackable=\"true\" /> -->\n\n        \n         \n        <img alt=\"\" height=\"578\" src=\"https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram1.jpg/_jcr_content/renditions/Diagram1.webp\" width=\"1263\" />\n    \n\n            <figcaption class=\"dr-typography-t5 dr-color-ink-60 dr-image-rte\"><p style=\"text-align: center;\">A high-level overview of our 400G network architecture</p>\n</figcaption>\n        \n    </figure>\n</div></div>\n<div class=\"section aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-article-content__section\" id=\"-the-case-for-400g\">\n    <h2 class=\"dr-article-content__section-title\"> The case for 400G</h2>\n</div>\n</div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>Dropbox has come a long way since launching as a simple file storage company in 2008. We are now a global cloud content platform at scale, providing an AI-powered, multi-product portfolio to our more than 700 million registered users, while also securely storing more than 800 billion pieces of content.\u00a0</p>\n<p>The Dropbox platform runs on a hybrid cloud infrastructure that encompasses our data centers, global backbone, public cloud, and <a href=\"https://dropbox.tech/infrastructure/dropbox-traffic-infrastructure-edge-network\" target=\"_blank\">edge points-of-presence (POPs)</a>. To efficiently meet our growing resource needs, the Dropbox hardware team is continuously redesigning our <a href=\"https://dropbox.tech/infrastructure/sixth-generation-server-hardware\" target=\"_blank\">high performance server racks</a> using the latest state-of-the-art components. Recently, these designs reached a critical density where the bandwidth requirements of a server rack are expected to exceed the capabilities of 100G ethernet. For example, our upcoming seventh generation storage servers will require 200G network interface cards (NICs) and 1.6Tb/s of uplink bandwidth per rack in order to meet their data replication SLAs!\u00a0</p>\n\n</div>\n<div class=\"image c04-image aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-image image cq-dd-image  \">\n    <figure class=\"dr-margin-0 dr-display-inline-block\">\n        \n            \n    \n\n        \n\n        \n        \n        \n\n        \n        \n        \n\n        <!--optimized image webp-->\n        \n\n        \n        <!-- <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram2-720xauto.png 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram2-720xauto.png\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1440\"\n             data-sly-attribute.height=\"912\"\n             data-aem-asset-id=\"93ee6563-d2d1-42d3-91e6-fe8f7654633c:Diagram2-720xauto.png\"\n             data-trackable=\"true\" />\n        <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram2-720xauto.png 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram2-720xauto.png\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1440\"\n             data-sly-attribute.height=\"912\"\n             data-aem-asset-id=\"93ee6563-d2d1-42d3-91e6-fe8f7654633c:Diagram2-720xauto.png\"\n             data-trackable=\"true\" /> -->\n\n        \n         \n        <img alt=\"\" height=\"912\" src=\"https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram2-720xauto.png/_jcr_content/renditions/Diagram2-720xauto.webp\" width=\"1440\" />\n    \n\n            <figcaption class=\"dr-typography-t5 dr-color-ink-60 dr-image-rte\"><p style=\"text-align: center;\">The Dropbox platform?s hybrid cloud infrastructure. Our first 400G data center is located in the US-WEST region</p>\n</figcaption>\n        \n    </figure>\n</div></div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>While we considered trying to scale our 100G-based architecture by using bigger devices with a larger numbers of 100G links, we calculated that, for us, this would be wasteful from a power, cabling, and materials standpoint. We anticipated an inevitable need to upgrade to 400G within the next 24 months at most, and deemed it <a href=\"https://dropbox.tech/infrastructure/making-dropbox-data-centers-carbon-neutral\" target=\"_blank\">contrary to our sustainability goals</a> to ship a bandaid 100G architecture comprised of hundreds of devices and thousands of optics, only for them to become e-waste within a year or two.</p>\n<p>Our decision to adopt 400G stemmed from hardware advancements made by our server design team, increasing levels of video and images uploaded to Dropbox, and the growing adoption of our latest product experiences, <a href=\"https://www.dropbox.com/dash\" target=\"_blank\">Dash</a>, <a href=\"https://www.dropbox.com/capture\" target=\"_blank\">Capture</a>, and <a href=\"https://www.dropbox.com/replay\" target=\"_blank\">Replay</a>. Our hardware and storage teams are in the process of finalizing the manufacture of servers that will require network interface speeds of up to 200G per host, and throughput requirements that greatly exceed the 3.2Tb/s switching rate of our current-generation top-of-rack switch.</p>\n<p>Our final design produced efficiency improvements at four sections of our network: the fabric core, the connections to the top-of-rack switches, the data center interconnect routers, and the optical transport shelves.</p>\n\n</div>\n<div class=\"section aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-article-content__section\" id=\"-fabric-core-zero-optic-energy-efficient\">\n    <h2 class=\"dr-article-content__section-title\"> Fabric core: Zero-optic, energy efficient</h2>\n</div>\n</div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>At the heart of our 400G data center design, we retained our <a href=\"https://dropbox.tech/infrastructure/the-scalable-fabric-behind-our-growing-data-center-network\" target=\"_blank\">production-proven quad-plane fabric topology</a>, updated to use 12.8T 32x400G switches in the place of 3.2T 32x100G devices. Sticking with a fabric architecture allowed us to retain the desirable features of our existing 100G design?non-blocking oversubscription rates, small failure domains, and scale-on-demand modularity?while increasing its speed by a factor of four.\u00a0</p>\n<p>Crucially, we were able to do this without expanding our power requirements. We accomplished this by leveraging 400G direct attach copper (DAC) cabling for the dense spine-leaf interconnection links. 400G-DAC is an electrically passive cable that requires virtually no additional power or cooling, so by choosing it we were able to fully offset the increased energy requirements of the faster chips powering the 400G switches themselves.</p>\n<p>Comparing power usage metrics from our new 400G fabric core with our legacy 100G data center confirms that the 400G fabric is 3x more energy efficient per Gigabit.</p>\n\n</div>\n<div class=\"image c04-image aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-image image cq-dd-image  \">\n    <figure class=\"dr-margin-0 dr-display-inline-block\">\n        \n            \n    \n\n        \n\n        \n        \n        \n\n        \n        \n        \n\n        <!--optimized image webp-->\n        \n\n        \n        <!-- <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram3.jpg 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram3.jpg\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1138\"\n             data-sly-attribute.height=\"373\"\n             data-aem-asset-id=\"cfbc99e5-2b1b-4ffb-a2cf-aa78fc58858f:Diagram3.jpg\"\n             data-trackable=\"true\" />\n        <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram3.jpg 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram3.jpg\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1138\"\n             data-sly-attribute.height=\"373\"\n             data-aem-asset-id=\"cfbc99e5-2b1b-4ffb-a2cf-aa78fc58858f:Diagram3.jpg\"\n             data-trackable=\"true\" /> -->\n\n        \n         \n        <img alt=\"\" height=\"373\" src=\"https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram3.jpg/_jcr_content/renditions/Diagram3.webp\" width=\"1138\" />\n    \n\n            <figcaption class=\"dr-typography-t5 dr-color-ink-60 dr-image-rte\"><p style=\"text-align: center;\">We based the core of our 400G fabric on the same quad-plane fabric architecture we?ve successfully deployed in various iterations for our past five 100G data center builds, but updated it to use 32x400G devices and extremely energy-efficient 400G-DAC cabling</p>\n</figcaption>\n        \n    </figure>\n</div></div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>The drawbacks of 400G-DAC were its short three meter range and wider cable thickness. We solved for these constraints by meticulously planning (and mocking up in our lab) different permutations of device placement, port assignments, and cable management strategies until we reached an optimal configuration. This culminated in what we call our ?odd-even split? main distribution frame (MDF) design, pictured below.</p>\n\n</div>\n<div class=\"image c04-image aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-image image cq-dd-image  \">\n    <figure class=\"dr-margin-0 dr-display-inline-block\">\n        \n            \n    \n\n        \n\n        \n        \n        \n\n        \n        \n        \n\n        <!--optimized image webp-->\n        \n\n        \n        <!-- <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram4-720xauto.png 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram4-720xauto.png\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1440\"\n             data-sly-attribute.height=\"1298\"\n             data-aem-asset-id=\"3af158c8-beb0-4cc5-87ef-790b9d583d9c:Diagram4-720xauto.png\"\n             data-trackable=\"true\" />\n        <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram4-720xauto.png 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram4-720xauto.png\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1440\"\n             data-sly-attribute.height=\"1298\"\n             data-aem-asset-id=\"3af158c8-beb0-4cc5-87ef-790b9d583d9c:Diagram4-720xauto.png\"\n             data-trackable=\"true\" /> -->\n\n        \n         \n        <img alt=\"\" height=\"1298\" src=\"https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram4-720xauto.png/_jcr_content/renditions/Diagram4-720xauto.webp\" width=\"1440\" />\n    \n\n            <figcaption class=\"dr-typography-t5 dr-color-ink-60 dr-image-rte\"><p style=\"text-align: center;\">A simplified version of our 400G data center MDF racks using 400G-DAC interconnects. Spine switches are stacked in the center rack, connected to leaf switches that are striped evenly between the adjacent racks. Only DAC cables to the first leaf switch in each of the odd (left) and even (right) racks are pictured. This design was repeated four times for each of the data center?s four parallel fabric planes</p>\n</figcaption>\n        \n    </figure>\n</div></div>\n<div class=\"section aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-article-content__section\" id=\"-top-of-rack-interconnect-backwards-compatibility\">\n    <h2 class=\"dr-article-content__section-title\"> Top-of-rack interconnect: Backwards compatibility</h2>\n</div>\n</div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>Another key architectural component we needed to consider was the optical fiber plant which connects the top-of-rack switches in the data hall to the 400G fabric core. We designed these links based on three requirements:</p>\n<ul>\n<li>The need to support connectivity to both our existing 100G as well as next generation 400G top-of-rack switches</li>\n<li>The ability to extend these runs up to 500 meters to accommodate multi-megawatt-scale deployments</li>\n<li>The desire to provide the most reliable infrastructure while optimizing power usage and materials cost</li>\n</ul>\n<p>After testing various 400G transceivers in this role, we selected the 400G-DR4 optic, which provided the best fit for the three requirements mentioned above:</p>\n<ul>\n<li>400G-DR4 can support our existing 100G top-of-rack switches by fanning out to 4x100G-DR links. Its built-in digital signal processor chip is able to convert between 400G and 100G signals without imposing any additional computational costs on the switches themselves.</li>\n<li>The 400G-DR4 optic has a max range of 500 meters, which meets the distance requirements of even our largest data center facilities.</li>\n<li>At 8 watts of max power draw per optic, 400G-DR4 is more energy efficient than 4x100G-SR4 optics at 2.5 watts (2.5 * 4 = 10W). 400G-DR4 also runs over single mode fiber, which requires 30% less energy and materials to manufacture than the multi-mode fiber we?ve used in our previous generation 100G architectures.</li>\n</ul>\n\n</div>\n<div class=\"section aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-article-content__section\" id=\"-data-center-interconnect-enhanced-efficiency-scalability\">\n    <h2 class=\"dr-article-content__section-title\"> Data center interconnect: Enhanced efficiency, scalability</h2>\n</div>\n</div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>The data center interconnect (DI) layer has been completely revamped to reflect updates in both bandwidth density and a more powerful, feature-filled networking tier. Today, DI traffic patterns consist of:\u00a0</p>\n<ul>\n<li><b>Cross-datacenter traffic</b> between data centers\u00a0</li>\n<li><b>External traffic </b>between data centers and POPs, such as Dropbox customers, cloud storage providers, or corporate networks</li>\n</ul>\n<p>Previously, the network used distinct tiers to manage these traffic types?one tier for cross-datacenter traffic and another tier for external traffic between data centers and POPs. This involved three separate networking devices, pictured below.</p>\n\n</div>\n<div class=\"image c04-image aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-image image cq-dd-image  \">\n    <figure class=\"dr-margin-0 dr-display-inline-block\">\n        \n            \n    \n\n        \n\n        \n        \n        \n\n        \n        \n        \n\n        <!--optimized image webp-->\n        \n\n        \n        <!-- <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram5-720xauto.png 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram5-720xauto.png\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1440\"\n             data-sly-attribute.height=\"1290\"\n             data-aem-asset-id=\"1e302615-4cde-4c47-8fe9-1d1b246e18aa:Diagram5-720xauto.png\"\n             data-trackable=\"true\" />\n        <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram5-720xauto.png 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram5-720xauto.png\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1440\"\n             data-sly-attribute.height=\"1290\"\n             data-aem-asset-id=\"1e302615-4cde-4c47-8fe9-1d1b246e18aa:Diagram5-720xauto.png\"\n             data-trackable=\"true\" /> -->\n\n        \n         \n        <img alt=\"\" height=\"1290\" src=\"https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram5-720xauto.png/_jcr_content/renditions/Diagram5-720xauto.webp\" width=\"1440\" />\n    \n\n            <figcaption class=\"dr-typography-t5 dr-color-ink-60 dr-image-rte\"><p style=\"text-align: center;\">Our old data center interconnect design</p>\n</figcaption>\n        \n    </figure>\n</div></div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>400G technology enabled us to combine these three devices into a single data center interconnect. At the same time, features such as class-based forwarding?which wasn?t available during the initial tiered design?made it possible to use quality-of-service markings to logically separate traffic over different label-switched paths with the appropriate priorities.</p>\n\n</div>\n<div class=\"image c04-image aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-image image cq-dd-image  \">\n    <figure class=\"dr-margin-0 dr-display-inline-block\">\n        \n            \n    \n\n        \n\n        \n        \n        \n\n        \n        \n        \n\n        <!--optimized image webp-->\n        \n\n        \n        <!-- <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram6-720xauto.png 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram6-720xauto.png\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1440\"\n             data-sly-attribute.height=\"1174\"\n             data-aem-asset-id=\"a1375c8d-310b-4aad-afd6-751e1942c36a:Diagram6-720xauto.png\"\n             data-trackable=\"true\" />\n        <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram6-720xauto.png 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram6-720xauto.png\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1440\"\n             data-sly-attribute.height=\"1174\"\n             data-aem-asset-id=\"a1375c8d-310b-4aad-afd6-751e1942c36a:Diagram6-720xauto.png\"\n             data-trackable=\"true\" /> -->\n\n        \n         \n        <img alt=\"\" height=\"1174\" src=\"https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram6-720xauto.png/_jcr_content/renditions/Diagram6-720xauto.webp\" width=\"1440\" />\n    \n\n            <figcaption class=\"dr-typography-t5 dr-color-ink-60 dr-image-rte\"><p style=\"text-align: center;\">Our new data center interconnect design</p>\n</figcaption>\n        \n    </figure>\n</div></div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>The optimized DI tier offers multiple advantages:</p>\n<ul>\n<li>There is a 60% reduction in the number of devices employed at the tier, resulting in notable improvements in space utilization, energy efficiency, and device cost savings, thereby enhancing the network's environmental and economic sustainability.</li>\n<li>The new architecture leverages MPLS RSVP TE to replace ECMP, making the data center edge bandwidth-aware, thereby boosting resiliency and efficiency.</li>\n<li>New architecture allows us to streamline routing by incorporating route aggregation, community tags, and advertising only the default route down to the fabric.</li>\n<li>The new DI tier seamlessly maintains backward compatibility with 100G-based hardware and technology, enabling us to upgrade specific parts of the network while still leveraging the value of our existing 100G hardware investments.</li>\n</ul>\n<p>Furthermore, the adoption of 400G hardware unlocks the potential for the DI to scale up to eight times its current maximum capacity, paving the way for future expansion and adaptability. This comprehensive reimagining of the DI marks a significant stride towards an optimized architecture that prioritizes efficiency, scalability, and reliability.</p>\n\n</div>\n<div class=\"section aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-article-content__section\" id=\"-optical-transport-backbone-connectivity\">\n    <h2 class=\"dr-article-content__section-title\"> Optical transport: Backbone connectivity</h2>\n</div>\n</div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>The optical transport tier is a dense wavelength division multiplexing system (DWDM) that is responsible for all data plane connectivity between the data center and the backbone. Utilizing two strands of fiber optics between the data center and each backbone POP in the metro, the new architecture provides two 6.4 Tb/s tranches of completely diverse network capacity to the data center, for a total of 12.8 Tb/s of available capacity. The system can scale up to 76.8 Tb/s (38.4 Tb/s diverse) before additional dark fiber is required.</p>\n<p>In comparison, the largest capacity a pair of fiber can carry <i>without</i> this DWDM system is 400 Gb/s.</p>\n\n</div>\n<div class=\"image c04-image aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-image image cq-dd-image  \">\n    <figure class=\"dr-margin-0 dr-display-inline-block\">\n        \n            \n    \n\n        \n\n        \n        \n        \n\n        \n        \n        \n\n        <!--optimized image webp-->\n        \n\n        \n        <!-- <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram7.jpg 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram7.jpg\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1173\"\n             data-sly-attribute.height=\"282\"\n             data-aem-asset-id=\"118dbf24-fda2-422d-b766-f5ca8c3819b6:Diagram7.jpg\"\n             data-trackable=\"true\" />\n        <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram7.jpg 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram7.jpg\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1173\"\n             data-sly-attribute.height=\"282\"\n             data-aem-asset-id=\"118dbf24-fda2-422d-b766-f5ca8c3819b6:Diagram7.jpg\"\n             data-trackable=\"true\" /> -->\n\n        \n         \n        <img alt=\"\" height=\"282\" src=\"https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/Diagram7.jpg/_jcr_content/renditions/Diagram7.webp\" width=\"1173\" />\n    \n\n            <figcaption class=\"dr-typography-t5 dr-color-ink-60 dr-image-rte\"><p style=\"text-align: center;\">One of the two 6.4 Tb/s diverse data center uplinks spans</p>\n</figcaption>\n        \n    </figure>\n</div></div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>New to the optical tier in this generation is the use of 800 Gb/s tuned waves (versus 250 Gb/s in the previous generation) which allows for greatly increased density and significantly lower cost-per-gigabit compared to previous deployments. Additionally, this tier was engineered to afford significant flexibility in the deployment of 100G/400G client links. The multi-faceted nature of this architecture enabled Dropbox to adapt to unexpected delays in equipment deliveries due to commodity shortages, ensuring on-time turn-up of our 400G data center.</p>\n\n</div>\n<div class=\"section aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-article-content__section\" id=\"-what-we-learned\">\n    <h2 class=\"dr-article-content__section-title\"> What we learned</h2>\n</div>\n</div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>Since its launch in December 2022, our first 400G data center has been serving Dropbox customers at blazingly fast speeds, with additional facilities slated to come online before the end of 2023. But as with any new technological development, adopting 400G forced us to overcome new obstacles and chart new paths along the way.\u00a0</p>\n<p>Here are some lessons learned from our multi-year journey to this point:</p>\n<ul>\n<li><b>Meticulously test all components. </b>Since every 400G router, switch, cable, and optic in our design was one of the first of its kind to be manufactured, our team recognized the need to evaluate each product?s ability to perform and interoperate in a multi-vendor architecture. To this end, we designed a purpose-built 400G test lab equipped with a packet generator capable of emulating future-scale workloads, and physically and logically stress-tested each component.</li>\n<li><b>Ensure backwards compatibility at the 400G-100G boundary. </b>We discovered in testing that a 100G top-of-rack switch we deploy extensively in our production environment was missing support for the 100G-DR optic we?d selected to connect our existing 100G top-of-rack switches to the new 400G fabric. Fortunately, we were able to surface the issue early enough to request a patch from the vendor to add support for this optic.</li>\n<li><b>Have contingency plans for supply chain headwinds. </b>During our design and build cycle for 400G, unpredictability in the global supply chain was an unfortunate reality. We mitigated these risks by qualifying multiple sources for each component in our design. When the vendor supplying our 400G DI devices backed out one month before launch due to a chip shortage, the team rapidly developed a contingency plan. Because 400G QSFP-DD ports are backwards compatible with 100G QSFP28 optics, we devised a temporary interconnect strategy using 100G devices in the DI role until their permanent 400G replacements could be swapped in.</li>\n</ul>\n\n</div>\n<div class=\"section aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-article-content__section\" id=\"-whats-next\">\n    <h2 class=\"dr-article-content__section-title\"> What?s next</h2>\n</div>\n</div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p>The successful launch of our first 400G data center has given us the confidence needed to continue rolling out 400G technology to other areas of the Dropbox production network. 400G data centers based on this same design are slated to launch in US-CENTRAL and US-EAST by the end of 2023. Test racks of our 7th generation servers with 400G top-of-rack switches are already running in US-WEST and will be deployed at scale in early 2024. We also plan on extending 400G to the Dropbox backbone throughout 2024 and 2025.</p>\n<p>Finally, an emerging long-haul optical technology called 400G-ZR+ promises to deliver even greater efficiency gains. With 400G-ZR+, we can replace our existing 12-foot-high optical transport shelves with a pluggable transceiver the size of a stick of gum!\u00a0\u00a0</p>\n\n</div>\n<div class=\"image c04-image aem-GridColumn aem-GridColumn--default--12\">\n<div class=\"dr-image image cq-dd-image  \">\n    <figure class=\"dr-margin-0 dr-display-inline-block\">\n        \n            \n    \n\n        \n\n        \n        \n        \n\n        \n        \n        \n\n        <!--optimized image webp-->\n        \n\n        \n        <!-- <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/danielking-400g-zrplus.jpg 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/danielking-400g-zrplus.jpg\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1280\"\n             data-sly-attribute.height=\"920\"\n             data-aem-asset-id=\"bcb6d405-833f-4177-b6df-71579d418617:danielking-400g-zrplus.jpg\"\n             data-trackable=\"true\" />\n        <img data-sly-test.highRes=\"false\"\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/danielking-400g-zrplus.jpg 2x,  1x\"\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/danielking-400g-zrplus.jpg\"\n             aria-hidden=\"\"\n             alt=\"\"\n             class=\"\"\n             data-sly-attribute.width=\"1280\"\n             data-sly-attribute.height=\"920\"\n             data-aem-asset-id=\"bcb6d405-833f-4177-b6df-71579d418617:danielking-400g-zrplus.jpg\"\n             data-trackable=\"true\" /> -->\n\n        \n         \n        <img alt=\"\" height=\"920\" src=\"https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/danielking-400g-zrplus.jpg/_jcr_content/renditions/danielking-400g-zrplus.webp\" width=\"1280\" />\n    \n\n            <figcaption class=\"dr-typography-t5 dr-color-ink-60 dr-image-rte\"><p style=\"text-align: center;\">Daniel King, one of our data center operations technicians, holds a pluggable transceiver in front of the equipment it will eventually replace.</p>\n</figcaption>\n        \n    </figure>\n</div></div>\n<div class=\"text parbase aem-GridColumn aem-GridColumn--default--12\">\n<p style=\"text-align: center;\">~ ~ ~</p>\n<p><i>If building innovative products, experiences, and infrastructure excites you, come build the future with us! Visit </i><a href=\"https://dropbox.com/jobs\" target=\"_blank\"><i><u>dropbox.com/jobs</u></i></a><i> to see our open roles, and follow @LifeInsideDropbox on </i><a href=\"https://www.instagram.com/lifeinsidedropbox/?hl=en\" target=\"_blank\"><i><u>Instagram</u></i></a><i> and </i><a href=\"https://www.facebook.com/lifeinsidedropbox/\" target=\"_blank\"><i><u>Facebook</u></i></a><i> to see what it's like to create a more enlightened way of working.\u00a0</i></p>\n\n</div>\n\n    \n</div>"
      }
    ],
    "media_thumbnail": [
      {
        "url": "https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/400GNetworking-1440x305-light.png"
      }
    ],
    "href": "",
    "media_content": [
      {
        "url": "https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2023/11/400g/400GNetworking-1440x305-light.png",
        "medium": "image"
      }
    ]
  },
  "Bazaarvoice": {
    "title": "How We Scale to 16+ Billion Calls",
    "xmlUrl": "https://blog.developer.bazaarvoice.com/feed/",
    "htmlUrl": "https://blog.developer.bazaarvoice.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.developer.bazaarvoice.com/feed/",
      "value": "How We Scale to 16+ Billion Calls"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.developer.bazaarvoice.com/2023/12/20/how-we-scale-to-16-billion-calls/"
      }
    ],
    "link": "https://blog.developer.bazaarvoice.com/2023/12/20/how-we-scale-to-16-billion-calls/",
    "authors": [
      {
        "name": "Allan Hunter"
      }
    ],
    "author": "Allan Hunter",
    "author_detail": {
      "name": "Allan Hunter"
    },
    "published": "Wed, 20 Dec 2023 12:25:06 +0000",
    "published_parsed": [
      2023,
      12,
      20,
      12,
      25,
      6,
      2,
      354,
      0
    ],
    "tags": [
      {
        "term": "Software Architecture",
        "scheme": null,
        "label": null
      },
      {
        "term": "Testing",
        "scheme": null,
        "label": null
      },
      {
        "term": "BFCM",
        "scheme": null,
        "label": null
      },
      {
        "term": "performance testing",
        "scheme": null,
        "label": null
      },
      {
        "term": "Quality Assurance",
        "scheme": null,
        "label": null
      },
      {
        "term": "Reliability",
        "scheme": null,
        "label": null
      },
      {
        "term": "Scalability",
        "scheme": null,
        "label": null
      },
      {
        "term": "Test Automation",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://blog.developer.bazaarvoice.com/?p=1874",
    "guidislink": false,
    "summary": "The holiday season brings a huge spike in traffic for many companies. While increased traffic is great for retail business, it also puts infrastructure reliability to the test. At times when every second of uptime is of elevated importance, how can engineering teams ensure zero downtime and performant applications? Here are some key strategies and [&#8230;]",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.developer.bazaarvoice.com/feed/",
      "value": "The holiday season brings a huge spike in traffic for many companies. While increased traffic is great for retail business, it also puts infrastructure reliability to the test. At times when every second of uptime is of elevated importance, how can engineering teams ensure zero downtime and performant applications? Here are some key strategies and [&#8230;]"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.developer.bazaarvoice.com/feed/",
        "value": "<p>The holiday season brings a huge spike in traffic for many companies. While increased traffic is great for retail business, it also puts infrastructure reliability to the test. At times when every second of uptime is of elevated importance, how can engineering teams ensure zero downtime and performant applications? Here are some key strategies and considerations we employ at Bazaarvoice as we prepare our platform to handle over <strong>16 Billion API calls</strong> during Cyber Week.</p>\n\n\n\n<p class=\"has-text-align-center\"><img height=\"358.70347353670445\" src=\"https://lh7-us.googleusercontent.com/7uAXCcNma6-3iUNW5QCTgjUpNCc-6JkCXC7D-8IgrVPqgsNRIlERATSXRHCwrSob15mfOJpGpHwWZYv7hzS1f8hGqb_twaLFOxIogCzfG7wmEPKSL3U4bylUxL_vT_1NqHlGJLd6cwRpO9_MuFG9xcM\" width=\"442\" /></p>\n\n\n\n<p>Key to approaching readiness for peak load events is defining the scope of testing. Identify which services need to be tested and be clear about success requirements.&nbsp; A common trade off will be choosing between reliability and cost. When making this choice, reliability is always the top priority. \u2018Customer is Key\u2019 is a key value at Bazaarvoice, and drives our decisions and behavior.&nbsp; Service Level Objectives (SLOs) drive clarity of reliability requirements through each of our services.</p>\n\n\n\n<p class=\"has-text-align-center\">&#8220;<em>Reliability is always the top priority</em>&#8220;</p>\n\n\n\n<p>When customer traffic is at its peak, reliability and uptime must take precedence over all other concerns. While cost efficiency is important, the customer experience is key during these critical traffic surges. Engineers should have the infrastructure resources they need to maintain stability and performance, even if it means higher costs in the short-term.</p>\n\n\n\n<p>Thorough testing and validation well in advance is essential to surfacing any issues before the holidays. All critical customer-facing services undergo load and failover simulations to identify performance bottlenecks and points of failure. In a Serverless-first architecture, ensuring configuration like reserved concurrency and quota limits are sufficient for autoscaling requirements are valuable to validate.&nbsp; Often these simulations will uncover problems you have not previously encountered. For example, in this year&#8217;s preparations our load simulations uncovered scale limitations in our redis cache which required fixes prior to Black Friday.</p>\n\n\n\n<p class=\"has-text-align-center\"><em>\u201cIt\u2019s not only about testing the ability to handle peak load\u201d</em></p>\n\n\n\n<p>It\u2019s important to note readiness is not only about testing the ability to handle peak load. Disaster recovery plans are validated through simulated scenarios. Runbooks are verified as up-to-date, to ensure efficient incident response in the event something goes wrong. Verifying instrumentation and infrastructure that supports operability are tested, ensuring our tooling works when we need it most.</p>\n\n\n\n<p>Similarly ensuring the appropriate tooling and processes are in place to address security concerns is another key concern. Preventing DDoS attacks which could easily overwhelm the system if not identified and mitigated, preventing impact of service availability.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Predicting the future</h2>\n\n\n\n<p>Observability through actionable monitoring, logging, and metrics provides the essential visibility to detect and isolate emerging problems early. It also provides the historical context and growth of traffic data over time, which can help forecast capacity needs and establish performance baselines that align with real production usage. In addition to quantitative measures, proactively reaching out to clients means we are in step with client needs about expected traffic helping align testing to actual usage patterns.&nbsp; This data is important to simulate real world traffic patterns based on what has gone before, and has enabled us to accurately predict Black Friday traffic trends. However it\u2019s important our systems are architected to scale with demand, to handle unpredicted load if need be, key to this is observing and understanding how our systems behave in production.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Traffic Trends</h2>\n\n\n\n<p>What did it look like this year? Consumer shopping patterns remained quite consistent on an elevated scale. Black Friday continues to be the largest shopping day of the year, and consumers continue to shop online in increasing numbers. During Cyber Week alone, Bazaarvoice handled over 16 Billion API calls.</p>\n\n\n\n<p class=\"has-text-align-center\"><img height=\"260\" src=\"https://lh7-us.googleusercontent.com/oKmRK2GAsnyMxr05OqAjY465gUOqY3FA2j110_3oZ1iNvRhU3-gElYZyNs2Mz2_M8c_lEUjFHA8Y-sS5oqjkNlDJ0QnmKpwl2m_mYTp--b9cxWhw_KOst2BwEZ7J3fBo-WxM3b8wXa17tpzoUCYtk_o\" width=\"500\" /></p>\n\n\n\n<h2 class=\"wp-block-heading\">Solving common problems once</h2>\n\n\n\n<p>While individual engineering teams own service readiness, having a coordinated effort ensures all critical dependencies are covered. Sharing forecasts, requirements, and learnings across teams enables better preparation. Testing surprises on dependent teams should be avoided through clear communication.</p>\n\n\n\n<p>Automating performance testing, failover drills, and monitoring checks as part of regular release cycles or scheduled pipelines reduces the overhead of peak traffic preparation. Following site reliability principles and instilling always-ready operational practices makes services far more resilient year-round.&nbsp;</p>\n\n\n\n<p>For example, we recently put in place a shared dev pattern for continuous performance testing.&nbsp; This involves a quick setup of k6 performance script, an example github action pipeline and observability configured to monitor performance over time. We also use an in-house <a href=\"https://backstage.io/blog/2020/05/14/tech-radar-plugin/\">Tech Radar</a> to converge on common tooling so a greater number of teams can learn and stand on the shoulders of teams who have already tried and tested tooling in their context.</p>\n\n\n\n<p>Other examples include, adding automation to performance tests to replay production requests for a given load profile makes tests easier to maintain, and reflect more accurately production behavior. Additionally, make use of automated fault injection tooling, chaos engineering and automated runbooks.</p>\n\n\n\n<p class=\"has-text-align-center\"><img height=\"309\" src=\"https://lh7-us.googleusercontent.com/VuZs9IVYNCwZ-gznrTTzjVZlyowIQ5OEZBctr-UTYJtlk4RTNzeL4beGPgWlzPLVzGkZRQyT9UPfHQyi2NGrLGKGKUg5LsM3vFCqnowAJc1QWISGIHGFORRkZombi9vgWTeBl_b8NZBv4qKWleLn2l4\" width=\"507\" /></p>\n\n\n\n<p>Adding automation and ensuring these practices are part of your everyday way of working are key to reducing the overhead of preparing for the holidays.</p>\n\n\n\n<p class=\"has-text-align-center\"><em>Consistent, continuous training conditions us to always be ready</em></p>\n\n\n\n<p>Moving to an always-ready posture ensures our infrastructure is scalable, reliable and robust all year round.  Implementing continuous performance testing using frequent baseline tests provides frequent feedback on performance from release to release.&nbsp; Automated operational readiness service checks ensure principles and expectations are in place for production services and are continuously checked.&nbsp; For example, automated checking of expected monitors, alerts, runbooks and incident escalation policy requirements.</p>\n\n\n\n<p>At Bazaarvoice our engineering teams align on shared System Standards which gives technical direction and guidance to engineers on commonly solved problems, continuously evolving our systems and increasing our innovation velocity.&nbsp; To use a trail running analogy, System Standards define the preferred paths and combined with Tech Radar, provide recommendations to help you succeed.&nbsp; For example, what trail running shoes should I choose, what energy refuelling strategy should I use, how should I monitor performance.&nbsp; The same is true for building resilient reliable software, as teams solve these common problems, share the learnings for those teams which come after.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Looking Ahead</h2>\n\n\n\n<p>With a relentless focus on reliability, scalability, continuous testing, enhanced observability, and cross-team collaboration, engineering organizations can optimize performance and minimize downtime during critical traffic surges.&nbsp;</p>\n\n\n\n<p>Don\u2019t forget after the peak has passed and we have descended from the summit, analyze the data.&nbsp; What went well, what didn\u2019t go well, and what opportunities are there to improve for the next peak.</p>"
      }
    ]
  },
  "Stripe": {
    "title": "Stripe Sessions 2024\u2014come join us",
    "xmlUrl": "https://stripe.com/blog/feed.rss",
    "htmlUrl": "https://stripe.com/blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://stripe.com/blog/feed.rss",
      "value": "Stripe Sessions 2024\u2014come join us"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://stripe.com/blog/stripe-sessions-2024"
      },
      {
        "length": "289833",
        "type": "image/png",
        "href": "https://images.ctfassets.net/fzn2n1nzq965/2Zt7r0Y4ZHEn3g9fYZ7RRI/96e44f86bb135c84d3b894b27da52fd6/Sessions_Demand_BlogThumbnail_1048x856_01.png",
        "rel": "enclosure"
      }
    ],
    "link": "https://stripe.com/blog/stripe-sessions-2024",
    "summary": "Please join us April 23\u201325 at Moscone West in San Francisco for our largest event ever.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://stripe.com/blog/feed.rss",
      "value": "Please join us April 23\u201325 at Moscone West in San Francisco for our largest event ever."
    },
    "published": "Thu, 14 Dec 2023 00:00:00 +0000",
    "published_parsed": [
      2023,
      12,
      14,
      0,
      0,
      0,
      3,
      348,
      0
    ],
    "id": "https://stripe.com/blog/stripe-sessions-2024",
    "guidislink": false,
    "updated": "2023-12-14T00:00:00+00:00",
    "updated_parsed": [
      2023,
      12,
      14,
      0,
      0,
      0,
      3,
      348,
      0
    ]
  },
  "Tumblr": {
    "title": "alias please=sudo",
    "xmlUrl": "https://engineering.tumblr.com/rss",
    "htmlUrl": "https://engineering.tumblr.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.tumblr.com/rss",
      "value": "alias please=sudo"
    },
    "summary": "<div class=\"npf_row\"><figure class=\"tmblr-full\"><img src=\"https://64.media.tumblr.com/7e36533fe1233ed21aa6673631af4e62/f15a07668b93275c-c6/s640x960/a4eed2e1bb53709c1d0dd172fd6b48bbf2814d64.jpg\" /></figure></div><h2>alias please=sudo</h2><p>Keeping a site like Tumblr alive and snappy for you to post at a moment\u2019s notice, all day and night, is no small feat. Pesky crabs sneak into our data centers and cut cables all the time\u2026</p><p>If you want to help our small but excellent systems team, want to work from anywhere, and are deep into nginx, mysql, kubernetes, and caching, <a href=\"https://href.li/?https://automattic.com/work-with-us/job/systems-engineering/\">join us in this adventure.</a> Or, if you have a friend or a colleague who\u2019s good with servers, <a href=\"https://href.li/?https://automattic.com/work-with-us/job/systems-engineering/\">send them our way.</a></p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.tumblr.com/rss",
      "value": "<div class=\"npf_row\"><figure class=\"tmblr-full\"><img src=\"https://64.media.tumblr.com/7e36533fe1233ed21aa6673631af4e62/f15a07668b93275c-c6/s640x960/a4eed2e1bb53709c1d0dd172fd6b48bbf2814d64.jpg\" /></figure></div><h2>alias please=sudo</h2><p>Keeping a site like Tumblr alive and snappy for you to post at a moment\u2019s notice, all day and night, is no small feat. Pesky crabs sneak into our data centers and cut cables all the time\u2026</p><p>If you want to help our small but excellent systems team, want to work from anywhere, and are deep into nginx, mysql, kubernetes, and caching, <a href=\"https://href.li/?https://automattic.com/work-with-us/job/systems-engineering/\">join us in this adventure.</a> Or, if you have a friend or a colleague who\u2019s good with servers, <a href=\"https://href.li/?https://automattic.com/work-with-us/job/systems-engineering/\">send them our way.</a></p>"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.tumblr.com/post/733445594295762944"
      }
    ],
    "link": "https://engineering.tumblr.com/post/733445594295762944",
    "id": "https://engineering.tumblr.com/post/733445594295762944",
    "guidislink": false,
    "published": "Wed, 08 Nov 2023 13:30:25 -0500",
    "published_parsed": [
      2023,
      11,
      8,
      18,
      30,
      25,
      2,
      312,
      0
    ],
    "tags": [
      {
        "term": "tumblr engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "systems engineering",
        "scheme": null,
        "label": null
      }
    ]
  },
  "MapTiler": {
    "title": "GeoCamp ES 2023",
    "xmlUrl": "https://www.maptiler.com/blog/feed/posts.xml",
    "htmlUrl": "https://www.maptiler.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.maptiler.com/news/feed/posts.xml",
      "value": "GeoCamp ES 2023"
    },
    "summary": "GeoCamp ES is a non-profit, free-to-attend, and self-financed national conference of the international collective Geoinquietos. To talk and learn about earth sciences, open geodata services, free software, and GIS applications, especially around the OSGeo community.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.maptiler.com/news/feed/posts.xml",
      "value": "GeoCamp ES is a non-profit, free-to-attend, and self-financed national conference of the international collective Geoinquietos. To talk and learn about earth sciences, open geodata services, free software, and GIS applications, especially around the OSGeo community."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.maptiler.com/news/2023/12/geocamp-es-2023"
      }
    ],
    "link": "https://www.maptiler.com/news/2023/12/geocamp-es-2023",
    "id": "https://www.maptiler.com/news/2023/12/geocamp-es-2023",
    "guidislink": false,
    "authors": [
      {
        "name": "MapTiler (Wladimir Szczerban)"
      }
    ],
    "author": "MapTiler (Wladimir Szczerban)",
    "author_detail": {
      "name": "MapTiler (Wladimir Szczerban)"
    },
    "published": "Mon, 04 Dec 2023 00:00:00 GMT",
    "published_parsed": [
      2023,
      12,
      4,
      0,
      0,
      0,
      0,
      338,
      0
    ]
  },
  "Babbel": {
    "title": "The Language Of Self-Care: Understanding Wellness Terms In The New Year",
    "xmlUrl": "https://blog.babbel.com/en/feed/",
    "htmlUrl": "https://bytes.babbel.com/en/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://cms.babbel.news/feed/?post_type=english_edition%2F",
      "value": "The Language Of Self-Care: Understanding Wellness Terms In The New Year"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.babbel.com/en/magazine/the-language-of-self-care"
      }
    ],
    "link": "https://www.babbel.com/en/magazine/the-language-of-self-care",
    "authors": [
      {
        "name": "Steph Koyfman"
      }
    ],
    "author": "Steph Koyfman",
    "author_detail": {
      "name": "Steph Koyfman"
    },
    "published": "Fri, 12 Jan 2024 13:10:00 +0000",
    "published_parsed": [
      2024,
      1,
      12,
      13,
      10,
      0,
      4,
      12,
      0
    ],
    "tags": [
      {
        "term": "Culture",
        "scheme": null,
        "label": null
      },
      {
        "term": "French",
        "scheme": null,
        "label": null
      },
      {
        "term": "German",
        "scheme": null,
        "label": null
      },
      {
        "term": "Health",
        "scheme": null,
        "label": null
      },
      {
        "term": "Italian",
        "scheme": null,
        "label": null
      },
      {
        "term": "Mexican Spanish",
        "scheme": null,
        "label": null
      },
      {
        "term": "Spanish",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://www.babbel.com/en/magazine/",
    "guidislink": false,
    "summary": "<p>What do all those wellness buzzwords really mean?</p>\n<p>The post <a href=\"https://www.babbel.com/en/magazine/the-language-of-self-care\" rel=\"nofollow\">The Language Of Self-Care: Understanding Wellness Terms In The New Year</a> appeared first on <a href=\"https://www.babbel.com\" rel=\"nofollow\">Babbel</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://cms.babbel.news/feed/?post_type=english_edition%2F",
      "value": "<p>What do all those wellness buzzwords really mean?</p>\n<p>The post <a href=\"https://www.babbel.com/en/magazine/the-language-of-self-care\" rel=\"nofollow\">The Language Of Self-Care: Understanding Wellness Terms In The New Year</a> appeared first on <a href=\"https://www.babbel.com\" rel=\"nofollow\">Babbel</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://cms.babbel.news/feed/?post_type=english_edition%2F",
        "value": "<div class=\"featured-image\"><img alt=\"woman sitting in therapist&#039;s office\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"675\" src=\"https://cms.babbel.news/wp-content/uploads/2020/01/CM_MagazineHeader_SelfCare.png\" width=\"1200\" /></div>\n<p>With January upon us, it&#8217;s the time of year you might think about how you want to reorient your approach to the world. &#8220;New Year, New Me&#8221; is a mantra that is a testament to our enduring belief in our own abilities to change. And one way you may be thinking of making self-care a core part of your new year. But what does self-care really look like in your day-to-day life?</p>\n\n\n\n<p>Self-care is a lot of things, and the debate over its <a href=\"https://intothegloss.com/2018/11/what-is-self-care-black-girl-in-om/\" rel=\"noreferrer noopener nofollow\" target=\"_blank\">true meaning</a> and <a href=\"https://www.vice.com/en_us/article/zmdwm4/the-young-and-the-uncared-for-v25n4\" rel=\"noreferrer noopener nofollow\" target=\"_blank\">utility</a> has spurred a lot of hot takes in recent years. It&#8217;s gotten a bad reputation lately as a way for people to ignore the world and put the mselves before others, but that&#8217;s not what self-care is really about. Sometimes it&#8217;s actions like buying a treat or taking a bath. Sometimes it&#8217;s drinking enough water and getting sufficient sleep. Sometimes it&#8217;s doing things that are kind of unpleasant in the moment that you know will lead to improved conditions down the line. In almost every case, self-care is simply whatever&#8217;s going to support your physical and <a href=\"https://www.babbel.com/en/magazine/how-to-talk-about-mental-health-in-6-different-languages\" rel=\"noopener noreferrer\" target=\"_blank\">mental health</a> and prevent longer-term burnout.</p>\n\n\n\n<p>Though the total commodification of self-care is pretty recent, self-care as a concept isn&#8217;t all that new. <a href=\"https://www.newyorker.com/culture/culture-desk/the-politics-of-selfcare\" rel=\"noreferrer noopener nofollow\" target=\"_blank\">Socrates</a> may have been one of the first major thinkers to lay the groundwork for the notion that we have to fill our own cups first before tending to others. It eventually took on political overtones in the 1970s and 80s within queer and POC communities. Activist Audre Lorde famously said that \u201ccaring for myself is not self-indulgence, it is self-preservation, and that is an act of political warfare.\u201d</p>\n\n\n\n<p>The contemporary self-care movement is also somewhat political. It might be trendy, but it <a href=\"https://www.nytimes.com/2016/12/10/fashion/post-election-anxiety-self-care.html?_r=0\" rel=\"noreferrer noopener nofollow\" target=\"_blank\">became especially trendy</a> in the weeks following the November 2016 election in the United States. In the years since, we&#8217;ve also become familiar with a number of other wellness words that often have psychological or mental health implications. Because these concepts can often be kind of obtuse and prone to being overused to the point of meaninglessness, here are some working definitions to help you understand the universe of self-care. Then, you might be able to carry these ideas into 2024 and see what a new you really looks like.</p>\n\n\n\n<h2 id=\"h-self-care-vocabulary-defined\">Self-Care Vocabulary, Defined</h2>\n\n\n\n<h3 id=\"h-boundaries\">Boundaries</h3>\n\n\n\n<p>Culturally, we are recognizing the need to have healthy boundaries with others. Often, you have to recognize (and then name) your limits first to do this, and there&#8217;s no one-size-fits-all approach, which is why it&#8217;s not always simple to define &#8220;boundaries.&#8221; For one person, it may look like not giving in to pressure to respond to texts or emails immediately. For another person, it may look like saying &#8220;no&#8221; to friends or family members who ask for financial favors, or perhaps ending a conversation when it becomes hurtful or abusive.</p>\n\n\n\n<p>Boundaries are an important component of self-care because looking out for yourself is not always about what you do, but also what you <em>don&#8217;t</em> agree to do (or take responsibility for).</p>\n\n\n\n<h3 id=\"h-valid\">Valid</h3>\n\n\n\n<p>&#8220;Your feelings are valid.&#8221; &#8220;Thanks for validating me.&#8221; &#8220;I feel like you&#8217;re invalidating my lived experience.&#8221; You may have heard these phrases, or variations thereof, populating the discourse of years past. For something to be valid, it has to be relevant, meaningful and grounded in some semblance of truth. In the past, &#8220;valid&#8221; was often used to describe things with legal or logical validity, but its common application to the murkier emotional realms is a little more recent. And to understand this usage, it&#8217;s probably necessary to talk about why we would need to affirm the legitimacy of feelings or subjective truths.</p>\n\n\n\n<p>A lot of times, insisting that &#8220;feelings are valid&#8221; is meant to counteract the tendency to elevate rational thinking above emotional thinking (to the point that our heads override our hearts completely). And sometimes, it&#8217;s in response to gaslighting \u2014 another popular buzzword \u2014 which is a manipulation tactic people use to make others feel like they can&#8217;t count on their own perceptions. Sometimes, &#8220;valid&#8221; is used to make a statement \u2014 one that legitimizes identities or perspectives that are marginalized in society.</p>\n\n\n\n<p>&#8220;Feelings are valid&#8221; often comes with a disclaimer, however. Emotions are real and worth paying attention to, but they&#8217;re not always an appropriate response to the situation at hand. To say emotions are &#8220;valid&#8221; is not to give carte blanche to throw gratuitous temper tantrums. It&#8217;s more about reminding people not to ignore or discredit their feelings.</p>\n\n\n\n<h3 id=\"h-cleanse\">Cleanse</h3>\n\n\n\n<p>Typically, you see &#8220;cleanse&#8221; used interchangeably with &#8220;detox,&#8221; often in the context of a temporary diet meant to purge your body of toxins and impurities. Of course, you could take issue with the purported science behind some of these cleanses, as well as the meaning of the word &#8220;detox&#8221; in this context. Livers do our detoxing automatically, and the boost in energy you might receive from doing a cleanse is not necessarily the same as the physical process of clearing toxins from your system.</p>\n\n\n\n<p>However, &#8220;cleanse&#8221; can also apply to lots of things beyond nutrition. You can do a social media cleanse by unfollowing accounts that provoke your anxiety or simply taking time away from the internet. You can perform a cleanse of your living space by giving it the <a href=\"https://www.babbel.com/en/magazine/marie-kondo-your-language-studies\" rel=\"noopener noreferrer\" target=\"_blank\">Marie Kondo</a> treatment or getting rid of things you associate with negative memories. Any area of your life that&#8217;s prone to accumulating literal or metaphorical dust is fair game for a cleanse.</p>\n\n\n\n<h3 id=\"h-unplug\">Unplug</h3>\n\n\n\n<p>In line with the concept of an internet cleanse, our tech-saturated society has created a world that we occasionally need to &#8220;unplug&#8221; from. To unplug for a bit can mean literally shutting off your electronic devices to get a mental health break from the barrage of constant updates, internet junk and pressure of being &#8220;watched&#8221; all the time.</p>\n\n\n\n<p>You don&#8217;t have to get off the grid to unplug in the new year. Instead, unplugging can be simply turning off notifications for your busiest apps, putting a ban on checking work emails after you&#8217;ve left the office, or avoiding a specific social media platform for a set amount of time.</p>\n\n\n\n<h3 id=\"h-burnout\">Burnout</h3>\n\n\n\n<p>Our work culture puts a lot of pressure on people to maximize their productivity at all times, which is often more than what the average person&#8217;s physical and mental health comfortably allows for. The onus to stay late at the office, sometimes work multiple jobs, and still excel in every other area of life can all lead to a state of total exhaustion we&#8217;ve dubbed &#8220;burnout.&#8221;</p>\n\n\n\n<p>You can be in a state of constant stress for a long time leading up to the point of burnout, but usually, by the time you&#8217;re there, it&#8217;s because you&#8217;ve been in prolonged &#8220;fight or flight&#8221; mode for long enough that you simply don&#8217;t have it in you to keep going like that. Part of the purported goal of self-care is to prevent this sort of burnout.</p>\n\n\n\n<p>BuzzFeed writer Anne Helen Petersen sparked a specific conversation around the way young people specifically experience burnout \u2014 a.k.a. &#8220;<a href=\"https://www.buzzfeednews.com/article/annehelenpetersen/millennials-burnout-generation-debt-work\" rel=\"noreferrer noopener nofollow\" target=\"_blank\">Millennial Burnout</a>.&#8221; The combination of poor economic prospects, crushing debt, the constant demand for our attention online, and being raised to optimize every aspect of our lives have all led to a state of &#8220;errand paralysis&#8221; that can make seemingly simple tasks, like mailing a package, feel so daunting that Millennials avoid going to the post office altogether.</p>\n\n\n\n<h3 id=\"h-hold-space\">Hold Space</h3>\n\n\n\n<p>What does it mean to &#8220;hold space&#8221; for someone? And what does it mean to &#8220;hold space&#8221; for the possibility of things to come?</p>\n\n\n\n<p>To &#8220;hold space&#8221; is to provide a receptive container for another person to vent their feelings, or for new possibilities you haven&#8217;t fully entertained or anticipated. This implies that in order for someone to have a proper catharsis with someone else, they need to feel witnessed. And that in order to accept a possibility you weren&#8217;t expecting, you need to turn off your constant drive to &#8220;know things&#8221; and &#8220;make things happen&#8221; and allow some elbow room for everything that&#8217;s beyond the narrow scope of your own will.</p>\n\n\n\n<p>In a way, this is sort of just a new age way of describing the concept of &#8220;listening.&#8221; Too often, we&#8217;re inclined to talk over others or make the conversation about ourselves. Instead, when you hold space for someone, you give them your quiet presence and attention.</p>\n<p>The post <a href=\"https://www.babbel.com/en/magazine/the-language-of-self-care\" rel=\"nofollow\">The Language Of Self-Care: Understanding Wellness Terms In The New Year</a> appeared first on <a href=\"https://www.babbel.com\" rel=\"nofollow\">Babbel</a>.</p>"
      }
    ]
  },
  "Mesosphere": {
    "title": "Failing in the Cloud\u2013How to Turn It Around",
    "xmlUrl": "https://mesosphere.com/feed/",
    "htmlUrl": "https://mesosphere.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://d2iq.com/feed",
      "value": "Failing in the Cloud\u2013How to Turn It Around"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://d2iq.com/blog/failing-in-the-cloud"
      }
    ],
    "link": "https://d2iq.com/blog/failing-in-the-cloud",
    "id": "https://d2iq.com/blog/failing-in-the-cloud",
    "guidislink": false,
    "tags": [
      {
        "term": "Kubernetes",
        "scheme": null,
        "label": null
      }
    ],
    "published": "Tue, 26 Sep 2023 16:00:00 +0000",
    "published_parsed": [
      2023,
      9,
      26,
      16,
      0,
      0,
      1,
      269,
      0
    ],
    "summary": "<p>Success in the cloud continues to be elusive for many organizations. A recent <i>Forbes</i> article describes how financial services firms <a href=\"https://www.forbes.com/sites/davidparker/2023/09/06/why-financial-services-firms-are-struggling-to-succeed-with-cloud-computing/?sh=1c52ac4076f2\">are struggling to succeed in the cloud</a>, citing <a href=\"https://www.accenture.com/us-en/insights/cloud/cloud-outcomes-perspective\">Accenture Research</a> that found that only 40% of banks and less than half of insurers fully achieved their expected outcomes from migrating to cloud.</p><p>&nbsp;</p><p>Similarly, a 2022 <a href=\"https://kpmg.com/us/en/articles/2022/2022-us-technology-survey.html\">KPMG Technology Survey</a> found that 67% of organizations said they had failed to receive a return on investment in the cloud.&nbsp;&nbsp;</p><p>&nbsp;</p><p><a href=\"https://techcrunch.com/2023/03/20/the-cloud-backlash-has-begun-why-big-data-is-pulling-compute-back-on-premises/\">Techcrunch</a> reports that \u201ccloud-first strategies may be hitting the limits of their efficacy, and in many cases, ROIs are diminishing, triggering a major cloud backlash.\u201d The author ascribes the problems to out-of-control costs, deepening complexity, restrictive vendor lock-in, and cloud sprawl.</p><p>&nbsp;</p><h3>Misguided Cloud Strategies</h3><p>In \u201c<a href=\"https://www.infoworld.com/article/3675374/companies-are-still-waiting-for-their-cloud-roi.html\">Companies are still waiting for their cloud ROI</a><i>,\u201d</i> David Linthicum writes that, \u201cWe\u2019ve learned that most enterprises do not use cloud in business-optimized ways and thus end up missing the promised ROI.\u201d&nbsp;</p><p>&nbsp;</p><p>Similarly, <a href=\"https://www.cio.com/article/462840/think-carefully-before-considering-cloud-repatriation.html\">CIO.com</a> reports that, \u201cOverall, disappointment comes from poor planning most of the time.\u201d A common reason for failure is that companies put information assets on the cloud in a \u201clift and shift\u201d operation so their applications never benefit from the advantages of cloud, such as elasticity.&nbsp;</p><p>&nbsp;</p><p>Inefficient cloud and data center architectures also lead to excessive costs, says CIO.com. \u201cIf you move the front end of an application to the cloud, but leave the back end in your data center, then all of a sudden you\u2019re paying for two sets of infrastructure.\u201d&nbsp;&nbsp;&nbsp;</p><p>&nbsp;</p><p>Many enterprises just push scads of applications and databases onto cloud platforms and then wonder why their cloud bill is so high,\u201d says Linthicum. \u201cThe scary part,\u201d he says, \u201cis that people making decisions often don\u2019t understand how to get to an optimized solution.\u201d</p><p>&nbsp;</p><h3>Turnaround Is Hard Work</h3><p>It\u2019s easy for everyone to get in a circle and blame bad technology decisions on the deficiencies of cloud computing ROI, says Linthicum. \u201cThe harder but more productive conversation is how to put cloud systems on a more cost- and business-efficient path.\u201d</p><p>&nbsp;</p><p>To succeed, he says, you need to build cloud-based configurations of technology that are better than the \u201cas is\u201d state. To reverse the losses and achieve positive cloud ROI requires optimization, FinOps, and refactoring, he notes.&nbsp;</p><p>&nbsp;</p><p>CIO.com advises organizations to follow Gartner\u2019s <a href=\"https://www.gartner.com/en/webinar/519005/1179202\">Cloud Strategy Cookbook 2023</a>, which calls for developing a cloud strategy before moving to the cloud, regularly updating the strategy, keeping a record in a living document, and aligning your cloud strategy with desired business outcomes.&nbsp;</p><p>&nbsp;</p><p>Although many organizations are considering cloud repatriation, migrating back from the cloud is not an easy process and too many organizations do so with equally poor planning, warns CIO.com.</p><p>&nbsp;</p><h3>Formula for Success</h3><p>Organizations that are failing in the cloud can reverse their losses and get on a winning track by doing the hard work Lithicum describes. In doing so, employing automation is a key element for success.&nbsp;</p><p>&nbsp;</p><p>As IBM notes in <a href=\"https://www.ibm.com/blog/cloud-modernization-failure-patterns/\">4 Failure Patterns to Avoid in Cloud Modernization</a>, \u201cThe only way technology teams have a hope of keeping up with expectations is if they drive very high levels of automation.\u201d Unfortunately, the article notes, many companies fail to invest in the automation necessary to transform IT and&nbsp; take advantage of the new technologies.&nbsp;</p><p>&nbsp;</p><p>The best way to succeed is to employ a <a href=\"https://d2iq.com/blog/kubernetes-platform-management-simplification-through-automation\">highly automated Kubernetes platform</a> that provides centralized multi-cluster, multi-cloud fleet management, is based on <a href=\"https://d2iq.com/blog/business-case-capi-enhanced-kubernetes-management\">declarative APIs and GitOps</a>, and includes <a href=\"https://d2iq.com/blog/immutable-self-healing-infrastructure-advantages\">self-healing capabilities</a>, observability, and cost controls.&nbsp;</p><p>&nbsp;</p><p>This can be achieved by deploying a feature-complete, production-ready Kubernetes platform that essentially provides <a href=\"https://d2iq.com/blog/simplify-kubernetes-instant-platform-engineering\">instant platform engineering</a>. This type of platform also will provide an ideal setting for <a href=\"https://d2iq.com/blog/all-together-finops-kubernetes-platform-engineering\">FinOps</a> and <a href=\"https://d2iq.com/blog/kubernetes-devsecops-platform-engineering\">DevSecOps</a>.</p><p>&nbsp;</p><p>It also is important to employ a platform based on <a href=\"https://d2iq.com/resources/solution-brief/pure-upstream-open-source-kubernetes\">pure CNCF-conformant Kubernetes</a>.This gives you portability, easier upgradeability, and trouble-free extensibility by easily accommodating the innovation that continually arises within the open-source community.&nbsp;</p><p>&nbsp;</p><p>To learn more about how you can turn around a failing cloud deployment and avoid failing in the first place, access these resources:&nbsp;</p><li><a href=\"https://d2iq.com/resources/webinar/failing-cloud-kubernetes\">Are you one of the 67% Failing in the Cloud? How to do Kubernetes Right</a></li><li><a href=\"https://d2iq.com/resources/webinar/doing-kubernetes-multi-cloud-hybrid-management-right\">Doing Kubernetes Multi-cloud and Hybrid Management Right</a></li><li><a href=\"https://d2iq.com/resources/webinar/avoid-kubernetes-deployment-pitfalls\">Success in the Cloud: How to Avoid Kubernetes Deployment Pitfalls</a></li><p>&nbsp;</p><p>To book a personal consultation, <a href=\"https://d2iq.com/contact\">contact the experts at D2iQ</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://d2iq.com/feed",
      "value": "<p>Success in the cloud continues to be elusive for many organizations. A recent <i>Forbes</i> article describes how financial services firms <a href=\"https://www.forbes.com/sites/davidparker/2023/09/06/why-financial-services-firms-are-struggling-to-succeed-with-cloud-computing/?sh=1c52ac4076f2\">are struggling to succeed in the cloud</a>, citing <a href=\"https://www.accenture.com/us-en/insights/cloud/cloud-outcomes-perspective\">Accenture Research</a> that found that only 40% of banks and less than half of insurers fully achieved their expected outcomes from migrating to cloud.</p><p>&nbsp;</p><p>Similarly, a 2022 <a href=\"https://kpmg.com/us/en/articles/2022/2022-us-technology-survey.html\">KPMG Technology Survey</a> found that 67% of organizations said they had failed to receive a return on investment in the cloud.&nbsp;&nbsp;</p><p>&nbsp;</p><p><a href=\"https://techcrunch.com/2023/03/20/the-cloud-backlash-has-begun-why-big-data-is-pulling-compute-back-on-premises/\">Techcrunch</a> reports that \u201ccloud-first strategies may be hitting the limits of their efficacy, and in many cases, ROIs are diminishing, triggering a major cloud backlash.\u201d The author ascribes the problems to out-of-control costs, deepening complexity, restrictive vendor lock-in, and cloud sprawl.</p><p>&nbsp;</p><h3>Misguided Cloud Strategies</h3><p>In \u201c<a href=\"https://www.infoworld.com/article/3675374/companies-are-still-waiting-for-their-cloud-roi.html\">Companies are still waiting for their cloud ROI</a><i>,\u201d</i> David Linthicum writes that, \u201cWe\u2019ve learned that most enterprises do not use cloud in business-optimized ways and thus end up missing the promised ROI.\u201d&nbsp;</p><p>&nbsp;</p><p>Similarly, <a href=\"https://www.cio.com/article/462840/think-carefully-before-considering-cloud-repatriation.html\">CIO.com</a> reports that, \u201cOverall, disappointment comes from poor planning most of the time.\u201d A common reason for failure is that companies put information assets on the cloud in a \u201clift and shift\u201d operation so their applications never benefit from the advantages of cloud, such as elasticity.&nbsp;</p><p>&nbsp;</p><p>Inefficient cloud and data center architectures also lead to excessive costs, says CIO.com. \u201cIf you move the front end of an application to the cloud, but leave the back end in your data center, then all of a sudden you\u2019re paying for two sets of infrastructure.\u201d&nbsp;&nbsp;&nbsp;</p><p>&nbsp;</p><p>Many enterprises just push scads of applications and databases onto cloud platforms and then wonder why their cloud bill is so high,\u201d says Linthicum. \u201cThe scary part,\u201d he says, \u201cis that people making decisions often don\u2019t understand how to get to an optimized solution.\u201d</p><p>&nbsp;</p><h3>Turnaround Is Hard Work</h3><p>It\u2019s easy for everyone to get in a circle and blame bad technology decisions on the deficiencies of cloud computing ROI, says Linthicum. \u201cThe harder but more productive conversation is how to put cloud systems on a more cost- and business-efficient path.\u201d</p><p>&nbsp;</p><p>To succeed, he says, you need to build cloud-based configurations of technology that are better than the \u201cas is\u201d state. To reverse the losses and achieve positive cloud ROI requires optimization, FinOps, and refactoring, he notes.&nbsp;</p><p>&nbsp;</p><p>CIO.com advises organizations to follow Gartner\u2019s <a href=\"https://www.gartner.com/en/webinar/519005/1179202\">Cloud Strategy Cookbook 2023</a>, which calls for developing a cloud strategy before moving to the cloud, regularly updating the strategy, keeping a record in a living document, and aligning your cloud strategy with desired business outcomes.&nbsp;</p><p>&nbsp;</p><p>Although many organizations are considering cloud repatriation, migrating back from the cloud is not an easy process and too many organizations do so with equally poor planning, warns CIO.com.</p><p>&nbsp;</p><h3>Formula for Success</h3><p>Organizations that are failing in the cloud can reverse their losses and get on a winning track by doing the hard work Lithicum describes. In doing so, employing automation is a key element for success.&nbsp;</p><p>&nbsp;</p><p>As IBM notes in <a href=\"https://www.ibm.com/blog/cloud-modernization-failure-patterns/\">4 Failure Patterns to Avoid in Cloud Modernization</a>, \u201cThe only way technology teams have a hope of keeping up with expectations is if they drive very high levels of automation.\u201d Unfortunately, the article notes, many companies fail to invest in the automation necessary to transform IT and&nbsp; take advantage of the new technologies.&nbsp;</p><p>&nbsp;</p><p>The best way to succeed is to employ a <a href=\"https://d2iq.com/blog/kubernetes-platform-management-simplification-through-automation\">highly automated Kubernetes platform</a> that provides centralized multi-cluster, multi-cloud fleet management, is based on <a href=\"https://d2iq.com/blog/business-case-capi-enhanced-kubernetes-management\">declarative APIs and GitOps</a>, and includes <a href=\"https://d2iq.com/blog/immutable-self-healing-infrastructure-advantages\">self-healing capabilities</a>, observability, and cost controls.&nbsp;</p><p>&nbsp;</p><p>This can be achieved by deploying a feature-complete, production-ready Kubernetes platform that essentially provides <a href=\"https://d2iq.com/blog/simplify-kubernetes-instant-platform-engineering\">instant platform engineering</a>. This type of platform also will provide an ideal setting for <a href=\"https://d2iq.com/blog/all-together-finops-kubernetes-platform-engineering\">FinOps</a> and <a href=\"https://d2iq.com/blog/kubernetes-devsecops-platform-engineering\">DevSecOps</a>.</p><p>&nbsp;</p><p>It also is important to employ a platform based on <a href=\"https://d2iq.com/resources/solution-brief/pure-upstream-open-source-kubernetes\">pure CNCF-conformant Kubernetes</a>.This gives you portability, easier upgradeability, and trouble-free extensibility by easily accommodating the innovation that continually arises within the open-source community.&nbsp;</p><p>&nbsp;</p><p>To learn more about how you can turn around a failing cloud deployment and avoid failing in the first place, access these resources:&nbsp;</p><li><a href=\"https://d2iq.com/resources/webinar/failing-cloud-kubernetes\">Are you one of the 67% Failing in the Cloud? How to do Kubernetes Right</a></li><li><a href=\"https://d2iq.com/resources/webinar/doing-kubernetes-multi-cloud-hybrid-management-right\">Doing Kubernetes Multi-cloud and Hybrid Management Right</a></li><li><a href=\"https://d2iq.com/resources/webinar/avoid-kubernetes-deployment-pitfalls\">Success in the Cloud: How to Avoid Kubernetes Deployment Pitfalls</a></li><p>&nbsp;</p><p>To book a personal consultation, <a href=\"https://d2iq.com/contact\">contact the experts at D2iQ</a>.</p>"
    }
  },
  "BBC": {
    "title": "Getting inspired at the BBC Engineering Conference",
    "xmlUrl": "https://medium.com/feed/bbc-design-engineering",
    "htmlUrl": "https://medium.com/bbc-design-engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/bbc-design-engineering",
      "value": "Getting inspired at the BBC Engineering Conference"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/bbc-product-technology/getting-inspired-at-the-bbc-engineering-conference-79be80ec30b7?source=rss----ccd524e1760a---4"
      }
    ],
    "link": "https://medium.com/bbc-product-technology/getting-inspired-at-the-bbc-engineering-conference-79be80ec30b7?source=rss----ccd524e1760a---4",
    "id": "https://medium.com/p/79be80ec30b7",
    "guidislink": false,
    "tags": [
      {
        "term": "tech-conference",
        "scheme": null,
        "label": null
      },
      {
        "term": "conference",
        "scheme": null,
        "label": null
      },
      {
        "term": "bbc",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "David Andrade"
      }
    ],
    "author": "David Andrade",
    "author_detail": {
      "name": "David Andrade"
    },
    "published": "Thu, 17 Nov 2022 14:46:00 GMT",
    "published_parsed": [
      2022,
      11,
      17,
      14,
      46,
      0,
      3,
      321,
      0
    ],
    "updated": "2022-11-17T14:46:00.246Z",
    "updated_parsed": [
      2022,
      11,
      17,
      14,
      46,
      0,
      3,
      321,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/bbc-design-engineering",
        "value": "<p>The BBC\u2019s Engineering teams develop and run our digital products at scale\u200a\u2014\u200aensuring our digital services are available and accessible to audiences that need them the most, and as as reliable as our broadcast ones.</p><p>Recent times have tested the resilience of our teams and our services but we\u2019ve delivered at every moment. Overcoming significant technical challenges and enabling the BBC to serve millions of users with great content, across different products and\u00a0devices.</p><p>And so we thought it was about time that the team had a chance to get together, connect with each other face to face, and get inspired by how much we do for our audiences.</p><p>In October, over 600 colleagues from more than 150 technical teams from across the BBC got together in Manchester for the first BBC Engineering Conference. The day covered a range technical areas, knowledge sharing and networking. We had both internal and external speakers, as well as a leadership panel.</p><p>Sometimes we set out to inspire our teams and they inspire us even more in return, this was one of those moments. It sets up perfectly for a great end of 2022 and also for a future Digital First\u00a0BBC.</p><p>The video is a snapshot of what we got up\u00a0to!</p><a href=\"https://medium.com/media/5c612b0a119a4270f7864e92823c0d82/href\">https://medium.com/media/5c612b0a119a4270f7864e92823c0d82/href</a><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=79be80ec30b7\" width=\"1\" /><hr /><p><a href=\"https://medium.com/bbc-product-technology/getting-inspired-at-the-bbc-engineering-conference-79be80ec30b7\">Getting inspired at the BBC Engineering Conference</a> was originally published in <a href=\"https://medium.com/bbc-product-technology\">BBC Product &amp; Technology</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>The BBC\u2019s Engineering teams develop and run our digital products at scale\u200a\u2014\u200aensuring our digital services are available and accessible to audiences that need them the most, and as as reliable as our broadcast ones.</p><p>Recent times have tested the resilience of our teams and our services but we\u2019ve delivered at every moment. Overcoming significant technical challenges and enabling the BBC to serve millions of users with great content, across different products and\u00a0devices.</p><p>And so we thought it was about time that the team had a chance to get together, connect with each other face to face, and get inspired by how much we do for our audiences.</p><p>In October, over 600 colleagues from more than 150 technical teams from across the BBC got together in Manchester for the first BBC Engineering Conference. The day covered a range technical areas, knowledge sharing and networking. We had both internal and external speakers, as well as a leadership panel.</p><p>Sometimes we set out to inspire our teams and they inspire us even more in return, this was one of those moments. It sets up perfectly for a great end of 2022 and also for a future Digital First\u00a0BBC.</p><p>The video is a snapshot of what we got up\u00a0to!</p><a href=\"https://medium.com/media/5c612b0a119a4270f7864e92823c0d82/href\">https://medium.com/media/5c612b0a119a4270f7864e92823c0d82/href</a><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=79be80ec30b7\" width=\"1\" /><hr /><p><a href=\"https://medium.com/bbc-product-technology/getting-inspired-at-the-bbc-engineering-conference-79be80ec30b7\">Getting inspired at the BBC Engineering Conference</a> was originally published in <a href=\"https://medium.com/bbc-product-technology\">BBC Product &amp; Technology</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Kogan.com": {
    "title": "Decreasing CI Build times up to 50% by caching derived data using github actions.",
    "xmlUrl": "https://devblog.kogan.com/blog?format=RSS",
    "htmlUrl": "https://devblog.kogan.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://devblog.kogan.com/blog?format=RSS",
      "value": "Decreasing CI Build times up to 50% by caching derived data using github actions."
    },
    "authors": [
      {
        "name": "Gareth Lloyd"
      }
    ],
    "author": "Gareth Lloyd",
    "author_detail": {
      "name": "Gareth Lloyd"
    },
    "published": "Wed, 04 Oct 2023 05:16:00 +0000",
    "published_parsed": [
      2023,
      10,
      4,
      5,
      16,
      0,
      2,
      277,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://devblog.kogan.com/blog/decreasing-ci-build-times-up-to-50-by-caching-derived-data-using-github-actions"
      }
    ],
    "link": "https://devblog.kogan.com/blog/decreasing-ci-build-times-up-to-50-by-caching-derived-data-using-github-actions",
    "id": "5664c2f3e4b0957c43aa14f4:5666531469a91a17ec801e9c:651cf4540ffe8f1059b23b86",
    "guidislink": false,
    "summary": "<p>We had a problem. Our CI pipeline was increasingly becoming a bottleneck in our iOS continuous integration. We here at Kogan like to develop at a fast pace, however we were constantly being held up waiting for builds to complete, leading to a lot of frustration within the team. The rest of the engineering team had switched to using Github Actions(GHA), and with us still using CircleCI, it was time for us to make the change. This was the perfect time for us to re-evaluate how our pipeline was working, to ensure it was the most efficient that it can be. With a build time of over 30 minutes currently, there was a lot of room for improvement. </p>\n<p>As we were making a switch, we brainstormed some ideas of ways to improve the overall efficiency of our pipeline, and we kept returning to Derived data. This is how Apple handles build caching within Xcode, but could we use this within our CI Pipeline? Through a bit of investigation, it turns out we weren\u2019t the first to have this thought, and we used this blog post (<a href=\"https://michalzaborowski.medium.com/circleci-60-faster-builds-use-xcode-deriveddata-for-caching-96fb9a58930\">https://michalzaborowski.medium.com/circleci-60-faster-builds-use-xcode-deriveddata-for-caching-96fb9a58930</a>) as a base for our improvement.</p>\n<p>So, where to begin? We first started by replicating our current CI pipeline to GHA, which was pretty smooth other than a few challenges trying to access some of our private repositories. Our build times with this switch had slightly improved, but were still regularly more than 30 minutes to complete. We were already caching the swift packages we use in the project, however there was still plenty of room for improvement.</p>\n<p>First we need to ensure that we have fetched the latest changes to the repository, which can be done simply by using the option <code>fetch-depth: 0</code> on the checkout action in our existing initial step.</p>\n<blockquote>\n<ul>\n<li>uses: actions/checkout@v4\nwith:\ntoken: ${{ secrets.GITHUB_TOKEN }}\nfetch-depth: 0</li>\n</ul>\n</blockquote>\n<p>We then need to cache the derived data. We need to do this in two parts - caching the derived data when a pull request has been successfully merged, and then also restoring the latest derived data cache to the CI pipeline whenever a pull request is opened. </p>\n<p>In order to identify the latest develop commit, we use the GHA marketplace action which finds and creates a variable to be used for the latest develop commit SHA.</p>\n<blockquote>\n<ul>\n<li>name: Create variable for the nearest develop commit SHA\nuses: nrwl/nx-set-shas@v3\nwith: \nmain-branch-name: 'develop'</li>\n</ul>\n</blockquote>\n<p>Then, we need to create a separate pipeline, which will be used to save the derived data whenever a pull request is successfully saved to develop. This will be a very similar flow to our original however the difference will be that we save the cache at the end like the below. This will cache the tmp/derived-data file (which we have set to be the location of derived data in fastlane) to be stored against the latest develop commit SHA.</p>\n<blockquote>\n<ul>\n<li>uses: actions/cache/save@v3\nname: Save Derived Data Cache\nwith:\npath: tmp/derived-data\nkey: v1-derived-data-cache-${{ steps.setSHAs.outputs.head }}</li>\n</ul>\n</blockquote>\n<p>Next we need to get the correct cached derived data in our CI pipeline for pull requests. We need to again use the latest develop commit SHA to find the correct derived data cache. We use the restore version of the same action used above in order to find the right cache. This will either find a cache with an exact match, or it will fall back and use the most recent derived data with a partial match.</p>\n<blockquote>\n<ul>\n<li>uses: actions/cache/restore@v3\nname: Restore Derived Data Cache\nwith:\npath: tmp/derived-data\nkey: |\nv1-derived-data-cache-${{ steps.setSHAs.outputs.head }}\nv1-derived-data-cache-</li>\n</ul>\n</blockquote>\n<p>Similar to the mentioned blog post, GHA will also set the last modified time to be the time that the file was cloned. As Xcode is using this time, we need to update this in order to take advantage of the derived data caching. We managed to find a GHA marketplace action which allowed us to do this.</p>\n<blockquote>\n<ul>\n<li>name: Update mtime for incremental builds\nuses: chetan/git-restore-mtime-action@v2</li>\n</ul>\n</blockquote>\n<p>Last but not least, we need to set the IgnoreFileSystemDeviceInodeChanges=YES in order to ensure Xcode does not consider our cached derived data to be out of date.</p>\n<blockquote>\n<ul>\n<li>name: Set IgnoreFileSystemDeviceInodeChanges flag\nrun: defaults write com.apple.dt.XCBuild IgnoreFileSystemDeviceInodeChanges -bool YES</li>\n</ul>\n</blockquote>\n<p>Now that is all complete, we have successfully sped up our CI Pipelines, and decreased our build times by up to 50%. Before we started with CircleCI we were regularly exceeding 30 mins, and after caching derived data and switching to GHA, we got our builds down to roughly 15 mins. This is a massive improvement and has definitely made us developers much happier!</p>\n<p>Looking forward we do want to carry on improving our pipeline, and are always looking for ways to keep it up to date, and as fast as it can be. One problem we have encountered using this caching method is that there is no way to clear cache fully and force the build to run without the cached data in case of any build problems other than manually deleting each cache individually. This can be time consuming so we would like to investigate this further and try to find ways to mitigate this.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://devblog.kogan.com/blog?format=RSS",
      "value": "<p>We had a problem. Our CI pipeline was increasingly becoming a bottleneck in our iOS continuous integration. We here at Kogan like to develop at a fast pace, however we were constantly being held up waiting for builds to complete, leading to a lot of frustration within the team. The rest of the engineering team had switched to using Github Actions(GHA), and with us still using CircleCI, it was time for us to make the change. This was the perfect time for us to re-evaluate how our pipeline was working, to ensure it was the most efficient that it can be. With a build time of over 30 minutes currently, there was a lot of room for improvement. </p>\n<p>As we were making a switch, we brainstormed some ideas of ways to improve the overall efficiency of our pipeline, and we kept returning to Derived data. This is how Apple handles build caching within Xcode, but could we use this within our CI Pipeline? Through a bit of investigation, it turns out we weren\u2019t the first to have this thought, and we used this blog post (<a href=\"https://michalzaborowski.medium.com/circleci-60-faster-builds-use-xcode-deriveddata-for-caching-96fb9a58930\">https://michalzaborowski.medium.com/circleci-60-faster-builds-use-xcode-deriveddata-for-caching-96fb9a58930</a>) as a base for our improvement.</p>\n<p>So, where to begin? We first started by replicating our current CI pipeline to GHA, which was pretty smooth other than a few challenges trying to access some of our private repositories. Our build times with this switch had slightly improved, but were still regularly more than 30 minutes to complete. We were already caching the swift packages we use in the project, however there was still plenty of room for improvement.</p>\n<p>First we need to ensure that we have fetched the latest changes to the repository, which can be done simply by using the option <code>fetch-depth: 0</code> on the checkout action in our existing initial step.</p>\n<blockquote>\n<ul>\n<li>uses: actions/checkout@v4\nwith:\ntoken: ${{ secrets.GITHUB_TOKEN }}\nfetch-depth: 0</li>\n</ul>\n</blockquote>\n<p>We then need to cache the derived data. We need to do this in two parts - caching the derived data when a pull request has been successfully merged, and then also restoring the latest derived data cache to the CI pipeline whenever a pull request is opened. </p>\n<p>In order to identify the latest develop commit, we use the GHA marketplace action which finds and creates a variable to be used for the latest develop commit SHA.</p>\n<blockquote>\n<ul>\n<li>name: Create variable for the nearest develop commit SHA\nuses: nrwl/nx-set-shas@v3\nwith: \nmain-branch-name: 'develop'</li>\n</ul>\n</blockquote>\n<p>Then, we need to create a separate pipeline, which will be used to save the derived data whenever a pull request is successfully saved to develop. This will be a very similar flow to our original however the difference will be that we save the cache at the end like the below. This will cache the tmp/derived-data file (which we have set to be the location of derived data in fastlane) to be stored against the latest develop commit SHA.</p>\n<blockquote>\n<ul>\n<li>uses: actions/cache/save@v3\nname: Save Derived Data Cache\nwith:\npath: tmp/derived-data\nkey: v1-derived-data-cache-${{ steps.setSHAs.outputs.head }}</li>\n</ul>\n</blockquote>\n<p>Next we need to get the correct cached derived data in our CI pipeline for pull requests. We need to again use the latest develop commit SHA to find the correct derived data cache. We use the restore version of the same action used above in order to find the right cache. This will either find a cache with an exact match, or it will fall back and use the most recent derived data with a partial match.</p>\n<blockquote>\n<ul>\n<li>uses: actions/cache/restore@v3\nname: Restore Derived Data Cache\nwith:\npath: tmp/derived-data\nkey: |\nv1-derived-data-cache-${{ steps.setSHAs.outputs.head }}\nv1-derived-data-cache-</li>\n</ul>\n</blockquote>\n<p>Similar to the mentioned blog post, GHA will also set the last modified time to be the time that the file was cloned. As Xcode is using this time, we need to update this in order to take advantage of the derived data caching. We managed to find a GHA marketplace action which allowed us to do this.</p>\n<blockquote>\n<ul>\n<li>name: Update mtime for incremental builds\nuses: chetan/git-restore-mtime-action@v2</li>\n</ul>\n</blockquote>\n<p>Last but not least, we need to set the IgnoreFileSystemDeviceInodeChanges=YES in order to ensure Xcode does not consider our cached derived data to be out of date.</p>\n<blockquote>\n<ul>\n<li>name: Set IgnoreFileSystemDeviceInodeChanges flag\nrun: defaults write com.apple.dt.XCBuild IgnoreFileSystemDeviceInodeChanges -bool YES</li>\n</ul>\n</blockquote>\n<p>Now that is all complete, we have successfully sped up our CI Pipelines, and decreased our build times by up to 50%. Before we started with CircleCI we were regularly exceeding 30 mins, and after caching derived data and switching to GHA, we got our builds down to roughly 15 mins. This is a massive improvement and has definitely made us developers much happier!</p>\n<p>Looking forward we do want to carry on improving our pipeline, and are always looking for ways to keep it up to date, and as fast as it can be. One problem we have encountered using this caching method is that there is no way to clear cache fully and force the build to run without the cached data in case of any build problems other than manually deleting each cache individually. This can be time consuming so we would like to investigate this further and try to find ways to mitigate this.</p>"
    }
  },
  "Stride": {
    "title": "Breast Cancer Nearly Took my Life. Instead, it Made Me a Better CEO.",
    "xmlUrl": "https://www.stridenyc.com/blog/rss.xml",
    "htmlUrl": "https://blog.stridenyc.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.stridenyc.com/blog/rss.xml",
      "value": "Breast Cancer Nearly Took my Life. Instead, it Made Me a Better CEO."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.stridenyc.com/blog/breast-cancer-nearly-took-my-life.-instead-it-made-me-a-better-ceo.-heres-how"
      }
    ],
    "link": "https://www.stridenyc.com/blog/breast-cancer-nearly-took-my-life.-instead-it-made-me-a-better-ceo.-heres-how",
    "summary": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://www.stridenyc.com/blog/breast-cancer-nearly-took-my-life.-instead-it-made-me-a-better-ceo.-heres-how\" title=\"\"> <img alt=\"Colleagues celebrate and appreciate breast cancer awareness month.\" class=\"hs-featured-image\" src=\"https://www.stridenyc.com/hubfs/urban-pink-ribbon-month.png\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> \n<p>On September 5, 2015 I discovered a tumor in my left armpit. Two days later, I was diagnosed with Stage II HER2 Positive Breast Cancer. I was 41.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.stridenyc.com/blog/rss.xml",
      "value": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://www.stridenyc.com/blog/breast-cancer-nearly-took-my-life.-instead-it-made-me-a-better-ceo.-heres-how\" title=\"\"> <img alt=\"Colleagues celebrate and appreciate breast cancer awareness month.\" class=\"hs-featured-image\" src=\"https://www.stridenyc.com/hubfs/urban-pink-ribbon-month.png\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> \n<p>On September 5, 2015 I discovered a tumor in my left armpit. Two days later, I was diagnosed with Stage II HER2 Positive Breast Cancer. I was 41.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.stridenyc.com/blog/rss.xml",
        "value": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://www.stridenyc.com/blog/breast-cancer-nearly-took-my-life.-instead-it-made-me-a-better-ceo.-heres-how\" title=\"\"> <img alt=\"Colleagues celebrate and appreciate breast cancer awareness month.\" class=\"hs-featured-image\" src=\"https://www.stridenyc.com/hubfs/urban-pink-ribbon-month.png\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> \n<p>On September 5, 2015 I discovered a tumor in my left armpit. Two days later, I was diagnosed with Stage II HER2 Positive Breast Cancer. I was 41.</p>  \n<img alt=\"\" height=\"1\" src=\"https://track.hubspot.com/__ptq.gif?a=2136473&amp;k=14&amp;r=https%3A%2F%2Fwww.stridenyc.com%2Fblog%2Fbreast-cancer-nearly-took-my-life.-instead-it-made-me-a-better-ceo.-heres-how&amp;bu=https%253A%252F%252Fwww.stridenyc.com%252Fblog&amp;bvt=rss\" style=\"width: 1px!important;\" width=\"1\" />"
      }
    ],
    "tags": [
      {
        "term": "People & Culture",
        "scheme": null,
        "label": null
      }
    ],
    "published": "Mon, 02 Oct 2023 16:00:00 GMT",
    "published_parsed": [
      2023,
      10,
      2,
      16,
      0,
      0,
      0,
      275,
      0
    ],
    "authors": [
      {
        "name": "Debbie Madden",
        "email": "debbie@stridenyc.com"
      }
    ],
    "author": "debbie@stridenyc.com (Debbie Madden)",
    "author_detail": {
      "name": "Debbie Madden",
      "email": "debbie@stridenyc.com"
    },
    "id": "https://www.stridenyc.com/blog/breast-cancer-nearly-took-my-life.-instead-it-made-me-a-better-ceo.-heres-how",
    "guidislink": false,
    "updated": "2023-10-02T16:00:00Z",
    "updated_parsed": [
      2023,
      10,
      2,
      16,
      0,
      0,
      0,
      275,
      0
    ]
  },
  "BitTorrent": {
    "title": "HTTP/RPC Security Vulnerabilities Resolved in uTorrent, BitTorrent and uTorrent Web",
    "xmlUrl": "https://engineering.bittorrent.com/feed/",
    "htmlUrl": "http://engineering.bittorrent.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.bittorrent.com/feed/",
      "value": "HTTP/RPC Security Vulnerabilities Resolved in uTorrent, BitTorrent and uTorrent Web"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.bittorrent.com/2018/02/22/httprpc-security-vulnerabilities-resolved-in-utorrent-bittorrent-and-utorrent-web/"
      }
    ],
    "link": "https://engineering.bittorrent.com/2018/02/22/httprpc-security-vulnerabilities-resolved-in-utorrent-bittorrent-and-utorrent-web/",
    "comments": "https://engineering.bittorrent.com/2018/02/22/httprpc-security-vulnerabilities-resolved-in-utorrent-bittorrent-and-utorrent-web/#comments",
    "authors": [
      {
        "name": "David Rees"
      }
    ],
    "author": "David Rees",
    "author_detail": {
      "name": "David Rees"
    },
    "published": "Thu, 22 Feb 2018 23:58:19 +0000",
    "published_parsed": [
      2018,
      2,
      22,
      23,
      58,
      19,
      3,
      53,
      0
    ],
    "tags": [
      {
        "term": "Engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "Uncategorized",
        "scheme": null,
        "label": null
      },
      {
        "term": "\u00b5Torrent",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.gyre.wpengine.com/?p=294",
    "guidislink": false,
    "summary": "A fix for multiple vulnerabilities affecting all uTorrent, BitTorrent and uTorrent Web Windows users is now available for immediate download at the links below. We must stress that while this is a vulnerability that can be exploited to trigger unauthorized downloads to take place, BitTorrent Inc. is not aware of any incidents related to these [&#8230;]",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.bittorrent.com/feed/",
      "value": "A fix for multiple vulnerabilities affecting all uTorrent, BitTorrent and uTorrent Web Windows users is now available for immediate download at the links below. We must stress that while this is a vulnerability that can be exploited to trigger unauthorized downloads to take place, BitTorrent Inc. is not aware of any incidents related to these [&#8230;]"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.bittorrent.com/feed/",
        "value": "<p>A fix for multiple vulnerabilities affecting all uTorrent, BitTorrent and uTorrent Web Windows users is now available for immediate download at the links below. We must stress that while this is a vulnerability that can be exploited to trigger unauthorized downloads to take place, BitTorrent Inc. is not aware of any incidents related to these vulnerabilities. As always, we highly encourage all of our customers to stay up to date.  Android and Mac users are not affected by the reported vulnerabilities.</p>\n<p>Download the latest builds:</p>\n<p><a href=\"https://download-lb.utorrent.com/uuid/55e91716-3803-49ba-b054-8de686b87c3e\" target=\"_blank\">uTorrent Stable 3.5.3.44358</a><br />\n<a href=\"https://www.bittorrent.com/downloads/complete/track/stable/os/win\" target=\"_blank\">Bittorrent Stable 7.10.3.44359</a><br />\n<a href=\"https://www.utorrent.com/downloads/complete/track/beta/os/win\" target=\"_blank\">uTorrent Beta 3.5.3.44352</a><br />\n<a href=\"https://download-new.utorrent.com/endpoint/utweb/track/beta/os/win\" target=\"_blank\">uTorrent Web 0.12.0.502</a></p>\n<p>The team began rolling out the update to beta uTorrent Windows users via the auto update mechanism on Feb 16, 2018. As of today, Feb 22, 2018, the rollout for beta users has concluded and the stable rollout has started. Included in the latest builds are fixes to the way uTorrent and uTorrent Web authenticate WebUI requests and generate session and authentication tokens. In addition to this, the updates clamp down on guest account access limits and enforce more checks on potentially malicious HTTP headers sent to the client. </p>\n<p>Customers and developers of 3rd-party applications that rely on the default-open state of port 10000 should be aware that moving forward, clients <em>will no longer be discoverable over port 10000</em>. Pairing negotiation <em>is now only allowed over a mutually agreed upon port</em>. Customers can set this port manually by enabling WebUI functionality via Advanced->WebUI-> Enable Web UI and then specifying a port under the Connectivity section.</p>\n<p><img alt=\"WebUISettings\" class=\"aligncenter size-full wp-image-295\" height=\"496\" src=\"https://engineering.bittorrent.com/files/2018/02/WebUISettings.png\" width=\"667\" /></p>\n<p>You can find the full changelog here: </p>\n<blockquote class=\"wp-embedded-content\"><p><a href=\"https://blog.utorrent.com/release-notes/utorrent-3-5-3-for-windows-build-44358/\">uTorrent 3.5.3 For Windows (build 44358)</a></p></blockquote>\n<p></p>"
      }
    ],
    "wfw_commentrss": "https://engineering.bittorrent.com/2018/02/22/httprpc-security-vulnerabilities-resolved-in-utorrent-bittorrent-and-utorrent-web/feed/",
    "slash_comments": "8"
  },
  "Blender": {
    "title": "A New Developer Documentation Platform",
    "xmlUrl": "https://code.blender.org/rss",
    "htmlUrl": "https://code.blender.org/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://code.blender.org/feed/",
      "value": "A New Developer Documentation Platform"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://code.blender.org/2023/12/a-new-developer-documentation-platform/"
      }
    ],
    "link": "https://code.blender.org/2023/12/a-new-developer-documentation-platform/",
    "comments": "https://code.blender.org/2023/12/a-new-developer-documentation-platform/#comments",
    "authors": [
      {
        "name": "Julian Eisel"
      }
    ],
    "author": "Julian Eisel",
    "author_detail": {
      "name": "Julian Eisel"
    },
    "published": "Wed, 13 Dec 2023 16:04:21 +0000",
    "published_parsed": [
      2023,
      12,
      13,
      16,
      4,
      21,
      2,
      347,
      0
    ],
    "tags": [
      {
        "term": "General Development",
        "scheme": null,
        "label": null
      },
      {
        "term": "Technical Documentation",
        "scheme": null,
        "label": null
      },
      {
        "term": "documentation",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://code.blender.org/?p=11354",
    "guidislink": false,
    "summary": "A new platform to foster a shift in developer documentation culture.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://code.blender.org/feed/",
      "value": "A new platform to foster a shift in developer documentation culture."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://code.blender.org/feed/",
        "value": "<p><em>In this proposal, Julian Eisel highlights how a more accessible and powerful documentation platform can help the push towards a development culture more centered around documentation and design.</em></p>\n\n\n\n<div class=\"wp-block-group is-style-default has-medium-font-size is-layout-constrained wp-block-group-is-layout-constrained\" style=\"padding-bottom: 0.45em;\">\n<p><em>The focus is on issues with higher level technical documentation (architecture, modules, overall intent, etc.), not lower level API documentation.</em></p>\n</div>\n\n\n\n<div class=\"wp-block-columns are-vertically-aligned-top is-style-box is-layout-flex wp-container-core-columns-layout-1 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-vertically-aligned-top is-style-default has-small-font-size is-layout-flow wp-block-column-is-layout-flow\" style=\"padding-top: 0; padding-right: 0; padding-bottom: 0; padding-left: 0;\">\n<p>This post is based on a presentation given by Julian Eisel at the Blender headquarters during November 2023.</p>\n</div>\n\n\n\n<div class=\"wp-block-column is-vertically-aligned-top is-layout-flow wp-block-column-is-layout-flow\">\n<div class=\"wp-block-buttons is-content-justification-center is-layout-flex wp-container-core-buttons-layout-1 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button has-custom-width wp-block-button__width-100 has-custom-font-size is-style-outline has-small-font-size\"><a class=\"wp-block-button__link wp-element-button\" href=\"https://code.blender.org/wp-content/uploads/2023/12/A-New-Developer-Documentation-Platform.pdf?x36445\" rel=\"https://code.blender.org/wp-content/uploads/2023/12/a-new-developer-documentation-platform.pdf\">Download Slides</a></div>\n</div>\n</div>\n</div>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#the-current-platform\"><h2 class=\"wp-block-heading is-style-default\" id=\"the-current-platform\">The Current Platform</h2></a>\n\n\n\n<p>To start off easy, let&rsquo;s analyze the current wiki-based documentation system.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-2023-12-05-at-15.52.27.png?x36445\"><img alt=\"The Wiki landing page.\" class=\"wp-image-11525\" height=\"699\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-2023-12-05-at-15.52.27-1024x699.png?x36445\" width=\"1024\" /></a></figure>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#the-editing-experience\"><h3 class=\"wp-block-heading\" id=\"the-editing-experience\">The Editing Experience</h3></a>\n\n\n\n<p>The MediaWiki text editor feels outdated, and uses a specific syntax (not Markdown), but most of all provides a very cumbersome workflow for uploading images. These aspects affect the motivation of developers when using it.</p>\n\n\n\n<p>A more modern alternative called <a href=\"https://hackmd.io/\">HackMD</a> is used much more often instead. That is a Markdown editor with live-preview and collaborative editing, where multiple people can work on a document at the same time.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-15-30-09-1.png?x36445\"><img alt=\"Live editing in HackMD: Edit Markdown on the left, see the rendered result on the right - updated as you type.\" class=\"wp-image-11417\" height=\"575\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-15-30-09-1-1024x575.png?x36445\" width=\"1024\" /></a><figcaption class=\"wp-element-caption\">Live editing in HackMD: Edit Markdown on the left, see the rendered result on the right &ndash; updated as you type.</figcaption></figure>\n\n\n\n<p>Some developers used this for technical documentation too and it works well. Eventually, the content needs to be moved to the wiki, which means having to convert the Markdown syntax to the wiki syntax. Sometimes this meant that content wouldn&rsquo;t end up getting ported.</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#navigation-and-structure\"><h3 class=\"wp-block-heading\" id=\"navigation-and-structure\">Navigation and Structure</h3></a>\n\n\n\n<div class=\"wp-block-group is-nowrap is-layout-flex wp-container-core-group-layout-2 wp-block-group-is-layout-flex\">\n<p>Currently, the navigation on the wiki provides a limited amount of entry points (for the most used pages) and requires manual edits to add new entries, both for the sidebar and for breadcrumbs. This means that often it is not easy to understand the context of a document, and it is also not easy to find the document on the platform starting from the landing page.</p>\n</div>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-15-48-03.png?x36445\"><img alt=\"Wiki page navigation: Unrelated, hard-coded top level navigation on the left, current page navigation on the right. There's no good navigation in-between.\" class=\"wp-image-11433\" height=\"551\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-15-48-03-1024x551.png?x36445\" width=\"1024\" /></a><figcaption class=\"wp-element-caption\">Wiki page navigation: Unrelated, hard-coded top level navigation on the left, current page navigation on the right. There&rsquo;s no good navigation in-between.</figcaption></figure>\n\n\n\n<p>More effort can be put in categorizing content as well, making entry-level docs easier to find.</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#disconnected-from-the-code\"><h3 class=\"wp-block-heading\" id=\"disconnected-from-the-code\">Disconnected From the Code</h3></a>\n\n\n\n<p>The wiki is a separate website that you typically don&rsquo;t have open unless you consciously decide to use it. Other organizations found that such platforms tend to see less activity from developers; they require a context switch. The closer documentation is to the code, where developers do their actual work, the more likely they are to work on it as well.</p>\n\n\n\n<p>Imagine if descriptions for tooltips would live on a separate webpage. They would probably get outdated quite quickly. Currently they live in the source code, and developers maintain them actively (even if there&rsquo;s a lot of room for improvement still).</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#invite-only-platform\"><h3 class=\"wp-block-heading\" id=\"invite-only-platform\">Invite-only Platform</h3></a>\n\n\n\n<p>To prevent spam and abuse, the wiki has been an invite-only platform for several years now. This makes extremely hard for community members to get involved and contribute.</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#unrelated-to-the-platform\"><h3 class=\"wp-block-heading\" id=\"unrelated-to-the-platform\">Unrelated to the Platform</h3></a>\n\n\n\n<p><strong>There is a shortage of technical documentation.</strong> While there are a few well documented areas, and more general information like build instructions are covered well, a lot of Blender&rsquo;s designs are not documented, and much of the existing documentation is not up-to-date or simply not that useful.</p>\n\n\n\n<p>The practical difficulty of contributing improvements, and the lack of good examples has led many developers to not open up the wiki and contribute to it.  </p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" />\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#documentation-culture\"><h2 class=\"wp-block-heading\" id=\"documentation-culture\">Documentation Culture</h2></a>\n\n\n\n<p>Let&rsquo;s take a step back, and look for more intrinsic motivations. In fact, this article isn&rsquo;t just about a change in platform. It is looking for something bigger: <em>Can we build a new developer documentation </em>culture<em>?</em></p>\n\n\n\n<p>That is a big question, isn&rsquo;t it? Well, here&rsquo;s some good news: others have done it. Check out <a href=\"https://www.doctave.com/blog/2021/09/07/how-google-twitter-and-spotify-build-culture-of-documentation.html\">&ldquo;How Google, Twitter and Spotify built a culture of documentation&rdquo;</a>.</p>\n\n\n\n<p>This change was driven by technical writers. Originally technical writers that felt like they failed in addressing the problem they were supposed to solve. They would just jump from project to project, leaving behind brand new documentation that would become outdated in no time. Nowadays, their technical documentation gets <strong>used and updated all the time &ndash; by engineers!</strong> Can it be true?</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#how-did-they-do-it\"><h3 class=\"wp-block-heading\" id=\"how-did-they-do-it\">How did they do it?</h3></a>\n\n\n\n<p>Various resources from Twitter, Google and Spotify tell their story. They closely followed the same approach, even if specifics differ. Briefly, here are some key findings:</p>\n\n\n\n<ul>\n<li><strong>Culture of docs:</strong> Regular documentation sprints. Educate developers on technical writing. Lead by example.</li>\n\n\n\n<li><strong>Standardize and centralize:</strong> Provide answers about writing documentation before they arise. Clear examples and templates. Share the same platform for all documentation.</li>\n\n\n\n<li><strong>Feedback loops:</strong> Make it easy to give feedback (e.g. mark text in documentation &gt; right click &gt; &ldquo;<em>Report a Bug</em>&rdquo;).</li>\n\n\n\n<li><strong>Keep it simple:</strong> Don&rsquo;t overcomplicate; avoid/remove any points of friction so the actual content is the focus.</li>\n</ul>\n\n\n\n<p>The technical writers are still there, but their role changed to helping and empowering developers. For example, they maintain the documentation infrastructure and make relevant strategic decisions. They make sure documentation just works for the developers/engineers.</p>\n\n\n\n<p>This brings us to what appears to be the most important change: <em>Fiercely optimize for the engineer.</em></p>\n\n\n\n<p>Twitter, Google and Spotify have committed to a documentation infrastructure that is based on the idea of <strong>Docs as Code</strong>.</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#docs-as-code\"><h3 class=\"wp-block-heading\" id=\"docs-as-code\">Docs as Code</h3></a>\n\n\n\n<p>The idea is simple: Treat documentation like code. Employ a workflow that developers are comfortable with; make them feel at home. This includes features like version control, collaboration and automation.</p>\n\n\n\n<p>More specifically, Docs as Code typically features the following:</p>\n\n\n\n<ul>\n<li>Simple markup language (Markdown, ReStructured text, etc.)</li>\n\n\n\n<li>Version controlled repository, close to the code</li>\n\n\n\n<li>Pull requests, versioning, branching</li>\n\n\n\n<li>Forge integration (Gitea, Github, etc.)</li>\n\n\n\n<li>Continuous delivery, automated checks</li>\n</ul>\n\n\n\n<p>We actually have some experience with such platforms. The <a href=\"https://docs.blender.org/manual/en/latest/\">Blender Manual</a>, <a href=\"https://studio.blender.org/pipeline/\">Blender Studio pipeline documentation</a> and <a href=\"https://flamenco.blender.org/\">Flamenco documentation</a> follow a similar approach. Let&rsquo;s try to bring this to the developer documentation. This is where it can really shine.</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#new-platform-proposal\"><h2 class=\"wp-block-heading is-style-default\" id=\"new-platform-proposal\">New Platform Proposal</h2></a>\n\n\n\n<p>Things should be simple, so they key elements of the new platform are simple as well:</p>\n\n\n\n<ul>\n<li><a href=\"https://squidfunk.github.io/mkdocs-material/\">Material for MkDocs</a></li>\n\n\n\n<li>Continuous delivery via buildbot</li>\n\n\n\n<li>Edit with preview in Gitea</li>\n\n\n\n<li>Git LFS (Large File Storage) repository</li>\n\n\n\n<li>Possibly pulled with <code>make update</code></li>\n\n\n\n<li>URL: <a href=\"http://developer.blender.org/docs\">developer.blender.org/docs</a></li>\n</ul>\n\n\n\n<p><a href=\"https://squidfunk.github.io/mkdocs-material/\">Material for MkDocs</a> is a <a href=\"https://m3.material.io/\">Material</a> based theme and framework around the <a href=\"https://www.mkdocs.org/\">MkDocs</a> static site generator. Essentially it turns Markdown files into HTML pages that look great and offer a great browsing experience. It has been chosen over alternatives (such as Sphinx, VitePress and Hugo) since it seems like the best fitting platform. The main features are:</p>\n\n\n\n<ul>\n<li>Easy to set up and use. Developers will have it up and running in an instant.</li>\n\n\n\n<li>Markdown is readable in source, widely used (for example on most developer platforms) and well supported. Many IDEs have builtin Markdown editing and previewing support. Copy &amp; paste from HackMD possible.</li>\n\n\n\n<li>Modern looking, rich in features (client side search, dark mode, &hellip; see below) and a big amount of common <a href=\"https://python-markdown.github.io/extensions/\">markdown extensions</a> and <a href=\"https://github.com/mkdocs/catalog\">plugins</a>.</li>\n\n\n\n<li>Live reloading.</li>\n\n\n\n<li>Python based.</li>\n\n\n\n<li>Good search.</li>\n</ul>\n\n\n\n<p>Overall it&rsquo;s a great documentation experience for both writing and browsing.</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#impressions\"><h3 class=\"wp-block-heading\" id=\"impressions\">Impressions</h3></a>\n\n\n\n<p>There is an experimental setup of the new documentation platform available under <a href=\"http://developer.blender.org/docs\">developer.blender.org/docs</a>.</p>\n\n\n\n<p>This is how a documentation page looks like:</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-16-32-28.png?x36445\"><img alt=\"Documentation page for the GPU module.\" class=\"wp-image-11482\" height=\"547\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-16-32-28-1024x547.png?x36445\" width=\"1024\" /></a></figure>\n\n\n\n<p>Note the top-level navigation at the top, the navigation for the current category on the left, and the current page navigation on the right.</p>\n\n\n\n<p>A simple toggle in the header switches between light and dark mode:</p>\n\n\n<div class=\"compare-media\" id=\"compare-media-block_ba697b63d95523733d36df125e183d91\">\n\t<div class=\"images-compare\">\n\t\t<div style=\"display: none;\">\n\t\t\t\n\t\t\t\t\t\t\t<img alt=\"\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-16-10-45-1024x518.png?x36445\" />\n\t\t\t\t\t</div>\n\n\t\t<div>\n\t\t\t\n\t\t\t\t\t\t\t<img alt=\"\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-16-10-41-1024x518.png?x36445\" />\n\t\t\t\t\t</div>\n\t</div>\n\n\t\n  </div>\n\n\n\n\n<p>Material for MkDocs supports <a href=\"https://github.com/mermaid-js/mermaid\">Mermaid</a> to define diagrams as text in Markdown, and render them on the fly using the theme colors:</p>\n\n\n<div class=\"compare-media\" id=\"compare-media-block_43e67e43eb1a69b9bd8352b8268e490e\">\n\t<div class=\"images-compare\">\n\t\t<div style=\"display: none;\">\n\t\t\t\n\t\t\t\t\t\t\t<img alt=\"\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-16-21-59-1024x541.png?x36445\" />\n\t\t\t\t\t</div>\n\n\t\t<div>\n\t\t\t\n\t\t\t\t\t\t\t<img alt=\"\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-16-21-56-1024x541.png?x36445\" />\n\t\t\t\t\t</div>\n\t</div>\n\n\t\n  </div>\n\n\n\n\n<p>Who would&rsquo;ve thought that creating such diagrams can actually be fun (for developers)!</p>\n\n\n\n<p>Lastly, Material for MkDocs comes with a great working search feature:</p>\n\n\n<div class=\"tabs\" id=\"tabs-block_afe1142d5bea9ef279402fb68a01472f\">\n\t<div>\n\t\t<ul class=\"nav nav-tabs\">\n\t\t\t\t\t\t<li class=\"nav-item\">\n\t\t\t\t<a class=\"nav-link active\" href=\"https://code.blender.org/feed/#t-dark-0\" id=\"t-dark-0-tab\">\n\t\t\t\t\tDark\t\t\t\t</a>\n\t\t\t</li>\n\t\t\t\t\t\t<li class=\"nav-item\">\n\t\t\t\t<a class=\"nav-link \" href=\"https://code.blender.org/feed/#t-light-1\" id=\"t-light-1-tab\">\n\t\t\t\t\tLight\t\t\t\t</a>\n\t\t\t</li>\n\t\t\t\t\t</ul>\n\t\t<div class=\"tab-content text-center\">\n\t\t\t\t\t\t\t<div class=\"tab-pane show active\" id=\"t-dark-0\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<img alt=\"Dark\" class=\"img-fluid rounded\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-15-55-00.png?x36445\" />\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t<div class=\"tab-pane \" id=\"t-light-1\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<img alt=\"Light\" class=\"img-fluid rounded\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-15-55-08.png?x36445\" />\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t</div>\n\t</div>\n\n  </div>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#editing\"><h3 class=\"wp-block-heading\" id=\"editing\">Editing</h3></a>\n\n\n\n<p>There are two main workflows for editing pages with the new platform. Online and offline editing.</p>\n\n\n\n<p>To edit pages online, simply click the editing icon at the top of a page: </p>\n\n\n\n<figure class=\"wp-block-image size-full\"><a href=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-19-06-38.png?x36445\"><img alt=\"Edit icon.\" class=\"wp-image-11508\" height=\"75\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-19-06-38.png?x36445\" width=\"73\" /></a></figure>\n\n\n\n<p>This brings you to Gitea, where you can immediately edit the page&rsquo;s Markdown. </p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-19-10-32.png?x36445\"><img alt=\"Edit documentation pages on Gitea with its builtin Markdown editor.\" class=\"wp-image-11511\" height=\"532\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-19-10-32-1024x532.png?x36445\" width=\"1024\" /></a></figure>\n\n\n\n<p>Although a side-by-side view would be a lot nicer, a simple click on the <em>Preview</em> tab gives a preview of the rendered result: </p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-19-10-40.png?x36445\"><img alt=\"Gitea's preview for Markdown text. This can be enabled by clicking on the &quot;Preview&quot; tab.\" class=\"wp-image-11512\" height=\"532\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-12-04-19-10-40-1024x532.png?x36445\" width=\"1024\" /></a></figure>\n\n\n\n<p>This is Gitea&rsquo;s Markdown preview, so there might be smaller differences to the output of Material for MkDocs. But it works extremely well. Plus, as you can see, Gitea supports the Mermaid diagrams too!</p>\n\n\n\n<p>The second way to edit is offline. Many editors support Markdown editing and previewing. Here is a setup in Visual Studio Code:</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-11-27-13-06-48.png?x36445\"><img alt=\"Visual studio code setup for editing Markdown. The Markdown text is edited on the left, the result generated with Material for MkDocs is rendered on the right.\" class=\"wp-image-11515\" height=\"535\" src=\"https://code.blender.org/wp-content/uploads/2023/12/Screenshot-from-2023-11-27-13-06-48-1024x535.png?x36445\" width=\"1024\" /></a></figure>\n\n\n\n<p>MkDocs supports live reloading. Every time you save the file, the preview on the right gets updated. This is using the <a href=\"https://marketplace.visualstudio.com/items?itemName=ms-vscode.live-server\">live preview extension</a> for Visual Studio Code, but the builtin Markdown preview works well too.</p>\n\n\n\n<p>When done, you can simply commit and push the edits (or create a pull request). Either via the Gitea UI when editing online, or manually, using the Git interface of your choice. Buildbot will update the documentation output on <a href=\"http://developer.blender.org/docs\">developer.blender.org/docs</a> within few minutes.</p>\n\n\n\n<p>Since this is Markdown, there is another convenient way to edit the docs: HackMD. Work with live preview and in collaboration with others, then simply copy the result from there to the documentation!</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#goodbye-wiki\"><h3 class=\"wp-block-heading\" id=\"goodbye-wiki\">Goodbye Wiki?</h3></a>\n\n\n\n<p>The new platform would replace the current <a href=\"https://wiki.blender.org/wiki/Main_Page\">wiki</a>. All the documentation, as well as the release notes can move to the new platform. Personal pages like the weekly reports of developers can be moved to personal repositories on Gitea, also using simple Markdown.</p>\n\n\n\n<p>Although converters from Wiki syntax to Markdown are available, the transition will require manual work. Mostly to fix issues from the conversion, fix links, add missing images, etc. A few people volunteered to help already, more help would be welcome.</p>\n\n\n\n<a class=\"is-heading-anchor\" href=\"https://code.blender.org/feed/#status-next-steps\"><h2 class=\"wp-block-heading\" id=\"status-next-steps\">Status &amp; Next Steps</h2></a>\n\n\n\n<p>Most preparation work is done:</p>\n\n\n\n<ul>\n<li>Research, testing and experiments</li>\n\n\n\n<li>Buy-in from developers and stakeholders</li>\n\n\n\n<li><a href=\"https://builder.blender.org/admin/#/builders/192\">Buildbot continuous delivery setup</a> (push changes, Buildbot generates and publishes output to <a href=\"http://developer.blender.org/docs\">developer.blender.org/docs</a>)</li>\n\n\n\n<li>Hosting on <a href=\"http://developer.blender.org/docs\">developer.blender.org/docs</a></li>\n\n\n\n<li><a href=\"https://projects.blender.org/blender/blender-developer-docs\">blender-developer-docs</a> Git LFS repository with Material for MkDocs setup &amp; customizations</li>\n</ul>\n\n\n\n<p>Follow the latest status on the dedicated task: <a href=\"https://projects.blender.org/blender/blender/issues/116055\">#116055: New Developer Documentation Platform</a></p>\n\n\n\n<p>This means we are ready to prepare the actual transition, whereby the wiki will be archived. Once this is done we can decide if we want to include the developer documentation as part of the source code or its additional resources (updated together with the source code via <code>make update</code>). This would move the documentation closer to the code, and ensure there&rsquo;s easy and continuously updated access. Further, we can investigate ways to include internal API documentation (generated from C/C++ API comments using <a href=\"https://www.doxygen.nl/\">Doxygen</a>) as part of the platform.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" />\n\n\n\n<p>Building a developer documentation culture is challenging but possible, like other organizations show. Maybe all it takes is a few clever changes, and a bit of pushing to reach some tipping point; and then it snowballs!</p>\n\n\n\n<p>The truth is, developers know that they should be writing technical documentation. They just don&rsquo;t feel empowered enough to do so, there are too many hurdles and too few incentives. It is time to do some changes:</p>\n\n\n\n<ul>\n<li>A new documentation platform that is optimized for the engineer (<em>docs as code)</em> and removes friction from the workflow.</li>\n\n\n\n<li>Make it easy to write documentation by providing clear examples, templates, tools and education.</li>\n\n\n\n<li>Rethink how we write documentation. Make it actually useful for new and experienced developers alike.</li>\n\n\n\n<li>Foster a culture of documentation. Push until using and writing technical documentation becomes part of every day life for a developer &mdash; like it happened with unit testing.</li>\n\n\n\n<li>Open up to the community. A new culture can be a lot more exciting for technical writers or the general community to get involved.</li>\n</ul>\n\n\n\n<p>Or, how the technical writers who revolutionized technical documentation at Google put it:</p>\n\n\n\n<blockquote class=\"wp-block-quote\">\n<p><em><strong>First tooling, then culture. </strong>[&hellip;]<strong> Focus on the Engineer.</strong></em></p>\n<cite><a href=\"http://The%20Knowledge:%20Towards%20a%20Culture%20of%20Engineering%20Documentation\">The Knowledge: Towards a Culture of Engineering Documentation &ndash; Riana MacNamara, Google</a></cite></blockquote>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" />\n\n\n\n<div class=\"wp-block-group is-style-box mt-5 is-layout-flow wp-block-group-is-layout-flow\">\n<h4 class=\"wp-block-heading\" style=\"font-size: 28px;\">Support the Future of Blender</h4>\n\n\n\n<p class=\"mb-0 is-style-default has-medium-font-size\">Donate and support Blender Foundation to work on core Blender development.</p>\n\n\n\n<div class=\"wp-block-buttons is-content-justification-right is-layout-flex wp-container-core-buttons-layout-2 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button has-custom-font-size is-style-accent plausible-event-name=Block+DevFund+Button has-medium-font-size\"><a class=\"wp-block-button__link wp-element-button\" href=\"https://fund.blender.org/?utm_medium=reusable-block\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Donate</strong> to Blender</a></div>\n</div>\n</div>"
      }
    ],
    "wfw_commentrss": "https://code.blender.org/2023/12/a-new-developer-documentation-platform/feed/",
    "slash_comments": "2"
  },
  "Feedzai": {
    "title": "AML Reimagined: LaundroGraph Exploits Graph Structure to Assist Anti-Money Laundering Activities",
    "xmlUrl": "https://medium.com/feed/feedzaitech",
    "htmlUrl": "https://medium.com/feedzaitech",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/feedzaitech",
      "value": "AML Reimagined: LaundroGraph Exploits Graph Structure to Assist Anti-Money Laundering Activities"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/feedzaitech/aml-reimagined-laundrograph-exploits-graph-structure-to-assist-anti-money-laundering-activities-c72763f38207?source=rss----e11168e7fe6b---4"
      }
    ],
    "link": "https://medium.com/feedzaitech/aml-reimagined-laundrograph-exploits-graph-structure-to-assist-anti-money-laundering-activities-c72763f38207?source=rss----e11168e7fe6b---4",
    "id": "https://medium.com/p/c72763f38207",
    "guidislink": false,
    "tags": [
      {
        "term": "artificial-intelligence",
        "scheme": null,
        "label": null
      },
      {
        "term": "self-supervised-learning",
        "scheme": null,
        "label": null
      },
      {
        "term": "anti-money-laundering",
        "scheme": null,
        "label": null
      },
      {
        "term": "graph-neural-networks",
        "scheme": null,
        "label": null
      },
      {
        "term": "deep-learning",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "M\u00e1rio Cardoso"
      }
    ],
    "author": "M\u00e1rio Cardoso",
    "author_detail": {
      "name": "M\u00e1rio Cardoso"
    },
    "published": "Thu, 28 Sep 2023 09:41:58 GMT",
    "published_parsed": [
      2023,
      9,
      28,
      9,
      41,
      58,
      3,
      271,
      0
    ],
    "updated": "2023-09-28T09:41:58.535Z",
    "updated_parsed": [
      2023,
      9,
      28,
      9,
      41,
      58,
      3,
      271,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/feedzaitech",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*NqGgA5KjSMJZdLXkVPG3Fg.png\" /></figure><h3>1. Motivation</h3><p>Money laundering involves the illegal practice of making the origins of criminally obtained money appear legitimate. Financial institutions implement anti-money laundering (AML) processes to detect suspicious activities based on predefined rules. These rules trigger an investigation process that is both tedious and time-consuming, undertaken by compliance professionals. The availability of tools that can simplify and speed up these investigations is crucial in allowing for more informed decision-making and optimizing the use of human experts\u2019\u00a0time.</p><p>In this blog post, we introduce <strong>LaundroGraph</strong>, a novel system developed at Feedzai that supports the money laundering reviewing process by providing meaningful AI-powered insights to the expert regarding an alerted entity\u2019s transactional behavior. These insights are supplied during the investigation, accelerating and facilitating the process. LaundroGraph is based on graph-neural networks, trained in a fully self-supervised manner (yes, it doesn\u2019t need\u00a0labels).</p><p>This blog post is based on the paper, \u201cLaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering\u201d by M\u00e1rio Cardoso, Pedro Saleiro, Pedro Bizarro, that was published at the Third ACM International Conference on AI in Finance. You can find a copy of the paper <a href=\"https://research.feedzai.com/publication/laundrograph-self-supervised-graph-representation-learning-for-anti-money-laundering/\">here</a>, as well as a video presentation <a href=\"https://www.youtube.com/watch?v=lO4nYN1ZSBU\">here</a>.</p><p><strong>The Challenges of AML Reviewing</strong></p><p>During the investigation process, compliance experts investigate the financial movements centered around entities of interest (e.g., bank accounts or customers) to identify suspicious activity. To manage the complex task of navigating a large network of interactions and tracking flows of money, experts often rely on aggregations of meaningful categories, historical knowledge, and past experience.</p><p>Nevertheless, two major challenges persist:</p><p>1) New analysts require additional effort to familiarize themselves with recurring customers and understand new customers entering the\u00a0system;</p><p>2) Navigating the bulk of transactions to identify suspicious movements can be challenging, and a coarse-grained view can lead to overlooking crucial transaction details.</p><p>These challenges further intensify the manual workload imposed on experts during alert investigations, ultimately leading to a highly time-consuming process.</p><p><strong>Why Graphs\u00a0Matter</strong></p><p>Within the fields of data analytics and machine learning, graphs are data structures that excel in representing complex relationships between entities. At its most basic form, a graph G = (V, E) is a set of nodes V (also known as vertices) connected by a set of edges E (also known as links). This general formulation can yield a variety of graphs with different properties, such as graphs with different types of nodes/edges, and graphs with attributes at different granularities.</p><p>Money laundering schemes typically involve intricate webs of transactions and interactions between multiple entities. Traditional machine learning approaches often do not have a view of the full network, limiting their ability to capture the intricacies and patterns of the underlying interactions.</p><p>This is exactly where graphs come into play. Employing the graph structure enables a holistic view of the transactional behavior of financial entities, allowing us to uncover hidden patterns and understand the influence of indirect relationships. For these reasons, we focused on exploiting this type of data structure, and LaundroGraph relies on graph-neural networks to perform learning on top of\u00a0graphs.</p><p><strong>Why Do We Still Need\u00a0Rules?</strong></p><p>To adhere to strict anti-money laundering compliance regulations, financial institutions are required to deploy a predetermined set of rules, which cannot be subsumed by the decisions of a machine learning model. Furthermore, rules are easy to implement and easily understood even by non-technical personas.</p><p>Despite clear benefits, rule-based systems for anti-money laundering detection suffer from extremely high false positive rates, estimated to be over 95%. This poses a large burden on human analysts, which by law are obliged to investigate every\u00a0alert.</p><p>To address this challenge, there is a growing interest in developing machine learning models as complementary solutions to rule-based systems. However, these models face a significant hurdle: the scarcity of labeled data, which arises from the time-consuming and intricate process of money laundering reviewing, coupled with the very small percentage of actually suspicious events.</p><h3>2. Background</h3><p><strong>Graph Neural\u00a0Networks</strong></p><p>Graph Neural Networks (GNNs) provide a way to perform learning on top of graph-structured data, and are one of the most attractive areas of deep learning nowadays. Under this framework, each node is assigned a representation<strong> </strong>that is calculated by aggregating information sent by its local neighbors. In general, most GNNs define the following three operations:</p><ul><li><strong>Message (\ud835\udf06): </strong>Calculates the message sent from a local neighbor<strong>\u00a0j</strong>.</li><li><strong>Aggregation (\u2a01): </strong>Aggregates all the messages received through a permutation invariant operation.</li><li><strong>Update (\ud835\udf19):</strong> Combines the current node\u2019s information with the aggregated information.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/634/0*ro_c1rt97RzQlQfD\" /><figcaption>Fig 1: Graph neural network transformations.</figcaption></figure><p>In the equation above, <strong>l</strong> denotes the current layer, <strong>zi </strong>the representation calculated for node <strong>i</strong> and<strong> eij </strong>additional information that may exist to describe that specific interaction between nodes i and j. These networks compute representations by sending and aggregating messages from a node\u2019s local neighborhood,<strong> </strong>defined through the operations above. As a result, each node\u2019s representation is a summarization of its surrounding context, with the number of GNN layers typically dictating how far messages propagate.</p><h3>3. LaundroGraph</h3><p>LaundroGraph adapts the graph autoencoder framework to financial data and it is capable of providing AI-powered insights to experts during an investigation process. The system is trained in a fully self-supervised setting, removing the need for task-specific labels. The system is composed of three main\u00a0stages:</p><ul><li><strong>Graph Creation</strong>, in which a bipartite graph is constructed from the raw transaction data.</li><li><strong>Training</strong>, in which the graph neural network is trained through a link prediction objective between customer and transaction nodes.</li><li><strong>Insight Generation</strong>, in which we generate and provide a set of insights to the experts for each alerted\u00a0entity.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*9RdzwLhCHuiFIffi\" /><figcaption>Fig 2: LaundroGraph system training overview. Outgoing transactions are represented with filled arrows, and incoming transactions with dashed\u00a0arrows.</figcaption></figure><p><strong>Graph Creation</strong></p><p>Translating the information about financial interactions into a graph is a crucial design decision. In LaundroGraph we use a directed, bipartite graph comprising financial entities (e.g., bank customers) and transaction nodes. Customers are connected to each transaction they perform, and transactions are connected to the customers involved in that interaction.</p><p>Besides the graph structure, each node is endowed with a feature vector. Customer features are obtained based on metrics aligned with regulations and used by the rule-based systems. Transaction features describe properties of the corresponding interaction.</p><p>This choice of graph trivially allows the learning of separate latent embedding spaces for each node type, which can facilitate downstream tasks at different levels. It also maintains the fine-grained nature of the financial interactions, allows for dynamic updates as new nodes enter the system, and provides the flexibility to incorporate additional node types in the\u00a0future.</p><p><strong>Self-Supervised Training</strong></p><p>LaundroGraph is trained using a link prediction objective between pairs of customer and transaction nodes. Given a customer representation z_c and a transaction representation z_t, the network outputs the likelihood of an edge existing between those two nodes, and the predictions are evaluated through a binary cross-entropy (BCE).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/646/0*qEQxOEDyL1ruCaZV\" /><figcaption>Fig. 3: Link prediction algorithm.</figcaption></figure><p>As the system does not rely on any set of labels <em>a priori</em>, we need to define pairs of label positives and label negatives to enable learning. In this work, we follow the popular approach of defining positive labels as transactions that actually occurred, and negative labels as random samples of customer and transaction nodes. In other words, the network must distinguish if a given transaction belongs to the distribution of transactions typically performed by a customer or not, which is equivalent to identifying anomalous transactions given the local context of a customer.</p><p>Regardless, edges corresponding to the transaction being predicted are severed during message passing. Figure 4 illustrates the procedure to derive the input subgraph for a given edge we want to\u00a0score.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/0*aCeiu-o4s5DVizSL\" /><figcaption>Fig. 4: Procedure to generate input\u00a0samples.</figcaption></figure><p>To calculate the node-level representations, we use the popular graph attention network (GAT) message passing operator, which incorporates an attention coefficient when aggregating the neighborhood messages, dynamically setting different importance factors to different transactions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/582/0*5jJ-TP8NsJSwUE0d\" /><figcaption>Fig 5: Mathematical definition of the GAT operator.</figcaption></figure><p><strong>Insights Generation</strong></p><p>We\u2019ve seen how we can leverage a dataset of transactions to learn meaningful representations of financial entities. But the question of how this facilitates the process of money laundering investigation still remains. We leverage these learned general purpose representations to derive a variety of insights that will be shown to the expert reviewing the case. The AI-powered insights are digested and displayed on an interactive visualization investigation tool, designed to minimize redundant information.</p><p><strong>A. Transaction anomaly\u00a0score</strong></p><p>As a direct result of training with the link prediction objective, we can derive per-transaction anomaly scores from the viewpoint of a specific customer. The anomaly score for an interaction is defined as one minus the predicted likelihood. Transactions with abnormally high anomaly scores will be highlighted in the investigation tool, providing a starting point when investigating potentially suspicious interactions, alleviating the effort required to filter the large bulk of transactions.</p><p><strong>B. Transaction clustering</strong></p><p>The representations of transactions for a given customer can be clustered according to their representation similarity, grouping transactions according to what the model perceives as similar. Grouping transactions according to these clusters can provide interesting insights beyond simple aggregation schemes often used by experts, potentially highlighting clusters of normal or abnormal activity. This information is shown to the expert on-demand through a re-arrangement of the displayed transactions into different groups dictated by the clusters.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*XchvEh1F1nRRABVi\" /><figcaption>Fig 6: Transaction representation visualization using UMAP. Left plot depicts transactions colored by customer, and right plot colored by anomaly score. Circles represent outgoing transactions, and crosses incoming transactions.</figcaption></figure><p><strong>C. Customer behavior through\u00a0time</strong></p><p>In order to accelerate the contextualization of a given alerted customer, LaundroGraph provides a measure of behavior divergence across different time periods. This is achieved by comparing the similarity between customer representations at subsequent time intervals, using a sliding window approach.</p><p>This similarity can be quantified by measuring the displacement in the latent representation space, with large displacements indicating the model perceives a difference in behavior. Fig. 7 provides a visualization of these displacements (left) and corresponding similarities (right).</p><p>Quantifying the similarity across time-periods provides a continuous macro-view of behavior, which can be used to accelerate the contextualization of the corresponding customer. For example, if a customer has had several false positive alerts in the past, and his behavior did not diverge dramatically recently, then it is expected that the current alert is also a false positive.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*iH43wvJlnis08AiX\" /><figcaption>Fig 7: Customer representation visualization using UMAP. The left plot depicts the representation of 6 customers across 3 snapshots, and the right plots the cosine similarity heatmap between representations. Colors represent unique customers.</figcaption></figure><h3>4. Conclusions</h3><p>In this blog post, we discussed<strong> LaundroGraph</strong>, a label-free approach to derive representations for financial entities that can be leveraged to provide a variety of useful AI-powered insights. LaundroGraph represents the financial network as a bipartite customer-transaction graph, which is exploited through a graph neural network trained in a self-supervised manner.</p><p>These representations are used to accelerate the review times of complex cases through insights that contextualize and highlight the behavior of the entity under investigation. The system was developed to address the plethora of challenges in the anti-money laundering use-case, such as label scarcity and complexities associated with managing the network of interactions.</p><p>Nevertheless, the system can be applied to other use-cases, for example fraud detection. For more details, don\u2019t forget to check out our <a href=\"https://dl.acm.org/doi/abs/10.1145/3533271.3561727\">paper</a> published at the <a href=\"https://dl.acm.org/doi/proceedings/10.1145/3533271\">ICAIF </a>conference, as well as our <a href=\"https://www.youtube.com/watch?v=lO4nYN1ZSBU\">video presentation</a>.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c72763f38207\" width=\"1\" /><hr /><p><a href=\"https://medium.com/feedzaitech/aml-reimagined-laundrograph-exploits-graph-structure-to-assist-anti-money-laundering-activities-c72763f38207\">AML Reimagined: LaundroGraph Exploits Graph Structure to Assist Anti-Money Laundering Activities</a> was originally published in <a href=\"https://medium.com/feedzaitech\">Feedzai Techblog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*NqGgA5KjSMJZdLXkVPG3Fg.png\" /></figure><h3>1. Motivation</h3><p>Money laundering involves the illegal practice of making the origins of criminally obtained money appear legitimate. Financial institutions implement anti-money laundering (AML) processes to detect suspicious activities based on predefined rules. These rules trigger an investigation process that is both tedious and time-consuming, undertaken by compliance professionals. The availability of tools that can simplify and speed up these investigations is crucial in allowing for more informed decision-making and optimizing the use of human experts\u2019\u00a0time.</p><p>In this blog post, we introduce <strong>LaundroGraph</strong>, a novel system developed at Feedzai that supports the money laundering reviewing process by providing meaningful AI-powered insights to the expert regarding an alerted entity\u2019s transactional behavior. These insights are supplied during the investigation, accelerating and facilitating the process. LaundroGraph is based on graph-neural networks, trained in a fully self-supervised manner (yes, it doesn\u2019t need\u00a0labels).</p><p>This blog post is based on the paper, \u201cLaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering\u201d by M\u00e1rio Cardoso, Pedro Saleiro, Pedro Bizarro, that was published at the Third ACM International Conference on AI in Finance. You can find a copy of the paper <a href=\"https://research.feedzai.com/publication/laundrograph-self-supervised-graph-representation-learning-for-anti-money-laundering/\">here</a>, as well as a video presentation <a href=\"https://www.youtube.com/watch?v=lO4nYN1ZSBU\">here</a>.</p><p><strong>The Challenges of AML Reviewing</strong></p><p>During the investigation process, compliance experts investigate the financial movements centered around entities of interest (e.g., bank accounts or customers) to identify suspicious activity. To manage the complex task of navigating a large network of interactions and tracking flows of money, experts often rely on aggregations of meaningful categories, historical knowledge, and past experience.</p><p>Nevertheless, two major challenges persist:</p><p>1) New analysts require additional effort to familiarize themselves with recurring customers and understand new customers entering the\u00a0system;</p><p>2) Navigating the bulk of transactions to identify suspicious movements can be challenging, and a coarse-grained view can lead to overlooking crucial transaction details.</p><p>These challenges further intensify the manual workload imposed on experts during alert investigations, ultimately leading to a highly time-consuming process.</p><p><strong>Why Graphs\u00a0Matter</strong></p><p>Within the fields of data analytics and machine learning, graphs are data structures that excel in representing complex relationships between entities. At its most basic form, a graph G = (V, E) is a set of nodes V (also known as vertices) connected by a set of edges E (also known as links). This general formulation can yield a variety of graphs with different properties, such as graphs with different types of nodes/edges, and graphs with attributes at different granularities.</p><p>Money laundering schemes typically involve intricate webs of transactions and interactions between multiple entities. Traditional machine learning approaches often do not have a view of the full network, limiting their ability to capture the intricacies and patterns of the underlying interactions.</p><p>This is exactly where graphs come into play. Employing the graph structure enables a holistic view of the transactional behavior of financial entities, allowing us to uncover hidden patterns and understand the influence of indirect relationships. For these reasons, we focused on exploiting this type of data structure, and LaundroGraph relies on graph-neural networks to perform learning on top of\u00a0graphs.</p><p><strong>Why Do We Still Need\u00a0Rules?</strong></p><p>To adhere to strict anti-money laundering compliance regulations, financial institutions are required to deploy a predetermined set of rules, which cannot be subsumed by the decisions of a machine learning model. Furthermore, rules are easy to implement and easily understood even by non-technical personas.</p><p>Despite clear benefits, rule-based systems for anti-money laundering detection suffer from extremely high false positive rates, estimated to be over 95%. This poses a large burden on human analysts, which by law are obliged to investigate every\u00a0alert.</p><p>To address this challenge, there is a growing interest in developing machine learning models as complementary solutions to rule-based systems. However, these models face a significant hurdle: the scarcity of labeled data, which arises from the time-consuming and intricate process of money laundering reviewing, coupled with the very small percentage of actually suspicious events.</p><h3>2. Background</h3><p><strong>Graph Neural\u00a0Networks</strong></p><p>Graph Neural Networks (GNNs) provide a way to perform learning on top of graph-structured data, and are one of the most attractive areas of deep learning nowadays. Under this framework, each node is assigned a representation<strong> </strong>that is calculated by aggregating information sent by its local neighbors. In general, most GNNs define the following three operations:</p><ul><li><strong>Message (\ud835\udf06): </strong>Calculates the message sent from a local neighbor<strong>\u00a0j</strong>.</li><li><strong>Aggregation (\u2a01): </strong>Aggregates all the messages received through a permutation invariant operation.</li><li><strong>Update (\ud835\udf19):</strong> Combines the current node\u2019s information with the aggregated information.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/634/0*ro_c1rt97RzQlQfD\" /><figcaption>Fig 1: Graph neural network transformations.</figcaption></figure><p>In the equation above, <strong>l</strong> denotes the current layer, <strong>zi </strong>the representation calculated for node <strong>i</strong> and<strong> eij </strong>additional information that may exist to describe that specific interaction between nodes i and j. These networks compute representations by sending and aggregating messages from a node\u2019s local neighborhood,<strong> </strong>defined through the operations above. As a result, each node\u2019s representation is a summarization of its surrounding context, with the number of GNN layers typically dictating how far messages propagate.</p><h3>3. LaundroGraph</h3><p>LaundroGraph adapts the graph autoencoder framework to financial data and it is capable of providing AI-powered insights to experts during an investigation process. The system is trained in a fully self-supervised setting, removing the need for task-specific labels. The system is composed of three main\u00a0stages:</p><ul><li><strong>Graph Creation</strong>, in which a bipartite graph is constructed from the raw transaction data.</li><li><strong>Training</strong>, in which the graph neural network is trained through a link prediction objective between customer and transaction nodes.</li><li><strong>Insight Generation</strong>, in which we generate and provide a set of insights to the experts for each alerted\u00a0entity.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*9RdzwLhCHuiFIffi\" /><figcaption>Fig 2: LaundroGraph system training overview. Outgoing transactions are represented with filled arrows, and incoming transactions with dashed\u00a0arrows.</figcaption></figure><p><strong>Graph Creation</strong></p><p>Translating the information about financial interactions into a graph is a crucial design decision. In LaundroGraph we use a directed, bipartite graph comprising financial entities (e.g., bank customers) and transaction nodes. Customers are connected to each transaction they perform, and transactions are connected to the customers involved in that interaction.</p><p>Besides the graph structure, each node is endowed with a feature vector. Customer features are obtained based on metrics aligned with regulations and used by the rule-based systems. Transaction features describe properties of the corresponding interaction.</p><p>This choice of graph trivially allows the learning of separate latent embedding spaces for each node type, which can facilitate downstream tasks at different levels. It also maintains the fine-grained nature of the financial interactions, allows for dynamic updates as new nodes enter the system, and provides the flexibility to incorporate additional node types in the\u00a0future.</p><p><strong>Self-Supervised Training</strong></p><p>LaundroGraph is trained using a link prediction objective between pairs of customer and transaction nodes. Given a customer representation z_c and a transaction representation z_t, the network outputs the likelihood of an edge existing between those two nodes, and the predictions are evaluated through a binary cross-entropy (BCE).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/646/0*qEQxOEDyL1ruCaZV\" /><figcaption>Fig. 3: Link prediction algorithm.</figcaption></figure><p>As the system does not rely on any set of labels <em>a priori</em>, we need to define pairs of label positives and label negatives to enable learning. In this work, we follow the popular approach of defining positive labels as transactions that actually occurred, and negative labels as random samples of customer and transaction nodes. In other words, the network must distinguish if a given transaction belongs to the distribution of transactions typically performed by a customer or not, which is equivalent to identifying anomalous transactions given the local context of a customer.</p><p>Regardless, edges corresponding to the transaction being predicted are severed during message passing. Figure 4 illustrates the procedure to derive the input subgraph for a given edge we want to\u00a0score.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/0*aCeiu-o4s5DVizSL\" /><figcaption>Fig. 4: Procedure to generate input\u00a0samples.</figcaption></figure><p>To calculate the node-level representations, we use the popular graph attention network (GAT) message passing operator, which incorporates an attention coefficient when aggregating the neighborhood messages, dynamically setting different importance factors to different transactions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/582/0*5jJ-TP8NsJSwUE0d\" /><figcaption>Fig 5: Mathematical definition of the GAT operator.</figcaption></figure><p><strong>Insights Generation</strong></p><p>We\u2019ve seen how we can leverage a dataset of transactions to learn meaningful representations of financial entities. But the question of how this facilitates the process of money laundering investigation still remains. We leverage these learned general purpose representations to derive a variety of insights that will be shown to the expert reviewing the case. The AI-powered insights are digested and displayed on an interactive visualization investigation tool, designed to minimize redundant information.</p><p><strong>A. Transaction anomaly\u00a0score</strong></p><p>As a direct result of training with the link prediction objective, we can derive per-transaction anomaly scores from the viewpoint of a specific customer. The anomaly score for an interaction is defined as one minus the predicted likelihood. Transactions with abnormally high anomaly scores will be highlighted in the investigation tool, providing a starting point when investigating potentially suspicious interactions, alleviating the effort required to filter the large bulk of transactions.</p><p><strong>B. Transaction clustering</strong></p><p>The representations of transactions for a given customer can be clustered according to their representation similarity, grouping transactions according to what the model perceives as similar. Grouping transactions according to these clusters can provide interesting insights beyond simple aggregation schemes often used by experts, potentially highlighting clusters of normal or abnormal activity. This information is shown to the expert on-demand through a re-arrangement of the displayed transactions into different groups dictated by the clusters.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*XchvEh1F1nRRABVi\" /><figcaption>Fig 6: Transaction representation visualization using UMAP. Left plot depicts transactions colored by customer, and right plot colored by anomaly score. Circles represent outgoing transactions, and crosses incoming transactions.</figcaption></figure><p><strong>C. Customer behavior through\u00a0time</strong></p><p>In order to accelerate the contextualization of a given alerted customer, LaundroGraph provides a measure of behavior divergence across different time periods. This is achieved by comparing the similarity between customer representations at subsequent time intervals, using a sliding window approach.</p><p>This similarity can be quantified by measuring the displacement in the latent representation space, with large displacements indicating the model perceives a difference in behavior. Fig. 7 provides a visualization of these displacements (left) and corresponding similarities (right).</p><p>Quantifying the similarity across time-periods provides a continuous macro-view of behavior, which can be used to accelerate the contextualization of the corresponding customer. For example, if a customer has had several false positive alerts in the past, and his behavior did not diverge dramatically recently, then it is expected that the current alert is also a false positive.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*iH43wvJlnis08AiX\" /><figcaption>Fig 7: Customer representation visualization using UMAP. The left plot depicts the representation of 6 customers across 3 snapshots, and the right plots the cosine similarity heatmap between representations. Colors represent unique customers.</figcaption></figure><h3>4. Conclusions</h3><p>In this blog post, we discussed<strong> LaundroGraph</strong>, a label-free approach to derive representations for financial entities that can be leveraged to provide a variety of useful AI-powered insights. LaundroGraph represents the financial network as a bipartite customer-transaction graph, which is exploited through a graph neural network trained in a self-supervised manner.</p><p>These representations are used to accelerate the review times of complex cases through insights that contextualize and highlight the behavior of the entity under investigation. The system was developed to address the plethora of challenges in the anti-money laundering use-case, such as label scarcity and complexities associated with managing the network of interactions.</p><p>Nevertheless, the system can be applied to other use-cases, for example fraud detection. For more details, don\u2019t forget to check out our <a href=\"https://dl.acm.org/doi/abs/10.1145/3533271.3561727\">paper</a> published at the <a href=\"https://dl.acm.org/doi/proceedings/10.1145/3533271\">ICAIF </a>conference, as well as our <a href=\"https://www.youtube.com/watch?v=lO4nYN1ZSBU\">video presentation</a>.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c72763f38207\" width=\"1\" /><hr /><p><a href=\"https://medium.com/feedzaitech/aml-reimagined-laundrograph-exploits-graph-structure-to-assist-anti-money-laundering-activities-c72763f38207\">AML Reimagined: LaundroGraph Exploits Graph Structure to Assist Anti-Money Laundering Activities</a> was originally published in <a href=\"https://medium.com/feedzaitech\">Feedzai Techblog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Instacart": {
    "title": "One model to serve them all",
    "xmlUrl": "https://tech.instacart.com/feed",
    "htmlUrl": "https://tech.instacart.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.instacart.com/feed",
      "value": "One model to serve them all"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.instacart.com/one-model-to-serve-them-all-0eb6bf60b00d?source=rss----587883b5d2ee---4"
      }
    ],
    "link": "https://tech.instacart.com/one-model-to-serve-them-all-0eb6bf60b00d?source=rss----587883b5d2ee---4",
    "id": "https://medium.com/p/0eb6bf60b00d",
    "guidislink": false,
    "tags": [
      {
        "term": "machine-learning",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Cheng Jia"
      }
    ],
    "author": "Cheng Jia",
    "author_detail": {
      "name": "Cheng Jia"
    },
    "published": "Tue, 19 Dec 2023 23:03:32 GMT",
    "published_parsed": [
      2023,
      12,
      19,
      23,
      3,
      32,
      1,
      353,
      0
    ],
    "updated": "2023-12-19T23:03:32.046Z",
    "updated_parsed": [
      2023,
      12,
      19,
      23,
      3,
      32,
      1,
      353,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://tech.instacart.com/feed",
        "value": "<p>How Instacart deployed a single Deep Learning pCTR model for multiple surfaces with improved operations and performance along the\u00a0way</p><p><strong>Authors: </strong><a href=\"https://www.linkedin.com/in/cheng-jia-00787629a/\">Cheng Jia</a>, <a href=\"https://www.linkedin.com/in/peng-qi-47221234/\">Peng Qi</a>, <a href=\"https://cs.uwaterloo.ca/~jharalds/\">Joseph Haraldson</a>, <a href=\"https://www.linkedin.com/in/adwaydhillon/\">Adway Dhillon</a>, <a href=\"https://www.linkedin.com/in/qiao-jiang/\">Qiao Jiang</a>, <a href=\"https://www.linkedin.com/in/sharathrao/\">Sharath\u00a0Rao</a></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ar29WOgQwVC7OnigvYRSZA.png\" /></figure><h3>Introduction</h3><h4>Instacart Ads and Ranking\u00a0Models</h4><p>At Instacart Ads, our focus lies in delivering the utmost relevance in advertisements to our customers, facilitating novel product discovery and enhancing their grocery shopping journey. Concurrently, we strive to offer value to our advertisers by bolstering brand recognition, augmenting product sales, and extending their customer reach. Fulfilling these interlinked objectives on this multi-sided marketplace necessitates a strategic approach to ad-serving, particularly in terms of the algorithm governing ad rankings\u200a\u2014\u200aan aspect that we hold to exceedingly high standards.</p><p>Over the course of our journey, we have created a diverse array of page layouts, each tailored to offer distinct user experiences. Our customers can directly search for specific products, or browse for products on a storefront, mirroring the process of navigating a physical grocery store. The latter\u200a\u2014\u200athe browsing interfaces\u200a\u2014\u200aare designed with specific intentions in mind, which\u00a0include:</p><ul><li><strong>Buy It Again (BIA): </strong>showcasing products that a user has previously purchased.</li><li><strong>Frequently Bought With (FBW): </strong>suggesting products often bought alongside items already in the users\u2019\u00a0carts.</li><li><strong>Store Root: </strong>displaying products available in the store currently being\u00a0viewed.</li><li><strong>Collections: </strong>highlighting a collection of products within the same category.</li><li><strong>Item Details: </strong>introducing products related to an item under inspection by the customer.</li></ul><p>These ad surfaces may appear similar, but the key distinction lies in their <strong>contextual</strong> differences. For example, Collections feature a specific category name, while Item Details provide information related to an item the user is currently examining, and so\u00a0on.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*5igYtBm2sXPXU3ls\" /><figcaption>Buy It Again Surface\u00a0(BIA)</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*In-_JTupqpEwBzoT\" /><figcaption>Collections Surface</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Ze3MMABNBCVTvKvd\" /><figcaption>Item Details\u00a0Surface</figcaption></figure><p>Fig-1: examples of Browse surfaces on instacart.com</p><h4>Legacy XGBoost Browse pCTR\u00a0Models</h4><p>In the early stages of developing these surfaces, we designed basic ranking models, using XGBoost to predict ad click-through rates (CTR) and rank ads based on the predictions. As mentioned above, different surfaces tend to have varying contexts and generate unique sets of inputs and features. Consequently, whenever a new context was introduced, the team would create a new model, resulting in a growing collection of\u00a0models.</p><p>Over time, as our range of browsing surfaces expanded, we accumulated a set of XGBoost-based ranking models designed specifically for advertising on different surfaces. As a result, several limitations also emerged with this approach:</p><ol><li><strong>Disparate Training Datasets:</strong> The separation in training datasets made cross-sharing of user interaction insights impossible. For example, if a user displayed interest in specific products on one surface by interacting with them, this engagement data would fail to propagate to other surfaces when constructing the training data for the other pCTR\u00a0models.</li><li><strong>XGBoost Model Limitations:</strong> The XGBoost models themselves are constrained in their capacity to incorporate certain types of features, which are required to unify the models for all surfaces. Notably, accommodating high-cardinality categorical features within the model posed a challenge, as one-hot encoding of these features will result in impossibly high dimension of inputs. Consequently, we can\u2019t incorporate collection names for collections, product IDs for item details, or search terms for FBW into the\u00a0model.</li><li><strong>Maintenance Complexity:</strong> Deploying a model for each surface introduces significant operational complexities. The effort managing the service, monitors and incident response for both data pipelines and model serving grows linearly with the number of surfaces. Future changes are further hindered by orchestrating changes with cross-functional stakeholders.</li><li><strong>Isolated Model Infrastructure: </strong>The legacy model training and serving platform for the XGBoost pCTR model relies on outdated serving infrastructure, which prevents us from taking advantage of the latest improvements offered by our company\u2019s ML infrastructure stack. As a result, we are unable to benefit from the enhancements implemented by our cross-functional partners.</li></ol><p>These challenges represent typical growing pains experienced by rapidly expanding companies. As our focus primarily revolved around product development to enhance customer experience and introduce new advertising platforms, infrastructure development received less attention. Consequently, we lacked the necessary training pipelines to effectively develop a unified model. Moreover, the risk associated with implementing such a unified model was exceedingly high, given that the legacy models were already deployed and serving live\u00a0traffic.</p><h3>Unified Browse pCTR\u00a0Model</h3><h4>Overview</h4><p>Recognizing these limitations of the legacy Browse model, we embarked on the creation of a Unified Browse pCTR model. This initiative aimed to rectify the aforementioned issues and improve the performance of pCTR models on our browsing surfaces. Our approach is to use a Deep Learning model to unify all surfaces. To achieve this, we consolidated the data generation process by coalescing data from all disparate surfaces, as is shown in\u00a0Fig-1.</p><ul><li><strong>Unified Dataset: </strong>Combining the training data for each surface yields a richer dataset that can train more sophisticated models. Not only is this forward compatible with new surfaces, but this also unlocks powerful cross-surface interactions and user level signals. For illustration purposes, let us consider the following naive example of a user interacting by clicking on a product within the Buy-It-Again (BIA) surface. After combining the data, this information is propagated to other surfaces, leading to an increased predicted probability of a click in those surfaces for this user-product pair.</li><li><strong>Deep Learning Framework: </strong>Deep learning frameworks come with several advantages, notably on high cardinality features such as user IDs, product IDs and search texts that capture preferences and intent. These features are incorporated into the model through embedding matrices to achieve dimensionality reduction while still retaining predictive power. Moreover, unlike the legacy XGBoost models, Deep Learning provides opportunities to experiment with novel model architectures and incorporate the state of the art ML techniques from the literature.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*kM1P1XcKHjDAjK_W\" /><figcaption>Legacy Browse pCTR\u00a0Model</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*0wTl1YuqvcrF5XM9\" /><figcaption>Unified Browse pCTR\u00a0Model</figcaption></figure><p>Fig-2: Comparison of the training data generation and model architecture of the Unified Browse pCTR model (lower panel) to the legacy Browse pCTR models (upper\u00a0panel).</p><h4>Training Data</h4><p>The training data for the Unified Browse pCTR model encompasses the following distinct (yet not exhaustive) categories of features:</p><ul><li><strong>User Features:</strong> This category encompasses features about the user to whom the ads impressions are presented. Through a series of iterations, we have included information such as user ID, user\u2019s historical views, clicks, and purchase patterns, along with supplementary behavioral signals that unveil historical user responses to sales and promotions, their propensity of repurchasing a product, brand loyalty, etc, which have proven to be highly powerful features for prediction.</li><li><strong>Product Features:</strong> In this section, we have included attributes pertaining to the product under evaluation. Notably, we consider product ID, name, brand, broad category, and price as significant indicators. Furthermore, we encompass specific product details such as whether the item holds attributes like being alcoholic, kosher, or organic. Additionally, we\u2019ve integrated synthesized attributes into the mix, e.g., scores built on top of deep learning models that reveal more abstract relationships that can\u2019t be fully captured through simple statistics, such as the competitiveness within its category.</li><li><strong>Context Features: </strong>These features describe the contextual backdrop against which an ad impression is presented. Some features in this group are present for all contexts, such as types of the placement the ads appear on. But the availability of other features could depend on the given context. For instance, on the item detail surface (Fig-2), the product attributes of the reference product are provided to the model as features when scoring ads on this surface. As another example, on surfaces where we exhibit collections of products within a store, the collection names, such as \u201cfruit juices\u201d or \u201ccleaning products,\u201d are also included as features to the\u00a0model.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*T0zUvTMBpMA4gUdE\" /></figure><p>Fig-3: Example of an item detail surface where a focal reference product is situated in the center of the surface, and ads under scoring appear in a carousel below the reference product.</p><ul><li><strong>Mean Target Encoding:</strong> These MTE features encode the historical CTRs for specific data segments. They can either apply universally across all contexts, like historical user-product interactions, or exist specifically for certain contexts, such as historical interactions between reference and target product categories on item detail surfaces. These MTE features offer valuable insights into past engagements, serving as potent predictors of future performance. For more details on the MTE features and the streamlined pipeline for their calculation and integration into our training data, stay tuned for a forthcoming post on this\u00a0topic!</li><li><strong>Data Sparsity and Missing Features: </strong>A notable challenge imposed upon working context features is the substantial imputation required within the training data. For simplicity, in our model, we opted for a straightforward approach of imputation with default values. This choice was motivated by the fact that default values in this context symbolize a lack of available data, a concept that the model can learn from. Moreover, considering the sheer magnitude of the data handled by our model, alternate methods such as using an auxiliary model or other statistical signals could prove computationally intractable.</li></ul><h4>Model Architecture</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*470SHVF7hhhMRWZ0\" /></figure><p>Fig-4: Diagram of the Wide-and-Deep model architecture with a second order interaction component for the Unified Browse pCTR\u00a0model.</p><p>The architecture of the Unified Browse pCTR model draws strong inspiration from the Wide-and-Deep architecture, which forms the foundation of numerous pCTR models for user response predictions in the industry.</p><h4>Deep Side</h4><p>For the deep side, our model heavily relies on three large-scale embedding matrices that are trained specifically for capturing essential information from features such as product id, user id, and various textual attributes (e.g., product name, brand name, search\u00a0term).</p><p>These embedding matrices serve as a crucial component of the Deep Learning feature extraction process in our model. By leveraging these matrices, we can effectively handle the high cardinality associated with users and products, allowing us to capture the nuances and preferences that play a significant role in determining the click-through probability.</p><p>Once the embedding vectors are obtained, they are concatenated and fed through multiple fully connected layers. These layers serve as an essential mechanism for approximating the highly non-linear effects of each feature and capturing complex interactions between them. By incorporating this deep side architecture, our model can capture intricate patterns and relationships hidden within the data, leading to more accurate predictions.</p><h4>Wide Side</h4><p>On the wide side of our model, we carefully select a range of features to include low cardinality categorical attributes, especially surface type indicators, as well as continuous features. These wide side features, along with the embedding vectors, are concatenated before we introduce pairwise interactions between these features by employing a classical factorization machine. This allows us to capture and adjust coefficients based on the surface types, leading to the ability to model specific distinctions between different surfaces in a more flexible\u00a0manner.</p><h4>Second-order interaction</h4><p>There\u2019s a wealth of literature stressing the importance of explicitly modeling both shallow and higher-order interactions between features in response prediction tasks\u200a\u2014\u200atake xDeepFM, PNN, and DCN2 as examples. In the first iteration of our model, we decided to incorporate a basic second-order interaction layer via a factorization machine, primarily for its simplicity of implementation and demonstrated efficacy in boosting the model\u2019s performance. In our test, this architecture change resulted in a notable improvement of 1% in both the test log loss and test AUC metrics. To provide some context, in certain experiments, a 1.8% increase in AUC led to a remarkable boost of over 12% in click-through rates on Browse surfaces. Hence, a 1% improvement from the architecture change alone carries substantial impact. This improvement highlights the effectiveness of incorporating these interactions in enhancing the overall performance and capturing additional intricacies in the unified Browse pCTR\u00a0model.</p><h3>Model Performance</h3><p>We performed extensive offline evaluations comparing the new Unified Browse pCTR model to the legacy Browse pCTR model. The new model has shown significantly better performance both offline and\u00a0online.</p><h4>Offline</h4><p>We checked a series of offline test metrics, with the focus on test log loss, test AUC-ROC, test AUC-PR as well as test calibration. We also performed feature importance studies to assess the impact of the features included. The offline metrics are omitted here as we effectively use the same metrics offline and online, and online metrics will be reported in the next\u00a0section.</p><h4>Online</h4><p>Compared to the legacy Browse XGBoost pCTR models, the Unified Browse pCTR model has achieved significant improvements in performance online.</p><p><strong>AUC-PR</strong>: The Unified Browse pCTR model has achieved a 10% improvement over legacy Browse pCTR models on the BIA surface, 48% on the Store Root surfaces, and a whopping 190% improvement on Collection and other surfaces.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*rGPes2M5o1rEzh7a\" /></figure><p>Fig-5: Breakdown of AUC-PR by\u00a0surface</p><p><strong>AUC-ROC:</strong> The Unified Browse pCTR model has achieved a 4.8% improvement over legacy Browse pCTR models on the Store Root surfaces, 20% on the Collection surfaces, and 18% on the Other surfaces.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*sNQExdRam4WRjITD\" /></figure><p>Fig-6: Breakdown of AUC-ROC by\u00a0surface</p><p>The AUC-ROC improvement on the BIA surfaces didn\u2019t see a major lift during the first model rollout due to some discrepancies between online and offline inputs after the model was shipped. However, after resolving this issue in later updates, we significantly boosted performance on that surface, beating the legacy model by 2% on\u00a0AUC-ROC.</p><p><strong>Calibration:</strong> The Unified Browse pCTR model has achieved around 64%-77% improvement over legacy Browse XGBoost pCTR models on all surfaces except BIA. It significantly reduced the bias of the model and provided fairer second-price-auction (2PA) pricing for our auction\u00a0systems.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*dui4pQYGoa00ryX9\" /></figure><p>Fig-7: Breakdown of the calibration by\u00a0surface</p><h3>Impacts</h3><p>A/B Tests showed that the new model substantially improved incremental sales and return on ads spend (ROAS) for the advertisers, and decreased ads end-to-end latency by onboarding to the new model serving platform. Moreover, it significantly increased overall cart adds, demonstrating its ability to increase sales without cannibalizing organic conversions. It was truly a triple win for Instacart, our customers and advertising partners.</p><p>What\u2019s more exciting: consolidating the model allowed us to iterate more efficiently. Two weeks after the initial rollout, the team launched a second iteration of the model, which incorporated real-time features from the Ads Marketplace team, along with short-term and long-term user history features including those from user modeling to give the performance yet another boost. This iteration again improved ROAS for the advertisers and increased profit per\u00a0user.</p><p>Combining the two rollout stages led to significant improvements in advertiser incrementality and performance, and substantial gain in cart adds, by raising the quality of ads shown to Instacart customers, while reducing end-to-end latency and operational overhead for Instacart. This achievement testifies to the impact of investment in ML expertise and infrastructure.</p><h3>Learnings &amp; Conclusions</h3><ul><li><strong>Unified modeling:</strong> By consolidating data and training a single unified model, we were able to improve user profiling and enhance performance across various browsing surfaces.</li><li><strong>Deep Learning advantages:</strong> Leveraging Deep Learning frameworks enabled us to integrate high-cardinality features, incorporating contextual information for all various surfaces. Deep Learning frameworks also capture complex interactions, resulting in more accurate predictions and improved model performance.</li><li><strong>Missing values:</strong> Even though different Browse surfaces have unique sets of contexts, Deep Learning models can learn the meanings of missing values. Even without employing complicated imputation techniques, the model\u2019s performance remains unaffected.</li><li><strong>Shallow interactions:</strong> We also introduced shallow interactions through factorization machines, which led to a notable 1% improvement in metrics such as log loss and AUC. This demonstrates the effectiveness of this technique in enhancing model performance.</li><li><strong>Iterative improvements:</strong> The ability to iterate and optimize the model quickly by incorporating new features and experimenting with different model architectures is crucial for maintaining a streamlined ML workflow and achieving ongoing success in machine learning.</li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0eb6bf60b00d\" width=\"1\" /><hr /><p><a href=\"https://tech.instacart.com/one-model-to-serve-them-all-0eb6bf60b00d\">One model to serve them all</a> was originally published in <a href=\"https://tech.instacart.com\">tech-at-instacart</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>How Instacart deployed a single Deep Learning pCTR model for multiple surfaces with improved operations and performance along the\u00a0way</p><p><strong>Authors: </strong><a href=\"https://www.linkedin.com/in/cheng-jia-00787629a/\">Cheng Jia</a>, <a href=\"https://www.linkedin.com/in/peng-qi-47221234/\">Peng Qi</a>, <a href=\"https://cs.uwaterloo.ca/~jharalds/\">Joseph Haraldson</a>, <a href=\"https://www.linkedin.com/in/adwaydhillon/\">Adway Dhillon</a>, <a href=\"https://www.linkedin.com/in/qiao-jiang/\">Qiao Jiang</a>, <a href=\"https://www.linkedin.com/in/sharathrao/\">Sharath\u00a0Rao</a></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ar29WOgQwVC7OnigvYRSZA.png\" /></figure><h3>Introduction</h3><h4>Instacart Ads and Ranking\u00a0Models</h4><p>At Instacart Ads, our focus lies in delivering the utmost relevance in advertisements to our customers, facilitating novel product discovery and enhancing their grocery shopping journey. Concurrently, we strive to offer value to our advertisers by bolstering brand recognition, augmenting product sales, and extending their customer reach. Fulfilling these interlinked objectives on this multi-sided marketplace necessitates a strategic approach to ad-serving, particularly in terms of the algorithm governing ad rankings\u200a\u2014\u200aan aspect that we hold to exceedingly high standards.</p><p>Over the course of our journey, we have created a diverse array of page layouts, each tailored to offer distinct user experiences. Our customers can directly search for specific products, or browse for products on a storefront, mirroring the process of navigating a physical grocery store. The latter\u200a\u2014\u200athe browsing interfaces\u200a\u2014\u200aare designed with specific intentions in mind, which\u00a0include:</p><ul><li><strong>Buy It Again (BIA): </strong>showcasing products that a user has previously purchased.</li><li><strong>Frequently Bought With (FBW): </strong>suggesting products often bought alongside items already in the users\u2019\u00a0carts.</li><li><strong>Store Root: </strong>displaying products available in the store currently being\u00a0viewed.</li><li><strong>Collections: </strong>highlighting a collection of products within the same category.</li><li><strong>Item Details: </strong>introducing products related to an item under inspection by the customer.</li></ul><p>These ad surfaces may appear similar, but the key distinction lies in their <strong>contextual</strong> differences. For example, Collections feature a specific category name, while Item Details provide information related to an item the user is currently examining, and so\u00a0on.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*5igYtBm2sXPXU3ls\" /><figcaption>Buy It Again Surface\u00a0(BIA)</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*In-_JTupqpEwBzoT\" /><figcaption>Collections Surface</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Ze3MMABNBCVTvKvd\" /><figcaption>Item Details\u00a0Surface</figcaption></figure><p>Fig-1: examples of Browse surfaces on instacart.com</p><h4>Legacy XGBoost Browse pCTR\u00a0Models</h4><p>In the early stages of developing these surfaces, we designed basic ranking models, using XGBoost to predict ad click-through rates (CTR) and rank ads based on the predictions. As mentioned above, different surfaces tend to have varying contexts and generate unique sets of inputs and features. Consequently, whenever a new context was introduced, the team would create a new model, resulting in a growing collection of\u00a0models.</p><p>Over time, as our range of browsing surfaces expanded, we accumulated a set of XGBoost-based ranking models designed specifically for advertising on different surfaces. As a result, several limitations also emerged with this approach:</p><ol><li><strong>Disparate Training Datasets:</strong> The separation in training datasets made cross-sharing of user interaction insights impossible. For example, if a user displayed interest in specific products on one surface by interacting with them, this engagement data would fail to propagate to other surfaces when constructing the training data for the other pCTR\u00a0models.</li><li><strong>XGBoost Model Limitations:</strong> The XGBoost models themselves are constrained in their capacity to incorporate certain types of features, which are required to unify the models for all surfaces. Notably, accommodating high-cardinality categorical features within the model posed a challenge, as one-hot encoding of these features will result in impossibly high dimension of inputs. Consequently, we can\u2019t incorporate collection names for collections, product IDs for item details, or search terms for FBW into the\u00a0model.</li><li><strong>Maintenance Complexity:</strong> Deploying a model for each surface introduces significant operational complexities. The effort managing the service, monitors and incident response for both data pipelines and model serving grows linearly with the number of surfaces. Future changes are further hindered by orchestrating changes with cross-functional stakeholders.</li><li><strong>Isolated Model Infrastructure: </strong>The legacy model training and serving platform for the XGBoost pCTR model relies on outdated serving infrastructure, which prevents us from taking advantage of the latest improvements offered by our company\u2019s ML infrastructure stack. As a result, we are unable to benefit from the enhancements implemented by our cross-functional partners.</li></ol><p>These challenges represent typical growing pains experienced by rapidly expanding companies. As our focus primarily revolved around product development to enhance customer experience and introduce new advertising platforms, infrastructure development received less attention. Consequently, we lacked the necessary training pipelines to effectively develop a unified model. Moreover, the risk associated with implementing such a unified model was exceedingly high, given that the legacy models were already deployed and serving live\u00a0traffic.</p><h3>Unified Browse pCTR\u00a0Model</h3><h4>Overview</h4><p>Recognizing these limitations of the legacy Browse model, we embarked on the creation of a Unified Browse pCTR model. This initiative aimed to rectify the aforementioned issues and improve the performance of pCTR models on our browsing surfaces. Our approach is to use a Deep Learning model to unify all surfaces. To achieve this, we consolidated the data generation process by coalescing data from all disparate surfaces, as is shown in\u00a0Fig-1.</p><ul><li><strong>Unified Dataset: </strong>Combining the training data for each surface yields a richer dataset that can train more sophisticated models. Not only is this forward compatible with new surfaces, but this also unlocks powerful cross-surface interactions and user level signals. For illustration purposes, let us consider the following naive example of a user interacting by clicking on a product within the Buy-It-Again (BIA) surface. After combining the data, this information is propagated to other surfaces, leading to an increased predicted probability of a click in those surfaces for this user-product pair.</li><li><strong>Deep Learning Framework: </strong>Deep learning frameworks come with several advantages, notably on high cardinality features such as user IDs, product IDs and search texts that capture preferences and intent. These features are incorporated into the model through embedding matrices to achieve dimensionality reduction while still retaining predictive power. Moreover, unlike the legacy XGBoost models, Deep Learning provides opportunities to experiment with novel model architectures and incorporate the state of the art ML techniques from the literature.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*kM1P1XcKHjDAjK_W\" /><figcaption>Legacy Browse pCTR\u00a0Model</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*0wTl1YuqvcrF5XM9\" /><figcaption>Unified Browse pCTR\u00a0Model</figcaption></figure><p>Fig-2: Comparison of the training data generation and model architecture of the Unified Browse pCTR model (lower panel) to the legacy Browse pCTR models (upper\u00a0panel).</p><h4>Training Data</h4><p>The training data for the Unified Browse pCTR model encompasses the following distinct (yet not exhaustive) categories of features:</p><ul><li><strong>User Features:</strong> This category encompasses features about the user to whom the ads impressions are presented. Through a series of iterations, we have included information such as user ID, user\u2019s historical views, clicks, and purchase patterns, along with supplementary behavioral signals that unveil historical user responses to sales and promotions, their propensity of repurchasing a product, brand loyalty, etc, which have proven to be highly powerful features for prediction.</li><li><strong>Product Features:</strong> In this section, we have included attributes pertaining to the product under evaluation. Notably, we consider product ID, name, brand, broad category, and price as significant indicators. Furthermore, we encompass specific product details such as whether the item holds attributes like being alcoholic, kosher, or organic. Additionally, we\u2019ve integrated synthesized attributes into the mix, e.g., scores built on top of deep learning models that reveal more abstract relationships that can\u2019t be fully captured through simple statistics, such as the competitiveness within its category.</li><li><strong>Context Features: </strong>These features describe the contextual backdrop against which an ad impression is presented. Some features in this group are present for all contexts, such as types of the placement the ads appear on. But the availability of other features could depend on the given context. For instance, on the item detail surface (Fig-2), the product attributes of the reference product are provided to the model as features when scoring ads on this surface. As another example, on surfaces where we exhibit collections of products within a store, the collection names, such as \u201cfruit juices\u201d or \u201ccleaning products,\u201d are also included as features to the\u00a0model.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*T0zUvTMBpMA4gUdE\" /></figure><p>Fig-3: Example of an item detail surface where a focal reference product is situated in the center of the surface, and ads under scoring appear in a carousel below the reference product.</p><ul><li><strong>Mean Target Encoding:</strong> These MTE features encode the historical CTRs for specific data segments. They can either apply universally across all contexts, like historical user-product interactions, or exist specifically for certain contexts, such as historical interactions between reference and target product categories on item detail surfaces. These MTE features offer valuable insights into past engagements, serving as potent predictors of future performance. For more details on the MTE features and the streamlined pipeline for their calculation and integration into our training data, stay tuned for a forthcoming post on this\u00a0topic!</li><li><strong>Data Sparsity and Missing Features: </strong>A notable challenge imposed upon working context features is the substantial imputation required within the training data. For simplicity, in our model, we opted for a straightforward approach of imputation with default values. This choice was motivated by the fact that default values in this context symbolize a lack of available data, a concept that the model can learn from. Moreover, considering the sheer magnitude of the data handled by our model, alternate methods such as using an auxiliary model or other statistical signals could prove computationally intractable.</li></ul><h4>Model Architecture</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*470SHVF7hhhMRWZ0\" /></figure><p>Fig-4: Diagram of the Wide-and-Deep model architecture with a second order interaction component for the Unified Browse pCTR\u00a0model.</p><p>The architecture of the Unified Browse pCTR model draws strong inspiration from the Wide-and-Deep architecture, which forms the foundation of numerous pCTR models for user response predictions in the industry.</p><h4>Deep Side</h4><p>For the deep side, our model heavily relies on three large-scale embedding matrices that are trained specifically for capturing essential information from features such as product id, user id, and various textual attributes (e.g., product name, brand name, search\u00a0term).</p><p>These embedding matrices serve as a crucial component of the Deep Learning feature extraction process in our model. By leveraging these matrices, we can effectively handle the high cardinality associated with users and products, allowing us to capture the nuances and preferences that play a significant role in determining the click-through probability.</p><p>Once the embedding vectors are obtained, they are concatenated and fed through multiple fully connected layers. These layers serve as an essential mechanism for approximating the highly non-linear effects of each feature and capturing complex interactions between them. By incorporating this deep side architecture, our model can capture intricate patterns and relationships hidden within the data, leading to more accurate predictions.</p><h4>Wide Side</h4><p>On the wide side of our model, we carefully select a range of features to include low cardinality categorical attributes, especially surface type indicators, as well as continuous features. These wide side features, along with the embedding vectors, are concatenated before we introduce pairwise interactions between these features by employing a classical factorization machine. This allows us to capture and adjust coefficients based on the surface types, leading to the ability to model specific distinctions between different surfaces in a more flexible\u00a0manner.</p><h4>Second-order interaction</h4><p>There\u2019s a wealth of literature stressing the importance of explicitly modeling both shallow and higher-order interactions between features in response prediction tasks\u200a\u2014\u200atake xDeepFM, PNN, and DCN2 as examples. In the first iteration of our model, we decided to incorporate a basic second-order interaction layer via a factorization machine, primarily for its simplicity of implementation and demonstrated efficacy in boosting the model\u2019s performance. In our test, this architecture change resulted in a notable improvement of 1% in both the test log loss and test AUC metrics. To provide some context, in certain experiments, a 1.8% increase in AUC led to a remarkable boost of over 12% in click-through rates on Browse surfaces. Hence, a 1% improvement from the architecture change alone carries substantial impact. This improvement highlights the effectiveness of incorporating these interactions in enhancing the overall performance and capturing additional intricacies in the unified Browse pCTR\u00a0model.</p><h3>Model Performance</h3><p>We performed extensive offline evaluations comparing the new Unified Browse pCTR model to the legacy Browse pCTR model. The new model has shown significantly better performance both offline and\u00a0online.</p><h4>Offline</h4><p>We checked a series of offline test metrics, with the focus on test log loss, test AUC-ROC, test AUC-PR as well as test calibration. We also performed feature importance studies to assess the impact of the features included. The offline metrics are omitted here as we effectively use the same metrics offline and online, and online metrics will be reported in the next\u00a0section.</p><h4>Online</h4><p>Compared to the legacy Browse XGBoost pCTR models, the Unified Browse pCTR model has achieved significant improvements in performance online.</p><p><strong>AUC-PR</strong>: The Unified Browse pCTR model has achieved a 10% improvement over legacy Browse pCTR models on the BIA surface, 48% on the Store Root surfaces, and a whopping 190% improvement on Collection and other surfaces.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*rGPes2M5o1rEzh7a\" /></figure><p>Fig-5: Breakdown of AUC-PR by\u00a0surface</p><p><strong>AUC-ROC:</strong> The Unified Browse pCTR model has achieved a 4.8% improvement over legacy Browse pCTR models on the Store Root surfaces, 20% on the Collection surfaces, and 18% on the Other surfaces.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*sNQExdRam4WRjITD\" /></figure><p>Fig-6: Breakdown of AUC-ROC by\u00a0surface</p><p>The AUC-ROC improvement on the BIA surfaces didn\u2019t see a major lift during the first model rollout due to some discrepancies between online and offline inputs after the model was shipped. However, after resolving this issue in later updates, we significantly boosted performance on that surface, beating the legacy model by 2% on\u00a0AUC-ROC.</p><p><strong>Calibration:</strong> The Unified Browse pCTR model has achieved around 64%-77% improvement over legacy Browse XGBoost pCTR models on all surfaces except BIA. It significantly reduced the bias of the model and provided fairer second-price-auction (2PA) pricing for our auction\u00a0systems.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*dui4pQYGoa00ryX9\" /></figure><p>Fig-7: Breakdown of the calibration by\u00a0surface</p><h3>Impacts</h3><p>A/B Tests showed that the new model substantially improved incremental sales and return on ads spend (ROAS) for the advertisers, and decreased ads end-to-end latency by onboarding to the new model serving platform. Moreover, it significantly increased overall cart adds, demonstrating its ability to increase sales without cannibalizing organic conversions. It was truly a triple win for Instacart, our customers and advertising partners.</p><p>What\u2019s more exciting: consolidating the model allowed us to iterate more efficiently. Two weeks after the initial rollout, the team launched a second iteration of the model, which incorporated real-time features from the Ads Marketplace team, along with short-term and long-term user history features including those from user modeling to give the performance yet another boost. This iteration again improved ROAS for the advertisers and increased profit per\u00a0user.</p><p>Combining the two rollout stages led to significant improvements in advertiser incrementality and performance, and substantial gain in cart adds, by raising the quality of ads shown to Instacart customers, while reducing end-to-end latency and operational overhead for Instacart. This achievement testifies to the impact of investment in ML expertise and infrastructure.</p><h3>Learnings &amp; Conclusions</h3><ul><li><strong>Unified modeling:</strong> By consolidating data and training a single unified model, we were able to improve user profiling and enhance performance across various browsing surfaces.</li><li><strong>Deep Learning advantages:</strong> Leveraging Deep Learning frameworks enabled us to integrate high-cardinality features, incorporating contextual information for all various surfaces. Deep Learning frameworks also capture complex interactions, resulting in more accurate predictions and improved model performance.</li><li><strong>Missing values:</strong> Even though different Browse surfaces have unique sets of contexts, Deep Learning models can learn the meanings of missing values. Even without employing complicated imputation techniques, the model\u2019s performance remains unaffected.</li><li><strong>Shallow interactions:</strong> We also introduced shallow interactions through factorization machines, which led to a notable 1% improvement in metrics such as log loss and AUC. This demonstrates the effectiveness of this technique in enhancing model performance.</li><li><strong>Iterative improvements:</strong> The ability to iterate and optimize the model quickly by incorporating new features and experimenting with different model architectures is crucial for maintaining a streamlined ML workflow and achieving ongoing success in machine learning.</li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0eb6bf60b00d\" width=\"1\" /><hr /><p><a href=\"https://tech.instacart.com/one-model-to-serve-them-all-0eb6bf60b00d\">One model to serve them all</a> was originally published in <a href=\"https://tech.instacart.com\">tech-at-instacart</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "CockroachDB": {
    "title": "PostgreSQL data types: what are they, and when to use each",
    "xmlUrl": "https://www.cockroachlabs.com/blog/index.xml",
    "htmlUrl": "https://www.cockroachlabs.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.cockroachlabs.com/blog/index.xml",
      "value": "PostgreSQL data types: what are they, and when to use each"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.cockroachlabs.com/blog/postgres-data-types/"
      }
    ],
    "link": "https://www.cockroachlabs.com/blog/postgres-data-types/",
    "published": "Fri, 12 Jan 2024 16:50:02 +0000",
    "published_parsed": [
      2024,
      1,
      12,
      16,
      50,
      2,
      4,
      12,
      0
    ],
    "id": "https://www.cockroachlabs.com/blog/postgres-data-types/",
    "guidislink": false,
    "summary": "PostgreSQL data types: what are they, and when to use each Enforcing strict data types is one of the major advantages of relational databases, and PostgreSQL is one of the most popular open-source relational database options. In this article, we\u2019ll look at many of the most commonly used data types in Postgres, how they\u2019re used, and even how they map to more advanced distributed SQL databases.\n(Note that when in doubt, you should always refer to Postgres\u2019s official documentation for the latest information).",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.cockroachlabs.com/blog/index.xml",
      "value": "PostgreSQL data types: what are they, and when to use each Enforcing strict data types is one of the major advantages of relational databases, and PostgreSQL is one of the most popular open-source relational database options. In this article, we\u2019ll look at many of the most commonly used data types in Postgres, how they\u2019re used, and even how they map to more advanced distributed SQL databases.\n(Note that when in doubt, you should always refer to Postgres\u2019s official documentation for the latest information)."
    }
  },
  "Just Eat": {
    "title": "App launching: OperationQueue to the rescue",
    "xmlUrl": "https://tech.just-eat.com/feed/",
    "htmlUrl": "https://tech.just-eat.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.justeattakeaway.com:443/feed/",
      "value": "App launching: OperationQueue to the rescue"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.justeattakeaway.com/2021/02/04/app-launching-operationqueue-to-the-rescue/"
      }
    ],
    "link": "https://tech.justeattakeaway.com/2021/02/04/app-launching-operationqueue-to-the-rescue/",
    "authors": [
      {
        "name": "Luigi Parpinel"
      }
    ],
    "author": "Luigi Parpinel",
    "author_detail": {
      "name": "Luigi Parpinel"
    },
    "published": "Thu, 04 Feb 2021 18:29:37 +0000",
    "published_parsed": [
      2021,
      2,
      4,
      18,
      29,
      37,
      3,
      35,
      0
    ],
    "tags": [
      {
        "term": "iOS",
        "scheme": null,
        "label": null
      },
      {
        "term": "Mobile",
        "scheme": null,
        "label": null
      },
      {
        "term": "Architecture",
        "scheme": null,
        "label": null
      },
      {
        "term": "Concurrency",
        "scheme": null,
        "label": null
      },
      {
        "term": "Performance",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://tech.just-eat.com/?p=466245",
    "guidislink": false,
    "summary": "The challenge: MAD (Massive App Delegate) Modern apps are complex, the iOS community has come up with a few architectural patterns to manage such complexity. Nonetheless, there is a step in the apps lifecycle where this complexity has not yet been tamed: the app launch. It\u2019s quite common to find bugs in which an app...",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://tech.justeattakeaway.com:443/feed/",
      "value": "The challenge: MAD (Massive App Delegate) Modern apps are complex, the iOS community has come up with a few architectural patterns to manage such complexity. Nonetheless, there is a step in the apps lifecycle where this complexity has not yet been tamed: the app launch. It\u2019s quite common to find bugs in which an app..."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://tech.justeattakeaway.com:443/feed/",
        "value": "<h2><strong>The challenge: MAD (Massive App Delegate)</strong></h2>\n\n\n\n<p>Modern apps are complex, the iOS community has come up with a few architectural patterns to manage such complexity. Nonetheless, there is a step in the apps lifecycle where this complexity has not yet been tamed: the app launch. It\u2019s quite common to find bugs in which an app does not behave as expected, when launched from springboard shortcuts, or notifications. These bugs are usually related to:</p>\n\n\n\n<ul><li>non-linear navigation, this happens when an app is already running and you try to navigate to a screen that can\u2019t be reached from the current screen</li><li>issues in managing the request because the app is launching from a cold start.</li></ul>\n\n\n\n<p>As developers we want our app to behave correctly and to launch as fast as it can. The iOS watchdog monitors the app\u2019s launch time, and terminates&nbsp; the app if the startup is not fast enough.</p>\n\n\n\n<p>The complexity comes from all the steps that the app needs to perform to be ready to be used. These steps include things like fetching and applying feature flags, executing asynchronous network code, migrating databases, initializing third-party SDKs and other operations such as the handling of universal links, NSUserActivity or quick actions.&nbsp;</p>\n\n\n\n<p>It\u2019s important to note that some of these operations can be executed concurrently, while others should be done in a specific order.</p>\n\n\n\n<p>Another source of complexity is time. The AppDelegate is (<a href=\"https://developer.apple.com/documentation/swiftui/app\"><em>was</em></a>, but this is out of topic for this post&#8230;) the first object that you see when you create a new project and this usually means that it is one of the oldest files in your codebase. It is supposed to be used as an interface to communicate with the OS, but it ends up being an over complicated and confusing class, in which you can find every kind of code, from network code to UI code.&nbsp;</p>\n\n\n\n<h2><strong>Divide et impera</strong></h2>\n\n\n\n<p>Let\u2019s define what we want to achieve. We want our app launching code to be:</p>\n\n\n\n<ul><li>Fast</li><li>Predictable</li><li>Encapsulated</li><li>Decoupled</li><li>Testable</li><li>Maintainable&nbsp;</li></ul>\n\n\n\n<p>To achieve this we can use the <em>divide et impera</em> strategy. The app setup should be divided into small chunks of initialisation code following the <a href=\"https://en.wikipedia.org/wiki/Single-responsibility_principle\"><em>single responsibility principle</em></a>. These chunks will have dependencies between each other so we need to track which chunk depends on what. Conceptually the app is ready to be used when all these chunks have been executed. An important note is that the code of the chunks must be decoupled, but this does not mean that they can\u2019t be dependent on each other, for example one chunk can produce a result that another chunk will consume as its input. Once we have all these blocks of code we need one or more executors to run them.</p>\n\n\n\n<p>Foundation already provides a great way to achieve this: <a href=\"https://developer.apple.com/documentation/foundation/operationqueue\">OperationQueue</a>.</p>\n\n\n\n<p>Each chunk of code will be an <a href=\"https://developer.apple.com/documentation/foundation/operation\">operation</a>. The operations are encapsulated and can be easily tested on their own. Their code is decoupled but it\u2019s very easy to define dependencies between operations in a declarative way and the framework will handle the dependencies for you. Dependencies can be even defined on operations enqueued on different queues running on different threads.&nbsp;</p>\n\n\n\n<p>Defining dependencies in a declarative way will make it very easy to understand and maintain them. It will make your code predictable because you will always know in which order it will be executed.</p>\n\n\n\n<p>To make our code faster and to avoid blocking the main thread for too long, we can use multiple queues to execute code in parallel. A possible setup could be:</p>\n\n\n\n<ul><li>using the main operation queue to execute the operations one by one on the main queue running on the main thread</li><li>using a background concurrent queue to execute in parallel multiple operations that do not need to be executed on the main queue, such as networking code or database management.</li></ul>\n\n\n\n<p>The OS will automatically scale the number of concurrently running operations based on the device resources (RAM, number of CPU cores, etc.) and the dependencies between the operations, which will guarantee the fastest possible execution and the most efficient resource usage.</p>\n\n\n\n<h2><strong>Show me some code (or pseudo-code)</strong></h2>\n\n\n\n<p>It\u2019s not easy to provide a real and meaningful example of an app setup, but I want to provide a quick example. A common and complex-enough scenario, is when the user launches the app using a quick action from the home screen. It\u2019s quite easy to handle, isn\u2019t it?</p>\n\n\n\n<div class=\"wp-block-simple-code-block-ace\" style=\"height: 250px; margin-bottom: 50px;\"><pre class=\"wp-block-simple-code-block-ace\">func application(_ application: UIApplication,\n                 didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n\n        if let shortcut = launchOptions?[.shortcutItem] as? UIApplicationShortcutItem {\n            doSomething(shortcut)\n        }\n\n        return true\n}\n</pre></div>\n\n\n\n<p>Sadly, it is not that easy\u2026 because we need to do other stuff first, like initialise the crash reporting sdk.</p>\n\n\n\n<div class=\"wp-block-simple-code-block-ace\" style=\"height: 250px; margin-bottom: 50px;\"><pre class=\"wp-block-simple-code-block-ace\"> func application(_ application: UIApplication,\n                  didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n\n        AnotherSDK(key: \"Th1s1s4S3cretK3y\")\n        \n        if let shortcut = launchOptions?[.shortcutItem] as? UIApplicationShortcutItem {\n            doSomething(shortcut)\n        }\n\n        return true\n    }\n</pre></div>\n\n\n\n<p>Done! More or less.. Other things to consider include:&nbsp;</p>\n\n\n\n<ul><li>The network call which should be fired as soon asthe app starts to fetch the user\u2019s data.</li><li>The feature toggles should be fetched before performing the action, but after the SDK initialisation.&nbsp;</li></ul>\n\n\n\n<div class=\"wp-block-simple-code-block-ace\" style=\"height: 250px; margin-bottom: 50px;\"><pre class=\"wp-block-simple-code-block-ace\"> func application(_ application: UIApplication,\n                     didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n\n        AnotherSDK(key: \"Th1s1s4S3cretK3y\")\n        \n        let userDataTask = URLSession.shared.dataTask(with: self.userDataURL) { [unowned self] _, _, _ in\n            let featureToggleTask = URLSession.shared.dataTask(with: self.toggleURL) { _, _, _ in\n                if let shortcut = launchOptions?[.shortcutItem] as? UIApplicationShortcutItem {\n                    self.doSomething(shortcut)\n                }\n            }\n            featureToggleTask.resume()\n        }\n        userDataTask.resume()\n\n        return true\n    }\n</pre></div>\n\n\n\n<p>How easy is it to understand and change coupled code like this? It already starts to look like a Massive App Delegate.</p>\n\n\n\n<p>In the following diagram you can see how the initialisation code can be split into operations and their dependencies (keep a lookout for circular dependencies to avoid potential deadlocks). The blocks represent the operations. The yellow blocks are the initialisations one and the green \u201chandle shortcut\u201d block is the action that the app should perform when the app is ready. The arrows show the dependencies between the blocks.</p>\n\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh6.googleusercontent.com/dl3HGOkGEOnmu12g0QlTnf1BNEnPstQfcn60JiJipP7jqAMQAy9YmHpj988TqZ5Td5qD1WuICP6T7_DHzSBcf_22U95tCGRe5cYwSZQ_-lRLCMZWwz-iOS6eH59ABPp44qxenajf\" /></figure>\n\n\n\n<p><a href=\"https://lucid.app/documents/edit/7d865c32-0d7f-46c6-acda-f97745fd9229/0?callback=close&amp;name=docs&amp;callback_type=back&amp;v=490&amp;s=595.4399999999999\"></a></p>\n\n\n\n<p>Now that we know what we want to achieve, let\u2019s see how the code will look.&nbsp;</p>\n\n\n\n<div class=\"wp-block-simple-code-block-ace\" style=\"height: 250px; margin-bottom: 50px;\"><pre class=\"wp-block-simple-code-block-ace\">// The returned queue executes one operation at a time on the app\u2019s main thread\nlet mainOperationQueue = OperationQueue.main\n\nlet concurrentOperationQueue: OperationQueue = {\n    let queue = OperationQueue()\n    queue.qualityOfService = .userInitiated\n    return queue\n}()\n    \nfunc application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n\n    let handleQuickAction = BlockOperation { [unowned self] in\n        if let shortcut = launchOptions?[.shortcutItem] as? UIApplicationShortcutItem {\n            self.doSomething(shortcut)\n        }\n    }\n        \n    let sdkInitializationOperation = BlockOperation {\n        AnotherSDK(key: \"Th1s1s4S3cretK3y\")\n    }\n        \n    let fetchUserDataOperation = AsyncBlockOperation { [unowned self] operation in\n        let task = URLSession.shared.dataTask(with: self.userDataURL) { _, _, _ in\n            // Do something with the response\n            operation.finish()\n        }\n        task.resume()\n    }\n\n    let fetchFeatureToggleOperation = AsyncBlockOperation { [unowned self] operation in\n        let task = URLSession.shared.dataTask(with: self.toggleURL) { _, _, _ in\n            // Do something with the response\n            operation.finish()\n        }\n        task.resume()\n    }\n        \n        // Setting up the dependencies\n    handleQuickAction.addDependency(fetchUserDataOperation)\n    handleQuickAction.addDependency(fetchFeatureToggleOperation)\n    \n    fetchFeatureToggleOperation.addDependency(sdkInitializationOperation)\n        \n    mainOperationQueue.addOperations([handleQuickAction], waitUntilFinished: false)\n    concurrentOperationQueue.addOperations([sdkInitializationOperation,\n                                        \n    return true\n}\n</pre></div>\n\n\n\n<p>The operations can be moved away from the app delegate and from the <em>application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -&gt; Bool. </em>The key point here is that each operation is self-contained, they can be tested separately and the dependency management between them is easy to change, it\u2019s declarative and it is decoupled from their creation, making it easy to modify the execution order and the concurrency model.</p>\n\n\n\n<p>Note: <em>AsyncBlockOperation </em>is a common <em>Operation</em> subclass that I suggest to add to your codebase. An example can be found <a href=\"https://gist.github.com/gigisommo/0bebb9e7d6d3104cd99eeb9c51c0847e\">here</a>.</p>\n\n\n\n<h2>Conclusion</h2>\n\n\n\n<p>In software engineering there are always multiple solutions to address an issue and this is just one of the ways in which you can better handle the application setup.</p>\n\n\n\n<p>The most important advantages in this solution are:</p>\n\n\n\n<ul><li>It is built-in in the iOS SDK. OperationQueue is available since iOS 2.0, it\u2019s been&nbsp; battle-tested over the years and it\u2019s good to rely on something supported by Apple for a critical part of the app such as the app setup;</li><li>It is quite easy to implement. Making an operation starting from a block of code is very easy so it should be straightforward to refactor existing code with this approach;</li><li>The declarative style for dependency management makes it very easy to write predictable code.</li></ul>\n\n\n\n<p>On top of all of that, every iOS developer should already be familiar with OperationQueue so it should be easy for everyone in your team to work with them without having to learn another framework or paradigm and, maybe, someone will enjoy this powerful tool even more!</p>"
      }
    ]
  },
  "Nordic APIs": {
    "title": "APIFutures: API Sprawl to Be a Pressing Concern in 2024",
    "xmlUrl": "https://nordicapis.com/feed/",
    "htmlUrl": "https://nordicapis.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://nordicapis.com/feed/",
      "value": "APIFutures: API Sprawl to Be a Pressing Concern in 2024"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://nordicapis.com/api-futures-api-sprawl-to-be-a-pressing-concern-in-2024/"
      }
    ],
    "link": "https://nordicapis.com/api-futures-api-sprawl-to-be-a-pressing-concern-in-2024/",
    "comments": "https://nordicapis.com/api-futures-api-sprawl-to-be-a-pressing-concern-in-2024/#respond",
    "authors": [
      {
        "name": "Bill Doerrfeld"
      }
    ],
    "author": "Bill Doerrfeld",
    "author_detail": {
      "name": "Bill Doerrfeld"
    },
    "published": "Thu, 11 Jan 2024 00:01:00 +0000",
    "published_parsed": [
      2024,
      1,
      11,
      0,
      1,
      0,
      3,
      11,
      0
    ],
    "tags": [
      {
        "term": "blog",
        "scheme": null,
        "label": null
      },
      {
        "term": "Design",
        "scheme": null,
        "label": null
      },
      {
        "term": "Platforms",
        "scheme": null,
        "label": null
      },
      {
        "term": "Security",
        "scheme": null,
        "label": null
      },
      {
        "term": "API",
        "scheme": null,
        "label": null
      },
      {
        "term": "API as a Product",
        "scheme": null,
        "label": null
      },
      {
        "term": "API Security",
        "scheme": null,
        "label": null
      },
      {
        "term": "OWASP",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://nordicapis.com/?p=18609",
    "guidislink": false,
    "summary": "API reliance is continuing to escalate across the board. And, in some situations, it&#8217;s getting out of hand. A 2021 F5 report estimated the total number of APIs worldwide (public and private) is approaching 200 million. We&#8217;ve also seen an increased emphasis on API governance lately, likely due to the need for more standards and <a class=\"read_more\" href=\"https://nordicapis.com/api-futures-api-sprawl-to-be-a-pressing-concern-in-2024/\">...</a>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://nordicapis.com/feed/",
      "value": "API reliance is continuing to escalate across the board. And, in some situations, it&#8217;s getting out of hand. A 2021 F5 report estimated the total number of APIs worldwide (public and private) is approaching 200 million. We&#8217;ve also seen an increased emphasis on API governance lately, likely due to the need for more standards and <a class=\"read_more\" href=\"https://nordicapis.com/api-futures-api-sprawl-to-be-a-pressing-concern-in-2024/\">...</a>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://nordicapis.com/feed/",
        "value": "<p>API reliance is continuing to escalate across the board. And, in some situations, it&#8217;s getting out of hand. A 2021 <a href=\"https://www.f5.com/pdf/reports/f5-office-of-the-cto-report-continuous-api-sprawl.pdf\">F5 report</a> estimated the total number of APIs worldwide (public and private) is approaching 200 million. We&#8217;ve also seen an increased emphasis on <a href=\"https://nordicapis.com/how-to-build-and-enforce-great-api-governance/\">API governance</a> lately, likely due to the need for more standards and oversight in the wake of such sudden API growth.</p>\n<p>86% of developers <a href=\"https://www.nylas.com/state-of-api-developer-experience/\">surveyed by Nylas</a> reported they anticipated their use of APIs to increase. And, in 2023, new threats like Improper Inventory Management and Unsafe Consumption of APIs made the <a href=\"https://owasp.org/www-project-api-security/\">OWASP API Security Top 10</a>. To me, this demonstrates the growth in overall API usage and the fact that organizations aren&#8217;t always keeping an accurate inventory of the APIs they produce and integrate into their applications.</p>\n<p>In the immediate future, I anticipate large organizations running into more API sprawl issues. And in the coming year, addressing API sprawl will become more of a pressing priority for IT leadership. This will likely materialize in the form of more API governance and guardrails around internal API-related operations. Below, I&#8217;ll overview what sprawl is, what software architects should watch out for, and how they can respond.</p>\n<div class=\"well\"><em>This post is part of APIFutures, a community-led, collaborative effort to identify the top challenges and opportunities facing the API economy in 2024. For other perspectives, be sure to read the articles by other authors <a href=\"https://matthewreinbold.github.io/APIFutures/index.html\">listed here</a>.</em></div>\n<a href=\"https://matthewreinbold.github.io/APIFutures/index.html\"><img alt=\"APIFutures\" class=\"aligncenter size-large wp-image-18622\" height=\"140\" src=\"https://nordicapis.com/wp-content/uploads/Partners-banner-dark-1024x140.png\" width=\"1024\" /></a>\n<h2 id=\"api-sprawl-the-what-where-how-and-why\">API Sprawl: The What, Where, How, and Why</h2>\n<p>Companies are using more and more APIs. Developers are wrapping APIs over databases, and teams are deploying applications built upon internal microservices. IT is also consuming various public API-based SaaS to avoid reinventing the wheel. They&#8217;re even <a href=\"https://blog.treblle.com/strategies-for-monetizing-public-apis/\">externalizing their own APIs</a> as <a href=\"https://blog.treblle.com/strategies-for-monetizing-public-apis/\">fully-fledged products</a>. In short, the number of APIs a single company manages continues to increase.</p>\n<p>For example, <a href=\"https://stateofapis.com/\">Rapid&#8217;s 2022 State of APIs report</a> found that large companies with 10,000 or more employees tend to have over 250 internal APIs. But, likely due to pressure to deliver code faster, many of these APIs are going undocumented. Alarmingly, only 10% of organizations fully document their APIs, according to a 2023 report from <a href=\"https://www.scmagazine.com/news/it-organizations-document-apis\">Enterprise Management Associates (EMA)</a>. This is a scenario poised for sprawl issues.</p>\n<p>In the context of APIs, I see sprawl as a quick, half-hazard adoption of APIs without following best practices. Overwhelmed with an escalating number of endpoints and juggling all the different versions and support timelines, managing a widening API portfolio becomes increasingly hectic. This can be especially challenging for those who initially thought the API movement was just a passing fad early on and didn&#8217;t bake the right practices into their software development culture for the long run.</p>\n<p>To put it simply:</p>\n<ul>\n<li>If you don&#8217;t know <em>what</em> APIs you have in your portfolio, you may have sprawl.</li>\n<li>If you don&#8217;t know <em>where</em> your APIs exist, you have sprawl.</li>\n<li>If you don&#8217;t know <em>how</em> your APIs are doing, you might have sprawl.</li>\n<li>If you don&#8217;t know <em>why</em> your integrations are breaking, you might have sprawl.</li>\n</ul>\n<h2 id=\"the-challenges-of-api-sprawl\">The Challenges of API Sprawl</h2>\n<p>API sprawl presents several potential challenges for software development groups. For instance, developers may waste time navigating the spaghetti code of intertwined, undocumented services. Or, it may be the harbinger of <a href=\"https://devops.com/how-to-prevent-zombie-apis/\">forgotten zombie APIs</a> that pose security threats. Here are some challenges API sprawl can bring a software organization.</p>\n<h3 id=\"poor-service-discoverability\">Poor Service Discoverability</h3>\n<p>Amid tooling sprawl, the likelihood of having a comprehensive catalog of all your internal services begins to wane. APIs become much less discoverable, hurting internal reusability. A lack of <a href=\"https://nordicapis.com/api-inventory-navigating-through-invisible-threats/\">API inventory management</a> can have dire security repercussions, too, since you can&#8217;t secure what you don&#8217;t know, as they say. Fixing vulnerabilities hinges on knowing what APIs exist and where, and an unmanaged widening surface area becomes stomping grounds for hackers.</p>\n<h3 id=\"inconsistencies-between-apis\">Inconsistencies Between APIs</h3>\n<p>Another outcome of a ballooning API portfolio is contending with <a href=\"https://nordicapis.com/how-to-test-apis-across-multiple-styles/\">disparate protocols and styles</a>. Web APIs, as we know them, have been in development for roughly two decades. Many API design formats have emerged in this timespan, from SOAP to <a href=\"https://nordicapis.com/the-ten-rest-commandments/\">REST</a>, <a href=\"https://nordicapis.com/6-strategies-for-documenting-webhooks/\">webhooks</a>, WebSockets, <a href=\"https://nordicapis.com/protecting-graphql-against-owasp-top-ten-api-risks/\">GraphQL</a>, and <a href=\"https://nordicapis.com/how-to-write-your-first-asyncapi-specification/\">asynchronous protocols</a>.</p>\n<p>These paradigms were leveraged to suit different needs and technology stacks at various times. And, in a large company, developers are likely juggling a combination of both newer and more legacy formats. A lack of guidance around <a href=\"https://nordicapis.com/11-tips-for-creating-an-api-style-guide/\">API style</a> across an API inventory can prevent learnability and inhibit developer experience.</p>\n<h3 id=\"lack-of-lifecycle-management\">Lack of Lifecycle Management</h3>\n<p>APIs evolve, and major versions may alter their structures or request mechanics, causing <a href=\"https://nordicapis.com/5-ways-to-detect-breaking-changes-in-your-apis/\">breaking changes</a>. Ungoverned API sprawl can produce a situation in which the state of APIs and their versions is not tracked well. Without well-documented <a>versioning and deprecation information</a>, you can have a fractured ecosystem with unclear support timelines.</p>\n<p>At the micro level, the issues caused by API sprawl can lead to a more chaotic software design culture and worsened <a href=\"https://www.cio.com/article/1255774/is-it-worth-measuring-software-developer-productivity-cios-weigh-in.html\">developer productivity</a>. At a macro level, unmitigated sprawl could affect the business by causing broken clients and outages for the end user, equating to a loss of revenue. Security threats stemming from sprawl issues could also lead to costly breaches, harming a business&#8217; reputation and balance sheet.</p>\n<h2 id=\"opportunities-and-solutions-to-mitigate-api-sprawl\">Opportunities And Solutions To Mitigate API Sprawl</h2>\n<p>Okay, that&#8217;s a lot of doom and gloom. So, what are some potential solutions to avoid API sprawl? Well, the vendors will say you need some sort of <a href=\"https://devops.com/supergraph-one-graphql-schema-to-rule-them-all/\">unification layer</a> or <a href=\"https://nordicapis.com/9-kubernetes-native-api-management-tools/\">management platform</a> to contend with API sprawl. While that may be helpful in certain situations, I&#8217;ll focus my advice below on some more general practices to help encourage better API standards across an organization to reduce the adverse effects of sprawl.</p>\n<ul>\n<li><strong>Document your APIs</strong>: Document the APIs you develop and follow <a href=\"https://nordicapis.com/10-tips-for-writing-great-api-documentation/\">standard documentation guidelines</a>. Include human-readable method descriptions, error messages, and sample code. (Here are <a href=\"https://nordicapis.com/5-examples-of-excellent-api-documentation/\">good examples of API documentation</a>). Assign people to support these APIs. (Documentation generation is one area where <a href=\"https://devops.com/how-generative-ai-can-streamline-code-documentation/\">AI might assist in the near future</a>).</li>\n<li><strong>Keep an active API inventory</strong>: Keep an up-to-date internal developer portal that lists all the APIs your organization maintains and integrates. This may involve continual runtime analysis to generate an active inventory. A spreadsheet is better than no action at all, but ideally, this system is more dynamic. A functional API inventory will help with risk management and compliance, too.</li>\n<li><strong>Have an API style guide</strong>: Centralize API design practices with an <a href=\"https://nordicapis.com/11-tips-for-creating-an-api-style-guide/\">API style guide</a> that outlines common conventions for your organization. You could also lint new APIs against this style guide as they are created.</li>\n<li><strong>Use specification-driven development</strong>: This may still be a dream, even for API-first companies, but <a href=\"https://nordicapis.com/what-is-specification-driven-api-development/\">spec-driven development</a> brings many benefits worth considering. Synchronizing documentation, SDKs, and production implementations with a core OpenAPI specification grants tangible outcomes for API management at scale.</li>\n<li><strong>Automate API governance</strong>: Dedicate personnel to advance API excellence and knowledge-sharing. However, another option is to make API governance self-service when possible. This could be a tool that scans API specs to reveal flaws or automatically catalogs services, for example.</li>\n<li><strong>Check out APIs.json</strong>: <a href=\"https://apisjson.org/\">APIs.json</a> is an interesting machine-readable specification that can help improve the discoverability of API operations and metadata.</li>\n<li><strong>Plan for the long-term</strong>: On the provider side, many APIs are built without a plan for long-term maintenance and eventual retirement. <a href=\"https://nordicapis.com/how-do-you-treat-an-api-as-a-product/\">Treat the service as a product</a>, and set these policies upfront.</li>\n<li><strong>Formalize feedback mechanisms</strong>: To encourage more collaboration, it&#8217;s good to incorporate other developers&#8217; feedback as you iterate new interfaces. Taking this a step further, Google&#8217;s <a href=\"https://nordicapis.com/api-improvement-proposals-googles-take-on-the-api-style-guide/\">API Improvement Proposals</a> is an example of an interesting API design guidance system.</li>\n</ul>\n<h2 id=\"final-thoughts\">Final Thoughts</h2>\n<p>One on hand, I&#8217;m very excited about the growing momentum around API adoption. And arguably, the <a href=\"https://www.apifirst.tech/p/ai-and-apis-what-experts-think-the-future-holds\">current AI wave</a> will only bring new APIs to the market. However, in 2024, I anticipate more emphasis on responding to the operational logistics of ungoverned API development and integration. Architects will have to deal with sprawl in some form or another.</p>\n<p>2023 was a record year for API breaches. According to a <a href=\"https://www.businesswire.com/news/home/20230510005193/en/FireTail-API-Security-Report-2023-On-Track-for-Record-Year-Of-API-Breaches\">FireTail report</a>, API disclosures within the first two months of 2023 accounted for a potential impact of 49 million records. Inventorizing these APIs will be essential to increase visibility into the widening portfolio and potential threats therein.</p>\n<p>Sprawl rears its ugly head within a large organization with various siloed software development departments and a lack of communication. But, many of these issues <em>can</em> be overcome as API usage scales, with a collaborative culture that follows best practices concerning design, documentation, lifecycle management, and overall knowledge sharing.</p>\n<div class=\"well\"><em>APIFutures is a creator-led initiative that brings together a diverse array of voices from the API community to identify the most significant opportunities and challenges facing the API community in 2024. <a href=\"https://matthewreinbold.github.io/APIFutures/index.html\">Be sure to read the other APIFutures articles here</a>.</em></div>\n<p><em><a href=\"https://matthewreinbold.github.io/APIFutures/index.html\" rel=\"noopener\" target=\"_blank\"><img alt=\"\" class=\"aligncenter wp-image-18623 size-large\" height=\"256\" src=\"https://nordicapis.com/wp-content/uploads/LinkedIn-personal-profile-APIfutures-1024x256.png\" width=\"1024\" /></a></em></p>"
      }
    ],
    "wfw_commentrss": "https://nordicapis.com/api-futures-api-sprawl-to-be-a-pressing-concern-in-2024/feed/",
    "slash_comments": "0"
  },
  "Google Online Security": {
    "title": "Hardening cellular basebands in Android",
    "xmlUrl": "https://security.googleblog.com/feeds/posts/default",
    "htmlUrl": "https://security.googleblog.com/",
    "id": "tag:blogger.com,1999:blog-1176949257541686127.post-2267894734490098363",
    "guidislink": true,
    "link": "http://security.googleblog.com/2023/12/hardening-cellular-basebands-in-android.html",
    "published": "2023-12-12T12:00:00.000-05:00",
    "published_parsed": [
      2023,
      12,
      12,
      17,
      0,
      0,
      1,
      346,
      0
    ],
    "updated": "2023-12-12T12:00:09.520-05:00",
    "updated_parsed": [
      2023,
      12,
      12,
      17,
      0,
      9,
      1,
      346,
      0
    ],
    "tags": [
      {
        "term": "android",
        "scheme": "http://www.blogger.com/atom/ns#",
        "label": null
      },
      {
        "term": "android security",
        "scheme": "http://www.blogger.com/atom/ns#",
        "label": null
      }
    ],
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://feeds.feedburner.com/GoogleOnlineSecurityBlog",
      "value": "Hardening cellular basebands in Android"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "http://feeds.feedburner.com/GoogleOnlineSecurityBlog",
        "value": "<span class=\"byline-author\">Posted by Ivan Lozano and Roger Piqueras Jover</span>\n\n<p>\nAndroid\u2019s defense-in-depth strategy applies not only to the Android OS running on the Application Processor (AP) but also the firmware that runs on devices. We particularly <a href=\"https://security.googleblog.com/2023/02/hardening-firmware-across-android.html\">prioritize hardening the cellular baseband</a> given its unique combination of running in an elevated privilege and parsing untrusted inputs that are remotely delivered into the device.\n</p>\n<p>\nThis post covers how to use two high-value sanitizers which can prevent specific classes of vulnerabilities found within the baseband. They are architecture agnostic, suitable for bare-metal deployment, and should be enabled in existing C/C++ code bases to mitigate unknown vulnerabilities. Beyond security, addressing the issues uncovered by these sanitizers improves code health and overall stability, reducing resources spent addressing bugs in the future.\n</p>\n<h1>An increasingly popular attack surface</h1>\n\n\n<p>\nAs we <a href=\"https://security.googleblog.com/2023/02/hardening-firmware-across-android.html\">outlined previously</a>, security research focused on the baseband has highlighted a consistent lack of exploit mitigations in firmware. Baseband Remote Code Execution (RCE) exploits <a href=\"https://www.zerodium.com/images/zerodium_prices_mobiles.png\">have their own categorization</a> in well-known third-party marketplaces with a relatively low payout. This suggests baseband bugs may potentially be abundant and/or not too complex to find and exploit, and their prominent inclusion in the marketplace demonstrates that they are useful.\n</p>\n<p>\nBaseband security and exploitation has been a <a href=\"https://www.usenix.org/system/files/conference/woot12/woot12-final24.pdf\">recurring</a> <a href=\"https://www.blackhat.com/docs/us-14/materials/us-14-Lindh-Attacking-Mobile-Broadband-Modems-Like-A-Criminal-Would.pdf\">theme</a> in <a href=\"https://vimeo.com/showcase/4562410/video/214013463\">security</a> <a href=\"https://speakerdeck.com/marcograss/exploitation-of-a-modern-smartphone-baseband\">conferences</a> <a href=\"https://i.blackhat.com/USA21/Wednesday-Handouts/us-21-Over-The-Air-Baseband-Exploit-Gaining-Remote-Code-Execution-On-5G-Smartphones.pdf\">for the last decade</a>. Researchers have also made a dent in this area in <a href=\"https://www.forbes.com/sites/daveywinder/2019/11/10/samsung-galaxy-s10-hacked-twice/?sh=54b24bb25bd7\">well-known exploitation contests</a>. Most recently, this area has become prominent enough that it is  common to find practical baseband exploitation <a href=\"https://milano.securitybsides.it/baseband-exploitation.html\">trainings</a> in <a href=\"https://hardwear.io/usa-2023/training/reverse-engineering-emulation-dynamic-testing-cellular-baseband-firmware.php\">top</a> <a href=\"https://www.offensivecon.org/trainings/2023/baseband-exploitation.html\">security</a> <a href=\"https://www.hexacon.fr/trainer/ribeiro_burke/\">conferences</a>.\n</p>\n<p>\nAcknowledging this trend, combined with the severity and apparent abundance of these vulnerabilities, last year we introduced updates to the <a href=\"https://source.android.com/docs/security/overview/updates-resources#severity\">severity guidelines</a> of Android\u2019s Vulnerability Rewards Program (VRP). For example, we consider vulnerabilities allowing Remote Code Execution (RCE) in the cellular baseband to be of CRITICAL severity.\n</p>\n<h1>Mitigating Vulnerability Root Causes with Sanitizers</h1>\n\n\n<p>\nCommon classes of vulnerabilities can be mitigated through the use of sanitizers provided by <a href=\"https://clang.llvm.org/\">Clang-based toolchains</a>. These sanitizers insert runtime checks against common classes of vulnerabilities. GCC-based toolchains may also provide some level of support for these flags as well, but will not be considered further in this post. We encourage you to check your toolchain\u2019s documentation.\n</p>\n<p>\nTwo sanitizers included in <a href=\"https://source.android.com/docs/security/test/ubsan\">Undefined Behavior Sanitizer</a> (UBSan) will be our focus \u2013 <a href=\"https://source.android.com/docs/security/test/intsan\">Integer Overflow Sanitizer</a> (IntSan) and <a href=\"https://source.android.com/docs/security/test/bounds-sanitizer\">BoundsSanitizer</a> (BoundSan). These have been <a href=\"https://android-developers.googleblog.com/2016/05/hardening-media-stack.html\">widely deployed</a> in <a href=\"https://android-developers.googleblog.com/2018/06/compiler-based-security-mitigations-in.html\">Android userspace</a> <a href=\"https://android-developers.googleblog.com/2019/05/queue-hardening-enhancements.html\">for years</a> following <a href=\"https://security.googleblog.com/2021/01/data-driven-security-hardening-in.html\">a data-driven approach</a>. These two are well suited for bare-metal environments such as the baseband since they do not require support from the OS or specific architecture features, and so are generally supported for all Clang targets.\n</p>\n<h2>Integer Overflow Sanitizer (IntSan)</h2>\n\n\n<p>\nIntSan causes signed and unsigned integer overflows to abort execution unless the overflow is made explicit. While unsigned integer overflows are technically defined behavior, it can often lead to unintentional behavior and vulnerabilities \u2013 especially when they\u2019re used to index into arrays.\n</p>\n<p>\nAs both intentional and unintentional overflows are likely present in most code bases, IntSan may require refactoring and annotating the code base to prevent intentional or benign overflows from trapping (which we consider a false positive for our purposes). Overflows which need to be addressed can be uncovered via testing (see the Deploying Sanitizers section)\n</p>\n<h2>BoundsSanitizer (BoundSan)</h2>\n\n\n<p>\nBoundSan inserts instrumentation to perform bounds checks around some array accesses. These checks are only added if the compiler cannot prove at compile time that the access will be safe and if the size of the array will be known at runtime, so that it can be checked against. Note that this will not cover all array accesses as the size of the array may not be known at runtime, such as function arguments which are arrays.\n</p>\n<p>\nAs long as the code is correctly written C/C++, BoundSan should produce no false positives. Any violations discovered when first enabling BoundSan is at least a bug, if not a vulnerability. Resolving even those which aren\u2019t exploitable can greatly improve stability and code quality.\n</p>\n<h2>Modernize your toolchains</h2>\n\n\n<p>\nAdopting modern mitigations also means adopting (and maintaining) modern toolchains. The benefits of this go beyond utilizing sanitizers however. Maintaining an old toolchain is not free and entails hidden opportunity costs. Toolchains contain bugs which are addressed in <a href=\"https://releases.llvm.org/17.0.1/tools/clang/docs/ReleaseNotes.html#bug-fixes-in-this-version\">subsequent releases</a>. Newer toolchains bring new <a href=\"https://releases.llvm.org/17.0.1/tools/clang/docs/ReleaseNotes.html#bug-fixes-in-this-version:~:text=Improved%20code%20generation,MS%20C%2B%2B%20ABI.\">performance optimizations</a>, valuable in the highly constrained bare-metal environment that basebands operate in. <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2018-12886\">Security</a> <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-4039\">issues</a> can even exist in the generated code of out-of-date compilers.\n</p>\n<p>\nMaintaining a modern up-to-date toolchain for the baseband entails some costs in terms of maintenance, especially at first if the toolchain is particularly old, but over time the benefits, as outlined above, outweigh the costs.\n</p>\n<h1>Where to apply sanitizers</h1>\n\n\n<p>\nBoth BoundSan and IntSan have a measurable performance overhead. Although we were able to significantly reduce this overhead in the past (<a href=\"https://security.googleblog.com/2019/05/queue-hardening-enhancements.html\">for example to less than 1% in media codecs</a>), even very small increases in CPU load can have a substantial impact in some environments.\n</p>\n<p>\nEnabling sanitizers over the entire codebase provides the most benefit, but enabling them in security-critical attack surfaces can serve as a first step in an incremental deployment. For example:\n</p>\n<ul>\n\n<li>Functions parsing messages delivered over the air in 2G, 3G, 4G, and 5G (especially functions handling pre-authentication messages that can be injected with a false/malicious base station)\n\n<li>Libraries encoding/decoding complex formats (e.g. ASN.1, XML, DNS, etc\u2026)\n\n<li>IMS, TCP and IP stacks\n\n<li>Messaging functions (SMS, MMS)\n</li>\n</ul>\n<p>\nIn the particular case of 2G, the best strategy is to disable the stack altogether by supporting Android\u2019s \u201c<a href=\"https://source.android.com/docs/setup/about/android-12-release#2g-toggle\">2G toggle</a>\u201d. However, 2G is still a necessary mobile access technology in certain parts of the world and some users might need to have this legacy protocol enabled.\n</p>\n<h1>Deploying Sanitizers</h1>\n\n\n<p>\nHaving a clear plan for deployment of sanitizers saves a lot of time and effort. We think of the deployment process as having three stages:\n</p>\n<ul>\n\n<li>Detecting (and fixing) violations\n\n<li>Measuring and reducing overhead\n\n<li>Soaking in pre-production\n</li>\n</ul>\n<p>\nWe also introduce two modes in which sanitizers should be run: <strong>diagnostics mode</strong> and <strong>trapping mode</strong>. These will be discussed in the following sections, but briefly: diagnostics mode recovers from violations and provides valuable debug information, while trapping mode actively mitigates vulnerabilities by trapping execution on violations.\n</p>\n<h2>Detecting (and Fixing) Violations</h2>\n\n\n<p>\nTo successfully ship these sanitizers, any benign integer overflows must be made explicit and accidental out-of-bounds accesses must be addressed. These will have to be uncovered through testing. The higher the code coverage your tests provide, the more issues you can uncover at this stage and the easier deployment will be later on.\n</p>\n<p>\nTo diagnose violations uncovered in testing, sanitizers can emit calls to runtime handlers with debug information such as the file, line number, and values leading to the violation. Sanitizers can optionally continue execution after a violation has occurred, allowing multiple violations to be discovered in a single test run. We refer to using the sanitizers in this way as running them in \u201c<strong>diagnostics mode</strong>\u201d. Diagnostics mode is not intended for production as it provides no security benefits and adds high overhead.\n</p>\n<p>\nDiagnostics mode for the sanitizers can be set using the following flags:\n</p>\n\n\n\n<pre class=\"prettyprint\">-fsanitize=signed-integer-overflow,unsigned-integer-overflow,bounds -fsanitize-recover=all</pre>\n\n\n<p>\nSince Clang does not provide a UBSan runtime for bare-metal targets, a runtime will need to be defined and provided at link time:\n</p>\n\n\n\n<pre class=\"prettyprint\">// integer overflow handlers\n__ubsan_handle_add_overflow(OverflowData *data, ValueHandle lhs, ValueHandle rhs)\n__ubsan_handle_sub_overflow(OverflowData *data, ValueHandle lhs, ValueHandle rhs)\n__ubsan_handle_mul_overflow(OverflowData *data, ValueHandle lhs, ValueHandle rhs)\n__ubsan_handle_divrem_overflow(OverflowData *data, ValueHandle lhs, ValueHandle rhs)\n__ubsan_handle_negate_overflow(OverflowData *data, ValueHandle old_val)\n// boundsan handler\n__ubsan_handle_out_of_bounds_overflow(OverflowData *data, ValueHandle old_val)</pre>\n\n\n<p>\nAs an example, see the <a href=\"https://cs.android.com/android-llvm/toolchain/llvm-project/+/master:compiler-rt/lib/ubsan/ubsan_handlers.cc\">default Clang implementation</a>; the Linux Kernels <a href=\"https://cs.android.com/android/kernel/superproject/+/common-android-mainline:common/lib/ubsan.c;l=335?\">implementation</a> may also be illustrative.\n</p>\n<p>\nWith the runtime defined, enable the sanitizer over the entire baseband codebase and run all available tests to uncover and address any violations. Vulnerabilities should be patched, and overflows should either be refactored or made explicit through the use of <a href=\"https://clang.llvm.org/docs/LanguageExtensions.html#checked-arithmetic-builtins\">checked arithmetic builtins</a> which do not trigger sanitizer violations. Certain functions which are expected to have intentional overflows (such as cryptographic functions) can be preemptively excluded from sanitization (see next section).\n</p>\n<p>\nAside from uncovering security vulnerabilities, this stage is highly effective at uncovering code quality and stability bugs that could result in instability on user devices.\n</p>\n<p>\nOnce violations have been addressed and tests are no longer uncovering new violations, the next stage can begin.\n</p>\n<h2>Measuring and Reducing Overhead</h2>\n\n\n<p>\nOnce shallow violations have been addressed, benchmarks can be run and the overhead from the sanitizers (performance, code size, memory footprint) can be measured.\n</p>\n<p>\nMeasuring overhead must be done using production flags \u2013 namely <strong>\u201ctrapping mode\u201d</strong>, where violations cause execution to abort. The diagnostics runtime used in the first stage carries significant overhead and is not indicative of the actual performance sanitizer overhead.\n</p>\n<p>\nTrapping mode can be enabled using the following flags:\n</p>\n\n\n\n<pre class=\"prettyprint\">-fsanitize=signed-integer-overflow,unsigned-integer-overflow,bounds -fsanitize-trap=all</pre>\n\n\n<p>\nMost of the overhead is likely due to a small handful of \u201chot functions\u201d, for example those with tight long-running loops. Fine-grained per-function performance metrics (similar to what <a href=\"https://android.googlesource.com/platform/system/extras/+/master/simpleperf/doc/README.md\">Simpleperf</a> provides for Android), allows comparing metrics before and after sanitizers and provides the easiest means to identify hot functions. These functions can either be refactored or, after manual inspection to verify that they are safe, have sanitization disabled.\n</p>\n<p>\nSanitizers can be disabled either <a href=\"https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html#disabling-instrumentation-with-attribute-no-sanitize-undefined\">inline in the source</a> or through the use of <a href=\"https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html#suppressing-errors-in-recompiled-code-ignorelist\">ignorelists</a> and the -fsanitize-ignorelist flag.\n</p>\n<p>\nThe physical layer code, with its extremely tight performance margins and lower chance of exploitable vulnerabilities, may be a good candidate to disable sanitization wholesale if initial performance seems prohibitive.\n</p>\n<h2>Soaking in Pre-production</h2>\n\n\n<p>\nWith overhead minimized and shallow bugs resolved, the final stage is enabling the sanitizers in trapping mode to mitigate vulnerabilities.\n</p>\n<p>\nWe strongly recommend a long period of internal soak in pre-production with test populations to uncover any remaining violations not discovered in testing. The more thorough the test coverage and length of the soak period, the less risk there will be from undiscovered violations.\n</p>\n<p>\nAs above, the configuration for trapping mode is as follows:\n</p>\n\n\n\n<pre class=\"prettyprint\">-fsanitize=signed-integer-overflow,unsigned-integer-overflow,bounds -fsanitize-trap=all</pre>\n\n\n<p>\nHaving infrastructure in place to collect bug reports which result from any undiscovered violations can help minimize the risk they present.\n</p>\n<h1>Transitioning to Memory Safe Languages</h1>\n\n\n<p>\nThe benefits from deploying sanitizers in your existing code base are tangible, however ultimately they address only the lowest hanging fruit and will not result in a code base free of vulnerabilities. Other classes of memory safety vulnerabilities remain unaddressed by these sanitizers. A longer term solution is to begin transitioning <em>today</em> to memory-safe languages such as Rust.\n</p>\n<p>\n<a href=\"https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html\">Rust is ready for bare-metal environments</a> such as the baseband, and we are already using it in other bare-metal components in Android. There is no need to rewrite everything in Rust, as Rust provides a strong C FFI support and easily interfaces with existing C codebases. <a href=\"https://security.googleblog.com/2021/04/rust-in-android-platform.html#:~:text=But%20what%20about%20all%20that%20existing%20C%2B%2B%3F\">Just writing new code in Rust</a> can rapidly <a href=\"https://security.googleblog.com/2022/12/memory-safe-languages-in-android-13.html\">reduce the number of memory safety vulnerabilities</a>. Rewrites should be limited/prioritized only for the most critical components, such as complex parsers handling untrusted data.\n</p>\n<p>\nThe Android team has developed a <a href=\"https://google.github.io/comprehensive-rust/\">Rust training</a> meant to help experienced developers quickly ramp up Rust fundamentals. An entire day for <a href=\"https://google.github.io/comprehensive-rust/bare-metal.html\">bare-metal Rust</a> is included, and the course has been translated to a number of different languages.\n</p>\n<p>\nWhile the Rust compiler may not explicitly support your bare-metal target, because it is a front-end for LLVM, any target supported by LLVM can be supported in Rust through <a href=\"https://docs.rust-embedded.org/embedonomicon/custom-target.html\">custom target definitions</a>.\n</p>\n<h1>Raising the Bar</h1>\n\n\n<p>\nAs the high-level operating system becomes a more difficult target for attackers to successfully exploit, we expect that lower level components such as the baseband will attract more attention. By using modern toolchains and deploying exploit mitigation technologies, the bar for attacking the baseband can be raised as well. If you have any questions, let us know \u2013 we\u2019re here to help!\n</p>"
      }
    ],
    "summary": "<span class=\"byline-author\">Posted by Ivan Lozano and Roger Piqueras Jover</span>\n\n<p>\nAndroid\u2019s defense-in-depth strategy applies not only to the Android OS running on the Application Processor (AP) but also the firmware that runs on devices. We particularly <a href=\"https://security.googleblog.com/2023/02/hardening-firmware-across-android.html\">prioritize hardening the cellular baseband</a> given its unique combination of running in an elevated privilege and parsing untrusted inputs that are remotely delivered into the device.\n</p>\n<p>\nThis post covers how to use two high-value sanitizers which can prevent specific classes of vulnerabilities found within the baseband. They are architecture agnostic, suitable for bare-metal deployment, and should be enabled in existing C/C++ code bases to mitigate unknown vulnerabilities. Beyond security, addressing the issues uncovered by these sanitizers improves code health and overall stability, reducing resources spent addressing bugs in the future.\n</p>\n<h1>An increasingly popular attack surface</h1>\n\n\n<p>\nAs we <a href=\"https://security.googleblog.com/2023/02/hardening-firmware-across-android.html\">outlined previously</a>, security research focused on the baseband has highlighted a consistent lack of exploit mitigations in firmware. Baseband Remote Code Execution (RCE) exploits <a href=\"https://www.zerodium.com/images/zerodium_prices_mobiles.png\">have their own categorization</a> in well-known third-party marketplaces with a relatively low payout. This suggests baseband bugs may potentially be abundant and/or not too complex to find and exploit, and their prominent inclusion in the marketplace demonstrates that they are useful.\n</p>\n<p>\nBaseband security and exploitation has been a <a href=\"https://www.usenix.org/system/files/conference/woot12/woot12-final24.pdf\">recurring</a> <a href=\"https://www.blackhat.com/docs/us-14/materials/us-14-Lindh-Attacking-Mobile-Broadband-Modems-Like-A-Criminal-Would.pdf\">theme</a> in <a href=\"https://vimeo.com/showcase/4562410/video/214013463\">security</a> <a href=\"https://speakerdeck.com/marcograss/exploitation-of-a-modern-smartphone-baseband\">conferences</a> <a href=\"https://i.blackhat.com/USA21/Wednesday-Handouts/us-21-Over-The-Air-Baseband-Exploit-Gaining-Remote-Code-Execution-On-5G-Smartphones.pdf\">for the last decade</a>. Researchers have also made a dent in this area in <a href=\"https://www.forbes.com/sites/daveywinder/2019/11/10/samsung-galaxy-s10-hacked-twice/?sh=54b24bb25bd7\">well-known exploitation contests</a>. Most recently, this area has become prominent enough that it is  common to find practical baseband exploitation <a href=\"https://milano.securitybsides.it/baseband-exploitation.html\">trainings</a> in <a href=\"https://hardwear.io/usa-2023/training/reverse-engineering-emulation-dynamic-testing-cellular-baseband-firmware.php\">top</a> <a href=\"https://www.offensivecon.org/trainings/2023/baseband-exploitation.html\">security</a> <a href=\"https://www.hexacon.fr/trainer/ribeiro_burke/\">conferences</a>.\n</p>\n<p>\nAcknowledging this trend, combined with the severity and apparent abundance of these vulnerabilities, last year we introduced updates to the <a href=\"https://source.android.com/docs/security/overview/updates-resources#severity\">severity guidelines</a> of Android\u2019s Vulnerability Rewards Program (VRP). For example, we consider vulnerabilities allowing Remote Code Execution (RCE) in the cellular baseband to be of CRITICAL severity.\n</p>\n<h1>Mitigating Vulnerability Root Causes with Sanitizers</h1>\n\n\n<p>\nCommon classes of vulnerabilities can be mitigated through the use of sanitizers provided by <a href=\"https://clang.llvm.org/\">Clang-based toolchains</a>. These sanitizers insert runtime checks against common classes of vulnerabilities. GCC-based toolchains may also provide some level of support for these flags as well, but will not be considered further in this post. We encourage you to check your toolchain\u2019s documentation.\n</p>\n<p>\nTwo sanitizers included in <a href=\"https://source.android.com/docs/security/test/ubsan\">Undefined Behavior Sanitizer</a> (UBSan) will be our focus \u2013 <a href=\"https://source.android.com/docs/security/test/intsan\">Integer Overflow Sanitizer</a> (IntSan) and <a href=\"https://source.android.com/docs/security/test/bounds-sanitizer\">BoundsSanitizer</a> (BoundSan). These have been <a href=\"https://android-developers.googleblog.com/2016/05/hardening-media-stack.html\">widely deployed</a> in <a href=\"https://android-developers.googleblog.com/2018/06/compiler-based-security-mitigations-in.html\">Android userspace</a> <a href=\"https://android-developers.googleblog.com/2019/05/queue-hardening-enhancements.html\">for years</a> following <a href=\"https://security.googleblog.com/2021/01/data-driven-security-hardening-in.html\">a data-driven approach</a>. These two are well suited for bare-metal environments such as the baseband since they do not require support from the OS or specific architecture features, and so are generally supported for all Clang targets.\n</p>\n<h2>Integer Overflow Sanitizer (IntSan)</h2>\n\n\n<p>\nIntSan causes signed and unsigned integer overflows to abort execution unless the overflow is made explicit. While unsigned integer overflows are technically defined behavior, it can often lead to unintentional behavior and vulnerabilities \u2013 especially when they\u2019re used to index into arrays.\n</p>\n<p>\nAs both intentional and unintentional overflows are likely present in most code bases, IntSan may require refactoring and annotating the code base to prevent intentional or benign overflows from trapping (which we consider a false positive for our purposes). Overflows which need to be addressed can be uncovered via testing (see the Deploying Sanitizers section)\n</p>\n<h2>BoundsSanitizer (BoundSan)</h2>\n\n\n<p>\nBoundSan inserts instrumentation to perform bounds checks around some array accesses. These checks are only added if the compiler cannot prove at compile time that the access will be safe and if the size of the array will be known at runtime, so that it can be checked against. Note that this will not cover all array accesses as the size of the array may not be known at runtime, such as function arguments which are arrays.\n</p>\n<p>\nAs long as the code is correctly written C/C++, BoundSan should produce no false positives. Any violations discovered when first enabling BoundSan is at least a bug, if not a vulnerability. Resolving even those which aren\u2019t exploitable can greatly improve stability and code quality.\n</p>\n<h2>Modernize your toolchains</h2>\n\n\n<p>\nAdopting modern mitigations also means adopting (and maintaining) modern toolchains. The benefits of this go beyond utilizing sanitizers however. Maintaining an old toolchain is not free and entails hidden opportunity costs. Toolchains contain bugs which are addressed in <a href=\"https://releases.llvm.org/17.0.1/tools/clang/docs/ReleaseNotes.html#bug-fixes-in-this-version\">subsequent releases</a>. Newer toolchains bring new <a href=\"https://releases.llvm.org/17.0.1/tools/clang/docs/ReleaseNotes.html#bug-fixes-in-this-version:~:text=Improved%20code%20generation,MS%20C%2B%2B%20ABI.\">performance optimizations</a>, valuable in the highly constrained bare-metal environment that basebands operate in. <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2018-12886\">Security</a> <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-4039\">issues</a> can even exist in the generated code of out-of-date compilers.\n</p>\n<p>\nMaintaining a modern up-to-date toolchain for the baseband entails some costs in terms of maintenance, especially at first if the toolchain is particularly old, but over time the benefits, as outlined above, outweigh the costs.\n</p>\n<h1>Where to apply sanitizers</h1>\n\n\n<p>\nBoth BoundSan and IntSan have a measurable performance overhead. Although we were able to significantly reduce this overhead in the past (<a href=\"https://security.googleblog.com/2019/05/queue-hardening-enhancements.html\">for example to less than 1% in media codecs</a>), even very small increases in CPU load can have a substantial impact in some environments.\n</p>\n<p>\nEnabling sanitizers over the entire codebase provides the most benefit, but enabling them in security-critical attack surfaces can serve as a first step in an incremental deployment. For example:\n</p>\n<ul>\n\n<li>Functions parsing messages delivered over the air in 2G, 3G, 4G, and 5G (especially functions handling pre-authentication messages that can be injected with a false/malicious base station)\n\n<li>Libraries encoding/decoding complex formats (e.g. ASN.1, XML, DNS, etc\u2026)\n\n<li>IMS, TCP and IP stacks\n\n<li>Messaging functions (SMS, MMS)\n</li>\n</ul>\n<p>\nIn the particular case of 2G, the best strategy is to disable the stack altogether by supporting Android\u2019s \u201c<a href=\"https://source.android.com/docs/setup/about/android-12-release#2g-toggle\">2G toggle</a>\u201d. However, 2G is still a necessary mobile access technology in certain parts of the world and some users might need to have this legacy protocol enabled.\n</p>\n<h1>Deploying Sanitizers</h1>\n\n\n<p>\nHaving a clear plan for deployment of sanitizers saves a lot of time and effort. We think of the deployment process as having three stages:\n</p>\n<ul>\n\n<li>Detecting (and fixing) violations\n\n<li>Measuring and reducing overhead\n\n<li>Soaking in pre-production\n</li>\n</ul>\n<p>\nWe also introduce two modes in which sanitizers should be run: <strong>diagnostics mode</strong> and <strong>trapping mode</strong>. These will be discussed in the following sections, but briefly: diagnostics mode recovers from violations and provides valuable debug information, while trapping mode actively mitigates vulnerabilities by trapping execution on violations.\n</p>\n<h2>Detecting (and Fixing) Violations</h2>\n\n\n<p>\nTo successfully ship these sanitizers, any benign integer overflows must be made explicit and accidental out-of-bounds accesses must be addressed. These will have to be uncovered through testing. The higher the code coverage your tests provide, the more issues you can uncover at this stage and the easier deployment will be later on.\n</p>\n<p>\nTo diagnose violations uncovered in testing, sanitizers can emit calls to runtime handlers with debug information such as the file, line number, and values leading to the violation. Sanitizers can optionally continue execution after a violation has occurred, allowing multiple violations to be discovered in a single test run. We refer to using the sanitizers in this way as running them in \u201c<strong>diagnostics mode</strong>\u201d. Diagnostics mode is not intended for production as it provides no security benefits and adds high overhead.\n</p>\n<p>\nDiagnostics mode for the sanitizers can be set using the following flags:\n</p>\n\n\n\n<pre class=\"prettyprint\">-fsanitize=signed-integer-overflow,unsigned-integer-overflow,bounds -fsanitize-recover=all</pre>\n\n\n<p>\nSince Clang does not provide a UBSan runtime for bare-metal targets, a runtime will need to be defined and provided at link time:\n</p>\n\n\n\n<pre class=\"prettyprint\">// integer overflow handlers\n__ubsan_handle_add_overflow(OverflowData *data, ValueHandle lhs, ValueHandle rhs)\n__ubsan_handle_sub_overflow(OverflowData *data, ValueHandle lhs, ValueHandle rhs)\n__ubsan_handle_mul_overflow(OverflowData *data, ValueHandle lhs, ValueHandle rhs)\n__ubsan_handle_divrem_overflow(OverflowData *data, ValueHandle lhs, ValueHandle rhs)\n__ubsan_handle_negate_overflow(OverflowData *data, ValueHandle old_val)\n// boundsan handler\n__ubsan_handle_out_of_bounds_overflow(OverflowData *data, ValueHandle old_val)</pre>\n\n\n<p>\nAs an example, see the <a href=\"https://cs.android.com/android-llvm/toolchain/llvm-project/+/master:compiler-rt/lib/ubsan/ubsan_handlers.cc\">default Clang implementation</a>; the Linux Kernels <a href=\"https://cs.android.com/android/kernel/superproject/+/common-android-mainline:common/lib/ubsan.c;l=335?\">implementation</a> may also be illustrative.\n</p>\n<p>\nWith the runtime defined, enable the sanitizer over the entire baseband codebase and run all available tests to uncover and address any violations. Vulnerabilities should be patched, and overflows should either be refactored or made explicit through the use of <a href=\"https://clang.llvm.org/docs/LanguageExtensions.html#checked-arithmetic-builtins\">checked arithmetic builtins</a> which do not trigger sanitizer violations. Certain functions which are expected to have intentional overflows (such as cryptographic functions) can be preemptively excluded from sanitization (see next section).\n</p>\n<p>\nAside from uncovering security vulnerabilities, this stage is highly effective at uncovering code quality and stability bugs that could result in instability on user devices.\n</p>\n<p>\nOnce violations have been addressed and tests are no longer uncovering new violations, the next stage can begin.\n</p>\n<h2>Measuring and Reducing Overhead</h2>\n\n\n<p>\nOnce shallow violations have been addressed, benchmarks can be run and the overhead from the sanitizers (performance, code size, memory footprint) can be measured.\n</p>\n<p>\nMeasuring overhead must be done using production flags \u2013 namely <strong>\u201ctrapping mode\u201d</strong>, where violations cause execution to abort. The diagnostics runtime used in the first stage carries significant overhead and is not indicative of the actual performance sanitizer overhead.\n</p>\n<p>\nTrapping mode can be enabled using the following flags:\n</p>\n\n\n\n<pre class=\"prettyprint\">-fsanitize=signed-integer-overflow,unsigned-integer-overflow,bounds -fsanitize-trap=all</pre>\n\n\n<p>\nMost of the overhead is likely due to a small handful of \u201chot functions\u201d, for example those with tight long-running loops. Fine-grained per-function performance metrics (similar to what <a href=\"https://android.googlesource.com/platform/system/extras/+/master/simpleperf/doc/README.md\">Simpleperf</a> provides for Android), allows comparing metrics before and after sanitizers and provides the easiest means to identify hot functions. These functions can either be refactored or, after manual inspection to verify that they are safe, have sanitization disabled.\n</p>\n<p>\nSanitizers can be disabled either <a href=\"https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html#disabling-instrumentation-with-attribute-no-sanitize-undefined\">inline in the source</a> or through the use of <a href=\"https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html#suppressing-errors-in-recompiled-code-ignorelist\">ignorelists</a> and the -fsanitize-ignorelist flag.\n</p>\n<p>\nThe physical layer code, with its extremely tight performance margins and lower chance of exploitable vulnerabilities, may be a good candidate to disable sanitization wholesale if initial performance seems prohibitive.\n</p>\n<h2>Soaking in Pre-production</h2>\n\n\n<p>\nWith overhead minimized and shallow bugs resolved, the final stage is enabling the sanitizers in trapping mode to mitigate vulnerabilities.\n</p>\n<p>\nWe strongly recommend a long period of internal soak in pre-production with test populations to uncover any remaining violations not discovered in testing. The more thorough the test coverage and length of the soak period, the less risk there will be from undiscovered violations.\n</p>\n<p>\nAs above, the configuration for trapping mode is as follows:\n</p>\n\n\n\n<pre class=\"prettyprint\">-fsanitize=signed-integer-overflow,unsigned-integer-overflow,bounds -fsanitize-trap=all</pre>\n\n\n<p>\nHaving infrastructure in place to collect bug reports which result from any undiscovered violations can help minimize the risk they present.\n</p>\n<h1>Transitioning to Memory Safe Languages</h1>\n\n\n<p>\nThe benefits from deploying sanitizers in your existing code base are tangible, however ultimately they address only the lowest hanging fruit and will not result in a code base free of vulnerabilities. Other classes of memory safety vulnerabilities remain unaddressed by these sanitizers. A longer term solution is to begin transitioning <em>today</em> to memory-safe languages such as Rust.\n</p>\n<p>\n<a href=\"https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html\">Rust is ready for bare-metal environments</a> such as the baseband, and we are already using it in other bare-metal components in Android. There is no need to rewrite everything in Rust, as Rust provides a strong C FFI support and easily interfaces with existing C codebases. <a href=\"https://security.googleblog.com/2021/04/rust-in-android-platform.html#:~:text=But%20what%20about%20all%20that%20existing%20C%2B%2B%3F\">Just writing new code in Rust</a> can rapidly <a href=\"https://security.googleblog.com/2022/12/memory-safe-languages-in-android-13.html\">reduce the number of memory safety vulnerabilities</a>. Rewrites should be limited/prioritized only for the most critical components, such as complex parsers handling untrusted data.\n</p>\n<p>\nThe Android team has developed a <a href=\"https://google.github.io/comprehensive-rust/\">Rust training</a> meant to help experienced developers quickly ramp up Rust fundamentals. An entire day for <a href=\"https://google.github.io/comprehensive-rust/bare-metal.html\">bare-metal Rust</a> is included, and the course has been translated to a number of different languages.\n</p>\n<p>\nWhile the Rust compiler may not explicitly support your bare-metal target, because it is a front-end for LLVM, any target supported by LLVM can be supported in Rust through <a href=\"https://docs.rust-embedded.org/embedonomicon/custom-target.html\">custom target definitions</a>.\n</p>\n<h1>Raising the Bar</h1>\n\n\n<p>\nAs the high-level operating system becomes a more difficult target for attackers to successfully exploit, we expect that lower level components such as the baseband will attract more attention. By using modern toolchains and deploying exploit mitigation technologies, the bar for attacking the baseband can be raised as well. If you have any questions, let us know \u2013 we\u2019re here to help!\n</p>",
    "links": [
      {
        "href": "http://security.googleblog.com/feeds/2267894734490098363/comments/default",
        "rel": "replies",
        "title": "Post Comments",
        "type": "application/atom+xml"
      },
      {
        "href": "http://www.blogger.com/comment.g?blogID=1176949257541686127&postID=2267894734490098363&isPopup=true",
        "rel": "replies",
        "title": "0 Comments",
        "type": "text/html"
      },
      {
        "href": "http://www.blogger.com/feeds/1176949257541686127/posts/default/2267894734490098363",
        "rel": "edit",
        "type": "application/atom+xml"
      },
      {
        "href": "http://www.blogger.com/feeds/1176949257541686127/posts/default/2267894734490098363",
        "rel": "self",
        "type": "application/atom+xml"
      },
      {
        "href": "http://security.googleblog.com/2023/12/hardening-cellular-basebands-in-android.html",
        "rel": "alternate",
        "title": "Hardening cellular basebands in Android",
        "type": "text/html"
      }
    ],
    "authors": [
      {
        "name": "Edward Fernandez",
        "href": "http://www.blogger.com/profile/03784424747198152685",
        "email": "noreply@blogger.com"
      }
    ],
    "author_detail": {
      "name": "Edward Fernandez",
      "href": "http://www.blogger.com/profile/03784424747198152685",
      "email": "noreply@blogger.com"
    },
    "href": "http://www.blogger.com/profile/03784424747198152685",
    "author": "Edward Fernandez (noreply@blogger.com)",
    "gd_image": {
      "height": "16",
      "rel": "http://schemas.google.com/g/2005#thumbnail",
      "src": "https://img1.blogblog.com/img/b16-rounded.gif",
      "width": "16"
    },
    "thr_total": "0"
  },
  "Etsy": {
    "title": "Behind the Scenes - A Glimpse to Tax Calculations",
    "xmlUrl": "https://codeascraft.com/feed/",
    "htmlUrl": "https://codeascraft.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.etsy.com/codeascraft/rss",
      "value": "Behind the Scenes - A Glimpse to Tax Calculations"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.etsy.com/codeascraft/behind-the-scenes---a-glimpse-to-tax-calculations?utm_source=OpenGraph&utm_medium=PageTools&utm_campaign=Share"
      }
    ],
    "link": "https://www.etsy.com/codeascraft/behind-the-scenes---a-glimpse-to-tax-calculations?utm_source=OpenGraph&utm_medium=PageTools&utm_campaign=Share",
    "authors": [
      {
        "name": "Nancy Arnold"
      }
    ],
    "author": "Nancy Arnold",
    "author_detail": {
      "name": "Nancy Arnold"
    },
    "published": "Wed, 3 Jan 2024 11:12:58 -0500",
    "published_parsed": [
      2024,
      1,
      3,
      16,
      12,
      58,
      2,
      3,
      0
    ],
    "id": "https://www.etsy.com/codeascraft/behind-the-scenes---a-glimpse-to-tax-calculations?utm_source=OpenGraph&utm_medium=PageTools&utm_campaign=Share",
    "guidislink": false,
    "summary": "<p>In the past, sellers were responsible for managing and fulfilling their own tax obligations. \nHowever, more and more jurisdictions are now requiring marketplaces such as Etsy to collect the tax from buyers and remit the tax to the relevant authorities. Etsy now plays an active role in collecting tax from buyers and remitting it all over the world. In this post, I will walk you through our tax calculation infrastructure and how we adapted to the ongoing increase in traffic and business needs over the years.</p>\n<p><strong>The tax calculation workflow</strong></p>\n<p>We determine tax whenever a buyer adds an item to their Etsy shopping cart. The tax determination is based on buyer and seller location and product category, and a set of tax rules and mappings. To handle the details of these calculations we partner with Vertex, and issue a call to their <a href=\"https://www.vertexinc.com/\">tax engine</a> via the Quotation Request API to get the right amount to show in our buyer's cart. </p>\n<p>Vertex ensures accurate and efficient tax management and continuously updates the tax rules and rates for jurisdictions around the world. The two main API calls we use are Quotation Request and DistributeTaxRequest SOAP calls.</p>\n<p>When the buyer proceeds to payment, an order is created, and we call back to Vertex with a DistributeTaxRequest sending the order information and tax details. We sync information with Vertex through the order fulfillment lifecycle. To keep things up to date in case an order is canceled or a refund needs to be issued later on, we inform the details of the cancellation and refunds to the tax engine via DistributeTaxRequest. This ensures that when Vertex generates tax reports for us they will be based on a complete record of all the relevant transactions. \nEtsy collects the tax from the buyers and remits that tax to the taxing authority, when required. </p>\n<p><strong>Generate tax details for reporting and audit purpose</strong></p>\n<p>Vertex comes with a variety of report formats out of the box, and gives us tools to define our own. When Etsy calls the Distribute Tax API, Vertex saves the information we pass to it as raw metadata in its tax journal database. A daily cron job in Vertex then moves this data to the transaction detail table, populating it with tax info. When reports and audit data are generated, we download these reports and import to Etsy\u2019s bigdata and the workflow completes.</p>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/b7e136/5660475277/inv_fullxfull.5660475277_6aqobaes.jpg?version=0\" />\n</figure>\n<p><strong>Mapping the Etsy taxonomy to tax categories</strong></p>\n<p>Etsy maintains product categories to help our buyers find exactly the items they're looking for. </p>\n<p>To determine whether transactions are taxed or exempt it's not enough to know item prices and buyer locations: we have to map our product categories to Vertex's rule drivers. That was an effort involving not just engineering but also our tax and analytics teams, and with the wide range of Etsy taxonomy categories it was no small task.</p>\n<p><strong>Handling increased API traffic</strong></p>\n<p>Coping with the continuous increase in traffic and maintaining the best checkout experience without delays has been a challenge all the time. Out of the different upgrades we did, the most important ones were to switch to multiple instances for vertex calls and shadowing.</p>\n<p><strong>Multiple Instance upgrade</strong></p>\n<p>In our initial integration, we were using the same vertex instance for Quotation and Distribute calls. And the same instance was responsible for generating the reports. This report generation started to affect our checkout experience. </p>\n<p>Reports are generally used by our tax team and they run them on a regular basis. But on top of that, we also run daily reports to feed the data captured by Vertex back into our own system for analytics purposes.</p>\n<p>We solved this by routing the quotation calls to one instance and then distributing them to the other. This helped in maintaining a clear separation of functionalities, and avoided interference between the two processes. We had to align the configurations between the instances as well. \nSplitting up the quotation and distribution calls opened up the door to horizontal scaling, now we can add as many instances of each type and load balance the requests between instances. </p>\n<p>Eg: When a request type lists multiple instances, we load balance between the instances by using the cart_id for quotations and receipt_ids for distributes I.e. cart_id % quotation_instance_count</p>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/55e80d/5612390760/inv_fullxfull.5612390760_2x0ox160.jpg?version=0\" />\n</figure>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/54571d/5660478985/inv_fullxfull.5660478985_h59bbdge.jpg?version=0\" />\n</figure>\n<p><strong>Shadow logging</strong></p>\n<p>Shadow logging the requests helped us to simulate the stress on Vertex and monitor the checkout experience. We used this technique multiple times  in the past.</p>\n<p>Whenever we had situations like, for example, adding five hundred thousand more listings whose taxes would be passed through the Vertex engine, we were concerned that the increase in traffic might impact buyer experience. To ensure it wouldn't, we tested for a period of time by slowly ramping shadow requests to Vertex: \"Shadow requests\" are test requests that we send to Vertex from orders, but without applying the calculated tax details to buyers' carts. This will simulate the load on vertex and we can monitor the cart checkout experience. </p>\n<p>Once we have done shadowing and seen how well Vertex handled the increased traffic, we are confident that releasing the features ensures it would not have any performance implications.</p>\n<p><strong>Conclusion</strong></p>\n<p>Given the volume of increasing traffic and the data involved, we will have to keep improving our design to support those. We've also had to address analytics, reporting, configuration sync and many more in designing the system, but we'll leave that story for next time.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.etsy.com/codeascraft/rss",
      "value": "<p>In the past, sellers were responsible for managing and fulfilling their own tax obligations. \nHowever, more and more jurisdictions are now requiring marketplaces such as Etsy to collect the tax from buyers and remit the tax to the relevant authorities. Etsy now plays an active role in collecting tax from buyers and remitting it all over the world. In this post, I will walk you through our tax calculation infrastructure and how we adapted to the ongoing increase in traffic and business needs over the years.</p>\n<p><strong>The tax calculation workflow</strong></p>\n<p>We determine tax whenever a buyer adds an item to their Etsy shopping cart. The tax determination is based on buyer and seller location and product category, and a set of tax rules and mappings. To handle the details of these calculations we partner with Vertex, and issue a call to their <a href=\"https://www.vertexinc.com/\">tax engine</a> via the Quotation Request API to get the right amount to show in our buyer's cart. </p>\n<p>Vertex ensures accurate and efficient tax management and continuously updates the tax rules and rates for jurisdictions around the world. The two main API calls we use are Quotation Request and DistributeTaxRequest SOAP calls.</p>\n<p>When the buyer proceeds to payment, an order is created, and we call back to Vertex with a DistributeTaxRequest sending the order information and tax details. We sync information with Vertex through the order fulfillment lifecycle. To keep things up to date in case an order is canceled or a refund needs to be issued later on, we inform the details of the cancellation and refunds to the tax engine via DistributeTaxRequest. This ensures that when Vertex generates tax reports for us they will be based on a complete record of all the relevant transactions. \nEtsy collects the tax from the buyers and remits that tax to the taxing authority, when required. </p>\n<p><strong>Generate tax details for reporting and audit purpose</strong></p>\n<p>Vertex comes with a variety of report formats out of the box, and gives us tools to define our own. When Etsy calls the Distribute Tax API, Vertex saves the information we pass to it as raw metadata in its tax journal database. A daily cron job in Vertex then moves this data to the transaction detail table, populating it with tax info. When reports and audit data are generated, we download these reports and import to Etsy\u2019s bigdata and the workflow completes.</p>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/b7e136/5660475277/inv_fullxfull.5660475277_6aqobaes.jpg?version=0\" />\n</figure>\n<p><strong>Mapping the Etsy taxonomy to tax categories</strong></p>\n<p>Etsy maintains product categories to help our buyers find exactly the items they're looking for. </p>\n<p>To determine whether transactions are taxed or exempt it's not enough to know item prices and buyer locations: we have to map our product categories to Vertex's rule drivers. That was an effort involving not just engineering but also our tax and analytics teams, and with the wide range of Etsy taxonomy categories it was no small task.</p>\n<p><strong>Handling increased API traffic</strong></p>\n<p>Coping with the continuous increase in traffic and maintaining the best checkout experience without delays has been a challenge all the time. Out of the different upgrades we did, the most important ones were to switch to multiple instances for vertex calls and shadowing.</p>\n<p><strong>Multiple Instance upgrade</strong></p>\n<p>In our initial integration, we were using the same vertex instance for Quotation and Distribute calls. And the same instance was responsible for generating the reports. This report generation started to affect our checkout experience. </p>\n<p>Reports are generally used by our tax team and they run them on a regular basis. But on top of that, we also run daily reports to feed the data captured by Vertex back into our own system for analytics purposes.</p>\n<p>We solved this by routing the quotation calls to one instance and then distributing them to the other. This helped in maintaining a clear separation of functionalities, and avoided interference between the two processes. We had to align the configurations between the instances as well. \nSplitting up the quotation and distribution calls opened up the door to horizontal scaling, now we can add as many instances of each type and load balance the requests between instances. </p>\n<p>Eg: When a request type lists multiple instances, we load balance between the instances by using the cart_id for quotations and receipt_ids for distributes I.e. cart_id % quotation_instance_count</p>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/55e80d/5612390760/inv_fullxfull.5612390760_2x0ox160.jpg?version=0\" />\n</figure>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/54571d/5660478985/inv_fullxfull.5660478985_h59bbdge.jpg?version=0\" />\n</figure>\n<p><strong>Shadow logging</strong></p>\n<p>Shadow logging the requests helped us to simulate the stress on Vertex and monitor the checkout experience. We used this technique multiple times  in the past.</p>\n<p>Whenever we had situations like, for example, adding five hundred thousand more listings whose taxes would be passed through the Vertex engine, we were concerned that the increase in traffic might impact buyer experience. To ensure it wouldn't, we tested for a period of time by slowly ramping shadow requests to Vertex: \"Shadow requests\" are test requests that we send to Vertex from orders, but without applying the calculated tax details to buyers' carts. This will simulate the load on vertex and we can monitor the cart checkout experience. </p>\n<p>Once we have done shadowing and seen how well Vertex handled the increased traffic, we are confident that releasing the features ensures it would not have any performance implications.</p>\n<p><strong>Conclusion</strong></p>\n<p>Given the volume of increasing traffic and the data involved, we will have to keep improving our design to support those. We've also had to address analytics, reporting, configuration sync and many more in designing the system, but we'll leave that story for next time.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.etsy.com/codeascraft/rss",
        "value": "<p>In the past, sellers were responsible for managing and fulfilling their own tax obligations. \nHowever, more and more jurisdictions are now requiring marketplaces such as Etsy to collect the tax from buyers and remit the tax to the relevant authorities. Etsy now plays an active role in collecting tax from buyers and remitting it all over the world. In this post, I will walk you through our tax calculation infrastructure and how we adapted to the ongoing increase in traffic and business needs over the years.</p>\n<p><strong>The tax calculation workflow</strong></p>\n<p>We determine tax whenever a buyer adds an item to their Etsy shopping cart. The tax determination is based on buyer and seller location and product category, and a set of tax rules and mappings. To handle the details of these calculations we partner with Vertex, and issue a call to their <a href=\"https://www.vertexinc.com/\">tax engine</a> via the Quotation Request API to get the right amount to show in our buyer's cart. </p>\n<p>Vertex ensures accurate and efficient tax management and continuously updates the tax rules and rates for jurisdictions around the world. The two main API calls we use are Quotation Request and DistributeTaxRequest SOAP calls.</p>\n<p>When the buyer proceeds to payment, an order is created, and we call back to Vertex with a DistributeTaxRequest sending the order information and tax details. We sync information with Vertex through the order fulfillment lifecycle. To keep things up to date in case an order is canceled or a refund needs to be issued later on, we inform the details of the cancellation and refunds to the tax engine via DistributeTaxRequest. This ensures that when Vertex generates tax reports for us they will be based on a complete record of all the relevant transactions. \nEtsy collects the tax from the buyers and remits that tax to the taxing authority, when required. </p>\n<p><strong>Generate tax details for reporting and audit purpose</strong></p>\n<p>Vertex comes with a variety of report formats out of the box, and gives us tools to define our own. When Etsy calls the Distribute Tax API, Vertex saves the information we pass to it as raw metadata in its tax journal database. A daily cron job in Vertex then moves this data to the transaction detail table, populating it with tax info. When reports and audit data are generated, we download these reports and import to Etsy\u2019s bigdata and the workflow completes.</p>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/b7e136/5660475277/inv_fullxfull.5660475277_6aqobaes.jpg?version=0\" />\n</figure>\n<p><strong>Mapping the Etsy taxonomy to tax categories</strong></p>\n<p>Etsy maintains product categories to help our buyers find exactly the items they're looking for. </p>\n<p>To determine whether transactions are taxed or exempt it's not enough to know item prices and buyer locations: we have to map our product categories to Vertex's rule drivers. That was an effort involving not just engineering but also our tax and analytics teams, and with the wide range of Etsy taxonomy categories it was no small task.</p>\n<p><strong>Handling increased API traffic</strong></p>\n<p>Coping with the continuous increase in traffic and maintaining the best checkout experience without delays has been a challenge all the time. Out of the different upgrades we did, the most important ones were to switch to multiple instances for vertex calls and shadowing.</p>\n<p><strong>Multiple Instance upgrade</strong></p>\n<p>In our initial integration, we were using the same vertex instance for Quotation and Distribute calls. And the same instance was responsible for generating the reports. This report generation started to affect our checkout experience. </p>\n<p>Reports are generally used by our tax team and they run them on a regular basis. But on top of that, we also run daily reports to feed the data captured by Vertex back into our own system for analytics purposes.</p>\n<p>We solved this by routing the quotation calls to one instance and then distributing them to the other. This helped in maintaining a clear separation of functionalities, and avoided interference between the two processes. We had to align the configurations between the instances as well. \nSplitting up the quotation and distribution calls opened up the door to horizontal scaling, now we can add as many instances of each type and load balance the requests between instances. </p>\n<p>Eg: When a request type lists multiple instances, we load balance between the instances by using the cart_id for quotations and receipt_ids for distributes I.e. cart_id % quotation_instance_count</p>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/55e80d/5612390760/inv_fullxfull.5612390760_2x0ox160.jpg?version=0\" />\n</figure>\n<figure>\n<img alt=\"\" src=\"https://i.etsystatic.com/inv/54571d/5660478985/inv_fullxfull.5660478985_h59bbdge.jpg?version=0\" />\n</figure>\n<p><strong>Shadow logging</strong></p>\n<p>Shadow logging the requests helped us to simulate the stress on Vertex and monitor the checkout experience. We used this technique multiple times  in the past.</p>\n<p>Whenever we had situations like, for example, adding five hundred thousand more listings whose taxes would be passed through the Vertex engine, we were concerned that the increase in traffic might impact buyer experience. To ensure it wouldn't, we tested for a period of time by slowly ramping shadow requests to Vertex: \"Shadow requests\" are test requests that we send to Vertex from orders, but without applying the calculated tax details to buyers' carts. This will simulate the load on vertex and we can monitor the cart checkout experience. </p>\n<p>Once we have done shadowing and seen how well Vertex handled the increased traffic, we are confident that releasing the features ensures it would not have any performance implications.</p>\n<p><strong>Conclusion</strong></p>\n<p>Given the volume of increasing traffic and the data involved, we will have to keep improving our design to support those. We've also had to address analytics, reporting, configuration sync and many more in designing the system, but we'll leave that story for next time.</p>"
      }
    ]
  },
  "Yammer": {
    "title": "Seven Schools, Four Cities, and Three Countries Later",
    "xmlUrl": "https://medium.com/feed/yammer-engineering",
    "htmlUrl": "https://medium.com/yammer-engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/yammer-engineering",
      "value": "Seven Schools, Four Cities, and Three Countries Later"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/yammer-engineering/seven-schools-four-cities-and-three-countries-later-237fb94dc99e?source=rss----d77643e2fe1f---4"
      }
    ],
    "link": "https://medium.com/yammer-engineering/seven-schools-four-cities-and-three-countries-later-237fb94dc99e?source=rss----d77643e2fe1f---4",
    "id": "https://medium.com/p/237fb94dc99e",
    "guidislink": false,
    "tags": [
      {
        "term": "tech",
        "scheme": null,
        "label": null
      },
      {
        "term": "diversity",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Mannie Tagarira"
      }
    ],
    "author": "Mannie Tagarira",
    "author_detail": {
      "name": "Mannie Tagarira"
    },
    "published": "Wed, 15 Mar 2017 21:56:46 GMT",
    "published_parsed": [
      2017,
      3,
      15,
      21,
      56,
      46,
      2,
      74,
      0
    ],
    "updated": "2017-03-16T17:04:07.507Z",
    "updated_parsed": [
      2017,
      3,
      16,
      17,
      4,
      7,
      3,
      75,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/yammer-engineering",
        "value": "<h4>A Conversation About Diversity</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*8EcRTZcNWljqs5lKfvGgQA.jpeg\" /><figcaption><em>Let\u2019s examine what lies across country\u00a0borders.</em></figcaption></figure><p>Growing up, I wondered what lay across country borders. <em>What makes their country special compared to any other? Why is their food so different from ours?</em> I was always curious about what people from other nations were like, so I dreamed of visiting distant lands. My mother\u2019s stories, stories I vividly remember, of her travels to neighboring countries encouraged those dreams; I had so much hope that one day she\u2019d see the world. I\u2019ve held on to her stories, sometimes returning to them as if they were receipts for experiences that I too might\u00a0have.</p><p><strong>My Last Few Months of Schooling in\u00a0Zimbabwe</strong></p><p>I was in a class of kids that, for the most part, grew up in the same society. As I remember it, there was one Pakistani girl\u200a\u2014\u200aRaima. She hardly spoke to anyone, it seemed. She kept to herself. Whenever I\u2019d walk over to say \u2018hi\u2019 and make small talk (maybe flirt a little), she would clam up. \u2018Damn, this girl is shy\u2019, I\u2019d think after any attempt to befriend her. Now I can\u2019t help but wonder, \u2018Was it really shyness or maybe something else?\u2019</p><p>In 2004, I relocated to Manchester, England. This was a move that would ultimately change me. At the time, my young mind hadn\u2019t yet fathomed the significance of the transition: opportunity with responsibility, a gift and a\u00a0curse.</p><p><strong>Excited but Terribly\u00a0Confused</strong></p><p>The experience of being in a new country with unfamiliar customs and a different education system was exhilarating and baffling at the same time. I struggled to fit in and found myself in a tug-of-war between teachers who liked me because they saw my potential and teachers who felt that I was shown favoritism for being in \u2018the minority group\u2019. I can\u2019t explain why, but I just couldn\u2019t fit in, even with kids who had the same skin color as mine. I\u2019d always thought of myself as a friendly and sociable individual. <em>What was I doing wrong?</em> It didn\u2019t take too long for me to realize how Raima\u00a0felt.</p><p>In hindsight, it was neither a problem of nerves nor a matter of what we were possibly doing wrong. It was simpler than that. This was about our differences\u2015having different backgrounds and customs from one another. Humans are predisposed towards comfort. We seek out individuals who most resemble our own selves, looking for a resemblance that, at times, transcends physical appearance. As such, I found myself becoming really good friends with two fellas\u2015Aamir from Pakistan and Bashir from Somalia\u2015who shared passion and interests similar to mine. We bonded over the realities of being outcasts.</p><p><strong>One Year\u00a0Later</strong></p><p>I had to decide where I would complete my A-Levels. Aamir and I both made our decisions somewhat based on emotion, seeking out an environment that was most familiar. At the school I settled into, there were more people who shared my upbringing and looked more like me, and I found myself becoming good friends with a collective of talented and resourceful individuals who grew up in southern Africa. Over the next couple of years, we would geek out over music and dream of one day owning our own businesses in hopes of going back to Africa and improving the economy. You know, \u2018making it big\u2019, whatever that meant at the time. Even though these aspirations kept me connected to my new group of friends, I could never really imagine going \u2018home\u2019. <em>Would I be able to re-integrate into that society?</em> I had already started to change. I had gotten so used to attention; most of it wasn\u2019t a result of my achievements, but rather just being\u00a0myself.</p><p>By graduation day, I had effectively spent 5 of the preceding 7 years training for an industry that may not accept the various stereotypes I conformed to. I was a twenty-something-year-old black male with a love for basketball, hip hop and everything that came along with the two. Even my hair and dress sense reflected my pastimes\u2015something I had to change in order to fit in with the professional crowd.</p><p><strong>London, August of\u00a02011</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JBuiW4Pa-4E2vRJ0Ks26tw.jpeg\" /></figure><p>I joined an investment banking firm. Within the first few days around the office, I noticed a popular topic of discussion: <strong>diversity</strong>.</p><p><em>Why is this \u201cdiversity thing\u201d so important?</em> I quickly came to understand that the concept is intended to help people feel empowered through acknowledgement of their differences. Let me explain: Working with people of similar backgrounds allows for a certain level of confidence and comfort. <em>There\u2019s that \u2018comfort\u2019 word, again\u2026</em> At the least, I think we\u2019d all agree that communication is somewhat effortless if we speak the same language (both literally and metaphorically). Makes sense,\u00a0right?</p><p>Now 7 schools, 3 cities and 2 countries in, I was ready to take on the world, diverse or not. I felt like everything I had ever learned was in preparation for that moment, the moment my career officially began. You see, before I joined the firm, I had already met a lot of intelligent individuals, which were rather humbling experiences. Some of the most unassuming of characters I crossed paths with had ideas, really smart ones, that bordered insanity!</p><p>I had no misconceptions about my level of intelligence coming into this\u2026 or going into the corporate world, rather. Being part of that large corporation was just unnerving. I was indeed a small fish in a pond filled with other well-decorated fish. How does one even stand out? Heck, how did I even blend\u00a0in?</p><p><strong>A Bad Case of Imposter\u00a0Syndrome</strong></p><p>I managed to find myself on a team where everyone else was way above my pay grade, and I was so afraid that one day they would realize I was seriously underqualified for the role. I sat through a plethora of meetings, mostly silently. <em>I should say something smart, but the other team members are more experienced and smarter than I am. They\u2019ll just think I\u2019m being\u00a0silly.</em></p><p>Outside of my immediate team, I was surrounded by people of many different nationalities, and even though we were connected by profession, or everyday business tasks, I still didn\u2019t quite fit in. I underestimated how much my need to make real connections fueled my preoccupation with blending in. For a while, I forgot the reason diversity mattered. All of us, people from different walks of life, were sitting at the same table for the same reason. But at the time, my reasoning was still far removed from the\u00a0truth.</p><p><strong>One Fateful\u00a0Night</strong></p><p>I was out with some of the grads contemplating life in fintech. It must have been close to midnight after a few tequila-infused cocktails when the obvious hit me: Instead of focusing my energy on trying to be someone else, I should just be myself (stereotypes and all). I used to act differently depending on who I was around: my peers, my team, my friends and family. Of course, all of them appealed to different facets of me, but I shouldn\u2019t have been worried of their perceptions of \u2018the real me\u2019. Intrinsically, the real me is inquisitive, so now I channel my energy into asking insightful questions, the ones most people are too afraid to ask. One of my go-to questions is, \u2018What are you doing to make people who are different feel accepted?\u2019</p><p>My job in risk management was great but, like all good things, came to an end. I\u2019d spent much time straddling business and tech functions; I never quite felt like I was making the most of my software engineering degree. So I joined a publishing company that was working to digitize all of their print publications. I could officially spend more time coding and doing other software\u00a0stuff.</p><p>At the publishing company, my approach to solving problems was different from that of my colleagues. I interacted with other teams across the company in a way none of the other engineers on the team did. I didn\u2019t take everything at face value. I felt responsible for getting to the root cause of most things. I found myself working with customer-facing teams more each day. Working there felt like d\u00e9j\u00e0 vu. Again, I was walking the business-tech divide; screw you, life, and your\u00a0sarcasm.</p><p><strong>Country #3</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UE6mPBCnlgLjc6Y9aEEXdQ.jpeg\" /><figcaption>I had hope that America, the land of opportunity, would change my\u00a0fortune.</figcaption></figure><p>A few years and some jobs later, I find myself in San Francisco. Being a software engineer of African descent is rather uncommon in Europe. I had hope that America, the land of opportunity, would change my fortune. Almost everyone in the Bay Area is a transplant\u2015just like everyone in London! So the diversity here must be awesome, right? Not entirely\u2026</p><p>Don\u2019t get me wrong. San Francisco houses many immigrants. The variety of food is second to none, and art is everywhere! Thanks to the city\u2019s microclimates, there are so many outdoorsy things to do. Then there\u2019s theatre, great nightlife, startups, music.</p><p>But that\u2019s not all there is to being diverse. The city doesn\u2019t have a variety of industries to sustain its residents. Here you\u2019ll find technology and finance, mostly technology. The influx of technical opportunities has left the city less socially diverse; long-time residents are being forced out of the city, which means it houses only those who can afford to\u00a0stay.</p><p>I used to spend so much effort trying to fit in that now I don\u2019t care\u2026 not nearly as much. At tech conferences, I\u2019m \u2018the black guy\u2019. At work socials, I\u2019m \u2018the African\u2019. At socials with non-techies, I apparently \u2018don\u2019t really give a \ud83d\ude4a\u2019, and at socials with other techies, I \u2018have no ambition\u2019 because I refuse to only talk about technology. I\u2019m not saying that I\u2019m entirely indifferent; I just recognize the impossibility of blending\u00a0in.</p><blockquote>\u2018What is it about who I am that makes me unforgettable? What is it about what I\u2019ve done that makes it so incredible?\u2019\u200a\u2014\u200aDMX</blockquote><p>I heard this line for the first time over a decade ago in DMX\u2019s song called \u2018Fame\u2019. By the time I graduated from college, I had gone through so many interviews and networking events that the most frequently asked question was, \u2018Your English is really good. Did you learn English in Zimbabwe?\u2019 They probably didn\u2019t think much about it, like the person who complimented my way of asking questions\u2026 right before they said, \u2018You sound like you\u2019re rapping\u2019.</p><p>I\u2019m sure none of them meant any harm, but I fear that many people in tech make it difficult for those who aren\u2019t \u2018a cultural fit\u2019 to fit in. So we\u2019d gladly train our teams on how to interact with tools but not with fellow coworkers? That\u2019s absurd! People have feelings, but tools don\u2019t. People behave differently given the same input, tools don\u2019t. People speak different languages, have different beliefs and reason differently; again, tools\u00a0don\u2019t.</p><p>Technology is at the forefront of a changing world; I feel that all technologists have great responsibility to each other and society. It\u2019s the gift and the\u00a0curse.</p><p><strong>A Different Definition</strong></p><p>I wouldn\u2019t dare dismiss the explanation of workplace diversity that favors the idea of leveraging various experiences and viewpoints of different individuals. Even I, little old me who was silent during all those meetings, made substantial contributions to the companies I worked\u00a0for.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XNawdLd6sTyTm8IAxTNdCg.jpeg\" /><figcaption>It\u2019s about appreciating each other as human\u00a0beings.</figcaption></figure><p>But diversity is really about appreciation. It\u2019s about appreciating each other as human\u00a0beings.</p><p>My parents were providers for a working-class household, so my inquisitive nature was somewhat to my detriment: My folks stopped buying me toys after my 5th birthday because I\u2019d break them apart trying to understand how they worked. Now I know what DMX was talking about. You know, being unforgettable and doing something incredible is born out of your own flavor of diversity, so keep\u00a0it.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=237fb94dc99e\" width=\"1\" /><hr /><p><a href=\"https://medium.com/yammer-engineering/seven-schools-four-cities-and-three-countries-later-237fb94dc99e\">Seven Schools, Four Cities, and Three Countries Later</a> was originally published in <a href=\"https://medium.com/yammer-engineering\">Yammer Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h4>A Conversation About Diversity</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*8EcRTZcNWljqs5lKfvGgQA.jpeg\" /><figcaption><em>Let\u2019s examine what lies across country\u00a0borders.</em></figcaption></figure><p>Growing up, I wondered what lay across country borders. <em>What makes their country special compared to any other? Why is their food so different from ours?</em> I was always curious about what people from other nations were like, so I dreamed of visiting distant lands. My mother\u2019s stories, stories I vividly remember, of her travels to neighboring countries encouraged those dreams; I had so much hope that one day she\u2019d see the world. I\u2019ve held on to her stories, sometimes returning to them as if they were receipts for experiences that I too might\u00a0have.</p><p><strong>My Last Few Months of Schooling in\u00a0Zimbabwe</strong></p><p>I was in a class of kids that, for the most part, grew up in the same society. As I remember it, there was one Pakistani girl\u200a\u2014\u200aRaima. She hardly spoke to anyone, it seemed. She kept to herself. Whenever I\u2019d walk over to say \u2018hi\u2019 and make small talk (maybe flirt a little), she would clam up. \u2018Damn, this girl is shy\u2019, I\u2019d think after any attempt to befriend her. Now I can\u2019t help but wonder, \u2018Was it really shyness or maybe something else?\u2019</p><p>In 2004, I relocated to Manchester, England. This was a move that would ultimately change me. At the time, my young mind hadn\u2019t yet fathomed the significance of the transition: opportunity with responsibility, a gift and a\u00a0curse.</p><p><strong>Excited but Terribly\u00a0Confused</strong></p><p>The experience of being in a new country with unfamiliar customs and a different education system was exhilarating and baffling at the same time. I struggled to fit in and found myself in a tug-of-war between teachers who liked me because they saw my potential and teachers who felt that I was shown favoritism for being in \u2018the minority group\u2019. I can\u2019t explain why, but I just couldn\u2019t fit in, even with kids who had the same skin color as mine. I\u2019d always thought of myself as a friendly and sociable individual. <em>What was I doing wrong?</em> It didn\u2019t take too long for me to realize how Raima\u00a0felt.</p><p>In hindsight, it was neither a problem of nerves nor a matter of what we were possibly doing wrong. It was simpler than that. This was about our differences\u2015having different backgrounds and customs from one another. Humans are predisposed towards comfort. We seek out individuals who most resemble our own selves, looking for a resemblance that, at times, transcends physical appearance. As such, I found myself becoming really good friends with two fellas\u2015Aamir from Pakistan and Bashir from Somalia\u2015who shared passion and interests similar to mine. We bonded over the realities of being outcasts.</p><p><strong>One Year\u00a0Later</strong></p><p>I had to decide where I would complete my A-Levels. Aamir and I both made our decisions somewhat based on emotion, seeking out an environment that was most familiar. At the school I settled into, there were more people who shared my upbringing and looked more like me, and I found myself becoming good friends with a collective of talented and resourceful individuals who grew up in southern Africa. Over the next couple of years, we would geek out over music and dream of one day owning our own businesses in hopes of going back to Africa and improving the economy. You know, \u2018making it big\u2019, whatever that meant at the time. Even though these aspirations kept me connected to my new group of friends, I could never really imagine going \u2018home\u2019. <em>Would I be able to re-integrate into that society?</em> I had already started to change. I had gotten so used to attention; most of it wasn\u2019t a result of my achievements, but rather just being\u00a0myself.</p><p>By graduation day, I had effectively spent 5 of the preceding 7 years training for an industry that may not accept the various stereotypes I conformed to. I was a twenty-something-year-old black male with a love for basketball, hip hop and everything that came along with the two. Even my hair and dress sense reflected my pastimes\u2015something I had to change in order to fit in with the professional crowd.</p><p><strong>London, August of\u00a02011</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JBuiW4Pa-4E2vRJ0Ks26tw.jpeg\" /></figure><p>I joined an investment banking firm. Within the first few days around the office, I noticed a popular topic of discussion: <strong>diversity</strong>.</p><p><em>Why is this \u201cdiversity thing\u201d so important?</em> I quickly came to understand that the concept is intended to help people feel empowered through acknowledgement of their differences. Let me explain: Working with people of similar backgrounds allows for a certain level of confidence and comfort. <em>There\u2019s that \u2018comfort\u2019 word, again\u2026</em> At the least, I think we\u2019d all agree that communication is somewhat effortless if we speak the same language (both literally and metaphorically). Makes sense,\u00a0right?</p><p>Now 7 schools, 3 cities and 2 countries in, I was ready to take on the world, diverse or not. I felt like everything I had ever learned was in preparation for that moment, the moment my career officially began. You see, before I joined the firm, I had already met a lot of intelligent individuals, which were rather humbling experiences. Some of the most unassuming of characters I crossed paths with had ideas, really smart ones, that bordered insanity!</p><p>I had no misconceptions about my level of intelligence coming into this\u2026 or going into the corporate world, rather. Being part of that large corporation was just unnerving. I was indeed a small fish in a pond filled with other well-decorated fish. How does one even stand out? Heck, how did I even blend\u00a0in?</p><p><strong>A Bad Case of Imposter\u00a0Syndrome</strong></p><p>I managed to find myself on a team where everyone else was way above my pay grade, and I was so afraid that one day they would realize I was seriously underqualified for the role. I sat through a plethora of meetings, mostly silently. <em>I should say something smart, but the other team members are more experienced and smarter than I am. They\u2019ll just think I\u2019m being\u00a0silly.</em></p><p>Outside of my immediate team, I was surrounded by people of many different nationalities, and even though we were connected by profession, or everyday business tasks, I still didn\u2019t quite fit in. I underestimated how much my need to make real connections fueled my preoccupation with blending in. For a while, I forgot the reason diversity mattered. All of us, people from different walks of life, were sitting at the same table for the same reason. But at the time, my reasoning was still far removed from the\u00a0truth.</p><p><strong>One Fateful\u00a0Night</strong></p><p>I was out with some of the grads contemplating life in fintech. It must have been close to midnight after a few tequila-infused cocktails when the obvious hit me: Instead of focusing my energy on trying to be someone else, I should just be myself (stereotypes and all). I used to act differently depending on who I was around: my peers, my team, my friends and family. Of course, all of them appealed to different facets of me, but I shouldn\u2019t have been worried of their perceptions of \u2018the real me\u2019. Intrinsically, the real me is inquisitive, so now I channel my energy into asking insightful questions, the ones most people are too afraid to ask. One of my go-to questions is, \u2018What are you doing to make people who are different feel accepted?\u2019</p><p>My job in risk management was great but, like all good things, came to an end. I\u2019d spent much time straddling business and tech functions; I never quite felt like I was making the most of my software engineering degree. So I joined a publishing company that was working to digitize all of their print publications. I could officially spend more time coding and doing other software\u00a0stuff.</p><p>At the publishing company, my approach to solving problems was different from that of my colleagues. I interacted with other teams across the company in a way none of the other engineers on the team did. I didn\u2019t take everything at face value. I felt responsible for getting to the root cause of most things. I found myself working with customer-facing teams more each day. Working there felt like d\u00e9j\u00e0 vu. Again, I was walking the business-tech divide; screw you, life, and your\u00a0sarcasm.</p><p><strong>Country #3</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UE6mPBCnlgLjc6Y9aEEXdQ.jpeg\" /><figcaption>I had hope that America, the land of opportunity, would change my\u00a0fortune.</figcaption></figure><p>A few years and some jobs later, I find myself in San Francisco. Being a software engineer of African descent is rather uncommon in Europe. I had hope that America, the land of opportunity, would change my fortune. Almost everyone in the Bay Area is a transplant\u2015just like everyone in London! So the diversity here must be awesome, right? Not entirely\u2026</p><p>Don\u2019t get me wrong. San Francisco houses many immigrants. The variety of food is second to none, and art is everywhere! Thanks to the city\u2019s microclimates, there are so many outdoorsy things to do. Then there\u2019s theatre, great nightlife, startups, music.</p><p>But that\u2019s not all there is to being diverse. The city doesn\u2019t have a variety of industries to sustain its residents. Here you\u2019ll find technology and finance, mostly technology. The influx of technical opportunities has left the city less socially diverse; long-time residents are being forced out of the city, which means it houses only those who can afford to\u00a0stay.</p><p>I used to spend so much effort trying to fit in that now I don\u2019t care\u2026 not nearly as much. At tech conferences, I\u2019m \u2018the black guy\u2019. At work socials, I\u2019m \u2018the African\u2019. At socials with non-techies, I apparently \u2018don\u2019t really give a \ud83d\ude4a\u2019, and at socials with other techies, I \u2018have no ambition\u2019 because I refuse to only talk about technology. I\u2019m not saying that I\u2019m entirely indifferent; I just recognize the impossibility of blending\u00a0in.</p><blockquote>\u2018What is it about who I am that makes me unforgettable? What is it about what I\u2019ve done that makes it so incredible?\u2019\u200a\u2014\u200aDMX</blockquote><p>I heard this line for the first time over a decade ago in DMX\u2019s song called \u2018Fame\u2019. By the time I graduated from college, I had gone through so many interviews and networking events that the most frequently asked question was, \u2018Your English is really good. Did you learn English in Zimbabwe?\u2019 They probably didn\u2019t think much about it, like the person who complimented my way of asking questions\u2026 right before they said, \u2018You sound like you\u2019re rapping\u2019.</p><p>I\u2019m sure none of them meant any harm, but I fear that many people in tech make it difficult for those who aren\u2019t \u2018a cultural fit\u2019 to fit in. So we\u2019d gladly train our teams on how to interact with tools but not with fellow coworkers? That\u2019s absurd! People have feelings, but tools don\u2019t. People behave differently given the same input, tools don\u2019t. People speak different languages, have different beliefs and reason differently; again, tools\u00a0don\u2019t.</p><p>Technology is at the forefront of a changing world; I feel that all technologists have great responsibility to each other and society. It\u2019s the gift and the\u00a0curse.</p><p><strong>A Different Definition</strong></p><p>I wouldn\u2019t dare dismiss the explanation of workplace diversity that favors the idea of leveraging various experiences and viewpoints of different individuals. Even I, little old me who was silent during all those meetings, made substantial contributions to the companies I worked\u00a0for.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XNawdLd6sTyTm8IAxTNdCg.jpeg\" /><figcaption>It\u2019s about appreciating each other as human\u00a0beings.</figcaption></figure><p>But diversity is really about appreciation. It\u2019s about appreciating each other as human\u00a0beings.</p><p>My parents were providers for a working-class household, so my inquisitive nature was somewhat to my detriment: My folks stopped buying me toys after my 5th birthday because I\u2019d break them apart trying to understand how they worked. Now I know what DMX was talking about. You know, being unforgettable and doing something incredible is born out of your own flavor of diversity, so keep\u00a0it.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=237fb94dc99e\" width=\"1\" /><hr /><p><a href=\"https://medium.com/yammer-engineering/seven-schools-four-cities-and-three-countries-later-237fb94dc99e\">Seven Schools, Four Cities, and Three Countries Later</a> was originally published in <a href=\"https://medium.com/yammer-engineering\">Yammer Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Stackshare": {
    "title": "Optimizing Pinterest\u2019s Data Ingestion Stack: Findings and Learnings",
    "xmlUrl": "https://stackshare.io/featured-posts.atom",
    "htmlUrl": "https://stackshare.io/feed",
    "id": "tag:stackshare.io,2005:Stack/1055123",
    "guidislink": true,
    "link": "https://stackshare.io/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings",
    "published": "2022-06-29T04:48:20Z",
    "published_parsed": [
      2022,
      6,
      29,
      4,
      48,
      20,
      2,
      180,
      0
    ],
    "updated": "2023-10-24T10:51:32Z",
    "updated_parsed": [
      2023,
      10,
      24,
      10,
      51,
      32,
      1,
      297,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://stackshare.io/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings"
      },
      {
        "href": "https://stackshare.io/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "title_detail": {
      "type": "text/plain",
      "language": "en-US",
      "base": "https://stackshare.io/featured-posts.atom",
      "value": "Optimizing Pinterest\u2019s Data Ingestion Stack: Findings and Learnings"
    },
    "content": [
      {
        "type": "text/html",
        "language": "en-US",
        "base": "https://stackshare.io/featured-posts.atom",
        "value": "<p><strong><em>By Ping-Min Lin | Software Engineer, Logging Platform</em></strong></p>\n\n<hr />\n\n<p>At <a href=\"https://stackshare.io/companies/pinterest\">Pinterest</a>, the Logging Platform team maintains the backbone of data ingestion infrastructure that ingests terabytes of data per day. When building the services powering these pipelines, it is extremely important that we build efficient systems considering how widespread and deep in the stack the systems are. Along our journey of continuous improvement, we\u2019ve figured out basic but useful patterns and learnings that could be applied in general \u2014 and hopefully for you as well.</p>\n\n<h1><strong>MemQ: Achieving memory-efficient batch data delivery using Netty</strong></h1>\n\n<p><a href=\"https://stackshare.io/pinterest/memq-an-efficient-scalable-cloud-native-pubsub-system\">MemQ</a> is the next-gen data ingestion platform built in-house and recently open-sourced by the Logging Platform team. When designing the service, we tried hard to maximize the efficiency of our resources, specifically, we focused on reducing GC by using off-heap memory. <a href=\"https://stackshare.io/netty\">Netty</a> was chosen as our low-level networking framework due to its great balance between flexibility, performance, and sophisticated out-of-the-box features. For example, we used ByteBuf heavily throughout the project. ByteBufs are the building blocks of data within Netty. They are similar to <a href=\"https://stackshare.io/java\">Java</a> NIO ByteBuffers, but allow the developers much more control of the lifecycle of the objects by providing a \u201csmart pointer\u201d approach for customized memory management using manual <a href=\"https://netty.io/wiki/reference-counted-objects.html\">reference counting</a>. By using ByteBufs, we managed to transport messages with a single copy of data by passing off-heap network buffer pointers, further reducing cycles used on garbage collection.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-000.png\" title=\"image_tooltip\" /></p>\n\n<p>The typical journey of a message in the MemQ broker: Each message received from the network will be reconstructed via a length-encoded protocol that will be allocated into a ByteBuf that is off of the JVM heap (direct memory in Netty terms), and will be the only existing copy of the payload throughout the whole pipeline. This ByteBuf reference will be passed into the topic processor and put into a Batch along with other messages that are also waiting to be uploaded to the storage destination. Once the upload constraints are met, either due to the time threshold or the size threshold, the Batch will be dispatched. In the case of uploading to a remote object store like <a href=\"https://stackshare.io/amazon-s3\">S3</a>, the whole batch of messages will be kept in a CompositeByteBuf (which is a virtual wrapper ByteBuf consisting of multiple ByteBufs) and uploaded to the destination using the netty-reactor library, allowing us to create no additional copies of data within the processing path. By building on top of ByteBufs and other Netty constructs, we were able to iterate rapidly without sacrificing performance and avoid reinventing the wheel.</p>\n\n<h1><strong>Singer: Leveraging asynchronous processing to reduce thread overheads</strong></h1>\n\n<p><a href=\"https://medium.com/pinterest-engineering/open-sourcing-singer-pinterests-performant-and-reliable-logging-agent-610fecf35566\">Singer</a> has been around at Pinterest for a long time, reliably delivering messages to PubSub backends. With more and more use cases onboarded to Singer, we\u2019ve started to hit bottlenecks on memory usage that led to frequent OOM issues and incidents. Singer has memory and CPU resources constrained on nearly all fleets at Pinterest to avoid impact on the host service e.g. our API serving layer. After inspecting the code and leveraging debugging tools such as VisualVM, Native Memory Tracking (NMT), and pmap, we noticed various potential improvements to be done, most notably reducing the number of threads. After performing NMT result analysis we noticed the number of threads and the memory used by the stack as a result of these threads (allocated due to the Singer executor and producer thread pools).</p>\n\n<p>Taking a deeper look into the source of these threads, the majority of these threads come from the thread pools for each <a href=\"https://stackshare.io/kafka\">Kafka</a> cluster Singer publishes to. The threads in these thread pools are used to wait for Kafka to complete writing messages to a partition and then report the status of the writes. While the threads do the job, each thread in the JVM (by <a href=\"https://docs.oracle.com/cd/E13150_01/jrockit_jvm/jrockit/geninfo/diagnos/thread_basics.html#wp1094805\">default</a>) will allocate 1MB of memory used for the thread\u2019s stack.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-001.png\" title=\"image_tooltip\" /></p>\n\n<p>A Singer NMT report showing the different memory regions a JVM process allocates. The <em>Thread</em> entry represents the thread stack. <em>Arena</em> contains the off-heap/direct memory portion managed outside of the JVM heap.</p>\n\n<p>Even with lazy allocation of the stack memory on the underlying operating systems until the thread is actually used, this still quickly adds up to hundreds of MBs of the process\u2019 memory. When there are a lot of log streams publishing to multiple partitions on different clusters, the memory used by thread stacks can be easily comparable to the 800MB default heap size of Singer and eats into the resources of the application.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-002.png\" title=\"image_tooltip\" /></p>\n\n<p>Each submission of KafkaWriteTask will occupy a thread. Full code can be found <a href=\"https://github.com/kabochya/singer/blob/b45051c/singer/src/main/java/com/pinterest/singer/writer/kafka/CommittableKafkaWriter.java#L192\">here</a></p>\n\n<p>By closely examining the usage of these threads, it quickly becomes clear that most of these threads are doing non-blocking operations such as updating metrics and are perfectly suitable for asynchronous processing using <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html\">CompletableFutures</a> provided starting in <a href=\"https://stackshare.io/java\">Java 8</a>. The CompletableFuture allows us to resolve the blocking calls by chaining stages asynchronously, thus replacing the usage of these threads that had to wait until the results to come back from Kafka. By utilizing the callback in the <em>KafkaProducer.send(record, callback)</em> method, we rely on the Kafka producer\u2019s network client to be completely in control of the multiplexing of networking.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-003.png\" title=\"image_tooltip\" /></p>\n\n<p>A brief example of the result code after using CompletableFutures. Full code can be found <a href=\"https://github.com/pinterest/singer/blob/5cc504da01c4c2cd747c8e0bb6a56b94571c8a60/singer/src/main/java/com/pinterest/singer/writer/kafka/CommittableKafkaWriter.java#L213\">here</a></p>\n\n<p>Once we convert the original logic into several chained non-blocking stages, it becomes obvious to use a single common thread pool to handle them regardless of the logstream, so we use the <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html#commonPool--\">common ForkJoinPool</a> that is already at our disposal from JVM. This dramatically reduces the thread usage for Singer, from a couple of hundred threads to virtually no additional threads. This improvement demonstrates the power of asynchronous processing and how network-bound applications can benefit from it.</p>\n\n<h1><strong>Kafka and Singer: Balancing performance and efficiency with controllable variance</strong></h1>\n\n<p><a href=\"https://www.confluent.io/blog/running-kafka-at-scale-at-pinterest/\">Operating our Kafka clusters</a> has always been a delicate balance between performance, fault tolerance, and efficiency. Our logging agent Singer, at the front line of publishing messages to Kafka, is a crucial component that plays a heavy role in these factors, especially in routing the traffic by deciding which partitions we deliver data to for a topic.</p>\n\n<h2><strong>The Default Partitioner: Evenly Distributed Traffic</strong></h2>\n\n<p>In Singer, logs from a machine would be picked up and routed to the corresponding topic it belongs to and published to that topic in Kafka. In the early days, Singer would publish uniformly to all the partitions that topic has in a round-robin fashion using our default partitioner. For example, if there were 3000 messages on a particular host that needed to be published to a 30 partition topic, each partition would roughly receive 100 messages. This worked pretty well for most of the use cases and has a nice benefit where all partitions receive the same amount of messages, which is great for the consumers of these topics since the workload is evenly distributed amongst them.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-004.png\" title=\"image_tooltip\" /></p>\n\n<p>DefaultPartitioner: Producers and Partitions are fully connected</p>\n\n<h2><strong>The Single Partition Partitioner: In Favor of the Law of Large Numbers</strong></h2>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-005.png\" title=\"image_tooltip\" /></p>\n\n<p>SinglePartitionPartitioner: Ideal scenario where connections are evenly distributed</p>\n\n<p>As Pinterest grew, we had fleets expanding to thousands of hosts, and this evenly-distributed approach started to cause some issues to our Kafka brokers: high connections counts and large amounts of produce requests started to elevate the brokers\u2019 CPU usage, and spreading out the messages means that the batch sizes are smaller for each partition, or lower efficiency of the compression, resulting in higher aggregated network traffic. To tackle this, we implemented a new partitioner: the SinglePartitionPartitioner. This partitioner solves the issue by forcing Singer to only write to one random partition per topic per host, reducing the fanout from all brokers to a single broker. This partition remains the same throughout the producer\u2019s lifetime until Singer restarts.</p>\n\n<p>For pipelines that had a large producer fleet and relatively uniform message rates across hosts, this was extremely effective: The law of large numbers worked in our favor, and statistically, if the number of producers is significantly larger than partitions, each partition will still receive a similar amount of traffic. Connection count went down from <strong>(number of brokers serving the topic)</strong> times <strong>(number of producers)</strong> to only <strong>(number of producers)</strong>, which could be up to a hundred times less for larger topics. Meanwhile, batching up all messages per producer to a single partition improved compression ratios by at least 10% in most use cases.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-006.png\" title=\"image_tooltip\" /></p>\n\n<p>SinglePartitionPartitioner: Skewed scenario where there are too few producers vs. partitions</p>\n\n<h2><strong>The Fixed Partitions Partitioner: Configurable variance for adjusting trade-offs</strong></h2>\n\n<p>Despite coming up with this new solution, there were still some pipelines that lie in the middle ground where both solutions are subpar, such as when the number of producers is not large enough to outnumber the number of partitions. In this case, the SinglePartitionPartitioner would introduce significant skew between partitions: some partitions will have multiple producers writing to them, and some are assigned very few or even no producers. This skew could cause unbalanced workloads for the downstream consumers, and also increases the burden for our team to manage the cluster, especially when storage is tight. We thus recently introduced a new partitioner that can be used on these cases, and even cover the original use cases: the FixedPartitionsPartitioner, which basically allows us to not only publish to one fixed partition like the SinglePartitionPartitioner, but randomly across a fixed number of partitions.</p>\n\n<p>This approach is somewhat similar to the concept of <a href=\"https://en.wikipedia.org/wiki/Consistent_hashing#Reduction_variance\">virtual nodes</a> in consistent hashing, where we artificially create more \u201ceffective producers\u201d to achieve a more continuous distribution. Since the number of partitions for each host can be configured, we can tune it to the sweet spot where the efficiency and performance are both at desired levels. This partitioner could also help with \u201chot producers\u201d by spreading traffic out while still maintaining a reasonable connection count. Although a simple concept, it turns out that having the ability to configure the degree of variance could be a powerful tool to manage trade-offs.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-007.png\" title=\"image_tooltip\" /></p>\n\n<p>FixedPartitionsPartitioner: Less skew while still keeping connection count lower than the default</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-008.png\" title=\"image_tooltip\" /></p>\n\n<p>Relative compression ratio and request rate skew with different numbers of fixed partitions on a 120 partition topic on 30 brokers</p>\n\n<h1><strong>Conclusion and Acknowledgements</strong></h1>\n\n<p>These learnings are just a few examples of improvements the Logging Platform team has been making. Despite their seemingly different nature, the ultimate goal of all these improvements was to achieve better results for our team and our customers. We hope that these findings are inspiring and could spark a few ideas for you.</p>\n\n<p>None of the content in this article could have been delivered without the in-depth discussions and candid feedback from Ambud Sharma, Eric Lopez, Henry Cai, Jeff Xiang, and Vahid Hashemian on the Logging Platform team. We also deeply appreciate the great support from external teams that provided support and input on the various improvements we\u2019ve been working on. As we strive for continuous improvement within our architecture, we hope we will be able to share more interesting findings in our pursuit of perfecting our system.</p>"
      }
    ],
    "summary": "<p><strong><em>By Ping-Min Lin | Software Engineer, Logging Platform</em></strong></p>\n\n<hr />\n\n<p>At <a href=\"https://stackshare.io/companies/pinterest\">Pinterest</a>, the Logging Platform team maintains the backbone of data ingestion infrastructure that ingests terabytes of data per day. When building the services powering these pipelines, it is extremely important that we build efficient systems considering how widespread and deep in the stack the systems are. Along our journey of continuous improvement, we\u2019ve figured out basic but useful patterns and learnings that could be applied in general \u2014 and hopefully for you as well.</p>\n\n<h1><strong>MemQ: Achieving memory-efficient batch data delivery using Netty</strong></h1>\n\n<p><a href=\"https://stackshare.io/pinterest/memq-an-efficient-scalable-cloud-native-pubsub-system\">MemQ</a> is the next-gen data ingestion platform built in-house and recently open-sourced by the Logging Platform team. When designing the service, we tried hard to maximize the efficiency of our resources, specifically, we focused on reducing GC by using off-heap memory. <a href=\"https://stackshare.io/netty\">Netty</a> was chosen as our low-level networking framework due to its great balance between flexibility, performance, and sophisticated out-of-the-box features. For example, we used ByteBuf heavily throughout the project. ByteBufs are the building blocks of data within Netty. They are similar to <a href=\"https://stackshare.io/java\">Java</a> NIO ByteBuffers, but allow the developers much more control of the lifecycle of the objects by providing a \u201csmart pointer\u201d approach for customized memory management using manual <a href=\"https://netty.io/wiki/reference-counted-objects.html\">reference counting</a>. By using ByteBufs, we managed to transport messages with a single copy of data by passing off-heap network buffer pointers, further reducing cycles used on garbage collection.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-000.png\" title=\"image_tooltip\" /></p>\n\n<p>The typical journey of a message in the MemQ broker: Each message received from the network will be reconstructed via a length-encoded protocol that will be allocated into a ByteBuf that is off of the JVM heap (direct memory in Netty terms), and will be the only existing copy of the payload throughout the whole pipeline. This ByteBuf reference will be passed into the topic processor and put into a Batch along with other messages that are also waiting to be uploaded to the storage destination. Once the upload constraints are met, either due to the time threshold or the size threshold, the Batch will be dispatched. In the case of uploading to a remote object store like <a href=\"https://stackshare.io/amazon-s3\">S3</a>, the whole batch of messages will be kept in a CompositeByteBuf (which is a virtual wrapper ByteBuf consisting of multiple ByteBufs) and uploaded to the destination using the netty-reactor library, allowing us to create no additional copies of data within the processing path. By building on top of ByteBufs and other Netty constructs, we were able to iterate rapidly without sacrificing performance and avoid reinventing the wheel.</p>\n\n<h1><strong>Singer: Leveraging asynchronous processing to reduce thread overheads</strong></h1>\n\n<p><a href=\"https://medium.com/pinterest-engineering/open-sourcing-singer-pinterests-performant-and-reliable-logging-agent-610fecf35566\">Singer</a> has been around at Pinterest for a long time, reliably delivering messages to PubSub backends. With more and more use cases onboarded to Singer, we\u2019ve started to hit bottlenecks on memory usage that led to frequent OOM issues and incidents. Singer has memory and CPU resources constrained on nearly all fleets at Pinterest to avoid impact on the host service e.g. our API serving layer. After inspecting the code and leveraging debugging tools such as VisualVM, Native Memory Tracking (NMT), and pmap, we noticed various potential improvements to be done, most notably reducing the number of threads. After performing NMT result analysis we noticed the number of threads and the memory used by the stack as a result of these threads (allocated due to the Singer executor and producer thread pools).</p>\n\n<p>Taking a deeper look into the source of these threads, the majority of these threads come from the thread pools for each <a href=\"https://stackshare.io/kafka\">Kafka</a> cluster Singer publishes to. The threads in these thread pools are used to wait for Kafka to complete writing messages to a partition and then report the status of the writes. While the threads do the job, each thread in the JVM (by <a href=\"https://docs.oracle.com/cd/E13150_01/jrockit_jvm/jrockit/geninfo/diagnos/thread_basics.html#wp1094805\">default</a>) will allocate 1MB of memory used for the thread\u2019s stack.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-001.png\" title=\"image_tooltip\" /></p>\n\n<p>A Singer NMT report showing the different memory regions a JVM process allocates. The <em>Thread</em> entry represents the thread stack. <em>Arena</em> contains the off-heap/direct memory portion managed outside of the JVM heap.</p>\n\n<p>Even with lazy allocation of the stack memory on the underlying operating systems until the thread is actually used, this still quickly adds up to hundreds of MBs of the process\u2019 memory. When there are a lot of log streams publishing to multiple partitions on different clusters, the memory used by thread stacks can be easily comparable to the 800MB default heap size of Singer and eats into the resources of the application.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-002.png\" title=\"image_tooltip\" /></p>\n\n<p>Each submission of KafkaWriteTask will occupy a thread. Full code can be found <a href=\"https://github.com/kabochya/singer/blob/b45051c/singer/src/main/java/com/pinterest/singer/writer/kafka/CommittableKafkaWriter.java#L192\">here</a></p>\n\n<p>By closely examining the usage of these threads, it quickly becomes clear that most of these threads are doing non-blocking operations such as updating metrics and are perfectly suitable for asynchronous processing using <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html\">CompletableFutures</a> provided starting in <a href=\"https://stackshare.io/java\">Java 8</a>. The CompletableFuture allows us to resolve the blocking calls by chaining stages asynchronously, thus replacing the usage of these threads that had to wait until the results to come back from Kafka. By utilizing the callback in the <em>KafkaProducer.send(record, callback)</em> method, we rely on the Kafka producer\u2019s network client to be completely in control of the multiplexing of networking.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-003.png\" title=\"image_tooltip\" /></p>\n\n<p>A brief example of the result code after using CompletableFutures. Full code can be found <a href=\"https://github.com/pinterest/singer/blob/5cc504da01c4c2cd747c8e0bb6a56b94571c8a60/singer/src/main/java/com/pinterest/singer/writer/kafka/CommittableKafkaWriter.java#L213\">here</a></p>\n\n<p>Once we convert the original logic into several chained non-blocking stages, it becomes obvious to use a single common thread pool to handle them regardless of the logstream, so we use the <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html#commonPool--\">common ForkJoinPool</a> that is already at our disposal from JVM. This dramatically reduces the thread usage for Singer, from a couple of hundred threads to virtually no additional threads. This improvement demonstrates the power of asynchronous processing and how network-bound applications can benefit from it.</p>\n\n<h1><strong>Kafka and Singer: Balancing performance and efficiency with controllable variance</strong></h1>\n\n<p><a href=\"https://www.confluent.io/blog/running-kafka-at-scale-at-pinterest/\">Operating our Kafka clusters</a> has always been a delicate balance between performance, fault tolerance, and efficiency. Our logging agent Singer, at the front line of publishing messages to Kafka, is a crucial component that plays a heavy role in these factors, especially in routing the traffic by deciding which partitions we deliver data to for a topic.</p>\n\n<h2><strong>The Default Partitioner: Evenly Distributed Traffic</strong></h2>\n\n<p>In Singer, logs from a machine would be picked up and routed to the corresponding topic it belongs to and published to that topic in Kafka. In the early days, Singer would publish uniformly to all the partitions that topic has in a round-robin fashion using our default partitioner. For example, if there were 3000 messages on a particular host that needed to be published to a 30 partition topic, each partition would roughly receive 100 messages. This worked pretty well for most of the use cases and has a nice benefit where all partitions receive the same amount of messages, which is great for the consumers of these topics since the workload is evenly distributed amongst them.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-004.png\" title=\"image_tooltip\" /></p>\n\n<p>DefaultPartitioner: Producers and Partitions are fully connected</p>\n\n<h2><strong>The Single Partition Partitioner: In Favor of the Law of Large Numbers</strong></h2>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-005.png\" title=\"image_tooltip\" /></p>\n\n<p>SinglePartitionPartitioner: Ideal scenario where connections are evenly distributed</p>\n\n<p>As Pinterest grew, we had fleets expanding to thousands of hosts, and this evenly-distributed approach started to cause some issues to our Kafka brokers: high connections counts and large amounts of produce requests started to elevate the brokers\u2019 CPU usage, and spreading out the messages means that the batch sizes are smaller for each partition, or lower efficiency of the compression, resulting in higher aggregated network traffic. To tackle this, we implemented a new partitioner: the SinglePartitionPartitioner. This partitioner solves the issue by forcing Singer to only write to one random partition per topic per host, reducing the fanout from all brokers to a single broker. This partition remains the same throughout the producer\u2019s lifetime until Singer restarts.</p>\n\n<p>For pipelines that had a large producer fleet and relatively uniform message rates across hosts, this was extremely effective: The law of large numbers worked in our favor, and statistically, if the number of producers is significantly larger than partitions, each partition will still receive a similar amount of traffic. Connection count went down from <strong>(number of brokers serving the topic)</strong> times <strong>(number of producers)</strong> to only <strong>(number of producers)</strong>, which could be up to a hundred times less for larger topics. Meanwhile, batching up all messages per producer to a single partition improved compression ratios by at least 10% in most use cases.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-006.png\" title=\"image_tooltip\" /></p>\n\n<p>SinglePartitionPartitioner: Skewed scenario where there are too few producers vs. partitions</p>\n\n<h2><strong>The Fixed Partitions Partitioner: Configurable variance for adjusting trade-offs</strong></h2>\n\n<p>Despite coming up with this new solution, there were still some pipelines that lie in the middle ground where both solutions are subpar, such as when the number of producers is not large enough to outnumber the number of partitions. In this case, the SinglePartitionPartitioner would introduce significant skew between partitions: some partitions will have multiple producers writing to them, and some are assigned very few or even no producers. This skew could cause unbalanced workloads for the downstream consumers, and also increases the burden for our team to manage the cluster, especially when storage is tight. We thus recently introduced a new partitioner that can be used on these cases, and even cover the original use cases: the FixedPartitionsPartitioner, which basically allows us to not only publish to one fixed partition like the SinglePartitionPartitioner, but randomly across a fixed number of partitions.</p>\n\n<p>This approach is somewhat similar to the concept of <a href=\"https://en.wikipedia.org/wiki/Consistent_hashing#Reduction_variance\">virtual nodes</a> in consistent hashing, where we artificially create more \u201ceffective producers\u201d to achieve a more continuous distribution. Since the number of partitions for each host can be configured, we can tune it to the sweet spot where the efficiency and performance are both at desired levels. This partitioner could also help with \u201chot producers\u201d by spreading traffic out while still maintaining a reasonable connection count. Although a simple concept, it turns out that having the ability to configure the degree of variance could be a powerful tool to manage trade-offs.</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-007.png\" title=\"image_tooltip\" /></p>\n\n<p>FixedPartitionsPartitioner: Less skew while still keeping connection count lower than the default</p>\n\n<p><img alt=\"\" src=\"https://img.stackshare.io/featured_posts/pinterest/optimizing-pinterests-data-ingestion-stack-findings-and-learnings/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-008.png\" title=\"image_tooltip\" /></p>\n\n<p>Relative compression ratio and request rate skew with different numbers of fixed partitions on a 120 partition topic on 30 brokers</p>\n\n<h1><strong>Conclusion and Acknowledgements</strong></h1>\n\n<p>These learnings are just a few examples of improvements the Logging Platform team has been making. Despite their seemingly different nature, the ultimate goal of all these improvements was to achieve better results for our team and our customers. We hope that these findings are inspiring and could spark a few ideas for you.</p>\n\n<p>None of the content in this article could have been delivered without the in-depth discussions and candid feedback from Ambud Sharma, Eric Lopez, Henry Cai, Jeff Xiang, and Vahid Hashemian on the Logging Platform team. We also deeply appreciate the great support from external teams that provided support and input on the various improvements we\u2019ve been working on. As we strive for continuous improvement within our architecture, we hope we will be able to share more interesting findings in our pursuit of perfecting our system.</p>"
  },
  "Zendesk": {
    "title": "Kafka: Automating Root CA rotation with Vault",
    "xmlUrl": "https://medium.com/feed/zendesk-engineering",
    "htmlUrl": "https://medium.com/zendesk-engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/zendesk-engineering",
      "value": "Kafka: Automating Root CA rotation with Vault"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://zendesk.engineering/kafka-automating-root-ca-rotation-with-vault-9bbbe07c7c6e?source=rss----a88376ea904a---4"
      }
    ],
    "link": "https://zendesk.engineering/kafka-automating-root-ca-rotation-with-vault-9bbbe07c7c6e?source=rss----a88376ea904a---4",
    "id": "https://medium.com/p/9bbbe07c7c6e",
    "guidislink": false,
    "tags": [
      {
        "term": "vault",
        "scheme": null,
        "label": null
      },
      {
        "term": "authentication",
        "scheme": null,
        "label": null
      },
      {
        "term": "kafka",
        "scheme": null,
        "label": null
      },
      {
        "term": "mtls-authentication",
        "scheme": null,
        "label": null
      },
      {
        "term": "security",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Tim Cuthbertson"
      }
    ],
    "author": "Tim Cuthbertson",
    "author_detail": {
      "name": "Tim Cuthbertson"
    },
    "published": "Tue, 19 Dec 2023 00:34:45 GMT",
    "published_parsed": [
      2023,
      12,
      19,
      0,
      34,
      45,
      1,
      353,
      0
    ],
    "updated": "2023-12-19T00:34:45.308Z",
    "updated_parsed": [
      2023,
      12,
      19,
      0,
      34,
      45,
      1,
      353,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/zendesk-engineering",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/975/1*X4eUG_P5TUb4KPh4Rf3odw.png\" /></figure><h4>Background</h4><p>Nearly three years ago, we first implemented mTLS (mutual TLS) for Apache Kafka at Zendesk. Our <a href=\"https://zendesk.engineering/implementing-mtls-and-securing-apache-kafka-at-zendesk-10f309db208d\">previous blog post</a> goes into great detail about how this\u00a0works.</p><p>Recently, we embarked on a process to replace our Kafka-specific authentication tooling with Zendesk\u2019s internal \u201cTemp Auth\u201d tooling for authenticating to other datastores like MySQL, Redis,\u00a0etc.</p><p>Temp Auth includes an <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/init-containers/\">init container</a>, responsible for delivering credentials to Kubernetes pods based on <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">custom resources</a> associated with the pod\u2019s project. We have a number of Kubernetes <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/operator/\">operators</a> which are responsible for:</p><ul><li>provisioning datastores (MySQL, DymanoDB, Kafka topics,\u00a0etc)</li><li>configuring access</li><li>populating credentials in <a href=\"https://www.vaultproject.io/\">Vault</a> and configuring vault\u00a0roles</li></ul><p>The init container\u2019s job is to read secrets from Vault based on a project\u2019s declared datastores, and deliver them as files on disk for the application container to read. It also deals with either evicting a pod or refreshing its credentials when any of these short-lived credentials are close to\u00a0expiry.</p><h3>mTLS Refresher</h3><p>When I\u2019m not actively working on mTLS, I usually forget how it works. So here\u2019s a refresher of the important parts of how mTLS works for\u00a0Kafka:</p><p>In typical browser TLS, only the server has a certificate. The client connects to example.com, and the server presents its certificate for example.com. This certificate will be signed by some Certificate Authority (CA). Typically this is an <em>intermediate</em> CA, which is itself signed by another CA. At some point up the chain of certificates, your browser encounters a certificate that it already trusts, because it matches one of the hundreds of well-known CAs already included in your\u00a0browser.</p><p>If a trust path is found, then your browser trusts the server. But the server has no idea who you are, so you\u2019ll typically use a username / password to authenticate yourself.</p><p>With <em>mutual</em> TLS, both sides verify each other. The broker provides a certificate which the client verifies, just like the above scenario. But the client also provides its own certificate, which the broker verifies. Now both sides know exactly who they\u2019re talking to, so we can do away with username / passwords entirely.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/852/1*Zzn4EnCRiKAA9Km8XAU26A.png\" /><figcaption>mTLS setup using a single Root\u00a0CA</figcaption></figure><p>The simplest version of this is when both certificates are directly issued by a single CA. We use Vault\u2019s PKI engine to easily create an internal self-signed CA. We don\u2019t need to bother with chains of intermediate CAs, as we can quickly distribute the root CA\u2019s certificate to every broker and\u00a0client.</p><h4>CA Rotation</h4><p>So far, so good. Clients trust Brokers, and Brokers trust clients. We don\u2019t need a separate username / password system, a single Vault CA can issue certificates for both use\u00a0cases.</p><p>But the big problem is how to rotate certificates. It\u2019s extremely unlikely that an attacker could steal the private key belonging to the Root CA. There are multiple layers of protection before an attacker could get to Vault, and Vault itself provides no access to read these private\u00a0keys.</p><p>However unlikely it is, if it <em>did</em> happen we\u2019d have to take Kafka offline, and that\u2019s unacceptable\u200a\u2014\u200aKafka\u2019s kind of important! So we need to have a process to rotate the Root CA. This is done by creating a new Root CA, and throwing the old one away. But again, we\u2019d like Kafka to keep working while this happens, and it can\u2019t be done instantly. So we use a gradual process to change root CAs. If we\u2019re retiring root-a and replacing it with root-b, the required steps\u00a0are:</p><ul><li><strong>Step 1: distribute both CA certificates to all clients.</strong><br />At this stage, everyone is still using certificates issued by root-a. But they\u2019ll also start trusting certificates issued by\u00a0root-b.</li><li><strong>Step 2: switch the primary issuer to </strong><strong>root-b.<br /></strong>Now that everyone trusts root-b certificates, we can start using\u00a0them.</li><li><strong>Step 3: remove the old </strong><strong>root-a certificate from all clients.<br /></strong>Now that nobody has certificates issued by this CA, we can stop trusting\u00a0it.</li></ul><p>Each of these steps takes some time to propagate to all clients and brokers, which is why we can\u2019t just swap the CAs instantly.</p><h3>Our original multi-root setup</h3><p>Managing this rotation process requires some shared state so that clients do the right thing at all times. In particular, everyone needs to\u00a0know:</p><ul><li>what is the primary CA, used for issuing certificates</li><li>what is the secondary CA (if any), which should be trusted alongside the primary root\u00a0CA</li></ul><p>As described in <a href=\"https://zendesk.engineering/implementing-mtls-and-securing-apache-kafka-at-zendesk-10f309db208d\">our earlier blog post</a>, we use a <a href=\"https://www.consul.io/\">Consul</a> key/value entry for this, where the value is a JSON structure containing the Vault paths for the current primary and secondary issuers. The process to initialize an authenticated Kafka client goes like\u00a0this:</p><p>Firstly, we need to know what Root CAs exist, and which is the primary one. We query the well-known kafka-pki/root Consul key, which returns a JSON value with the primary and secondary issuer\u00a0path(s).</p><p>Once we know those paths,\u00a0we:</p><ul><li>Ask the primary issuer to issue a certificate. The issued certificate contains the app\u2019s identity, which is used in Kafka for controlling access and\u00a0quotas.</li><li>Ask all secondary issuers for their certificate.</li></ul><p>With that information we can construct a Kafka Keystore and Truststore. The Keystore contains our client certificate (and private key). The Truststore contains all the issuers (both primary and secondary), which means that we\u2019ll be able to securely communicate with a broker who has a certificate issued by either\u00a0CA.</p><p>This process is shown below, with primary and secondary CAs in\u00a0use:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9EP2UXPd1nzJ1PhX9z4yAw.png\" /></figure><h3>That\u2019s pretty\u00a0bespoke!</h3><p>It is, isn\u2019t it? Three requests across two services. The interactions aren\u2019t that novel, but they\u2019re also not standard.</p><p>Honestly, throughout the initial design we were convinced there ought to be a simpler, more standard way. Surely other people rotate their root CAs, why did we have to invent our own glue for all of this? It really seemed like there should be some standard layer of indirection which we could use to swap out the primary issuer, without clients needing to be told about the\u00a0change.</p><p>Well at least we\u2019re not alone\u200a\u2014\u200awe dug into how folks are doing Istio root CA rotation and <a href=\"https://blog.christianposta.com/diving-into-istio-1-6-certificate-rotation/\">it\u2019s a pretty similar workflow</a>. This uses Kubernetes resources for indirection instead of Consul and also involves intermediate CAs. But the core process behind rotating the root CA is the\u00a0same.</p><h3>Enter Vault multi-issuer support</h3><p>In <a href=\"https://www.hashicorp.com/blog/vault-1-1\">Vault 1.11 (June 2022)</a>, there\u2019s now support for multiple issuers in one PKI engine. Which turns out to be exactly the layer of indirection we needed. Using this, we can have a single PKI engine mounted at /kafka-pki, but it can contain multiple issuers (root CAs in our case). Vault provides an API to set the default issuer, which will be used to issue certificates. That way clients can always make the same /kafka-pki/issue request, but we can swap the issuer behind the\u00a0scenes!</p><p>So that solves half the problem\u200a\u2014\u200aknowing about the primary issuer. But what about the secondary issuer? One way we could handle this is for clients to make a Vault API call to list all the issuers within /kafka/pki, and trust all their certificates. This would work fine, but the Temp Auth system we\u2019re integrating doesn\u2019t have any special multi-issuer logic, and ideally it shouldn\u2019t care.</p><p>When Vault issues you a certificate, it gives you back the certificate, the private key associated with that certificate, and a ca_chain. The idea is that you\u2019ll present this ca_chain when making a connection, and your peer will validate that it can find a path from your certificate up to some root it already trusts, using the chain you\u00a0provide.</p><p>Initially we planned to use this property to enable two-path validation, using intermediate CAs. That is, we\u2019d have a setup where the same intermediate CA was signed by two parent CAs. Whichever of the two root CAs you trusted, you would trust the intermediate because it had multiple trust paths, one back to each of the root\u00a0CAs.</p><p>We tried this out, and there\u2019s probably some way to get it to work. But when bashing our heads against Terraform and various openssl commands we don\u2019t use everyday, we realised there\u2019s a simpler, dumber way: <strong>just shove both roots in the </strong><strong>ca_chain.</strong></p><h3>(Ab)using the\u00a0ca_chain</h3><p>We don\u2019t have any use for the ca_chain currently, because we don\u2019t use intermediate CAs. We can distribute root CAs to all our clients quickly, so there\u2019s no need for the added complexity of intermediate CAs.</p><p>While we were busy putting both root CAs into the ca_chain of our intermediate, we realised that this is a pretty convenient way to give the client a list of CAs, which is exactly what we need to inform clients about multiple issuers. In our setup we know that both sides are using the same issuer, so the CAs used by a client are also the CAs it needs to trust to validate the broker\u2019s certificate.</p><p>So we actually put all CA certificates into the ca_chain of each issuer. And when configuring our Kafka clients, we use the returned ca_chain as a <em>truststore</em> instead of a ca_chain. That is, we trust every certificate that Vault returns in its ca_chain in our newly issued certificate.</p><p>This is, it should be noted, <strong>not what the ca_chain is for, nor how it\u2019s typically used</strong>. In a regular internet-style setup, you distribute root CAs out of band (e.g. bundling them in system packages), and the client presents a ca_chain which links the certificate <em>they have</em> back to a CA <em>you trust</em>. It would be a terrible mistake to trust the entries in a CA chain that a client gives you. But we\u2019re not doing that\u200a\u2014\u200awe\u2019re configuring Vault to return a ca_chain containing all the root CAs, and then trusting those (because we trust Vault). And this works for both the clients and brokers, because they\u2019re all using the same Vault issuer /\u00a0CAs.</p><p>The good news is that this unusual setup is restricted to how we <em>u</em>se the ca_chain (and configure Vault). As far as Temp Auth cares this is just a standard TLS certificate it\u2019s generating; it has no understanding of multiple\u00a0CAs.</p><p>Shown here is the overall process: just a single request to Vault and no special code to deal with multiple\u00a0issuers:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SKixcxbbNEPLsI-Bx01BCg.png\" /></figure><h3>Keep on\u00a0rolling</h3><p>At this point we had an interface that didn\u2019t require any bespoke logic to work with Temp Auth, our standard datastore authentication system. But that\u2019s only half of the picture. Our team owns the Vault PKI issuers and the process for doing the CA rotation.</p><p>In the initial mTLS implementation, we used Terraform. CA rotation was done semi-automatically, where an engineer followed a runbook, creating simple Terraform changes (updating a few JSON / HCL values) for Atlantis to apply for each step of the rotation process. This was a conscious tradeoff: fully automating the rotation would be difficult, and we didn\u2019t rotate CAs all that often (as I mentioned, it\u2019d be pretty hard to get these keys out of\u00a0Vault!).</p><p>But thanks to some pretty glaring bugs (<a href=\"https://github.com/hashicorp/terraform-provider-vault/issues/1968\">example</a>) in the Terraform Vault provider around multiple issuers, we decided it was time to automate the CA rotation.</p><p>To be honest, it was way easier than we expected. We periodically run a reconcile job which performs the following pseudo-logic:</p><p><strong>1)</strong> list all the issuers in /kafka-pki, sort them oldest-first and return the first\u00a03</p><p><strong>2)</strong> if there are less than 3 issuers, create a new issuer and go back to <strong>step\u00a01</strong></p><p><strong>3)</strong> assign these three issuers to variables previous, current and\u00a0next</p><p><strong>4)</strong> if next is older than ROTATION_TIME: create a new issuer, and shuffle the existing issuers (i.e. the new issuer becomes next, the old next becomes current, the old current becomes previous and the old previous is forgotten)</p><p><strong>5)</strong> set the ca_chain in all three issuers to [previous, current,\u00a0next]</p><p><strong>6)</strong> mark current as the primary issuer in Vault (if it isn\u2019t\u00a0already)</p><p><strong>7)</strong> delete any issuers not in [previous, current,\u00a0next]</p><p>This is a relatively straightforward process that is robust to interruptions\u200a\u2014\u200aif the process crashes at any point, it\u2019ll end up with the 3 desired issuers after the next run regardless of which point it got up to, and there\u2019s no point where a crash would leave Vault in an unwanted state (e.g. deleting an issuer before all references to it have been removed).</p><h3>Three little pi\u0336g\u0336g\u0336i\u0336e\u0336s\u0336 CAs</h3><p>One thing that surprised me was that we ended up with three CAs at all times. We used to have one most of the time, and two during a rotation. We originally wrote an algorithm to replicate this, but it needed a mode concept which represented whether we were bringing in a new CA or phasing out an old\u00a0one.</p><p>But this new logic is always doing <em>both</em> at the same time. We never considered that with the old runbook-based approach as it\u2019d be more work. But when automated it led to less code, which was a funny realisation. Right after a after a rotation happens, these are the CA\u00a0states:</p><ul><li>The next issuer is brand new. Nobody trusts it yet, so we can\u2019t issue certificates with it. Clients will start trusting it when they next provision certificates.</li><li>next &gt; current (rotate in): Every client now trusts this CA so we promote it to be the primary issuer of certificates.</li><li>current &gt; previous (rotate out): All existing certificates were issued by this CA, so we need to keep trusting it until they\u00a0expire.</li><li>previous &gt; (deleted): It\u2019s been long enough that nobody still holds a certificate issued by this CA, so we can delete\u00a0it.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/916/1*eb4AII6g_wB6yqWRieGTBA.png\" /><figcaption>The three-CA rotation process, illustrated</figcaption></figure><h3>The second 90% of the work: migration</h3><p>Zendesk has been running Kafka clusters for around a decade now, and we have hundreds of services relying on it. Our most recent migration was from Chef-managed VMs to Kubernetes, which we did very gradually over the course of many months, with zero downtime for clients. For any migration we do, sudden breaking changes are simply out of the question.</p><p>For this migration, we paved the way by introducing our new multi-issuer endpoint as a secondary_issuer in the existing Consul-based system. We also tweaked the old init container code to trust all ca_chain entries, not just the issuing certificate. This way, old clients would trust all four issuers (the old one and our three new issuers). And once we promoted the new multi-issuer endpoint to the primary_issuer (and wait for that to propagate), all our clients trust the same three root CAs regardless of which init container they\u2019re\u00a0using.</p><p>When changing authentication, there\u2019s a real risk of breaking things for existing clients. There are a whole bunch of ways you can break the trust between two processes, not to mention the deployment surprises in switching to a different init container.</p><p>Thinking through all the states and interactions between clients and brokers in various states of the migration is important, but unfortunately not sufficient. We did a lot of testing in our staging environment\u200a\u2014\u200arolling forward, rolling back, and keeping an eye out for any issues that might be authentication-related. For the most part they weren\u2019t that hard to spot\u00a0\ud83d\ude05.</p><p>When changing something this large and previously stable, you always end up flushing out some other associated problems. During our test rollouts we uncovered a number of related\u00a0issues:</p><ul><li>A bug in our deployment tooling which caused applications to be pinned to an old version of our init-container, instead of receiving the latest version at deployment time.</li><li>One VM hostgroup where we\u2019d overlooked the necessary upgrade of the init container, as this process differs from Kubernetes workloads.</li><li>Some interactions between different Kubernetes controllers, where under certain conditions the Temp Auth init container would try to generate Kafka certificates, but the destination volume didn\u2019t exist in the pod\u2019s manifest.</li><li>Subtly misconfigured clients, which would only trust the first issuer in the truststore we had generated\u200a\u2014\u200amany tools will quietly read \u201ca certificate\u201d from a file containing multiple, which is hard to notice when you usually only need the first\u00a0one.</li></ul><p>This all slowed down our rollout, but for a good cause. Having flushed out those issues in staging, we could proceed to roll out to production with no customer impact, and a peaceful night\u2019s sleep for our on-call engineers.</p><h3>Conclusion</h3><p>We\u2019re really happy with this new setup. The first time we implemented mTLS for Kafka it seemed like there must be a better way, and now I feel like we\u2019ve found it. The whole setup is easier to understand, observe, and it\u2019s now fully automated.</p><p>Thanks to that automation, we can have an aggressive rotation schedule in days, not years. The only requirement is that ROTATION_TIME needs to be longer than the TTL of our issued certificates, to ensure that everyone\u2019s seen the latest state before we perform the next rotation.</p><p>I\u2019ll be honest, doing this work wasn\u2019t a smooth process. Our team aren\u2019t PKI experts, we took a while to meander our way through the problem space (and Terraform!) to find something that works. But we\u2019re really happy with the results. We get to retire our Kafka-only auth injection system and reuse the common Temp Auth tooling used by other datastores at Zendesk, plus we managed to end up with a much simpler and fully automated CA rotation\u00a0system.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9bbbe07c7c6e\" width=\"1\" /><hr /><p><a href=\"https://zendesk.engineering/kafka-automating-root-ca-rotation-with-vault-9bbbe07c7c6e\">Kafka: Automating Root CA rotation with Vault</a> was originally published in <a href=\"https://zendesk.engineering\">Zendesk Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/975/1*X4eUG_P5TUb4KPh4Rf3odw.png\" /></figure><h4>Background</h4><p>Nearly three years ago, we first implemented mTLS (mutual TLS) for Apache Kafka at Zendesk. Our <a href=\"https://zendesk.engineering/implementing-mtls-and-securing-apache-kafka-at-zendesk-10f309db208d\">previous blog post</a> goes into great detail about how this\u00a0works.</p><p>Recently, we embarked on a process to replace our Kafka-specific authentication tooling with Zendesk\u2019s internal \u201cTemp Auth\u201d tooling for authenticating to other datastores like MySQL, Redis,\u00a0etc.</p><p>Temp Auth includes an <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/init-containers/\">init container</a>, responsible for delivering credentials to Kubernetes pods based on <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">custom resources</a> associated with the pod\u2019s project. We have a number of Kubernetes <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/operator/\">operators</a> which are responsible for:</p><ul><li>provisioning datastores (MySQL, DymanoDB, Kafka topics,\u00a0etc)</li><li>configuring access</li><li>populating credentials in <a href=\"https://www.vaultproject.io/\">Vault</a> and configuring vault\u00a0roles</li></ul><p>The init container\u2019s job is to read secrets from Vault based on a project\u2019s declared datastores, and deliver them as files on disk for the application container to read. It also deals with either evicting a pod or refreshing its credentials when any of these short-lived credentials are close to\u00a0expiry.</p><h3>mTLS Refresher</h3><p>When I\u2019m not actively working on mTLS, I usually forget how it works. So here\u2019s a refresher of the important parts of how mTLS works for\u00a0Kafka:</p><p>In typical browser TLS, only the server has a certificate. The client connects to example.com, and the server presents its certificate for example.com. This certificate will be signed by some Certificate Authority (CA). Typically this is an <em>intermediate</em> CA, which is itself signed by another CA. At some point up the chain of certificates, your browser encounters a certificate that it already trusts, because it matches one of the hundreds of well-known CAs already included in your\u00a0browser.</p><p>If a trust path is found, then your browser trusts the server. But the server has no idea who you are, so you\u2019ll typically use a username / password to authenticate yourself.</p><p>With <em>mutual</em> TLS, both sides verify each other. The broker provides a certificate which the client verifies, just like the above scenario. But the client also provides its own certificate, which the broker verifies. Now both sides know exactly who they\u2019re talking to, so we can do away with username / passwords entirely.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/852/1*Zzn4EnCRiKAA9Km8XAU26A.png\" /><figcaption>mTLS setup using a single Root\u00a0CA</figcaption></figure><p>The simplest version of this is when both certificates are directly issued by a single CA. We use Vault\u2019s PKI engine to easily create an internal self-signed CA. We don\u2019t need to bother with chains of intermediate CAs, as we can quickly distribute the root CA\u2019s certificate to every broker and\u00a0client.</p><h4>CA Rotation</h4><p>So far, so good. Clients trust Brokers, and Brokers trust clients. We don\u2019t need a separate username / password system, a single Vault CA can issue certificates for both use\u00a0cases.</p><p>But the big problem is how to rotate certificates. It\u2019s extremely unlikely that an attacker could steal the private key belonging to the Root CA. There are multiple layers of protection before an attacker could get to Vault, and Vault itself provides no access to read these private\u00a0keys.</p><p>However unlikely it is, if it <em>did</em> happen we\u2019d have to take Kafka offline, and that\u2019s unacceptable\u200a\u2014\u200aKafka\u2019s kind of important! So we need to have a process to rotate the Root CA. This is done by creating a new Root CA, and throwing the old one away. But again, we\u2019d like Kafka to keep working while this happens, and it can\u2019t be done instantly. So we use a gradual process to change root CAs. If we\u2019re retiring root-a and replacing it with root-b, the required steps\u00a0are:</p><ul><li><strong>Step 1: distribute both CA certificates to all clients.</strong><br />At this stage, everyone is still using certificates issued by root-a. But they\u2019ll also start trusting certificates issued by\u00a0root-b.</li><li><strong>Step 2: switch the primary issuer to </strong><strong>root-b.<br /></strong>Now that everyone trusts root-b certificates, we can start using\u00a0them.</li><li><strong>Step 3: remove the old </strong><strong>root-a certificate from all clients.<br /></strong>Now that nobody has certificates issued by this CA, we can stop trusting\u00a0it.</li></ul><p>Each of these steps takes some time to propagate to all clients and brokers, which is why we can\u2019t just swap the CAs instantly.</p><h3>Our original multi-root setup</h3><p>Managing this rotation process requires some shared state so that clients do the right thing at all times. In particular, everyone needs to\u00a0know:</p><ul><li>what is the primary CA, used for issuing certificates</li><li>what is the secondary CA (if any), which should be trusted alongside the primary root\u00a0CA</li></ul><p>As described in <a href=\"https://zendesk.engineering/implementing-mtls-and-securing-apache-kafka-at-zendesk-10f309db208d\">our earlier blog post</a>, we use a <a href=\"https://www.consul.io/\">Consul</a> key/value entry for this, where the value is a JSON structure containing the Vault paths for the current primary and secondary issuers. The process to initialize an authenticated Kafka client goes like\u00a0this:</p><p>Firstly, we need to know what Root CAs exist, and which is the primary one. We query the well-known kafka-pki/root Consul key, which returns a JSON value with the primary and secondary issuer\u00a0path(s).</p><p>Once we know those paths,\u00a0we:</p><ul><li>Ask the primary issuer to issue a certificate. The issued certificate contains the app\u2019s identity, which is used in Kafka for controlling access and\u00a0quotas.</li><li>Ask all secondary issuers for their certificate.</li></ul><p>With that information we can construct a Kafka Keystore and Truststore. The Keystore contains our client certificate (and private key). The Truststore contains all the issuers (both primary and secondary), which means that we\u2019ll be able to securely communicate with a broker who has a certificate issued by either\u00a0CA.</p><p>This process is shown below, with primary and secondary CAs in\u00a0use:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9EP2UXPd1nzJ1PhX9z4yAw.png\" /></figure><h3>That\u2019s pretty\u00a0bespoke!</h3><p>It is, isn\u2019t it? Three requests across two services. The interactions aren\u2019t that novel, but they\u2019re also not standard.</p><p>Honestly, throughout the initial design we were convinced there ought to be a simpler, more standard way. Surely other people rotate their root CAs, why did we have to invent our own glue for all of this? It really seemed like there should be some standard layer of indirection which we could use to swap out the primary issuer, without clients needing to be told about the\u00a0change.</p><p>Well at least we\u2019re not alone\u200a\u2014\u200awe dug into how folks are doing Istio root CA rotation and <a href=\"https://blog.christianposta.com/diving-into-istio-1-6-certificate-rotation/\">it\u2019s a pretty similar workflow</a>. This uses Kubernetes resources for indirection instead of Consul and also involves intermediate CAs. But the core process behind rotating the root CA is the\u00a0same.</p><h3>Enter Vault multi-issuer support</h3><p>In <a href=\"https://www.hashicorp.com/blog/vault-1-1\">Vault 1.11 (June 2022)</a>, there\u2019s now support for multiple issuers in one PKI engine. Which turns out to be exactly the layer of indirection we needed. Using this, we can have a single PKI engine mounted at /kafka-pki, but it can contain multiple issuers (root CAs in our case). Vault provides an API to set the default issuer, which will be used to issue certificates. That way clients can always make the same /kafka-pki/issue request, but we can swap the issuer behind the\u00a0scenes!</p><p>So that solves half the problem\u200a\u2014\u200aknowing about the primary issuer. But what about the secondary issuer? One way we could handle this is for clients to make a Vault API call to list all the issuers within /kafka/pki, and trust all their certificates. This would work fine, but the Temp Auth system we\u2019re integrating doesn\u2019t have any special multi-issuer logic, and ideally it shouldn\u2019t care.</p><p>When Vault issues you a certificate, it gives you back the certificate, the private key associated with that certificate, and a ca_chain. The idea is that you\u2019ll present this ca_chain when making a connection, and your peer will validate that it can find a path from your certificate up to some root it already trusts, using the chain you\u00a0provide.</p><p>Initially we planned to use this property to enable two-path validation, using intermediate CAs. That is, we\u2019d have a setup where the same intermediate CA was signed by two parent CAs. Whichever of the two root CAs you trusted, you would trust the intermediate because it had multiple trust paths, one back to each of the root\u00a0CAs.</p><p>We tried this out, and there\u2019s probably some way to get it to work. But when bashing our heads against Terraform and various openssl commands we don\u2019t use everyday, we realised there\u2019s a simpler, dumber way: <strong>just shove both roots in the </strong><strong>ca_chain.</strong></p><h3>(Ab)using the\u00a0ca_chain</h3><p>We don\u2019t have any use for the ca_chain currently, because we don\u2019t use intermediate CAs. We can distribute root CAs to all our clients quickly, so there\u2019s no need for the added complexity of intermediate CAs.</p><p>While we were busy putting both root CAs into the ca_chain of our intermediate, we realised that this is a pretty convenient way to give the client a list of CAs, which is exactly what we need to inform clients about multiple issuers. In our setup we know that both sides are using the same issuer, so the CAs used by a client are also the CAs it needs to trust to validate the broker\u2019s certificate.</p><p>So we actually put all CA certificates into the ca_chain of each issuer. And when configuring our Kafka clients, we use the returned ca_chain as a <em>truststore</em> instead of a ca_chain. That is, we trust every certificate that Vault returns in its ca_chain in our newly issued certificate.</p><p>This is, it should be noted, <strong>not what the ca_chain is for, nor how it\u2019s typically used</strong>. In a regular internet-style setup, you distribute root CAs out of band (e.g. bundling them in system packages), and the client presents a ca_chain which links the certificate <em>they have</em> back to a CA <em>you trust</em>. It would be a terrible mistake to trust the entries in a CA chain that a client gives you. But we\u2019re not doing that\u200a\u2014\u200awe\u2019re configuring Vault to return a ca_chain containing all the root CAs, and then trusting those (because we trust Vault). And this works for both the clients and brokers, because they\u2019re all using the same Vault issuer /\u00a0CAs.</p><p>The good news is that this unusual setup is restricted to how we <em>u</em>se the ca_chain (and configure Vault). As far as Temp Auth cares this is just a standard TLS certificate it\u2019s generating; it has no understanding of multiple\u00a0CAs.</p><p>Shown here is the overall process: just a single request to Vault and no special code to deal with multiple\u00a0issuers:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SKixcxbbNEPLsI-Bx01BCg.png\" /></figure><h3>Keep on\u00a0rolling</h3><p>At this point we had an interface that didn\u2019t require any bespoke logic to work with Temp Auth, our standard datastore authentication system. But that\u2019s only half of the picture. Our team owns the Vault PKI issuers and the process for doing the CA rotation.</p><p>In the initial mTLS implementation, we used Terraform. CA rotation was done semi-automatically, where an engineer followed a runbook, creating simple Terraform changes (updating a few JSON / HCL values) for Atlantis to apply for each step of the rotation process. This was a conscious tradeoff: fully automating the rotation would be difficult, and we didn\u2019t rotate CAs all that often (as I mentioned, it\u2019d be pretty hard to get these keys out of\u00a0Vault!).</p><p>But thanks to some pretty glaring bugs (<a href=\"https://github.com/hashicorp/terraform-provider-vault/issues/1968\">example</a>) in the Terraform Vault provider around multiple issuers, we decided it was time to automate the CA rotation.</p><p>To be honest, it was way easier than we expected. We periodically run a reconcile job which performs the following pseudo-logic:</p><p><strong>1)</strong> list all the issuers in /kafka-pki, sort them oldest-first and return the first\u00a03</p><p><strong>2)</strong> if there are less than 3 issuers, create a new issuer and go back to <strong>step\u00a01</strong></p><p><strong>3)</strong> assign these three issuers to variables previous, current and\u00a0next</p><p><strong>4)</strong> if next is older than ROTATION_TIME: create a new issuer, and shuffle the existing issuers (i.e. the new issuer becomes next, the old next becomes current, the old current becomes previous and the old previous is forgotten)</p><p><strong>5)</strong> set the ca_chain in all three issuers to [previous, current,\u00a0next]</p><p><strong>6)</strong> mark current as the primary issuer in Vault (if it isn\u2019t\u00a0already)</p><p><strong>7)</strong> delete any issuers not in [previous, current,\u00a0next]</p><p>This is a relatively straightforward process that is robust to interruptions\u200a\u2014\u200aif the process crashes at any point, it\u2019ll end up with the 3 desired issuers after the next run regardless of which point it got up to, and there\u2019s no point where a crash would leave Vault in an unwanted state (e.g. deleting an issuer before all references to it have been removed).</p><h3>Three little pi\u0336g\u0336g\u0336i\u0336e\u0336s\u0336 CAs</h3><p>One thing that surprised me was that we ended up with three CAs at all times. We used to have one most of the time, and two during a rotation. We originally wrote an algorithm to replicate this, but it needed a mode concept which represented whether we were bringing in a new CA or phasing out an old\u00a0one.</p><p>But this new logic is always doing <em>both</em> at the same time. We never considered that with the old runbook-based approach as it\u2019d be more work. But when automated it led to less code, which was a funny realisation. Right after a after a rotation happens, these are the CA\u00a0states:</p><ul><li>The next issuer is brand new. Nobody trusts it yet, so we can\u2019t issue certificates with it. Clients will start trusting it when they next provision certificates.</li><li>next &gt; current (rotate in): Every client now trusts this CA so we promote it to be the primary issuer of certificates.</li><li>current &gt; previous (rotate out): All existing certificates were issued by this CA, so we need to keep trusting it until they\u00a0expire.</li><li>previous &gt; (deleted): It\u2019s been long enough that nobody still holds a certificate issued by this CA, so we can delete\u00a0it.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/916/1*eb4AII6g_wB6yqWRieGTBA.png\" /><figcaption>The three-CA rotation process, illustrated</figcaption></figure><h3>The second 90% of the work: migration</h3><p>Zendesk has been running Kafka clusters for around a decade now, and we have hundreds of services relying on it. Our most recent migration was from Chef-managed VMs to Kubernetes, which we did very gradually over the course of many months, with zero downtime for clients. For any migration we do, sudden breaking changes are simply out of the question.</p><p>For this migration, we paved the way by introducing our new multi-issuer endpoint as a secondary_issuer in the existing Consul-based system. We also tweaked the old init container code to trust all ca_chain entries, not just the issuing certificate. This way, old clients would trust all four issuers (the old one and our three new issuers). And once we promoted the new multi-issuer endpoint to the primary_issuer (and wait for that to propagate), all our clients trust the same three root CAs regardless of which init container they\u2019re\u00a0using.</p><p>When changing authentication, there\u2019s a real risk of breaking things for existing clients. There are a whole bunch of ways you can break the trust between two processes, not to mention the deployment surprises in switching to a different init container.</p><p>Thinking through all the states and interactions between clients and brokers in various states of the migration is important, but unfortunately not sufficient. We did a lot of testing in our staging environment\u200a\u2014\u200arolling forward, rolling back, and keeping an eye out for any issues that might be authentication-related. For the most part they weren\u2019t that hard to spot\u00a0\ud83d\ude05.</p><p>When changing something this large and previously stable, you always end up flushing out some other associated problems. During our test rollouts we uncovered a number of related\u00a0issues:</p><ul><li>A bug in our deployment tooling which caused applications to be pinned to an old version of our init-container, instead of receiving the latest version at deployment time.</li><li>One VM hostgroup where we\u2019d overlooked the necessary upgrade of the init container, as this process differs from Kubernetes workloads.</li><li>Some interactions between different Kubernetes controllers, where under certain conditions the Temp Auth init container would try to generate Kafka certificates, but the destination volume didn\u2019t exist in the pod\u2019s manifest.</li><li>Subtly misconfigured clients, which would only trust the first issuer in the truststore we had generated\u200a\u2014\u200amany tools will quietly read \u201ca certificate\u201d from a file containing multiple, which is hard to notice when you usually only need the first\u00a0one.</li></ul><p>This all slowed down our rollout, but for a good cause. Having flushed out those issues in staging, we could proceed to roll out to production with no customer impact, and a peaceful night\u2019s sleep for our on-call engineers.</p><h3>Conclusion</h3><p>We\u2019re really happy with this new setup. The first time we implemented mTLS for Kafka it seemed like there must be a better way, and now I feel like we\u2019ve found it. The whole setup is easier to understand, observe, and it\u2019s now fully automated.</p><p>Thanks to that automation, we can have an aggressive rotation schedule in days, not years. The only requirement is that ROTATION_TIME needs to be longer than the TTL of our issued certificates, to ensure that everyone\u2019s seen the latest state before we perform the next rotation.</p><p>I\u2019ll be honest, doing this work wasn\u2019t a smooth process. Our team aren\u2019t PKI experts, we took a while to meander our way through the problem space (and Terraform!) to find something that works. But we\u2019re really happy with the results. We get to retire our Kafka-only auth injection system and reuse the common Temp Auth tooling used by other datastores at Zendesk, plus we managed to end up with a much simpler and fully automated CA rotation\u00a0system.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9bbbe07c7c6e\" width=\"1\" /><hr /><p><a href=\"https://zendesk.engineering/kafka-automating-root-ca-rotation-with-vault-9bbbe07c7c6e\">Kafka: Automating Root CA rotation with Vault</a> was originally published in <a href=\"https://zendesk.engineering\">Zendesk Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Arkency": {
    "title": "Repository implementation on ActiveRecord",
    "xmlUrl": "http://blog.arkency.com/atom.xml",
    "htmlUrl": "http://blog.arkency.com/",
    "id": "tag:blog.arkency.com,2023-12-28:/activerecord-repository/",
    "guidislink": true,
    "link": "https://blog.arkency.com/activerecord-repository/",
    "title_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.arkency.com/",
      "value": "Repository implementation on ActiveRecord"
    },
    "published": "2023-12-28T15:00:00Z",
    "published_parsed": [
      2023,
      12,
      28,
      15,
      0,
      0,
      3,
      362,
      0
    ],
    "updated": "2023-12-28T15:00:00Z",
    "updated_parsed": [
      2023,
      12,
      28,
      15,
      0,
      0,
      3,
      362,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "href": "https://blog.arkency.com/activerecord-repository/",
        "type": "text/html"
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.arkency.com/",
        "value": "<h1 id=\"repository_implementation_on_activerecord\">Repository implementation on ActiveRecord</h1>\n<p>In its essence, a Repository separates domain objects from how they&rsquo;re persisted and provides a limited interface to access them. It&rsquo;s a tactical pattern described with far more words by <a href=\"https://martinfowler.com/eaaCatalog/repository.html\">Fowler</a> and <a href=\"https://www.domainlanguage.com\">Evans</a> than I&rsquo;d like to include in this introduction.\nIt stands in complete opposition to what <a href=\"https://www.martinfowler.com/eaaCatalog/activeRecord.html\">ActiveRecord</a> pattern promotes. Why bother transforming one into another?  </p>\n\n<p>The problem with ActiveRecord pattern comes from its greatest strength. It&rsquo;s a double-edged sword. Immensely useful in rapid prototyping for a &ldquo;solopreneur&rdquo;. Flexible for a well-knit and disciplined team. Spiralling out of control in a wide organisation with multiple teams working on a relatively big legacy application.</p>\n\n<p>As of now bare <code>ActiveRecord::Base</code> begins with 350 instance methods on its public interface. Add to that 496 methods of <code>ActiveRecord::Relation</code> that one usually interacts with. Performing a larger refactoring that covers all possible usage patterns of such ActiveRecord models becomes a nightmare. Initial checklist includes:</p>\n\n<ul>\n<li>vast query API</li>\n<li>callbacks</li>\n<li>relations, its extensions and the conventional behaviour</li>\n<li>gems in the <code>Gemfile</code> that extend <code>ActiveRecord::Base</code> \u2014 adding new methods and altering behaviours</li>\n</ul>\n\n<p>That&rsquo;s a significant scope to cover. It translates to a certain cost of time, energy and confidence to pull out any change on it in a production system that earns money.</p>\n\n<p>I remember a few past attempts from my colleagues to control the scope of ActiveRecord surfaced in larger codebases.\nThere was the <a href=\"https://github.com/paneq/not_activerecord\">not_activerecord</a> to help express the boundaries. There were various approaches to <a href=\"https://codeclimate.com/blog/7-ways-to-decompose-fat-activerecord-models\">query</a> <a href=\"https://thoughtbot.com/blog/a-case-for-query-objects-in-rails\">objects</a> that addressed the read part.</p>\n\n<p>I also vaguely recall a quote from <a href=\"https://adam.pohorecki.pl/blog/2013/06/27/bogus-talk-at-drug/\">Adam Pohorecki on a DRUG meetup</a> that you can get 80% benefits out of Repository by putting 20% effort into shaping ActiveRecord like this:</p>\n<div class=\"highlight\"><pre class=\"highlight ruby\"><code><span class=\"k\">class</span> <span class=\"nc\">Transaction</span>\n  <span class=\"k\">def</span> <span class=\"nc\">self</span><span class=\"o\">.</span><span class=\"nf\">of_id</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">)</span>\n    <span class=\"n\">find</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">)</span>\n  <span class=\"k\">end</span>\n\n  <span class=\"k\">def</span> <span class=\"nc\">self</span><span class=\"o\">.</span><span class=\"nf\">last_not_pending_of_user_id</span><span class=\"p\">(</span><span class=\"n\">user_id</span><span class=\"p\">)</span>\n    <span class=\"n\">where</span><span class=\"p\">.</span><span class=\"nf\">not</span><span class=\"p\">(</span><span class=\"ss\">status: </span><span class=\"s2\">\"pending\"</span><span class=\"p\">).</span><span class=\"nf\">where</span><span class=\"p\">(</span><span class=\"ss\">user_id: </span><span class=\"n\">user_id</span><span class=\"p\">).</span><span class=\"nf\">order</span><span class=\"p\">(</span><span class=\"ss\">:id</span><span class=\"p\">).</span><span class=\"nf\">last</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>It relies very much on the discipline of team \u2014 to treat <code>ActiveRecord::Base</code> methods as &ldquo;private&rdquo; and only access the model by the application-specific class methods.</p>\n\n<p>This the repository I&rsquo;d make today, without any external dependencies in the framework you already have:</p>\n<div class=\"highlight\"><pre class=\"highlight ruby\"><code><span class=\"k\">class</span> <span class=\"nc\">TransactionRepository</span>\n  <span class=\"k\">class</span> <span class=\"nc\">Record</span> <span class=\"o\">&lt;</span> <span class=\"no\">ActiveRecord</span><span class=\"o\">::</span><span class=\"no\">Base</span>\n    <span class=\"nb\">self</span><span class=\"p\">.</span><span class=\"nf\">table_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"transactions\"</span>\n  <span class=\"k\">end</span>\n  <span class=\"n\">private_constant</span> <span class=\"ss\">:Record</span>\n\n  <span class=\"no\">Transaction</span> <span class=\"o\">=</span> <span class=\"no\">Data</span><span class=\"p\">.</span><span class=\"nf\">define</span><span class=\"p\">(</span><span class=\"no\">Record</span><span class=\"p\">.</span><span class=\"nf\">attribute_names</span><span class=\"p\">.</span><span class=\"nf\">map</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"ss\">:to_sym</span><span class=\"p\">))</span>\n\n  <span class=\"k\">class</span> <span class=\"o\">&lt;&lt;</span> <span class=\"nb\">self</span>\n    <span class=\"k\">def</span> <span class=\"nf\">of_id</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">)</span>\n      <span class=\"n\">as_struct</span><span class=\"p\">(</span><span class=\"no\">Record</span><span class=\"p\">.</span><span class=\"nf\">find</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">))</span>\n    <span class=\"k\">end</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">last_not_pending_of_user_id</span><span class=\"p\">(</span><span class=\"n\">user_id</span><span class=\"p\">)</span>\n      <span class=\"n\">as_struct</span><span class=\"p\">(</span><span class=\"no\">Record</span><span class=\"p\">.</span><span class=\"nf\">where</span><span class=\"p\">.</span><span class=\"nf\">not</span><span class=\"p\">(</span><span class=\"ss\">status: </span><span class=\"s2\">\"pending\"</span><span class=\"p\">).</span><span class=\"nf\">where</span><span class=\"p\">(</span><span class=\"ss\">user_id: </span><span class=\"n\">user_id</span><span class=\"p\">).</span><span class=\"nf\">order</span><span class=\"p\">(</span><span class=\"ss\">:id</span><span class=\"p\">).</span><span class=\"nf\">last</span><span class=\"p\">)</span>\n    <span class=\"k\">end</span>\n\n    <span class=\"kp\">private</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">as_struct</span><span class=\"p\">(</span><span class=\"n\">record</span><span class=\"p\">)</span>\n      <span class=\"no\">Transaction</span><span class=\"p\">.</span><span class=\"nf\">new</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">record</span><span class=\"p\">.</span><span class=\"nf\">attributes</span><span class=\"p\">.</span><span class=\"nf\">symbolize_keys</span><span class=\"p\">)</span>\n    <span class=\"k\">end</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>Let&rsquo;s dissect this sample a bit.</p>\n\n<ol>\n<li><code>TransactionRepository</code> and its public methods form the API. Since it takes no dependencies and carries no state within its lifecycle, the methods are on the singleton. These are the only ways to access the data and the surface is very limited.</li>\n<li><code>TransactionRepository::Record</code> is the ActiveRecord class. We have to point to its database table with <code>self.table_name</code>, since its namespace is &ldquo;unconventional&rdquo; to the framework mechanics. We may use <code>Record</code> within the repository and to implement its functionality. This constant is not available outside the repository \u2014 encapsulation is fulfilled.</li>\n<li>Return values of repository queries are immutable structs. They&rsquo;re not <code>ActiveRecord::Relation</code>. They&rsquo;re not <code>ActiveRecord::Base</code> instances either.</li>\n</ol>\n\n<p>Does this approach have drawbacks? It certainly does. Like everything else it&rsquo;s an art of choice. We&rsquo;re trading convenience off in one area for predictability and maintainability in the other. YMMV.</p>\n\n<p>Where vast ActiveRecord surface shines the most is the view layer and the numerous framework helpers built on top of it. We don&rsquo;t get that benefits with our structs. We might get back some of them by including <code>ActiveModel::Naming</code> behaviours.</p>\n\n<p>Does this approach have any alternatives? The CQRS \u2014 a separation of write and read models, where there was previously one, could be a viable option for some. Given that writes and reads are implemented and optimised differently, the ActiveRecord fits the read part perfectly. It is my preferred vehicle to implement Read Model on top of denormalised SQL database tables in Rails.</p>"
      }
    ],
    "summary": "<h1 id=\"repository_implementation_on_activerecord\">Repository implementation on ActiveRecord</h1>\n<p>In its essence, a Repository separates domain objects from how they&rsquo;re persisted and provides a limited interface to access them. It&rsquo;s a tactical pattern described with far more words by <a href=\"https://martinfowler.com/eaaCatalog/repository.html\">Fowler</a> and <a href=\"https://www.domainlanguage.com\">Evans</a> than I&rsquo;d like to include in this introduction.\nIt stands in complete opposition to what <a href=\"https://www.martinfowler.com/eaaCatalog/activeRecord.html\">ActiveRecord</a> pattern promotes. Why bother transforming one into another?  </p>\n\n<p>The problem with ActiveRecord pattern comes from its greatest strength. It&rsquo;s a double-edged sword. Immensely useful in rapid prototyping for a &ldquo;solopreneur&rdquo;. Flexible for a well-knit and disciplined team. Spiralling out of control in a wide organisation with multiple teams working on a relatively big legacy application.</p>\n\n<p>As of now bare <code>ActiveRecord::Base</code> begins with 350 instance methods on its public interface. Add to that 496 methods of <code>ActiveRecord::Relation</code> that one usually interacts with. Performing a larger refactoring that covers all possible usage patterns of such ActiveRecord models becomes a nightmare. Initial checklist includes:</p>\n\n<ul>\n<li>vast query API</li>\n<li>callbacks</li>\n<li>relations, its extensions and the conventional behaviour</li>\n<li>gems in the <code>Gemfile</code> that extend <code>ActiveRecord::Base</code> \u2014 adding new methods and altering behaviours</li>\n</ul>\n\n<p>That&rsquo;s a significant scope to cover. It translates to a certain cost of time, energy and confidence to pull out any change on it in a production system that earns money.</p>\n\n<p>I remember a few past attempts from my colleagues to control the scope of ActiveRecord surfaced in larger codebases.\nThere was the <a href=\"https://github.com/paneq/not_activerecord\">not_activerecord</a> to help express the boundaries. There were various approaches to <a href=\"https://codeclimate.com/blog/7-ways-to-decompose-fat-activerecord-models\">query</a> <a href=\"https://thoughtbot.com/blog/a-case-for-query-objects-in-rails\">objects</a> that addressed the read part.</p>\n\n<p>I also vaguely recall a quote from <a href=\"https://adam.pohorecki.pl/blog/2013/06/27/bogus-talk-at-drug/\">Adam Pohorecki on a DRUG meetup</a> that you can get 80% benefits out of Repository by putting 20% effort into shaping ActiveRecord like this:</p>\n<div class=\"highlight\"><pre class=\"highlight ruby\"><code><span class=\"k\">class</span> <span class=\"nc\">Transaction</span>\n  <span class=\"k\">def</span> <span class=\"nc\">self</span><span class=\"o\">.</span><span class=\"nf\">of_id</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">)</span>\n    <span class=\"n\">find</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">)</span>\n  <span class=\"k\">end</span>\n\n  <span class=\"k\">def</span> <span class=\"nc\">self</span><span class=\"o\">.</span><span class=\"nf\">last_not_pending_of_user_id</span><span class=\"p\">(</span><span class=\"n\">user_id</span><span class=\"p\">)</span>\n    <span class=\"n\">where</span><span class=\"p\">.</span><span class=\"nf\">not</span><span class=\"p\">(</span><span class=\"ss\">status: </span><span class=\"s2\">\"pending\"</span><span class=\"p\">).</span><span class=\"nf\">where</span><span class=\"p\">(</span><span class=\"ss\">user_id: </span><span class=\"n\">user_id</span><span class=\"p\">).</span><span class=\"nf\">order</span><span class=\"p\">(</span><span class=\"ss\">:id</span><span class=\"p\">).</span><span class=\"nf\">last</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>It relies very much on the discipline of team \u2014 to treat <code>ActiveRecord::Base</code> methods as &ldquo;private&rdquo; and only access the model by the application-specific class methods.</p>\n\n<p>This the repository I&rsquo;d make today, without any external dependencies in the framework you already have:</p>\n<div class=\"highlight\"><pre class=\"highlight ruby\"><code><span class=\"k\">class</span> <span class=\"nc\">TransactionRepository</span>\n  <span class=\"k\">class</span> <span class=\"nc\">Record</span> <span class=\"o\">&lt;</span> <span class=\"no\">ActiveRecord</span><span class=\"o\">::</span><span class=\"no\">Base</span>\n    <span class=\"nb\">self</span><span class=\"p\">.</span><span class=\"nf\">table_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"transactions\"</span>\n  <span class=\"k\">end</span>\n  <span class=\"n\">private_constant</span> <span class=\"ss\">:Record</span>\n\n  <span class=\"no\">Transaction</span> <span class=\"o\">=</span> <span class=\"no\">Data</span><span class=\"p\">.</span><span class=\"nf\">define</span><span class=\"p\">(</span><span class=\"no\">Record</span><span class=\"p\">.</span><span class=\"nf\">attribute_names</span><span class=\"p\">.</span><span class=\"nf\">map</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"ss\">:to_sym</span><span class=\"p\">))</span>\n\n  <span class=\"k\">class</span> <span class=\"o\">&lt;&lt;</span> <span class=\"nb\">self</span>\n    <span class=\"k\">def</span> <span class=\"nf\">of_id</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">)</span>\n      <span class=\"n\">as_struct</span><span class=\"p\">(</span><span class=\"no\">Record</span><span class=\"p\">.</span><span class=\"nf\">find</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">))</span>\n    <span class=\"k\">end</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">last_not_pending_of_user_id</span><span class=\"p\">(</span><span class=\"n\">user_id</span><span class=\"p\">)</span>\n      <span class=\"n\">as_struct</span><span class=\"p\">(</span><span class=\"no\">Record</span><span class=\"p\">.</span><span class=\"nf\">where</span><span class=\"p\">.</span><span class=\"nf\">not</span><span class=\"p\">(</span><span class=\"ss\">status: </span><span class=\"s2\">\"pending\"</span><span class=\"p\">).</span><span class=\"nf\">where</span><span class=\"p\">(</span><span class=\"ss\">user_id: </span><span class=\"n\">user_id</span><span class=\"p\">).</span><span class=\"nf\">order</span><span class=\"p\">(</span><span class=\"ss\">:id</span><span class=\"p\">).</span><span class=\"nf\">last</span><span class=\"p\">)</span>\n    <span class=\"k\">end</span>\n\n    <span class=\"kp\">private</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">as_struct</span><span class=\"p\">(</span><span class=\"n\">record</span><span class=\"p\">)</span>\n      <span class=\"no\">Transaction</span><span class=\"p\">.</span><span class=\"nf\">new</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">record</span><span class=\"p\">.</span><span class=\"nf\">attributes</span><span class=\"p\">.</span><span class=\"nf\">symbolize_keys</span><span class=\"p\">)</span>\n    <span class=\"k\">end</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>Let&rsquo;s dissect this sample a bit.</p>\n\n<ol>\n<li><code>TransactionRepository</code> and its public methods form the API. Since it takes no dependencies and carries no state within its lifecycle, the methods are on the singleton. These are the only ways to access the data and the surface is very limited.</li>\n<li><code>TransactionRepository::Record</code> is the ActiveRecord class. We have to point to its database table with <code>self.table_name</code>, since its namespace is &ldquo;unconventional&rdquo; to the framework mechanics. We may use <code>Record</code> within the repository and to implement its functionality. This constant is not available outside the repository \u2014 encapsulation is fulfilled.</li>\n<li>Return values of repository queries are immutable structs. They&rsquo;re not <code>ActiveRecord::Relation</code>. They&rsquo;re not <code>ActiveRecord::Base</code> instances either.</li>\n</ol>\n\n<p>Does this approach have drawbacks? It certainly does. Like everything else it&rsquo;s an art of choice. We&rsquo;re trading convenience off in one area for predictability and maintainability in the other. YMMV.</p>\n\n<p>Where vast ActiveRecord surface shines the most is the view layer and the numerous framework helpers built on top of it. We don&rsquo;t get that benefits with our structs. We might get back some of them by including <code>ActiveModel::Naming</code> behaviours.</p>\n\n<p>Does this approach have any alternatives? The CQRS \u2014 a separation of write and read models, where there was previously one, could be a viable option for some. Given that writes and reads are implemented and optimised differently, the ActiveRecord fits the read part perfectly. It is my preferred vehicle to implement Read Model on top of denormalised SQL database tables in Rails.</p>"
  },
  "Gusto": {
    "title": "Unraveling a Spaghetti Model",
    "xmlUrl": "https://engineering.gusto.com/rss/",
    "htmlUrl": "http://engineering.gusto.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.gusto.com/rss/",
      "value": "Unraveling a Spaghetti Model"
    },
    "summary": "In many established Ruby on Rails applications, there are often a couple of classes that become entangled with the rest of the code base. These early models start small and simple, possibly present\u2026",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.gusto.com/rss/",
      "value": "In many established Ruby on Rails applications, there are often a couple of classes that become entangled with the rest of the code base. These early models start small and simple, possibly present\u2026"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.gusto.com/unraveling-a-spaghetti-model/"
      }
    ],
    "link": "https://engineering.gusto.com/unraveling-a-spaghetti-model/",
    "id": "659de61636ff450001d43366",
    "guidislink": false,
    "tags": [
      {
        "term": "Ruby On Rails",
        "scheme": null,
        "label": null
      },
      {
        "term": "Modular Monolith",
        "scheme": null,
        "label": null
      },
      {
        "term": "Modularization",
        "scheme": null,
        "label": null
      },
      {
        "term": "Spaghetti Model",
        "scheme": null,
        "label": null
      },
      {
        "term": "Packwerk",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Todd Sedano"
      }
    ],
    "author": "Todd Sedano",
    "author_detail": {
      "name": "Todd Sedano"
    },
    "published": "Thu, 11 Jan 2024 19:03:16 GMT",
    "published_parsed": [
      2024,
      1,
      11,
      19,
      3,
      16,
      3,
      11,
      0
    ],
    "media_content": [
      {
        "url": "https://engineering.gusto.com/content/images/2024/01/1_ubtAILPxBLYrrX49v7IWHA.jpg",
        "medium": "image"
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.gusto.com/rss/",
        "value": "<figure class=\"kg-card kg-image-card\"><img alt=\"Unraveling a Spaghetti Model\" class=\"kg-image\" height=\"1095\" src=\"https://engineering.gusto.com/content/images/2024/01/1_ubtAILPxBLYrrX49v7IWHA-1.jpg\" width=\"1600\" /></figure><img alt=\"Unraveling a Spaghetti Model\" src=\"https://engineering.gusto.com/content/images/2024/01/1_ubtAILPxBLYrrX49v7IWHA.jpg\" /><p>In many established Ruby on Rails applications, there are often a couple of classes that become entangled with the rest of the code base. These early models start small and simple, possibly present for the first commit, but over time, the rest of the code base becomes entangled with them.</p><p>Some call them god objects (omniscient or all-knowing objects) since they reference a large number of other objects and often have unrelated methods. It&#x2019;s a well-known anti-pattern or code smell [<a href=\"https://amzn.to/3uijk3p?ref=engineering.gusto.com\" rel=\"noopener\">1996 Reference</a>].</p><p>In Gusto&#x2019;s <a href=\"https://engineering.gusto.com/laying-the-cultural-and-technical-foundation-for-big-rails/\" rel=\"noopener\">journey</a> to create a modularized monolith, we leverage <a href=\"https://github.com/Shopify/packwerk?ref=engineering.gusto.com\" rel=\"noopener\">Packwerk</a> to move domain concepts into packs. For example. we created a <code>payments</code> pack and then moved all the models, controllers, views, services, and specs needed for that domain. With all the code in packs, we created a public API for the rest of the code to access that domain&#x2019;s interface. What&#x2019;s left are our &#x201c;spaghetti&#x201d; models. They are called spaghetti models because they are entangled with all the domain&#x2019;s code (via associations) and contain domain code (via methods) that belong somewhere else. In this blog series, I&#x2019;ll share how I tackled our largest spaghetti model.</p><p><strong>Tackling spaghetti models can feel overwhelming</strong>. It took years for them to form and untangling the mess can feel like a Gordian knot with no clear starting place. At Gusto, we have two main spaghetti models: company and employee. When I first started untangling the company spaghetti model, I didn&#x2019;t know where to start. The other members of my team were concerned about whether we could even tackle the problem. Here&#x2019;s a class with 11 years&#x2019; worth of experience, 408 methods, 195 associations, and 51 columns. Engineers on other teams are afraid to touch it: &#x201c;If you modify it, it might break our business-critical payroll. It&#x2019;s so entangled.&#x201d;</p><p>So with a bit of audacity, naivety, and experience, I picked up my chisel and slowly started chipping away at it. We know from <a href=\"https://www.amazon.com/dp/1501111116/ref=cm_sw_r_as_gl_api_gl_i_G2RD1G57FQ9KTB2F4DTV?linkCode=ml2&amp;tag=sedano-20&amp;ref=engineering.gusto.com\" rel=\"noopener\">Angela Duckworth&#x2019;s book</a>, that grit is the secret to outstanding achievement. Fortunately, I kept chiseling away at our spaghetti model.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Unraveling a Spaghetti Model\" class=\"kg-image\" height=\"1106\" src=\"https://cdn-images-1.medium.com/max/1600/1*Pv0Ofeus8FkdpqBfn9JUQA.png\" width=\"1794\" /><figcaption><span style=\"white-space: pre-wrap;\">Number of company model methods over&#xa0;time</span></figcaption></figure><p><strong>This is the story of my journey.</strong> These techniques worked well for us. I wanted a safe removal and refactoring of code without breaking the system. Feel free to try the techniques in a different order and let me know about your journey.</p><p><strong>Objective: Move domain concepts into domain modules.</strong> In our system, the Company model represents a business that wants to use our products. Ideally, our Company model would only contain code related to the company&#x2019;s identity (business name, tax number, legal trading name, id). However, most of the stuff on the Company model was domain concepts that belong in different modules or packs. In our project, we split our codebase into packs with private and public APIs (see <a href=\"https://github.com/rubyatscale?ref=engineering.gusto.com\" rel=\"noopener\">Ruby At Scale</a> for more information). My refactors then moved methods from the company or its concerns to domain packs. Our long-term goal is a slim company model that is only identity information.</p><p><strong>Objective: Clean boundaries. </strong>In our ideal system,<strong> </strong>public APIs return simple ruby objects so that client code can not leverage associations and other Ruby on Rails convenience methods. Private APIs can return ActiveRecord models. Code calling other domains should use public APs. Instead of passing a company rails model around, we pass a company_id or a company value object.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Unraveling a Spaghetti Model\" class=\"kg-image\" height=\"1110\" src=\"https://cdn-images-1.medium.com/max/1600/1*-W4IyGGMRrvb2aa8vqLAmg.png\" width=\"1782\" /><figcaption><span style=\"white-space: pre-wrap;\">Number of company model associations over&#xa0;time</span></figcaption></figure><h3 id=\"goal-1-prevent-the-model-from-getting-worse\">Goal 1: Prevent the model from getting&#xa0;worse</h3><p>Our first step is to write tests to prevent other developers from adding more methods, associations, and columns. See <a href=\"https://medium.com/p/26afde018ebe/edit?ref=engineering.gusto.com\">Add Tests To Stop the Growing Spaghetti Model </a>for details. &#xa0;</p><p>Honestly, I didn&#x2019;t start here, but once I noticed that other developers were still adding to the company model, we wrote some tests. The tests provide an automatic feedback mechanism for developers.</p><h3 id=\"goal-2-examine-the-database\">Goal 2: Examine the&#xa0;database</h3><p>I started with an audit of the model. I skimmed through each method, trying to see where to start. After the read-through, I then looked at the database columns. I noticed that some of these had not been written in years. I chose to clean up our database table before taking anything else. After getting familiar with the columns, I then removed dead methods and started inlining the code. See <a href=\"https://engineering.gusto.com/removing-dead-columns-in-rails/\" rel=\"noreferrer\">Safely Removing Dead Columns</a> for details.</p><h3 id=\"goal-3-move-domain-logic-to-domain-packs\">Goal 3: Move domain logic to domain&#xa0;packs</h3><p>Shrinking a spaghetti model is removing all the code that doesn&#x2019;t belong there. A typical ActiveRecord Model will have:</p><ul><li>columns</li><li>methods</li><li>associations (has_many, has_one, belongs_to)</li><li>lifecycle callbacks (after_create, before_save,&#xa0;&#x2026;)</li><li>validations</li><li>ActiveSupport::Concerns</li><li>mixins</li><li>delegated methods</li><li>scopes</li></ul><p>My job was to remove all the junk that didn&#x2019;t belong there.&#xa0;</p><h4 id=\"what-to-work-on-first\">What to work on&#xa0;first?</h4><p>I went through the spaghetti model and moved domain logic into domain packs. After moving some methods, associations, and callbacks, I found that some refactors were simpler than others. From easiest to hardest:</p><ol><li>methods are the easiest</li><li>ActiveSupport::Concerns (*)</li><li>infrequently referenced associations</li><li>lifecycle callback methods</li><li>columns</li><li>frequently referenced associations are the hardest, and it may be that we&#x2019;ll never remove all of them</li></ol><p>(*) Since ActiveSupport::Concerns serve as inline code, they can contain methods, associations, and lifecycle callbacks. To address ActiveSupport::Concerns, I used the same tactics for addressing methods, associations, and lifecycle callbacks.</p><h4 id=\"tactics\">Tactics</h4><p>A spaghetti model is a collection of methods, associations, scopes, call-backs, and delegated methods. For each of these, I wrote a blog post on how I handled them:</p><p><strong>A. Dealing with method</strong>s [Part 3, coming soon]</p><ul><li>Safely remove dead methods</li><li>Safely inline wrapper method</li><li>Safely extract new public APIs</li><li>Safely extract new public APIs with value objects</li></ul><p><strong>B. Dealing with Active Model </strong>[Part 4, coming soon]</p><ul><li>Safely remove scopes</li><li>Safely remove associations</li></ul><p><strong>C. Dealing with ActiveSupport::Concerns </strong>[ Part 5, coming soon ]</p><ul><li>Safely remove active concerns (see other techniques)</li><li>Sleuthing</li></ul><p><strong>D. ActiveAdmin </strong>[Part 6, coming soon]</p><ul><li>Creating another model for ActiveAdmin ransack methods (coming soon)</li></ul><h3 id=\"tracking-deprecations\">Tracking Deprecations&#xa0;</h3><p>In each of the safe techniques listed in the Tactics section, I leveraged ActiveSupport::Deprecation.warn to verify that the method or association or lifecycle callback was no longer used in production. I would wait until I felt it was safe to remove the code from the system. To help me track my merged deprecation warnings, I used a simple spreadsheet.</p><p>|------------|------------------|--------------------|--------------------|<br />| Date Added | Class            | added by           | removed by         |<br />|------------|------------------|--------------------|--------------------|<br />| 2023/06/14 | company          | &lt;pull request url&gt; | &lt;pull request url&gt; |<br />| 2023/06/15 | company          | &lt;pull request url&gt; | &lt;pull request url&gt; |<br />| 2023/07/01 | company          | &lt;pull request url&gt; |                    |<br />| 2023/07/15 | bank_accountable | &lt;pull request url&gt; |                    |<br />|------------|------------------|--------------------|--------------------|</p><p>Whenever I had a few minutes between meetings, I&#x2019;d look at this table to see if any deprecated methods or associations were ready to be deleted. I then checked DataDog to verify that nothing had used the method in the last few weeks. I&#x2019;d then remove the code for good.</p><h3 id=\"conclusion\">Conclusion</h3><p>By following popular and espoused Ruby on Rails patterns, and with a lack of investment in deliberate work on architecture, long-lived code bases foster spaghetti models. In this blog post, I provide a top-level strategy for tackling spaghetti models with follow-up blog posts digging into specific tactics.</p><p>In time, your code base will have less chaos and will be humming along.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Unraveling a Spaghetti Model\" class=\"kg-image\" height=\"1664\" src=\"https://cdn-images-1.medium.com/max/1600/1*g-Um8pNYOmNVIIZMiZgGrQ.jpeg\" width=\"2432\" /></figure><p><em>Originally published at </em><a href=\"https://sedano.org/toddsedano/2023/07/27/unraveling-a-spaghetti-model.html?ref=engineering.gusto.com\" rel=\"noopener\"><em>https://sedano.org</em></a><em> on July 27, 2023.</em></p>"
      }
    ]
  },
  "Honeybadger": {
    "title": "Deploy a Rails app to a VPS with Kamal",
    "xmlUrl": "http://blog.honeybadger.io/feed.xml",
    "htmlUrl": "http://blog.honeybadger.io/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.honeybadger.io/blog/feed.xml",
      "value": "Deploy a Rails app to a VPS with Kamal"
    },
    "links": [
      {
        "rel": "alternate",
        "href": "https://www.honeybadger.io/blog/deploy-rails-with-kamal/",
        "type": "text/html"
      }
    ],
    "link": "https://www.honeybadger.io/blog/deploy-rails-with-kamal/",
    "id": "https://www.honeybadger.io/blog/deploy-rails-with-kamal/",
    "guidislink": false,
    "published": "2023-12-14T00:00:00+00:00",
    "published_parsed": [
      2023,
      12,
      14,
      0,
      0,
      0,
      3,
      348,
      0
    ],
    "updated": "2024-01-10T07:16:29+00:00",
    "updated_parsed": [
      2024,
      1,
      10,
      7,
      16,
      29,
      2,
      10,
      0
    ],
    "authors": [
      {
        "name": "Roel Bondoc"
      }
    ],
    "author_detail": {
      "name": "Roel Bondoc"
    },
    "author": "Roel Bondoc",
    "summary": "Building your app is only half the battle. The other half is deploying it. Kamal makes it easy to deploy a Rails app without a PhD in infrastructure and operations.",
    "summary_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.honeybadger.io/blog/feed.xml",
      "value": "Building your app is only half the battle. The other half is deploying it. Kamal makes it easy to deploy a Rails app without a PhD in infrastructure and operations."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.honeybadger.io/blog/feed.xml",
        "value": "<p><strong><a href=\"https://rubyonrails.org\">Ruby on Rails</a> has always been at the forefront of developer productivity, and building robust, highly interactive web applications has never been easier.</strong> Rails has been accurately described as <a href=\"https://developers.slashdot.org/story/21/12/19/2043226/ruby-on-rails-creator-touts-70-as-one-person-framework-the-way-it-used-to-be\">the one-person framework</a>. However, building your app is only half the battle. The other half is publishing it for others to use. Unfortunately, being able to deploy your application has always been an afterthought for most developers. The &quot;one-person framework&quot; doesn't carry through when it comes to deployment and operations unless you have specialized knowledge of building out infrastructure or pay others large sums of money to do it for you\u2014until now. With the release of Kamal, the &quot;one-person framework&quot; idea completes the stack from end to end, allowing a single developer to do more with fewer resources.</p>\n\n<p><a href=\"https://kamal-deploy.org\">Kamal</a> is a new deployment tool created by the folks at <a href=\"https://37signals.com\">37Signals</a>. It allows you to codify the deployment process into a single file and abstract many complicated bits that most applications don't need to worry about. It does this by using a combination of software like <a href=\"https://www.docker.com\">Docker</a> containers and <a href=\"https://traefik.io\">Traefik</a>. Out of the box, along with Rails, you get a complete package that will get you production-ready in no time.</p>\n\n<h2 id=\"how-it-works\">How it works</h2>\n\n<p>Kamal runs your web application in a Docker container on a server. It then uses a web server called Traefik to handle the network traffic between the Docker container and the internet.</p>\n\n<p>The neat thing is that whenever you deploy a new version of your application, Kamal will do the following:</p>\n\n<ol>\n<li>Build a new version of a Docker image.</li>\n<li>Start a new container of that image.</li>\n<li>Ensure that the new container is healthy.</li>\n<li>Tell Traefik to start directing traffic to the new container.</li>\n<li>Stop the old container.</li>\n</ol>\n\n<p>The benefit is that you can theoretically have zero downtime and blue/green deploys.</p>\n\n<p>Kamal can also help scale your application horizontally by deploying your containers to multiple servers\u2014but you'll need to load balance the servers yourself.</p>\n\n<h2 id=\"setup\">Setup</h2>\n\n<p>Install the Kamal gem on your local computer:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>gem install kamal\n</code></pre></div>\n<p>Then, in your Rails application, initialize the setup:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>kamal init\n</code></pre></div>\n<p>The <code>kamal init</code> command will create two files. <code>config/deploy.yml</code> contains everything Kamal will use to deploy your app, and <code>.env</code> has secret environment variables used to configure your app (and should not get committed to your repo).</p>\n\n<h2 id=\"acquire-a-vps\">Acquire a VPS</h2>\n\n<p>Before configuring Kamal, let's discuss where we'll host our web app. There are lots of great options to choose from. An excellent cost-effective choice is a Virtual Private Server (VPS). A VPS is cost-effective because you are essentially sharing hardware with other customers. Although completely isolated from each other access-wise, you may have to contend with others for resources, which means some CPU bandwidth, memory, and storage limitations. A VPS should be fine for most applications, especially for this tutorial.</p>\n\n<p>When choosing a VPS hosting provider, find one with a data center closest to you for faster response times. When selecting the level of resources, at a minimum, I'd recommend something with at least 1GB of memory for Rails applications. Also, choose a Debian-based Linux for the OS, as it's a popular choice, and it will be easy to find help if you run into trouble. Make sure that you have SSH access to the VPS. After creating your VPS, make a note of the published IP Address.</p>\n\n<h2 id=\"acquire-a-domain-name\">Acquire a domain name</h2>\n\n<p>If you plan to enable TLS/SSL for your application, you'll need to register a domain name and configure the DNS with a CNAME record to point to the IP address of your VPS.</p>\n\n<h2 id=\"docker-image-registry\">Docker image registry</h2>\n\n<p>Kamal uses Docker containers for deployment. It takes your <code>Dockerfile</code> and builds an image that will be used on your server. This image must be uploaded to a &quot;registry.&quot; However, there are many free options to choose from, such as <a href=\"https://hub.docker.com\">DockerHub</a>, <a href=\"https://github.com\">GitHub</a>, or <a href=\"https://www.digitalocean.com\">DigitalOcean</a>. You'll need to sign up for one of these services and note the username and password you'll use to log in (or access tokens if applicable).</p>\n\n<h2 id=\"configuration\">Configuration</h2>\n\n<p>Now that you have your VPS and registry login credentials, we can start configuring the deployment. At a minimum, your <code>config/deploy.yml</code> file should look like this:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>service: my-app\nimage: &lt;your-registry-username&gt;/my-app\nservers:\n  web:\n    hosts:\n      - &lt;your vps ip address&gt;\nregistry:\n  username:\n    - &lt;your-registry-username&gt;\n  password:\n    - KAMAL_REGISTRY_PASSWORD\n\n# If you use another service like DigitalOcean:\n# registry:\n#   server: registry.digitalocean.com\n#   username:\n#     - &lt;your-registry-username&gt;\n#   password:\n#     - KAMAL_REGISTRY_PASSWORD\n\nenv:\n  secret:\n    - RAILS_MASTER_KEY\n</code></pre></div>\n<p>Fill in the required values as needed. Two environment variables will need our attention: <code>KAMAL_REGISTRY_PASSWORD</code> and <code>RAILS_MASTER_KEY</code>. These get populated by the <code>.env</code> file upon deployment. Edit your <code>.env</code> file to look something like this:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>KAMAL_REGISTRY_PASSWORD=&lt;your-registry-password-or-token&gt;\nRAILS_MASTER_KEY=&lt;your-rails-production.key-value&gt;\n</code></pre></div>\n<p>These values can be safely stored here as they shouldn't be committed to your repo, and they get securely transferred to the VPS when deployed. The <code>RAILS_MASTER_KEY</code> can be found in <code>config/credentials/production.key</code>. If it doesn't exist, you can create it by running the following:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>rails credentials:edit --environment=production\n</code></pre></div>\n<h2 id=\"deployment\">Deployment</h2>\n\n<p>The first thing you'll want to do is run the server bootstrap command:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>kamal server bootstrap\n</code></pre></div>\n<p>This command will SSH into your VPS and set up and install everything necessary for Kamal to run your application. It's a good idea to run this separately first in case of any failures; if there are any, they'll be easier to spot and diagnose. It only needs to be run once.</p>\n\n<p>Next, we can start the deploy:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>kamal deploy\n</code></pre></div>\n<p>The <code>deploy</code> command will start the Docker build process locally and then push the image to your registry. Next, Kamal will boot a Traefik container on your server. Kamal will then start the healthcheck process container to ensure it boots and runs without issues. If successful, it'll start a permanent container that Traefik will see and begin directing traffic to it. If everything goes well, your Rails application should be available on port 80 of your VPS. Of course, Rails requires SSL by default for newer applications and will redirect you if you try to access it.</p>\n\n<h2 id=\"tls-ssl\">TLS/SSL</h2>\n\n<p>In production, you'll want to set up your web application with TLS/SSL to protect your users' privacy. Luckily, the Traefik server has built-in functionality to help us do that! We'll need to make a few modifications to <code>config/deploy.yml</code>. First, tell Kamal that our Traefik server requires TLS/SSL. Add the following to <code>deploy.yml</code>.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>traefik:\n  options:\n    publish:\n      - 443:443\n    volume:\n      - \"letsencrypt:/letsencrypt\"\n  args:\n    entrypoints.web.address: ':80'\n    entrypoints.websecure.address: ':443'\n    certificatesResolvers.letsencrypt.acme.httpchallenge: true\n    certificatesResolvers.letsencrypt.acme.httpchallenge.entrypoint: web\n    certificatesResolvers.letsencrypt.acme.email: &lt;your email address here&gt;\n    certificatesResolvers.letsencrypt.acme.storage: /letsencrypt/acme.json\n</code></pre></div>\n<p>This config tells Traefik to use LetsEncrypt to acquire an SSL certificate and store it in a mounted volume. A mounted volume is crucial because it allows the certificate to persist if the container or server restarts. Port <code>443</code> is the default SSL port. All traffic that arrives via SSL can be tagged as coming from the <code>websecure</code> entry point.</p>\n\n<p>Next, we need to tell Traefik where to send this SSL traffic. Modify the servers part of the <code>deploy.yml</code>:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>servers:\n  web:\n    hosts:\n      - &lt;your vps ip address&gt;\n    labels:\n      traefik.http.routers.maildown-web.rule: 'Host(`&lt;your domain name&gt;`)'\n      traefik.http.routers.maildown-web.entrypoints: websecure\n      traefik.http.routers.maildown-web.tls.certresolver: letsencrypt\n</code></pre></div>\n<p>By adding these Docker labels to your application container, Traefik will act as an SSL termination point and direct all <code>websecure</code> traffic to the application. Let's deploy these changes:</p>\n\n<p>First, we reboot Traefik to pick up the new configuration:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>kamal traefik reboot\n</code></pre></div>\n<p>Then, we redeploy our application to pick up the new labels:</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>kamal deploy\n</code></pre></div>\n<p>If everything goes well, you can now access your web app via https://.</p>\n\n<h2 id=\"where-to-go-from-here\">Where to go from here</h2>\n\n<p>I hope that you've found this introduction to Kamal useful. There is a lot more we can do with Kamal. Look for more blog posts about Kamal coming soon. In the meantime, check out some of these links for other Kamal features:</p>\n\n<ul>\n<li><a href=\"https://kamal-deploy.org/docs/configuration#using-accessories-for-database-cache-search-services\">Accessories</a></li>\n<li><a href=\"https://kamal-deploy.org/docs/configuration#using-volumes\">Volumes</a></li>\n</ul>"
      }
    ]
  },
  "Stitch Fix": {
    "title": "Towards Service Deployment Agility",
    "xmlUrl": "https://multithreaded.stitchfix.com/feed.xml",
    "htmlUrl": "http://multithreaded.stitchfix.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://multithreaded.stitchfix.com/feed.xml",
      "value": "Towards Service Deployment Agility"
    },
    "summary": "<h1 id=\"introduction\">Introduction</h1>\n<p>At Stitch Fix, our data platform is designed to be self-service, with our users taking ownership of their own ETL, models, and microservices. To support this approach, the platform team prioritizes user autonomy and end-to-end tooling in their tooling designs, minimizing the involvement of platform engineers in day-to-day engineering and data science workflows.</p>\n\n<p>We regularly evaluate our infrastructure against new frameworks to assess the costs and benefits of potential updates. Last year, we transitioned our <a href=\"https://multithreaded.stitchfix.com/blog/2022/03/14/spark-eks/\">EMR-based Spark infrastructure to EKS</a> to take advantage of its benefits.  The next logical step was to re-examine how our core platform services were deployed and updated, especially those still deployed directly to instances.</p>\n\n<p>We also recognized that Kubernetes, a popular open-source system for handling the deployment of containerized applications, could provide benefits for microservice orchestration beyond just batch compute infrastructure.  Our existing instance-based service deployment framework was beginning to show its age in areas that were critical for Stitch Fix, such as the development lifecycle\u2019s velocity. As we saw an opportunity to leverage Kubernetes to address these issues, we identified pain points in our service deployment ecosystem.</p>\n\n<h2 id=\"pain-points\">Pain Points</h2>\n<ol>\n  <li>\n    <p><strong>Building and deploying services can be a time-consuming process</strong>, involving multiple steps and dependencies. We needed a solution that would streamline this process and enable us to deploy services more efficiently.</p>\n  </li>\n  <li>\n    <p><strong>Polyglot environments</strong>, where multiple programming languages are used within the same system, can present a challenge for deployment standardization. At Stitch Fix, we use a variety of languages, including Python, Golang, Nodejs, and JVM (Java and Scala), making it difficult to establish consistent deployment practices across the board. We needed a way to deploy polyglot environments in a standardized and efficient manner.</p>\n  </li>\n  <li>\n    <p><strong>Autoscaling and rollback capabilities</strong> are essential for managing service deployment at scale. At Stitch Fix, we found that our existing infrastructure had limited capabilities in these areas. We needed a solution that would enable us to easily scale services up and down as needed, and quickly rollback changes if necessary.</p>\n  </li>\n  <li>\n    <p><strong>Traffic segmentation</strong> is an important aspect of service deployment, enabling us to direct traffic to different parts of our infrastructure based on various factors. However, we found that we were using different solutions for traffic segmentation across our various services, which created inconsistencies and added complexity to our infrastructure. We needed a solution that would enable us to manage traffic segmentation in a consistent and efficient manner.</p>\n  </li>\n</ol>\n\n<p>We evaluated industry options and were pleased to realize that we could address our pain points by adopting open source tools and applying a dash of Stitch Fix flavor. And, so we did: introducing the <strong>Service Operator Service (SOS)</strong>!</p>\n\n<h1 id=\"introducing-service-operator-service-sos\">Introducing: Service Operator Service (SOS)</h1>\n<h2 id=\"the-philosophy\">The Philosophy</h2>\n<p>SOS is a service deployment framework based on Kubernetes, designed to enable Stitch Fix data platform engineers, data engineers, and data scientists to manage their own deployment lifecycle through a self-service approach.</p>\n\n<p>With SOS, end users can interact with a streamlined set of tools, without the need to learn or be aware of Kubernetes. Meanwhile, maintainers can remain agile with industry-standard tools by leveraging cloud-native open-source software such as <a href=\"https://knative.dev/\">Knative</a> and building on top of a thin layer of opinionated APIs. Knative offers a simplified abstraction that streamlines certain aspects of the Kubernetes application deployment process, including the management of network configurations.</p>\n\n<figure>\n    <img src=\"https://multithreaded.stitchfix.com/assets/posts/2023-09-19-towards-service-deployment-agility/sos-bov-architecture.png\" style=\"width: 100%;\" />\n    <figcaption style=\"text-align: center;\">Simplified diagram of the SOS architecture presenting the main components of the system.</figcaption>\n</figure>\n\n<h2 id=\"addressing-the-pain-points\">Addressing the Pain Points</h2>\n<p>The design of SOS focused on a set of key features centered around addressing our previously-detailed pain points:</p>\n\n<h3 id=\"fast-deployments\">Fast Deployments</h3>\n<p>Deployments in SOS are lightning-fast, thanks to two design decisions: we use Knative to reduce overhead, and we run all services as artifacts on standardized Docker images.</p>\n\n<p>Knative\u2019s quick pod provisioning is a major advantage, as we\u2019ve discovered firsthand - our deployments can be up and running in under 10 seconds. One of the ways Knative achieves this is by using a shared load balancer for all deployments, which reduces the overhead of deploying a new service.</p>\n\n<p>In SOS, each revision of a service is a self-contained artifact that runs on a curated Docker image specific to the service\u2019s language - Python, NodeJS, Golang, or JVM. This approach, while standard for Golang binaries and JVM jars, can be more challenging with Python due to its less-robust dependency management and portability issues.</p>\n\n<p>With this in mind, we set up a remote build process for each supported language that can compile an artifact on the same Docker image that the artifact would be run on. Each of the languages artifacts are defined as follows:</p>\n<ul>\n  <li>Golang - Golang binary</li>\n  <li>JVM - executable assembly jar file</li>\n  <li>Python - <a href=\"https://shiv.readthedocs.io/en/latest/\">shiv archive</a> creates self-contained Python zipapps</li>\n  <li>NodeJS - <a href=\"https://github.com/vercel/ncc\">ncc</a> compiles a NodeJS project into a single file</li>\n</ul>\n\n<p>By bundling all dependencies within the artifact, we save significant time - anywhere from a few seconds to several minutes - that would otherwise be spent installing dependencies during runtime. As a result, services can enter a ready state more quickly. For services that have a more complex set of Python dependencies, we\u2019ve seen time savings of more than 5 minutes!</p>\n\n<h3 id=\"standardized-build-and-deployment-processes\">Standardized Build and Deployment Processes</h3>\n<h4 id=\"build-process\">Build Process</h4>\n<p>In addition to infrastructure work, we realized that for SOS to succeed, it was essential to offer a streamlined and straightforward method for users to create their artifacts. Without a standardized build and deploy process, users would have to sift through documentation to set up their local environments and handle processor architectures. We wanted to alleviate these overheads and provide users a least-resistance path to start experiencing SOS \u2013  batteries <em>are</em> included!</p>\n\n<p>To address this issue, we established a command-line tool where running <code class=\"language-plaintext highlighter-rouge\">sos build</code> in your project directory will automatically detect project metadata (such as if it\u2019s a Python or Golang deployment), perform integrity checks, and launch a remote build job that creates the SOS artifact on the same Docker image it would run on.</p>\n\n<figure>\n    <img src=\"https://multithreaded.stitchfix.com/assets/posts/2023-09-19-towards-service-deployment-agility/sos-build-deploy.png\" style=\"width: 100%;\" />\n    <figcaption style=\"text-align: center;\">We standardized the build process with a command-line tool that initiates remote build jobs, reducing user overhead in setting up environments and mitigating compatibility issues between runtime environments.</figcaption>\n</figure>\n\n<h4 id=\"deploy-process\">Deploy Process</h4>\n<p>We offer two interfaces for creating and updating service deployments in SOS: a Python client and a web-based UI built with React.</p>\n\n<p>The Python client allows users to declare their services as a DSL in a familiar Python ecosystem. To ensure consistent types, we synchronize data models between the SOS client and the SOS API using shared protobuf files. We will cover the Python client\u2019s user interface in more detail later.</p>\n\n<p>Our web-based UI allows users to easily review revision histories and adjust traffic policies. We have ensured feature parity between the Python client and the web UI, enabling our users to choose the interface that suits them best.</p>\n\n<figure>\n    <img src=\"https://multithreaded.stitchfix.com/assets/posts/2023-09-19-towards-service-deployment-agility/sos-ui.png\" style=\"width: 100%;\" />\n    <figcaption style=\"text-align: center;\">Our UI provides an alternative way to easily manage deployments. This screenshot shows how the UI can be used to adjust the traffic segmentation between different revisions.</figcaption>\n</figure>\n\n<h3 id=\"traffic-segmentation-and-responsive-autoscaling-over-multiple-axes\">Traffic Segmentation and Responsive Autoscaling Over Multiple Axes</h3>\n<p>SOS included traffic segmentation and responsive scaling as a key feature for several reasons. These features enabled faster deployments and rollbacks, which facilitated shorter development cycles. Moreover, because all metrics and logs are namespaced by the traffic segmentation, we gained much better insights into service behavior. This feature also made gradual traffic cutovers possible and allowed for fast autoscaling to handle traffic bursts while reducing costs by scaling down unused instances.</p>\n\n<p>For example, by setting services to use a minimum of zero instances, it is possible to make SOS services serverless. No pods would be provisioned until they receive traffic. Implementing this feature for our services allowed us to save significant costs on staging deployments and production services that receive less constant traffic.</p>\n\n<h1 id=\"the-sos-user-experience\">The SOS User Experience</h1>\n<h2 id=\"blissful-ignorance\">Blissful Ignorance</h2>\n<p>Users don\u2019t need to be aware that SOS runs on Kubernetes - all they need to do to start deploying services is install the SOS Python client!</p>\n\n<h2 id=\"decoupled-application-and-system\">Decoupled Application and System</h2>\n<p>SOS ensures that each user\u2019s new code deployment is immutable and has a unique ID, tied to an SOS artifact with its own dependencies. This decouples the system and application, setting clear boundaries and avoiding the issue of Nginx configs and secrets management bundled into an application\u2019s source code that we faced with our previous instance-based deployment.</p>\n\n<p>We wanted to avoid a scenario where users inherit and patch and layers of Docker images until they become unmaintainable black boxes. By running all service artifacts on top of curated Docker images, we avoided the problem of users managing their own Docker images. This made it easier to implement platform-wide changes over time, as we could patch and improve the Docker images without relying on users to rebuild their applications. This also allowed us to efficiently tweak and fine-tune the observability agents on the system.</p>\n\n<h2 id=\"single-source-of-truth\">Single Source of Truth</h2>\n<p>The SOS service itself is the source of truth for each deployment, so users don\u2019t need to manage multiple configurations for the same service. When deploying a service, the SOS service will merge any necessary files at the service level, which prevents confusion that can arise when configuration files are stored in different branches or exist only in a user\u2019s local environment.</p>\n\n<h2 id=\"the-experience\">The Experience</h2>\n<p>The SOS Python client is the tool that our users use to interact with SOS. Below are some examples of the SOS Python client and how a user would use it to define their service deployment.</p>\n\n<h3 id=\"service-creation\">Service Creation</h3>\n<p>Each SOS service correlates with a service that\u2019s created in Kubernetes.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">service</span> <span class=\"o\">=</span> <span class=\"n\">Service</span><span class=\"p\">(</span>\n  <span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service\"</span><span class=\"p\">,</span>\n  <span class=\"n\">owner_id</span><span class=\"o\">=</span><span class=\"s\">\":team:sfix_team_name\"</span><span class=\"p\">,</span>\n  <span class=\"n\">env</span><span class=\"o\">=</span><span class=\"s\">\"prod\"</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"creating-a-revision\">Creating a Revision</h3>\n<p>In SOS, a service can have multiple revisions, with each revision representing an immutable version of the service that can be deployed independently.</p>\n\n<p>The example below shows the minimal configurations to create a revision that deploys a Python artifact. The <code class=\"language-plaintext highlighter-rouge\">Artifact</code> is a self-contained Python artifact that has been deployed to Artifactory, which we use as our sink of artifacts.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">revision</span> <span class=\"o\">=</span> <span class=\"n\">Revision</span><span class=\"p\">(</span>\n  <span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service-5\"</span><span class=\"p\">,</span>\n  <span class=\"n\">artifact</span><span class=\"o\">=</span><span class=\"n\">Artifact</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service\"</span><span class=\"p\">,</span> <span class=\"n\">version</span><span class=\"o\">=</span><span class=\"s\">\"v0.0.16\"</span><span class=\"p\">),</span>\n  <span class=\"n\">python_config</span><span class=\"o\">=</span><span class=\"n\">PythonConfig</span><span class=\"p\">(</span>\n          <span class=\"n\">python_version</span><span class=\"o\">=</span><span class=\"s\">\"3.9\"</span><span class=\"p\">,</span>\n          <span class=\"n\">gunicorn_config</span><span class=\"o\">=</span><span class=\"n\">GunicornConfig</span><span class=\"p\">(</span><span class=\"n\">worker_class</span><span class=\"o\">=</span><span class=\"s\">\"gevent\"</span><span class=\"p\">),</span>\n          <span class=\"n\">app_module</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service.server:app\"</span><span class=\"p\">,</span>\n  <span class=\"p\">),</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">logging</span><span class=\"p\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"n\">service</span><span class=\"p\">.</span><span class=\"n\">add_revision</span><span class=\"p\">(</span><span class=\"n\">revision</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<p>Additional settings can be configured for more complex deployments, such as port number, environment variables, memory and CPU allocation, health checks, and thread and worker counts. Here\u2019s an example of how to set these configurations:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">revision</span> <span class=\"o\">=</span> <span class=\"n\">Revision</span><span class=\"p\">(</span>\n  <span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service-5\"</span><span class=\"p\">,</span>\n  <span class=\"n\">artifact</span><span class=\"o\">=</span><span class=\"n\">Artifact</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service\"</span><span class=\"p\">,</span> <span class=\"n\">version</span><span class=\"o\">=</span><span class=\"s\">\"v0.0.16\"</span><span class=\"p\">),</span>\n  <span class=\"n\">container</span><span class=\"o\">=</span><span class=\"n\">Container</span><span class=\"p\">(</span>\n          <span class=\"n\">port</span><span class=\"o\">=</span><span class=\"mi\">5001</span><span class=\"p\">,</span>\n          <span class=\"n\">env_vars</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">EnvVar</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s\">\"env_var\"</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"o\">=</span><span class=\"s\">\"env_value\"</span><span class=\"p\">)],</span>\n          <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">Resources</span><span class=\"p\">(</span><span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"s\">\"2G\"</span><span class=\"p\">,</span> <span class=\"n\">cpu</span><span class=\"o\">=</span><span class=\"s\">\"1000m\"</span><span class=\"p\">),</span>\n  <span class=\"p\">),</span>\n  <span class=\"n\">health_check</span><span class=\"o\">=</span><span class=\"n\">HealthCheck</span><span class=\"p\">(</span><span class=\"n\">liveness_probe</span><span class=\"o\">=</span><span class=\"s\">\"/\"</span><span class=\"p\">,</span> <span class=\"n\">readiness_probe</span><span class=\"o\">=</span><span class=\"s\">\"/\"</span><span class=\"p\">),</span>\n  <span class=\"n\">sf_env</span><span class=\"o\">=</span><span class=\"s\">\"prod\"</span><span class=\"p\">,</span>\n  <span class=\"n\">python_config</span><span class=\"o\">=</span><span class=\"n\">PythonConfig</span><span class=\"p\">(</span>\n          <span class=\"n\">python_version</span><span class=\"o\">=</span><span class=\"s\">\"3.9\"</span><span class=\"p\">,</span>\n          <span class=\"n\">gunicorn_config</span><span class=\"o\">=</span><span class=\"n\">GunicornConfig</span><span class=\"p\">(</span><span class=\"n\">worker_count</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">thread_count</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">worker_class</span><span class=\"o\">=</span><span class=\"s\">\"gevent\"</span><span class=\"p\">),</span>\n          <span class=\"n\">app_module</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service.server:app\"</span><span class=\"p\">,</span>\n  <span class=\"p\">),</span>\n  <span class=\"n\">autoscaling</span><span class=\"o\">=</span><span class=\"n\">Autoscaling</span><span class=\"p\">(</span><span class=\"n\">min_scale</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">),</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">logging</span><span class=\"p\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"n\">service</span><span class=\"p\">.</span><span class=\"n\">add_revision</span><span class=\"p\">(</span><span class=\"n\">revision</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<h3 id=\"set-traffic-for-new-revision\">Set Traffic for New Revision</h3>\n<p>We recognized the importance of providing robust support for traffic segmentation, as users should have confidence that deploying new code wouldn\u2019t negatively impact their entire system. By giving them complete control over the flow of traffic, they could confidently iterate on changes without fear of breaking everything. This was crucial to enabling faster development cycles and smoother rollbacks, as well as improving our understanding of service behavior through fine-grained traffic analysis.</p>\n\n<p>The following example shows how the newly created revision can be set to receive 100% traffic. However, to roll out changes more safely, traffic can be segmented between multiple revisions by adding more Route objects to the TrafficRoute.routes configuration. SOS\u2019s observability tooling can be used to monitor the traffic and ensure a smooth transition.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">service</span><span class=\"p\">.</span><span class=\"n\">add_traffic</span><span class=\"p\">(</span>\n    <span class=\"n\">Traffic</span><span class=\"p\">(</span>\n        <span class=\"n\">traffic_route</span><span class=\"o\">=</span><span class=\"n\">TrafficRoute</span><span class=\"p\">(</span>\n            <span class=\"n\">routes</span><span class=\"o\">=</span><span class=\"p\">[</span>\n                <span class=\"n\">Route</span><span class=\"p\">(</span>\n                    <span class=\"n\">percent</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span>\n                    <span class=\"n\">revision_id</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service-5\"</span><span class=\"p\">,</span>\n                    <span class=\"n\">dns_record_suffix</span><span class=\"o\">=</span><span class=\"s\">\"active\"</span><span class=\"p\">,</span>\n                <span class=\"p\">),</span>\n            <span class=\"p\">]</span>\n        <span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h1 id=\"the-present-and-the-future\">The Present and the Future</h1>\n<p>Most data platform services have already been migrated to SOS.  It hosts many critical services, including the components of our batch processor, <a href=\"https://github.com/stitchfix/flotilla-os\">job execution engine</a>, our metastore, configuration management service, Kafka connect cluster, ownership discovery service, and more! While there are some data science services deployed on SOS, most of the currently-deployed services are focused on powering our data platform.</p>\n\n<p>SOS aims to streamline the service lifecycle, yet its opinionated approach might not suit all deployments. Certain open-source tools align better with standard industry patterns. For instance, we deploy Trino directly onto Kubernetes and use a Helm Chart for Airflow. While SOS isn\u2019t a one-size-fits-all solution, it remains highly effective for the majority of our existing and future deployments.</p>\n\n<p>We are regularly improving the user experience of SOS by migrating existing services and building new ones on top of it. Our goal is to reduce the complexity of service deployment and continue to empower our data scientists and engineers at Stitch Fix to be more efficient and effective.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://multithreaded.stitchfix.com/feed.xml",
      "value": "<h1 id=\"introduction\">Introduction</h1>\n<p>At Stitch Fix, our data platform is designed to be self-service, with our users taking ownership of their own ETL, models, and microservices. To support this approach, the platform team prioritizes user autonomy and end-to-end tooling in their tooling designs, minimizing the involvement of platform engineers in day-to-day engineering and data science workflows.</p>\n\n<p>We regularly evaluate our infrastructure against new frameworks to assess the costs and benefits of potential updates. Last year, we transitioned our <a href=\"https://multithreaded.stitchfix.com/blog/2022/03/14/spark-eks/\">EMR-based Spark infrastructure to EKS</a> to take advantage of its benefits.  The next logical step was to re-examine how our core platform services were deployed and updated, especially those still deployed directly to instances.</p>\n\n<p>We also recognized that Kubernetes, a popular open-source system for handling the deployment of containerized applications, could provide benefits for microservice orchestration beyond just batch compute infrastructure.  Our existing instance-based service deployment framework was beginning to show its age in areas that were critical for Stitch Fix, such as the development lifecycle\u2019s velocity. As we saw an opportunity to leverage Kubernetes to address these issues, we identified pain points in our service deployment ecosystem.</p>\n\n<h2 id=\"pain-points\">Pain Points</h2>\n<ol>\n  <li>\n    <p><strong>Building and deploying services can be a time-consuming process</strong>, involving multiple steps and dependencies. We needed a solution that would streamline this process and enable us to deploy services more efficiently.</p>\n  </li>\n  <li>\n    <p><strong>Polyglot environments</strong>, where multiple programming languages are used within the same system, can present a challenge for deployment standardization. At Stitch Fix, we use a variety of languages, including Python, Golang, Nodejs, and JVM (Java and Scala), making it difficult to establish consistent deployment practices across the board. We needed a way to deploy polyglot environments in a standardized and efficient manner.</p>\n  </li>\n  <li>\n    <p><strong>Autoscaling and rollback capabilities</strong> are essential for managing service deployment at scale. At Stitch Fix, we found that our existing infrastructure had limited capabilities in these areas. We needed a solution that would enable us to easily scale services up and down as needed, and quickly rollback changes if necessary.</p>\n  </li>\n  <li>\n    <p><strong>Traffic segmentation</strong> is an important aspect of service deployment, enabling us to direct traffic to different parts of our infrastructure based on various factors. However, we found that we were using different solutions for traffic segmentation across our various services, which created inconsistencies and added complexity to our infrastructure. We needed a solution that would enable us to manage traffic segmentation in a consistent and efficient manner.</p>\n  </li>\n</ol>\n\n<p>We evaluated industry options and were pleased to realize that we could address our pain points by adopting open source tools and applying a dash of Stitch Fix flavor. And, so we did: introducing the <strong>Service Operator Service (SOS)</strong>!</p>\n\n<h1 id=\"introducing-service-operator-service-sos\">Introducing: Service Operator Service (SOS)</h1>\n<h2 id=\"the-philosophy\">The Philosophy</h2>\n<p>SOS is a service deployment framework based on Kubernetes, designed to enable Stitch Fix data platform engineers, data engineers, and data scientists to manage their own deployment lifecycle through a self-service approach.</p>\n\n<p>With SOS, end users can interact with a streamlined set of tools, without the need to learn or be aware of Kubernetes. Meanwhile, maintainers can remain agile with industry-standard tools by leveraging cloud-native open-source software such as <a href=\"https://knative.dev/\">Knative</a> and building on top of a thin layer of opinionated APIs. Knative offers a simplified abstraction that streamlines certain aspects of the Kubernetes application deployment process, including the management of network configurations.</p>\n\n<figure>\n    <img src=\"https://multithreaded.stitchfix.com/assets/posts/2023-09-19-towards-service-deployment-agility/sos-bov-architecture.png\" style=\"width: 100%;\" />\n    <figcaption style=\"text-align: center;\">Simplified diagram of the SOS architecture presenting the main components of the system.</figcaption>\n</figure>\n\n<h2 id=\"addressing-the-pain-points\">Addressing the Pain Points</h2>\n<p>The design of SOS focused on a set of key features centered around addressing our previously-detailed pain points:</p>\n\n<h3 id=\"fast-deployments\">Fast Deployments</h3>\n<p>Deployments in SOS are lightning-fast, thanks to two design decisions: we use Knative to reduce overhead, and we run all services as artifacts on standardized Docker images.</p>\n\n<p>Knative\u2019s quick pod provisioning is a major advantage, as we\u2019ve discovered firsthand - our deployments can be up and running in under 10 seconds. One of the ways Knative achieves this is by using a shared load balancer for all deployments, which reduces the overhead of deploying a new service.</p>\n\n<p>In SOS, each revision of a service is a self-contained artifact that runs on a curated Docker image specific to the service\u2019s language - Python, NodeJS, Golang, or JVM. This approach, while standard for Golang binaries and JVM jars, can be more challenging with Python due to its less-robust dependency management and portability issues.</p>\n\n<p>With this in mind, we set up a remote build process for each supported language that can compile an artifact on the same Docker image that the artifact would be run on. Each of the languages artifacts are defined as follows:</p>\n<ul>\n  <li>Golang - Golang binary</li>\n  <li>JVM - executable assembly jar file</li>\n  <li>Python - <a href=\"https://shiv.readthedocs.io/en/latest/\">shiv archive</a> creates self-contained Python zipapps</li>\n  <li>NodeJS - <a href=\"https://github.com/vercel/ncc\">ncc</a> compiles a NodeJS project into a single file</li>\n</ul>\n\n<p>By bundling all dependencies within the artifact, we save significant time - anywhere from a few seconds to several minutes - that would otherwise be spent installing dependencies during runtime. As a result, services can enter a ready state more quickly. For services that have a more complex set of Python dependencies, we\u2019ve seen time savings of more than 5 minutes!</p>\n\n<h3 id=\"standardized-build-and-deployment-processes\">Standardized Build and Deployment Processes</h3>\n<h4 id=\"build-process\">Build Process</h4>\n<p>In addition to infrastructure work, we realized that for SOS to succeed, it was essential to offer a streamlined and straightforward method for users to create their artifacts. Without a standardized build and deploy process, users would have to sift through documentation to set up their local environments and handle processor architectures. We wanted to alleviate these overheads and provide users a least-resistance path to start experiencing SOS \u2013  batteries <em>are</em> included!</p>\n\n<p>To address this issue, we established a command-line tool where running <code class=\"language-plaintext highlighter-rouge\">sos build</code> in your project directory will automatically detect project metadata (such as if it\u2019s a Python or Golang deployment), perform integrity checks, and launch a remote build job that creates the SOS artifact on the same Docker image it would run on.</p>\n\n<figure>\n    <img src=\"https://multithreaded.stitchfix.com/assets/posts/2023-09-19-towards-service-deployment-agility/sos-build-deploy.png\" style=\"width: 100%;\" />\n    <figcaption style=\"text-align: center;\">We standardized the build process with a command-line tool that initiates remote build jobs, reducing user overhead in setting up environments and mitigating compatibility issues between runtime environments.</figcaption>\n</figure>\n\n<h4 id=\"deploy-process\">Deploy Process</h4>\n<p>We offer two interfaces for creating and updating service deployments in SOS: a Python client and a web-based UI built with React.</p>\n\n<p>The Python client allows users to declare their services as a DSL in a familiar Python ecosystem. To ensure consistent types, we synchronize data models between the SOS client and the SOS API using shared protobuf files. We will cover the Python client\u2019s user interface in more detail later.</p>\n\n<p>Our web-based UI allows users to easily review revision histories and adjust traffic policies. We have ensured feature parity between the Python client and the web UI, enabling our users to choose the interface that suits them best.</p>\n\n<figure>\n    <img src=\"https://multithreaded.stitchfix.com/assets/posts/2023-09-19-towards-service-deployment-agility/sos-ui.png\" style=\"width: 100%;\" />\n    <figcaption style=\"text-align: center;\">Our UI provides an alternative way to easily manage deployments. This screenshot shows how the UI can be used to adjust the traffic segmentation between different revisions.</figcaption>\n</figure>\n\n<h3 id=\"traffic-segmentation-and-responsive-autoscaling-over-multiple-axes\">Traffic Segmentation and Responsive Autoscaling Over Multiple Axes</h3>\n<p>SOS included traffic segmentation and responsive scaling as a key feature for several reasons. These features enabled faster deployments and rollbacks, which facilitated shorter development cycles. Moreover, because all metrics and logs are namespaced by the traffic segmentation, we gained much better insights into service behavior. This feature also made gradual traffic cutovers possible and allowed for fast autoscaling to handle traffic bursts while reducing costs by scaling down unused instances.</p>\n\n<p>For example, by setting services to use a minimum of zero instances, it is possible to make SOS services serverless. No pods would be provisioned until they receive traffic. Implementing this feature for our services allowed us to save significant costs on staging deployments and production services that receive less constant traffic.</p>\n\n<h1 id=\"the-sos-user-experience\">The SOS User Experience</h1>\n<h2 id=\"blissful-ignorance\">Blissful Ignorance</h2>\n<p>Users don\u2019t need to be aware that SOS runs on Kubernetes - all they need to do to start deploying services is install the SOS Python client!</p>\n\n<h2 id=\"decoupled-application-and-system\">Decoupled Application and System</h2>\n<p>SOS ensures that each user\u2019s new code deployment is immutable and has a unique ID, tied to an SOS artifact with its own dependencies. This decouples the system and application, setting clear boundaries and avoiding the issue of Nginx configs and secrets management bundled into an application\u2019s source code that we faced with our previous instance-based deployment.</p>\n\n<p>We wanted to avoid a scenario where users inherit and patch and layers of Docker images until they become unmaintainable black boxes. By running all service artifacts on top of curated Docker images, we avoided the problem of users managing their own Docker images. This made it easier to implement platform-wide changes over time, as we could patch and improve the Docker images without relying on users to rebuild their applications. This also allowed us to efficiently tweak and fine-tune the observability agents on the system.</p>\n\n<h2 id=\"single-source-of-truth\">Single Source of Truth</h2>\n<p>The SOS service itself is the source of truth for each deployment, so users don\u2019t need to manage multiple configurations for the same service. When deploying a service, the SOS service will merge any necessary files at the service level, which prevents confusion that can arise when configuration files are stored in different branches or exist only in a user\u2019s local environment.</p>\n\n<h2 id=\"the-experience\">The Experience</h2>\n<p>The SOS Python client is the tool that our users use to interact with SOS. Below are some examples of the SOS Python client and how a user would use it to define their service deployment.</p>\n\n<h3 id=\"service-creation\">Service Creation</h3>\n<p>Each SOS service correlates with a service that\u2019s created in Kubernetes.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">service</span> <span class=\"o\">=</span> <span class=\"n\">Service</span><span class=\"p\">(</span>\n  <span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service\"</span><span class=\"p\">,</span>\n  <span class=\"n\">owner_id</span><span class=\"o\">=</span><span class=\"s\">\":team:sfix_team_name\"</span><span class=\"p\">,</span>\n  <span class=\"n\">env</span><span class=\"o\">=</span><span class=\"s\">\"prod\"</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"creating-a-revision\">Creating a Revision</h3>\n<p>In SOS, a service can have multiple revisions, with each revision representing an immutable version of the service that can be deployed independently.</p>\n\n<p>The example below shows the minimal configurations to create a revision that deploys a Python artifact. The <code class=\"language-plaintext highlighter-rouge\">Artifact</code> is a self-contained Python artifact that has been deployed to Artifactory, which we use as our sink of artifacts.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">revision</span> <span class=\"o\">=</span> <span class=\"n\">Revision</span><span class=\"p\">(</span>\n  <span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service-5\"</span><span class=\"p\">,</span>\n  <span class=\"n\">artifact</span><span class=\"o\">=</span><span class=\"n\">Artifact</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service\"</span><span class=\"p\">,</span> <span class=\"n\">version</span><span class=\"o\">=</span><span class=\"s\">\"v0.0.16\"</span><span class=\"p\">),</span>\n  <span class=\"n\">python_config</span><span class=\"o\">=</span><span class=\"n\">PythonConfig</span><span class=\"p\">(</span>\n          <span class=\"n\">python_version</span><span class=\"o\">=</span><span class=\"s\">\"3.9\"</span><span class=\"p\">,</span>\n          <span class=\"n\">gunicorn_config</span><span class=\"o\">=</span><span class=\"n\">GunicornConfig</span><span class=\"p\">(</span><span class=\"n\">worker_class</span><span class=\"o\">=</span><span class=\"s\">\"gevent\"</span><span class=\"p\">),</span>\n          <span class=\"n\">app_module</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service.server:app\"</span><span class=\"p\">,</span>\n  <span class=\"p\">),</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">logging</span><span class=\"p\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"n\">service</span><span class=\"p\">.</span><span class=\"n\">add_revision</span><span class=\"p\">(</span><span class=\"n\">revision</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<p>Additional settings can be configured for more complex deployments, such as port number, environment variables, memory and CPU allocation, health checks, and thread and worker counts. Here\u2019s an example of how to set these configurations:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">revision</span> <span class=\"o\">=</span> <span class=\"n\">Revision</span><span class=\"p\">(</span>\n  <span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service-5\"</span><span class=\"p\">,</span>\n  <span class=\"n\">artifact</span><span class=\"o\">=</span><span class=\"n\">Artifact</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service\"</span><span class=\"p\">,</span> <span class=\"n\">version</span><span class=\"o\">=</span><span class=\"s\">\"v0.0.16\"</span><span class=\"p\">),</span>\n  <span class=\"n\">container</span><span class=\"o\">=</span><span class=\"n\">Container</span><span class=\"p\">(</span>\n          <span class=\"n\">port</span><span class=\"o\">=</span><span class=\"mi\">5001</span><span class=\"p\">,</span>\n          <span class=\"n\">env_vars</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">EnvVar</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s\">\"env_var\"</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"o\">=</span><span class=\"s\">\"env_value\"</span><span class=\"p\">)],</span>\n          <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">Resources</span><span class=\"p\">(</span><span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"s\">\"2G\"</span><span class=\"p\">,</span> <span class=\"n\">cpu</span><span class=\"o\">=</span><span class=\"s\">\"1000m\"</span><span class=\"p\">),</span>\n  <span class=\"p\">),</span>\n  <span class=\"n\">health_check</span><span class=\"o\">=</span><span class=\"n\">HealthCheck</span><span class=\"p\">(</span><span class=\"n\">liveness_probe</span><span class=\"o\">=</span><span class=\"s\">\"/\"</span><span class=\"p\">,</span> <span class=\"n\">readiness_probe</span><span class=\"o\">=</span><span class=\"s\">\"/\"</span><span class=\"p\">),</span>\n  <span class=\"n\">sf_env</span><span class=\"o\">=</span><span class=\"s\">\"prod\"</span><span class=\"p\">,</span>\n  <span class=\"n\">python_config</span><span class=\"o\">=</span><span class=\"n\">PythonConfig</span><span class=\"p\">(</span>\n          <span class=\"n\">python_version</span><span class=\"o\">=</span><span class=\"s\">\"3.9\"</span><span class=\"p\">,</span>\n          <span class=\"n\">gunicorn_config</span><span class=\"o\">=</span><span class=\"n\">GunicornConfig</span><span class=\"p\">(</span><span class=\"n\">worker_count</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">thread_count</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">worker_class</span><span class=\"o\">=</span><span class=\"s\">\"gevent\"</span><span class=\"p\">),</span>\n          <span class=\"n\">app_module</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service.server:app\"</span><span class=\"p\">,</span>\n  <span class=\"p\">),</span>\n  <span class=\"n\">autoscaling</span><span class=\"o\">=</span><span class=\"n\">Autoscaling</span><span class=\"p\">(</span><span class=\"n\">min_scale</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">),</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">logging</span><span class=\"p\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"n\">service</span><span class=\"p\">.</span><span class=\"n\">add_revision</span><span class=\"p\">(</span><span class=\"n\">revision</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<h3 id=\"set-traffic-for-new-revision\">Set Traffic for New Revision</h3>\n<p>We recognized the importance of providing robust support for traffic segmentation, as users should have confidence that deploying new code wouldn\u2019t negatively impact their entire system. By giving them complete control over the flow of traffic, they could confidently iterate on changes without fear of breaking everything. This was crucial to enabling faster development cycles and smoother rollbacks, as well as improving our understanding of service behavior through fine-grained traffic analysis.</p>\n\n<p>The following example shows how the newly created revision can be set to receive 100% traffic. However, to roll out changes more safely, traffic can be segmented between multiple revisions by adding more Route objects to the TrafficRoute.routes configuration. SOS\u2019s observability tooling can be used to monitor the traffic and ensure a smooth transition.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">service</span><span class=\"p\">.</span><span class=\"n\">add_traffic</span><span class=\"p\">(</span>\n    <span class=\"n\">Traffic</span><span class=\"p\">(</span>\n        <span class=\"n\">traffic_route</span><span class=\"o\">=</span><span class=\"n\">TrafficRoute</span><span class=\"p\">(</span>\n            <span class=\"n\">routes</span><span class=\"o\">=</span><span class=\"p\">[</span>\n                <span class=\"n\">Route</span><span class=\"p\">(</span>\n                    <span class=\"n\">percent</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span>\n                    <span class=\"n\">revision_id</span><span class=\"o\">=</span><span class=\"s\">\"sfix_service-5\"</span><span class=\"p\">,</span>\n                    <span class=\"n\">dns_record_suffix</span><span class=\"o\">=</span><span class=\"s\">\"active\"</span><span class=\"p\">,</span>\n                <span class=\"p\">),</span>\n            <span class=\"p\">]</span>\n        <span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h1 id=\"the-present-and-the-future\">The Present and the Future</h1>\n<p>Most data platform services have already been migrated to SOS.  It hosts many critical services, including the components of our batch processor, <a href=\"https://github.com/stitchfix/flotilla-os\">job execution engine</a>, our metastore, configuration management service, Kafka connect cluster, ownership discovery service, and more! While there are some data science services deployed on SOS, most of the currently-deployed services are focused on powering our data platform.</p>\n\n<p>SOS aims to streamline the service lifecycle, yet its opinionated approach might not suit all deployments. Certain open-source tools align better with standard industry patterns. For instance, we deploy Trino directly onto Kubernetes and use a Helm Chart for Airflow. While SOS isn\u2019t a one-size-fits-all solution, it remains highly effective for the majority of our existing and future deployments.</p>\n\n<p>We are regularly improving the user experience of SOS by migrating existing services and building new ones on top of it. Our goal is to reduce the complexity of service deployment and continue to empower our data scientists and engineers at Stitch Fix to be more efficient and effective.</p>"
    },
    "published": "Tue, 19 Sep 2023 15:00:00 +0000",
    "published_parsed": [
      2023,
      9,
      19,
      15,
      0,
      0,
      1,
      262,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://multithreaded.stitchfix.com/blog/2023/09/19/towards-service-deployment-agility/"
      }
    ],
    "link": "https://multithreaded.stitchfix.com/blog/2023/09/19/towards-service-deployment-agility/",
    "id": "https://multithreaded.stitchfix.com/blog/2023/09/19/towards-service-deployment-agility/",
    "guidislink": false
  },
  "ShowMax": {
    "title": "Pytest Appium: iOS/Android Setup BrowserStack and Simulators",
    "xmlUrl": "https://tech.showmax.com/feed.xml",
    "htmlUrl": "https://tech.showmax.com",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://showmax.engineering/feed.xml",
      "value": "Pytest Appium: iOS/Android Setup BrowserStack and Simulators"
    },
    "summary": "Mobile applications are becoming more and more popular and their quality is key for success in the market. But how can you ensure that the application...",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://showmax.engineering/feed.xml",
      "value": "Mobile applications are becoming more and more popular and their quality is key for success in the market. But how can you ensure that the application..."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://showmax.engineering/articles/pytest-appium-iosandroid-setup-browserstack-and-simulators"
      }
    ],
    "link": "https://showmax.engineering/articles/pytest-appium-iosandroid-setup-browserstack-and-simulators",
    "id": "https://showmax.engineering/articles/pytest-appium-iosandroid-setup-browserstack-and-simulators",
    "guidislink": false,
    "published": "Thu, 14 Dec 2023 00:00:00 GMT",
    "published_parsed": [
      2023,
      12,
      14,
      0,
      0,
      0,
      3,
      348,
      0
    ]
  },
  "Guardian": {
    "title": "Large language models and generative AI: a recent hack day",
    "xmlUrl": "https://www.theguardian.com/info/series/digital-blog/rss",
    "htmlUrl": "https://www.theguardian.com/info/developer-blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.theguardian.com/info/series/engineering-blog/rss",
      "value": "Large language models and generative AI: a recent hack day"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.theguardian.com/info/2023/dec/22/large-language-models-and-generative-ai-a-recent-hack-day"
      }
    ],
    "link": "https://www.theguardian.com/info/2023/dec/22/large-language-models-and-generative-ai-a-recent-hack-day",
    "summary": "<p>Developers in the Product and Engineering department came together with colleagues from across the Guardian to explore the potential of LLMs and more</p><p>The discussion of large language models (LLMs) and generative artificial intelligence was everywhere in 2023 \u2013 not least in the Guardian\u2019s Product and Engineering department. Hack days are a staple part of the software development culture, so it was no surprise that at this year\u2019s final hackathon, several developers and data scientists focused their attention in this area \u2013 covering potential applications in podcasting, search and image generation. And who wouldn\u2019t want a browser extension that assesses the mood of a news article and finds an appropriate music track to enhance your reading experience?</p><p>In total, the teams, including colleagues from across the Guardian, produced and presented 24 hacks in the course of the two-day event \u2013 some of which took an entirely different turn. These included: a product that spits out cultural recommendations; a dedicated platform for showcasing <a href=\"https://www.theguardian.com/documentaries\">Guardian documentaries</a>; experiments with ChatGPT and Google Bard involving tools like Trello to improve efficiency; and a Guardian-themed generative AI screensaver.</p> <a href=\"https://www.theguardian.com/info/2023/dec/22/large-language-models-and-generative-ai-a-recent-hack-day\">Continue reading...</a>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.theguardian.com/info/series/engineering-blog/rss",
      "value": "<p>Developers in the Product and Engineering department came together with colleagues from across the Guardian to explore the potential of LLMs and more</p><p>The discussion of large language models (LLMs) and generative artificial intelligence was everywhere in 2023 \u2013 not least in the Guardian\u2019s Product and Engineering department. Hack days are a staple part of the software development culture, so it was no surprise that at this year\u2019s final hackathon, several developers and data scientists focused their attention in this area \u2013 covering potential applications in podcasting, search and image generation. And who wouldn\u2019t want a browser extension that assesses the mood of a news article and finds an appropriate music track to enhance your reading experience?</p><p>In total, the teams, including colleagues from across the Guardian, produced and presented 24 hacks in the course of the two-day event \u2013 some of which took an entirely different turn. These included: a product that spits out cultural recommendations; a dedicated platform for showcasing <a href=\"https://www.theguardian.com/documentaries\">Guardian documentaries</a>; experiments with ChatGPT and Google Bard involving tools like Trello to improve efficiency; and a Guardian-themed generative AI screensaver.</p> <a href=\"https://www.theguardian.com/info/2023/dec/22/large-language-models-and-generative-ai-a-recent-hack-day\">Continue reading...</a>"
    },
    "published": "Fri, 22 Dec 2023 11:02:35 GMT",
    "published_parsed": [
      2023,
      12,
      22,
      11,
      2,
      35,
      4,
      356,
      0
    ],
    "id": "https://www.theguardian.com/info/2023/dec/22/large-language-models-and-generative-ai-a-recent-hack-day",
    "guidislink": false,
    "media_content": [
      {
        "width": "140",
        "url": "https://i.guim.co.uk/img/media/606f5ac0f77c78cd168dd713f386f99b09c2c71f/0_165_5000_3002/master/5000.jpg?width=140&quality=85&auto=format&fit=max&s=f4395049666737fb7f19b22cfab0a7ca"
      },
      {
        "width": "460",
        "url": "https://i.guim.co.uk/img/media/606f5ac0f77c78cd168dd713f386f99b09c2c71f/0_165_5000_3002/master/5000.jpg?width=460&quality=85&auto=format&fit=max&s=cc56a4d1217f6b768d9da0a82bde8999"
      }
    ],
    "media_credit": [
      {
        "scheme": "urn:ebu",
        "content": "Photograph: John Williams RF/Alamy"
      },
      {
        "scheme": "urn:ebu",
        "content": "Photograph: John Williams RF/Alamy"
      }
    ],
    "credit": "Photograph: John Williams RF/Alamy",
    "authors": [
      {
        "name": "Rasha Ardati"
      }
    ],
    "author": "Rasha Ardati",
    "author_detail": {
      "name": "Rasha Ardati"
    },
    "updated": "2023-12-22T11:02:35Z",
    "updated_parsed": [
      2023,
      12,
      22,
      11,
      2,
      35,
      4,
      356,
      0
    ]
  },
  "Thoughtbot": {
    "title": "Update from RubyConf 2023",
    "xmlUrl": "https://feeds.feedburner.com/GiantRobotsSmashingIntoOtherGiantRobots",
    "htmlUrl": "https://robots.thoughtbot.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://feeds.feedburner.com/GiantRobotsSmashingIntoOtherGiantRobots",
      "value": "Update from RubyConf 2023"
    },
    "links": [
      {
        "rel": "alternate",
        "href": "https://thoughtbot.com/blog/update-from-rubyconf-2023",
        "type": "text/html"
      }
    ],
    "link": "https://thoughtbot.com/blog/update-from-rubyconf-2023",
    "authors": [
      {
        "name": "Justin Toniazzo"
      }
    ],
    "author_detail": {
      "name": "Justin Toniazzo"
    },
    "author": "Justin Toniazzo",
    "id": "https://thoughtbot.com/blog/update-from-rubyconf-2023",
    "guidislink": false,
    "published": "2024-01-10T00:00:00+00:00",
    "published_parsed": [
      2024,
      1,
      10,
      0,
      0,
      0,
      2,
      10,
      0
    ],
    "updated": "2024-01-09T15:03:22Z",
    "updated_parsed": [
      2024,
      1,
      9,
      15,
      3,
      22,
      1,
      9,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://feeds.feedburner.com/GiantRobotsSmashingIntoOtherGiantRobots",
        "value": "<p>If you missed out on RubyConf 2023 or just want to relive the action, video recordings of thoughtbot\u2019s presentations are now available on YouTube. Please check them out!</p>\n<h2 id=\"which-time-is-it\">\n  <a href=\"https://feeds.feedburner.com/GiantRobotsSmashingIntoOtherGiantRobots#which-time-is-it\">\n    Which Time Is It?\n  </a>\n</h2>\n\n<p>By Jo\u00ebl Quenneville</p>\n\n<blockquote>\n<p>Can you add two time values together? Yes. No. Not so fast! <br /> <br /></p>\n\n<p>Reset your clocks and join me on a graphical tour of time itself. You&rsquo;ll discover how &ldquo;time&rdquo; is more than a single thing, build intuition around what different operations mean, and get a sense of when some operations are nonsensical. You&rsquo;ll leave with a better mental model for thinking about time and avoiding subtle time-related bugs in your own code.</p>\n</blockquote>\n\n\n<h2 id=\"the-unbreakable-code-whose-breaking-won-wwii\">\n  <a href=\"https://feeds.feedburner.com/GiantRobotsSmashingIntoOtherGiantRobots#the-unbreakable-code-whose-breaking-won-wwii\">\n    The Unbreakable Code Whose Breaking Won WWII\n  </a>\n</h2>\n\n<p>By Aji Slater</p>\n\n<blockquote>\n<p>After the last carrier pigeon but before digital encryption algorithms, there was the Enigma machine. An ingenious piece of pre-atomic age technology encoded German military secrets during World War II, baffling code-breakers with mere physical rotors, and switches, without elliptic curves or private keys. <br /> <br /></p>\n\n<p>Delve into object-oriented programming and bring the Enigma machine back to life with an emulator built in Ruby. Unravel the secrets of this nigh-unbreakable cipher device, witness OO principles unlock its mysteries, discover the power and versatility of the patterns we use as developers and how they mirror the Enigma&rsquo;s inner workings.</p>\n</blockquote>\n\n\n<h2 id=\"getting-good-at-being-bad-at-things\">\n  <a href=\"https://feeds.feedburner.com/GiantRobotsSmashingIntoOtherGiantRobots#getting-good-at-being-bad-at-things\">\n    Getting Good At Being Bad At Things\n  </a>\n</h2>\n\n<p>By Victoria Guido</p>\n\n<p>Learn how embracing fear and discomfort can make you a better leader.</p>\n\n\n\n<p>Thanks so much to all the awesome presenters and organizers at RubyConf 2023. Here&rsquo;s looking forward to 2024!</p>"
      }
    ],
    "summary": "Watch video recordings of thoughtbot&rsquo;s presentations at RubyConf.",
    "summary_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://feeds.feedburner.com/GiantRobotsSmashingIntoOtherGiantRobots",
      "value": "Watch video recordings of thoughtbot&rsquo;s presentations at RubyConf."
    },
    "auto_social_share": "true"
  },
  "Slack": {
    "title": "Our Journey Migrating to AWS IMDSv2",
    "xmlUrl": "https://slack.engineering/feed",
    "htmlUrl": "https://slack.engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://slack.engineering/feed/",
      "value": "Our Journey Migrating to AWS IMDSv2"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://slack.engineering/our-journey-migrating-to-aws-imdsv2/"
      }
    ],
    "link": "https://slack.engineering/our-journey-migrating-to-aws-imdsv2/",
    "authors": [
      {
        "name": "Archie Gunasekara"
      }
    ],
    "author": "Archie Gunasekara",
    "author_detail": {
      "name": "Archie Gunasekara"
    },
    "published": "Tue, 12 Dec 2023 07:00:52 +0000",
    "published_parsed": [
      2023,
      12,
      12,
      7,
      0,
      52,
      1,
      346,
      0
    ],
    "tags": [
      {
        "term": "Uncategorized",
        "scheme": null,
        "label": null
      },
      {
        "term": "aws",
        "scheme": null,
        "label": null
      },
      {
        "term": "cloud-computing",
        "scheme": null,
        "label": null
      },
      {
        "term": "infrastructure",
        "scheme": null,
        "label": null
      },
      {
        "term": "security",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://slack.engineering/?p=16504",
    "guidislink": false,
    "summary": "<p>We are heavy users of Amazon Compute Compute Cloud (EC2) at Slack \u2014 we run approximately 60,000 EC2 instances across 17 AWS regions while operating hundreds of AWS accounts. A multitude of teams own and manage our various instances. The Instance Metadata Service (IMDS) is an on-instance component that can be used to gain an [&#8230;]</p>\n<p>The post <a href=\"https://slack.engineering/our-journey-migrating-to-aws-imdsv2/\" rel=\"nofollow\">Our Journey Migrating to AWS IMDSv2</a> appeared first on <a href=\"https://slack.engineering\" rel=\"nofollow\">Slack Engineering</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://slack.engineering/feed/",
      "value": "<p>We are heavy users of Amazon Compute Compute Cloud (EC2) at Slack \u2014 we run approximately 60,000 EC2 instances across 17 AWS regions while operating hundreds of AWS accounts. A multitude of teams own and manage our various instances. The Instance Metadata Service (IMDS) is an on-instance component that can be used to gain an [&#8230;]</p>\n<p>The post <a href=\"https://slack.engineering/our-journey-migrating-to-aws-imdsv2/\" rel=\"nofollow\">Our Journey Migrating to AWS IMDSv2</a> appeared first on <a href=\"https://slack.engineering\" rel=\"nofollow\">Slack Engineering</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://slack.engineering/feed/",
        "value": "<p>We are heavy users of Amazon Compute Compute Cloud (EC2) at Slack \u2014 we run approximately 60,000 EC2 instances across 17 AWS regions while operating hundreds of AWS accounts. A multitude of teams own and manage our various instances.</p>\n<p>The Instance Metadata Service (IMDS) is an on-instance component that can be used to gain an insight to the instance\u2019s current state. Since it first launched over 10 years ago, AWS customers used this service to gather useful information about their instances. At Slack, IMDS is used heavily for instance provisioning, and also used by tools that need to understand their running environments.</p>\n<p>Information exposed by IMDS includes IAM credentials, metrics about the instance, security group IDs, and a whole lot more. This information can be highly sensitive &#8211; if an instance is compromised, an attacker may be able to use instance metadata to gain access to other Slack services on the network.</p>\n<p>In 2019, AWS released a new version of IMDS (IMDSv2) where every request is protected by session authentication. As part of our commitment to high security standards, Slack moved the entire fleet and tools to IMDSv2. In this article, we are going to discuss the pitfalls of using IMDSv1 and our journey towards fully migrating to IMDSv2.</p>\n<h2>The v2 difference</h2>\n<p>IMDSv1 uses a simple request-and-response pattern that can magnify the impact of <a href=\"https://owasp.org/www-community/attacks/Server_Side_Request_Forgery\">Server Side Request Forgery (SSRF)</a> vulnerabilities \u2014 if an application deployed on an instance is vulnerable to SSRF, an attacker can exploit the application to make requests on their behalf. Since IMDSv1 supports simple GET requests, they can extract credentials using its API.</p>\n<p>IMDSv2 eliminates this attack vector by using session-oriented requests. IMDSv2 works by requiring these two steps:</p>\n<ol>\n<li>Make a PUT request with the header X-aws-ec2-metadata-token-ttl-secondsheader, and receive a token that is valid for the TTL provided in the request</li>\n<li>Use that token in a HTTP GET request with the header named X-aws-ec2-metadata-token to make any follow-up IMDS calls</li>\n</ol>\n<p>With IMDSv2, rather than simply making HTTP GET requests, an attacker needs to exploit vulnerabilities to make PUT requests with headers. Then they will have to use the obtained credentials to make follow-up GET requests with headers to access IMDS data. This makes it much more challenging for attackers to access IMDS via vulnerabilities such as SSRF.</p>\n<h2>Our journey towards IMDSv2</h2>\n<p>At Slack there are several instance provisioning mechanisms at play, such as Terraform, CloudFormation and various in-house tools that call the AWS EC2 API. As an organization, we rely heavily on IMDS to get insights into our instances during provisioning and the lifecycle of these instances.</p>\n<p>We create AWS accounts per environment (Sandbox, Dev and Prod) and per service team and sometimes even per application &#8211; so we have hundreds of AWS accounts.</p>\n<p>We have a single root AWS organization account. All our child accounts are members of this organization. When we create an AWS account, the account creation process writes information about the account (such as the account ID, owner details, and account tags) to a DynamoDB table. Information in this table is accessible via an internal API called Archipelago for account discovery.</p>\n<h3>Figuring out the scale of the problem</h3>\n<p>Before migrating, first we needed to understand how many instances in our fleet used IMDSv1. For this we used the EC2 CloudWatch metric called <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html\">MetadataNoToken</a> that counts how often the IMDSv1 API was used for a given instance.</p>\n<p>We created an application called imds-cw-metric-collector to map those metrics and instance IDs we collected to alert various service teams and applications. The application used our internal Archipelago API to get a list of our AWS accounts, the aforementioned MetadataNoToken metric, and talked to our instance provisioning services to collect info like owner IDs and Chef Roles (for instances that are using <a href=\"https://www.chef.io/blog/chef-provisioning-infrastructure-as-code\">Chef</a> to configure them). Our custom app sent all those metrics to our <a href=\"https://prometheus.io/\">Prometheus monitoring</a> system.</p>\n<p><span style=\"font-weight: 400;\">A dashboard aggregated these metrics to track all instances that made IMDSv1 calls. This information was then used to connect with service teams, and work with them to update their services to use IMDSv2.</span></p>\n<p><img alt=\"IMDSv1 usage dashboard\" class=\"alignnone size-medium wp-image-16505\" height=\"662\" src=\"https://slack.engineering/wp-content/uploads/sites/7/2023/12/2.png?w=640\" width=\"1774\" /></p>\n<p><span style=\"font-weight: 400;\">However, the list of EC2 instance IDs and their owners was only a part of the equation. We also needed to understand which processes on these instances were making these calls to the IMDSv1 API.</span></p>\n<p>At Slack, for the most part, we use Ubuntu and Amazon Linux on our EC2 instances. For IMDSv1 call detection, AWS provides a tool called <a href=\"https://github.com/aws/aws-imds-packet-analyzer\">AWS ImdsPacketAnalyzer</a>. We decided to build the tool and package it up as a Debian Linux distribution package (*.deb) in our APT repository. This allowed the service teams to install this tool on demand and investigate IMDSv1 calls.</p>\n<p>This worked perfectly for our Ubuntu 22.04 (Jammy Jellyfish) and Amazon Linux instances. However, the <a href=\"https://github.com/aws/aws-imds-packet-analyzer\">ImdsPacketAnalyzer</a> does not work on our legacy Ubuntu 18.04 (Bionic Beaver) instances so we had to resort to using tools such as <a href=\"https://man7.org/linux/man-pages/man8/lsof.8.html\">lsof</a> and <a href=\"https://github.com/raboof/nethogs\">netlogs</a> in some cases.</p>\n<p>As a last resort on some of our dev instances we just turned off IMDSv1 and listed things that were broken.</p>\n<h2>Stop calling IMDSv1</h2>\n<p>Once we had a list of instances and processes on those instances that were making the IMDSv1 calls, it was time for us to get to work and update each one to use IMDSv2 instead.</p>\n<p>Updating our bash scripts was the easy part, as AWS provides <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-metadata-v2-how-it-works.html\">very clear steps</a> on switching from IMDSv1 and IMDSv2 for these. We also upgraded our AWS CLI to the latest version to get IMDSv2 support. However doing this for services that are written using other languages was a bit more complicated. Luckily AWS has a <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/use-a-supported-sdk-version-for-imdsv2.html\">comprehensive list of libraries</a> that we should be using to enforce IMDSv2 for various languages. We worked with service teams to upgrade their applications to IMDSv2 supported versions of libraries and roll these out across our fleet.</p>\n<p>Once we had rolled out those changes, the number of instances using IMDSv1 dropped precipitously.</p>\n<h2>Turning off IMDSv1 for new instances</h2>\n<p>Preventing our services from using the IMDSv1 API only solved part of the problem. We also needed to turn off IMDSv1 on all future instances. To solve this problem, we turned to our provisioning tools.</p>\n<p>First we looked at our most commonly used provisioning tool, Terraform. Our team provides a set of standard Terraform modules for service teams to use to create things such as AutoScaling groups, S3 buckets, and RDS instances. These common modules enable us to make a change in a single place and roll it out to many teams. Service teams that just want to build an AutoScaling group do not need to know the nitty-gritty configurations of Terraform to use one of these modules.</p>\n<p>However we didn\u2019t want to roll out this change to all our AWS child accounts at the same time, as there were service teams that were actively working on switching to IMDSv1 at this time. Therefore we needed a way to exclude those teams and their child accounts. We came up with a custom Terraform module called <code>accounts_using_imdsv1</code> as the solution.Then we were able to use this module in our shared Terraform modules to keep or terminate IMDSv1 as per the example below:</p>\n<pre><code class=\"language-hcl\">module &quot;accounts_using_imdsv1&quot; {\n  source = &quot;../slack/accounts_using_imdsv&quot;\n}\n\nresource &quot;aws_instance&quot; &quot;example&quot; {\n  ami           = data.aws_ami.amzn-linux-2023-ami.id\n  instance_type = &quot;c6a.2xlarge&quot;\n  subnet_id     = aws_subnet.example.id\n\n  metadata_options {\n    http_endpoint  = &quot;enabled&quot;\n    http_tokens    = module.accounts_using_imdsv1.is_my_account_using_imdsv1 ? &quot;optional&quot; : &quot;required&quot;\n  }\n}</code></pre>\n<p>We started with a large list of accounts in the accounts_using_imdsv1 module as using IMDSv1, but we were slowly able to remove them as service teams migrated to IMDSv2.</p>\n<h2>Blocking instances with IMDSv1 from launching</h2>\n<p>The next step for us was to block launching instances with IMDSv1 enabled. For this we turned to <a href=\"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\">AWS Service control policies (SCPs)</a>. We updated our SCPs to block launching IMDSv1 supported instances across all our child accounts. However, similar to the AutoScaling group changes we discussed earlier, we wanted to exclude some accounts at the beginning while the service owners were working to switch to IMDSv2. Our accounts_using_imdsv1 Terraform module came to the rescue here too. We were able to use this module in our SCPs as below. We blocked the ability to launch instances with IMDSv1 support and also blocked the ability to turn on IMDSv1 on existing instances.</p>\n<pre><code class=\"language-hcl\"> # Block launching instances with IMDSv1 enabled\n  statement {\n    effect = &quot;Deny&quot;\n\n    actions = [\n      &quot;ec2:RunInstances&quot;,\n    ]\n\n    resources = [\n      &quot;arn:aws:ec2:*:*:instance/*&quot;,\n    ]\n\n    condition {\n      test     = &quot;StringNotEquals&quot;\n      variable = &quot;ec2:MetadataHttpTokens&quot;\n      values     = [&quot;required&quot;]\n    }\n\n    condition {\n      test          = &quot;StringNotEquals&quot;\n      variable = &quot;aws:PrincipalAccount&quot;\n      values     = module.accounts_using_imdsv1.accounts_list_using_imdsv1\n    }\n  }\n\n  # Block turning on IMDSv1 if it&#039;s already turned off\n  statement {\n    effect = &quot;Deny&quot;\n\n    actions = [\n      &quot;ec2:ModifyInstanceMetadataOptions&quot;,\n    ]\n\n    resources = [\n      &quot;arn:aws:ec2:*:*:instance/*&quot;,\n    ]\n\n    condition {\n      test          = &quot;StringNotEquals&quot;\n      variable = &quot;ec2:Attribute/HttpTokens&quot;\n      values     = [&quot;required&quot;]\n    }\n\n    condition {\n      test          = &quot;StringNotEquals&quot;\n      variable = &quot;aws:PrincipalAccount&quot;\n      values     = module.accounts_using_imdsv1.accounts_list_using_imdsv1\n    }\n  }\n}\n</code></pre>\n<h2>How effective are these SCPs?</h2>\n<p>SCPs are effective when it comes to blocking most IMDSv1 usage. However there are some places where they do not work.</p>\n<p>SCPs do not apply to the AWS root organization\u2019s account, and only apply to child accounts that are members of the organization. Therefore, SCPs do not prevent launching instances with IMDSv1 enabled, nor turning on IMDSv1 on an existing instance in the root AWS account.</p>\n<p>SCPs also do not apply to service-linked roles. For example, if an autoscaling group launches an instance in response to a scaling event, under the hood the AutoScaling service is using a service-linked IAM role managed by AWS and those instance launches are not impacted by the above SCPs.</p>\n<p>We looked at preventing teams from creating AWS Launch Templates that do not enforce IMDSv2, but AWS Launch Template policy condition keys currently <a href=\"https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonec2.html\">do not provide support for ec2:Attribute/HttpTokens</a>.</p>\n<h2>What other safety mechanisms are in place?</h2>\n<p>As there is no 100%-foolproof way to stop someone from launching an IMDSv1-enabled EC2 instance, we put in a notification system utilizing AWS <a href=\"https://aws.amazon.com/eventbridge/\">EventBridge</a> and <a href=\"https://aws.amazon.com/lambda/\">Lambda</a>.</p>\n<p>We created two EventBridge rules in each of our child accounts using CloudTrail events for EC2 events. One rule captures requests to the EC2 API and the second captures responses from the EC2 API, telling us when someone is making a EC2:RunInstances call with IMDSv1 enabled.</p>\n<p>Rule 1: Capturing the requests</p>\n<pre><code class=\"language-json\">{\n  &quot;detail&quot;: {\n    &quot;eventName&quot;: [&quot;RunInstances&quot;],\n    &quot;eventSource&quot;: [&quot;ec2.amazonaws.com&quot;],\n    &quot;requestParameters&quot;: {\n      &quot;metadataOptions&quot;: {\n        &quot;httpTokens&quot;: [&quot;optional&quot;]\n      }\n    }\n  },\n  &quot;detail-type&quot;: [&quot;AWS API Call via CloudTrail&quot;],\n  &quot;source&quot;: [&quot;aws.ec2&quot;]\n}</code></pre>\n<p>Rule 2: Capturing the responses</p>\n<pre><code class=\"language-json\">{\n  &quot;detail&quot;: {\n    &quot;eventName&quot;: [&quot;RunInstances&quot;],\n    &quot;eventSource&quot;: [&quot;ec2.amazonaws.com&quot;],\n    &quot;responseElements&quot;: {\n      &quot;instancesSet&quot;: {\n        &quot;items&quot;: {\n          &quot;metadataOptions&quot;: {\n            &quot;httpTokens&quot;: [&quot;optional&quot;]\n          }\n        }\n      }\n    }\n  },\n  &quot;detail-type&quot;: [&quot;AWS API Call via CloudTrail&quot;],\n  &quot;source&quot;: [&quot;aws.ec2&quot;]\n}</code></pre>\n<p>These event rules have a target setup to point them at a central event bus living in an account managed by our team.</p>\n<p><img alt=\"AWS Eventbridge Targets\" class=\"alignnone size-medium wp-image-16506\" height=\"403\" src=\"https://slack.engineering/wp-content/uploads/sites/7/2023/12/3.png?w=640\" width=\"1476\" /></p>\n<p>Events matching these rules are sent to the central event bus. The Central Event bus captures these events via a similar set of rules. Next it sends them through an <a href=\"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-transform-target-input.html\">Input Transformer</a> to format the event similar to the following:</p>\n<p>Input path:</p>\n<pre><code class=\"language-json\">{\n  &quot;account&quot;: &quot;$.account&quot;,\n  &quot;instanceid&quot;: &quot;$.detail.responseElements.instancesSet.items[0].instanceId&quot;,\n  &quot;region&quot;: &quot;$.region&quot;,\n  &quot;time&quot;: &quot;$.time&quot;\n}</code></pre>\n<p>Input template:</p>\n<pre><code class=\"language-json\"> {\n  &quot;source&quot; : &quot;slack&quot;,\n  &quot;detail-type&quot;: &quot;slack.api.postMessage&quot;,\n  &quot;version&quot;: 1,\n  &quot;account_id&quot;: &quot;&lt;account&gt;&quot;,\n  &quot;channel_tag&quot;: &quot;event_alerts_channel_imdsv1&quot;,\n  &quot;detail&quot;: {\n    &quot;text&quot;: &quot;:importantred: :provisioning: instance `&lt;instanceid&gt; (&lt;region&gt;)` in the AWS account `&lt;account&gt;` was launched with `IMDSv1` support&quot;\n  }\n}</code></pre>\n<p>Finally the transformed events get sent a Lambda function in our account.</p>\n<p><img alt=\"AWS Eventbridge Targets\" class=\"alignnone size-medium wp-image-16507\" height=\"357\" src=\"https://slack.engineering/wp-content/uploads/sites/7/2023/12/4.png?w=640\" width=\"1483\" /></p>\n<p>This Lambda function uses the account ID from the event and our internal Archipelago API to determine the Slack Channel, then sends this event to Slack.</p>\n<p><img alt=\"IMDSv1 Slack Alerts\" class=\"alignnone size-medium wp-image-16508\" height=\"195\" src=\"https://slack.engineering/wp-content/uploads/sites/7/2023/12/5.png?w=640\" width=\"881\" /></p>\n<p>This flow looks like the following:</p>\n<p><img alt=\"IMDSv1 Slack Alert Flow\" class=\"alignnone size-medium wp-image-16509\" height=\"635\" src=\"https://slack.engineering/wp-content/uploads/sites/7/2023/12/6.png?w=640\" width=\"798\" /></p>\n<p>We also have a similar alert in place for when IMDSv1 is turned on for an existing instance.</p>\n<p><img alt=\"IMDSv1 Enabled Slack Alert\" class=\"alignnone size-medium wp-image-16510\" height=\"75\" src=\"https://slack.engineering/wp-content/uploads/sites/7/2023/12/7.png?w=640\" width=\"753\" /></p>\n<h2>What about the instances with IMDSv1 enabled?</h2>\n<p>Launching new instances with IMDSv2 is cool and all, but what about our thousands of existing instances? We needed a way to enforce IMDSv2 on them as well. As we saw above, SCPs do not block launching instances with IMDSv1 entirely.</p>\n<p>This is why we created a service called IMDSv1 Terminator. It\u2019s deployed on <a href=\"https://aws.amazon.com/eks/\">EKS</a> and uses an <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html\">IAM OIDC provider</a> to obtain IAM credentials. These credentials have access to assume a highly restricted role in all our child accounts created for this very purpose.</p>\n<p>The policy attached to the role assumed by IMDSv1 Terminator in child accounts is as below:</p>\n<pre><code class=\"language-json\">{\n    &quot;Statement&quot;: [\n        {\n            &quot;Action&quot;: &quot;ec2:ModifyInstanceMetadataOptions&quot;,\n            &quot;Condition&quot;: {\n                &quot;StringEquals&quot;: {\n                    &quot;ec2:Attribute/HttpTokens&quot;: &quot;required&quot;\n                }\n            },\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Resource&quot;: &quot;arn:aws:ec2:*:*:instance/*&quot;,\n            &quot;Sid&quot;: &quot;&quot;\n        },\n        {\n            &quot;Action&quot;: [\n                &quot;ec2:DescribeRegions&quot;,\n                &quot;ec2:DescribeInstances&quot;\n            ],\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Resource&quot;: &quot;*&quot;,\n            &quot;Sid&quot;: &quot;&quot;\n        }\n    ],\n    &quot;Version&quot;: &quot;2012-10-17&quot;\n}\n</code></pre>\n<p>Similar to our earlier metric collector application, this also uses the internal Archipelago API to get a list of our AWS accounts, lists our EC2 instances in batches and analyzes each one and checks if IMDSv1 is enabled. If it is, the service will enforce IMDSv2 on the instance.</p>\n<p>When the service remediates an instance, we get notified in Slack.</p>\n<p><img alt=\"IMDSv1 Terminator Slack Alert\" class=\"alignnone size-medium wp-image-16511\" height=\"140\" src=\"https://slack.engineering/wp-content/uploads/sites/7/2023/12/8.png?w=640\" width=\"849\" /></p>\n<p>Initially we saw hundreds of these messages for existing instances, but as they were remediated and only new instances were launched with IMDSv2, we stopped seeing these messages. Now if an instance gets launched with IMDSv1 support enabled we have the comfort of knowing that it\u2019ll get remediated and we\u2019ll get notified.</p>\n<p>This service also sends metrics to our <a href=\"https://prometheus.io/\">Prometheus monitoring</a> system about the IMDS status of our instances. We can easily visualize what AWS accounts and regions that are still running IMDSv1 enabled instances, if there are any.</p>\n<p><img alt=\"IMDSv1 Usage Dashboard\" class=\"alignnone size-medium wp-image-16512\" height=\"736\" src=\"https://slack.engineering/wp-content/uploads/sites/7/2023/12/9.png?w=640\" width=\"1777\" /></p>\n<h2>Some last words</h2>\n<p>Being able to enforce IMDSv2 across Slack\u2019s vast network was a challenging but rewarding experience for the Cloud Foundations team. We worked with our large number of service teams to accomplish this goal, in particular our SecOps team who went above and beyond to help us complete the migration.</p>\n\t\t\t<p class=\"hiring\">\n\t\t\t\tWant to help us build out our cloud infrastructure? We&#039;re hiring!\t\t\t\t<a class=\"\" href=\"https://slack.com/careers\" target=\"_blank\">Apply now</a>\n\t\t\t</p>\n\t\t\n<p>The post <a href=\"https://slack.engineering/our-journey-migrating-to-aws-imdsv2/\" rel=\"nofollow\">Our Journey Migrating to AWS IMDSv2</a> appeared first on <a href=\"https://slack.engineering\" rel=\"nofollow\">Slack Engineering</a>.</p>"
      }
    ],
    "post-id": "16504"
  },
  "HackerEarth": {
    "title": "Computing accurate skill percentile with DDSketch",
    "xmlUrl": "http://engineering.hackerearth.com/rss",
    "htmlUrl": "http://engineering.hackerearth.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://engineering.hackerearth.com/rss",
      "value": "Computing accurate skill percentile with DDSketch"
    },
    "summary": "<h3 id=\"introduction\">Introduction</h3>\n\n<p>HackerEarth has lots of candidates getting evaluated on a daily basis. We have a feature that benchmarks candidates across the platform. Benchmarking is the process of creating the profile of the ideal candidate for a position, and then measuring all candidates against that profile.\nTo benchmark candidate skills against our millions of candidates, we decided to move away from our regular cron solution to build a more reliable and accurate data pipeline. To support this, we created a new data ingestion flow and data read flow. We moved away from our deterministic algorithms to probabilistic algorithms with <a href=\"https://github.com/DataDog/sketches-py\">DDSketch</a>.</p>\n\n<h3 id=\"problem\">Problem</h3>\n\n<p>Our old benchmarking solution was trying to compute the global benchmarking of a candidate on the fly by calculating the solve percentage of the individual skills and returning the geometric mean of all the skill benchmarks. We handle huge volumes of data every day. Analyzing this data itself\u2014for example, calculating a quantile was optimal in terms of resources.</p>\n\n<h3 id=\"solution\">Solution</h3>\n\n<p>We came up with a solution that computes an approximate quantile from a compressed representation of that data. We first need to appropriately summarize that data without incurring an excessive loss of fidelity. We do this by creating a sketch. Sketch algorithms generate sketches: smaller, more manageable data structures, from which we can calculate some properties of the original data.</p>\n\n<p>We considered various algorithms to accurately compute percentiles on noisy, large-scale, real-time data that we were receiving from candidates\u2019 skill scores. We considered using Tdigest and DDSketch. For our use case, DDSketch served the purpose.We did a POC and compared the accuracy of both the algorithms as shown below to come up with a finalized algorithm.</p>\n\n<h3 id=\"poc-results-and-observations\">POC results and observations</h3>\n\n<p>We compared the actual percentile ranges in comparison to the two probabilistic approaches we mentioned(DDSketch and T-DIgest), and these were the results. Note: we have run these tests on the random data samples from the POC point of view.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">Initial</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">1000</span><span class=\"p\">(</span><span class=\"n\">unbiased</span><span class=\"p\">)</span>\n<span class=\"n\">New</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span>  <span class=\"mi\">2</span><span class=\"o\">%</span> <span class=\"n\">of</span> <span class=\"n\">actual</span> <span class=\"n\">samples</span> <span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">e</span><span class=\"p\">.,</span> <span class=\"mi\">20</span>\n\n<span class=\"n\">actual_percentile_thresholds</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.1</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">97.56</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">96.31</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">91.37</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.44</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.44</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.79</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.27</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_ddsketch</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">98.5</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">98.5</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">96.55</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.93</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.95</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.53</span><span class=\"p\">}</span>\n\n\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">ddsketch</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">0.61</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.96</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.25</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">0.48</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.26</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.26</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.21</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.36</span><span class=\"p\">}</span>\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">tdigest</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.08</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.03</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.02</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.21</span><span class=\"p\">}</span>\n\n <span class=\"o\">--------------------------------------------------------------------------------</span>\n<span class=\"n\">Initial</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">(</span><span class=\"n\">unbiased</span><span class=\"p\">)</span>\n<span class=\"n\">New</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span>  <span class=\"mi\">2</span><span class=\"o\">%</span> <span class=\"n\">of</span> <span class=\"n\">actual</span> <span class=\"n\">samples</span> <span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">e</span><span class=\"p\">.,</span> <span class=\"mi\">10</span>\n<span class=\"n\">actual_percentile_thresholds</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.18</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">96.88</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">94.98</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.79</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.95</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.95</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.65</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">70.55</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_ddsketch</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">98.5</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">96.55</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">94.64</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.93</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.95</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">70.11</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_tdigest</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.33</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">97.0</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">94.99</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.84</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.97</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.97</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.83</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">70.58</span><span class=\"p\">}</span>\n\n\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">ddsketch</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">0.69</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">0.34</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">0.36</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.15</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">0.37</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">0.37</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.4</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">0.62</span><span class=\"p\">}</span>\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">tdigest</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.15</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.12</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.06</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.02</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.02</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.24</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.04</span><span class=\"p\">}</span>\n\n<span class=\"o\">--------------------------------------------------------------------------------</span>\n<span class=\"n\">Initial</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">5000</span><span class=\"p\">(</span><span class=\"n\">unbiased</span><span class=\"p\">)</span>\n<span class=\"n\">actual_percentile_thresholds</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.23</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">97.25</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">95.25</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.24</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">81.05</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">81.05</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">76.16</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.07</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_ddsketch</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">98.5</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">96.55</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">94.64</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.93</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.95</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.53</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_tdigest</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.23</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">97.25</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">95.23</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.24</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">81.08</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">81.08</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">76.1</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.08</span><span class=\"p\">}</span>\n\n\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">ddsketch</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">0.74</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">0.72</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">0.64</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.76</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">0.49</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">0.49</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">0.28</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.65</span><span class=\"p\">}</span>\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">tdigest</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">0.02</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.04</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.04</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">0.08</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">}</span>\n\n</code></pre></div></div>\n\n<p>From above calculations we can deduce that, the percentile deviation in tdigest is close to actual percentile deviation i.e(&lt; 0.2 %), whereas the percentile deviation in ddsketch is approx (&lt; 0.6 %) which is still very accurate to the actual percentile.</p>\n\n<p>We further did a time and space complexity analysis for both the algorithms.Below were the observations.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">Sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">1000</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">sketch</span><span class=\"p\">(</span><span class=\"n\">DDSketch</span><span class=\"p\">):</span> <span class=\"mf\">4.124</span> <span class=\"n\">ms</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">tdigest</span><span class=\"p\">:</span> <span class=\"mf\">76.15</span> <span class=\"n\">ms</span>\n\n<span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">10000</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">DDSketch</span><span class=\"p\">:</span> <span class=\"mf\">27.54</span> <span class=\"n\">ms</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span> <span class=\"mf\">658.18</span> <span class=\"n\">ms</span>\n\n<span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">100000</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">DDSketch</span><span class=\"p\">:</span> <span class=\"mf\">298.89</span> <span class=\"n\">ms</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span>  <span class=\"mi\">7243</span> <span class=\"n\">ms</span> <span class=\"o\">-&gt;</span> <span class=\"mf\">7.243</span> <span class=\"n\">sec</span>\n</code></pre></div></div>\n\n<p>Based on the above calculation, we can see that for same sample size (100000) of data DDSketch 298.89 ms to calculate the sketch with deviation of &lt;0.6% from actual percentile and TDigest takes 7.243 sec with 0.2% deviation from actual percentile.</p>\n\n<p>Serialized object size Comparison:\nAs sketch or digest objects will be stored as serialized files, we also calculated the size of the objects</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">Sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">1000</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">DDSketch</span> <span class=\"nb\">object</span><span class=\"p\">:</span> <span class=\"mi\">4127</span> <span class=\"nb\">bytes</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span> <span class=\"mi\">10015</span> <span class=\"nb\">bytes</span>\n\n\n<span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">10000</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">DDSketch</span> <span class=\"nb\">object</span><span class=\"p\">:</span> <span class=\"mi\">5138</span> <span class=\"nb\">bytes</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span> <span class=\"mi\">17496</span> <span class=\"nb\">bytes</span>\n\n<span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">100000</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">DDSketch</span> <span class=\"nb\">object</span><span class=\"p\">:</span> <span class=\"mi\">6224</span> <span class=\"nb\">bytes</span><span class=\"p\">,</span> <span class=\"n\">at</span> <span class=\"n\">relative</span> <span class=\"n\">accuracy</span><span class=\"p\">(</span><span class=\"mf\">0.01</span><span class=\"p\">)</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span> <span class=\"mi\">22049</span> <span class=\"nb\">bytes</span><span class=\"p\">,</span> <span class=\"n\">at</span> <span class=\"n\">relative</span> <span class=\"n\">accuracy</span><span class=\"p\">(</span><span class=\"mf\">0.01</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"poc-conclusion\">POC Conclusion</h3>\n\n<p>Based on the above calculation, we can conclude that TDigest gives less deviation to accurate percentiles in comparison to DDSketch, consuming more memory and time. Whereas in our case, we can afford to have accuracy with deviation close to 1%, time and memory plays an important role in faster calculations of sketches.</p>\n\n<p>Hence, we went with the DDSketch algorithm which takes a nominal time and memory for creating sketches.</p>\n\n<h3 id=\"data-ingestion-pipeline-improved-architechture\">Data Ingestion Pipeline (Improved Architechture)</h3>\n\n<p>Now that we know that we need to create sketches, we need to create new sketches for every new data point regularly coming from millions of candidates taking tests at our platform. We needed a data ingestion pipeline for updation of these sketches in near real time.</p>\n\n<p>We built a data pipeline to update the sketch. Individual candidate skills and scores were stored in dynamo DB. Participation end triggers the data from Dynamo db to the map-reduce flow ;  the candidates skill data is consumed by reducer SQS queue. Reducer lambda takes data in batches of 10000 or 5 mins time intervals and reduces the data to skill-wise scores. These messages are then consumed by the SQS FIFO queue, which groups the data based on problem template and skills. This data is again consumed by the sketch update lambda, which generates the new sketch, merges the new skill sketch with the old sketch, and then calculates the percentile threshold. This flow in turn is consumed by the SQS queue which updates the data in the SQL table.</p>\n\n<p>Model for Storing the Percentile Threshold:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n<span class=\"n\">Class</span> <span class=\"n\">ProblemsPercentileThreshold</span><span class=\"p\">(</span><span class=\"n\">Base</span><span class=\"p\">,</span> <span class=\"n\">Generic</span><span class=\"p\">):</span>\n  <span class=\"s\">\"\"\"\n  Model to store the percentile thresholds of a problem.\n  \"\"\"</span>\n  <span class=\"n\">percentile_thresholds</span> <span class=\"o\">=</span> <span class=\"n\">JsonField</span><span class=\"p\">()</span>\n  <span class=\"n\">denominator</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"p\">.</span><span class=\"n\">IntegerField</span><span class=\"p\">()</span>\n  <span class=\"n\">sketch_file</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"p\">.</span><span class=\"n\">FileField</span><span class=\"p\">()</span> \n  <span class=\"n\">users_attempted</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"p\">.</span><span class=\"n\">IntegerField</span><span class=\"p\">()</span> <span class=\"c1\"># approach 4\n</span>  <span class=\"n\">last_updated_timestamp</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"p\">.</span><span class=\"n\">DateTimeField</span><span class=\"p\">()</span>\n\n</code></pre></div></div>\n\n<p>Script to do the initial precomutaion:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># DDSketch\n</span><span class=\"kn\">from</span> <span class=\"nn\">ddsketch</span> <span class=\"kn\">import</span> <span class=\"n\">DDSketch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">ddsketch.pb.ddsketch_pb2</span> <span class=\"kn\">import</span> <span class=\"n\">DDSketch</span> <span class=\"k\">as</span> <span class=\"n\">DDSketch_PB</span>\n<span class=\"kn\">from</span> <span class=\"nn\">ddsketch.pb.proto</span> <span class=\"kn\">import</span> <span class=\"n\">DDSketchProto</span>\n\n<span class=\"n\">sketch</span> <span class=\"o\">=</span> <span class=\"n\">DDSketch</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">score</span> <span class=\"ow\">in</span> <span class=\"n\">normailzed_scores</span><span class=\"p\">:</span>\n    <span class=\"n\">sketch</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">score</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># to serialize to string and store sketch\n</span><span class=\"n\">protobuf_obj</span> <span class=\"o\">=</span> <span class=\"n\">DDSketchProto</span><span class=\"p\">.</span><span class=\"n\">to_proto</span><span class=\"p\">(</span><span class=\"n\">sketch</span><span class=\"p\">)</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">protobuf_obj</span><span class=\"p\">.</span><span class=\"n\">SerializeToString</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># to deserialize back to obj\n</span><span class=\"n\">protobuf_obj</span> <span class=\"o\">=</span> <span class=\"n\">DDSketch_PB</span><span class=\"p\">()</span>\n<span class=\"n\">protobuf_obj</span><span class=\"p\">.</span><span class=\"n\">ParseFromString</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"n\">sketch</span> <span class=\"o\">=</span> <span class=\"n\">DDSketchProto</span><span class=\"p\">.</span><span class=\"n\">from_proto</span><span class=\"p\">(</span><span class=\"n\">protobuf_obj</span><span class=\"p\">)</span>\n<span class=\"c1\">###############################################################################################\n#T-digest\n</span><span class=\"kn\">from</span> <span class=\"nn\">tdigest</span> <span class=\"kn\">import</span> <span class=\"n\">TDigest</span>\n\n<span class=\"n\">digest</span> <span class=\"o\">=</span> <span class=\"n\">TDigest</span><span class=\"p\">()</span>\n<span class=\"n\">digest</span><span class=\"p\">.</span><span class=\"n\">batch_update</span><span class=\"p\">(</span><span class=\"n\">normailzed_scores</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># to serialize to json\n</span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"p\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">digest</span><span class=\"p\">.</span><span class=\"n\">to_dict</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># to deserialize\n</span><span class=\"n\">digest_dict</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"p\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"n\">digest</span> <span class=\"o\">=</span> <span class=\"n\">TDigest</span><span class=\"p\">()</span>\n<span class=\"n\">digest</span><span class=\"p\">.</span><span class=\"n\">update_from_dict</span><span class=\"p\">(</span><span class=\"n\">digest_dict</span><span class=\"p\">)</span>\n\n</code></pre></div></div>\n\n<p><img alt=\"improved architecture\" src=\"http://engineering.hackerearth.com/images/Data_ingestion_architechture.png\" /></p>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>We built <strong>global_benchmarking</strong> to reliably and effectively run resource-intensive and time-intensive percentile calculations asynchronously in the background. It is now responsible for running asynchronous flows for supporting benchmarking analysis on 1 million or more candidates. This is a beneficial insight for enabling recruiters to make best decisions as well as enabling candidates to improve their skill set.</p>\n\n<p>Posted by [Raunak choudhary] (https://www.linkedin.com/in/raunak-chowdhary-b49406b1)</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "http://engineering.hackerearth.com/rss",
      "value": "<h3 id=\"introduction\">Introduction</h3>\n\n<p>HackerEarth has lots of candidates getting evaluated on a daily basis. We have a feature that benchmarks candidates across the platform. Benchmarking is the process of creating the profile of the ideal candidate for a position, and then measuring all candidates against that profile.\nTo benchmark candidate skills against our millions of candidates, we decided to move away from our regular cron solution to build a more reliable and accurate data pipeline. To support this, we created a new data ingestion flow and data read flow. We moved away from our deterministic algorithms to probabilistic algorithms with <a href=\"https://github.com/DataDog/sketches-py\">DDSketch</a>.</p>\n\n<h3 id=\"problem\">Problem</h3>\n\n<p>Our old benchmarking solution was trying to compute the global benchmarking of a candidate on the fly by calculating the solve percentage of the individual skills and returning the geometric mean of all the skill benchmarks. We handle huge volumes of data every day. Analyzing this data itself\u2014for example, calculating a quantile was optimal in terms of resources.</p>\n\n<h3 id=\"solution\">Solution</h3>\n\n<p>We came up with a solution that computes an approximate quantile from a compressed representation of that data. We first need to appropriately summarize that data without incurring an excessive loss of fidelity. We do this by creating a sketch. Sketch algorithms generate sketches: smaller, more manageable data structures, from which we can calculate some properties of the original data.</p>\n\n<p>We considered various algorithms to accurately compute percentiles on noisy, large-scale, real-time data that we were receiving from candidates\u2019 skill scores. We considered using Tdigest and DDSketch. For our use case, DDSketch served the purpose.We did a POC and compared the accuracy of both the algorithms as shown below to come up with a finalized algorithm.</p>\n\n<h3 id=\"poc-results-and-observations\">POC results and observations</h3>\n\n<p>We compared the actual percentile ranges in comparison to the two probabilistic approaches we mentioned(DDSketch and T-DIgest), and these were the results. Note: we have run these tests on the random data samples from the POC point of view.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">Initial</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">1000</span><span class=\"p\">(</span><span class=\"n\">unbiased</span><span class=\"p\">)</span>\n<span class=\"n\">New</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span>  <span class=\"mi\">2</span><span class=\"o\">%</span> <span class=\"n\">of</span> <span class=\"n\">actual</span> <span class=\"n\">samples</span> <span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">e</span><span class=\"p\">.,</span> <span class=\"mi\">20</span>\n\n<span class=\"n\">actual_percentile_thresholds</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.1</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">97.56</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">96.31</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">91.37</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.44</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.44</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.79</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.27</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_ddsketch</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">98.5</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">98.5</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">96.55</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.93</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.95</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.53</span><span class=\"p\">}</span>\n\n\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">ddsketch</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">0.61</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.96</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.25</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">0.48</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.26</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.26</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.21</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.36</span><span class=\"p\">}</span>\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">tdigest</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.08</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.03</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.02</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.21</span><span class=\"p\">}</span>\n\n <span class=\"o\">--------------------------------------------------------------------------------</span>\n<span class=\"n\">Initial</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">(</span><span class=\"n\">unbiased</span><span class=\"p\">)</span>\n<span class=\"n\">New</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span>  <span class=\"mi\">2</span><span class=\"o\">%</span> <span class=\"n\">of</span> <span class=\"n\">actual</span> <span class=\"n\">samples</span> <span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">e</span><span class=\"p\">.,</span> <span class=\"mi\">10</span>\n<span class=\"n\">actual_percentile_thresholds</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.18</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">96.88</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">94.98</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.79</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.95</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.95</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.65</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">70.55</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_ddsketch</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">98.5</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">96.55</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">94.64</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.93</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.95</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">70.11</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_tdigest</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.33</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">97.0</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">94.99</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.84</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.97</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.97</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.83</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">70.58</span><span class=\"p\">}</span>\n\n\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">ddsketch</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">0.69</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">0.34</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">0.36</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.15</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">0.37</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">0.37</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.4</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">0.62</span><span class=\"p\">}</span>\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">tdigest</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.15</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.12</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.06</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.02</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.02</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.24</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.04</span><span class=\"p\">}</span>\n\n<span class=\"o\">--------------------------------------------------------------------------------</span>\n<span class=\"n\">Initial</span> <span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">5000</span><span class=\"p\">(</span><span class=\"n\">unbiased</span><span class=\"p\">)</span>\n<span class=\"n\">actual_percentile_thresholds</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.23</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">97.25</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">95.25</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.24</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">81.05</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">81.05</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">76.16</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.07</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_ddsketch</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">98.5</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">96.55</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">94.64</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.93</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">80.65</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">75.95</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.53</span><span class=\"p\">}</span>\n<span class=\"n\">percentile_thresholds_tdigest</span><span class=\"p\">:</span>  \n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">99.23</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">97.25</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">95.23</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">90.24</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">81.08</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">81.08</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">76.1</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"mf\">71.08</span><span class=\"p\">}</span>\n\n\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">ddsketch</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">0.74</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">0.72</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">0.64</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.76</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"mf\">0.49</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"mf\">0.49</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">0.28</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.65</span><span class=\"p\">}</span>\n<span class=\"n\">Deviation</span> <span class=\"k\">for</span> <span class=\"n\">tdigest</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s\">'p99'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p97'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p95'</span><span class=\"p\">:</span> <span class=\"mf\">0.02</span><span class=\"p\">,</span> <span class=\"s\">'p90'</span><span class=\"p\">:</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"s\">'p85'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.04</span><span class=\"p\">,</span> <span class=\"s\">'p80'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.04</span><span class=\"p\">,</span> <span class=\"s\">'p75'</span><span class=\"p\">:</span> <span class=\"mf\">0.08</span><span class=\"p\">,</span> <span class=\"s\">'p70'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">}</span>\n\n</code></pre></div></div>\n\n<p>From above calculations we can deduce that, the percentile deviation in tdigest is close to actual percentile deviation i.e(&lt; 0.2 %), whereas the percentile deviation in ddsketch is approx (&lt; 0.6 %) which is still very accurate to the actual percentile.</p>\n\n<p>We further did a time and space complexity analysis for both the algorithms.Below were the observations.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">Sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">1000</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">sketch</span><span class=\"p\">(</span><span class=\"n\">DDSketch</span><span class=\"p\">):</span> <span class=\"mf\">4.124</span> <span class=\"n\">ms</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">tdigest</span><span class=\"p\">:</span> <span class=\"mf\">76.15</span> <span class=\"n\">ms</span>\n\n<span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">10000</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">DDSketch</span><span class=\"p\">:</span> <span class=\"mf\">27.54</span> <span class=\"n\">ms</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span> <span class=\"mf\">658.18</span> <span class=\"n\">ms</span>\n\n<span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">100000</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">DDSketch</span><span class=\"p\">:</span> <span class=\"mf\">298.89</span> <span class=\"n\">ms</span>\n<span class=\"n\">Time</span> <span class=\"n\">taken</span> <span class=\"n\">to</span> <span class=\"n\">add</span> <span class=\"n\">samples</span> <span class=\"n\">to</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span>  <span class=\"mi\">7243</span> <span class=\"n\">ms</span> <span class=\"o\">-&gt;</span> <span class=\"mf\">7.243</span> <span class=\"n\">sec</span>\n</code></pre></div></div>\n\n<p>Based on the above calculation, we can see that for same sample size (100000) of data DDSketch 298.89 ms to calculate the sketch with deviation of &lt;0.6% from actual percentile and TDigest takes 7.243 sec with 0.2% deviation from actual percentile.</p>\n\n<p>Serialized object size Comparison:\nAs sketch or digest objects will be stored as serialized files, we also calculated the size of the objects</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">Sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">1000</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">DDSketch</span> <span class=\"nb\">object</span><span class=\"p\">:</span> <span class=\"mi\">4127</span> <span class=\"nb\">bytes</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span> <span class=\"mi\">10015</span> <span class=\"nb\">bytes</span>\n\n\n<span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">10000</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">DDSketch</span> <span class=\"nb\">object</span><span class=\"p\">:</span> <span class=\"mi\">5138</span> <span class=\"nb\">bytes</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span> <span class=\"mi\">17496</span> <span class=\"nb\">bytes</span>\n\n<span class=\"n\">sample</span> <span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"mi\">100000</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">DDSketch</span> <span class=\"nb\">object</span><span class=\"p\">:</span> <span class=\"mi\">6224</span> <span class=\"nb\">bytes</span><span class=\"p\">,</span> <span class=\"n\">at</span> <span class=\"n\">relative</span> <span class=\"n\">accuracy</span><span class=\"p\">(</span><span class=\"mf\">0.01</span><span class=\"p\">)</span>\n<span class=\"n\">Size</span> <span class=\"n\">of</span> <span class=\"n\">serialized</span> <span class=\"n\">TDigest</span><span class=\"p\">:</span> <span class=\"mi\">22049</span> <span class=\"nb\">bytes</span><span class=\"p\">,</span> <span class=\"n\">at</span> <span class=\"n\">relative</span> <span class=\"n\">accuracy</span><span class=\"p\">(</span><span class=\"mf\">0.01</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"poc-conclusion\">POC Conclusion</h3>\n\n<p>Based on the above calculation, we can conclude that TDigest gives less deviation to accurate percentiles in comparison to DDSketch, consuming more memory and time. Whereas in our case, we can afford to have accuracy with deviation close to 1%, time and memory plays an important role in faster calculations of sketches.</p>\n\n<p>Hence, we went with the DDSketch algorithm which takes a nominal time and memory for creating sketches.</p>\n\n<h3 id=\"data-ingestion-pipeline-improved-architechture\">Data Ingestion Pipeline (Improved Architechture)</h3>\n\n<p>Now that we know that we need to create sketches, we need to create new sketches for every new data point regularly coming from millions of candidates taking tests at our platform. We needed a data ingestion pipeline for updation of these sketches in near real time.</p>\n\n<p>We built a data pipeline to update the sketch. Individual candidate skills and scores were stored in dynamo DB. Participation end triggers the data from Dynamo db to the map-reduce flow ;  the candidates skill data is consumed by reducer SQS queue. Reducer lambda takes data in batches of 10000 or 5 mins time intervals and reduces the data to skill-wise scores. These messages are then consumed by the SQS FIFO queue, which groups the data based on problem template and skills. This data is again consumed by the sketch update lambda, which generates the new sketch, merges the new skill sketch with the old sketch, and then calculates the percentile threshold. This flow in turn is consumed by the SQS queue which updates the data in the SQL table.</p>\n\n<p>Model for Storing the Percentile Threshold:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n<span class=\"n\">Class</span> <span class=\"n\">ProblemsPercentileThreshold</span><span class=\"p\">(</span><span class=\"n\">Base</span><span class=\"p\">,</span> <span class=\"n\">Generic</span><span class=\"p\">):</span>\n  <span class=\"s\">\"\"\"\n  Model to store the percentile thresholds of a problem.\n  \"\"\"</span>\n  <span class=\"n\">percentile_thresholds</span> <span class=\"o\">=</span> <span class=\"n\">JsonField</span><span class=\"p\">()</span>\n  <span class=\"n\">denominator</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"p\">.</span><span class=\"n\">IntegerField</span><span class=\"p\">()</span>\n  <span class=\"n\">sketch_file</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"p\">.</span><span class=\"n\">FileField</span><span class=\"p\">()</span> \n  <span class=\"n\">users_attempted</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"p\">.</span><span class=\"n\">IntegerField</span><span class=\"p\">()</span> <span class=\"c1\"># approach 4\n</span>  <span class=\"n\">last_updated_timestamp</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"p\">.</span><span class=\"n\">DateTimeField</span><span class=\"p\">()</span>\n\n</code></pre></div></div>\n\n<p>Script to do the initial precomutaion:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># DDSketch\n</span><span class=\"kn\">from</span> <span class=\"nn\">ddsketch</span> <span class=\"kn\">import</span> <span class=\"n\">DDSketch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">ddsketch.pb.ddsketch_pb2</span> <span class=\"kn\">import</span> <span class=\"n\">DDSketch</span> <span class=\"k\">as</span> <span class=\"n\">DDSketch_PB</span>\n<span class=\"kn\">from</span> <span class=\"nn\">ddsketch.pb.proto</span> <span class=\"kn\">import</span> <span class=\"n\">DDSketchProto</span>\n\n<span class=\"n\">sketch</span> <span class=\"o\">=</span> <span class=\"n\">DDSketch</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">score</span> <span class=\"ow\">in</span> <span class=\"n\">normailzed_scores</span><span class=\"p\">:</span>\n    <span class=\"n\">sketch</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">score</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># to serialize to string and store sketch\n</span><span class=\"n\">protobuf_obj</span> <span class=\"o\">=</span> <span class=\"n\">DDSketchProto</span><span class=\"p\">.</span><span class=\"n\">to_proto</span><span class=\"p\">(</span><span class=\"n\">sketch</span><span class=\"p\">)</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">protobuf_obj</span><span class=\"p\">.</span><span class=\"n\">SerializeToString</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># to deserialize back to obj\n</span><span class=\"n\">protobuf_obj</span> <span class=\"o\">=</span> <span class=\"n\">DDSketch_PB</span><span class=\"p\">()</span>\n<span class=\"n\">protobuf_obj</span><span class=\"p\">.</span><span class=\"n\">ParseFromString</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"n\">sketch</span> <span class=\"o\">=</span> <span class=\"n\">DDSketchProto</span><span class=\"p\">.</span><span class=\"n\">from_proto</span><span class=\"p\">(</span><span class=\"n\">protobuf_obj</span><span class=\"p\">)</span>\n<span class=\"c1\">###############################################################################################\n#T-digest\n</span><span class=\"kn\">from</span> <span class=\"nn\">tdigest</span> <span class=\"kn\">import</span> <span class=\"n\">TDigest</span>\n\n<span class=\"n\">digest</span> <span class=\"o\">=</span> <span class=\"n\">TDigest</span><span class=\"p\">()</span>\n<span class=\"n\">digest</span><span class=\"p\">.</span><span class=\"n\">batch_update</span><span class=\"p\">(</span><span class=\"n\">normailzed_scores</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># to serialize to json\n</span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"p\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">digest</span><span class=\"p\">.</span><span class=\"n\">to_dict</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># to deserialize\n</span><span class=\"n\">digest_dict</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"p\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"n\">digest</span> <span class=\"o\">=</span> <span class=\"n\">TDigest</span><span class=\"p\">()</span>\n<span class=\"n\">digest</span><span class=\"p\">.</span><span class=\"n\">update_from_dict</span><span class=\"p\">(</span><span class=\"n\">digest_dict</span><span class=\"p\">)</span>\n\n</code></pre></div></div>\n\n<p><img alt=\"improved architecture\" src=\"http://engineering.hackerearth.com/images/Data_ingestion_architechture.png\" /></p>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>We built <strong>global_benchmarking</strong> to reliably and effectively run resource-intensive and time-intensive percentile calculations asynchronously in the background. It is now responsible for running asynchronous flows for supporting benchmarking analysis on 1 million or more candidates. This is a beneficial insight for enabling recruiters to make best decisions as well as enabling candidates to improve their skill set.</p>\n\n<p>Posted by [Raunak choudhary] (https://www.linkedin.com/in/raunak-chowdhary-b49406b1)</p>"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "http://engineering.hackerearth.com/2023/09/17/building-a-relaible-global-benchmarking-platform/"
      }
    ],
    "link": "http://engineering.hackerearth.com/2023/09/17/building-a-relaible-global-benchmarking-platform/",
    "id": "http://engineering.hackerearth.com/2023/09/17/building-a-relaible-global-benchmarking-platform",
    "guidislink": false,
    "published": "2023-09-17T00:00:00+00:00",
    "published_parsed": [
      2023,
      9,
      17,
      0,
      0,
      0,
      6,
      260,
      0
    ]
  },
  "Cloudera": {
    "title": "Cloudera Week of Giving Recap",
    "xmlUrl": "https://blog.cloudera.com/feed/",
    "htmlUrl": "https://blog.cloudera.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.cloudera.com/feed/",
      "value": "Cloudera Week of Giving Recap"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.cloudera.com/cloudera-week-of-giving-recap/"
      }
    ],
    "link": "https://blog.cloudera.com/cloudera-week-of-giving-recap/",
    "comments": "https://blog.cloudera.com/cloudera-week-of-giving-recap/#respond",
    "authors": [
      {
        "name": "Debbie Kruger"
      }
    ],
    "author": "Debbie Kruger",
    "author_detail": {
      "name": "Debbie Kruger"
    },
    "published": "Fri, 22 Dec 2023 14:00:36 +0000",
    "published_parsed": [
      2023,
      12,
      22,
      14,
      0,
      36,
      4,
      356,
      0
    ],
    "tags": [
      {
        "term": "Culture",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://blog.cloudera.com/?p=146469",
    "guidislink": false,
    "summary": "<p>500 Clouderans engaged, 1.3K hours volunteered, $93,000 donated and more!</p>\n<p>The post <a href=\"https://blog.cloudera.com/cloudera-week-of-giving-recap/\">Cloudera Week of Giving Recap</a> appeared first on <a href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.cloudera.com/feed/",
      "value": "<p>500 Clouderans engaged, 1.3K hours volunteered, $93,000 donated and more!</p>\n<p>The post <a href=\"https://blog.cloudera.com/cloudera-week-of-giving-recap/\">Cloudera Week of Giving Recap</a> appeared first on <a href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.cloudera.com/feed/",
        "value": "<img src=\"https://blog.cloudera.com/wp-content/uploads/2023/10/felix-russell-saw-106849-2-273x182.jpg\" /><p>his November, Cloudera hosted its annual Week of Giving\u00a0 \u2013 a dedicated time each year for employees to come together as a community \u2013 to engage with one another and to make a positive impact in our society.</p>\n<p>From Sao Paolo to Seattle, London to Shanghai, nearly 500 Clouderans participated, supporting causes meaningful to them. Together, we supported 345 nonprofit organizations \u2013 donating over 1,300 volunteer hours and $93,000.</p>\n<blockquote><p>\u201cParticipating in Week of Giving was one of the best moments of this year, being able to connect with other colleagues while doing something meaningful outside of our day to day job.\u201d</p></blockquote>\n<p>Take a look at some of the highlights from throughout the week:</p>\n<p>&nbsp;</p>\n<p>Giving back is an integral part of Cloudera\u2019s culture. In addition to Week of Giving, we are proud to match employee donations, incentivize volunteering\u00a0 and cultivate a network of global volunteer ambassadors to ensure we carry the momentum of Week of Giving throughout the year.</p>\n<p>The post <a href=\"https://blog.cloudera.com/cloudera-week-of-giving-recap/\">Cloudera Week of Giving Recap</a> appeared first on <a href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://blog.cloudera.com/cloudera-week-of-giving-recap/feed/",
    "slash_comments": "0"
  },
  "Freeletics": {
    "title": "droidcon Berlin 2021: impressions and trends",
    "xmlUrl": "https://freeletics.engineering/feed.xml",
    "htmlUrl": "https://freeletics.engineering/",
    "title_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://freeletics.engineering/feed.xml",
      "value": "droidcon Berlin 2021: impressions and trends"
    },
    "links": [
      {
        "href": "https://freeletics.engineering/2021/11/16/droidcon-berlin-2021.html",
        "rel": "alternate",
        "type": "text/html",
        "title": "droidcon Berlin 2021: impressions and trends"
      }
    ],
    "link": "https://freeletics.engineering/2021/11/16/droidcon-berlin-2021.html",
    "published": "2021-11-16T11:00:00+00:00",
    "published_parsed": [
      2021,
      11,
      16,
      11,
      0,
      0,
      1,
      320,
      0
    ],
    "updated": "2021-11-16T11:00:00+00:00",
    "updated_parsed": [
      2021,
      11,
      16,
      11,
      0,
      0,
      1,
      320,
      0
    ],
    "id": "https://freeletics.engineering/2021/11/16/droidcon-berlin-2021",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://freeletics.engineering/2021/11/16/droidcon-berlin-2021.html",
        "value": "<p>Last month three Android engineers from Freeletics went to the first in a long time in-person conference - droidcon Berlin 2021. The conference was packed with interesting topics, this blog post is just a snapshot of topics we were most interested in.</p>\n\n<p>Full content of the conference can be found <a href=\"https://www.berlin.droidcon.com/schedule\">here</a>, all the talks have been recorded and can be found <a href=\"https://www.droidcon.com/content/?filter_postyear=2021&amp;filter_post_event_tag=droidcon-berlin\">here</a>.</p>\n\n<h2 id=\"about-the-conference\">About the conference</h2>\n<p>droidcon Berlin is <strong>one of the oldest Android conferences in the world</strong> making its first appearance in 2009 only 1 year after Android 1.0 was released. The conference is known for attracting some of the most famous people in the Android community in Europe and worldwide, such as private contributors, Google Developer Experts, Kotlin experts, engineers from Google. What was great, is that participants were able to propose their own topics for the 3rd day of the conference, which was focused on the community. Topics and panel discussions for that day were chosen by popular vote.</p>\n\n<h2 id=\"keynote-speaker---chet-haase\">Keynote speaker - Chet Haase</h2>\n<p>Chet is one of the early engineers on the Android project, having joined the project in 2010 just 2 years after Android 1.0. He has been mostly working on and leading the UI Toolkit team at Google and is probably most known in the community as a host of <a href=\"https://open.spotify.com/show/1oROjHFwXUkoeqgivvgAal?si=aI_rkONLQ5WZ-dHBzi9ldQ\">Android Developers Backstage</a> podcast.</p>\n\n<p>In his keynote presentation, Chet took a dive into the history of Android as a software project outlining challenges the team had to face in the early stages. The team had to pivot from the initial idea of building a software platform for cameras, push the idea through with the VCs and face a vigorous competition on the market at the time (Symbian OS, Blackberry RIM, later iPhone).</p>\n\n<p><strong>One of the key reasons for success was having a long-term vision for the product</strong>, according to Chet. In the end the project managed to succeed and Android became the most widespread mobile platform running on more than 3 billion devices today, giving millions of developers (including us) room for creativity.</p>\n\n<h2 id=\"the-main-trend-in-android-development-in-2021---surprise-surprise-jetpack-compose\">The main trend in Android development in 2021-  (surprise, surprise) Jetpack Compose</h2>\n<p>Earlier this year Jetpack Compose reached its official 1.0 production release status. Jetpack Compose is a new approach to defining UI elements on Android in a declarative way (similar to SwiftUI on Apple devices). UI elements can be represented as Composable Kotlin functions as opposed to using XML text files, the approach that was predominantly used before since the inception of Android.</p>\n\n<p>Naturally a 2021 Android conference was dominated by Compose-related topics, ranging from <a href=\"https://www.droidcon.com/2021/11/10/the-journey-of-adopting-jetpack-compose-in-babbels-app/\">migration stories</a> with gotchas when adopting Compose, <a href=\"https://www.droidcon.com/2021/11/10/hosting-our-states-in-compose/\">state management</a> and interoperability to deep dives into the <a href=\"https://www.droidcon.com/2021/11/10/a-hitchhikers-guide-to-compose-compiler-composers-compiler-plugins-and-snapshots/\">internals of Compose</a> covering rendering model with group slots, snapshots and <a href=\"https://www.droidcon.com/2021/11/10/testing-jetpack-compose-ui/\">testing</a>.</p>\n\n<p>Surprisingly, not that many companies are using Compose in their production environment, according to the data from the \u201cmost\u201d reliable source - a vote by show of hands in the room. For us though, <strong>every new screen we\u2019ve shiped since the release of Jetpack Compose has been built using Compose, which is something we can be proud of.</strong></p>\n\n<h2 id=\"kotlin-flows\">Kotlin Flows</h2>\n<p>Flows, despite being cold, have been a hot topic for a while now. Many Android developers are using Jetpacks LiveData these days, to handle UI updates in a lifecycle aware way. Now Flows are the new thing that everyone talks about. But are they an easy drop-in replacement for LiveData? \nThis question is answered by Fatih Giris\u2019 talk <a href=\"https://www.droidcon.com/2021/11/10/using-kotlin-flow-in-mvvm/\">Using Kotlin Flow in MVVM</a>. In his talk, Fatih shows step by step how we can replace LiveData with Flows and which caveats are waiting for us. He details the differences between both technologies and shows how Flows can be made lifecycle aware (Spoiler: They aren\u2019t by default). He offers a way to slowly migrate, by using LiveData and Flow together, before removing LiveData completely. To top it off, he shows how to easily write UnitTests when using Flows. You can check out his slides <a href=\"https://speakerdeck.com/fgiris/using-kotlin-flow-in-mvvm\">here</a> or his Medium article about the talk <a href=\"https://proandroiddev.com/using-livedata-flow-in-mvvm-part-i-a98fe06077a0\">here</a>.</p>\n\n<h2 id=\"annotation-processors\">Annotation Processors</h2>\n<p>A personal highlight for us was the talk <a href=\"https://www.droidcon.com/2021/11/10/your-own-annotation-processor/\">Your own Annotation Processor</a> by Gabriel Samojlo. Annotation Processors is the topic most Android developers have heard about, but not everyone is familiar with how they work, not to mention how to build one. In short, an Annotation Processor scans the code for Annotations (e.g. @Singleton) in order to process the annotated code and do something with it. In many cases this mechanism is used to auto-generate code, which is very convenient for developers because it reduces boilerplate code and saves development time. And this is exactly what Gabriel impressively demonstrated in his 40 min talk, by showing a hands-on example on how to implement a simple Annotation Processor, which generates \u201ckotlinx.serializable\u201d data models just by adding one annotation to it. If you want to check out this example for yourself, head over to his Github page, where he provides the <a href=\"https://github.com/GabrielSamojlo/annotation-processor\">source code</a> for this talk.</p>\n\n<h2 id=\"scaling-an-android-app\">Scaling an Android app</h2>\n<p>There were plenty of talks that addressed classical Software Engineering challenges. How should the app architecture evolve when the team is going through a rapid growth phase in a way that multiple teams are able to work independently? Engineers from Zalando gave an <a href=\"https://www.droidcon.com/2021/11/10/scaling-app-development-at-zalando/\">overview</a> of their app architecture evolution in such a phase showing interesting insights into how their gradle setup evolved over time.</p>\n\n<p>Assuring multiple teams work together in a productive way goes hand in hand with build and release automations. Naturally, there has been no shortage of CI/CD related topics. The one that we found the most interesting was the talk from Ubiratan Soares where he <a href=\"https://www.droidcon.com/2021/11/10/automating-android-workflows-with-github-actions/\">demonstrated</a> how easy it is to work with GitHub actions to configure daily Android workflows.</p>\n\n<h2 id=\"wrap-up\">Wrap up</h2>\n<p>Overall we had a great time in Berlin and enjoyed the conference. Even though most of the conferences nowadays can be streamed or watched later from home, <strong>it\u2019s nice to see fellow Android developers from other companies in person and stumble upon old colleagues</strong>.</p>\n\n<p>Going to an in-person conference is definitely one of the best ways to get yourself familiar with the tech scene in Germany and in Europe, which is especially important for those of us relatively new here. Listening to conference talks can be a good first push to start on a learning path of a topic that has long been in some old dusty TODO list.</p>\n\n<p><img alt=\"Alexey, Sebastian and Thomas at droidcon\" src=\"https://freeletics.engineering/images/droidcon/together_picture.jpg\" /></p>\n\n<center>Alexey Reznik, Sebastian Neubauer, Thomas Kioko</center>"
      }
    ],
    "summary": "Last month three Android engineers from Freeletics went to the first in a long time in-person conference - droidcon Berlin 2021. The conference was packed with interesting topics, this blog post is just a snapshot of topics we were most interested in.",
    "authors": [
      {
        "name": "Alexey Reznik"
      }
    ],
    "author_detail": {
      "name": "Alexey Reznik"
    },
    "author": "Alexey Reznik",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://freeletics.engineering/feed.xml",
      "value": "Last month three Android engineers from Freeletics went to the first in a long time in-person conference - droidcon Berlin 2021. The conference was packed with interesting topics, this blog post is just a snapshot of topics we were most interested in."
    }
  },
  "Localytics": {
    "title": "Saving Money and Protecting Privacy With Bloom Filters",
    "xmlUrl": "https://eng.localytics.com/rss/",
    "htmlUrl": "http://eng.localytics.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://eng.localytics.com/rss/",
      "value": "Saving Money and Protecting Privacy With Bloom Filters"
    },
    "summary": "<!--kg-card-begin: markdown--><p>The EU General Data Protection Regulation (GDPR) went into effect on May 25th, 2018 and stipulates that companies processing personally identifiable information (PII) must carry out requests from end users to be &#x2018;forgotten&#x2019; from their systems. Implementing this right to be forgotten (RTBF) for our products means that</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://eng.localytics.com/rss/",
      "value": "<!--kg-card-begin: markdown--><p>The EU General Data Protection Regulation (GDPR) went into effect on May 25th, 2018 and stipulates that companies processing personally identifiable information (PII) must carry out requests from end users to be &#x2018;forgotten&#x2019; from their systems. Implementing this right to be forgotten (RTBF) for our products means that</p>"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://eng.localytics.com/saving-money-protecting-privacy-with-bloom-filters/"
      }
    ],
    "link": "https://eng.localytics.com/saving-money-protecting-privacy-with-bloom-filters/",
    "id": "5e30631d4fcd4100174d7765",
    "guidislink": false,
    "authors": [
      {
        "name": "Tristan Garwood"
      }
    ],
    "author": "Tristan Garwood",
    "author_detail": {
      "name": "Tristan Garwood"
    },
    "published": "Mon, 27 Aug 2018 17:08:17 GMT",
    "published_parsed": [
      2018,
      8,
      27,
      17,
      8,
      17,
      0,
      239,
      0
    ],
    "media_content": [
      {
        "url": "https://eng.localytics.com/content/images/2018/08/bloom-blossom-delicate-699919.jpg",
        "medium": "image"
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://eng.localytics.com/rss/",
        "value": "<!--kg-card-begin: markdown--><img alt=\"Saving Money and Protecting Privacy With Bloom Filters\" src=\"https://eng.localytics.com/content/images/2018/08/bloom-blossom-delicate-699919.jpg\" /><p>The EU General Data Protection Regulation (GDPR) went into effect on May 25th, 2018 and stipulates that companies processing personally identifiable information (PII) must carry out requests from end users to be &#x2018;forgotten&#x2019; from their systems. Implementing this right to be forgotten (RTBF) for our products means that not only do we need to take care of deleting historical data, but also filter out new data uploaded by the Localytics SDK to our backend services. It is impossible to guarantee that data from opted-out users won&#x2019;t end up in our ingestion pipeline due to the inherently unpredictable nature of distributed systems, so we have to do a GDPR status check against every data-point. To put this in perspective, we ingest on the order of 50k data-points per second on a typical day.</p>\n<p>As an AWS-native shop, DynamoDB is our NoSQL database of choice for ultra low-latency high-throughput point lookups in our ingestion pipeline. We already use DynamoDB to track and update user profiles for every data-point. At current prices (2018) the required additional read capacity would cost an extra $4500 per month at our present volume.</p>\n<p>In order to help reduce the extra costs associated with GDPR compliance, we took a look at bloom filters. Bloom filters are probabilistic data structures that allow for quick lookups and efficient memory usage. The tradeoff is that bloom filters have a non-zero false positive rate. However, it will always give you a positive answer for something that is actually in the bloom filter. The size and lookup speed of the bloom filter is directly related to this false positive rate.</p>\n<p>Our implementation of the GDPR data-point filter is as follows: We fill a bloom filter with opted-out users, serialize it, and upload it to S3. The bloom filters need to be recreated each time because you can only add, not remove keys. Our ingestion pipeline periodically downloads the newest bloom filter version and loads it into memory. We first check an incoming data-point against the bloom filter, and for every positive bloom filter check we make a call to a DynamoDB table that stores the user&#x2019;s true opt-in/out status. When we verify that the data is from an opted-out user, we simply drop the data-point. This implementation allows us to adjust the amount of DynamoDB calls and thus our costs based on the false positive rate. Once we perform the check for that user against our DynamoDB database, we additionally cache the result to save on subsequent DynamoDB requests.</p>\n<p>Let&#x2019;s look at a typical second long window of our data ingestion pipeline and crunch some numbers. First, let me define 1 data-point/second as 1 dpps for convenience, also let&#x2019;s assume that the dpps from opted-out users is small relative to everyone else. With 50k dpps being pretty standard for daily peak usage and a bloom filter false positive rate of 1 in 10,000, you&#x2019;re looking at about 50 dpps making it through the bloom filter. Our caching layer (to handle duplicates) typically cuts the actual number of requests to the database in half, so in the end we actually only need to make about 25 dpps dynamo calls. This is only about 0.05% of all the data-points that we actually need to hit the database for and only amounts to about $2 of extra dynamo charges per month. The size of the serialized bloom filter files amount to about 750 KB each, so there is room to decrease the false positive rate even further as long as available memory is not an issue.</p>\n<p><img alt=\"Saving Money and Protecting Privacy With Bloom Filters\" src=\"https://eng.localytics.com/content/images/2018/08/6mj33rz7-268908-2.png\" /></p>\n<p>All in all, the pattern described above for doing simple filtering checks against a database turned out to be very successful. If we had only used a caching layer instead, we would be looking at about 1 thousand times more database calls. We are considering other places in our system where a dynamically updated bloom filter could be helpful in reducing database read costs. As long as you have sufficient memory available and are able to periodically and asynchronously recreate the bloom filter, it is definitely worth considering these handy data structures.</p>\n<!--kg-card-end: markdown-->"
      }
    ]
  },
  "Yahoo": {
    "title": "Bullet Updates - Windowing, Apache Pulsar PubSub, Configuration-based Data Ingestion, and More",
    "xmlUrl": "https://yahooeng.tumblr.com/rss",
    "htmlUrl": "https://yahooeng.tumblr.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://yahooeng.tumblr.com/rss",
      "value": "Bullet Updates - Windowing, Apache Pulsar PubSub, Configuration-based Data Ingestion, and More"
    },
    "summary": "<p><a class=\"tumblr_blog\" href=\"https://yahoodevelopers.tumblr.com/post/183271418613/bullet-updates-windowing-apache-pulsar-pubsub\">yahoodevelopers</a>:</p><blockquote>\n<p>By\u00a0<a href=\"https://www.linkedin.com/in/akshai-sarma-9029b011/\">Akshay Sarma</a>, Principal Engineer, Verizon Media &amp;\u00a0<a href=\"https://www.linkedin.com/in/brian-xiao-77276450/\">Brian Xiao</a>, Software Engineer, Verizon Media<br /></p>\n<p>This is the first of an ongoing series of blog posts sharing releases and announcements for <a href=\"https://bullet-db.github.io/\">Bullet</a>, an open-sourced lightweight, scalable, pluggable, multi-tenant query system.<b><br /></b></p>\n<p>Bullet allows you to query any data flowing through a streaming system without having to store it first through its UI or API. The queries are injected into the running system and have minimal overhead. Running hundreds of queries generally fit into the overhead of just reading the streaming data. Bullet requires running an instance of its backend on your data. This backend runs on common stream processing frameworks (Storm and Spark Streaming currently supported).</p>\n<p>The data on which Bullet sits determines what it is used for. For example, our team runs an instance of Bullet on user engagement data (~1M events/sec) to let developers find their own events to validate their code that produces this data. We also use this instance to interactively explore data, throw up quick dashboards to monitor live releases, count unique users, debug issues, and more.</p>\n<p>Since <a href=\"https://yahooeng.tumblr.com/post/161855616651/open-sourcing-bullet-yahoos-forward-looking\">open sourcing Bullet in 2017</a>, we\u2019ve been hard at work adding many new features! We\u2019ll highlight some of these here and continue sharing update posts for future releases.</p>\n<p><b>Windowing</b></p>\n<p>Bullet used to operate in a request-response fashion - you would submit a query and wait for the query to meet its termination conditions (usually duration) before receiving results. For short-lived queries, say, a few seconds, this was fine. But as we started fielding more interactive and iterative queries, waiting even a minute for results became too cumbersome.</p>\n<p>Enter windowing! Bullet now supports time and record-based windowing. With time windowing, you can break up your query into chunks of time over its duration and retrieve results for each chunk. \u00a0For example, you can calculate the average of a field, and stream back results every second:</p>\n<div style=\"text-align: center;\"><figure class=\"tmblr-embed tmblr-full\"></figure></div>\n<p>In the above example, the aggregation is operating on all the data since the beginning of the query, but you can also do aggregations on just the windows themselves. This is often called a <i>Tumbling</i> window:<br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/e20d505ff2dddf5e646f126523ea4f9a/tumblr_inline_pnyky3M0Gi1wxhpzr_540.png\" /></figure><p>With record windowing, you can get the intermediate aggregation for each record that matches your query (a <i>Sliding</i> window). Or you can do a <i>Tumbling </i>window on records rather than time. For example, you could get results back every three records:<br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/a4c9350a85b8a29345ce92fe1498f91f/tumblr_inline_pnykzfHVar1wxhpzr_540.png\" /></figure><p>Overlapping windows in other ways (Hopping windows) or windows that reset based on different criteria (Session windows, Cascading windows) are currently being worked on. Stay tuned! <br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/0e341961272f73dd68c0570ed3e9ac07/tumblr_inline_pnyl3nZiUB1wxhpzr_540.png\" /></figure><figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/7c6699716b3e92703e23a9ef6cc1b3a3/tumblr_inline_pnyl47zEuK1wxhpzr_540.png\" /></figure><p><b>Apache Pulsar support as a native PubSub</b><br /></p>\n<p>Bullet uses a PubSub (publish-subscribe) message queue to send queries and results between the Web Service and Backend. As with everything else in Bullet, the PubSub is pluggable. You can use your favorite pubsub by implementing a few interfaces if you don\u2019t want to use the ones we provide. Until now, we\u2019ve maintained and supported a REST-based PubSub and an<a href=\"https://kafka.apache.org/\"> Apache Kafka</a> PubSub. Now we are excited to announce supporting <a href=\"http://pulsar.apache.org/\">Apache Pulsar</a> as well! <a href=\"https://bullet-db.github.io/pubsub/pulsar/\">Bullet Pulsar</a> will be useful to those users who want to use Pulsar as their underlying messaging service.<br /></p>\n<p>If you aren\u2019t familiar with Pulsar, setting up a local standalone is very simple, and by default, any Pulsar topics written to will automatically be created. Setting up an instance of Bullet with Pulsar instead of REST or Kafka is just as easy. You can refer to <a href=\"https://bullet-db.github.io/pubsub/pulsar/\">our documentation</a> for more details.</p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/b89986b095cee04c79d62c6425c09db2/aa61dd2f27cdffc3-22/s540x810/1961af5bb2ad5d8f0d43770c99543618a0ecf453.png\" /></figure><p><b>Plug your data into Bullet without code</b></p>\n<p>While Bullet worked on any data source located in any persistence layer, you still had to implement an interface to connect your data source to the Backend and convert it into a record container format that Bullet understands. For instance, your data might be located in Kafka and be in the Avro format. If you were using Bullet on Storm, you would perhaps write a Storm Spout to read from Kafka, deserialize, and convert the Avro data into the Bullet record format. This was the only interface in Bullet that required our customers to write their own code. Not anymore! Bullet DSL is a text/configuration-based format for users to plug in their data to the Bullet Backend without having to write a single line of code.</p>\n<p><a href=\"https://bullet-db.github.io/backend/dsl/\">Bullet DSL</a> abstracts away the two major components for plugging data into the Bullet Backend. A Connector piece to read from arbitrary data-sources and a Converter piece to convert that read data into the Bullet record container. We currently support and maintain a few of these - Kafka and Pulsar for Connectors and\u00a0Avro, Maps and arbitrary Java POJOs for Converters. The Converters understand typed data and can even do a bit of minor ETL (Extract, Transform and Load) if you need to change your data around before feeding it into Bullet. As always, the DSL components are pluggable and you can write your own (and contribute it back!) if you need one that we don\u2019t support.</p>\n<p>We appreciate your feedback and contributions! Explore Bullet on <a href=\"https://github.com/bullet-db\">GitHub</a>, use and help contribute to the project, and chat with us on <a href=\"https://groups.google.com/forum/#!forum/bullet-users\">Google Groups</a>. To get started, try our Quickstarts on <a href=\"https://bullet-db.github.io/quick-start/spark/\">Spark</a> or <a href=\"https://bullet-db.github.io/quick-start/storm/\">Storm</a> to set up an instance of Bullet on some fake data and play around with it.</p>\n</blockquote>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://yahooeng.tumblr.com/rss",
      "value": "<p><a class=\"tumblr_blog\" href=\"https://yahoodevelopers.tumblr.com/post/183271418613/bullet-updates-windowing-apache-pulsar-pubsub\">yahoodevelopers</a>:</p><blockquote>\n<p>By\u00a0<a href=\"https://www.linkedin.com/in/akshai-sarma-9029b011/\">Akshay Sarma</a>, Principal Engineer, Verizon Media &amp;\u00a0<a href=\"https://www.linkedin.com/in/brian-xiao-77276450/\">Brian Xiao</a>, Software Engineer, Verizon Media<br /></p>\n<p>This is the first of an ongoing series of blog posts sharing releases and announcements for <a href=\"https://bullet-db.github.io/\">Bullet</a>, an open-sourced lightweight, scalable, pluggable, multi-tenant query system.<b><br /></b></p>\n<p>Bullet allows you to query any data flowing through a streaming system without having to store it first through its UI or API. The queries are injected into the running system and have minimal overhead. Running hundreds of queries generally fit into the overhead of just reading the streaming data. Bullet requires running an instance of its backend on your data. This backend runs on common stream processing frameworks (Storm and Spark Streaming currently supported).</p>\n<p>The data on which Bullet sits determines what it is used for. For example, our team runs an instance of Bullet on user engagement data (~1M events/sec) to let developers find their own events to validate their code that produces this data. We also use this instance to interactively explore data, throw up quick dashboards to monitor live releases, count unique users, debug issues, and more.</p>\n<p>Since <a href=\"https://yahooeng.tumblr.com/post/161855616651/open-sourcing-bullet-yahoos-forward-looking\">open sourcing Bullet in 2017</a>, we\u2019ve been hard at work adding many new features! We\u2019ll highlight some of these here and continue sharing update posts for future releases.</p>\n<p><b>Windowing</b></p>\n<p>Bullet used to operate in a request-response fashion - you would submit a query and wait for the query to meet its termination conditions (usually duration) before receiving results. For short-lived queries, say, a few seconds, this was fine. But as we started fielding more interactive and iterative queries, waiting even a minute for results became too cumbersome.</p>\n<p>Enter windowing! Bullet now supports time and record-based windowing. With time windowing, you can break up your query into chunks of time over its duration and retrieve results for each chunk. \u00a0For example, you can calculate the average of a field, and stream back results every second:</p>\n<div style=\"text-align: center;\"><figure class=\"tmblr-embed tmblr-full\"></figure></div>\n<p>In the above example, the aggregation is operating on all the data since the beginning of the query, but you can also do aggregations on just the windows themselves. This is often called a <i>Tumbling</i> window:<br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/e20d505ff2dddf5e646f126523ea4f9a/tumblr_inline_pnyky3M0Gi1wxhpzr_540.png\" /></figure><p>With record windowing, you can get the intermediate aggregation for each record that matches your query (a <i>Sliding</i> window). Or you can do a <i>Tumbling </i>window on records rather than time. For example, you could get results back every three records:<br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/a4c9350a85b8a29345ce92fe1498f91f/tumblr_inline_pnykzfHVar1wxhpzr_540.png\" /></figure><p>Overlapping windows in other ways (Hopping windows) or windows that reset based on different criteria (Session windows, Cascading windows) are currently being worked on. Stay tuned! <br /></p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/0e341961272f73dd68c0570ed3e9ac07/tumblr_inline_pnyl3nZiUB1wxhpzr_540.png\" /></figure><figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/7c6699716b3e92703e23a9ef6cc1b3a3/tumblr_inline_pnyl47zEuK1wxhpzr_540.png\" /></figure><p><b>Apache Pulsar support as a native PubSub</b><br /></p>\n<p>Bullet uses a PubSub (publish-subscribe) message queue to send queries and results between the Web Service and Backend. As with everything else in Bullet, the PubSub is pluggable. You can use your favorite pubsub by implementing a few interfaces if you don\u2019t want to use the ones we provide. Until now, we\u2019ve maintained and supported a REST-based PubSub and an<a href=\"https://kafka.apache.org/\"> Apache Kafka</a> PubSub. Now we are excited to announce supporting <a href=\"http://pulsar.apache.org/\">Apache Pulsar</a> as well! <a href=\"https://bullet-db.github.io/pubsub/pulsar/\">Bullet Pulsar</a> will be useful to those users who want to use Pulsar as their underlying messaging service.<br /></p>\n<p>If you aren\u2019t familiar with Pulsar, setting up a local standalone is very simple, and by default, any Pulsar topics written to will automatically be created. Setting up an instance of Bullet with Pulsar instead of REST or Kafka is just as easy. You can refer to <a href=\"https://bullet-db.github.io/pubsub/pulsar/\">our documentation</a> for more details.</p>\n<figure class=\"tmblr-full\"><img alt=\"image\" src=\"https://64.media.tumblr.com/b89986b095cee04c79d62c6425c09db2/aa61dd2f27cdffc3-22/s540x810/1961af5bb2ad5d8f0d43770c99543618a0ecf453.png\" /></figure><p><b>Plug your data into Bullet without code</b></p>\n<p>While Bullet worked on any data source located in any persistence layer, you still had to implement an interface to connect your data source to the Backend and convert it into a record container format that Bullet understands. For instance, your data might be located in Kafka and be in the Avro format. If you were using Bullet on Storm, you would perhaps write a Storm Spout to read from Kafka, deserialize, and convert the Avro data into the Bullet record format. This was the only interface in Bullet that required our customers to write their own code. Not anymore! Bullet DSL is a text/configuration-based format for users to plug in their data to the Bullet Backend without having to write a single line of code.</p>\n<p><a href=\"https://bullet-db.github.io/backend/dsl/\">Bullet DSL</a> abstracts away the two major components for plugging data into the Bullet Backend. A Connector piece to read from arbitrary data-sources and a Converter piece to convert that read data into the Bullet record container. We currently support and maintain a few of these - Kafka and Pulsar for Connectors and\u00a0Avro, Maps and arbitrary Java POJOs for Converters. The Converters understand typed data and can even do a bit of minor ETL (Extract, Transform and Load) if you need to change your data around before feeding it into Bullet. As always, the DSL components are pluggable and you can write your own (and contribute it back!) if you need one that we don\u2019t support.</p>\n<p>We appreciate your feedback and contributions! Explore Bullet on <a href=\"https://github.com/bullet-db\">GitHub</a>, use and help contribute to the project, and chat with us on <a href=\"https://groups.google.com/forum/#!forum/bullet-users\">Google Groups</a>. To get started, try our Quickstarts on <a href=\"https://bullet-db.github.io/quick-start/spark/\">Spark</a> or <a href=\"https://bullet-db.github.io/quick-start/storm/\">Storm</a> to set up an instance of Bullet on some fake data and play around with it.</p>\n</blockquote>"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://yahooeng.tumblr.com/post/183315480351"
      }
    ],
    "link": "https://yahooeng.tumblr.com/post/183315480351",
    "id": "https://yahooeng.tumblr.com/post/183315480351",
    "guidislink": false,
    "published": "Fri, 08 Mar 2019 09:12:50 -0800",
    "published_parsed": [
      2019,
      3,
      8,
      17,
      12,
      50,
      4,
      67,
      0
    ],
    "tags": [
      {
        "term": "open source",
        "scheme": null,
        "label": null
      },
      {
        "term": "big data",
        "scheme": null,
        "label": null
      },
      {
        "term": "javascript",
        "scheme": null,
        "label": null
      },
      {
        "term": "java",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "rosaliebeevm"
      }
    ],
    "author": "rosaliebeevm",
    "author_detail": {
      "name": "rosaliebeevm"
    }
  },
  "Latacora": {
    "title": "A Case for Password Hashing With Delegation",
    "xmlUrl": "https://latacora.micro.blog/feed.xml",
    "htmlUrl": "https://latacora.singles/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.latacora.com/blog/index.xml",
      "value": "A Case for Password Hashing With Delegation"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://latacora.github.io/blog/2023/12/22/case-for-password-hashing/"
      }
    ],
    "link": "https://latacora.github.io/blog/2023/12/22/case-for-password-hashing/",
    "published": "Fri, 22 Dec 2023 10:18:16 -0500",
    "published_parsed": [
      2023,
      12,
      22,
      15,
      18,
      16,
      4,
      356,
      0
    ],
    "id": "https://latacora.github.io/blog/2023/12/22/case-for-password-hashing/",
    "guidislink": false,
    "summary": "When people talk about PBKDFs (Password Based Key Derivation Functions), this is usually either in the context of secure password storage, or in the context of how to derive cryptographic keys from potentially low-entropy passwords. The Password Hashing Competition (PHC, 2013-2015) was an open competition to derive new password hashing algorithms, resulting in Argon2 hash as its winner. Apart from achieving general hash security, many of the candidates focused on achieving resistance to parallel attacks on available hardware such as GPUs.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.latacora.com/blog/index.xml",
      "value": "When people talk about PBKDFs (Password Based Key Derivation Functions), this is usually either in the context of secure password storage, or in the context of how to derive cryptographic keys from potentially low-entropy passwords. The Password Hashing Competition (PHC, 2013-2015) was an open competition to derive new password hashing algorithms, resulting in Argon2 hash as its winner. Apart from achieving general hash security, many of the candidates focused on achieving resistance to parallel attacks on available hardware such as GPUs."
    }
  },
  "Pinterest": {
    "title": "Evolution of Ads Conversion Optimization Models at Pinterest",
    "xmlUrl": "https://medium.com/feed/@Pinterest_Engineering",
    "htmlUrl": "https://medium.com/@Pinterest_Engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/@Pinterest_Engineering",
      "value": "Evolution of Ads Conversion Optimization Models at Pinterest"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/pinterest-engineering/evolution-of-ads-conversion-optimization-models-at-pinterest-84b244043d51?source=rss-ef81ef829bcb------2"
      }
    ],
    "link": "https://medium.com/pinterest-engineering/evolution-of-ads-conversion-optimization-models-at-pinterest-84b244043d51?source=rss-ef81ef829bcb------2",
    "id": "https://medium.com/p/84b244043d51",
    "guidislink": false,
    "tags": [
      {
        "term": "machine-learning",
        "scheme": null,
        "label": null
      },
      {
        "term": "pinterest",
        "scheme": null,
        "label": null
      },
      {
        "term": "monetization",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Pinterest Engineering"
      }
    ],
    "author": "Pinterest Engineering",
    "author_detail": {
      "name": "Pinterest Engineering"
    },
    "published": "Tue, 09 Jan 2024 16:40:55 GMT",
    "published_parsed": [
      2024,
      1,
      9,
      16,
      40,
      55,
      1,
      9,
      0
    ],
    "updated": "2024-01-10T20:27:04.495Z",
    "updated_parsed": [
      2024,
      1,
      10,
      20,
      27,
      4,
      2,
      10,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/@Pinterest_Engineering",
        "value": "<p>A Journey from GBDT to Multi-Task Ensemble\u00a0DNN</p><p>Aayush Mudgal | Senior Machine Learning Engineer, Ads Ranking Conversion Modeling; Han Sun | Senior Machine Learning Engineer, Ads Ranking Conversion Modeling; Matt Meng | Senior Machine Learning Engineer, Ads Ranking Conversion Modeling; Runze Su | Machine Learning Engineer II, Ads Ranking Conversion Modeling; Jinfeng Zhuang | Staff Machine Learning Engineer, Ads Ranking Conversion Modeling</p><p>In this blog post, we will share how we improved Pinterest\u2019s conversion optimization performance by leveraging Deep Neural Networks (DNN), Multi-Task Learning (MTL), state-of-the-art feature interaction modules, in-model ensemble techniques, and user sequence modeling. We will also cover our transition to GPU serving, which is indispensable for large-scale complex\u00a0models.</p><h3>Background</h3><p>People often come to Pinterest for inspiration on their next life or shopping ideas. In fact, over half of Pinterest users think of Pinterest as a place to shop. Ads and other content from businesses are an important part of the consumer journey because they add value to the discovery process. <strong>Conversion Optimization</strong> optimizes <strong>Promoted Pins</strong> for specific consumer conversion actions, rather than just clicks. Advertisers can choose conversions as a campaign objective and inspire people to take specific actions like online checkouts, increased signups, or stronger leads. In this blog we will deep dive into some of our recent advancements in machine learning modeling to connect pinners with the most relevant\u00a0ads.</p><p>The Ads Ranking system at Pinterest has many standard pieces of a recommendation system involving targeting, retrieval, ranking, auction, and allocation, as it needs to be responsive to more than 480 million monthly active users\u2019 actions and performance and billions of pieces of content on the platform. The ranking layer focuses on finding the relevant pins given the user context, so improving this part of the system has a significant impact on the user experiences. This blog post will focus on our recent improvements on improving the models that predict offsite conversions given a user request on Pinterest. The following is a very high level overview of how the conversion optimization system typically works.</p><figure><img alt=\"Conversion Optimization: High Level Overview\u200a\u2014\u200a1. Ad created, 2. Prediction, 3. Ad Served, 4. Ad Engagement, 5. Ad Conversion, 6. Ad Measurement (Ingestion -&gt; User Match -&gt; Attribution), 7. Training Data and Features\" src=\"https://cdn-images-1.medium.com/max/1024/0*RjnHkPLlI6BevJtD\" /><figcaption>Figure 1: A high level overview of conversion optimization pipeline</figcaption></figure><p>Before diving deeper into the model evolution, let\u2019s also look into the unique characteristics of Ads conversion prediction, which is very different from typical engagement ranking problems.</p><ol><li><strong>Label quality</strong>: Since conversion events happen on advertiser platforms, the quality of the label is dependent on the advertisers, so we often deal with inaccurate and abnormal conversion volumes. Besides, the user match and attribution process is probabilistic which further introduces noise in the\u00a0labels.</li><li><strong>Data volume and label sparsity</strong>: Conversion is a more downstream event, and is thus inherently much sparser than click events on the platform. This significantly limits the complexity of the model we can build. Since the label is sparser, it also requires higher traffic percentages or longer running A/B experiments to detect significant changes in metrics, slowing down the iteration speed.</li><li><strong>Delayed feedback</strong>: Conversions are observed with a long-tail delay distribution after the onsite engagements (clicks or views) have happened, resulting in false negative labels during training. This brings challenges on the model training strategy, e.g., the model\u2019s update frequency, and complicates calibration estimations of the learned\u00a0models.</li></ol><h3>Classic Machine Learning Model\u00a0Period</h3><p>In the beginning (2018), our ads ranking model was a hybrid of Gradient Boosted Decision Trees (GBDT), embedded as feature translators, and a logistic regression model. This design choice enabled us to build performant models quickly for the scale of data and machine learning stack of that time. Ad space, comprising advertisers, ad groups, and ad campaigns have very different label characteristics both in terms of quality and volume, hence generalization across the sparse ID space was top consideration. To enable this we utilized the <a href=\"https://en.wikipedia.org/wiki/Feature_hashing\">feature hashing trick </a>into the logistic regression layer to learn the ID space information and control cross-advertiser label\u00a0impacts.</p><p>As the product <strong>grew rapidly, fueled by increasing amounts of data</strong>, it required better scalability in model training and serving, as the previous design became the bottleneck for fast system growth. The next set of iterations happened by transitioning from this GBDT + logistic regression structure to a deep learning based single model, and also unlocking the ability to do Multi-Task Learning (MTL) by co-training multiple objectives together like clicks, good clicks, checkout, and add-to-cart conversions. Moving to MTL and leveraging onsite actions helped increase model robustness to sparser tasks and unleashed the power to learn from the holistic onsite and offsite experience. By 2020, we transitioned to AutoML (<a href=\"https://medium.com/pinterest-engineering/how-we-use-automl-multi-task-learning-and-multi-tower-models-for-pinterest-ads-db966c3dc99e\">link</a>), which was a shift from previous traditional machine learning approaches by introducing an automatic way of feature engineering. The engineers could work on developing raw features instead of hand crafting the complex feature interactions. However, over this period of time, we encountered significant technical debt as we were moving fast to bring technical advancements by patching over existing systems to bring the fastest results. Between 2021\u20132022 we accomplished a complete overhaul of the entire ML Platform (<a href=\"https://medium.com/pinterest-engineering/mlenv-standardizing-ml-at-pinterest-under-one-ml-engine-to-accelerate-innovation-e2b30b2f6768\">link</a>), also leveraging flattened feature structures and adopting more sampling near the model trainer. This infrastructure migration enabled us to have a much more robust backbone for a substantially wider range of modeling ideas. Next we will discuss some of the recent architectural advancements and the lessons that help power these models\u00a0today.</p><h3>Modern Model Architectural Advancement</h3><p>With the transition to AutoML (auto feature interaction) and the MLEnv (Unified ML Engine) framework, we are unblocked with<strong> much faster model architecture iteration speed</strong>. Since then, we have experimented, iterated, and launched a number of state-of-the-art modern model architectures. Here is our learning summary of the architecture evolution.</p><h4>Feature Interaction Modules</h4><p>A very important component in modern recommendation systems is the feature interaction learning modules. Starting from MLP, our model advancement iterates along the following three modules, as elaborated below:</p><figure><img alt=\"DCNv2, Transformer, Masknet models\" src=\"https://cdn-images-1.medium.com/max/1024/1*W4FNeFH7hKV4gwgEdxmbCQ.png\" /><figcaption>Figure 2: Different feature interaction modules</figcaption></figure><p><strong>DCNv2:</strong></p><p><a href=\"https://arxiv.org/abs/2008.13535\">DCNv2</a>, also known as Deep &amp; Cross Network version 2, is a step forward from the original DCN model. It introduces a cross network and multiple deep layers to capture both explicit and implicit feature interactions. With DCNv2, explicit low-ordered feature interactions are captured through a low-dimensional cross network with a feature crossing matrix, and other implicit feature interactions are captured in a deep network, which is similar to the MLP layers. It outperforms the MLP layers while there\u2019s a larger infrastructure cost due to the introduction of the cross\u00a0network.</p><p><strong>Transformer:</strong></p><p><a href=\"https://arxiv.org/abs/1706.03762\">Transformer</a> is originally proposed for natural language processing tasks, but it also shows great potential in learning feature crossing in the advertising field. The self-attention mechanism in the transformer encoder maps the input into Q(Query), K(Key) and V(Value), where Q and K capture the feature interaction and cast the interaction into V. Transformer has demonstrated its performance by significantly improving the model performance, but it also resulted in a high memory usage during training and relatively higher\u00a0latency.</p><p><strong>MaskNet:</strong></p><p><a href=\"https://arxiv.org/abs/2102.07619\">MaskNet</a> proposes an instance-guided mask method which uses element-wise products in both the feature embedding layer and the feedforward layer in DNN. The instance-guided mask contains global contextual information that is dynamically incorporated into the feature embedding layer and the feedforward layer to highlight the important features.</p><p>MaskBlock is the module for feature interaction learning. It consists of three parts: the instance-guided mask, the feedforward layer, and the normalization layer. With this structure, the standard DNN is extended to contain interactive feature structures that can be added and multiplied. MaskNet is one of the most popular modules in advertising and recommendation systems and is of high performance in feature crossing\u00a0modules.</p><h4>Modern Model Multi-tasking and Ensemble\u00a0Learning</h4><p><strong>Multi-Task Learning (MTL) and in-model ensembling frameworks</strong> have been pushing recommendation model performance limits in recent years. With many powerful state-of-the-art feature interaction algorithms\u2019 (above discussed, e.g., transformer feature interaction, masknet feature interaction, etc). We embraced all their powers together and explored the following directions</p><p>We introduced <strong>MTL</strong> to combine multiple conversion objectives into a unified model by leveraging abundant onsite actions like clicks on the platform to enhance the training of sparse conversion objectives. This not only benefited each conversion objective but also largely reduced model serving and maintenance cost, as well as improved experimentation iteration velocity.</p><figure><img alt=\"Single Task Architecture to Multi-Task Model Architecture\" src=\"https://cdn-images-1.medium.com/max/1024/1*4gLFHziEFyJmPi7ljH95dg.png\" /><figcaption>Figure 3: Architectural evolution from single task to a shared multi-task model architecture</figcaption></figure><p>In the next iteration, we made the model more robust and introduced in-model ensemble techniques, where we <strong>ensembled two model backbones for feature crossing: DCNv2 and transformer respectively. </strong>We curated an empirical formula for their output scores at inference to compute the final model prediction, while we maintained individual training loss and gradient descent for each ensembled model. This curated architecture was able to benefit from each model backbone\u2019s diverse learning.</p><figure><img alt=\"DCNv2 and Transformer Ensemble Model\" src=\"https://cdn-images-1.medium.com/max/1024/1*OgiMIpJX_csNUWarfaPhdA.png\" /><figcaption>Figure 4: Ensemble model structure with DCNv2 and Transformer as feature interaction modules</figcaption></figure><p>The above architecture significantly increased the serving infrastructure cost. Next we decoupled feature interaction modules from the feature processing modules and utilized a <strong>shared bottom architecture for feature processing</strong> while maintaining the top architecture separated. This evolution significantly reduced infra cost of the model while maintaining same level of performance after parameter tunings</p><figure><img alt=\"Shared Bottom Architecture\" src=\"https://cdn-images-1.medium.com/max/1024/1*Hf0nW5aRbXECuG6g9n4wFw.png\" /><figcaption>Figure 5: Model architecture that leverages shared feature processing layer before the ensemble feature interaction learning</figcaption></figure><p>Realizing the power of learning in-model ensemble, we wanted to next move to a principled way of doing the same. We adopted the <a href=\"https://arxiv.org/abs/2203.11014\"><strong>Deep and Hierarchical Ensemble Network</strong></a><strong> (DHEN) framework with user sequence and MaskNet feature interaction</strong>. This modeling framework is scalable, optimizable, and modularizable and achieved the best offline and online model performance compared to each of the previous architectural choices.</p><figure><img alt=\"DHEN + User Sequence\" src=\"https://cdn-images-1.medium.com/max/1024/1*SnvgajriaTaxvV400AjuaA.png\" /><figcaption>Figure 6: Model architecture with Sequence Transformer addition</figcaption></figure><h4>User Sequence\u00a0Modeling</h4><p>The capability to model user activity sequence is a powerful modern modeling technique. We have explored extensively in the area of user sequence modeling and launched it in our conversion ranking model with significant offline and online performance gains. There are several advantage of including user sequences into conversion models:</p><ul><li>With a <strong>long lookback window</strong>, user sequence is extremely effective to capture information from sparse data space\u200a\u2014\u200ain our particular case, user and Ads interactions. It is even more powerful for Ads user conversion optimizations, given its sparsity and delaying nature compared to user engagement optimizations.</li><li>A <strong>direct model training with user sequence data</strong> in conversion ranking models unleashes its power in learning user interest from user activities\u200a\u2014\u200afrom user offsite events that are directly related to offsite conversions, to user onsite engagements that represents user\u00a0intends.</li><li>The essence part of user sequence data is its <strong>temporal information</strong>. The incorporation of temporal dimensionality to ranking models allow the rich feature interaction modules to learn news-level, seasonal, and life-time user interest shifts and patterns. This information is vitally important serving as the backbone of user representation in the ranking\u00a0models.</li></ul><h3>Evaluation Results</h3><p>Together with other improvements, such as additional features to feed the advanced model architectures, our above iterations have achieved a significant amount of both offline and online metrics gains and we summarized the relative performance as\u00a0below.</p><figure><img alt=\"Relative Improvements for each model evolution, Offline Metrics: Area Under the Curve (AUC), Online Metrics: Conversion Volume\" src=\"https://cdn-images-1.medium.com/max/1024/1*3VgRhA8_tTy-Jj0O-hwQoQ.png\" /></figure><h3>GPU Serving</h3><p>Our model ensemble and feature interaction components have made significant advancements; however, serving these models has become increasingly complex. We initially used CPU clusters to serve these ranking models, but this restricted the model capacity we could use whilst still maintaining low latency. To serve these big models with minimal cost increments, we also transitioned to using GPUs for online\u00a0serving.</p><h4>CUDA Graphs</h4><p>With the migration of the ranking models to <a href=\"https://medium.com/pinterest-engineering/mlenv-standardizing-ml-at-pinterest-under-one-ml-engine-to-accelerate-innovation-e2b30b2f6768\">Pinterest\u2019s MLEnv and PyTorch based framework</a>\u00a0, we were able to easily leverage <a href=\"https://pytorch.org/docs/master/notes/cuda.html#constraints\">CUDA graphs</a> for online serving. The traditional launch of CPU kernels creates gaps and inadvertent overhead between launches. CUDA graphs greatly reduce these gaps, optimizing subsequent executions and minimizing delays. Using CUDA graphs does present certain constraints. For example, the network must be graph-safe. A crucial condition of using CUDA graphs is the need for tensor shapes in memory to be static\u200a\u2014\u200adynamic inputs with varying tensor dimensions cause numerical errors in CUDA graphs. We used zero padding to ensure constant feature dimensions for ragged and other dynamically-shaped tensors.</p><h4>Mixed Precision Serving</h4><p>To further cut down on the infrastructure costs of model serving, we implemented the technique of mixed precision serving. This technique is prevalent in large model training and inferencing; it merges the use of 32-bit floating point (FP32) and 16-bit floating point (FP16) data types. The end result is a reduction in memory usage and a boost in the speed of model development and inference, all without compromising the accuracy of the model\u2019s predictions. For an in-depth understanding, refer to Nvidia\u2019s<a href=\"https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html\"> blog post</a>. We applied half-precision to modules with high computational demands, particularly those that included feature crossing layers, the ensemble layer, feature projection layers, and sequential processing layers.</p><figure><img alt=\"Mixed Precision Wrapper, USPS Transformer Module, MaskNet Module, MLP Module, Transformer Module\" src=\"https://cdn-images-1.medium.com/max/1024/0*oUf2If8jvj_Q2MCk\" /><figcaption>Figure 7: Integration of Mixed Precision Wrapper with the serving model\u00a0artifact</figcaption></figure><p>Based on our internal testing, utilizing mixed precision serving resulted in an increase in throughput and decrease in forward computation time.</p><h3>Conclusion</h3><p>Optimizing for conversion brings its unique challenges and are non-trivial to handle. Our work around incorporating Multi-Task Learning, moving to in-model ensemble techniques, and leveraging real time user action signals has greatly improved ads recommendation systems. Since there is a tradeoff between model capacity and infrastructure costs, requiring GPU serving and optimization indispensable for large scale, complex\u00a0models.</p><h3>Acknowledgements</h3><p>This work represents a result of collaboration of the conversion modeling team members and across multiple teams at Pinterest.</p><p>Engineering Teams:</p><p>Ads Ranking: Kungang Li, Ke Xu, Meng Qi, Meng Mei, Yinrui Li, Zhixuan Shao, Zhifang Liu, Liangzhe Chen, Yulin Lei, Kaili Zhang, Qifei Shen, Hongda\u00a0Shen</p><p>Advanced Technology Group: Yi-Ping Hsu, Pong Eksombatchai, Xiangyi\u00a0Chen</p><p>Ads ML Infra: Shantam Shorewala, Kartik Kapur, Matthew Jin, Haoyu He, Nuo Dou, Yiran Zhao, Joey Wang, Haoyang\u00a0Li</p><p>User Sequence Support: Kangnan Li, Zefan Fu, Kimmie\u00a0Hua</p><p>Leadership: Ling Leng, Shu Zhang, Jiajing Xu, Xiaofang Chen, Behnam\u00a0Rezaei</p><h3>References</h3><ol><li>Wang, Zhiqiang, Qingyun She, and Junlin Zhang. \u201cMaskNet: Introducing feature-wise multiplication to CTR ranking models by instance-guided mask.\u201d arXiv preprint arXiv:2102.07619 (2021).</li><li>Zhang, Buyun, et al. \u201cDHEN: A deep and hierarchical ensemble network for large-scale click-through rate prediction.\u201d arXiv preprint arXiv:2203.11014 (2022).</li><li>Wang, Ruoxi, et al. \u201cDcn v2: Improved deep &amp; cross network and practical lessons for web-scale learning to rank systems.\u201d Proceedings of the web conference 2021.\u00a02021.</li><li>MLEnv: Standardizing ML at Pinterest Under One ML Engine to Accelerate Innovation [<a href=\"https://medium.com/pinterest-engineering/mlenv-standardizing-ml-at-pinterest-under-one-ml-engine-to-accelerate-innovation-e2b30b2f6768\">Link</a>]</li><li>How we use AutoML, Multi-task learning and Multi-tower models for Pinterest Ads\u00a0[<a href=\"https://medium.com/pinterest-engineering/how-we-use-automl-multi-task-learning-and-multi-tower-models-for-pinterest-ads-db966c3dc99e\">Link</a>]</li><li>Feature Hashing Trick:\u00a0[<a href=\"https://en.wikipedia.org/wiki/Feature_hashing\">Link</a>]</li><li>CUDA Semantics: [<a href=\"https://pytorch.org/docs/master/notes/cuda.html#constraints\">Link</a>]</li><li>Mixed Precision Training\u00a0[<a href=\"https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html\">Link</a>]</li></ol><p><em>To learn more about engineering at Pinterest, check out the rest of our </em><a href=\"https://medium.com/pinterest-engineering\"><em>Engineering Blog</em></a><em> and visit our </em><a href=\"https://www.pinterestlabs.com/?utm_source=Medium&amp;utm_campaign=engineering-Q12024_Mudgal&amp;utm_medium=blogarticle\"><em>Pinterest Labs site</em></a><em>. To explore and apply to open roles, visit our </em><a href=\"https://www.pinterestcareers.com/?utm_source=Medium&amp;utm_campaign=engineering-Q12024_Mudgal&amp;utm_medium=blogarticle\"><em>Careers</em></a><em>\u00a0page.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=84b244043d51\" width=\"1\" /><hr /><p><a href=\"https://medium.com/pinterest-engineering/evolution-of-ads-conversion-optimization-models-at-pinterest-84b244043d51\">Evolution of Ads Conversion Optimization Models at Pinterest</a> was originally published in <a href=\"https://medium.com/pinterest-engineering\">Pinterest Engineering Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>A Journey from GBDT to Multi-Task Ensemble\u00a0DNN</p><p>Aayush Mudgal | Senior Machine Learning Engineer, Ads Ranking Conversion Modeling; Han Sun | Senior Machine Learning Engineer, Ads Ranking Conversion Modeling; Matt Meng | Senior Machine Learning Engineer, Ads Ranking Conversion Modeling; Runze Su | Machine Learning Engineer II, Ads Ranking Conversion Modeling; Jinfeng Zhuang | Staff Machine Learning Engineer, Ads Ranking Conversion Modeling</p><p>In this blog post, we will share how we improved Pinterest\u2019s conversion optimization performance by leveraging Deep Neural Networks (DNN), Multi-Task Learning (MTL), state-of-the-art feature interaction modules, in-model ensemble techniques, and user sequence modeling. We will also cover our transition to GPU serving, which is indispensable for large-scale complex\u00a0models.</p><h3>Background</h3><p>People often come to Pinterest for inspiration on their next life or shopping ideas. In fact, over half of Pinterest users think of Pinterest as a place to shop. Ads and other content from businesses are an important part of the consumer journey because they add value to the discovery process. <strong>Conversion Optimization</strong> optimizes <strong>Promoted Pins</strong> for specific consumer conversion actions, rather than just clicks. Advertisers can choose conversions as a campaign objective and inspire people to take specific actions like online checkouts, increased signups, or stronger leads. In this blog we will deep dive into some of our recent advancements in machine learning modeling to connect pinners with the most relevant\u00a0ads.</p><p>The Ads Ranking system at Pinterest has many standard pieces of a recommendation system involving targeting, retrieval, ranking, auction, and allocation, as it needs to be responsive to more than 480 million monthly active users\u2019 actions and performance and billions of pieces of content on the platform. The ranking layer focuses on finding the relevant pins given the user context, so improving this part of the system has a significant impact on the user experiences. This blog post will focus on our recent improvements on improving the models that predict offsite conversions given a user request on Pinterest. The following is a very high level overview of how the conversion optimization system typically works.</p><figure><img alt=\"Conversion Optimization: High Level Overview\u200a\u2014\u200a1. Ad created, 2. Prediction, 3. Ad Served, 4. Ad Engagement, 5. Ad Conversion, 6. Ad Measurement (Ingestion -&gt; User Match -&gt; Attribution), 7. Training Data and Features\" src=\"https://cdn-images-1.medium.com/max/1024/0*RjnHkPLlI6BevJtD\" /><figcaption>Figure 1: A high level overview of conversion optimization pipeline</figcaption></figure><p>Before diving deeper into the model evolution, let\u2019s also look into the unique characteristics of Ads conversion prediction, which is very different from typical engagement ranking problems.</p><ol><li><strong>Label quality</strong>: Since conversion events happen on advertiser platforms, the quality of the label is dependent on the advertisers, so we often deal with inaccurate and abnormal conversion volumes. Besides, the user match and attribution process is probabilistic which further introduces noise in the\u00a0labels.</li><li><strong>Data volume and label sparsity</strong>: Conversion is a more downstream event, and is thus inherently much sparser than click events on the platform. This significantly limits the complexity of the model we can build. Since the label is sparser, it also requires higher traffic percentages or longer running A/B experiments to detect significant changes in metrics, slowing down the iteration speed.</li><li><strong>Delayed feedback</strong>: Conversions are observed with a long-tail delay distribution after the onsite engagements (clicks or views) have happened, resulting in false negative labels during training. This brings challenges on the model training strategy, e.g., the model\u2019s update frequency, and complicates calibration estimations of the learned\u00a0models.</li></ol><h3>Classic Machine Learning Model\u00a0Period</h3><p>In the beginning (2018), our ads ranking model was a hybrid of Gradient Boosted Decision Trees (GBDT), embedded as feature translators, and a logistic regression model. This design choice enabled us to build performant models quickly for the scale of data and machine learning stack of that time. Ad space, comprising advertisers, ad groups, and ad campaigns have very different label characteristics both in terms of quality and volume, hence generalization across the sparse ID space was top consideration. To enable this we utilized the <a href=\"https://en.wikipedia.org/wiki/Feature_hashing\">feature hashing trick </a>into the logistic regression layer to learn the ID space information and control cross-advertiser label\u00a0impacts.</p><p>As the product <strong>grew rapidly, fueled by increasing amounts of data</strong>, it required better scalability in model training and serving, as the previous design became the bottleneck for fast system growth. The next set of iterations happened by transitioning from this GBDT + logistic regression structure to a deep learning based single model, and also unlocking the ability to do Multi-Task Learning (MTL) by co-training multiple objectives together like clicks, good clicks, checkout, and add-to-cart conversions. Moving to MTL and leveraging onsite actions helped increase model robustness to sparser tasks and unleashed the power to learn from the holistic onsite and offsite experience. By 2020, we transitioned to AutoML (<a href=\"https://medium.com/pinterest-engineering/how-we-use-automl-multi-task-learning-and-multi-tower-models-for-pinterest-ads-db966c3dc99e\">link</a>), which was a shift from previous traditional machine learning approaches by introducing an automatic way of feature engineering. The engineers could work on developing raw features instead of hand crafting the complex feature interactions. However, over this period of time, we encountered significant technical debt as we were moving fast to bring technical advancements by patching over existing systems to bring the fastest results. Between 2021\u20132022 we accomplished a complete overhaul of the entire ML Platform (<a href=\"https://medium.com/pinterest-engineering/mlenv-standardizing-ml-at-pinterest-under-one-ml-engine-to-accelerate-innovation-e2b30b2f6768\">link</a>), also leveraging flattened feature structures and adopting more sampling near the model trainer. This infrastructure migration enabled us to have a much more robust backbone for a substantially wider range of modeling ideas. Next we will discuss some of the recent architectural advancements and the lessons that help power these models\u00a0today.</p><h3>Modern Model Architectural Advancement</h3><p>With the transition to AutoML (auto feature interaction) and the MLEnv (Unified ML Engine) framework, we are unblocked with<strong> much faster model architecture iteration speed</strong>. Since then, we have experimented, iterated, and launched a number of state-of-the-art modern model architectures. Here is our learning summary of the architecture evolution.</p><h4>Feature Interaction Modules</h4><p>A very important component in modern recommendation systems is the feature interaction learning modules. Starting from MLP, our model advancement iterates along the following three modules, as elaborated below:</p><figure><img alt=\"DCNv2, Transformer, Masknet models\" src=\"https://cdn-images-1.medium.com/max/1024/1*W4FNeFH7hKV4gwgEdxmbCQ.png\" /><figcaption>Figure 2: Different feature interaction modules</figcaption></figure><p><strong>DCNv2:</strong></p><p><a href=\"https://arxiv.org/abs/2008.13535\">DCNv2</a>, also known as Deep &amp; Cross Network version 2, is a step forward from the original DCN model. It introduces a cross network and multiple deep layers to capture both explicit and implicit feature interactions. With DCNv2, explicit low-ordered feature interactions are captured through a low-dimensional cross network with a feature crossing matrix, and other implicit feature interactions are captured in a deep network, which is similar to the MLP layers. It outperforms the MLP layers while there\u2019s a larger infrastructure cost due to the introduction of the cross\u00a0network.</p><p><strong>Transformer:</strong></p><p><a href=\"https://arxiv.org/abs/1706.03762\">Transformer</a> is originally proposed for natural language processing tasks, but it also shows great potential in learning feature crossing in the advertising field. The self-attention mechanism in the transformer encoder maps the input into Q(Query), K(Key) and V(Value), where Q and K capture the feature interaction and cast the interaction into V. Transformer has demonstrated its performance by significantly improving the model performance, but it also resulted in a high memory usage during training and relatively higher\u00a0latency.</p><p><strong>MaskNet:</strong></p><p><a href=\"https://arxiv.org/abs/2102.07619\">MaskNet</a> proposes an instance-guided mask method which uses element-wise products in both the feature embedding layer and the feedforward layer in DNN. The instance-guided mask contains global contextual information that is dynamically incorporated into the feature embedding layer and the feedforward layer to highlight the important features.</p><p>MaskBlock is the module for feature interaction learning. It consists of three parts: the instance-guided mask, the feedforward layer, and the normalization layer. With this structure, the standard DNN is extended to contain interactive feature structures that can be added and multiplied. MaskNet is one of the most popular modules in advertising and recommendation systems and is of high performance in feature crossing\u00a0modules.</p><h4>Modern Model Multi-tasking and Ensemble\u00a0Learning</h4><p><strong>Multi-Task Learning (MTL) and in-model ensembling frameworks</strong> have been pushing recommendation model performance limits in recent years. With many powerful state-of-the-art feature interaction algorithms\u2019 (above discussed, e.g., transformer feature interaction, masknet feature interaction, etc). We embraced all their powers together and explored the following directions</p><p>We introduced <strong>MTL</strong> to combine multiple conversion objectives into a unified model by leveraging abundant onsite actions like clicks on the platform to enhance the training of sparse conversion objectives. This not only benefited each conversion objective but also largely reduced model serving and maintenance cost, as well as improved experimentation iteration velocity.</p><figure><img alt=\"Single Task Architecture to Multi-Task Model Architecture\" src=\"https://cdn-images-1.medium.com/max/1024/1*4gLFHziEFyJmPi7ljH95dg.png\" /><figcaption>Figure 3: Architectural evolution from single task to a shared multi-task model architecture</figcaption></figure><p>In the next iteration, we made the model more robust and introduced in-model ensemble techniques, where we <strong>ensembled two model backbones for feature crossing: DCNv2 and transformer respectively. </strong>We curated an empirical formula for their output scores at inference to compute the final model prediction, while we maintained individual training loss and gradient descent for each ensembled model. This curated architecture was able to benefit from each model backbone\u2019s diverse learning.</p><figure><img alt=\"DCNv2 and Transformer Ensemble Model\" src=\"https://cdn-images-1.medium.com/max/1024/1*OgiMIpJX_csNUWarfaPhdA.png\" /><figcaption>Figure 4: Ensemble model structure with DCNv2 and Transformer as feature interaction modules</figcaption></figure><p>The above architecture significantly increased the serving infrastructure cost. Next we decoupled feature interaction modules from the feature processing modules and utilized a <strong>shared bottom architecture for feature processing</strong> while maintaining the top architecture separated. This evolution significantly reduced infra cost of the model while maintaining same level of performance after parameter tunings</p><figure><img alt=\"Shared Bottom Architecture\" src=\"https://cdn-images-1.medium.com/max/1024/1*Hf0nW5aRbXECuG6g9n4wFw.png\" /><figcaption>Figure 5: Model architecture that leverages shared feature processing layer before the ensemble feature interaction learning</figcaption></figure><p>Realizing the power of learning in-model ensemble, we wanted to next move to a principled way of doing the same. We adopted the <a href=\"https://arxiv.org/abs/2203.11014\"><strong>Deep and Hierarchical Ensemble Network</strong></a><strong> (DHEN) framework with user sequence and MaskNet feature interaction</strong>. This modeling framework is scalable, optimizable, and modularizable and achieved the best offline and online model performance compared to each of the previous architectural choices.</p><figure><img alt=\"DHEN + User Sequence\" src=\"https://cdn-images-1.medium.com/max/1024/1*SnvgajriaTaxvV400AjuaA.png\" /><figcaption>Figure 6: Model architecture with Sequence Transformer addition</figcaption></figure><h4>User Sequence\u00a0Modeling</h4><p>The capability to model user activity sequence is a powerful modern modeling technique. We have explored extensively in the area of user sequence modeling and launched it in our conversion ranking model with significant offline and online performance gains. There are several advantage of including user sequences into conversion models:</p><ul><li>With a <strong>long lookback window</strong>, user sequence is extremely effective to capture information from sparse data space\u200a\u2014\u200ain our particular case, user and Ads interactions. It is even more powerful for Ads user conversion optimizations, given its sparsity and delaying nature compared to user engagement optimizations.</li><li>A <strong>direct model training with user sequence data</strong> in conversion ranking models unleashes its power in learning user interest from user activities\u200a\u2014\u200afrom user offsite events that are directly related to offsite conversions, to user onsite engagements that represents user\u00a0intends.</li><li>The essence part of user sequence data is its <strong>temporal information</strong>. The incorporation of temporal dimensionality to ranking models allow the rich feature interaction modules to learn news-level, seasonal, and life-time user interest shifts and patterns. This information is vitally important serving as the backbone of user representation in the ranking\u00a0models.</li></ul><h3>Evaluation Results</h3><p>Together with other improvements, such as additional features to feed the advanced model architectures, our above iterations have achieved a significant amount of both offline and online metrics gains and we summarized the relative performance as\u00a0below.</p><figure><img alt=\"Relative Improvements for each model evolution, Offline Metrics: Area Under the Curve (AUC), Online Metrics: Conversion Volume\" src=\"https://cdn-images-1.medium.com/max/1024/1*3VgRhA8_tTy-Jj0O-hwQoQ.png\" /></figure><h3>GPU Serving</h3><p>Our model ensemble and feature interaction components have made significant advancements; however, serving these models has become increasingly complex. We initially used CPU clusters to serve these ranking models, but this restricted the model capacity we could use whilst still maintaining low latency. To serve these big models with minimal cost increments, we also transitioned to using GPUs for online\u00a0serving.</p><h4>CUDA Graphs</h4><p>With the migration of the ranking models to <a href=\"https://medium.com/pinterest-engineering/mlenv-standardizing-ml-at-pinterest-under-one-ml-engine-to-accelerate-innovation-e2b30b2f6768\">Pinterest\u2019s MLEnv and PyTorch based framework</a>\u00a0, we were able to easily leverage <a href=\"https://pytorch.org/docs/master/notes/cuda.html#constraints\">CUDA graphs</a> for online serving. The traditional launch of CPU kernels creates gaps and inadvertent overhead between launches. CUDA graphs greatly reduce these gaps, optimizing subsequent executions and minimizing delays. Using CUDA graphs does present certain constraints. For example, the network must be graph-safe. A crucial condition of using CUDA graphs is the need for tensor shapes in memory to be static\u200a\u2014\u200adynamic inputs with varying tensor dimensions cause numerical errors in CUDA graphs. We used zero padding to ensure constant feature dimensions for ragged and other dynamically-shaped tensors.</p><h4>Mixed Precision Serving</h4><p>To further cut down on the infrastructure costs of model serving, we implemented the technique of mixed precision serving. This technique is prevalent in large model training and inferencing; it merges the use of 32-bit floating point (FP32) and 16-bit floating point (FP16) data types. The end result is a reduction in memory usage and a boost in the speed of model development and inference, all without compromising the accuracy of the model\u2019s predictions. For an in-depth understanding, refer to Nvidia\u2019s<a href=\"https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html\"> blog post</a>. We applied half-precision to modules with high computational demands, particularly those that included feature crossing layers, the ensemble layer, feature projection layers, and sequential processing layers.</p><figure><img alt=\"Mixed Precision Wrapper, USPS Transformer Module, MaskNet Module, MLP Module, Transformer Module\" src=\"https://cdn-images-1.medium.com/max/1024/0*oUf2If8jvj_Q2MCk\" /><figcaption>Figure 7: Integration of Mixed Precision Wrapper with the serving model\u00a0artifact</figcaption></figure><p>Based on our internal testing, utilizing mixed precision serving resulted in an increase in throughput and decrease in forward computation time.</p><h3>Conclusion</h3><p>Optimizing for conversion brings its unique challenges and are non-trivial to handle. Our work around incorporating Multi-Task Learning, moving to in-model ensemble techniques, and leveraging real time user action signals has greatly improved ads recommendation systems. Since there is a tradeoff between model capacity and infrastructure costs, requiring GPU serving and optimization indispensable for large scale, complex\u00a0models.</p><h3>Acknowledgements</h3><p>This work represents a result of collaboration of the conversion modeling team members and across multiple teams at Pinterest.</p><p>Engineering Teams:</p><p>Ads Ranking: Kungang Li, Ke Xu, Meng Qi, Meng Mei, Yinrui Li, Zhixuan Shao, Zhifang Liu, Liangzhe Chen, Yulin Lei, Kaili Zhang, Qifei Shen, Hongda\u00a0Shen</p><p>Advanced Technology Group: Yi-Ping Hsu, Pong Eksombatchai, Xiangyi\u00a0Chen</p><p>Ads ML Infra: Shantam Shorewala, Kartik Kapur, Matthew Jin, Haoyu He, Nuo Dou, Yiran Zhao, Joey Wang, Haoyang\u00a0Li</p><p>User Sequence Support: Kangnan Li, Zefan Fu, Kimmie\u00a0Hua</p><p>Leadership: Ling Leng, Shu Zhang, Jiajing Xu, Xiaofang Chen, Behnam\u00a0Rezaei</p><h3>References</h3><ol><li>Wang, Zhiqiang, Qingyun She, and Junlin Zhang. \u201cMaskNet: Introducing feature-wise multiplication to CTR ranking models by instance-guided mask.\u201d arXiv preprint arXiv:2102.07619 (2021).</li><li>Zhang, Buyun, et al. \u201cDHEN: A deep and hierarchical ensemble network for large-scale click-through rate prediction.\u201d arXiv preprint arXiv:2203.11014 (2022).</li><li>Wang, Ruoxi, et al. \u201cDcn v2: Improved deep &amp; cross network and practical lessons for web-scale learning to rank systems.\u201d Proceedings of the web conference 2021.\u00a02021.</li><li>MLEnv: Standardizing ML at Pinterest Under One ML Engine to Accelerate Innovation [<a href=\"https://medium.com/pinterest-engineering/mlenv-standardizing-ml-at-pinterest-under-one-ml-engine-to-accelerate-innovation-e2b30b2f6768\">Link</a>]</li><li>How we use AutoML, Multi-task learning and Multi-tower models for Pinterest Ads\u00a0[<a href=\"https://medium.com/pinterest-engineering/how-we-use-automl-multi-task-learning-and-multi-tower-models-for-pinterest-ads-db966c3dc99e\">Link</a>]</li><li>Feature Hashing Trick:\u00a0[<a href=\"https://en.wikipedia.org/wiki/Feature_hashing\">Link</a>]</li><li>CUDA Semantics: [<a href=\"https://pytorch.org/docs/master/notes/cuda.html#constraints\">Link</a>]</li><li>Mixed Precision Training\u00a0[<a href=\"https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html\">Link</a>]</li></ol><p><em>To learn more about engineering at Pinterest, check out the rest of our </em><a href=\"https://medium.com/pinterest-engineering\"><em>Engineering Blog</em></a><em> and visit our </em><a href=\"https://www.pinterestlabs.com/?utm_source=Medium&amp;utm_campaign=engineering-Q12024_Mudgal&amp;utm_medium=blogarticle\"><em>Pinterest Labs site</em></a><em>. To explore and apply to open roles, visit our </em><a href=\"https://www.pinterestcareers.com/?utm_source=Medium&amp;utm_campaign=engineering-Q12024_Mudgal&amp;utm_medium=blogarticle\"><em>Careers</em></a><em>\u00a0page.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=84b244043d51\" width=\"1\" /><hr /><p><a href=\"https://medium.com/pinterest-engineering/evolution-of-ads-conversion-optimization-models-at-pinterest-84b244043d51\">Evolution of Ads Conversion Optimization Models at Pinterest</a> was originally published in <a href=\"https://medium.com/pinterest-engineering\">Pinterest Engineering Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Galois": {
    "title": "Subverting Censorship: How a Galois-developed Android App Could Change the Game for Pro-Democracy Activists",
    "xmlUrl": "https://galois.com/feed/",
    "htmlUrl": "https://galois.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://galois.com/feed/",
      "value": "Subverting Censorship: How a Galois-developed Android App Could Change the Game for Pro-Democracy Activists"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://galois.com/blog/2024/01/subverting-censorship-how-a-galois-developed-android-app-could-change-the-game-for-pro-democracy-activists/"
      }
    ],
    "link": "https://galois.com/blog/2024/01/subverting-censorship-how-a-galois-developed-android-app-could-change-the-game-for-pro-democracy-activists/",
    "authors": [
      {
        "name": "Andrew Shaughnessy"
      }
    ],
    "author": "Andrew Shaughnessy",
    "author_detail": {
      "name": "Andrew Shaughnessy"
    },
    "published": "Wed, 10 Jan 2024 22:51:49 +0000",
    "published_parsed": [
      2024,
      1,
      10,
      22,
      51,
      49,
      2,
      10,
      0
    ],
    "tags": [
      {
        "term": "Cryptography",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://galois.com/?p=4990",
    "guidislink": false,
    "summary": "<p>For pro-democracy activists living under authoritarian regimes, communication can be a tricky \u2013 and often dangerous \u2013 endeavor. Posting dissident messages to social media, sending an email, or texting a friend or colleague can risk interception by vigilant government agents, censorship, and even jail time. Over the past few years, Galois has been developing, in [&#8230;]</p>\n<p>The post <a href=\"https://galois.com/blog/2024/01/subverting-censorship-how-a-galois-developed-android-app-could-change-the-game-for-pro-democracy-activists/\">Subverting Censorship: How a Galois-developed Android App Could Change the Game for Pro-Democracy Activists</a> appeared first on <a href=\"https://galois.com\">Galois, Inc.</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://galois.com/feed/",
      "value": "<p>For pro-democracy activists living under authoritarian regimes, communication can be a tricky \u2013 and often dangerous \u2013 endeavor. Posting dissident messages to social media, sending an email, or texting a friend or colleague can risk interception by vigilant government agents, censorship, and even jail time. Over the past few years, Galois has been developing, in [&#8230;]</p>\n<p>The post <a href=\"https://galois.com/blog/2024/01/subverting-censorship-how-a-galois-developed-android-app-could-change-the-game-for-pro-democracy-activists/\">Subverting Censorship: How a Galois-developed Android App Could Change the Game for Pro-Democracy Activists</a> appeared first on <a href=\"https://galois.com\">Galois, Inc.</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://galois.com/feed/",
        "value": "<p>For pro-democracy activists living under authoritarian regimes, communication can be a tricky \u2013 and often dangerous \u2013 endeavor. Posting dissident messages to social media, sending an email, or texting a friend or colleague can risk interception by vigilant government agents, censorship, and even jail time. Over the past few years, Galois has been developing, in collaboration with partners at the University of Florida, an innovative tool aimed at helping activists circumvent censorship.&nbsp;</p>\n\n\n\n<p>CADENAS is a text-based communication tool, housed in a handy Android app, that not only encrypts secret messages, but camouflages their very existence. Using a clever combination of encryption and AI predictive text generation, this groundbreaking technology allows users to hide a message in \u201ccover text\u201d designed to appear completely innocuous to observers.</p>\n\n\n\n<p>\u201cIn the past, other tools have had the ability to take a message, encrypt it, and then use those bits to choose random strings of words to try and hide the message,\u201d explained Galois Principal Scientist Dave Archer. \u201cThe problem is, a state actor can look at those random words and easily notice: \u2018That looks weird.\u2019 Our objective is much stronger. We want to have the cover text look so natural that it\u2019s<em> at least</em> indistinguishable from something generated by a large language model like GPT. Even better, we\u2019d ultimately like to have it be indistinguishable from text written by an actual human.\u201d</p>\n\n\n\n<p><strong>How Does CADENAS Work?</strong></p>\n\n\n\n<p>At a glance, CADENAS seems like a page straight out of a spy novel. Imagine trying to communicate, \u201cMeet at dawn,\u201d without alerting censors. Using the CADENAS app, a user could input the plaintext, and the tool would automatically generate contextually plausible content that hides the message in the arrangement and choice of words. The intended recipients, having agreed ahead of time on a unique key, and knowing to keep an eye out for communications in a certain feed or location, could feed the text through their own CADENAS app, which would then decrypt the message for them.</p>\n\n\n\n<p>But how does it work?</p>\n\n\n\n<p>First, the tool encrypts the secret message using an encryption scheme designed by Galois engineers. Next, it uses Large Language Models (LLMs) trained on different genres of text to probabilistically choose word sequences that encode the encrypted message\u2019s bit-stream, while still making sense within the chosen text style.&nbsp;</p>\n\n\n\n<p>\u201cWhen you run a large language model, you give it some seed text and then it generates all of the potential next tokens and their probabilities,\u201d said Galois Principal Researcher Alex Malozemoff. \u201cWe map those to a cumulative probability distribution between zero and one. Then we use the bits of the ciphertext, which are indistinguishable from random, to select a token within that range. That\u2019s the next token in our covertext. Then we feed that into the LLM, get the next token, and repeat. On the decoding side, we essentially do that in reverse.\u201d</p>\n\n\n\n<p>Because the encoding is in the arrangement of the words themselves, this seemingly innocent covertext can be hidden in any written communication: a Tweet, an email, a poster, or even written by hand. In each case, as long as the intended recipient knows where to look, and has the agreed upon key and seed text, they can decrypt the message. Meanwhile, villainous authorities are none the wiser.</p>\n\n\n\n<p><strong>Looking Ahead</strong></p>\n\n\n\n<p>In a world where the right to free expression, privacy, and information is not a given, our hope is that CADENAS will be a tool for good. As the tool is refined and expanded upon, we see other potential benefits, such as journalists working in risky settings being able to more safely relay sensitive information,&nbsp; or whistleblowers finding a secure channel to disclose wrongdoing without fear of reprisal. In short, when it comes to censorship-resistant communication, CADENAS has the potential to change the game.</p>\n\n\n\n<p>While CADENAS is still in the prototype stage, the results are already remarkable. Even now, the tool can reliably generate text that appears indistinguishable from the GPT-generated content already flooding social media streams and email inboxes. Now, our researchers are focused on ensuring the final product is not just mathematically secure, but natural-looking enough to pass for human-generated text.&nbsp;</p>\n\n\n\n<p>Keep an eye out. This one is going to be fun.</p>\n<p>The post <a href=\"https://galois.com/blog/2024/01/subverting-censorship-how-a-galois-developed-android-app-could-change-the-game-for-pro-democracy-activists/\">Subverting Censorship: How a Galois-developed Android App Could Change the Game for Pro-Democracy Activists</a> appeared first on <a href=\"https://galois.com\">Galois, Inc.</a>.</p>"
      }
    ],
    "post-id": "4990"
  },
  "Vinted": {
    "title": "Adopting the Vespa search engine for serving personalized second-hand fashion recommendations at Vinted",
    "xmlUrl": "http://engineering.vinted.com//atom.xml",
    "htmlUrl": "http://engineering.vinted.com/",
    "title_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://vinted.engineering/atom.xml",
      "value": "Adopting the Vespa search engine for serving personalized second-hand fashion recommendations at Vinted"
    },
    "links": [
      {
        "href": "https://vinted.engineering//2023/10/09/adopting-vespa-for-recommendation-retrieval/",
        "rel": "alternate",
        "type": "text/html",
        "title": "Adopting the Vespa search engine for serving personalized second-hand fashion recommendations at Vinted"
      }
    ],
    "link": "https://vinted.engineering//2023/10/09/adopting-vespa-for-recommendation-retrieval/",
    "published": "2023-10-09T00:00:00+00:00",
    "published_parsed": [
      2023,
      10,
      9,
      0,
      0,
      0,
      0,
      282,
      0
    ],
    "updated": "2023-10-09T00:00:00+00:00",
    "updated_parsed": [
      2023,
      10,
      9,
      0,
      0,
      0,
      0,
      282,
      0
    ],
    "id": "https://vinted.engineering//2023/10/09/adopting-vespa-for-recommendation-retrieval",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://vinted.engineering//2023/10/09/adopting-vespa-for-recommendation-retrieval/",
        "value": "<p>In today\u2019s digital landscape, recommender systems have become ubiquitous, curating user experiences across a wide array of online platforms, including Vinted - Europe\u2019s largest online second-hand fashion marketplace. In this blog post, we outline our journey of adopting the Vespa search engine to serve personalized homepage listing recommendations, helping our members find deals they will enjoy. We are excited to share our story as we have found Vespa to be a great solution combining the now trendy vector search with more traditional sparse search techniques, as well as offering a great engineering experience.</p>\n\n<p>At Vinted, we\u2019ve implemented a 3-stage recommender system that leverages both explicit and implicit user preferences to offer users a curated list of items presented on the homepage. Explicit preferences are inputted by users on the app, allowing them to specify details such as the clothing sizes they are interested in. Meanwhile, implicit preferences are extracted from historical user interactions on the platform, including clicks and purchases, via the use of machine learning models. This system distills a tailored selection from millions of available listings, presenting users with options most aligned with their tastes and behaviors.</p>\n\n<!--truncate-->\n\n<figure class=\"image\" style=\"text-align: center; margin-bottom: 1em;\">\n  <img alt=\"Vinted multi-stage recommender system\" src=\"https://vinted.engineering/static/2023/10/recommender_stages.png?style=centered\" />\n  <figcaption>Figure 1. 3-stage recommender system</figcaption>\n</figure>\n\n<p>The goal of the first stage of the system is to quickly ( &lt; 100 ms ) recall the most relevant content based on historical user behavior. This is done by utilizing the approximate nearest neighbor (ANN) search with embeddings obtained from an in-house two-tower recommendation model. The listing \u201ctower\u201d of this model is responsible for generating vector representations of listings based on various metadata such as brand, price, size as well as other unstructured data such as photos. The second \u201ctower\u201d is responsible for generating embeddings of user\u2019s preferences characterized by a sequence of past interactions (clicks, favorites &amp; purchases) with listings on the platform. The model is trained in such a way that the distance between a user\u2019s and listing\u2019s embedding represents the affinity or relevance for the given user-item pair. This score can then be used to rank listings based on relevance for a given user and select a smaller list of candidates for the next stage.</p>\n\n<figure class=\"image\" style=\"text-align: center; margin-bottom: 1em;\">\n  <img alt=\"A diagram of a two-tower recommender model\" src=\"https://vinted.engineering/static/2023/10/recommender_towers.png?style=centered\" />\n  <figcaption>Figure 2. Two-tower recommendation retrieval model</figcaption>\n</figure>\n\n<p>When implementing the first iteration of this system we have chosen to use the <a href=\"https://github.com/facebookresearch/faiss\">Facebook AI Similarity Search (Faiss)</a> library for performing ANN searches. While Faiss served us well in the first iterations of this system to prove value, it is not a complete database solution, and we found the following drawbacks:</p>\n<ol>\n  <li>We used Faiss as a read-only index in a stateless Kubernetes service that would have to be periodically rebuilt and redeployed to include newly uploaded items and remove sold or deleted content.</li>\n  <li>Faiss has no capability for approximate nearest neighbor searches with pre-filtering based on metadata. You can only retrieve the top-k scoring items from this index, and any filtering would have to be performed as a post-processing step on the fixed-length list of retrieved items. This was especially problematic for us, as our product allows users to specify custom filters. Therefore, if the top-scoring items retrieved did not pass these filters, our users would see no recommendations at all.</li>\n</ol>\n\n<p>So we set out in search of a database system that would take care of managing the data and indices, as well as allow us to filter items based on metadata such as brand, size, and so on such that we could always retrieve recommendations for our users, no matter what filters they have set.</p>\n\n<h1 id=\"in-search-for-a-vector-search-database\">In search for a vector search database</h1>\n\n<p>As alternative technologies that could satisfy the constraints mentioned above, in the summer of 2022, we\u2019ve evaluated Vespa and Elasticsearch. More systems that support ANN with prefiltering were researched but eventually rejected either because of licensing concerns ( Vinted prefers truly open-source licensed software ) or due to overall lack of maturity of the project.</p>\n\n<h3 id=\"vespa\">Vespa</h3>\n\n<p><a href=\"https://vespa.ai\">Vespa</a> is an application platform for low-latency computations over large datasets. It is used to solve problems such as search, vector search, real-time recommendation, personalization, ad targeting, etc. The platform is open source under the Apache 2.0 license. One particular aspect that drew us to Vespa was its first-class support for machine learning based search and ranking. On top of that, the real-time data update capability is appealing. The main complicating factor for adoption was that Vinted had no experience with Vespa.</p>\n\n<h3 id=\"elasticsearch\">Elasticsearch</h3>\n\n<p><a href=\"https://www.elastic.co\">Elasticsearch</a> is a mature and popular system for search and analytics use cases. Elasticsearch is built on top of the Lucene library. The seemingly endless list of <a href=\"https://www.elastic.co/elasticsearch/features#vector-search-ann\">features</a> makes it a trusty and future-proof technology. Elasticsearch supports <a href=\"https://www.elastic.co/blog/introducing-approximate-nearest-neighbor-search-in-elasticsearch-8-0\">ANN</a> with prefiltering from version 8.0.</p>\n\n<p>Even though the license is not open-source, Elasticsearch was a strong contender because Vinted was already using it for search and had solid engineering competencies to operate it at scale.</p>\n\n<h1 id=\"benchmarking\">Benchmarking</h1>\n\n<p>To understand how these technologies would perform for our use case, we implemented benchmarks using real data. The goal of these benchmarks was to measure peak document indexing throughput as well as query throughput and latency.</p>\n\n<h3 id=\"setup\">Setup</h3>\n\n<p>Benchmarks were performed on a single Google Cloud Platform n1-standard-64 VM instance (64 vCPUs, 236 GB). The dataset consisted of ~1M  documents, each document contained 12 fields and a 256 dimension float32 embedding. Both Elasticsearch (8.2.2) and Vespa (8.17.19) were deployed as Docker containers, and we\u2019ve made sure to keep the ANN index (HNSW) hyperparameters consistent across both platforms for a fair comparison.</p>\n\n<h3 id=\"results\">Results</h3>\n\n<p>In our benchmarks, we found that  Vespa had a 3.8x higher document indexing throughput. Furthermore, querying benchmarks have shown that  Vespa was able to handle 8x more RPS before saturating the CPU, and at this throughput had a P99 latency of 26ms. Elasticsearch, even at just 250 RPS had a P99 latency of 110ms (4.23 times higher).</p>\n\n<p>Of course, if the benchmarks were run today with up-to-date versions then the numbers would be different.</p>\n\n<p>Given these results, we have decided to move forward with setting up Vespa for an AB test.</p>\n\n<h1 id=\"system-setup\">System setup</h1>\n\n<p>Having the numbers from the load testing, we\u2019ve estimated that to achieve high-availability (HA), 3 servers with 56 CPU cores each were needed to handle the expected load for the AB test. Deploying Vespa was as easy as setting an environment variable</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>VESPA_CONFIGSERVERS=server1.vinted.com,server2.vinted.com,server3.vinted.com\n</code></pre></div></div>\n<p>and then running a Docker container with Vespa on each server.</p>\n\n<p>The application package was mostly the same as the one used for the load testing. The only change was that we\u2019ve set up the content cluster with 3 groups. That made each server store a complete copy of the dataset and having more groups helped to scale the query throughput.</p>\n<h3 id=\"operations\">Operations</h3>\n<p>We\u2019ve found that Vespa is generally easy to operate. One reason is that after the initial setup there is no need to touch the running servers: all the configuration is controlled by deploying the application package. On top of that, Vespa out-of-the-box exposes an extensive set of metrics in Prometheus format that makes creating detailed Grafana dashboards an easy task.</p>\n\n<p>We consider the performance to be good enough:  the P99 latency of first stage retrieval handled by Vespa is around ~50 ms. However, there was a small portion of problematic queries that took much longer to execute than the set query timeout of 150ms. Vespa has an excellent tool for debugging problematic queries: <a href=\"https://docs.vespa.ai/en/reference/query-api-reference.html#trace.level\">tracing</a>. With the hints from the traces, we\u2019ve sought help in the Vespa Slack which led to a GitHub <a href=\"https://github.com/vespa-engine/vespa/issues/26663\">issue</a>. The Vespa team was quick to respond and fixed the root cause of the issue in subsequent Vespa releases. So far so good.</p>\n\n<h3 id=\"approximate-search-vs-exact-search\">Approximate Search vs Exact Search</h3>\n\n<p>As mentioned previously, the first-stage of our recommendation system utilizes an approximate nearest neighbor search algorithm to balance the trade-off between accuracy and speed. When dealing with large datasets, finding exact nearest neighbors can be computationally expensive, as it requires a linear scan across the entire corpus. Approximate search algorithms such as HNSW aim to find neighbors that are \u201cclose enough\u201d, which makes the search faster at the cost of accuracy. Additionally, ANN search algorithms often allow for fine tuning of the accuracy vs speed trade-off via parameters such as the \u201c<a href=\"https://blog.vespa.ai/billion-scale-knn-part-two/#:~:text=max%2Dlinks%2Dper%2Dnode,value%20in%20Vespa%20is%2016\">max-links-per-node</a>\u201d.</p>\n\n<p>We were curious to quantify exactly how much accuracy was traded off by our choice of the HNSW parameters we\u2019ve set in our Vespa deployment. Initially, we started by measuring recall - the proportion of matching documents retrieved between approximate and exact searches. We\u2019ve found that with our choice of parameters the recall was around 60-70%. However, visually the retrieved results and scores were very similar, and we were wondering if our users could perceive this difference and if that difference would affect their engagement and satisfaction. To test this hypothesis, we performed an AB test where half of our users received recommendations retrieved using approximate search, and the other half received exact search results.</p>\n\n<p>To accommodate such an experiment we needed some spare hardware resources. Luckily, we\u2019ve recently set up a bigger Vespa deployment and until other features were deployed the resources were readily available. When it comes to Vespa, it is easy to switch from ANN to exact search just by changing a query parameter, i.e. <code class=\"language-plaintext highlighter-rouge\">approximate:true</code> was changed to <code class=\"language-plaintext highlighter-rouge\">approximate:false</code>, e.g.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>select * from doc where {targetHits: 100, approximate:true}nearestNeighbor(user_embeddings)\n// to\nselect * from doc where {targetHits: 100, approximate:false}nearestNeighbor(user_embeddings)\n</code></pre></div></div>\n\n<p>The change in algorithm caused the latency at P99 to jump from a stable ~50ms to a more bumpy ~70ms (+40%).</p>\n\n<figure class=\"image\" style=\"text-align: center; margin-bottom: 1em;\">\n  <img alt=\"A chart showing latency increase from 50ms to 70ms.\" src=\"https://vinted.engineering/static/2023/10/recommender_latency.png?style=centered\" />\n  <figcaption>Figure 3. Vespa P99 search latency after starting the exact search experiment</figcaption>\n</figure>\n\n<p>The CPU load on Vespa search nodes increased slightly, however, we found that the user satisfaction with the exact search had not increased enough to justify the higher resource usage and query latency.</p>\n\n<h3 id=\"member-testimonies\">Member testimonies</h3>\n\n<p>The implementation of our recommender system on Vespa was a pleasant experience from an engineering point of view. While we were able to measure increased member satisfaction via a sequence of AB tests along the way, we were pleasantly surprised to hear member feedback about improvements that we were able to deliver by utilizing the new capabilities provided by Vespa:</p>\n\n<blockquote>\n  <p>I don\u2019t know why I hadn\u2019t looked at this or used this before as much as I do now.</p>\n</blockquote>\n\n<blockquote>\n  <p>Actually, Vinted is I think the only app that I use to just browse the main page because the stuff that comes up there is personalized to the user and based probably on my recent searches and recent buys and finds.</p>\n</blockquote>\n\n<blockquote>\n  <p>I\u2019ve recently found that I do find myself overnight time scrolling through. Actually, the matches are pretty good, you know, often where I put quite a lot of stuff in my favorites by just looking at that.</p>\n</blockquote>\n\n<p>A cherry on top is when we hear anecdotal feedback from random people mentioning that they only use the recommendations feature on Vinted because for them it seems that Vinted has a better understanding of their taste now.</p>\n\n<h1 id=\"summary-and-future-work\">Summary and future work</h1>\n<p>By leveraging ANN with prefiltering we\u2019ve significantly improved the relevance of recommendations on our homepage. Also, the broader adoption of Vespa for item recommendation use cases enables numerous other product improvements and paves the way to simplify our system architecture.</p>\n\n<p>Our team is excited about what we\u2019ve achieved so far, and we can\u2019t wait until we release new features for Vinted members that leverage the blend of dense and sparse retrieval techniques. Stay tuned!</p>"
      }
    ],
    "summary": "In today\u2019s digital landscape, recommender systems have become ubiquitous, curating user experiences across a wide array of online platforms, including Vinted - Europe\u2019s largest online second-hand fashion marketplace. In this blog post, we outline our journey of adopting the Vespa search engine to serve personalized homepage listing recommendations, helping our members find deals they will enjoy. We are excited to share our story as we have found Vespa to be a great solution combining the now trendy vector search with more traditional sparse search techniques, as well as offering a great engineering experience. At Vinted, we\u2019ve implemented a 3-stage recommender system that leverages both explicit and implicit user preferences to offer users a curated list of items presented on the homepage. Explicit preferences are inputted by users on the app, allowing them to specify details such as the clothing sizes they are interested in. Meanwhile, implicit preferences are extracted from historical user interactions on the platform, including clicks and purchases, via the use of machine learning models. This system distills a tailored selection from millions of available listings, presenting users with options most aligned with their tastes and behaviors.",
    "authors": [
      {
        "name": "Aleksas Kateiva",
        "href": "https://github.com/akateiva"
      }
    ],
    "author_detail": {
      "name": "Aleksas Kateiva",
      "href": "https://github.com/akateiva"
    },
    "href": "https://github.com/akateiva",
    "author": "Aleksas Kateiva",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://vinted.engineering/atom.xml",
      "value": "In today\u2019s digital landscape, recommender systems have become ubiquitous, curating user experiences across a wide array of online platforms, including Vinted - Europe\u2019s largest online second-hand fashion marketplace. In this blog post, we outline our journey of adopting the Vespa search engine to serve personalized homepage listing recommendations, helping our members find deals they will enjoy. We are excited to share our story as we have found Vespa to be a great solution combining the now trendy vector search with more traditional sparse search techniques, as well as offering a great engineering experience. At Vinted, we\u2019ve implemented a 3-stage recommender system that leverages both explicit and implicit user preferences to offer users a curated list of items presented on the homepage. Explicit preferences are inputted by users on the app, allowing them to specify details such as the clothing sizes they are interested in. Meanwhile, implicit preferences are extracted from historical user interactions on the platform, including clicks and purchases, via the use of machine learning models. This system distills a tailored selection from millions of available listings, presenting users with options most aligned with their tastes and behaviors."
    }
  },
  "Drivy": {
    "title": "JPEG and EXIF Data Manipulation in Javascript",
    "xmlUrl": "https://drivy.engineering/feed.xml",
    "htmlUrl": "https://drivy.engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://getaround.tech/feed.xml",
      "value": "JPEG and EXIF Data Manipulation in Javascript"
    },
    "authors": [
      {
        "name": "C\u00e9dric Patchane"
      }
    ],
    "author": "C\u00e9dric Patchane",
    "author_detail": {
      "name": "C\u00e9dric Patchane"
    },
    "summary": "<p>The <strong>E</strong>xchangeable <strong>I</strong>mage <strong>F</strong>ile <strong>F</strong>ormat (EXIF) is a standard that specifies formats for images and sounds. It stores technical details through metadata, data that describes other data, such as the camera make and model and the date and time the image was taken.</p>\n\n<p>Initially, EXIF was used for two image formats, JPEG and TIFF. But today, other file formats such as PNG, WEBP, or HEIC also support EXIF for metadata.</p>\n\n<p>This article will focus on the JPEG format. In the first part, we will explore its structure before seeing how to read and update associated metadata through Javascript in a browser environment.</p>\n\n<p>Before moving on, it is essential to review some key concepts:</p>\n\n<p><strong>\ud83d\udccc What is the <code class=\"language-plaintext highlighter-rouge\">0x</code> notation?</strong>\n<code class=\"language-plaintext highlighter-rouge\">0x</code> indicates that the following number is in hexadecimal format, which uses a base-16 number system (as opposed to the base-10 decimal system). This notation is case-insensitive, meaning that <code class=\"language-plaintext highlighter-rouge\">0XFF</code> and <code class=\"language-plaintext highlighter-rouge\">0xff</code> are exactly the same.</p>\n\n<p><strong>\ud83d\udccc What is a bit or a byte?</strong>\nIn computer science, a bit is the smallest and the most basic unit of information. It is a binary digit (base 2) representing 0 or 1. A byte (or octet) is a group of eight bits. Since there are 256 possible combinations of 8 bits, a byte can be expressed as a hexadecimal number. For example:</p>\n\n<ul>\n  <li>The byte <code class=\"language-plaintext highlighter-rouge\">0x00</code> represents <code class=\"language-plaintext highlighter-rouge\">0</code> in decimal and corresponds to <code class=\"language-plaintext highlighter-rouge\">0000 0000</code> in binary, which is the minimum 8-bit value.</li>\n  <li>The byte <code class=\"language-plaintext highlighter-rouge\">0xD8</code> represents <code class=\"language-plaintext highlighter-rouge\">216</code> and corresponds to <code class=\"language-plaintext highlighter-rouge\">1101 1000</code>.</li>\n  <li>The byte <code class=\"language-plaintext highlighter-rouge\">0xFF</code> represents <code class=\"language-plaintext highlighter-rouge\">255</code> and corresponds to <code class=\"language-plaintext highlighter-rouge\">1111 1111</code>, which is the maximum 8-bit value.</li>\n</ul>\n\n<p>For multiple-byte words, the hex numbers are just combined: <code class=\"language-plaintext highlighter-rouge\">0xFFD8</code> is a two-byte word, and <code class=\"language-plaintext highlighter-rouge\">0x45786966</code> is a four-byte word.</p>\n\n<p><strong>\ud83d\udccc What is Endianness?</strong>\nThis is how a set of bytes is stored in memory. In big-endian, the most significant byte (leftmost) comes first, while in little-endian, the least significant byte (rightmost) comes first.</p>\n\n<p>For example, let\u2019s consider the two-byte word <code class=\"language-plaintext highlighter-rouge\">0x0124</code>. In a big-endian system, it will be written as <code class=\"language-plaintext highlighter-rouge\">01 24</code>, whereas in a little-endian one, it will be written as <code class=\"language-plaintext highlighter-rouge\">24 01</code>. Knowing whether an image has been written on a big or little-endian device is essential to read its data correctly.</p>\n\n<h2 id=\"the-exif-segment-in-the-jpeg-structure\">The EXIF segment in the JPEG structure</h2>\n\n<h3 id=\"segment-delimitations\">Segment delimitations</h3>\n\n<p>The structure of a JPEG image is divided into parts marked by two-byte markers, always starting with a <code class=\"language-plaintext highlighter-rouge\">0xFF</code> byte. Below is a list of key markers found in the pages 20/21 of the <a href=\"https://www.cipa.jp/std/documents/e/DC-008-2012_E.pdf\">JPEG compression specification</a>:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">0xFFD8</code>: <strong>SOI</strong> (Start of Image); indicates the beginning of the image structure.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">0xFFE*n*</code>: <strong>APPn</strong> (Application-related tags); following the <strong>SOI</strong> marker, with <code class=\"language-plaintext highlighter-rouge\">n</code> between <code class=\"language-plaintext highlighter-rouge\">0</code> and <code class=\"language-plaintext highlighter-rouge\">F</code> (<a href=\"https://exiftool.org/TagNames/JPEG.html\">full list</a>). For example, <strong>APP11</strong> (or <code class=\"language-plaintext highlighter-rouge\">0xFFEB</code>) is for HDR data, <strong>APP13</strong> (or <code class=\"language-plaintext highlighter-rouge\">0xFFED</code>) for Photoshop and <strong>APP1</strong> (or <code class=\"language-plaintext highlighter-rouge\">0xFFE1</code>) for EXIF.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">0xFFDA</code>: <strong>SOS</strong> (Start of Scan); indicates the beginning of the image-related data.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">0xFFD9</code>: <strong>EOI</strong> (End of Image); indicates the end of the image.</li>\n</ul>\n\n<p>The first four file bytes, here <code class=\"language-plaintext highlighter-rouge\">FF D8 FF E0</code> for JPEG, are also known as <a href=\"https://en.wikipedia.org/wiki/List_of_file_signatures\">magic numbers</a> and are used by software to identify the file type.</p>\n\n<h3 id=\"segment-size\">Segment size</h3>\n\n<p>The size of a segment can be determined by reading the two bytes following its marker. For example, if the segment starts with <code class=\"language-plaintext highlighter-rouge\">FFE1 0124 XXXXXXX</code>, then the APP1 segment size is 292 bytes, with <code class=\"language-plaintext highlighter-rouge\">0124</code> being the size\u2019s hexadecimal representation.</p>\n\n<h3 id=\"ifd-image-file-directory\">IFD: Image File Directory</h3>\n\n<p>Data in JPEG structure is grouped into directories called IFDs. For example, <code class=\"language-plaintext highlighter-rouge\">IDF0</code> is located in the <code class=\"language-plaintext highlighter-rouge\">APP1</code> segment, and <code class=\"language-plaintext highlighter-rouge\">IFDExif</code> is a sub-IFD of <code class=\"language-plaintext highlighter-rouge\">IDF0</code>.</p>\n\n<p>The IFD dataset includes a two-byte word indicating the number of tags, followed by the tags data and ending with the four-byte offset of the next IFD (or 0 if none).</p>\n\n<h3 id=\"ifd-tag\">IFD Tag</h3>\n\n<p>A tag, like all EXIF tags, is a twelve-byte length sequence made up of:</p>\n\n<ul>\n  <li>Tag ID (bytes 0-1): A two-byte word identifying the tag</li>\n  <li>Tag type (bytes 2-3): A two-byte word indicating the type. For example, a value of <code class=\"language-plaintext highlighter-rouge\">1</code> for a <code class=\"language-plaintext highlighter-rouge\">BYTE</code> (one-byte integer), <code class=\"language-plaintext highlighter-rouge\">3</code> for a <code class=\"language-plaintext highlighter-rouge\">SHORT</code> (two-byte integer), or <code class=\"language-plaintext highlighter-rouge\">4</code> for a <code class=\"language-plaintext highlighter-rouge\">LONG</code> (four-byte integer). For further details, see the pages 25 and 26 of the <a href=\"https://www.cipa.jp/std/documents/e/DC-008-2012_E.pdf\">JPEG compression specification</a>.</li>\n  <li>Tag count (bytes 4-7): A four-byte word indicating the number of values (usually 1)</li>\n  <li>Tag value or value offset (bytes 8-11): For <code class=\"language-plaintext highlighter-rouge\">SHORT</code> values, two bytes are read; for <code class=\"language-plaintext highlighter-rouge\">LONG</code> values, four bytes are read. If the value is longer than four bytes (e.g., <code class=\"language-plaintext highlighter-rouge\">RATIONAL</code> type), these four bytes store the offset needed to reach the actual value.</li>\n</ul>\n\n<figure>\n  <img alt=\"IFD tag example: the ExifImageWidth tag\" src=\"https://getaround.tech/assets/posts/2023-09-11-exif-data-manipulation-javascript/exif_ifd_tag.png\" />\n  <figcaption>\n    IFD tag example: the ExifImageWidth tag\n  </figcaption>\n</figure>\n\n<h2 id=\"locate-the-exif-part\">Locate the EXIF part</h2>\n\n<h3 id=\"from-image-to-bytes\">From image to bytes</h3>\n<p>Time to code! The <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/FileReader\"><code class=\"language-plaintext highlighter-rouge\">FileReader</code></a> API is here used to read the image as a <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer\"><code class=\"language-plaintext highlighter-rouge\">buffer</code></a>. Then it is transformed into a <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView\"><code class=\"language-plaintext highlighter-rouge\">DataView</code></a> for easier byte manipulation.</p>\n\n<p>The next step is to examine the start of the JPEG structure, which should be the <strong>SOI</strong> marker:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"c1\">// Where the final image with updated metadata will be stored</span>\n<span class=\"kd\">let</span> <span class=\"nx\">finalImageBlob</span> <span class=\"o\">=</span> <span class=\"kc\">null</span>\n\n<span class=\"kd\">const</span> <span class=\"nx\">reader</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nx\">FileReader</span><span class=\"p\">()</span>\n<span class=\"nx\">reader</span><span class=\"p\">.</span><span class=\"nx\">addEventListener</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">load</span><span class=\"dl\">\"</span><span class=\"p\">,</span> <span class=\"p\">({</span> <span class=\"nx\">target</span> <span class=\"p\">})</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">target</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">no blob found</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n  <span class=\"kd\">const</span> <span class=\"p\">{</span> <span class=\"na\">result</span><span class=\"p\">:</span> <span class=\"nx\">buffer</span> <span class=\"p\">}</span> <span class=\"o\">=</span> <span class=\"nx\">target</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">buffer</span> <span class=\"o\">||</span> <span class=\"k\">typeof</span> <span class=\"nx\">buffer</span> <span class=\"o\">===</span> <span class=\"dl\">\"</span><span class=\"s2\">string</span><span class=\"dl\">\"</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">not a valid JPEG</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n\n  <span class=\"kd\">const</span> <span class=\"nx\">view</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nb\">DataView</span><span class=\"p\">(</span><span class=\"nx\">buffer</span><span class=\"p\">)</span>\n  <span class=\"kd\">let</span> <span class=\"nx\">offset</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">SOI</span> <span class=\"o\">=</span> <span class=\"mh\">0xFFD8</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span><span class=\"p\">)</span> <span class=\"o\">!==</span> <span class=\"nx\">SOI</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">not a valid JPEG</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n  <span class=\"c1\">// Here will happen the image metadata manipulation</span>\n<span class=\"p\">})</span>\n<span class=\"c1\">// Image given as a Blob, but readAsArrayBuffer can also take a File</span>\n<span class=\"nx\">reader</span><span class=\"p\">.</span><span class=\"nx\">readAsArrayBuffer</span><span class=\"p\">(</span><span class=\"nx\">imageBlob</span><span class=\"p\">)</span></code></pre></figure>\n\n<p><strong>Note:</strong> The <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView/getUint16\"><code class=\"language-plaintext highlighter-rouge\">getUint16</code></a> function in Javascript is used to read two bytes (2*8 = 16bits), and there is a similar function for four bytes, <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView/getUint32\"><code class=\"language-plaintext highlighter-rouge\">getUint32</code></a>.</p>\n\n<h3 id=\"segments-reading\">Segments reading</h3>\n<p>From here can begin the loop through the image data to locate the EXIF section. The EXIF segment uses the <code class=\"language-plaintext highlighter-rouge\">APP1</code> marker followed by a special six-byte ASCII code <code class=\"language-plaintext highlighter-rouge\">Exif</code> (<code class=\"language-plaintext highlighter-rouge\">0x457869660000</code>) immediately following the <code class=\"language-plaintext highlighter-rouge\">APP1</code> size data.</p>\n\n<p>Reaching <strong>SOS</strong> marker is reached means reaching the start of the image data so the end of the metadata section.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"kd\">const</span> <span class=\"nx\">SOS</span> <span class=\"o\">=</span> <span class=\"mh\">0xFFDA</span>\n<span class=\"kd\">const</span> <span class=\"nx\">APP1</span> <span class=\"o\">=</span> <span class=\"mh\">0xFFE1</span>\n<span class=\"c1\">// Skip the last two bytes 0000 and just read the four first bytes</span>\n<span class=\"kd\">const</span> <span class=\"nx\">EXIF</span> <span class=\"o\">=</span> <span class=\"mh\">0x45786966</span>\n\n<span class=\"kd\">let</span> <span class=\"nx\">marker</span> <span class=\"o\">=</span> <span class=\"kc\">null</span>\n<span class=\"c1\">// The first two bytes (offset 0-1) was the SOI marker</span>\n<span class=\"nx\">offset</span> <span class=\"o\">+=</span> <span class=\"mi\">2</span>\n<span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"nx\">marker</span> <span class=\"o\">!==</span> <span class=\"nx\">SOS</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"nx\">marker</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span><span class=\"p\">)</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">size</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">marker</span> <span class=\"o\">===</span> <span class=\"nx\">APP1</span> <span class=\"o\">&amp;&amp;</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint32</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"mi\">4</span><span class=\"p\">)</span> <span class=\"o\">===</span> <span class=\"nx\">EXIF</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// EXIF segment found!</span>\n    <span class=\"c1\">// Following code will be here</span>\n  <span class=\"p\">}</span>\n  <span class=\"c1\">// Skip the entire segment (header of 2 bytes + size of the segment)</span>\n  <span class=\"nx\">offset</span> <span class=\"o\">+=</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"nx\">size</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>The last thing to do here is to determine which is the endianness used to encode that image. In the JPEG structure, the endianness is provided thanks to the two-bytes word following the <code class=\"language-plaintext highlighter-rouge\">Exif</code> special word. If the word is <code class=\"language-plaintext highlighter-rouge\">0x4949</code>, it means it\u2019s little endian, otherwise it is <code class=\"language-plaintext highlighter-rouge\">0x4D4D</code> for big endian. This endianness data must be followed by the two bytes <code class=\"language-plaintext highlighter-rouge\">0x002A</code> (42 in decimal).</p>\n\n<p><strong>Note:</strong> From now on, always provide the endianness to the <code class=\"language-plaintext highlighter-rouge\">getUint16</code>/<code class=\"language-plaintext highlighter-rouge\">getUint32</code> functions to correctly read the bytes.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"kd\">const</span> <span class=\"nx\">LITTLE_ENDIAN</span> <span class=\"o\">=</span> <span class=\"mh\">0x4949</span>\n<span class=\"kd\">const</span> <span class=\"nx\">BIG_ENDIAN</span> <span class=\"o\">=</span> <span class=\"mh\">0x4d4d</span>\n\n<span class=\"c1\">// The APP1 here is at the very beginning of the file</span>\n<span class=\"c1\">// So at this point offset = 2,</span>\n<span class=\"c1\">// + 10 to skip to the bytes after the Exif word</span>\n<span class=\"nx\">offset</span> <span class=\"o\">+=</span> <span class=\"mi\">10</span>\n\n<span class=\"kd\">let</span> <span class=\"nx\">isLittleEndian</span> <span class=\"o\">=</span> <span class=\"kc\">null</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span><span class=\"p\">)</span> <span class=\"o\">===</span> <span class=\"nx\">LITTLE_ENDIAN</span><span class=\"p\">)</span> <span class=\"nx\">isLittleEndian</span> <span class=\"o\">=</span> <span class=\"kc\">true</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span><span class=\"p\">)</span> <span class=\"o\">===</span> <span class=\"nx\">BIG_ENDIAN</span><span class=\"p\">)</span> <span class=\"nx\">isLittleEndian</span> <span class=\"o\">=</span> <span class=\"kc\">false</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">invalid endian</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n<span class=\"c1\">// From now, the endianness must be specify each time bytes are read</span>\n<span class=\"c1\">// The 42 word</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span> <span class=\"o\">!==</span> <span class=\"mh\">0x2a</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">invalid endian</span><span class=\"dl\">\"</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>If APP1 appears at the very beginning of the image structure (which is usually the case), then the structure should be as follows:</p>\n<figure>\n  <img alt=\"JPEG starting structure\" src=\"https://getaround.tech/assets/posts/2023-09-11-exif-data-manipulation-javascript/exif_markers.png\" />\n  <figcaption>\n    JPEG starting structure\n  </figcaption>\n</figure>\n\n<h2 id=\"read-and-replace-exif-tags\">Read and replace EXIF tags</h2>\n\n<p>All the necessary information are now known to search for the EXIF tags:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">Orientation</code>, located in the IFD <code class=\"language-plaintext highlighter-rouge\">IFD0</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">ExifImageWidth</code> or <code class=\"language-plaintext highlighter-rouge\">PixelXDimension</code> tag, located in the IFD <code class=\"language-plaintext highlighter-rouge\">IFDExif</code>, provided by the <code class=\"language-plaintext highlighter-rouge\">ExifOffset</code> tag of <code class=\"language-plaintext highlighter-rouge\">IFD0</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">ExifImageHeight</code> or <code class=\"language-plaintext highlighter-rouge\">PixelYDimension</code> tag, also located in <code class=\"language-plaintext highlighter-rouge\">IFDExif</code></li>\n</ul>\n\n<h3 id=\"ifd0\">IFD0</h3>\n\n<p>To locate the <code class=\"language-plaintext highlighter-rouge\">IFD0</code>, its offset is given by the 4-byte word immediately after the endianness <code class=\"language-plaintext highlighter-rouge\">42</code> number.</p>\n\n<p>This sequence that includes the endianness two-byte word, <code class=\"language-plaintext highlighter-rouge\">42</code>, and the <code class=\"language-plaintext highlighter-rouge\">IFD0</code> offset four-byte word is commonly referred to as the \u201cTIFF (<strong>T</strong>agged <strong>I</strong>mage <strong>F</strong>ile <strong>F</strong>ormat) Header\u201d:</p>\n\n<figure>\n  <img alt=\"The TIFF header\" src=\"https://getaround.tech/assets/posts/2023-09-11-exif-data-manipulation-javascript/exif_TIFF_header.png\" />\n  <figcaption>\n    The TIFF header\n  </figcaption>\n</figure>\n\n<p>At this point, there are two tags that need to be found through the <code class=\"language-plaintext highlighter-rouge\">IFD0</code> data:</p>\n\n<ul>\n  <li>The <a href=\"https://www.awaresystems.be/imaging/tiff/tifftags/orientation.html\"><code class=\"language-plaintext highlighter-rouge\">Orientation</code></a> tag (hex <code class=\"language-plaintext highlighter-rouge\">0x0112</code>) which is a <code class=\"language-plaintext highlighter-rouge\">SHORT</code> value that must be replaced by <code class=\"language-plaintext highlighter-rouge\">1</code></li>\n  <li>The EXIF specific IFD offset provided by the <a href=\"https://www.awaresystems.be/imaging/tiff/tifftags/exififd.html\"><code class=\"language-plaintext highlighter-rouge\">ExifOffset</code></a> tag (hex <code class=\"language-plaintext highlighter-rouge\">0x8769</code>) which is a <code class=\"language-plaintext highlighter-rouge\">LONG</code> value allowing to find the EXIF IFD tags</li>\n</ul>\n\n<p>As mentioned earlier, the first two-byte word of the IFD indicates the number of tags in the IFD. Since each tag is 12 bytes long, multiplying the number of tags by 12 gives the size of all the IFD tags, allowing for looping through them.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"kd\">const</span> <span class=\"nx\">TAG_ID_EXIF_SUB_IFD_POINTER</span> <span class=\"o\">=</span> <span class=\"mh\">0x8769</span>\n<span class=\"kd\">const</span> <span class=\"nx\">TAG_ID_ORIENTATION</span> <span class=\"o\">=</span> <span class=\"mh\">0x0112</span>\n<span class=\"kd\">const</span> <span class=\"nx\">newOrientationValue</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n\n<span class=\"c1\">// Here offset = 12</span>\n<span class=\"c1\">// IFD0 offset given by the 4 bytes after 42</span>\n<span class=\"kd\">const</span> <span class=\"nx\">ifd0Offset</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint32</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n<span class=\"kd\">const</span> <span class=\"nx\">ifd0TagsCount</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">ifd0Offset</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n<span class=\"c1\">// IFD0 ends after the two-byte tags count word + all the tags</span>\n<span class=\"kd\">const</span> <span class=\"nx\">endOfIFD0TagsOffset</span> <span class=\"o\">=</span> <span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">ifd0Offset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"nx\">ifd0TagsCount</span> <span class=\"o\">*</span> <span class=\"mi\">12</span>\n\n<span class=\"k\">for</span> <span class=\"p\">(</span>\n  <span class=\"kd\">let</span> <span class=\"nx\">i</span> <span class=\"o\">=</span> <span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">ifd0Offset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n  <span class=\"nx\">i</span> <span class=\"o\">&lt;</span> <span class=\"nx\">endOfIFD0TagsOffset</span><span class=\"p\">;</span>\n  <span class=\"nx\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">12</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"c1\">// First 2 bytes = tag type</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">tagId</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">i</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n\n  <span class=\"c1\">// If Orientation tag</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">tagId</span> <span class=\"o\">===</span> <span class=\"nx\">TAG_ID_ORIENTATION</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// Skipping the 2 bytes tag type and 4 bytes tag count</span>\n    <span class=\"c1\">// Type is SHORT, so 2 bytes to write</span>\n    <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">setUint16</span><span class=\"p\">(</span><span class=\"nx\">i</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"nx\">newOrientationValue</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n  <span class=\"p\">}</span>\n\n  <span class=\"c1\">// If ExifIFD offset tag</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">tagId</span> <span class=\"o\">===</span> <span class=\"nx\">TAG_ID_EXIF_SUB_IFD_POINTER</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// Type is LONG, so 4 bytes to read</span>\n    <span class=\"nx\">exifSubIfdOffset</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint32</span><span class=\"p\">(</span><span class=\"nx\">i</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p><strong>Note:</strong> Following the same logic as for reading, the <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView/setUint16\"><code class=\"language-plaintext highlighter-rouge\">setUint16</code></a>/<a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView/setUint32\"><code class=\"language-plaintext highlighter-rouge\">setUint32</code></a> functions are used to respectively write two or four bytes.</p>\n\n<h3 id=\"exif-sub-ifd\">EXIF Sub-IFD</h3>\n\n<p>Once the offset of the EXIF sub-IFD is found, a new loop must be executed through that IFD\u2019s data to find the remaining height and width tags.</p>\n\n<p>Here is information about the two tags that need to be replaced:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">ExifImageWidth</code> or <code class=\"language-plaintext highlighter-rouge\">PixelXDimension</code> tag (hex <code class=\"language-plaintext highlighter-rouge\">0xa002</code>), a <code class=\"language-plaintext highlighter-rouge\">LONG</code> value that must be replaced by <code class=\"language-plaintext highlighter-rouge\">1920</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">ExifImageHeight</code> or <code class=\"language-plaintext highlighter-rouge\">PixelYDimension</code> tag (hex <code class=\"language-plaintext highlighter-rouge\">0xa003</code>), a <code class=\"language-plaintext highlighter-rouge\">LONG</code> value that must be replaced by <code class=\"language-plaintext highlighter-rouge\">1080</code></li>\n</ul>\n\n<p>As a reminder of what was previously stated, the IFD tag is composed of 2 bytes for the type, 4 for the count, and 4 for the value.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"kd\">const</span> <span class=\"nx\">TAG_ID_EXIF_IMAGE_WIDTH</span> <span class=\"o\">=</span> <span class=\"mh\">0xa002</span>\n<span class=\"kd\">const</span> <span class=\"nx\">TAG_ID_EXIF_IMAGE_HEIGHT</span> <span class=\"o\">=</span> <span class=\"mh\">0xa003</span>\n<span class=\"kd\">const</span> <span class=\"nx\">newWidthValue</span> <span class=\"o\">=</span> <span class=\"mi\">1920</span>\n<span class=\"kd\">const</span> <span class=\"nx\">newHeightValue</span> <span class=\"o\">=</span> <span class=\"mi\">1080</span>\n\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">exifSubIfdOffset</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">exifSubIfdTagsCount</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">exifSubIfdOffset</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n<span class=\"c1\">// This IFD also ends after the two-byte tags count word + all the tags</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">endOfExifSubIfdTagsOffset</span> <span class=\"o\">=</span>\n    <span class=\"nx\">offset</span> <span class=\"o\">+</span>\n    <span class=\"nx\">exifSubIfdOffset</span> <span class=\"o\">+</span>\n    <span class=\"mi\">2</span> <span class=\"o\">+</span>\n    <span class=\"nx\">exifSubIfdTagsCount</span> <span class=\"o\">*</span> <span class=\"mi\">12</span>\n  <span class=\"k\">for</span> <span class=\"p\">(</span>\n    <span class=\"kd\">let</span> <span class=\"nx\">i</span> <span class=\"o\">=</span> <span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">exifSubIfdOffset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n    <span class=\"nx\">i</span> <span class=\"o\">&lt;</span> <span class=\"nx\">endOfExifSubIfdTagsOffset</span><span class=\"p\">;</span>\n    <span class=\"nx\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">12</span>\n  <span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// First 2 bytes = tag type</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">tagId</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">i</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n\n    <span class=\"c1\">// Skipping the 2 bytes tag type and 4 bytes tag count</span>\n    <span class=\"c1\">// The two types are LONG, so 4 bytes to write</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">tagId</span> <span class=\"o\">===</span> <span class=\"nx\">TAG_ID_EXIF_IMAGE_WIDTH</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">setUint32</span><span class=\"p\">(</span><span class=\"nx\">i</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"nx\">newWidthValue</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">tagId</span> <span class=\"o\">===</span> <span class=\"nx\">TAG_ID_EXIF_IMAGE_HEIGHT</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">setUint32</span><span class=\"p\">(</span><span class=\"nx\">i</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"nx\">newHeightValue</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<h3 id=\"write-back-the-image\">Write back the image</h3>\n\n<p>Getting the final image is as simple as building a new Blob from the updated buffer data:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"nx\">finalImageBlob</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nx\">Blob</span><span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>In the end, the updated blob can be converted to a file or downloaded, depending on the application\u2019s needs.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>This article covers the basics of reading and updating tags, but you can expand the code by adding more tags. All the hex codes for the tags can be found on <a href=\"https://exiftool.org/TagNames/EXIF.html\">exiftools.org</a> or <a href=\"https://www.awaresystems.be/imaging/tiff/tifftags.html\">this tags reference site</a>.</p>\n\n<p>It\u2019s worth noting that there are existing libraries like <a href=\"https://github.com/exif-js/exif-js/issues/266#issuecomment-1333686536\"><code class=\"language-plaintext highlighter-rouge\">exif-js</code></a> or <a href=\"https://github.com/hMatoba/piexifjs/issues/78\"><code class=\"language-plaintext highlighter-rouge\">piexifjs</code></a> for manipulating EXIF data, but they may be larger than what is needed here and seems not being actively maintained.</p>\n\n<p>If you want to see the full code used to write this article, feel free to check out <a href=\"https://gist.github.com/CPatchane/bcd523298e64b1fa813cfae82b0f2b42\">this gist</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://getaround.tech/feed.xml",
      "value": "<p>The <strong>E</strong>xchangeable <strong>I</strong>mage <strong>F</strong>ile <strong>F</strong>ormat (EXIF) is a standard that specifies formats for images and sounds. It stores technical details through metadata, data that describes other data, such as the camera make and model and the date and time the image was taken.</p>\n\n<p>Initially, EXIF was used for two image formats, JPEG and TIFF. But today, other file formats such as PNG, WEBP, or HEIC also support EXIF for metadata.</p>\n\n<p>This article will focus on the JPEG format. In the first part, we will explore its structure before seeing how to read and update associated metadata through Javascript in a browser environment.</p>\n\n<p>Before moving on, it is essential to review some key concepts:</p>\n\n<p><strong>\ud83d\udccc What is the <code class=\"language-plaintext highlighter-rouge\">0x</code> notation?</strong>\n<code class=\"language-plaintext highlighter-rouge\">0x</code> indicates that the following number is in hexadecimal format, which uses a base-16 number system (as opposed to the base-10 decimal system). This notation is case-insensitive, meaning that <code class=\"language-plaintext highlighter-rouge\">0XFF</code> and <code class=\"language-plaintext highlighter-rouge\">0xff</code> are exactly the same.</p>\n\n<p><strong>\ud83d\udccc What is a bit or a byte?</strong>\nIn computer science, a bit is the smallest and the most basic unit of information. It is a binary digit (base 2) representing 0 or 1. A byte (or octet) is a group of eight bits. Since there are 256 possible combinations of 8 bits, a byte can be expressed as a hexadecimal number. For example:</p>\n\n<ul>\n  <li>The byte <code class=\"language-plaintext highlighter-rouge\">0x00</code> represents <code class=\"language-plaintext highlighter-rouge\">0</code> in decimal and corresponds to <code class=\"language-plaintext highlighter-rouge\">0000 0000</code> in binary, which is the minimum 8-bit value.</li>\n  <li>The byte <code class=\"language-plaintext highlighter-rouge\">0xD8</code> represents <code class=\"language-plaintext highlighter-rouge\">216</code> and corresponds to <code class=\"language-plaintext highlighter-rouge\">1101 1000</code>.</li>\n  <li>The byte <code class=\"language-plaintext highlighter-rouge\">0xFF</code> represents <code class=\"language-plaintext highlighter-rouge\">255</code> and corresponds to <code class=\"language-plaintext highlighter-rouge\">1111 1111</code>, which is the maximum 8-bit value.</li>\n</ul>\n\n<p>For multiple-byte words, the hex numbers are just combined: <code class=\"language-plaintext highlighter-rouge\">0xFFD8</code> is a two-byte word, and <code class=\"language-plaintext highlighter-rouge\">0x45786966</code> is a four-byte word.</p>\n\n<p><strong>\ud83d\udccc What is Endianness?</strong>\nThis is how a set of bytes is stored in memory. In big-endian, the most significant byte (leftmost) comes first, while in little-endian, the least significant byte (rightmost) comes first.</p>\n\n<p>For example, let\u2019s consider the two-byte word <code class=\"language-plaintext highlighter-rouge\">0x0124</code>. In a big-endian system, it will be written as <code class=\"language-plaintext highlighter-rouge\">01 24</code>, whereas in a little-endian one, it will be written as <code class=\"language-plaintext highlighter-rouge\">24 01</code>. Knowing whether an image has been written on a big or little-endian device is essential to read its data correctly.</p>\n\n<h2 id=\"the-exif-segment-in-the-jpeg-structure\">The EXIF segment in the JPEG structure</h2>\n\n<h3 id=\"segment-delimitations\">Segment delimitations</h3>\n\n<p>The structure of a JPEG image is divided into parts marked by two-byte markers, always starting with a <code class=\"language-plaintext highlighter-rouge\">0xFF</code> byte. Below is a list of key markers found in the pages 20/21 of the <a href=\"https://www.cipa.jp/std/documents/e/DC-008-2012_E.pdf\">JPEG compression specification</a>:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">0xFFD8</code>: <strong>SOI</strong> (Start of Image); indicates the beginning of the image structure.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">0xFFE*n*</code>: <strong>APPn</strong> (Application-related tags); following the <strong>SOI</strong> marker, with <code class=\"language-plaintext highlighter-rouge\">n</code> between <code class=\"language-plaintext highlighter-rouge\">0</code> and <code class=\"language-plaintext highlighter-rouge\">F</code> (<a href=\"https://exiftool.org/TagNames/JPEG.html\">full list</a>). For example, <strong>APP11</strong> (or <code class=\"language-plaintext highlighter-rouge\">0xFFEB</code>) is for HDR data, <strong>APP13</strong> (or <code class=\"language-plaintext highlighter-rouge\">0xFFED</code>) for Photoshop and <strong>APP1</strong> (or <code class=\"language-plaintext highlighter-rouge\">0xFFE1</code>) for EXIF.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">0xFFDA</code>: <strong>SOS</strong> (Start of Scan); indicates the beginning of the image-related data.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">0xFFD9</code>: <strong>EOI</strong> (End of Image); indicates the end of the image.</li>\n</ul>\n\n<p>The first four file bytes, here <code class=\"language-plaintext highlighter-rouge\">FF D8 FF E0</code> for JPEG, are also known as <a href=\"https://en.wikipedia.org/wiki/List_of_file_signatures\">magic numbers</a> and are used by software to identify the file type.</p>\n\n<h3 id=\"segment-size\">Segment size</h3>\n\n<p>The size of a segment can be determined by reading the two bytes following its marker. For example, if the segment starts with <code class=\"language-plaintext highlighter-rouge\">FFE1 0124 XXXXXXX</code>, then the APP1 segment size is 292 bytes, with <code class=\"language-plaintext highlighter-rouge\">0124</code> being the size\u2019s hexadecimal representation.</p>\n\n<h3 id=\"ifd-image-file-directory\">IFD: Image File Directory</h3>\n\n<p>Data in JPEG structure is grouped into directories called IFDs. For example, <code class=\"language-plaintext highlighter-rouge\">IDF0</code> is located in the <code class=\"language-plaintext highlighter-rouge\">APP1</code> segment, and <code class=\"language-plaintext highlighter-rouge\">IFDExif</code> is a sub-IFD of <code class=\"language-plaintext highlighter-rouge\">IDF0</code>.</p>\n\n<p>The IFD dataset includes a two-byte word indicating the number of tags, followed by the tags data and ending with the four-byte offset of the next IFD (or 0 if none).</p>\n\n<h3 id=\"ifd-tag\">IFD Tag</h3>\n\n<p>A tag, like all EXIF tags, is a twelve-byte length sequence made up of:</p>\n\n<ul>\n  <li>Tag ID (bytes 0-1): A two-byte word identifying the tag</li>\n  <li>Tag type (bytes 2-3): A two-byte word indicating the type. For example, a value of <code class=\"language-plaintext highlighter-rouge\">1</code> for a <code class=\"language-plaintext highlighter-rouge\">BYTE</code> (one-byte integer), <code class=\"language-plaintext highlighter-rouge\">3</code> for a <code class=\"language-plaintext highlighter-rouge\">SHORT</code> (two-byte integer), or <code class=\"language-plaintext highlighter-rouge\">4</code> for a <code class=\"language-plaintext highlighter-rouge\">LONG</code> (four-byte integer). For further details, see the pages 25 and 26 of the <a href=\"https://www.cipa.jp/std/documents/e/DC-008-2012_E.pdf\">JPEG compression specification</a>.</li>\n  <li>Tag count (bytes 4-7): A four-byte word indicating the number of values (usually 1)</li>\n  <li>Tag value or value offset (bytes 8-11): For <code class=\"language-plaintext highlighter-rouge\">SHORT</code> values, two bytes are read; for <code class=\"language-plaintext highlighter-rouge\">LONG</code> values, four bytes are read. If the value is longer than four bytes (e.g., <code class=\"language-plaintext highlighter-rouge\">RATIONAL</code> type), these four bytes store the offset needed to reach the actual value.</li>\n</ul>\n\n<figure>\n  <img alt=\"IFD tag example: the ExifImageWidth tag\" src=\"https://getaround.tech/assets/posts/2023-09-11-exif-data-manipulation-javascript/exif_ifd_tag.png\" />\n  <figcaption>\n    IFD tag example: the ExifImageWidth tag\n  </figcaption>\n</figure>\n\n<h2 id=\"locate-the-exif-part\">Locate the EXIF part</h2>\n\n<h3 id=\"from-image-to-bytes\">From image to bytes</h3>\n<p>Time to code! The <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/FileReader\"><code class=\"language-plaintext highlighter-rouge\">FileReader</code></a> API is here used to read the image as a <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer\"><code class=\"language-plaintext highlighter-rouge\">buffer</code></a>. Then it is transformed into a <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView\"><code class=\"language-plaintext highlighter-rouge\">DataView</code></a> for easier byte manipulation.</p>\n\n<p>The next step is to examine the start of the JPEG structure, which should be the <strong>SOI</strong> marker:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"c1\">// Where the final image with updated metadata will be stored</span>\n<span class=\"kd\">let</span> <span class=\"nx\">finalImageBlob</span> <span class=\"o\">=</span> <span class=\"kc\">null</span>\n\n<span class=\"kd\">const</span> <span class=\"nx\">reader</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nx\">FileReader</span><span class=\"p\">()</span>\n<span class=\"nx\">reader</span><span class=\"p\">.</span><span class=\"nx\">addEventListener</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">load</span><span class=\"dl\">\"</span><span class=\"p\">,</span> <span class=\"p\">({</span> <span class=\"nx\">target</span> <span class=\"p\">})</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">target</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">no blob found</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n  <span class=\"kd\">const</span> <span class=\"p\">{</span> <span class=\"na\">result</span><span class=\"p\">:</span> <span class=\"nx\">buffer</span> <span class=\"p\">}</span> <span class=\"o\">=</span> <span class=\"nx\">target</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">buffer</span> <span class=\"o\">||</span> <span class=\"k\">typeof</span> <span class=\"nx\">buffer</span> <span class=\"o\">===</span> <span class=\"dl\">\"</span><span class=\"s2\">string</span><span class=\"dl\">\"</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">not a valid JPEG</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n\n  <span class=\"kd\">const</span> <span class=\"nx\">view</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nb\">DataView</span><span class=\"p\">(</span><span class=\"nx\">buffer</span><span class=\"p\">)</span>\n  <span class=\"kd\">let</span> <span class=\"nx\">offset</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">SOI</span> <span class=\"o\">=</span> <span class=\"mh\">0xFFD8</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span><span class=\"p\">)</span> <span class=\"o\">!==</span> <span class=\"nx\">SOI</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">not a valid JPEG</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n  <span class=\"c1\">// Here will happen the image metadata manipulation</span>\n<span class=\"p\">})</span>\n<span class=\"c1\">// Image given as a Blob, but readAsArrayBuffer can also take a File</span>\n<span class=\"nx\">reader</span><span class=\"p\">.</span><span class=\"nx\">readAsArrayBuffer</span><span class=\"p\">(</span><span class=\"nx\">imageBlob</span><span class=\"p\">)</span></code></pre></figure>\n\n<p><strong>Note:</strong> The <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView/getUint16\"><code class=\"language-plaintext highlighter-rouge\">getUint16</code></a> function in Javascript is used to read two bytes (2*8 = 16bits), and there is a similar function for four bytes, <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView/getUint32\"><code class=\"language-plaintext highlighter-rouge\">getUint32</code></a>.</p>\n\n<h3 id=\"segments-reading\">Segments reading</h3>\n<p>From here can begin the loop through the image data to locate the EXIF section. The EXIF segment uses the <code class=\"language-plaintext highlighter-rouge\">APP1</code> marker followed by a special six-byte ASCII code <code class=\"language-plaintext highlighter-rouge\">Exif</code> (<code class=\"language-plaintext highlighter-rouge\">0x457869660000</code>) immediately following the <code class=\"language-plaintext highlighter-rouge\">APP1</code> size data.</p>\n\n<p>Reaching <strong>SOS</strong> marker is reached means reaching the start of the image data so the end of the metadata section.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"kd\">const</span> <span class=\"nx\">SOS</span> <span class=\"o\">=</span> <span class=\"mh\">0xFFDA</span>\n<span class=\"kd\">const</span> <span class=\"nx\">APP1</span> <span class=\"o\">=</span> <span class=\"mh\">0xFFE1</span>\n<span class=\"c1\">// Skip the last two bytes 0000 and just read the four first bytes</span>\n<span class=\"kd\">const</span> <span class=\"nx\">EXIF</span> <span class=\"o\">=</span> <span class=\"mh\">0x45786966</span>\n\n<span class=\"kd\">let</span> <span class=\"nx\">marker</span> <span class=\"o\">=</span> <span class=\"kc\">null</span>\n<span class=\"c1\">// The first two bytes (offset 0-1) was the SOI marker</span>\n<span class=\"nx\">offset</span> <span class=\"o\">+=</span> <span class=\"mi\">2</span>\n<span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"nx\">marker</span> <span class=\"o\">!==</span> <span class=\"nx\">SOS</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"nx\">marker</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span><span class=\"p\">)</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">size</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">marker</span> <span class=\"o\">===</span> <span class=\"nx\">APP1</span> <span class=\"o\">&amp;&amp;</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint32</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"mi\">4</span><span class=\"p\">)</span> <span class=\"o\">===</span> <span class=\"nx\">EXIF</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// EXIF segment found!</span>\n    <span class=\"c1\">// Following code will be here</span>\n  <span class=\"p\">}</span>\n  <span class=\"c1\">// Skip the entire segment (header of 2 bytes + size of the segment)</span>\n  <span class=\"nx\">offset</span> <span class=\"o\">+=</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"nx\">size</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p>The last thing to do here is to determine which is the endianness used to encode that image. In the JPEG structure, the endianness is provided thanks to the two-bytes word following the <code class=\"language-plaintext highlighter-rouge\">Exif</code> special word. If the word is <code class=\"language-plaintext highlighter-rouge\">0x4949</code>, it means it\u2019s little endian, otherwise it is <code class=\"language-plaintext highlighter-rouge\">0x4D4D</code> for big endian. This endianness data must be followed by the two bytes <code class=\"language-plaintext highlighter-rouge\">0x002A</code> (42 in decimal).</p>\n\n<p><strong>Note:</strong> From now on, always provide the endianness to the <code class=\"language-plaintext highlighter-rouge\">getUint16</code>/<code class=\"language-plaintext highlighter-rouge\">getUint32</code> functions to correctly read the bytes.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"kd\">const</span> <span class=\"nx\">LITTLE_ENDIAN</span> <span class=\"o\">=</span> <span class=\"mh\">0x4949</span>\n<span class=\"kd\">const</span> <span class=\"nx\">BIG_ENDIAN</span> <span class=\"o\">=</span> <span class=\"mh\">0x4d4d</span>\n\n<span class=\"c1\">// The APP1 here is at the very beginning of the file</span>\n<span class=\"c1\">// So at this point offset = 2,</span>\n<span class=\"c1\">// + 10 to skip to the bytes after the Exif word</span>\n<span class=\"nx\">offset</span> <span class=\"o\">+=</span> <span class=\"mi\">10</span>\n\n<span class=\"kd\">let</span> <span class=\"nx\">isLittleEndian</span> <span class=\"o\">=</span> <span class=\"kc\">null</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span><span class=\"p\">)</span> <span class=\"o\">===</span> <span class=\"nx\">LITTLE_ENDIAN</span><span class=\"p\">)</span> <span class=\"nx\">isLittleEndian</span> <span class=\"o\">=</span> <span class=\"kc\">true</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span><span class=\"p\">)</span> <span class=\"o\">===</span> <span class=\"nx\">BIG_ENDIAN</span><span class=\"p\">)</span> <span class=\"nx\">isLittleEndian</span> <span class=\"o\">=</span> <span class=\"kc\">false</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">invalid endian</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n<span class=\"c1\">// From now, the endianness must be specify each time bytes are read</span>\n<span class=\"c1\">// The 42 word</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span> <span class=\"o\">!==</span> <span class=\"mh\">0x2a</span><span class=\"p\">)</span> <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">invalid endian</span><span class=\"dl\">\"</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>If APP1 appears at the very beginning of the image structure (which is usually the case), then the structure should be as follows:</p>\n<figure>\n  <img alt=\"JPEG starting structure\" src=\"https://getaround.tech/assets/posts/2023-09-11-exif-data-manipulation-javascript/exif_markers.png\" />\n  <figcaption>\n    JPEG starting structure\n  </figcaption>\n</figure>\n\n<h2 id=\"read-and-replace-exif-tags\">Read and replace EXIF tags</h2>\n\n<p>All the necessary information are now known to search for the EXIF tags:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">Orientation</code>, located in the IFD <code class=\"language-plaintext highlighter-rouge\">IFD0</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">ExifImageWidth</code> or <code class=\"language-plaintext highlighter-rouge\">PixelXDimension</code> tag, located in the IFD <code class=\"language-plaintext highlighter-rouge\">IFDExif</code>, provided by the <code class=\"language-plaintext highlighter-rouge\">ExifOffset</code> tag of <code class=\"language-plaintext highlighter-rouge\">IFD0</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">ExifImageHeight</code> or <code class=\"language-plaintext highlighter-rouge\">PixelYDimension</code> tag, also located in <code class=\"language-plaintext highlighter-rouge\">IFDExif</code></li>\n</ul>\n\n<h3 id=\"ifd0\">IFD0</h3>\n\n<p>To locate the <code class=\"language-plaintext highlighter-rouge\">IFD0</code>, its offset is given by the 4-byte word immediately after the endianness <code class=\"language-plaintext highlighter-rouge\">42</code> number.</p>\n\n<p>This sequence that includes the endianness two-byte word, <code class=\"language-plaintext highlighter-rouge\">42</code>, and the <code class=\"language-plaintext highlighter-rouge\">IFD0</code> offset four-byte word is commonly referred to as the \u201cTIFF (<strong>T</strong>agged <strong>I</strong>mage <strong>F</strong>ile <strong>F</strong>ormat) Header\u201d:</p>\n\n<figure>\n  <img alt=\"The TIFF header\" src=\"https://getaround.tech/assets/posts/2023-09-11-exif-data-manipulation-javascript/exif_TIFF_header.png\" />\n  <figcaption>\n    The TIFF header\n  </figcaption>\n</figure>\n\n<p>At this point, there are two tags that need to be found through the <code class=\"language-plaintext highlighter-rouge\">IFD0</code> data:</p>\n\n<ul>\n  <li>The <a href=\"https://www.awaresystems.be/imaging/tiff/tifftags/orientation.html\"><code class=\"language-plaintext highlighter-rouge\">Orientation</code></a> tag (hex <code class=\"language-plaintext highlighter-rouge\">0x0112</code>) which is a <code class=\"language-plaintext highlighter-rouge\">SHORT</code> value that must be replaced by <code class=\"language-plaintext highlighter-rouge\">1</code></li>\n  <li>The EXIF specific IFD offset provided by the <a href=\"https://www.awaresystems.be/imaging/tiff/tifftags/exififd.html\"><code class=\"language-plaintext highlighter-rouge\">ExifOffset</code></a> tag (hex <code class=\"language-plaintext highlighter-rouge\">0x8769</code>) which is a <code class=\"language-plaintext highlighter-rouge\">LONG</code> value allowing to find the EXIF IFD tags</li>\n</ul>\n\n<p>As mentioned earlier, the first two-byte word of the IFD indicates the number of tags in the IFD. Since each tag is 12 bytes long, multiplying the number of tags by 12 gives the size of all the IFD tags, allowing for looping through them.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"kd\">const</span> <span class=\"nx\">TAG_ID_EXIF_SUB_IFD_POINTER</span> <span class=\"o\">=</span> <span class=\"mh\">0x8769</span>\n<span class=\"kd\">const</span> <span class=\"nx\">TAG_ID_ORIENTATION</span> <span class=\"o\">=</span> <span class=\"mh\">0x0112</span>\n<span class=\"kd\">const</span> <span class=\"nx\">newOrientationValue</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n\n<span class=\"c1\">// Here offset = 12</span>\n<span class=\"c1\">// IFD0 offset given by the 4 bytes after 42</span>\n<span class=\"kd\">const</span> <span class=\"nx\">ifd0Offset</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint32</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n<span class=\"kd\">const</span> <span class=\"nx\">ifd0TagsCount</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">ifd0Offset</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n<span class=\"c1\">// IFD0 ends after the two-byte tags count word + all the tags</span>\n<span class=\"kd\">const</span> <span class=\"nx\">endOfIFD0TagsOffset</span> <span class=\"o\">=</span> <span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">ifd0Offset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"nx\">ifd0TagsCount</span> <span class=\"o\">*</span> <span class=\"mi\">12</span>\n\n<span class=\"k\">for</span> <span class=\"p\">(</span>\n  <span class=\"kd\">let</span> <span class=\"nx\">i</span> <span class=\"o\">=</span> <span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">ifd0Offset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n  <span class=\"nx\">i</span> <span class=\"o\">&lt;</span> <span class=\"nx\">endOfIFD0TagsOffset</span><span class=\"p\">;</span>\n  <span class=\"nx\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">12</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"c1\">// First 2 bytes = tag type</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">tagId</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">i</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n\n  <span class=\"c1\">// If Orientation tag</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">tagId</span> <span class=\"o\">===</span> <span class=\"nx\">TAG_ID_ORIENTATION</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// Skipping the 2 bytes tag type and 4 bytes tag count</span>\n    <span class=\"c1\">// Type is SHORT, so 2 bytes to write</span>\n    <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">setUint16</span><span class=\"p\">(</span><span class=\"nx\">i</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"nx\">newOrientationValue</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n  <span class=\"p\">}</span>\n\n  <span class=\"c1\">// If ExifIFD offset tag</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">tagId</span> <span class=\"o\">===</span> <span class=\"nx\">TAG_ID_EXIF_SUB_IFD_POINTER</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// Type is LONG, so 4 bytes to read</span>\n    <span class=\"nx\">exifSubIfdOffset</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint32</span><span class=\"p\">(</span><span class=\"nx\">i</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<p><strong>Note:</strong> Following the same logic as for reading, the <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView/setUint16\"><code class=\"language-plaintext highlighter-rouge\">setUint16</code></a>/<a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView/setUint32\"><code class=\"language-plaintext highlighter-rouge\">setUint32</code></a> functions are used to respectively write two or four bytes.</p>\n\n<h3 id=\"exif-sub-ifd\">EXIF Sub-IFD</h3>\n\n<p>Once the offset of the EXIF sub-IFD is found, a new loop must be executed through that IFD\u2019s data to find the remaining height and width tags.</p>\n\n<p>Here is information about the two tags that need to be replaced:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">ExifImageWidth</code> or <code class=\"language-plaintext highlighter-rouge\">PixelXDimension</code> tag (hex <code class=\"language-plaintext highlighter-rouge\">0xa002</code>), a <code class=\"language-plaintext highlighter-rouge\">LONG</code> value that must be replaced by <code class=\"language-plaintext highlighter-rouge\">1920</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">ExifImageHeight</code> or <code class=\"language-plaintext highlighter-rouge\">PixelYDimension</code> tag (hex <code class=\"language-plaintext highlighter-rouge\">0xa003</code>), a <code class=\"language-plaintext highlighter-rouge\">LONG</code> value that must be replaced by <code class=\"language-plaintext highlighter-rouge\">1080</code></li>\n</ul>\n\n<p>As a reminder of what was previously stated, the IFD tag is composed of 2 bytes for the type, 4 for the count, and 4 for the value.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"kd\">const</span> <span class=\"nx\">TAG_ID_EXIF_IMAGE_WIDTH</span> <span class=\"o\">=</span> <span class=\"mh\">0xa002</span>\n<span class=\"kd\">const</span> <span class=\"nx\">TAG_ID_EXIF_IMAGE_HEIGHT</span> <span class=\"o\">=</span> <span class=\"mh\">0xa003</span>\n<span class=\"kd\">const</span> <span class=\"nx\">newWidthValue</span> <span class=\"o\">=</span> <span class=\"mi\">1920</span>\n<span class=\"kd\">const</span> <span class=\"nx\">newHeightValue</span> <span class=\"o\">=</span> <span class=\"mi\">1080</span>\n\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">exifSubIfdOffset</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">exifSubIfdTagsCount</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">exifSubIfdOffset</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n<span class=\"c1\">// This IFD also ends after the two-byte tags count word + all the tags</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">endOfExifSubIfdTagsOffset</span> <span class=\"o\">=</span>\n    <span class=\"nx\">offset</span> <span class=\"o\">+</span>\n    <span class=\"nx\">exifSubIfdOffset</span> <span class=\"o\">+</span>\n    <span class=\"mi\">2</span> <span class=\"o\">+</span>\n    <span class=\"nx\">exifSubIfdTagsCount</span> <span class=\"o\">*</span> <span class=\"mi\">12</span>\n  <span class=\"k\">for</span> <span class=\"p\">(</span>\n    <span class=\"kd\">let</span> <span class=\"nx\">i</span> <span class=\"o\">=</span> <span class=\"nx\">offset</span> <span class=\"o\">+</span> <span class=\"nx\">exifSubIfdOffset</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n    <span class=\"nx\">i</span> <span class=\"o\">&lt;</span> <span class=\"nx\">endOfExifSubIfdTagsOffset</span><span class=\"p\">;</span>\n    <span class=\"nx\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">12</span>\n  <span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// First 2 bytes = tag type</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">tagId</span> <span class=\"o\">=</span> <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">getUint16</span><span class=\"p\">(</span><span class=\"nx\">i</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n\n    <span class=\"c1\">// Skipping the 2 bytes tag type and 4 bytes tag count</span>\n    <span class=\"c1\">// The two types are LONG, so 4 bytes to write</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">tagId</span> <span class=\"o\">===</span> <span class=\"nx\">TAG_ID_EXIF_IMAGE_WIDTH</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">setUint32</span><span class=\"p\">(</span><span class=\"nx\">i</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"nx\">newWidthValue</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">tagId</span> <span class=\"o\">===</span> <span class=\"nx\">TAG_ID_EXIF_IMAGE_HEIGHT</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"nx\">view</span><span class=\"p\">.</span><span class=\"nx\">setUint32</span><span class=\"p\">(</span><span class=\"nx\">i</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"nx\">newHeightValue</span><span class=\"p\">,</span> <span class=\"nx\">isLittleEndian</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre></figure>\n\n<h3 id=\"write-back-the-image\">Write back the image</h3>\n\n<p>Getting the final image is as simple as building a new Blob from the updated buffer data:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-javascript\"><span class=\"nx\">finalImageBlob</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nx\">Blob</span><span class=\"p\">(</span><span class=\"nx\">view</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>In the end, the updated blob can be converted to a file or downloaded, depending on the application\u2019s needs.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>This article covers the basics of reading and updating tags, but you can expand the code by adding more tags. All the hex codes for the tags can be found on <a href=\"https://exiftool.org/TagNames/EXIF.html\">exiftools.org</a> or <a href=\"https://www.awaresystems.be/imaging/tiff/tifftags.html\">this tags reference site</a>.</p>\n\n<p>It\u2019s worth noting that there are existing libraries like <a href=\"https://github.com/exif-js/exif-js/issues/266#issuecomment-1333686536\"><code class=\"language-plaintext highlighter-rouge\">exif-js</code></a> or <a href=\"https://github.com/hMatoba/piexifjs/issues/78\"><code class=\"language-plaintext highlighter-rouge\">piexifjs</code></a> for manipulating EXIF data, but they may be larger than what is needed here and seems not being actively maintained.</p>\n\n<p>If you want to see the full code used to write this article, feel free to check out <a href=\"https://gist.github.com/CPatchane/bcd523298e64b1fa813cfae82b0f2b42\">this gist</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://getaround.tech/feed.xml",
        "value": "<p>The <strong>E</strong>xchangeable <strong>I</strong>mage <strong>F</strong>ile <strong>F</strong>ormat (EXIF) is a standard that specifies formats for images and sounds. It stores technical details through metadata, data that describes other data, such as the camera make and model and the date and time the image was taken.</p>"
      }
    ],
    "published": "Mon, 11 Sep 2023 00:00:00 +0000",
    "published_parsed": [
      2023,
      9,
      11,
      0,
      0,
      0,
      0,
      254,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://getaround.tech/exif-data-manipulation-javascript/"
      }
    ],
    "link": "https://getaround.tech/exif-data-manipulation-javascript/",
    "id": "https://getaround.tech/exif-data-manipulation-javascript/",
    "guidislink": false
  },
  "Deliveroo": {
    "title": "From Code to Leadership: Empowering Women in Engineering at our New India Hub",
    "xmlUrl": "http://deliveroo.engineering/feed.xml",
    "htmlUrl": "https://deliveroo.engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://deliveroo.engineering/feed.xml",
      "value": "From Code to Leadership: Empowering Women in Engineering at our New India Hub"
    },
    "summary": "<p><strong><em>Could you introduce yourself and your role at Deliveroo?</em></strong></p>\n\n<p>I\u2019m Prachi, and I joined Deliveroo in August last year. I\u2019m located in India, and I bring with me about 10 years of work experience. Initially, I joined Deliveroo as a Senior Software Engineer, and I\u2019m thrilled to share that I\u2019ve recently transitioned into the role of an Engineering Manager within 10 months of joining.</p>\n\n<p>In my current role, I\u2019m responsible for managing a dynamic team of seven skilled engineers, focused on enhancing and transforming our systems to deliver a seamless experience to our users.</p>\n\n<p><strong><em>What made you choose Deliveroo as a place of work?</em></strong></p>\n\n<p>While I hadn\u2019t personally used the app as it isn\u2019t available in India, I dedicated time to learn about the company and its goals. One aspect that surprised me in a positive way is how quickly Deliveroo adapts to market dynamics. Considering that we operate in a  dynamic industry like food delivery, I knew there would be a lot of interesting challenges to solve and that generally comes with a steep learning curve, which I was looking forward to at that stage of my career.</p>\n\n<p>The opportunity for autonomy and flexibility in my work was particularly appealing to me, and this was reflected in the seamless nature of my interactions right from Day 1 - from the introductory call with the recruiter up to the moment I received the offer letter. This indicated to me  the kind of culture the company is striving to cultivate, and reinforced my belief that such a culture would significantly contribute to my overall well-being.</p>\n\n<p><strong><em>What have you enjoyed the most about your journey with Roo so far?</em></strong></p>\n\n<p>First and foremost, I am really enjoying the collaborative and supportive environment here. Despite the geo location and time zone differences, cross collaboration has never been easier, and I\u2019ve had the opportunity to work alongside multiple talented and passionate individuals - there is so much to learn from everyone around here.</p>\n\n<p>Secondly, the pace of execution, coupled with the level of autonomy and trust given to employees is amazing. From day one, I\u2019ve felt empowered to take ownership of my projects and have my voice heard. The company values input from employees at all levels, which fosters an environment where creativity and independent thinking are genuinely appreciated.</p>\n\n<p>Last but not the least, I have been really amazed at the level of investment in employee growth and development. I have been consistently encouraged to take on new challenges and have been provided opportunities to grow in my professional career, one of which being the transition from Individual Contributor to Engineering Manager</p>\n\n<p><strong><em>What made you transition from Individual Contributor to Engineering Manager?</em></strong></p>\n\n<p>I think in the back of my mind, I always knew that I had a passion for leading and mentoring others. I enjoy helping people grow and achieve their maximum potential, so transitioning into a leadership role felt like a natural step forward for me.</p>\n\n<p>Secondly, taking on this new challenge will  help me grow both personally and professionally. Managing teams and dealing with people-related challenges would give me the opportunity to broaden my skills and impact, by overseeing multiple projects and aligning their collective efforts towards larger organisational goals.</p>\n\n<p><strong><em>What do you think makes someone a  successful people manager?</em></strong></p>\n\n<p>I\u2019ve just started my journey as a people manager, so my personal style is still evolving, however I have had the good fortune of working with amazing managers in my professional life and I\u2019ve been actively picking valuable aspects from their unique managerial approaches.</p>\n\n<p>Moving into this new role has helped me realise that effective leadership is not a one-size-fits-all approach, and various styles can be successful depending on the context and the team. That being said, the following are the pillars of my management style:</p>\n\n<ul>\n  <li>Positive Work Culture: I work on creating an environment of trust, inclusiveness, and safety, where everyone feels they belong.</li>\n  <li>Continuous Learning: I focus on personal and professional growth, always learning new skills to better support the team.</li>\n  <li>Alignment with Goals: I ensure our team\u2019s work aligns with Deliveroo\u2019s mission and vision, ensuring everyone is working toward the same end goal.</li>\n  <li>Relationship Building: I prioritise building strong relationships with team members by investing time and effort.</li>\n  <li>Trust and Empowerment: I trust my team with responsibilities and empower them to make decisions within their expertise, fostering ownership and accountability.</li>\n</ul>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://deliveroo.engineering/feed.xml",
      "value": "<p><strong><em>Could you introduce yourself and your role at Deliveroo?</em></strong></p>\n\n<p>I\u2019m Prachi, and I joined Deliveroo in August last year. I\u2019m located in India, and I bring with me about 10 years of work experience. Initially, I joined Deliveroo as a Senior Software Engineer, and I\u2019m thrilled to share that I\u2019ve recently transitioned into the role of an Engineering Manager within 10 months of joining.</p>\n\n<p>In my current role, I\u2019m responsible for managing a dynamic team of seven skilled engineers, focused on enhancing and transforming our systems to deliver a seamless experience to our users.</p>\n\n<p><strong><em>What made you choose Deliveroo as a place of work?</em></strong></p>\n\n<p>While I hadn\u2019t personally used the app as it isn\u2019t available in India, I dedicated time to learn about the company and its goals. One aspect that surprised me in a positive way is how quickly Deliveroo adapts to market dynamics. Considering that we operate in a  dynamic industry like food delivery, I knew there would be a lot of interesting challenges to solve and that generally comes with a steep learning curve, which I was looking forward to at that stage of my career.</p>\n\n<p>The opportunity for autonomy and flexibility in my work was particularly appealing to me, and this was reflected in the seamless nature of my interactions right from Day 1 - from the introductory call with the recruiter up to the moment I received the offer letter. This indicated to me  the kind of culture the company is striving to cultivate, and reinforced my belief that such a culture would significantly contribute to my overall well-being.</p>\n\n<p><strong><em>What have you enjoyed the most about your journey with Roo so far?</em></strong></p>\n\n<p>First and foremost, I am really enjoying the collaborative and supportive environment here. Despite the geo location and time zone differences, cross collaboration has never been easier, and I\u2019ve had the opportunity to work alongside multiple talented and passionate individuals - there is so much to learn from everyone around here.</p>\n\n<p>Secondly, the pace of execution, coupled with the level of autonomy and trust given to employees is amazing. From day one, I\u2019ve felt empowered to take ownership of my projects and have my voice heard. The company values input from employees at all levels, which fosters an environment where creativity and independent thinking are genuinely appreciated.</p>\n\n<p>Last but not the least, I have been really amazed at the level of investment in employee growth and development. I have been consistently encouraged to take on new challenges and have been provided opportunities to grow in my professional career, one of which being the transition from Individual Contributor to Engineering Manager</p>\n\n<p><strong><em>What made you transition from Individual Contributor to Engineering Manager?</em></strong></p>\n\n<p>I think in the back of my mind, I always knew that I had a passion for leading and mentoring others. I enjoy helping people grow and achieve their maximum potential, so transitioning into a leadership role felt like a natural step forward for me.</p>\n\n<p>Secondly, taking on this new challenge will  help me grow both personally and professionally. Managing teams and dealing with people-related challenges would give me the opportunity to broaden my skills and impact, by overseeing multiple projects and aligning their collective efforts towards larger organisational goals.</p>\n\n<p><strong><em>What do you think makes someone a  successful people manager?</em></strong></p>\n\n<p>I\u2019ve just started my journey as a people manager, so my personal style is still evolving, however I have had the good fortune of working with amazing managers in my professional life and I\u2019ve been actively picking valuable aspects from their unique managerial approaches.</p>\n\n<p>Moving into this new role has helped me realise that effective leadership is not a one-size-fits-all approach, and various styles can be successful depending on the context and the team. That being said, the following are the pillars of my management style:</p>\n\n<ul>\n  <li>Positive Work Culture: I work on creating an environment of trust, inclusiveness, and safety, where everyone feels they belong.</li>\n  <li>Continuous Learning: I focus on personal and professional growth, always learning new skills to better support the team.</li>\n  <li>Alignment with Goals: I ensure our team\u2019s work aligns with Deliveroo\u2019s mission and vision, ensuring everyone is working toward the same end goal.</li>\n  <li>Relationship Building: I prioritise building strong relationships with team members by investing time and effort.</li>\n  <li>Trust and Empowerment: I trust my team with responsibilities and empower them to make decisions within their expertise, fostering ownership and accountability.</li>\n</ul>"
    },
    "published": "Mon, 09 Oct 2023 10:30:04 +0000",
    "published_parsed": [
      2023,
      10,
      9,
      10,
      30,
      4,
      0,
      282,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://deliveroo.engineering/2023/10/09/from-code-to-leadership.html"
      }
    ],
    "link": "https://deliveroo.engineering/2023/10/09/from-code-to-leadership.html",
    "id": "https://deliveroo.engineering/2023/10/09/from-code-to-leadership.html",
    "guidislink": false
  },
  "Lyft": {
    "title": "Druid Deprecation and ClickHouse Adoption at Lyft",
    "xmlUrl": "https://eng.lyft.com/feed",
    "htmlUrl": "https://eng.lyft.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://eng.lyft.com/feed",
      "value": "Druid Deprecation and ClickHouse Adoption at Lyft"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://eng.lyft.com/druid-deprecation-and-clickhouse-adoption-at-lyft-120af37651fd?source=rss----25cd379abb8---4"
      }
    ],
    "link": "https://eng.lyft.com/druid-deprecation-and-clickhouse-adoption-at-lyft-120af37651fd?source=rss----25cd379abb8---4",
    "id": "https://medium.com/p/120af37651fd",
    "guidislink": false,
    "tags": [
      {
        "term": "analytics",
        "scheme": null,
        "label": null
      },
      {
        "term": "clickhouse",
        "scheme": null,
        "label": null
      },
      {
        "term": "data-platforms",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Ritesh Varyani"
      }
    ],
    "author": "Ritesh Varyani",
    "author_detail": {
      "name": "Ritesh Varyani"
    },
    "published": "Wed, 29 Nov 2023 18:01:45 GMT",
    "published_parsed": [
      2023,
      11,
      29,
      18,
      1,
      45,
      2,
      333,
      0
    ],
    "updated": "2023-12-01T03:55:55.820Z",
    "updated_parsed": [
      2023,
      12,
      1,
      3,
      55,
      55,
      4,
      335,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://eng.lyft.com/feed",
        "value": "<p><em>Written by </em><a href=\"https://www.linkedin.com/in/riteshvaryani/\"><em>Ritesh Varyani</em></a><em> and </em><a href=\"https://www.linkedin.com/in/jeana-choi/\"><em>Jeana Choi</em></a><em> at\u00a0Lyft.</em></p><h3>Introduction</h3><p>At Lyft, we have used systems like ClickHouse and Apache Druid for near real-time and sub-second analytics. Sub-second query systems allow for near real-time data explorations and low latency, high throughput queries, which are particularly well-suited for handling time-series data. For our customers, this means faster analytics on near real-time data and decision making. This is crucial for use cases like market signaling and forecasting which benefit from, and depend upon, the most up-to-date information. Overall, these systems allow us to make timely decisions for the business with accurate predictions.</p><p>In this particular blog post, we explain how Druid has been used at Lyft and what led us to adopt ClickHouse for our sub-second analytic\u00a0system.</p><h3>Druid at\u00a0Lyft</h3><p><a href=\"https://druid.apache.org/\">Apache Druid</a> is an in-memory, columnar, distributed, open-source data store designed for sub-second queries on real-time and historical data. Druid enables low latency (real-time) data ingestion, flexible data exploration and fast data aggregation resulting in sub-second query latencies.</p><p>At Lyft, we started using Druid around six years ago as our first interactive query engine in the sub-second space. Our initial use for Druid was for near real-time geospatial querying and high performance on high-cardinality data sets. It also allowed us to optimize for handling time-series data and event data at\u00a0scale.</p><p>Druid leverages the concept of <em>segments</em>, a unit of storage that allows for parallel querying and columnar storage, complemented with efficient compression and data retrieval.</p><h3>Druid Architecture at\u00a0Lyft</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*T-pN-422J2NBnXAp\" /><figcaption>Druid Architecture at\u00a0Lyft</figcaption></figure><p>With Lyft as a Kubernetes shop, we ran all of the above processes into our stateful and stateless Kubernetes pods within the service namespaces. External dependencies for Druid were managed by our persistence teams and Amazon S3 was utilized for deep storage of our segments.</p><h3>Druid Performance</h3><p>For Druid query performance, we primarily focused on two types of optimization: <em>rollup</em> and <em>compaction</em>.</p><p>1. At Lyft, we used <em>rollup</em> as a data preprocessing technique which aggregates and reduces the granularity of data prior to being stored in segments. Pre-aggregating data at ingestion time helped optimize our query performance and reduce our storage\u00a0costs.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*qzEKj2FCyBDqDBZy\" /><figcaption>An example of how we use Druid rollup at\u00a0Lyft.</figcaption></figure><p>2. <em>Compaction</em> uses batch processing to combine many small, fragmented segments into fewer optimized segments, improving the query performance further.</p><h3>Druid Data Ingestion</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/627/0*6nOUlAOuAX_4wSYM\" /><figcaption>Our pipeline for the two methods of ingesting data into Druid\u2014the upper process is for batch ingestion, the lower process is for real-time ingestion.</figcaption></figure><h4>Real-time Ingestion</h4><p>Events from our real-time analytics pipeline were configured to be sent into our internal Flink application, streamed to Kafka, and written into Druid. This was our main form of ingestion.</p><h4>Batch Ingestion</h4><p>Our batch ingestion pipeline served as a backup ingestion method for backfills and maintenance tasks, specifically:</p><ul><li>Backfills covering for any data loss or downtime in real-time ingestion</li><li>Maintenance tasks such as compaction of\u00a0segments</li></ul><h3>Configuring Ingestion for\u00a0Druid</h3><p>To onboard a use case to Druid, our customers had to make the events streamed to our Flink application with the correct transformations if needed, and define the proto files to serialize and deserialize the data to Kafka to prepare them for ingestion into Druid. Then, they needed to define an ingestion specification which tells Druid how to process the data being ingested.</p><p>A Druid ingestion specification contains the following:</p><ul><li>Datasource schema: name, query / segment granularity, timestamp, dimension, metrics,\u00a0etc.</li><li>ioConfig: Kafka server info, topic names, etc. (ex. tuningConfig)</li></ul><pre>druid: {<br />ioConfig: {<br />taskCount: 3<br />replicas: 2<br />taskDuration: PT15M<br />completionTimeout: PT60M<br />earlyMessageRejectionPeriod: PT2H<br />}<br />tuningConfig: {<br />intermediatePersistPeriod: PT5M,<br />maxRowsPerSegment: 15000000<br />maxRowsInMemory: 500000<br />resetOffsetAutomatically: true<br />}<br />}<br />kafka {<br />partitions: 3<br />}</pre><h4>Druid Use Cases at\u00a0Lyft</h4><p>Druid powered crucial use cases for Lyft, including pricing models and campaigns created and analyzed by our campaigns and communications team. In addition, our experimentation team utilized the datastore to analyze recent experimentation data.</p><h3>Managing Druid and Issues We\u00a0Faced</h3><p>At Lyft, our primary Druid customers were data engineers and software engineers. One of the main barriers we faced for onboarding new customers was the steep ramp-up for writing and maintaining their ingestion specifications, as well as understanding the different tuning mechanisms for each use\u00a0case.</p><p>This involved:</p><ul><li>Ensuring the correct format for data being\u00a0ingested</li><li>Fixing downstream ingestion pipelines for use cases with any upstream\u00a0changes</li><li>Creating specification files for users well-versed in Python/SQL semantics, but not necessarily Druid-specific technologies</li></ul><p>These blockers made it difficult to find more customers and increase adoption. Over time, Druid was under-invested due to lack of ROI, despite the existing and active critical use cases for spend tracking, short-term forecasting, and signaling.</p><p>Around this time, Lyft began to run a lot leaner with different cost-cutting initiatives. For new platform engineers, it presented a steeper learning curve. This lean phase meant we hyper-prioritized and therefore could not quickly upgrade or maintain Druid\u2019s latest performance fixes.</p><p>In addition, when Lyft moved to Kubernetes Compute about three years ago, an extra layer of complexity was introduced, increasing the effort required for the team since multiple Druid clusters were running with many more components in the updated\u00a0system.</p><p>With these factors in mind, we wanted to take a step back and reevaluate our choices to consider if other technologies could be a net positive for\u00a0us.</p><h3>ClickHouse at\u00a0Lyft</h3><h4>What is ClickHouse?</h4><p>ClickHouse is an open-source, column-oriented database for online analytical processing. One of ClickHouse\u2019s standout factors is its high performance\u2014due to a combination of factors such as column-based data storage &amp; processing, data compression, and indexing.</p><h4>Initial Use\u00a0Case</h4><p>In 2020, while the data platform team was managing Druid, the marketplace team considered a new set of requirements:</p><ol><li>Data produced is immediately available for querying in near real-time</li><li>Latencies are sub-second for business dashboarding</li><li>Ingestion for quick slice and dice of datasets. (For example: How many rides in the last 2 hours in the SF\u00a0region?)</li><li>Nested data\u00a0support</li><li>Support for both real-time and batch ingestion</li><li>Native data deduplication at destination</li></ol><p>While the latest version of Druid would provide us with some of these features, such as nested joins (v0.18), other requirements such as deduplication at destination would not be well satisfied. Using our existing stack, we considered performing deduplication at the streaming layer instead of at the destination.</p><p>However, two main reasons prevented us from pursuing this\u00a0idea:</p><ol><li>We would want to perform this at the Destination Storage layer to deduplicate data between the stream and batch\u00a0loads.</li><li>Streaming solutions require setting up a mutability window per entity (ex. 24 hours per ride). This was a hard requirement from the business end due to possible scenarios of updating a past transactional entity already written to storage. This was coupled with the need of the entity to be queryable as soon as possible (at the end of a ride, for example, if not earlier).</li></ol><p>The conclusion was that we should be able to overwrite records as needed using the dedupe facility. With this information at top of mind in 2020, ClickHouse emerged as an option that satisfied the above requirements out of the box and was adopted by the marketplace team.</p><h3>Decision: ClickHouse or\u00a0Druid?</h3><p>ClickHouse gained momentum with our marketplace use cases, leading us to a series of questions\u200a\u2014\u200ashould we expand to other use cases? Can ClickHouse support our Druid use cases? Should we continue to run both systems at Lyft or consolidate into\u00a0one?</p><p>After a careful and deep analysis of cost, infrastructure management, and overall feature benefits, we decided to expand on ClickHouse and sunset Druid, migrating existing Druid use cases to ClickHouse. The following points expand on some benefits we saw with ClickHouse over\u00a0Druid:</p><ol><li><strong>Simplified infrastructure management</strong>\u2014with Lyft\u2019s pivot towards leaner teams and architecture, there was a preference for converging on a system with less management and maintenance requirements. Druid, due to its modular design, turned out to be a more complex system to maintain.</li><li><strong>Reduced learning</strong> <strong>curve</strong>\u2014our users are well versed in Python and SQL semantics compared to Java, etc. With more familiar language and tooling, onboarding their use cases would take less time. For example, defining sorting key and engine type in their object definitions with TTL would be a shorter learning curve compared to defining these as a Druid specification.</li><li><strong>Data deduplication\u2014</strong>covered in the \u201cInitial Use Case\u201d section\u00a0above.</li><li><strong>Cost</strong>\u2014for<strong> </strong>Lyft, as a Kubernetes Compute company, running ClickHouse over Druid would reduce our compute footprint by a large margin. Running much leaner with better TTL definitions at 1/8th of the cost was a big\u00a0plus.</li><li><strong>Specialized</strong> <strong>engines</strong>\u2014Replicated*, Replacing* and Kafka Engine types in ClickHouse allow Lyft to natively manage Kafka pull-based ingestion and also maintain high availability (HA) due to replication across\u00a0nodes.</li></ol><h3>Benchmarking, Performance, and Migration</h3><p>We created a benchmarking test suite, and while still serving queries off of Druid, provisioned our real-time &amp; batch ingestion in ClickHouse, and ran tests in a controlled environment comparing query performance between ClickHouse and\u00a0Druid.</p><p>We involved our stakeholder users in these tests and took queries running in our Druid production system, dynamically transpiled them to ClickHouse syntax, and fired both queries against Druid and ClickHouse respectively. We compared the query latencies and identified bottlenecks in ClickHouse.</p><p>For a couple of our experimentation use cases in ClickHouse, we observed unreliable (spiky, higher) latency performance due to the sorting key of the table and the query resulting in full scans of the table. Since the shape of the query was consistent and the data queried could be pre-aggregated, adding <em>projections</em> in ClickHouse helped.</p><p>Projections are essentially precomputed views of your data, which compute only on the columns needed and rather than running a full table scan, ClickHouse just scans the projection column. In addition to improving the query performance for the couple experimentation use cases, projections helped reduce our I/O as\u00a0well.</p><p>We measured correctness (by row counts returned and the diff of exact table results) and latency, and used a tiered migration serving 1%, 5%, 10%, 20%, 50% and then 100% from ClickHouse. We eventually also realized latency gains which is discussed in later sections.</p><p>Overall, our migration experience went smoothly. Use cases for campaigns, experimentation, forecasting, and spend tracking underwent this migration process. We communicated with customer teams and ensured correct read query translations from Druid to ClickHouse, as well as running the above benchmarking tests and performance analysis. Throughout the process, we worked on some query optimizations (see the\u201cClickHouse Query Optimizations\u201d section below) for certain scenarios where the latency was higher than\u00a0desired.</p><h3>ClickHouse Architecture at\u00a0Lyft</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*HTmFoNbQd-zFGNIZ\" /><figcaption>Current ClickHouse Architecture at\u00a0Lyft</figcaption></figure><p>We use <a href=\"https://github.com/Altinity/clickhouse-operator\">Altinity\u2019s Kubernetes Operator</a> to deploy the ClickHouse clusters. Currently, we run the 21.7 version of ClickHouse and have plans to upgrade to the latest version. The storage which we use are co-located EBS volumes in our stateful Kubernetes cluster. We run our clusters in HA mode with general-purpose AWS M5-type compute instances with our database objects being replicated across nodes. We do not use sharding on our clusters currently but there are plans to optimize the cluster performance as we scale\u00a0more.</p><p>ClickHouse data ingestion is discussed in detail below. ClickHouse read querying is served through our internal Proxy with ACLs and visualization tools such as\u00a0Mode.</p><h3>ClickHouse Data Ingestion</h3><p>For our ClickHouse infrastructure, we handle ingestion through three separate pipelines.</p><ol><li><strong>Kafka \u2192 ClickHouse: </strong>this is primarily used by our services which rely on a pub-sub model. ClickHouse is one of the subscribers to this data. There is native support in ClickHouse for the KafkaTableEngine, which uses a pull-based mechanism to read from Kafka cluster topics. We ingest up to 2 billion records per day into ClickHouse from Kafka-based ingestion.</li><li><strong>Kinesis \u2192 Flink \u2192 ClickHouse</strong>: this ingestion scheme populates our events data in ClickHouse. Events teams, who need their data in ClickHouse for analytics, onboard through this ingestion mechanism. Lyft generates about 600 million rows per day from Flink ingestion alone, in ClickHouse.</li><li><strong>Trino \u2192 Cron \u2192 ClickHouse: </strong>we also support batch ingestion from our offline systems through Trino. This is primarily used to export our marketplace health derived datasets for quick slice and dice in determining marketplace health.</li></ol><p>Moving forward, we will explore merging our real-time pipelines to ingest everything through Kafka for simplified architecture and\u00a0costs.</p><h3>ClickHouse Query Optimizations</h3><h4>Sorting Key</h4><p>The sorting key helps determine how data is physically organized on disk and speeds up query execution times. When data is sorted on particular column(s) frequently used in queries, the database can skip large portions of irrelevant data during query execution. For our time-series based datasets, many of the tables are sorted on event_time (or occurred_at time). This also helps with time-based range queries in the system. Along with reduced I/O due to sequential access of such data, sorting keys strongly help with query performance.</p><p>Choosing the right sorting key can easily be answered based on the type of queries that will run on those datasets.</p><h4>Skip Indices</h4><p>When querying data with filters where the sorting key is not defined, we risk a full scan of each column in order to apply the WHERE clause. To evaluate these non-indexed queries, we make use of Skip indices where ClickHouse uses the index file to understand which blocks of data can be skipped. At Lyft, we primarily have used minmax indices to increase our query performance.</p><pre>ALTER TABLE &lt;database&gt;.&lt;table&gt; ON cluster &lt;cluster&gt; ADD INDEX logged_at_idx (logged_at) TYPE minmax GRANULARITY 8192</pre><p>We then materialize this example index on already existing data. This allows ClickHouse to skip unnecessary data blocks and minimize I/O operations when running the queries, lowering our end-to-end latencies.</p><h4>Projections</h4><p>One of our customer requirements for the migration was to maintain, or lower, the latency. While most of the transpiled ClickHouse queries ran with a faster execution time, our health queries that regularly polled the latest experiment timestamps were much\u00a0slower.</p><p>We utilized the power of ClickHouse projections, specifically creating and materializing the projection SELECT max(occurred_at) to pre-compute and store the latest timestamp. With this projection, only a couple thousand rows are scanned rather than the entire table, speeding up our health checks from ~20 seconds to sub-second.</p><h3>ClickHouse Use Cases and\u00a0Scale</h3><p>Today, we serve the following use cases on ClickHouse:</p><ul><li>Market health</li><li>Policy reporting for bikes &amp;\u00a0scooters</li><li>Spend tracking</li><li>Forecasting and market signaling</li><li>Experimentation</li><li>Campaigns</li></ul><p>At Lyft, we ingest tens of millions of rows and execute millions of read queries in ClickHouse daily with volume continuing to increase. On a monthly basis, this means reading and writing more than 25TB of\u00a0data.</p><h3>Issues Managing ClickHouse</h3><p>While our migration process went smoothly, some pain points arose with our updated\u00a0system:</p><ul><li><strong>Query caching performance</strong>\u2014we have sometimes seen largely variable latencies, making it hard to promise SLAs for certain workloads to customers. Using query cache with appropriate cache size and TTL helps. Initially, when the cache is getting hydrated, the query performance can vary but the latency spikes are very short-lived.</li><li><strong>Kafka issues with MSK integration</strong>\u2014we use Kafka Table Engine extensively, which is a pull-based, native supported ingestion mechanism in ClickHouse. In Kafka Table Engine, the authentication scheme used for SASL is SCRAM-SHA-256 to ingest from in-house Kafka. <em>librdkafka</em> is a C library used by ClickHouse for data ingestion from Kafka. While trying to ingest from Amazon Managed Kafka (AWS MSK) for a new use case, the SASL mechanism <em>AWS_MSK_IAM</em> (AWS\u2019s SASL mechanism) is not supported in librdkafka (Confluent). The solution over here is to try Kafka Connect / MSK Connect, which we will tackle once we upgrade ClickHouse.</li><li><strong>Ingestion pipeline resiliency\u2014</strong>our Flink ingestion into ClickHouse is a push-based model and when ZooKeeper is doing conflict resolutions, it can mark the table as readonly, causing failures in the push model. We will explore a better push-based approach with Kafka Connect into ClickHouse and use Kafka between Flink and ClickHouse to stream the writes and store in Kafka while the Kafka Connect can batch write into ClickHouse.</li></ul><h3>What\u2019s next for ClickHouse at\u00a0Lyft?</h3><p>There are three main areas for expansion when it comes to ClickHouse at\u00a0Lyft:</p><ol><li><strong>Stabilize batch ingestion architecture with streaming Kinesis ingestion through Kafka</strong>\u2014we are working to stabilize our batch ingestion architecture to a more resilient orchestration platform, Apache Airflow, largely used at\u00a0Lyft.</li><li><strong>Move Flink SQL to ClickHouse</strong>\u2014certain Flink transformations can be directly done in destination in ClickHouse. We plan to leverage for multiple new use cases in ClickHouse.</li><li><strong>Retire</strong> <strong>ZooKeeper</strong>\u2014we are currently using Apache ZooKeeper for state management in ClickHouse. We will soon be upgrading ClickHouse and exploring ClickHouse Keeper to reduce external component dependencies.</li></ol><p><strong>Acknowledgements</strong></p><p>A huge Thank You to our stakeholders in Marketplace (Andrew Chan et. al.) and Data (Sarthak Sharma, Akash Katipally et. al.) for their support in enabling a transparent migration, and to our internal ClickHouse customers for their cooperation while we worked to streamline our sub-second infrastructure.</p><p>ClickHouse has been successful as a product for our use cases at Lyft and we are excited for what\u2019s next for\u00a0us!</p><p><em>If you\u2019re interested in working on problems like this in Data, visit Lyft\u2019s </em><a href=\"https://www.lyft.com/careers\"><em>careers page</em></a><em> to see our openings.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=120af37651fd\" width=\"1\" /><hr /><p><a href=\"https://eng.lyft.com/druid-deprecation-and-clickhouse-adoption-at-lyft-120af37651fd\">Druid Deprecation and ClickHouse Adoption at Lyft</a> was originally published in <a href=\"https://eng.lyft.com\">Lyft Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p><em>Written by </em><a href=\"https://www.linkedin.com/in/riteshvaryani/\"><em>Ritesh Varyani</em></a><em> and </em><a href=\"https://www.linkedin.com/in/jeana-choi/\"><em>Jeana Choi</em></a><em> at\u00a0Lyft.</em></p><h3>Introduction</h3><p>At Lyft, we have used systems like ClickHouse and Apache Druid for near real-time and sub-second analytics. Sub-second query systems allow for near real-time data explorations and low latency, high throughput queries, which are particularly well-suited for handling time-series data. For our customers, this means faster analytics on near real-time data and decision making. This is crucial for use cases like market signaling and forecasting which benefit from, and depend upon, the most up-to-date information. Overall, these systems allow us to make timely decisions for the business with accurate predictions.</p><p>In this particular blog post, we explain how Druid has been used at Lyft and what led us to adopt ClickHouse for our sub-second analytic\u00a0system.</p><h3>Druid at\u00a0Lyft</h3><p><a href=\"https://druid.apache.org/\">Apache Druid</a> is an in-memory, columnar, distributed, open-source data store designed for sub-second queries on real-time and historical data. Druid enables low latency (real-time) data ingestion, flexible data exploration and fast data aggregation resulting in sub-second query latencies.</p><p>At Lyft, we started using Druid around six years ago as our first interactive query engine in the sub-second space. Our initial use for Druid was for near real-time geospatial querying and high performance on high-cardinality data sets. It also allowed us to optimize for handling time-series data and event data at\u00a0scale.</p><p>Druid leverages the concept of <em>segments</em>, a unit of storage that allows for parallel querying and columnar storage, complemented with efficient compression and data retrieval.</p><h3>Druid Architecture at\u00a0Lyft</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*T-pN-422J2NBnXAp\" /><figcaption>Druid Architecture at\u00a0Lyft</figcaption></figure><p>With Lyft as a Kubernetes shop, we ran all of the above processes into our stateful and stateless Kubernetes pods within the service namespaces. External dependencies for Druid were managed by our persistence teams and Amazon S3 was utilized for deep storage of our segments.</p><h3>Druid Performance</h3><p>For Druid query performance, we primarily focused on two types of optimization: <em>rollup</em> and <em>compaction</em>.</p><p>1. At Lyft, we used <em>rollup</em> as a data preprocessing technique which aggregates and reduces the granularity of data prior to being stored in segments. Pre-aggregating data at ingestion time helped optimize our query performance and reduce our storage\u00a0costs.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*qzEKj2FCyBDqDBZy\" /><figcaption>An example of how we use Druid rollup at\u00a0Lyft.</figcaption></figure><p>2. <em>Compaction</em> uses batch processing to combine many small, fragmented segments into fewer optimized segments, improving the query performance further.</p><h3>Druid Data Ingestion</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/627/0*6nOUlAOuAX_4wSYM\" /><figcaption>Our pipeline for the two methods of ingesting data into Druid\u2014the upper process is for batch ingestion, the lower process is for real-time ingestion.</figcaption></figure><h4>Real-time Ingestion</h4><p>Events from our real-time analytics pipeline were configured to be sent into our internal Flink application, streamed to Kafka, and written into Druid. This was our main form of ingestion.</p><h4>Batch Ingestion</h4><p>Our batch ingestion pipeline served as a backup ingestion method for backfills and maintenance tasks, specifically:</p><ul><li>Backfills covering for any data loss or downtime in real-time ingestion</li><li>Maintenance tasks such as compaction of\u00a0segments</li></ul><h3>Configuring Ingestion for\u00a0Druid</h3><p>To onboard a use case to Druid, our customers had to make the events streamed to our Flink application with the correct transformations if needed, and define the proto files to serialize and deserialize the data to Kafka to prepare them for ingestion into Druid. Then, they needed to define an ingestion specification which tells Druid how to process the data being ingested.</p><p>A Druid ingestion specification contains the following:</p><ul><li>Datasource schema: name, query / segment granularity, timestamp, dimension, metrics,\u00a0etc.</li><li>ioConfig: Kafka server info, topic names, etc. (ex. tuningConfig)</li></ul><pre>druid: {<br />ioConfig: {<br />taskCount: 3<br />replicas: 2<br />taskDuration: PT15M<br />completionTimeout: PT60M<br />earlyMessageRejectionPeriod: PT2H<br />}<br />tuningConfig: {<br />intermediatePersistPeriod: PT5M,<br />maxRowsPerSegment: 15000000<br />maxRowsInMemory: 500000<br />resetOffsetAutomatically: true<br />}<br />}<br />kafka {<br />partitions: 3<br />}</pre><h4>Druid Use Cases at\u00a0Lyft</h4><p>Druid powered crucial use cases for Lyft, including pricing models and campaigns created and analyzed by our campaigns and communications team. In addition, our experimentation team utilized the datastore to analyze recent experimentation data.</p><h3>Managing Druid and Issues We\u00a0Faced</h3><p>At Lyft, our primary Druid customers were data engineers and software engineers. One of the main barriers we faced for onboarding new customers was the steep ramp-up for writing and maintaining their ingestion specifications, as well as understanding the different tuning mechanisms for each use\u00a0case.</p><p>This involved:</p><ul><li>Ensuring the correct format for data being\u00a0ingested</li><li>Fixing downstream ingestion pipelines for use cases with any upstream\u00a0changes</li><li>Creating specification files for users well-versed in Python/SQL semantics, but not necessarily Druid-specific technologies</li></ul><p>These blockers made it difficult to find more customers and increase adoption. Over time, Druid was under-invested due to lack of ROI, despite the existing and active critical use cases for spend tracking, short-term forecasting, and signaling.</p><p>Around this time, Lyft began to run a lot leaner with different cost-cutting initiatives. For new platform engineers, it presented a steeper learning curve. This lean phase meant we hyper-prioritized and therefore could not quickly upgrade or maintain Druid\u2019s latest performance fixes.</p><p>In addition, when Lyft moved to Kubernetes Compute about three years ago, an extra layer of complexity was introduced, increasing the effort required for the team since multiple Druid clusters were running with many more components in the updated\u00a0system.</p><p>With these factors in mind, we wanted to take a step back and reevaluate our choices to consider if other technologies could be a net positive for\u00a0us.</p><h3>ClickHouse at\u00a0Lyft</h3><h4>What is ClickHouse?</h4><p>ClickHouse is an open-source, column-oriented database for online analytical processing. One of ClickHouse\u2019s standout factors is its high performance\u2014due to a combination of factors such as column-based data storage &amp; processing, data compression, and indexing.</p><h4>Initial Use\u00a0Case</h4><p>In 2020, while the data platform team was managing Druid, the marketplace team considered a new set of requirements:</p><ol><li>Data produced is immediately available for querying in near real-time</li><li>Latencies are sub-second for business dashboarding</li><li>Ingestion for quick slice and dice of datasets. (For example: How many rides in the last 2 hours in the SF\u00a0region?)</li><li>Nested data\u00a0support</li><li>Support for both real-time and batch ingestion</li><li>Native data deduplication at destination</li></ol><p>While the latest version of Druid would provide us with some of these features, such as nested joins (v0.18), other requirements such as deduplication at destination would not be well satisfied. Using our existing stack, we considered performing deduplication at the streaming layer instead of at the destination.</p><p>However, two main reasons prevented us from pursuing this\u00a0idea:</p><ol><li>We would want to perform this at the Destination Storage layer to deduplicate data between the stream and batch\u00a0loads.</li><li>Streaming solutions require setting up a mutability window per entity (ex. 24 hours per ride). This was a hard requirement from the business end due to possible scenarios of updating a past transactional entity already written to storage. This was coupled with the need of the entity to be queryable as soon as possible (at the end of a ride, for example, if not earlier).</li></ol><p>The conclusion was that we should be able to overwrite records as needed using the dedupe facility. With this information at top of mind in 2020, ClickHouse emerged as an option that satisfied the above requirements out of the box and was adopted by the marketplace team.</p><h3>Decision: ClickHouse or\u00a0Druid?</h3><p>ClickHouse gained momentum with our marketplace use cases, leading us to a series of questions\u200a\u2014\u200ashould we expand to other use cases? Can ClickHouse support our Druid use cases? Should we continue to run both systems at Lyft or consolidate into\u00a0one?</p><p>After a careful and deep analysis of cost, infrastructure management, and overall feature benefits, we decided to expand on ClickHouse and sunset Druid, migrating existing Druid use cases to ClickHouse. The following points expand on some benefits we saw with ClickHouse over\u00a0Druid:</p><ol><li><strong>Simplified infrastructure management</strong>\u2014with Lyft\u2019s pivot towards leaner teams and architecture, there was a preference for converging on a system with less management and maintenance requirements. Druid, due to its modular design, turned out to be a more complex system to maintain.</li><li><strong>Reduced learning</strong> <strong>curve</strong>\u2014our users are well versed in Python and SQL semantics compared to Java, etc. With more familiar language and tooling, onboarding their use cases would take less time. For example, defining sorting key and engine type in their object definitions with TTL would be a shorter learning curve compared to defining these as a Druid specification.</li><li><strong>Data deduplication\u2014</strong>covered in the \u201cInitial Use Case\u201d section\u00a0above.</li><li><strong>Cost</strong>\u2014for<strong> </strong>Lyft, as a Kubernetes Compute company, running ClickHouse over Druid would reduce our compute footprint by a large margin. Running much leaner with better TTL definitions at 1/8th of the cost was a big\u00a0plus.</li><li><strong>Specialized</strong> <strong>engines</strong>\u2014Replicated*, Replacing* and Kafka Engine types in ClickHouse allow Lyft to natively manage Kafka pull-based ingestion and also maintain high availability (HA) due to replication across\u00a0nodes.</li></ol><h3>Benchmarking, Performance, and Migration</h3><p>We created a benchmarking test suite, and while still serving queries off of Druid, provisioned our real-time &amp; batch ingestion in ClickHouse, and ran tests in a controlled environment comparing query performance between ClickHouse and\u00a0Druid.</p><p>We involved our stakeholder users in these tests and took queries running in our Druid production system, dynamically transpiled them to ClickHouse syntax, and fired both queries against Druid and ClickHouse respectively. We compared the query latencies and identified bottlenecks in ClickHouse.</p><p>For a couple of our experimentation use cases in ClickHouse, we observed unreliable (spiky, higher) latency performance due to the sorting key of the table and the query resulting in full scans of the table. Since the shape of the query was consistent and the data queried could be pre-aggregated, adding <em>projections</em> in ClickHouse helped.</p><p>Projections are essentially precomputed views of your data, which compute only on the columns needed and rather than running a full table scan, ClickHouse just scans the projection column. In addition to improving the query performance for the couple experimentation use cases, projections helped reduce our I/O as\u00a0well.</p><p>We measured correctness (by row counts returned and the diff of exact table results) and latency, and used a tiered migration serving 1%, 5%, 10%, 20%, 50% and then 100% from ClickHouse. We eventually also realized latency gains which is discussed in later sections.</p><p>Overall, our migration experience went smoothly. Use cases for campaigns, experimentation, forecasting, and spend tracking underwent this migration process. We communicated with customer teams and ensured correct read query translations from Druid to ClickHouse, as well as running the above benchmarking tests and performance analysis. Throughout the process, we worked on some query optimizations (see the\u201cClickHouse Query Optimizations\u201d section below) for certain scenarios where the latency was higher than\u00a0desired.</p><h3>ClickHouse Architecture at\u00a0Lyft</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*HTmFoNbQd-zFGNIZ\" /><figcaption>Current ClickHouse Architecture at\u00a0Lyft</figcaption></figure><p>We use <a href=\"https://github.com/Altinity/clickhouse-operator\">Altinity\u2019s Kubernetes Operator</a> to deploy the ClickHouse clusters. Currently, we run the 21.7 version of ClickHouse and have plans to upgrade to the latest version. The storage which we use are co-located EBS volumes in our stateful Kubernetes cluster. We run our clusters in HA mode with general-purpose AWS M5-type compute instances with our database objects being replicated across nodes. We do not use sharding on our clusters currently but there are plans to optimize the cluster performance as we scale\u00a0more.</p><p>ClickHouse data ingestion is discussed in detail below. ClickHouse read querying is served through our internal Proxy with ACLs and visualization tools such as\u00a0Mode.</p><h3>ClickHouse Data Ingestion</h3><p>For our ClickHouse infrastructure, we handle ingestion through three separate pipelines.</p><ol><li><strong>Kafka \u2192 ClickHouse: </strong>this is primarily used by our services which rely on a pub-sub model. ClickHouse is one of the subscribers to this data. There is native support in ClickHouse for the KafkaTableEngine, which uses a pull-based mechanism to read from Kafka cluster topics. We ingest up to 2 billion records per day into ClickHouse from Kafka-based ingestion.</li><li><strong>Kinesis \u2192 Flink \u2192 ClickHouse</strong>: this ingestion scheme populates our events data in ClickHouse. Events teams, who need their data in ClickHouse for analytics, onboard through this ingestion mechanism. Lyft generates about 600 million rows per day from Flink ingestion alone, in ClickHouse.</li><li><strong>Trino \u2192 Cron \u2192 ClickHouse: </strong>we also support batch ingestion from our offline systems through Trino. This is primarily used to export our marketplace health derived datasets for quick slice and dice in determining marketplace health.</li></ol><p>Moving forward, we will explore merging our real-time pipelines to ingest everything through Kafka for simplified architecture and\u00a0costs.</p><h3>ClickHouse Query Optimizations</h3><h4>Sorting Key</h4><p>The sorting key helps determine how data is physically organized on disk and speeds up query execution times. When data is sorted on particular column(s) frequently used in queries, the database can skip large portions of irrelevant data during query execution. For our time-series based datasets, many of the tables are sorted on event_time (or occurred_at time). This also helps with time-based range queries in the system. Along with reduced I/O due to sequential access of such data, sorting keys strongly help with query performance.</p><p>Choosing the right sorting key can easily be answered based on the type of queries that will run on those datasets.</p><h4>Skip Indices</h4><p>When querying data with filters where the sorting key is not defined, we risk a full scan of each column in order to apply the WHERE clause. To evaluate these non-indexed queries, we make use of Skip indices where ClickHouse uses the index file to understand which blocks of data can be skipped. At Lyft, we primarily have used minmax indices to increase our query performance.</p><pre>ALTER TABLE &lt;database&gt;.&lt;table&gt; ON cluster &lt;cluster&gt; ADD INDEX logged_at_idx (logged_at) TYPE minmax GRANULARITY 8192</pre><p>We then materialize this example index on already existing data. This allows ClickHouse to skip unnecessary data blocks and minimize I/O operations when running the queries, lowering our end-to-end latencies.</p><h4>Projections</h4><p>One of our customer requirements for the migration was to maintain, or lower, the latency. While most of the transpiled ClickHouse queries ran with a faster execution time, our health queries that regularly polled the latest experiment timestamps were much\u00a0slower.</p><p>We utilized the power of ClickHouse projections, specifically creating and materializing the projection SELECT max(occurred_at) to pre-compute and store the latest timestamp. With this projection, only a couple thousand rows are scanned rather than the entire table, speeding up our health checks from ~20 seconds to sub-second.</p><h3>ClickHouse Use Cases and\u00a0Scale</h3><p>Today, we serve the following use cases on ClickHouse:</p><ul><li>Market health</li><li>Policy reporting for bikes &amp;\u00a0scooters</li><li>Spend tracking</li><li>Forecasting and market signaling</li><li>Experimentation</li><li>Campaigns</li></ul><p>At Lyft, we ingest tens of millions of rows and execute millions of read queries in ClickHouse daily with volume continuing to increase. On a monthly basis, this means reading and writing more than 25TB of\u00a0data.</p><h3>Issues Managing ClickHouse</h3><p>While our migration process went smoothly, some pain points arose with our updated\u00a0system:</p><ul><li><strong>Query caching performance</strong>\u2014we have sometimes seen largely variable latencies, making it hard to promise SLAs for certain workloads to customers. Using query cache with appropriate cache size and TTL helps. Initially, when the cache is getting hydrated, the query performance can vary but the latency spikes are very short-lived.</li><li><strong>Kafka issues with MSK integration</strong>\u2014we use Kafka Table Engine extensively, which is a pull-based, native supported ingestion mechanism in ClickHouse. In Kafka Table Engine, the authentication scheme used for SASL is SCRAM-SHA-256 to ingest from in-house Kafka. <em>librdkafka</em> is a C library used by ClickHouse for data ingestion from Kafka. While trying to ingest from Amazon Managed Kafka (AWS MSK) for a new use case, the SASL mechanism <em>AWS_MSK_IAM</em> (AWS\u2019s SASL mechanism) is not supported in librdkafka (Confluent). The solution over here is to try Kafka Connect / MSK Connect, which we will tackle once we upgrade ClickHouse.</li><li><strong>Ingestion pipeline resiliency\u2014</strong>our Flink ingestion into ClickHouse is a push-based model and when ZooKeeper is doing conflict resolutions, it can mark the table as readonly, causing failures in the push model. We will explore a better push-based approach with Kafka Connect into ClickHouse and use Kafka between Flink and ClickHouse to stream the writes and store in Kafka while the Kafka Connect can batch write into ClickHouse.</li></ul><h3>What\u2019s next for ClickHouse at\u00a0Lyft?</h3><p>There are three main areas for expansion when it comes to ClickHouse at\u00a0Lyft:</p><ol><li><strong>Stabilize batch ingestion architecture with streaming Kinesis ingestion through Kafka</strong>\u2014we are working to stabilize our batch ingestion architecture to a more resilient orchestration platform, Apache Airflow, largely used at\u00a0Lyft.</li><li><strong>Move Flink SQL to ClickHouse</strong>\u2014certain Flink transformations can be directly done in destination in ClickHouse. We plan to leverage for multiple new use cases in ClickHouse.</li><li><strong>Retire</strong> <strong>ZooKeeper</strong>\u2014we are currently using Apache ZooKeeper for state management in ClickHouse. We will soon be upgrading ClickHouse and exploring ClickHouse Keeper to reduce external component dependencies.</li></ol><p><strong>Acknowledgements</strong></p><p>A huge Thank You to our stakeholders in Marketplace (Andrew Chan et. al.) and Data (Sarthak Sharma, Akash Katipally et. al.) for their support in enabling a transparent migration, and to our internal ClickHouse customers for their cooperation while we worked to streamline our sub-second infrastructure.</p><p>ClickHouse has been successful as a product for our use cases at Lyft and we are excited for what\u2019s next for\u00a0us!</p><p><em>If you\u2019re interested in working on problems like this in Data, visit Lyft\u2019s </em><a href=\"https://www.lyft.com/careers\"><em>careers page</em></a><em> to see our openings.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=120af37651fd\" width=\"1\" /><hr /><p><a href=\"https://eng.lyft.com/druid-deprecation-and-clickhouse-adoption-at-lyft-120af37651fd\">Druid Deprecation and ClickHouse Adoption at Lyft</a> was originally published in <a href=\"https://eng.lyft.com\">Lyft Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "GitHub": {
    "title": "How we organize and get things done with SERVICEOWNERS",
    "xmlUrl": "https://githubengineering.com/atom.xml",
    "htmlUrl": "https://githubengineering.com/",
    "authors": [
      {
        "name": "Max Beizer"
      }
    ],
    "author_detail": {
      "name": "Max Beizer"
    },
    "author": "Max Beizer",
    "title_detail": {
      "type": "text/html",
      "language": "en-US",
      "base": "https://github.blog/engineering.atom",
      "value": "How we organize and get things done with SERVICEOWNERS"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/"
      }
    ],
    "link": "https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/",
    "id": "https://github.blog/?p=75858",
    "guidislink": false,
    "updated": "2023-12-19T18:37:22Z",
    "updated_parsed": [
      2023,
      12,
      19,
      18,
      37,
      22,
      1,
      353,
      0
    ],
    "published": "2023-12-19T18:00:08Z",
    "published_parsed": [
      2023,
      12,
      19,
      18,
      0,
      8,
      1,
      353,
      0
    ],
    "tags": [
      {
        "term": "Engineering",
        "scheme": "https://github.blog/category/engineering/",
        "label": null
      },
      {
        "term": "CODEOWNERS",
        "scheme": "https://github.blog/category/engineering/",
        "label": null
      },
      {
        "term": "How GitHub builds GitHub",
        "scheme": "https://github.blog/category/engineering/",
        "label": null
      },
      {
        "term": "Ruby on Rails",
        "scheme": "https://github.blog/category/engineering/",
        "label": null
      },
      {
        "term": "service-oriented architecture",
        "scheme": "https://github.blog/category/engineering/",
        "label": null
      }
    ],
    "summary": "<p>Take CODEOWNERS and GitHub teams to the next level. Learn about how GitHub engineering solves the age old problem of who owns what.</p>\n<p>The post <a href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/\">How we organize and get things done with SERVICEOWNERS</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": "en-US",
      "base": "https://github.blog/engineering.atom",
      "value": "<p>Take CODEOWNERS and GitHub teams to the next level. Learn about how GitHub engineering solves the age old problem of who owns what.</p>\n<p>The post <a href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/\">How we organize and get things done with SERVICEOWNERS</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": "en-US",
        "base": "https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/",
        "value": "<p>GitHub&rsquo;s primary codebase is <a href=\"https://github.blog/2023-04-06-building-github-with-ruby-and-rails/\">a large Ruby on Rails monolith</a> with over 4.2 million lines of code across roughly 30,000 files. As the platform has grown over the years, we have come to realize that we need a new way to organize and think about the systems we run. Our traditional approach to organizing Hubbers and code has been through <a href=\"https://docs.github.com/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-code-owners\">CODEOWNERS</a> in combination with GitHub teams, organizations, issues, and repositories. However, as GitHub&rsquo;s user base continues to grow, we have discovered we need a new layer of abstraction. This is where SERVICEOWNERS comes in.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Service-oriented_architecture\">Service-oriented architecture</a> is not new, but we do not talk often about how large engineering teams organize around services&ndash;especially in a hybrid monolith/services architecture. GitHub engineering determined that we were missing a layer in between CODEOWNERS, how we group humans, and work to be done. Injecting a &ldquo;service&rdquo; layer between groups of functionality and the people maintaining them opens up a number of interesting possibilities.</p>\n<p class=\"purple-text text-gradient-purple-coral mt-6 mb-6\">One side-effect of adopting SERVICEOWNERS was realizing that the &ldquo;ownership&rdquo; model does not quite express how we work. Given our place in the open source ecosystem and what we value as a company, we thought the &ldquo;maintainer&rdquo; model more accurately describes the relationships between services and teams. So, no team &ldquo;owns&rdquo; anything, but instead they &ldquo;maintain&rdquo; various services.</p>\n<h2 id=\"consistent-company-wide-grouping\">Consistent, company-wide grouping<a class=\"heading-link pl-2 text-italic text-bold\" href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/#consistent-company-wide-grouping\"></a></h2>\n<p>Achieving consistency in how we map running code&ndash;both within and without our monolith&ndash;to humans has had a number of positive outcomes. It promotes a shared lexicon, and, therefore, a shared understanding. The durability of services reduces the disruption of team reorganization. As priorities shift, services stay the same and require only minimal updates to yaml metadata to be accurate. Consistency in our service definitions also allows us to centralize information about the services we run into a service catalog. Our service catalog is the one-stop shop for up-to-date information on the services that power GitHub. Within the catalog, Hubbers of all stripes can find information on, for example, how a service is performing vis-a-vis an <a href=\"https://en.wikipedia.org/wiki/Service-level_objective\">SLO</a>. Each service in the service catalog also has a number of scorecards as part of our fundamentals program.</p>\n<p>With clearly defined services collected in a service catalog, we can easily visualize the relationships between services. We can identify dependencies and map how information flows through the platform. All this information improves the onboarding experience for new engineers, too, as the relationships between services define the platform architecture&mdash;without having to rely on out-of-date docs or hand-waving to explain our architecture.</p>\n<p>The service catalog also has the huge benefit of centralizing information about which teams maintain which services, how to reach an on-call engineer, and what expectations the service has set in terms of support SLAs. Clean lines of communication to maintainers of running services has been a huge help in reducing our incident remediation time. Incident commanders know how to contact on-call engineers because they can find it in the service catalog. All of this is only possible thanks to <code>SERVICEOWNERS</code>.</p>\n<h2 id=\"how-it-works\">How it works<a class=\"heading-link pl-2 text-italic text-bold\" href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/#how-it-works\"></a></h2>\n<p><img alt=\"a diagram depicting the connections between the GitHub monolith, the service catalog, repositories, and teams.\" class=\"aligncenter size-large wp-image-75862 width-fit\" height=\"378\" src=\"https://github.blog/wp-content/uploads/2023/12/serviceowners-with-connections.png?w=1024&#038;resize=1024%2C378\" width=\"1024\" /></p>\n<h3 id=\"the-serviceowners-file\">The <code>SERVICEOWNERS</code> file<a class=\"heading-link pl-2 text-italic text-bold\" href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/#the-serviceowners-file\"></a></h3>\n<p>A <code>SERVICEOWNERS</code> file lives next to the <code>CODEOWNERS</code> file within our monolith. Like a traditional <code>CODEOWNERS</code> file, <code>SERVICEOWNERS</code> consists of a series of glob patterns (for example, <code>app/api/integration*</code>), directory names (for example, <code>config/access_control/</code>) and filenames (for example, <code>app/api/grants.rb</code>) followed by a service name (for example <code>:apps</code> maps to the team <code>github/apps</code>). Our CI enforces rules like:</p>\n<ul>\n<li>There can be no duplicate patterns/directories/files in <code>SERVICEOWNERS</code>.</li>\n<li>All new files added to the github/github repository must have a service owner.  </li>\n<li>All patterns/directories/files must match at least one existing file.</li>\n<li>Files matched by multiple glob patterns must be disambiguated by a file or directory definition.</li>\n</ul>\n<h3 id=\"the-service-mappings-yaml-file\">The <code>service-mappings.yaml</code> file<a class=\"heading-link pl-2 text-italic text-bold\" href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/#the-service-mappings-yaml-file\"></a></h3>\n<p>A <code>service-mappings</code> file defines how services referenced in the <code>SERVICEOWNERS</code> file relate to services in the service catalog and GitHub teams. This configuration can define a service&rsquo;s product manager, engineering manager, repository, and chat information. Service mappings can also define information about a service&rsquo;s various classifications, such as its &ldquo;tier&rdquo; rating, with zero being critical to the GitHub platform and three being experimental/non-critical.</p>\n<h3 id=\"the-serviceowners-gem\">The <code>serviceowners</code> gem<a class=\"heading-link pl-2 text-italic text-bold\" href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/#the-serviceowners-gem\"></a></h3>\n<p>We have developed a Ruby gem we integrate with our Rails app that combines data from the <code>SERVICEOWNERS</code> and <code>service-mappings</code> files to produce several types of output. The <code>serviceowners</code> gem generates our <code>CODEOWNERS</code> file. So, instead of manually updating <code>CODEOWNERS</code>, changing which team or teams maintain a service is a one-line YAML change. The <code>serviceowners</code> gem also has an executable which allows engineers to query information about the maintainer of a file or which files a service maintains.</p>\n<p>Because it&rsquo;s GitHub, there&rsquo;s of course also <a href=\"https://github.blog/2020-10-22-devops-best-practices-qa-automated-deployments-at-github/\">a chat-op</a> for that:</p>\n<blockquote><p>\n  <strong>me</strong>: hubot serviceowners for test/jobs/do_the_thing_with_the_stuff_test.rb</p>\n<p>  <strong>hubot</strong>: The file <code>test/jobs/do_the_thing_with_the_stuff_test.rb</code> is part of the <code>github/some_service service</code> and is maintained by the <code>cool-fun-team</code> team who can be reached in #hijinx.\n</p></blockquote>\n<h3 id=\"the-ownership-yaml-file\">The <code>ownership.yaml</code> file<a class=\"heading-link pl-2 text-italic text-bold\" href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/#the-ownership-yaml-file\"></a></h3>\n<p>The above examples mostly focus on breaking up the monolith into services, but our service catalog can slurp up service information from any repository within the GitHub org that has an <code>ownership.yaml</code> file. Like the <code>service-mappings</code> file, <code>ownership</code> expresses version controlled values for various service metadata. This allows us to have the boundaries of a service span across multiple repositories; for example, the GitHub Desktop app can have a component service within the monolith while also having its own standalone artifact from a different repository. Another benefit of the <code>ownership</code> file is that it allows us to focus code changes to the monolith codebase primarily around functionality and not maintainership.</p>\n<h2 id=\"conclusion\">Conclusion<a class=\"heading-link pl-2 text-italic text-bold\" href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/#conclusion\"></a></h2>\n<p>The combination of CODEOWNERS and SERVICEOWNERS has provided serious value for us at GitHub. The tooling we continue to build atop these primitives will serve to make maintaining services clearer and easier. That&rsquo;s good news for the future of GitHub. It also pairs quite nicely with our open source identity and access management project, <a href=\"https://github.blog/2022-06-09-introducing-entitlements-githubs-open-source-identity-and-access-management-solution/\">entitlements</a>, too. If SERVICEOWNERS sounds like something your organization, open source or corporate alike, would benefit from, let us know on X at @<a href=\"https://twitter.com/github\">github</a>.</p>\n\n<p>The post <a href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/\">How we organize and get things done with SERVICEOWNERS</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>"
      }
    ]
  },
  "UpGrad": {
    "title": "Web Performance and Related Stories\u200a\u2014\u200aupgrad.com",
    "xmlUrl": "https://engineering.upgrad.com/feed",
    "htmlUrl": "https://engineering.upgrad.com",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.upgrad.com/feed",
      "value": "Web Performance and Related Stories\u200a\u2014\u200aupgrad.com"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.upgrad.com/web-performance-and-related-stories-upgrad-com-a9fb9c6bb766?source=rss----c08812b771e6---4"
      }
    ],
    "link": "https://engineering.upgrad.com/web-performance-and-related-stories-upgrad-com-a9fb9c6bb766?source=rss----c08812b771e6---4",
    "id": "https://medium.com/p/a9fb9c6bb766",
    "guidislink": false,
    "tags": [
      {
        "term": "performance",
        "scheme": null,
        "label": null
      },
      {
        "term": "nuxtjs",
        "scheme": null,
        "label": null
      },
      {
        "term": "upgrad",
        "scheme": null,
        "label": null
      },
      {
        "term": "lighthouse",
        "scheme": null,
        "label": null
      },
      {
        "term": "web-performance",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Mohit Karekar"
      }
    ],
    "author": "Mohit Karekar",
    "author_detail": {
      "name": "Mohit Karekar"
    },
    "published": "Fri, 11 Jun 2021 06:37:45 GMT",
    "published_parsed": [
      2021,
      6,
      11,
      6,
      37,
      45,
      4,
      162,
      0
    ],
    "updated": "2021-06-15T16:46:26.837Z",
    "updated_parsed": [
      2021,
      6,
      15,
      16,
      46,
      26,
      1,
      166,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.upgrad.com/feed",
        "value": "<h3>Web Performance and Related Stories\u200a\u2014\u200aupgrad.com</h3><p><em>The story and learnings from improving upgrad.com\u2019s (a Nuxt.js SSR application) Lighthouse performance scores from 17 to\u00a065</em></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QBnDE4-Mu_jnLSP8Z2lcQQ.png\" /></figure><p>In the month of January 2021 we, at upGrad, looked at our website\u2019s page speed scores and accepted the fact that they demanded considerable improvement. Lighthouse is a popular and extremely useful tool to measure web performance, and well, the scores for upgrad.com were barely crossing two-digit values. The situation wasn\u2019t great, but personally it was exciting for me because it presented a live problem to be solved, and this post is about the journey through the rough seas of web performance.</p><blockquote><strong>tl;dr<br /></strong><em>We were successful in improving our website performance in terms of the Lighthouse scores going from about </em><strong>5 and 15 to around 50 and 70</strong><em> on mobile and desktop respectively. I hope these numbers will encourage you to read the entire post, but I\u2019ll also try to make it interesting in general to read. See you until the\u00a0end!</em></blockquote><p>I consider this domain of web-development to carry a large importance for both\u200a\u2014\u200a<em>the developer working on the website/application, and the business/person owning the product</em>. The situation\u2019s better when you play both of these roles, let\u2019s say when you launch your side project. Web performance is an area which is interesting to work on as a tech person, as well as has direct impact on the business side of things. If you\u2019ve run your Lighthouse tests quite often (it is time to automate them), you might have seen these facts being\u00a0shown.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kWQI5aVwIa717hUT1sBtUQ.png\" /></figure><p><a href=\"https://web.dev/why-speed-matters/\"><strong>Speed does matter</strong></a>. As users of the internet ourselves, we know how frustrating it is to wait for a page to load. I sometimes empathize web developers of certain websites if they load slowly, and wait for a few more seconds. Unfortunately, real world users won\u2019t do that. As everything is becoming more and more instant, giving the best experience on the web is one of the core responsibilities of a web developer.</p><h3>The January of\u00a02021</h3><p>I do not want to sound poetic, but let\u2019s go back to the January of 2021. The growth team at upGrad had worked on a crucial project this month\u200a\u2014\u200athe separation of authentication logic from the website, and integrating a mobile OTP-based login+signup flow. It was an interesting project and Akshay (my teammate) is soon coming up with an article about it. But given that, now the upgrad.com website consisted only of representational content. In an ideal world, the website <em>could</em> have been built with plain HTML &amp; CSS, but having a framework like Nuxt.js gives us a lot of benefits in terms of operability and dynamism, given that we have an in-house CMS and\u00a0editors.</p><p>Anyway, the Lighthouse scores for the website were as follows (for desktop):</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*okRn0e4T_SrYXqFHgeB8-w.png\" /></figure><p>A 17 for desktop usually means your mobile scores sit somewhere lower, around 8\u201310. Things to note in the above screenshot are the values for the web vitals, <strong>most of them in red</strong>. Lighthouse considers these values to be important denoting factors about how your website loads and how it is perceived by the users. Let\u2019s take a short detour into how a browser loads a page, the web vitals then would be much clearer on the\u00a0way.</p><h3>Journey of a\u00a0page</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*cfQpu6Xvb7e9IiH4CCuiCg.png\" /><figcaption>Source: <a href=\"https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/\">https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/</a></figcaption></figure><p>A browser usually goes through the above flow whenever it receives its first chunk of HTML from the server. HTML is a special language, <strong><em>it is forgiving</em></strong>. And hence its parsing is special too. To go a bit into details, HTML does not have a Context-Free Grammar, as most of the languages would have. This grammar tells what is valid and what is invalid in a language. In HTML, the browser usually corrects if some parts are erroneous. In addition to this, HTML can change while parsing is still happening! JavaScript can inject HTML into the page using document.write() and because of this HTML parsing is called <em>re-entrant</em>.</p><p>If we consider a short example page\u2019s\u00a0HTML</p><h4>Scenario 1</h4><pre>&lt;html&gt;<br />    &lt;body&gt;<br />        &lt;h1&gt;Hello&lt;/h1&gt;<br />    &lt;/body&gt;<br />&lt;/html&gt;</pre><p>Here, the parser will start from the top and go on identifying corresponding nodes. It will find open html -&gt; open body -&gt; open h1 -&gt; text Hello -&gt; close h1 -&gt; close body -&gt; close html. At the end of the parsing you\u2019d generally have a syntax tree which will mirror a corresponding DOM tree. The object would be the one which will be exposed to JavaScript inside document.</p><p>Essentially, the DOM tree would be constructed, laying out would be done and then the bitmap would be painted on the screen. Super\u00a0optimal.</p><h4>Scenario 2</h4><pre>&lt;html&gt;<br />    &lt;head&gt;<br />        &lt;link <em>rel</em>=&quot;stylesheet&quot; <em>href</em>=&quot;/main.css&quot; /&gt;<br />    &lt;/head&gt;<br />    &lt;body&gt;<br />        &lt;h1&gt;Hello&lt;/h1&gt;<br />    &lt;/body&gt;<br />&lt;/html&gt;</pre><p>Let\u2019s consider this example which adds a remote CSS stylesheet to the page. Any form of <strong>CSS on the page is render-blocking</strong>. It means that until all the CSS isn\u2019t parsed, the renderer won\u2019t paint the page\u200a\u2014\u200aremember from the above flow diagram that the render tree construction requires the CSS tree to be\u00a0ready.</p><p>Hence in this example, the DOM tree would be constructed, but the rendering would not happen until the CSS file is loaded and parsed completely. A bit less\u00a0optimal.</p><h4>Scenario 3</h4><pre>&lt;html&gt;<br />    &lt;head&gt;<br />        &lt;link <em>rel</em>=&quot;stylesheet&quot; <em>href</em>=&quot;/main.css&quot; /&gt;<br />        &lt;script&gt;console.log('Hello from JavaScript!');&lt;/script<br />    &lt;/head&gt;<br />    &lt;body&gt;<br />        &lt;h1&gt;Hello&lt;/h1&gt;<br />    &lt;/body&gt;<br />&lt;/html&gt;</pre><p>Let\u2019s add a &lt;script&gt; tag to the head. Any form of <strong>JavaScript on the page is usually parser-blocking</strong>. The HTML parsing is blocked until the script is executed\u200a\u2014\u200athis is again because JS has the potential to modify the DOM, so the browser wouldn\u2019t want to proceed and later get to know that the code it had parsed was stale. You can think how this might get affected if you have remote JavaScript files, which is usually the case. The files would first have to be downloaded and then executed for the parser to move ahead. Very un-optimal.</p><p>Mozilla Developer Network documentation as well as Google\u2019s web.dev articles explain this in great detail. You might want to look into\u00a0those.</p><p>The crux of the detour above was to discuss what could potentially hinder our website from being loaded/visible to the users. From the discussion we can take two key\u00a0points:</p><ul><li>CSS is render-blocking</li><li>JavaScript is parser-blocking</li></ul><p>These two points form a base to a large number of optimizations that one can perform to speed up their website. The core web vitals also get affected due to\u00a0these.</p><p>Sourced directly from <a href=\"https://web.dev:\">https://web.dev:</a></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5V9pbAoFLzNJYA2uRK0bKw.png\" /></figure><p>Anything render-blocking will worsen LCP. Anything process heavy on page load will worsen FID, e.g. synchronous JavaScript execution on main thread. Anything writing to the document and hence drastically changing the page layout will worsen\u00a0CLS.</p><p>For the initial phases our target was reducing LCP. Additional reading:</p><p><a href=\"https://developers.google.com/web/fundamentals/performance/get-started\">Overview | Web Fundamentals | Google Developers</a></p><h3>Identifying Areas of Improvement &amp;\u00a0Budgets</h3><p>To tackle the problem of performance, usually one can look internally first (quite philosophical). Before performing a complex change in your system, one must try to find areas to improve in the existing setup. It is quite probable that there would be a lot to clean up and optimize. At least that was the case with\u00a0us.</p><p>But before beginning any work, how would you know what to pick and how that change would impact the performance? Enter performance analysis tools. There are numerous tools available online that help you know exactly where the bottleneck is. Lighthouse is one of such tools but I believe it should be used to benchmark the final score. There is another online tool called <a href=\"https://webpagetest.org/\"><strong>WebPageTest</strong></a> that gives you detailed report of your website\u2019s performance under various scenarios. I personally found is very useful to identify individual problems.</p><p>Following is a screenshot from webpagetest.org:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*y5MJRobxWlYjTqITVKp2EQ.png\" /></figure><p>The above report gives a detailed view of what is happening on the page\u200a\u2014\u200afrom the vitals to the waterfall view and the vitals marked on it. It was particularly helpful to map what was delaying certain metrics and then target those resources specifically.</p><h4>Budgeting</h4><p>This is a debatable topic but everyone can have their own preferred ways of budgeting your optimizations. This helps us maintain a threshold for either metrics or the experience that we want to provide to our users. I\u2019ll keep this section short and link to useful resources online:</p><ul><li><a href=\"https://web.dev/defining-core-web-vitals-thresholds/\">https://web.dev/defining-core-web-vitals-thresholds/</a></li><li><a href=\"https://csswizardry.com/2020/01/performance-budgets-pragmatically/\">https://csswizardry.com/2020/01/performance-budgets-pragmatically/</a></li></ul><p>We began with some obvious areas that we could target\u200a\u2014\u200asomething that we knew already but could not find time to fix. These included some unused scripts and some modules that were being loaded globally when we could load them locally. In Nuxt, you can define global plugins that get included in the main bundle\u200a\u2014\u200aoften a bad practice if not monitored properly. So in short, here are a few key areas that can be targeted:</p><h4>Lazy-load Everything Unnecessary</h4><p><strong><em>Impact\u200a\u2014\u200aTime To Interactive (TTI), First Contentful Paint\u00a0(FCP)</em></strong></p><p>You <em>must</em> defer/lazily-load everything that is not crucial for your first load and does not contribute to SEO. This includes modals, non-critical scripts, images, stylesheets and chunks of your application.</p><p>For our website, we saw a considerable difference when we lazy-loaded all our modal content. Since it was a separated module in itself, we could do this easily. Most of the frameworks have special syntax for lazy-loading components, e.g. React.lazy() in React and the import() syntax in Vue. Bundlers provide automatic code-splitting based on this syntax so that your chunks are separate and are only loaded when requested for.</p><p>Since Nuxt uses webpack, we could use <strong>webpack\u2019s magic comments</strong> that allow you to define loading behaviours on chunks. /* webpackPrefetch: true */ is one such useful comment that pre-fetches the chunk so that the experience is similar to loading it synchronously.</p><p><strong>Image lazy-loading</strong> is core to faster websites and usually is already implemented. But if it isn\u2019t then you should do it right away. There are popular libraries that allow this and now there\u2019s also a native way of doing it in HTML, though it isn\u2019t supported in all browsers.</p><p>The standard way of telling the browsers to defer loading a script, or load them asynchronously is by using the defer and async keywords correctly. <strong>defer moves the processing of a script to the end of parsing step</strong>. The script is fetched in the background and in parallel if many. This solves the issue mentioned in \u2018Scenario 3\u2019 above. That is also why usually it is recommended to keep your script tags at the end of the body. This helps in two ways\u200a\u2014\u200ait allows the script to \u2018see\u2019 the entire body of the page at it was built before the parser reached the script tag, and second that the parses did not get blocked on the script somewhere at the beginning of the\u00a0page.</p><p>async helps in a similar way but instead of loading the scripts in the end, <strong>they are loaded and even processed asynchronously</strong>. These won\u2019t wait for the DOM tree being built, but get executed as soon as they complete loading. A key difference between async and defer is that all scripts loaded with defer will block the DOMContentLoaded event while those loaded with async would\u00a0not.</p><p>Another useful thing that can be leveraged off of frameworks is the <strong>dynamic loading of scripts</strong>. Keeping the core idea in mind\u200a\u2014\u200a<em>load only those resources that are required to build the page\u200a</em>\u2014\u200awe can dynamically push &lt;script&gt; tags in our website\u2019s head. This allows, e.g. loading the YouTube player script only on pages that actually display a video, ensuring that does not slow down a page that does not have a video at\u00a0all.</p><h4>Limit Critical Resources\u200a\u2014\u200aShorten the Critical Rendering Path</h4><p><strong><em>Impact\u200a\u2014\u200aFirst Contentful Paint (FCP), Largest Contentful Paint\u00a0(LCP)</em></strong></p><p><strong>Critical rendering path</strong> (CRP) is the journey of a page being rendered in a browser from the point when the browser receives the first bytes of the response (HTML) to when the page starts becoming visible. Our aim should be to keep this as short as possible. As resources get added to this path, the time to start painting goes on increasing, hampering the page load experience.</p><p>CRP depends on the way your HTML document is parsed. If it is only static HTML, you would have a great LCP score. But practically, there are a lot of resources that usually get added on a HTML page, that are at times crucial for the website to behave properly. If these resources are required for your page to render, then they contribute to CRP. The parser has to do the work of loading and executing them and then continue to parse the page and then finally the renderer to take\u00a0over.</p><p>Good resources:</p><p><a href=\"https://developers.google.com/web/fundamentals/performance/critical-rendering-path/\">Critical Rendering Path | Web Fundamentals | Google Developers</a></p><p>For us, it was about looking at the waterfall snapshot from webpagetest and see what was delaying the first render. Upon checking, we could find that a particular CSS file was being loaded critically and to worsen the problem, it wasn\u2019t being served via a\u00a0CDN.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3iaZ8Cc33EkYklqpqqiXkQ.png\" /></figure><p>Finding such resources and unblocking them helped us improve our start render times by a good number\u200a\u2014<strong><em>\u200aold one being at 4.2 seconds, improved to 0.4\u00a0seconds.</em></strong></p><p>The initial HTML response of your page must contain only the critical CSS\u200a\u2014\u200aCSS required for your page to be properly styled. All others can be lazily loaded. One popular way to <strong>asynchronously load CSS</strong> is using the media attribute of link\u00a0tag.</p><pre>&lt;link<br />    <em>rel</em>=&quot;stylesheet&quot;<br />    <em>href</em>=&quot;/link/to/file.css&quot;<br />    <em>media</em>=&quot;print&quot;<br />    <em>onload</em>='<em>this</em>.media=&quot;all&quot;,<em>this</em>.onload=null'<br />/&gt;</pre><p>Here, since the media value is \u2018print\u2019, the HTML parser in a browser would skip waiting on this stylesheet and move ahead. The stylesheet will still load in the background, and whenever it does, it will get parsed. This prevents blocking of the parser at the CSS link tag and is good for stylesheets that aren\u2019t required at the time of first\u00a0load.</p><p>Even with the above solution, we must ensure that the critical CSS is lean. Tools like <a href=\"https://purgecss.com/\"><strong>PurgeCSS</strong></a> help in automating this by cleaning out the styles that are unused on the page by going over the HTML of the finally generated page.</p><h4>Preloading Critical\u00a0Assets</h4><p><strong><em>Impact\u200a\u2014\u200aLargest Contentful Paint\u00a0(LCP)</em></strong></p><p>One other important practice is to <strong>preload all your critical resources</strong>. If your website has an image in the first fold, you must preload it so that it is visually available as soon as possible.</p><p>One can use the preload keyword to do this and many bundlers do this automatically for\u00a0you.</p><pre>&lt;link <em>rel</em>=&quot;preload&quot; <em>as</em>=&quot;image&quot; <em>href</em>=&quot;banner-image.webp&quot; /&gt;</pre><p>More on preload\u00a0here:</p><p><a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Link_types/preload\">Link types: preload - HTML: HyperText Markup Language | MDN</a></p><p>Applying these practices brought down our LCP largely\u200a\u2014\u200a<strong><em>from 3.9 seconds to 0.9\u00a0seconds.</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*as8e_vFbraac5kzl3WcIEw.png\" /></figure><p>Google\u2019s web.dev sums up the above points in a very good way\u200a\u2014\u200ait introduces the <strong>PRPL\u00a0pattern</strong>.</p><ul><li>P\u200a\u2014\u200aPush (or preload) the most important resources.</li><li>R\u200a\u2014\u200aRender the initial route as soon as possible.</li><li>P\u200a\u2014\u200aPre-cache remaining assets.</li><li>L\u200a\u2014\u200aLazy load other routes and non-critical assets.</li></ul><p>Apart from pre-caching, I think I talked about the rest of the points. Pre-caching helps in improving the performance of the subsequent loads by caching assets that have a higher time-to-live.</p><h3>Overall Improvements in upgrad.com\u2019s Performance</h3><p>Since the website runs on a server-side rendered Nuxt, it poses some special conditions to approach performance. Any SSR framework, accompanied with a CDN cache, guarantees a great TTFB and LCP, but suffers in time to interactivity as there\u2019s a re-hydration process that happens on the front-end.</p><p>A short description of how SSR works in Nuxt (from <a href=\"https://nuxtjs.org/docs/2.x/concepts/server-side-rendering\">nuxtjs.org</a>):</p><blockquote>Server-side rendering (SSR), is the ability of an application to contribute by displaying the web-page on the server instead of rendering it in the browser. Server-side sends a fully rendered page to the client; the client\u2019s JavaScript bundle takes over which then allows the Vue.js app to\u00a0hydrate.</blockquote><p><a href=\"https://nuxtjs.org/docs/2.x/concepts/server-side-rendering\">Server Side Rendering</a></p><p>Considering this, we only targeted the rendering and preloading bit of the entire process. We have plans to move to complete static rendering in the future which should solve the problem of hydration.</p><p>Anyway, we did this exercise over a period of <strong>4 months</strong>, and occasionally worked on performance specific tasks. I believe most of the work in this field has to be slow and steady. There\u2019s a fair amount of trial and error, research and reading required when you begin. But consistent efforts towards improving and then maintaining performance do pay off well. This is how the LCP (in a desktop setup) improvement for us looked over\u00a0time:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AVWLPIod04llfLLmoY0MHQ.png\" /></figure><p>Our Lighthouse scores went up as well, as mentioned in the beginning of the article. Current\u00a0score:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BS0gm24ASh0wxTOREMBYQA.png\" /></figure><p>I have thoroughly enjoyed working on this and have learnt quite a lot about how pages get rendered and how to make them fast. We are targetting to a even better score as there is still a room for improvement, but honestly the current score is a good one to take a break and look back at it with a fresh mind. As next steps, this is what we are looking\u00a0at:</p><ol><li><strong>Performance Benchmarking</strong>\u200a\u2014\u200aWe\u2019ve improved the scores, but it\u2019s our job now to maintain them there. Continuous monitoring is a crucial part of maintaining performance. There are tools available out there, or you can easily make one on your own (I did that\u00a0:P, will link it\u00a0later).</li><li><strong>Performance-optimised components</strong>\u200a\u2014\u200aWe\u2019re looking towards replacing certain shared UI components with lighter-weight alternatives.</li><li><strong>Brotli Compression &amp; Infra-level changes</strong>\u200a\u2014\u200aBrotli is enabled but needs some improvement in terms of the implementation. Also, infra-wise we look to reduce the number of hops required before reaching our origin\u00a0server.</li></ol><p>This entire feat wouldn\u2019t have been possible without my cooperative team, my manager Maitrey and Rohan. Me, Rohan and Maitrey have had numerous meetings to discuss this and have always worked towards building a performant and efficient platform. Things have worked like magic! Also, kudos to product leaders\u200a\u2014\u200aRohit &amp; Shahir, to look at this as a direct business impact (and constantly pinging us about the website being slow\u00a0:D). And finally, thanks to engineering leaders Vishal and Puneet for constantly supporting this entire exercise.</p><p>I\u2019ve already linked relevant resources as and when required, but for all others, here\u2019s a collated\u00a0list:</p><ul><li><a href=\"https://www.smashingmagazine.com/2021/01/front-end-performance-2021-free-pdf-checklist/\">https://www.smashingmagazine.com/2021/01/front-end-performance-2021-free-pdf-checklist/</a></li><li><a href=\"https://www.smashingmagazine.com/2021/01/smashingmag-performance-case-study/\">https://www.smashingmagazine.com/2021/01/smashingmag-performance-case-study/</a></li><li><a href=\"https://web.dev/optimize-lcp/\">https://web.dev/optimize-lcp/</a></li><li><a href=\"https://web.dev/vitals/\">https://web.dev/vitals/</a></li><li><a href=\"https://csswizardry.com/2020/01/performance-budgets-pragmatically/\">https://csswizardry.com/2020/01/performance-budgets-pragmatically/</a></li></ul><p>This story was originally published on my personal blog. You can find my other writings there as\u00a0well.</p><p><a href=\"https://mohitkarekar.com/posts/2021/web-performance-upgrad/\">Web Performance and Related Stories - upgrad.com</a></p><p>Do you have any similar experience, or a suggestion? I\u2019d love to discuss! You can reach out to me on <a href=\"mailto:karekar.mohit@gmail.com\">email</a>, or <a href=\"https://twitter.com/MohitKarekar\">Twitter</a>, or comment below. Do visit <a href=\"https://www.upgrad.com/\"><strong>upGrad.com</strong></a> to check out our programs that are completely online! If you wish to work with our ever-enthusiastic team, check out <a href=\"https://www.upgrad.com/open-positions\"><strong>our careers page</strong></a><strong>.</strong> We are always on the lookout for ambitious, talented\u00a0folks!</p><p><a href=\"https://www.upgrad.com/careers/?utm_source=medium_blog&amp;utm_medium=web_perf_upgrad\">upGrad Careers</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a9fb9c6bb766\" width=\"1\" /><hr /><p><a href=\"https://engineering.upgrad.com/web-performance-and-related-stories-upgrad-com-a9fb9c6bb766\">Web Performance and Related Stories\u200a\u2014\u200aupgrad.com</a> was originally published in <a href=\"https://engineering.upgrad.com\">Technology at upGrad</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h3>Web Performance and Related Stories\u200a\u2014\u200aupgrad.com</h3><p><em>The story and learnings from improving upgrad.com\u2019s (a Nuxt.js SSR application) Lighthouse performance scores from 17 to\u00a065</em></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QBnDE4-Mu_jnLSP8Z2lcQQ.png\" /></figure><p>In the month of January 2021 we, at upGrad, looked at our website\u2019s page speed scores and accepted the fact that they demanded considerable improvement. Lighthouse is a popular and extremely useful tool to measure web performance, and well, the scores for upgrad.com were barely crossing two-digit values. The situation wasn\u2019t great, but personally it was exciting for me because it presented a live problem to be solved, and this post is about the journey through the rough seas of web performance.</p><blockquote><strong>tl;dr<br /></strong><em>We were successful in improving our website performance in terms of the Lighthouse scores going from about </em><strong>5 and 15 to around 50 and 70</strong><em> on mobile and desktop respectively. I hope these numbers will encourage you to read the entire post, but I\u2019ll also try to make it interesting in general to read. See you until the\u00a0end!</em></blockquote><p>I consider this domain of web-development to carry a large importance for both\u200a\u2014\u200a<em>the developer working on the website/application, and the business/person owning the product</em>. The situation\u2019s better when you play both of these roles, let\u2019s say when you launch your side project. Web performance is an area which is interesting to work on as a tech person, as well as has direct impact on the business side of things. If you\u2019ve run your Lighthouse tests quite often (it is time to automate them), you might have seen these facts being\u00a0shown.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kWQI5aVwIa717hUT1sBtUQ.png\" /></figure><p><a href=\"https://web.dev/why-speed-matters/\"><strong>Speed does matter</strong></a>. As users of the internet ourselves, we know how frustrating it is to wait for a page to load. I sometimes empathize web developers of certain websites if they load slowly, and wait for a few more seconds. Unfortunately, real world users won\u2019t do that. As everything is becoming more and more instant, giving the best experience on the web is one of the core responsibilities of a web developer.</p><h3>The January of\u00a02021</h3><p>I do not want to sound poetic, but let\u2019s go back to the January of 2021. The growth team at upGrad had worked on a crucial project this month\u200a\u2014\u200athe separation of authentication logic from the website, and integrating a mobile OTP-based login+signup flow. It was an interesting project and Akshay (my teammate) is soon coming up with an article about it. But given that, now the upgrad.com website consisted only of representational content. In an ideal world, the website <em>could</em> have been built with plain HTML &amp; CSS, but having a framework like Nuxt.js gives us a lot of benefits in terms of operability and dynamism, given that we have an in-house CMS and\u00a0editors.</p><p>Anyway, the Lighthouse scores for the website were as follows (for desktop):</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*okRn0e4T_SrYXqFHgeB8-w.png\" /></figure><p>A 17 for desktop usually means your mobile scores sit somewhere lower, around 8\u201310. Things to note in the above screenshot are the values for the web vitals, <strong>most of them in red</strong>. Lighthouse considers these values to be important denoting factors about how your website loads and how it is perceived by the users. Let\u2019s take a short detour into how a browser loads a page, the web vitals then would be much clearer on the\u00a0way.</p><h3>Journey of a\u00a0page</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*cfQpu6Xvb7e9IiH4CCuiCg.png\" /><figcaption>Source: <a href=\"https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/\">https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/</a></figcaption></figure><p>A browser usually goes through the above flow whenever it receives its first chunk of HTML from the server. HTML is a special language, <strong><em>it is forgiving</em></strong>. And hence its parsing is special too. To go a bit into details, HTML does not have a Context-Free Grammar, as most of the languages would have. This grammar tells what is valid and what is invalid in a language. In HTML, the browser usually corrects if some parts are erroneous. In addition to this, HTML can change while parsing is still happening! JavaScript can inject HTML into the page using document.write() and because of this HTML parsing is called <em>re-entrant</em>.</p><p>If we consider a short example page\u2019s\u00a0HTML</p><h4>Scenario 1</h4><pre>&lt;html&gt;<br />    &lt;body&gt;<br />        &lt;h1&gt;Hello&lt;/h1&gt;<br />    &lt;/body&gt;<br />&lt;/html&gt;</pre><p>Here, the parser will start from the top and go on identifying corresponding nodes. It will find open html -&gt; open body -&gt; open h1 -&gt; text Hello -&gt; close h1 -&gt; close body -&gt; close html. At the end of the parsing you\u2019d generally have a syntax tree which will mirror a corresponding DOM tree. The object would be the one which will be exposed to JavaScript inside document.</p><p>Essentially, the DOM tree would be constructed, laying out would be done and then the bitmap would be painted on the screen. Super\u00a0optimal.</p><h4>Scenario 2</h4><pre>&lt;html&gt;<br />    &lt;head&gt;<br />        &lt;link <em>rel</em>=&quot;stylesheet&quot; <em>href</em>=&quot;/main.css&quot; /&gt;<br />    &lt;/head&gt;<br />    &lt;body&gt;<br />        &lt;h1&gt;Hello&lt;/h1&gt;<br />    &lt;/body&gt;<br />&lt;/html&gt;</pre><p>Let\u2019s consider this example which adds a remote CSS stylesheet to the page. Any form of <strong>CSS on the page is render-blocking</strong>. It means that until all the CSS isn\u2019t parsed, the renderer won\u2019t paint the page\u200a\u2014\u200aremember from the above flow diagram that the render tree construction requires the CSS tree to be\u00a0ready.</p><p>Hence in this example, the DOM tree would be constructed, but the rendering would not happen until the CSS file is loaded and parsed completely. A bit less\u00a0optimal.</p><h4>Scenario 3</h4><pre>&lt;html&gt;<br />    &lt;head&gt;<br />        &lt;link <em>rel</em>=&quot;stylesheet&quot; <em>href</em>=&quot;/main.css&quot; /&gt;<br />        &lt;script&gt;console.log('Hello from JavaScript!');&lt;/script<br />    &lt;/head&gt;<br />    &lt;body&gt;<br />        &lt;h1&gt;Hello&lt;/h1&gt;<br />    &lt;/body&gt;<br />&lt;/html&gt;</pre><p>Let\u2019s add a &lt;script&gt; tag to the head. Any form of <strong>JavaScript on the page is usually parser-blocking</strong>. The HTML parsing is blocked until the script is executed\u200a\u2014\u200athis is again because JS has the potential to modify the DOM, so the browser wouldn\u2019t want to proceed and later get to know that the code it had parsed was stale. You can think how this might get affected if you have remote JavaScript files, which is usually the case. The files would first have to be downloaded and then executed for the parser to move ahead. Very un-optimal.</p><p>Mozilla Developer Network documentation as well as Google\u2019s web.dev articles explain this in great detail. You might want to look into\u00a0those.</p><p>The crux of the detour above was to discuss what could potentially hinder our website from being loaded/visible to the users. From the discussion we can take two key\u00a0points:</p><ul><li>CSS is render-blocking</li><li>JavaScript is parser-blocking</li></ul><p>These two points form a base to a large number of optimizations that one can perform to speed up their website. The core web vitals also get affected due to\u00a0these.</p><p>Sourced directly from <a href=\"https://web.dev:\">https://web.dev:</a></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5V9pbAoFLzNJYA2uRK0bKw.png\" /></figure><p>Anything render-blocking will worsen LCP. Anything process heavy on page load will worsen FID, e.g. synchronous JavaScript execution on main thread. Anything writing to the document and hence drastically changing the page layout will worsen\u00a0CLS.</p><p>For the initial phases our target was reducing LCP. Additional reading:</p><p><a href=\"https://developers.google.com/web/fundamentals/performance/get-started\">Overview | Web Fundamentals | Google Developers</a></p><h3>Identifying Areas of Improvement &amp;\u00a0Budgets</h3><p>To tackle the problem of performance, usually one can look internally first (quite philosophical). Before performing a complex change in your system, one must try to find areas to improve in the existing setup. It is quite probable that there would be a lot to clean up and optimize. At least that was the case with\u00a0us.</p><p>But before beginning any work, how would you know what to pick and how that change would impact the performance? Enter performance analysis tools. There are numerous tools available online that help you know exactly where the bottleneck is. Lighthouse is one of such tools but I believe it should be used to benchmark the final score. There is another online tool called <a href=\"https://webpagetest.org/\"><strong>WebPageTest</strong></a> that gives you detailed report of your website\u2019s performance under various scenarios. I personally found is very useful to identify individual problems.</p><p>Following is a screenshot from webpagetest.org:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*y5MJRobxWlYjTqITVKp2EQ.png\" /></figure><p>The above report gives a detailed view of what is happening on the page\u200a\u2014\u200afrom the vitals to the waterfall view and the vitals marked on it. It was particularly helpful to map what was delaying certain metrics and then target those resources specifically.</p><h4>Budgeting</h4><p>This is a debatable topic but everyone can have their own preferred ways of budgeting your optimizations. This helps us maintain a threshold for either metrics or the experience that we want to provide to our users. I\u2019ll keep this section short and link to useful resources online:</p><ul><li><a href=\"https://web.dev/defining-core-web-vitals-thresholds/\">https://web.dev/defining-core-web-vitals-thresholds/</a></li><li><a href=\"https://csswizardry.com/2020/01/performance-budgets-pragmatically/\">https://csswizardry.com/2020/01/performance-budgets-pragmatically/</a></li></ul><p>We began with some obvious areas that we could target\u200a\u2014\u200asomething that we knew already but could not find time to fix. These included some unused scripts and some modules that were being loaded globally when we could load them locally. In Nuxt, you can define global plugins that get included in the main bundle\u200a\u2014\u200aoften a bad practice if not monitored properly. So in short, here are a few key areas that can be targeted:</p><h4>Lazy-load Everything Unnecessary</h4><p><strong><em>Impact\u200a\u2014\u200aTime To Interactive (TTI), First Contentful Paint\u00a0(FCP)</em></strong></p><p>You <em>must</em> defer/lazily-load everything that is not crucial for your first load and does not contribute to SEO. This includes modals, non-critical scripts, images, stylesheets and chunks of your application.</p><p>For our website, we saw a considerable difference when we lazy-loaded all our modal content. Since it was a separated module in itself, we could do this easily. Most of the frameworks have special syntax for lazy-loading components, e.g. React.lazy() in React and the import() syntax in Vue. Bundlers provide automatic code-splitting based on this syntax so that your chunks are separate and are only loaded when requested for.</p><p>Since Nuxt uses webpack, we could use <strong>webpack\u2019s magic comments</strong> that allow you to define loading behaviours on chunks. /* webpackPrefetch: true */ is one such useful comment that pre-fetches the chunk so that the experience is similar to loading it synchronously.</p><p><strong>Image lazy-loading</strong> is core to faster websites and usually is already implemented. But if it isn\u2019t then you should do it right away. There are popular libraries that allow this and now there\u2019s also a native way of doing it in HTML, though it isn\u2019t supported in all browsers.</p><p>The standard way of telling the browsers to defer loading a script, or load them asynchronously is by using the defer and async keywords correctly. <strong>defer moves the processing of a script to the end of parsing step</strong>. The script is fetched in the background and in parallel if many. This solves the issue mentioned in \u2018Scenario 3\u2019 above. That is also why usually it is recommended to keep your script tags at the end of the body. This helps in two ways\u200a\u2014\u200ait allows the script to \u2018see\u2019 the entire body of the page at it was built before the parser reached the script tag, and second that the parses did not get blocked on the script somewhere at the beginning of the\u00a0page.</p><p>async helps in a similar way but instead of loading the scripts in the end, <strong>they are loaded and even processed asynchronously</strong>. These won\u2019t wait for the DOM tree being built, but get executed as soon as they complete loading. A key difference between async and defer is that all scripts loaded with defer will block the DOMContentLoaded event while those loaded with async would\u00a0not.</p><p>Another useful thing that can be leveraged off of frameworks is the <strong>dynamic loading of scripts</strong>. Keeping the core idea in mind\u200a\u2014\u200a<em>load only those resources that are required to build the page\u200a</em>\u2014\u200awe can dynamically push &lt;script&gt; tags in our website\u2019s head. This allows, e.g. loading the YouTube player script only on pages that actually display a video, ensuring that does not slow down a page that does not have a video at\u00a0all.</p><h4>Limit Critical Resources\u200a\u2014\u200aShorten the Critical Rendering Path</h4><p><strong><em>Impact\u200a\u2014\u200aFirst Contentful Paint (FCP), Largest Contentful Paint\u00a0(LCP)</em></strong></p><p><strong>Critical rendering path</strong> (CRP) is the journey of a page being rendered in a browser from the point when the browser receives the first bytes of the response (HTML) to when the page starts becoming visible. Our aim should be to keep this as short as possible. As resources get added to this path, the time to start painting goes on increasing, hampering the page load experience.</p><p>CRP depends on the way your HTML document is parsed. If it is only static HTML, you would have a great LCP score. But practically, there are a lot of resources that usually get added on a HTML page, that are at times crucial for the website to behave properly. If these resources are required for your page to render, then they contribute to CRP. The parser has to do the work of loading and executing them and then continue to parse the page and then finally the renderer to take\u00a0over.</p><p>Good resources:</p><p><a href=\"https://developers.google.com/web/fundamentals/performance/critical-rendering-path/\">Critical Rendering Path | Web Fundamentals | Google Developers</a></p><p>For us, it was about looking at the waterfall snapshot from webpagetest and see what was delaying the first render. Upon checking, we could find that a particular CSS file was being loaded critically and to worsen the problem, it wasn\u2019t being served via a\u00a0CDN.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3iaZ8Cc33EkYklqpqqiXkQ.png\" /></figure><p>Finding such resources and unblocking them helped us improve our start render times by a good number\u200a\u2014<strong><em>\u200aold one being at 4.2 seconds, improved to 0.4\u00a0seconds.</em></strong></p><p>The initial HTML response of your page must contain only the critical CSS\u200a\u2014\u200aCSS required for your page to be properly styled. All others can be lazily loaded. One popular way to <strong>asynchronously load CSS</strong> is using the media attribute of link\u00a0tag.</p><pre>&lt;link<br />    <em>rel</em>=&quot;stylesheet&quot;<br />    <em>href</em>=&quot;/link/to/file.css&quot;<br />    <em>media</em>=&quot;print&quot;<br />    <em>onload</em>='<em>this</em>.media=&quot;all&quot;,<em>this</em>.onload=null'<br />/&gt;</pre><p>Here, since the media value is \u2018print\u2019, the HTML parser in a browser would skip waiting on this stylesheet and move ahead. The stylesheet will still load in the background, and whenever it does, it will get parsed. This prevents blocking of the parser at the CSS link tag and is good for stylesheets that aren\u2019t required at the time of first\u00a0load.</p><p>Even with the above solution, we must ensure that the critical CSS is lean. Tools like <a href=\"https://purgecss.com/\"><strong>PurgeCSS</strong></a> help in automating this by cleaning out the styles that are unused on the page by going over the HTML of the finally generated page.</p><h4>Preloading Critical\u00a0Assets</h4><p><strong><em>Impact\u200a\u2014\u200aLargest Contentful Paint\u00a0(LCP)</em></strong></p><p>One other important practice is to <strong>preload all your critical resources</strong>. If your website has an image in the first fold, you must preload it so that it is visually available as soon as possible.</p><p>One can use the preload keyword to do this and many bundlers do this automatically for\u00a0you.</p><pre>&lt;link <em>rel</em>=&quot;preload&quot; <em>as</em>=&quot;image&quot; <em>href</em>=&quot;banner-image.webp&quot; /&gt;</pre><p>More on preload\u00a0here:</p><p><a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Link_types/preload\">Link types: preload - HTML: HyperText Markup Language | MDN</a></p><p>Applying these practices brought down our LCP largely\u200a\u2014\u200a<strong><em>from 3.9 seconds to 0.9\u00a0seconds.</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*as8e_vFbraac5kzl3WcIEw.png\" /></figure><p>Google\u2019s web.dev sums up the above points in a very good way\u200a\u2014\u200ait introduces the <strong>PRPL\u00a0pattern</strong>.</p><ul><li>P\u200a\u2014\u200aPush (or preload) the most important resources.</li><li>R\u200a\u2014\u200aRender the initial route as soon as possible.</li><li>P\u200a\u2014\u200aPre-cache remaining assets.</li><li>L\u200a\u2014\u200aLazy load other routes and non-critical assets.</li></ul><p>Apart from pre-caching, I think I talked about the rest of the points. Pre-caching helps in improving the performance of the subsequent loads by caching assets that have a higher time-to-live.</p><h3>Overall Improvements in upgrad.com\u2019s Performance</h3><p>Since the website runs on a server-side rendered Nuxt, it poses some special conditions to approach performance. Any SSR framework, accompanied with a CDN cache, guarantees a great TTFB and LCP, but suffers in time to interactivity as there\u2019s a re-hydration process that happens on the front-end.</p><p>A short description of how SSR works in Nuxt (from <a href=\"https://nuxtjs.org/docs/2.x/concepts/server-side-rendering\">nuxtjs.org</a>):</p><blockquote>Server-side rendering (SSR), is the ability of an application to contribute by displaying the web-page on the server instead of rendering it in the browser. Server-side sends a fully rendered page to the client; the client\u2019s JavaScript bundle takes over which then allows the Vue.js app to\u00a0hydrate.</blockquote><p><a href=\"https://nuxtjs.org/docs/2.x/concepts/server-side-rendering\">Server Side Rendering</a></p><p>Considering this, we only targeted the rendering and preloading bit of the entire process. We have plans to move to complete static rendering in the future which should solve the problem of hydration.</p><p>Anyway, we did this exercise over a period of <strong>4 months</strong>, and occasionally worked on performance specific tasks. I believe most of the work in this field has to be slow and steady. There\u2019s a fair amount of trial and error, research and reading required when you begin. But consistent efforts towards improving and then maintaining performance do pay off well. This is how the LCP (in a desktop setup) improvement for us looked over\u00a0time:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AVWLPIod04llfLLmoY0MHQ.png\" /></figure><p>Our Lighthouse scores went up as well, as mentioned in the beginning of the article. Current\u00a0score:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BS0gm24ASh0wxTOREMBYQA.png\" /></figure><p>I have thoroughly enjoyed working on this and have learnt quite a lot about how pages get rendered and how to make them fast. We are targetting to a even better score as there is still a room for improvement, but honestly the current score is a good one to take a break and look back at it with a fresh mind. As next steps, this is what we are looking\u00a0at:</p><ol><li><strong>Performance Benchmarking</strong>\u200a\u2014\u200aWe\u2019ve improved the scores, but it\u2019s our job now to maintain them there. Continuous monitoring is a crucial part of maintaining performance. There are tools available out there, or you can easily make one on your own (I did that\u00a0:P, will link it\u00a0later).</li><li><strong>Performance-optimised components</strong>\u200a\u2014\u200aWe\u2019re looking towards replacing certain shared UI components with lighter-weight alternatives.</li><li><strong>Brotli Compression &amp; Infra-level changes</strong>\u200a\u2014\u200aBrotli is enabled but needs some improvement in terms of the implementation. Also, infra-wise we look to reduce the number of hops required before reaching our origin\u00a0server.</li></ol><p>This entire feat wouldn\u2019t have been possible without my cooperative team, my manager Maitrey and Rohan. Me, Rohan and Maitrey have had numerous meetings to discuss this and have always worked towards building a performant and efficient platform. Things have worked like magic! Also, kudos to product leaders\u200a\u2014\u200aRohit &amp; Shahir, to look at this as a direct business impact (and constantly pinging us about the website being slow\u00a0:D). And finally, thanks to engineering leaders Vishal and Puneet for constantly supporting this entire exercise.</p><p>I\u2019ve already linked relevant resources as and when required, but for all others, here\u2019s a collated\u00a0list:</p><ul><li><a href=\"https://www.smashingmagazine.com/2021/01/front-end-performance-2021-free-pdf-checklist/\">https://www.smashingmagazine.com/2021/01/front-end-performance-2021-free-pdf-checklist/</a></li><li><a href=\"https://www.smashingmagazine.com/2021/01/smashingmag-performance-case-study/\">https://www.smashingmagazine.com/2021/01/smashingmag-performance-case-study/</a></li><li><a href=\"https://web.dev/optimize-lcp/\">https://web.dev/optimize-lcp/</a></li><li><a href=\"https://web.dev/vitals/\">https://web.dev/vitals/</a></li><li><a href=\"https://csswizardry.com/2020/01/performance-budgets-pragmatically/\">https://csswizardry.com/2020/01/performance-budgets-pragmatically/</a></li></ul><p>This story was originally published on my personal blog. You can find my other writings there as\u00a0well.</p><p><a href=\"https://mohitkarekar.com/posts/2021/web-performance-upgrad/\">Web Performance and Related Stories - upgrad.com</a></p><p>Do you have any similar experience, or a suggestion? I\u2019d love to discuss! You can reach out to me on <a href=\"mailto:karekar.mohit@gmail.com\">email</a>, or <a href=\"https://twitter.com/MohitKarekar\">Twitter</a>, or comment below. Do visit <a href=\"https://www.upgrad.com/\"><strong>upGrad.com</strong></a> to check out our programs that are completely online! If you wish to work with our ever-enthusiastic team, check out <a href=\"https://www.upgrad.com/open-positions\"><strong>our careers page</strong></a><strong>.</strong> We are always on the lookout for ambitious, talented\u00a0folks!</p><p><a href=\"https://www.upgrad.com/careers/?utm_source=medium_blog&amp;utm_medium=web_perf_upgrad\">upGrad Careers</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a9fb9c6bb766\" width=\"1\" /><hr /><p><a href=\"https://engineering.upgrad.com/web-performance-and-related-stories-upgrad-com-a9fb9c6bb766\">Web Performance and Related Stories\u200a\u2014\u200aupgrad.com</a> was originally published in <a href=\"https://engineering.upgrad.com\">Technology at upGrad</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "HubSpot": {
    "title": "Looking Back: Our Most Popular Posts of 2023",
    "xmlUrl": "https://product.hubspot.com/blog/rss.xml",
    "htmlUrl": "http://product.hubspot.com/blog/topic/engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://product.hubspot.com/blog/rss.xml",
      "value": "Looking Back: Our Most Popular Posts of 2023"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://product.hubspot.com/blog/2023-retro"
      }
    ],
    "link": "https://product.hubspot.com/blog/2023-retro",
    "summary": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://product.hubspot.com/blog/2023-retro\" title=\"\"> <img alt=\"Looking Back: Our Most Popular Posts of 2023\" class=\"hs-featured-image\" src=\"https://product.hubspot.com/hubfs/Preventing%20Serial%20Processing%20%281%29.png\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> \n<p>2023 was an incredible year of growth for us at HubSpot directly driven by our Product and Engineering teams who tackled hard problems that helped our customers grow better. Some of our HubSpotters shared impactful case studies, impressive growth stories and insights to highlight their work and just what it means to work at HubSpot on our Product Blog. We've gathered some of our most popular blogs of 2023 below in case you missed them, and stayed tuned this year for more behind-the-scenes content from our Product and Engineering teams!</p> \n<p>Looking for more stories about our culture and what it's like to work at HubSpot? Check out our <a href=\"https://www.hubspot.com/careers-blog\">Careers Blog</a>!</p> \n<p>_________</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://product.hubspot.com/blog/rss.xml",
      "value": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://product.hubspot.com/blog/2023-retro\" title=\"\"> <img alt=\"Looking Back: Our Most Popular Posts of 2023\" class=\"hs-featured-image\" src=\"https://product.hubspot.com/hubfs/Preventing%20Serial%20Processing%20%281%29.png\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> \n<p>2023 was an incredible year of growth for us at HubSpot directly driven by our Product and Engineering teams who tackled hard problems that helped our customers grow better. Some of our HubSpotters shared impactful case studies, impressive growth stories and insights to highlight their work and just what it means to work at HubSpot on our Product Blog. We've gathered some of our most popular blogs of 2023 below in case you missed them, and stayed tuned this year for more behind-the-scenes content from our Product and Engineering teams!</p> \n<p>Looking for more stories about our culture and what it's like to work at HubSpot? Check out our <a href=\"https://www.hubspot.com/careers-blog\">Careers Blog</a>!</p> \n<p>_________</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://product.hubspot.com/blog/rss.xml",
        "value": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://product.hubspot.com/blog/2023-retro\" title=\"\"> <img alt=\"Looking Back: Our Most Popular Posts of 2023\" class=\"hs-featured-image\" src=\"https://product.hubspot.com/hubfs/Preventing%20Serial%20Processing%20%281%29.png\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> \n<p>2023 was an incredible year of growth for us at HubSpot directly driven by our Product and Engineering teams who tackled hard problems that helped our customers grow better. Some of our HubSpotters shared impactful case studies, impressive growth stories and insights to highlight their work and just what it means to work at HubSpot on our Product Blog. We've gathered some of our most popular blogs of 2023 below in case you missed them, and stayed tuned this year for more behind-the-scenes content from our Product and Engineering teams!</p> \n<p>Looking for more stories about our culture and what it's like to work at HubSpot? Check out our <a href=\"https://www.hubspot.com/careers-blog\">Careers Blog</a>!</p> \n<p>_________</p>  \n<img alt=\"\" height=\"1\" src=\"https://track.hubspot.com/__ptq.gif?a=51294&amp;k=14&amp;r=https%3A%2F%2Fproduct.hubspot.com%2Fblog%2F2023-retro&amp;bu=https%253A%252F%252Fproduct.hubspot.com%252Fblog&amp;bvt=rss\" style=\"width: 1px!important;\" width=\"1\" />"
      }
    ],
    "tags": [
      {
        "term": "Engineering--Infrastructure",
        "scheme": null,
        "label": null
      },
      {
        "term": "Culture",
        "scheme": null,
        "label": null
      },
      {
        "term": "UX",
        "scheme": null,
        "label": null
      },
      {
        "term": "Engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "Product",
        "scheme": null,
        "label": null
      },
      {
        "term": "Engineering--Backend",
        "scheme": null,
        "label": null
      },
      {
        "term": "Engineering--Frontend",
        "scheme": null,
        "label": null
      },
      {
        "term": "Product Management",
        "scheme": null,
        "label": null
      }
    ],
    "published": "Tue, 09 Jan 2024 15:29:37 GMT",
    "published_parsed": [
      2024,
      1,
      9,
      15,
      29,
      37,
      1,
      9,
      0
    ],
    "authors": [
      {
        "name": "Ashlee Gerow",
        "email": "agerow@hubspot.com"
      }
    ],
    "author": "agerow@hubspot.com (Ashlee Gerow)",
    "author_detail": {
      "name": "Ashlee Gerow",
      "email": "agerow@hubspot.com"
    },
    "id": "https://product.hubspot.com/blog/2023-retro",
    "guidislink": false,
    "updated": "2024-01-09T15:29:37Z",
    "updated_parsed": [
      2024,
      1,
      9,
      15,
      29,
      37,
      1,
      9,
      0
    ]
  },
  "Helpshift": {
    "title": "Updating PostgreSQL server config",
    "xmlUrl": "https://medium.com/feed/helpshift-engineering",
    "htmlUrl": "https://medium.com/helpshift-engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/helpshift-engineering",
      "value": "Updating PostgreSQL server config"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/helpshift-engineering/updating-postgresql-server-config-78dc43150be9?source=rss----3229f31ca4f4---4"
      }
    ],
    "link": "https://medium.com/helpshift-engineering/updating-postgresql-server-config-78dc43150be9?source=rss----3229f31ca4f4---4",
    "id": "https://medium.com/p/78dc43150be9",
    "guidislink": false,
    "tags": [
      {
        "term": "database",
        "scheme": null,
        "label": null
      },
      {
        "term": "postgresql",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Vineet Naik"
      }
    ],
    "author": "Vineet Naik",
    "author_detail": {
      "name": "Vineet Naik"
    },
    "published": "Wed, 11 Oct 2023 04:43:14 GMT",
    "published_parsed": [
      2023,
      10,
      11,
      4,
      43,
      14,
      2,
      284,
      0
    ],
    "updated": "2023-10-11T07:31:06.388Z",
    "updated_parsed": [
      2023,
      10,
      11,
      7,
      31,
      6,
      2,
      284,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/helpshift-engineering",
        "value": "<p>If you are running a PostgreSQL (pg) server in production for a fair amount of time, chances are that you\u2019d have had to change its configuration at least once by now. Overtime any database server needs regular tuning to make it operationally suitable to the evolving needs, particularly if it powers a successful/growing product.</p><p>In case of pg, the simplest way to update server configuration is to make changes in the config file, postgresql.conf and restart the server process. But depending on your setup, doing this without downtime could be non-trivial at best (if your setup is highly available) or impossible at worst (if there\u2019s just one server running).</p><p>The good news is that in pg not all config parameter changes require a server restart. But how do we know whether or not the parameter we want to change requires a\u00a0restart?</p><h4>The pg_settings view</h4><p>The builtin view pg_settings can give us this information. This view provides access to run-time config parameters of the server through SQL queries. If you are connected to the db using psql, try running select * from pg_settings limit 10; to quickly check the\u00a0schema.</p><p>The column we\u2019re interested in is context which can have a bunch of values. For example - a query such\u00a0as,</p><pre>SELECT<br />    name,<br />    context<br />FROM<br />    pg_settings<br />WHERE<br />    name IN ('min_wal_size', 'max_wal_size', 'wal_level');</pre><p>would return the\u00a0result,</p><pre>     name     |  context<br />--------------+------------<br /> max_wal_size | sighup<br /> min_wal_size | sighup<br /> wal_level    | postmaster<br />(3 rows)</pre><p>In the above output we can see 2 different values for\u00a0context:</p><ol><li>sighup: This means changes to these settings can be made in postgresql.conf without restarting the server. We can simply send a SIGHUP signal to the postmaster process and it will re-read postgresql.conf and apply the\u00a0changes.</li><li>postmaster: These settings can only be applied when the server starts, so any change requires restarting the\u00a0server.</li></ol><p>Besides the above two, there are other types of contexts too. See docs\u200a\u2014\u200a<a href=\"https://www.postgresql.org/docs/current/view-pg-settings.html\">https://www.postgresql.org/docs/current/view-pg-settings.html</a>.</p><p>In the above case, max_wal_size and min_wal_size can be modified by reloading the config, whereas to modify wal_level we will need to restart the\u00a0server.</p><h4>Sending SIGHUP using \u2018pg_reload_conf\u2019</h4><p>One easy way to send SIGHUP to the postmaster from within a running psql session is by calling the admin function pg_reload_conf</p><pre>postgres=# select pg_reload_conf();<br /> pg_reload_conf<br />----------------<br /> t<br />(1 row)</pre><p>Note that the use of this function is restricted to superusers only, for obvious\u00a0reasons.</p><h4>Verifying that the new config is in\u00a0effect</h4><p>After reloading, you might want to confirm that the updated config has taken effect. To do that, you may either run the SHOWcommand as\u00a0follows,</p><pre>postgres=# show max_wal_size;<br /> max_wal_size<br />--------------<br /> 1536MB<br />(1 row)</pre><p>or query the same pg_settings view, which is more convenient for multiple config\u00a0params.</p><pre>SELECT<br />    name,<br />    setting,<br />    unit<br />FROM<br />    pg_settings<br />WHERE<br />    name IN ('min_wal_size', 'max_wal_size');</pre><h4>Making temporary config changes using \u2018alter\u00a0system\u2019</h4><p>It\u2019s even possible to update a \u201creloadable\u201d config parameter by setting it directly from the psql session (again, restricted to superuser).</p><pre>postgres=# alter system set max_wal_size = 144;<br />ALTER SYSTEM<br />postgres=# select pg_reload_conf();<br /> pg_reload_conf<br />----------------<br /> t<br />(1 row)<br />postgres=# SELECT name, setting, unit from pg_settings where name = 'max_wal_size';<br />     name     | setting | unit<br />--------------+---------+------<br /> max_wal_size | 144     | 16MB<br />(1 row)</pre><p>This way, there\u2019s no need to edit the config file thereby making it extremely useful\u00a0for,</p><ol><li>changing the config as quickly as possible during an ongoing incident\u00a0or,</li><li>trying out various config values while experimenting on a local/staging server.</li></ol><p>But in most other cases, it\u2019s recommended to update the config file in order to avoid any confusion. A config change done using alter system instead of updating the config file is ephemeral, i.e. if the server restarts for whatever reason, the change would get unknowingly reverted.</p><p>Having a provision to update the config without changing the config file also means that the config file cannot be treated as the source of truth. So if you want to check the current value of a config parameter, the best way to do so is to just query the pg_settings view.</p><h4>Config parameters with implicit\u00a0units</h4><p>In the previous example, notice that the max_wal_size value was set to 144. However, the entry in pg_settings view for this parameter shows 16MB in the \u201cunit\u201d\u00a0column.</p><p>Config parameters that store memory or time values have implicit units. In such cases, the actual value is then obtained by multiplying the explicitly set value (144) with the unit (16MB). This can be confirmed using the SHOW command which implicitly does the calculation.</p><pre>postgres=# SELECT name, setting, unit from pg_settings where name = 'max_wal_size';<br />     name     | setting | unit<br />--------------+---------+------<br /> max_wal_size | 144     | 16MB<br />(1 row)<br />postgres=# show max_wal_size;<br /> max_wal_size<br />--------------<br /> 2304MB<br />(1 row)</pre><p>The SHOW command correctly shows the value of max_wal_size as 144 * 16 = 2304MB\u00a0.</p><p>So when inspecting any config parameter value from the pg_settings view, make sure to include the unit column as well to get the full\u00a0picture.</p><h4>In summary</h4><p>If you find yourself in a situation that requires pg config changes, first find out whether any of the params require a restart of the postmaster. If all are \u201creloadable\u201d, then the config change is fairly trivial. On the other hand, if any of the params have \u2018postmaster\u2019 as the context, then a server restart is required. Depending on the above and your setup, you will need to plan it accordingly (planned maintenance window, customer communication etc.)</p><p>alter system is quite handy for experimentation and quickly making changes to recover from production incidents (<em>provided you know what you\u2019re\u00a0doing</em>).</p><p>The server config file postgresql.conf shouldn\u2019t be treated as a source of truth. Instead check the values by querying the pg_settings view. In any case, it\u2019s always recommended to update the config file for permanent changes.</p><p>When inspecting config values, don\u2019t forget to consider the implicit\u00a0units.</p><p>These are just a few useful things about postgresql configuration. For more comprehensive info on the subject, the official documentation is your friend\u200a\u2014\u200a<a href=\"https://www.postgresql.org/docs/current/runtime-config.html\">https://www.postgresql.org/docs/current/runtime-config.html</a>.</p><p><em>Thanks to </em><a href=\"https://medium.com/u/93c26ced7936\"><em>Narendra Pal</em></a><em> and Somya Maithani for reviewing the\u00a0drafts.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=78dc43150be9\" width=\"1\" /><hr /><p><a href=\"https://medium.com/helpshift-engineering/updating-postgresql-server-config-78dc43150be9\">Updating PostgreSQL server config</a> was originally published in <a href=\"https://medium.com/helpshift-engineering\">helpshift-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>If you are running a PostgreSQL (pg) server in production for a fair amount of time, chances are that you\u2019d have had to change its configuration at least once by now. Overtime any database server needs regular tuning to make it operationally suitable to the evolving needs, particularly if it powers a successful/growing product.</p><p>In case of pg, the simplest way to update server configuration is to make changes in the config file, postgresql.conf and restart the server process. But depending on your setup, doing this without downtime could be non-trivial at best (if your setup is highly available) or impossible at worst (if there\u2019s just one server running).</p><p>The good news is that in pg not all config parameter changes require a server restart. But how do we know whether or not the parameter we want to change requires a\u00a0restart?</p><h4>The pg_settings view</h4><p>The builtin view pg_settings can give us this information. This view provides access to run-time config parameters of the server through SQL queries. If you are connected to the db using psql, try running select * from pg_settings limit 10; to quickly check the\u00a0schema.</p><p>The column we\u2019re interested in is context which can have a bunch of values. For example - a query such\u00a0as,</p><pre>SELECT<br />    name,<br />    context<br />FROM<br />    pg_settings<br />WHERE<br />    name IN ('min_wal_size', 'max_wal_size', 'wal_level');</pre><p>would return the\u00a0result,</p><pre>     name     |  context<br />--------------+------------<br /> max_wal_size | sighup<br /> min_wal_size | sighup<br /> wal_level    | postmaster<br />(3 rows)</pre><p>In the above output we can see 2 different values for\u00a0context:</p><ol><li>sighup: This means changes to these settings can be made in postgresql.conf without restarting the server. We can simply send a SIGHUP signal to the postmaster process and it will re-read postgresql.conf and apply the\u00a0changes.</li><li>postmaster: These settings can only be applied when the server starts, so any change requires restarting the\u00a0server.</li></ol><p>Besides the above two, there are other types of contexts too. See docs\u200a\u2014\u200a<a href=\"https://www.postgresql.org/docs/current/view-pg-settings.html\">https://www.postgresql.org/docs/current/view-pg-settings.html</a>.</p><p>In the above case, max_wal_size and min_wal_size can be modified by reloading the config, whereas to modify wal_level we will need to restart the\u00a0server.</p><h4>Sending SIGHUP using \u2018pg_reload_conf\u2019</h4><p>One easy way to send SIGHUP to the postmaster from within a running psql session is by calling the admin function pg_reload_conf</p><pre>postgres=# select pg_reload_conf();<br /> pg_reload_conf<br />----------------<br /> t<br />(1 row)</pre><p>Note that the use of this function is restricted to superusers only, for obvious\u00a0reasons.</p><h4>Verifying that the new config is in\u00a0effect</h4><p>After reloading, you might want to confirm that the updated config has taken effect. To do that, you may either run the SHOWcommand as\u00a0follows,</p><pre>postgres=# show max_wal_size;<br /> max_wal_size<br />--------------<br /> 1536MB<br />(1 row)</pre><p>or query the same pg_settings view, which is more convenient for multiple config\u00a0params.</p><pre>SELECT<br />    name,<br />    setting,<br />    unit<br />FROM<br />    pg_settings<br />WHERE<br />    name IN ('min_wal_size', 'max_wal_size');</pre><h4>Making temporary config changes using \u2018alter\u00a0system\u2019</h4><p>It\u2019s even possible to update a \u201creloadable\u201d config parameter by setting it directly from the psql session (again, restricted to superuser).</p><pre>postgres=# alter system set max_wal_size = 144;<br />ALTER SYSTEM<br />postgres=# select pg_reload_conf();<br /> pg_reload_conf<br />----------------<br /> t<br />(1 row)<br />postgres=# SELECT name, setting, unit from pg_settings where name = 'max_wal_size';<br />     name     | setting | unit<br />--------------+---------+------<br /> max_wal_size | 144     | 16MB<br />(1 row)</pre><p>This way, there\u2019s no need to edit the config file thereby making it extremely useful\u00a0for,</p><ol><li>changing the config as quickly as possible during an ongoing incident\u00a0or,</li><li>trying out various config values while experimenting on a local/staging server.</li></ol><p>But in most other cases, it\u2019s recommended to update the config file in order to avoid any confusion. A config change done using alter system instead of updating the config file is ephemeral, i.e. if the server restarts for whatever reason, the change would get unknowingly reverted.</p><p>Having a provision to update the config without changing the config file also means that the config file cannot be treated as the source of truth. So if you want to check the current value of a config parameter, the best way to do so is to just query the pg_settings view.</p><h4>Config parameters with implicit\u00a0units</h4><p>In the previous example, notice that the max_wal_size value was set to 144. However, the entry in pg_settings view for this parameter shows 16MB in the \u201cunit\u201d\u00a0column.</p><p>Config parameters that store memory or time values have implicit units. In such cases, the actual value is then obtained by multiplying the explicitly set value (144) with the unit (16MB). This can be confirmed using the SHOW command which implicitly does the calculation.</p><pre>postgres=# SELECT name, setting, unit from pg_settings where name = 'max_wal_size';<br />     name     | setting | unit<br />--------------+---------+------<br /> max_wal_size | 144     | 16MB<br />(1 row)<br />postgres=# show max_wal_size;<br /> max_wal_size<br />--------------<br /> 2304MB<br />(1 row)</pre><p>The SHOW command correctly shows the value of max_wal_size as 144 * 16 = 2304MB\u00a0.</p><p>So when inspecting any config parameter value from the pg_settings view, make sure to include the unit column as well to get the full\u00a0picture.</p><h4>In summary</h4><p>If you find yourself in a situation that requires pg config changes, first find out whether any of the params require a restart of the postmaster. If all are \u201creloadable\u201d, then the config change is fairly trivial. On the other hand, if any of the params have \u2018postmaster\u2019 as the context, then a server restart is required. Depending on the above and your setup, you will need to plan it accordingly (planned maintenance window, customer communication etc.)</p><p>alter system is quite handy for experimentation and quickly making changes to recover from production incidents (<em>provided you know what you\u2019re\u00a0doing</em>).</p><p>The server config file postgresql.conf shouldn\u2019t be treated as a source of truth. Instead check the values by querying the pg_settings view. In any case, it\u2019s always recommended to update the config file for permanent changes.</p><p>When inspecting config values, don\u2019t forget to consider the implicit\u00a0units.</p><p>These are just a few useful things about postgresql configuration. For more comprehensive info on the subject, the official documentation is your friend\u200a\u2014\u200a<a href=\"https://www.postgresql.org/docs/current/runtime-config.html\">https://www.postgresql.org/docs/current/runtime-config.html</a>.</p><p><em>Thanks to </em><a href=\"https://medium.com/u/93c26ced7936\"><em>Narendra Pal</em></a><em> and Somya Maithani for reviewing the\u00a0drafts.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=78dc43150be9\" width=\"1\" /><hr /><p><a href=\"https://medium.com/helpshift-engineering/updating-postgresql-server-config-78dc43150be9\">Updating PostgreSQL server config</a> was originally published in <a href=\"https://medium.com/helpshift-engineering\">helpshift-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Twitch": {
    "title": "ThisEmoteDoesNotExist: Training a GAN for Twitch Emotes",
    "xmlUrl": "https://medium.com/feed/twitch-news/tagged/engineering",
    "htmlUrl": "https://blog.twitch.tv/tagged/engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/twitch-news/tagged/engineering",
      "value": "ThisEmoteDoesNotExist: Training a GAN for Twitch Emotes"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/twitch-news/thisemotedoesnotexist-training-a-gan-for-twitch-emotes-a742b6354b73?source=rss----3ae745429979--engineering"
      }
    ],
    "link": "https://medium.com/twitch-news/thisemotedoesnotexist-training-a-gan-for-twitch-emotes-a742b6354b73?source=rss----3ae745429979--engineering",
    "id": "https://medium.com/p/a742b6354b73",
    "guidislink": false,
    "tags": [
      {
        "term": "machine-learning",
        "scheme": null,
        "label": null
      },
      {
        "term": "twitch",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "neural-networks",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Avery Gnolek"
      }
    ],
    "author": "Avery Gnolek",
    "author_detail": {
      "name": "Avery Gnolek"
    },
    "published": "Wed, 24 Jul 2019 22:05:46 GMT",
    "published_parsed": [
      2019,
      7,
      24,
      22,
      5,
      46,
      2,
      205,
      0
    ],
    "updated": "2019-07-24T22:05:46.660Z",
    "updated_parsed": [
      2019,
      7,
      24,
      22,
      5,
      46,
      2,
      205,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/twitch-news/tagged/engineering",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xSaxmCkvWhkftSwuNv3tFA.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9Vd2r97WwGL_4v4kHGCnNg.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*__bFFGZ2NwhsHqcmkitzww.png\" /></figure><p>The idea for this project began when a coworker and I were talking about NVIDIA\u2019s photo-realistic generated human faces using StyleGAN and they mentioned \u201cI wish someone made one of those for Twitch emotes.\u201d I had always wanted to take some time to learn more about convolution neural networks and was in the middle of a machine learning project for work, so it seemed like trying to build this would be a quick and relevant personal\u00a0project.</p><p><strong>The original plan (with my time estimates):</strong></p><ol><li>Scrape all of the Twitch emote image assets (1\u00a0day)</li><li>Write a progressive growing GAN implementation using Keras as a proof of concept (1\u00a0week)</li><li>Adapt the emote dataset for use with a real research-caliber GAN implementation (1\u20132\u00a0days)</li><li>Train the GAN on the emote dataset (1\u00a0day)</li></ol><p><strong>1\u00a0. Scrape all of the emote image\u00a0assets</strong></p><p>This part of the project was actually quite straightforward. Twitch stores all of the emote images on a CDN using a monotonically increasing numeric <em>emote_id. </em>Each emote is available in three different sizes (1.0, 2.0, 3.0) corresponding to the resolutions of 28x28, 56x56, and\u00a0112x112.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/224/1*OJoswWAIcMqT7q2eIqhAlw.png\" /><figcaption><a href=\"https://static-cdn.jtvnw.net/emoticons/v1/778927/1.0\">emoticons/778927/1.0</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/224/1*ms3xJb9u0CSr2Xgn9bsjJQ.png\" /><figcaption><a href=\"https://static-cdn.jtvnw.net/emoticons/v1/778927/2.0\">emoticons/778927/2.0</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/224/1*xGZnSkVqweVUGUxeO-d3eQ.png\" /><figcaption><a href=\"https://static-cdn.jtvnw.net/emoticons/v1/778927/3.0\">emoticons/v1/778927/3.0</a></figcaption></figure><p>I wrote a quick python scraper which would go through ~2 million <em>emote_ids </em>of three different sizes and download the images locally. Even at a modest 200 requests per second, this was able to finish overnight. In fact, I think the limiting factor for the speed of this step was actually writing the image files to my HDD, not the network requests themselves. So far, I was right on track with my time estimate.</p><p><strong>2. Write a progressive growing GAN implementation using Keras as a proof of\u00a0concept</strong></p><p>As I had no experience with CNNs or deep learning before this project, I wanted to at least attempt to write a progressive growing GAN myself as a way to learn before switching to an existing implementation. As Twitch emotes are not even power of two sizes, it was not possible to exactly replicate the 4x4 pixel to 128x128 pixel growing architecture used by <a href=\"https://arxiv.org/pdf/1710.10196.pdf\">Karras</a>. Instead, I chose to start off with a 7x7 base convolution layer, and then gradually double the image size up to 112x112 pixels using repeated Upsample + 3x3 Conv + 3x3 Conv block layers. The higher resolution layers were slowly faded in using a weight factor as the GAN increased output resolutions. The mirror of this architecture was used for the discriminator. This GAN used a random 200k sample of the 2 million emotes as the training\u00a0data.</p><p>The low resolution images produced by this GAN showed some promise. They had a rough visually consistent color scheme within each generated emote and displayed early signs of creating faces. You can see this in the bottom-right corner generated emote in the figure below. When the generated emotes were compared side-by-side with down-scaled real emotes, it was not trivial to determine if an emote was generated or came from the training\u00a0data.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/594/1*iFhffMognATJ2wpnyYc1tQ.png\" /><figcaption>Generated emotes (Left) and down-scaled real emotes (Right) at 7x7 pixel resolution</figcaption></figure><p>With promising results on the lowest resolution, I began to allow my GAN to grow to larger sized emotes. At this resolution, the generated emotes were definitely more discernible from the training data. However, they were also developing more complex shapes and the beginnings of real faces. I attempted to continue to grow the output resolution of the\u00a0GAN.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lakCc5RehVa6XKiNR3D5wA.png\" /><figcaption>Generated Emotes after Stage 1 (7x7, Left) and Stage 2 (14x14,\u00a0Right)</figcaption></figure><p>However, my architecture was not able to reliably grow the generated image resolution above 14x14 pixels. All attempts to grow the generator to produce 28x28 pixel images led to generator collapse. At this time, I decided to move to an existing GAN implementation to see how the results would compare. Looking back, my original implementation was fading in the weights for the new higher resolution layers much too rapidly. However, later attempts to correct this after the fact by increasing the fade in time were not able to prevent the collapse. Instead, this just prolonged how long it took for the collapse to\u00a0occur.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1dG99hx0bupdOEOeE54qag.png\" /><figcaption>Generator collapse during Stage 3 growth\u00a0(28x28)</figcaption></figure><p>Although this step was unsuccessful at being able to produce full resolution emotes, I felt as though it gave me a necessary introduction to CNNs and was good preparation for the rest of the\u00a0project.</p><p>In total, this section took ~3 weeks from end-to-end. A majority of this was spent developing the initial custom network architecture and trying to correct GAN collapse problems.</p><p><strong>3. Adapt the emote dataset for use with a real research-caliber GAN implementation</strong></p><p>I decided to use the Tensorflow implementation of a progressive growing GAN provided <a href=\"https://github.com/tkarras/progressive_growing_of_gans#progressive-growing-of-gans-for-improved-quality-stability-and-variation-official-tensorflow-implementation-of-the-iclr-2018-paper\">here</a>. There were three main reasons for picking this specific GAN, given the huge diversity of different GAN architectures available.</p><p>The first reason was that this implementation had a proven history of being able to generate very high resolution images on diverse datasets, far above the resolution of what I would need for my emote dataset. Given the trouble I had consistently growing the output resolution of my own GAN, I wanted to see if this more complex implementation would be able to resolve these\u00a0issues.</p><p>Secondly, this GAN\u2019s ability to progressively grow the generator\u2019s image output resolution would dramatically reduce the training time, as the first few low resolution stages would complete very quickly. For reference, it took an equal amount of time to grow the GAN from an output resolution of 4x4 to 64x64 as it took to grow from 64x64 to 128x128. This meant that I could very quickly inspect low resolution results before committing to continue training the GAN up to much higher resolutions.</p><p>Finally, this GAN had significant tooling already in place for dataset generation and output visualization that I would be able to leverage. This made it easier to compose new datasets and validate results. This allowed me to create the first version of the of the training dataset in one\u00a0night.</p><p>As this GAN required square image sizes, I choose to pad the Twitch emotes from 112x112 to 128x128 with white background. For the first test, I choose another random 200k sample of the full dataset and started the training.</p><p><strong>4. Train the GAN on the emote\u00a0dataset</strong></p><p>After 72 hours of training locally on my GTX 1070, the GAN had grown to the full output resolution of 128x128. I opened up the results directory, awaiting my emotes. The actual results\u00a0were\u2026</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*wTFZvZqafU700om0A8IZsA.png\" /></figure><p>\u2026 a bit of a mess. These were certainly far better than what my GAN was able to achieve, but most of the generated emotes were composed of disjointed text, blurred blob faces, and a melting mix of colors. Not exactly the photo-realism that I had been promised!</p><p>I realized very quickly that the problem wasn\u2019t the GAN itself, but the training\u00a0set.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rfnIo7SwuSCOj9apvEdTyQ.png\" /><figcaption>Sample of the initial training\u00a0dataset</figcaption></figure><p>After pulling together a sample of the training emotes actually being fed into the neural network, it was clear that this jumble of unrelated images did not provide a clear set of features which could be learned by the GAN. The mix of cartoon-style faces, \u201crealistic\u201d faces, text, anthropomorphic random objects and hearts had so much variety that the GAN was forced to over-generalize to all styles, leaving it unable to produce high quality images within a specific style. <strong>A GAN is not magic, it still requires a clear visual pattern which can be learned in order to produce high quality\u00a0images.</strong></p><p>One interesting idea for future GAN research is developing an algorithm to train Progressive GANs that learns to automatically cluster implicit styles in the training data. This would allow GANs to be trained on mixed-style datasets directly, instead of requiring additional filtering steps to separate these datasets into their component styles before training.</p><p>I believe this issue was further exacerbated due to the GAN including a minibatch standard deviation layer at the end of the discriminator. This layer was meant to increase the variation in the images generated by the GAN by allowing the discriminator to easily discriminate against generated minibatches of images which have low variation. This was included in the original implementation to prevent the GAN from converging to a single local optimum face when trained on sets of human faces (Celeba-HQ) which were all visually similar. Given the huge variation of the emote training dataset, this layer effectively forced the generator to over-generalize, sacrificing image quality and visual consistency for image diversity.</p><p>With this in mind, I decided to create a more consistent dataset for a subset of the emotes available.</p><p><strong>5.1 Moving towards a more consistent dataset</strong></p><p>On Twitch, there are two main parts of metadata about an emote. The first, <em>emote_id </em>is the actual unique id that is used to reference an emote and was used for the data scraping in step 1. This id is never exposed to an actual Twitch user, as it is only used on the backend. Instead, there is a second identifier; <em>emote_code, </em>which is what users type in chat to get an emote to show up. This <em>emote_code</em> is actually composed of two parts, the <em>emote_prefix</em> and <em>the_part_that_isnt_the_prefix (emote_suffix? emote_remainder?).</em> All <em>emote_codes</em> for a given Twitch broadcaster will share the same <em>emote_prefix</em>. However, the rest of the <em>emote_code </em>is customizable<strong> </strong>by the broadcaster when they upload an new\u00a0emote.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/607/1*XClsxoFJO5zIpbK9Ugc8Dg.png\" /><figcaption>Three emotes for <a href=\"https://www.twitch.tv/thesushidragon\">thesushidragon</a> showing the consistent emote_prefix</figcaption></figure><p>What you will quickly realize using Twitch is that many different broadcasters have emotes with the same <em>emote_suffix.</em> Although the exact emotes can be very different, the general visual styles appeared to be roughly consistent. My first thought was using these shared <em>emote_suffixes </em>to build a better dataset upon which to train the GAN. The only concern was that there would not be enough emotes with the exact same <em>emote_suffix </em>to allow the GAN to learn a generalized emote style instead of learning to reproduce the exact training images from the limited dataset as closely as possible. After a few SUBSTRINGs and GROUP BYs, I had the following table:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/188/1*KLVrtrpMAfLf8NeX5VdoxA.png\" /></figure><p>The top few <em>emote_suffixes </em>would definitely have enough data, so I chose \u201cHype\u201d as the first <em>emote_suffix </em>to try and rebuilt another dataset with just those emotes. A sample of that training dataset follows\u00a0below:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-wIYLCtJtJTu3LTDlV1vog.png\" /><figcaption>Sample of the \u201cHype\u201d training\u00a0data</figcaption></figure><p>Although there was still a significant amount of variation between different emotes, this was looking a lot better and I felt confident to try it as a proof of concept. I fed these into the GAN and came back after a day to look at the partially trained 64x64 resolution network.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JLrehJs0bJNR4S0xdx_RMw.png\" /><figcaption>Generated images from the partially trained 64x64 resolution \u201cHype\u201d\u00a0dataset</figcaption></figure><p>These were developing faces and the \u201chype\u201d text was clearly recognizable, so this was definitely better than the first training attempt. However, many of generated emotes had the \u201chype\u201d text mirrored from right-to-left instead of left-to-right. This didn\u2019t occur in the training dataset at all, and it was very clearly the whole word reversed, not just a single letter. This told me that there was something wrong within the GAN itself. After digging through the code, I found a config parameter called <em>train_mirror_augment</em> which should have defaulted to <em>false </em>but was accidentally overridden to <em>true </em>when I copied configuration data from another dataset\u2019s configuration. This brings me to the first major lesson learned from this\u00a0project:</p><h3>Validate the configuration parameters match exactly what you expect before every single training\u00a0run.</h3><p>This was the first of multiple times I had to spend a bunch of time on issues that were caused by improper configuration. Many of these caused performance problems that were not immediately noticed, wasting both my debugging time and potential GAN training time. Although it may seem excessive, breaking out the debugger and stepping right up to the first training epoch to inspect any configuration data for the first few training cycles will help catch a lot of small problems that would otherwise stick around for a while. In the words of\u00a0<a href=\"https://karpathy.github.io/2019/04/25/recipe/\">Andrej</a>:</p><blockquote>Neural net training fails\u00a0silently</blockquote><blockquote>When you break or misconfigure code you will often get some kind of an exception. You plugged in an integer where something expected a string. The function only expected 3 arguments. This import failed. That key does not exist. The number of elements in the two lists isn\u2019t equal. In addition, it\u2019s often possible to create unit tests for a certain functionality.</blockquote><blockquote>This is just a start when it comes to training neural nets. Everything could be correct syntactically, but the whole thing isn\u2019t arranged properly, and it\u2019s really hard to tell. The \u201cpossible error surface\u201d is large, logical (as opposed to syntactic), and very tricky to unit test\u00a0\u2026 Therefore, your misconfigured neural net will throw exceptions only if you\u2019re lucky; Most of the time it will train but silently work a bit\u00a0worse.</blockquote><p>With the mirror augment fixed, I fired up another training iteration.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YmwZt9p4tO1cGT7Jn2Ouqw.png\" /><figcaption>Generated \u201cHype\u201d emotes, round\u00a02</figcaption></figure><p>The text direction was fixed and it was actually pretty readable, but the remainder of the image still had that amorphous blob look. In general, the training emotes fell into three different categories:</p><ol><li>\u201cHype\u201d on the top of the image with something below\u00a0it</li><li>\u201cHype\u201d or \u201cSub Hype\u201d all alone on a white background</li><li>\u201cHype\u201d on the bottom of the image with something above\u00a0it</li></ol><p>As as last ditch effort, I manually curated a dataset of only emotes from category 3, the retrained the GAN on this. This greatly stabilized the general structure of the generated emotes, even if a faces were still blurry\u00a0messes.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PwNLLoMyUFkBjuFnNZquIw.png\" /></figure><p><strong>5.2 Just the faces,\u00a0please</strong></p><p>Seeing how a more consistent training dataset had been able to stabilize the generated hype emotes, my next goal was removing all of non-faces from the original dataset. I pulled down the <a href=\"https://github.com/ageitgey/face_recognition\">face_recognition</a> python library, with uses a pre-trained CNN to detect the position of faces in an image. After running this for a few hours, I was left with a filtered dataset of ~400k images each containing exactly one face. This collection of images will subsequently be referred to as the \u201cface dataset\u201d and formed the base for the remainder of this project. The strength of this library is that it not only provides a bounding box for the face, but also the locations of 68 specific landmark points. These can be used for further filtering on the details of the\u00a0image.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/414/1*96UT-D8uSXjlnyvs9DZTog.png\" /><figcaption>Landmark points provided by face_recognition</figcaption></figure><p>For most emotes, the locations of these landmark points were highly accurate.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/243/1*3uWlmcKaviPrGV2ZnUvuag.png\" /><figcaption>\u201cKappaHD\u201d before and after being run through face_recognition</figcaption></figure><p>I chose specific locations for the left eye, right eye, and bottom of the chin (points 36, 45, and 8 in the diagram above), then filtered the face dataset to only emotes which had similar locations for their corresponding facial landmarks. My intuition was that these emotes would all share similar poses, even if the exact content of the emote was different. I kicked off the GAN training, and in three days came back to a bunch of people looking\u00a0left.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EqBunLTLbulmSYY4RGywOg.png\" /><figcaption>Generated emotes from the GAN trained on one single consistent pose</figcaption></figure><p><em>People </em>may have been a bit of an exaggeration, but these were looking better than anything I had been able to produce before. The removal of emotes with no faces as well as the consistent pose had really improved the quality. In fact, some of them were looking <em>too\u00a0</em>good.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/233/1*nxFIeoseFfVb4c6UxdgfJw.png\" /></figure><p>Somehow the GAN had been able to create nearly pixel-perfect replications of this emote. I had remembered seeing the yellow haired emote in the training dataset, but there was no clear reason at first why this one looked so much better. However, the fact that I could even remember the emote from the dataset was weird, since I definitely didn\u2019t remember nearly any of the other thousands of\u00a0emotes.</p><p>Digging in more, the problem revealed itself\u200a\u2014\u200aduplication. Since Twitch has no validation to ensure that emotes were distinct, there were multiples copies of many emotes. This duplication would most frequently occur if someone uploaded an new emote multiple times, slightly adjusting the cropping or color when testing what it would look like. This particular yellow-haired emote was massively duplicated, being fed through the GAN during training far more than the typical emote. This over-weighting was strong enough converge the GAN to a local optimum, producing a near perfect replication of this specific\u00a0emote.</p><p>Luckily, face_recognition provides a way to detect similar faces. Along with the position of <em>face_landmarks</em>, a <em>face_encoding </em>is output which should be nearly identical for all faces of the same person. You can read more about the ResNet CNN which is behind this encoding <a href=\"http://blog.dlib.net/2017/02/high-quality-face-recognition-with-deep.html\">here</a>. Since duplicate faces are likely to have similar <em>emote_ids </em>(due to being uploaded at nearly the same time), I ran a window function over the images sorted by <em>emote_id. </em>This compared the <em>face_encoding </em>values for all faces within a 1000 emote window to detect those which were near identical. The window size of 1000 was chosen empirically based on the max difference in observed <em>emote_ids </em>for duplicated emotes.</p><p>Out the ~400k face emotes, this identified ~20k which were duplicated. After confirming these were actually duplicates via brief visual inspection, these emotes were purged from the\u00a0dataset.</p><p><strong>5.3 Filters, Filters,\u00a0Filters</strong></p><p>After seeing how filtering the dataset based on the position of specific <em>face_landmarks </em>was<em> </em>able to stabilize the training, I removed the original <em>face_landmarks </em>filter and created four new\u00a0rules:</p><ol><li>Emotes should include between 20% and 50% white space. Emotes with more than 50% white space were usually text miscategorized as faces or were just the outlines of faces. Emotes with less than 20% whitespace were too zoomed in or had large colored backgrounds.</li><li>The chin position of the face (point 8) should be roughly vertically centered and near the bottom of the emote. Although this would filter out a few good training images which had slightly strange face positions, many of the faces which failed this rule had small faces with vertical text next to\u00a0them.</li><li>The size of the bounding box for each face should be between 50x50 and 90x90 pixels. Faces smaller than 50x50 were usually not the main focus of the emote. Faces larger than 90x90 were too zoomed in to be\u00a0usable.</li><li>None of the <em>face_landmark </em>points should fall outside of the bounds of the emote (112x112 pixels). This was also adapted to combat very zoomed in faces or emotes which had highly cropped\u00a0faces.</li></ol><p>The intersection of these rules formed a new dataset. These were composed into a new training set and I soon began to see much more promising results.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Ga28Duqn4wFsYGEHS4FQLA.png\" /><figcaption>First attempt at a rules-based approach for dataset filtering</figcaption></figure><p>I was particularly happy with these six, as they were either highly realistic or showed the ability of the GAN to generalize non-face features (headphones and sunglasses)</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/714/1*ZhKeIdAmYHO8jXxLHQ8rDg.png\" /></figure><p>This brings me to my second major lesson learned from this\u00a0project:</p><p><strong>Training dataset inspection is incredibly helpful at identifying sources of problems and can drastically improve the results generated by a\u00a0GAN</strong></p><p>When you do this, it is very easy to determine if you (as a human) can see a consistent pattern across most of the training data. If there are training images which you think are not good representative examples or are unlikely to contribute to the GAN\u2019s generalization learning, build an algorithm to filter them\u00a0out.</p><p>Of course, this approach works best when you have significantly more data than you actually need for training and can be picky about which subset of the dataset to train on. Since the de-duplicated face dataset had ~390k images to choose from and only ~30k or less were needed for training, it was worthwhile to trade recall for precision and create loose rules which would potentially filter out \u201cgood\u201d emotes, so long as the majority of emotes removed by a rule were \u201cbad\u201d. In doing this, the relative proportion of \u201cgood\u201d emotes in the training dataset would increase with the addition of each additional rule. Adding new rules followed this general\u00a0pattern:</p><ol><li>Look through the training data and find a few instances of emotes which are not high quality faces or have other noise that would likely degrade the quality of the generated GAN\u00a0emotes</li><li>Create a rule which would filter these\u00a0out</li><li>Run the rule against the entire remaining dataset and keep track of all emotes which would be filtered out by the new\u00a0rule</li><li>Quickly visually inspect the filtered out emotes to make sure a majority of them were\u00a0\u201cbad\u201d</li><li>Run the rule against the entire remaining dataset and keep only the emotes which would <em>not</em> be filtered out by the new\u00a0rule</li><li>Repeat steps 1 -5 until the quality and consistency of the training data has improved enough that you feel confident rerunning the GAN\u00a0training</li></ol><p>As a next step, two new rules were added. These were aimed at stabilizing the color scheme of the dataset by requiring that 90% of the pixels in every image be made of white, black, or skin-tone colors. In addition, no large portion of any emote could be gray. These rules were remarkable effective at improving the stability and realism of the generated emotes:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qDOqx8vt492U5MSQF3KdeA.png\" /><figcaption>Generated emotes after filtering very vivid colored emotes out of the training\u00a0data</figcaption></figure><p>One interesting realization from this is that the generated emotes with their entire faces blurred are actually <em>intentionally </em>produced by the GAN, as these blurry emotes occur with some frequency in the training dataset. The reason for this is that not all Twitch broadcasters provide full 112x112 resolution images for their emotes. Twitch requires uploading all three image resolutions when creating an emote, but some people choose to just upscale low resolution images instead of providing native 112x112 resolution assets. This degraded image quality is then replicated by the\u00a0GAN.</p><p>In addition, some generated emotes still had strange block-like artifacts. I believed that these artifacts were caused by the presence of text within emotes in the training dataset. Although emotes which were <em>only </em>text had almost entirely been filtered out by the addition of the prior rules, there were still some emotes that had small portions of text within the emote, usually above or below the\u00a0face.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/792/1*o2d4Fv4Y9D21lVRbgcV6eA.png\" /><figcaption>Generated Emotes with Artifacts (Left) and face emotes EAST identified as containing text (Right). The teal outlines show the bounding boxes for the detected\u00a0text</figcaption></figure><p>To remove these text emotes, I ran <a href=\"https://github.com/argman/EAST\">this implementation</a> of <a href=\"https://arxiv.org/abs/1704.03155v2\">EAST</a> over the training dataset, then removed any emotes which were detected to contain text. EAST is an <strong>E</strong>fficient and <strong>A</strong>ccurate<strong> S</strong>cene <strong>T</strong>ext detector which uses a combination of both a CNN and NMS merging stage to detect text at any orientation. This filtered out ~1k face emotes which also contained some text. The GAN was then retrained, but the results did not show much of a significant change after the removal of the text. The majority of the artifacts were gone, but it appeared that question marks alone were not detected by EAST, as one of the generated emotes showed this\u00a0feature.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zIF4a3KllqwkwOAdloAJng.png\" /><figcaption>Generated emotes after removing text from training\u00a0images</figcaption></figure><p><strong>5.4 Moving training to the cloud with AWS Deep learning\u00a0AMIs</strong></p><p>Prior to this point, I had been training on my home computer using a GTX 1070. This took ~1 day to grow the resolution of the GAN output to 64x64, and a further 2 days to grow to 128x128. This meant that I was unable to rapidly iterate on new training datasets or try multiple examples at\u00a0once.</p><p><strong>More importantly, I had to turn my graphics settings to <em>low </em>when playing video games.</strong> The graphics card was unable to handle 70% CUDA utilization and high resolution gaming at the same time, as it would frequently run into GPU memory allocation issues which required me to restart GAN training from the last checkpoint.</p><p>Because of this, I moved to training using AWS deep learning AMIs on GPU-accelerated EC2 instances. I choose to use thep3.2xlarge instance type, which includes one NVIDIA\u00ae V100 GPU. This reduced my training time from the aforementioned 3 days to almost exactly 24\u00a0hours.</p><p>However, this also increased my training cost from $0/hour to $3.06/hour. Although this is inexpensive compared to buying a V100 for <a href=\"https://www.amazon.com/PNY-TCSV100MPCIE-PB-Nvidia-Tesla-v100/dp/B076P84525\">$6718</a>, at ~75$ for each end-to-end training I certainly began to put more focus on pre-training dataset validation and testing. After moving to AWS, my new training workflow\u00a0became:</p><ol><li>Create dataset locally, push to\u00a0S3</li><li>Start the EC2 deep learning instance and ssh into\u00a0it</li><li>Pull down the dataset from S3 onto the instance, git clone the GAN repo, start training using\u00a0<a href=\"https://linux.die.net/man/1/screen\">screen</a></li><li>Come back in 24 hours, copy the trained NN checkpoint files to my local machine using\u00a0pscp</li><li>Kill the EC2\u00a0instance</li></ol><p>A significant amount of this manual work could have been automated, but I never expected to run so many different training iterations that the cost of automating this would have paid\u00a0off.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/404/1*r_-_ZWam5n6mQn0o121-6g.png\" /><figcaption><a href=\"https://xkcd.com/1319/\">https://xkcd.com/1319/</a></figcaption></figure><p>Outside of the improved training performance, the strong advantage I saw from using EC2 with deep learning AMIs is that all of the configuration work was already complete. The only thing left to do when connecting to any of the hosts was run source activate tensorflow_p36 then python train.py. This was a stark contrast to the many early hours I spent on this project properly installing the CUDA toolkit, getting the correct drivers, and managing python packages and their own dependencies on specific Tensorflow and CUDA versions. I considered using a Tensorflow Docker image to simplify this configuration work, but at that point I already had everything working locally and the thought of making any new changes which could potentially tip over the house of cards that was my local development stack seemed unattractive.</p><p><strong>5.5 Using the discriminator to improve data\u00a0quality</strong></p><p>At this point, I started struggling with new programmatic ways to improve the dataset quality. New rule-based approaches had low precision, filtering out too many good emotes along with the bad. However, there was still a non-trivial proportion of low quality emotes, far too many to remove by hand. The goal was to build a more complex system to be able to detect these and remove them from the training dataset. While coming up with ideas, I realized that I already had something that could work for this\u00a0task.</p><p>Although the GAN trained two neural networks, a discriminator and generator, only the generator was actually used. The discriminator was discarded after training, as it was no longer needed to synthesize emotes.</p><p>While training a GAN, the purpose of the discriminator is to detect which emotes come from the training set and which are generated by the generator. As such, the discriminator become very adapt at detecting \u201cstrange\u201d images which do not match the patterns found in the majority of the training data. This is used during training to update the generator\u2019s weight to produce better quality\u00a0images.</p><p>I took the training dataset and fed every emote through the trained discriminator. The output of this was a score for each emote ranging from -100 to 100. This score indicated the discriminator\u2019s belief that the emote came from the training dataset (100) or was generated (-100). The scores for the training emotes were roughly normally distributed, having a large center cluster and tail of outliers with both very positive and very negative scores. Interestingly, the mean score for the training emotes was only weakly positive.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/965/1*DlROP2WFq9X53U86JEzdew.png\" /></figure><p>I then visually inspected the emotes which were scored at the extreme ends of this range. Training emotes which scored very low (below 0) were generally overly simplified, heavily rotated, did not have a very clear face in the image, or had text in the image that EAST had missed. These were removed from the\u00a0dataset.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/568/1*UKQfVhq-dMaJTirdbKlWbw.png\" /><figcaption>Low-scored Emotes using the discriminator</figcaption></figure><p>On the opposite side, the very high-scored emotes were also useful to remove. Although these were generally high quality faces, they were plagued by another problem\u200a\u2014\u200aduplication.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/419/1*Ftz9bH5H4JxgB0d5_NDADA.png\" /><figcaption>High-scored emotes using the discriminator</figcaption></figure><p>Each of these emotes were duplicated dozens of times in the dataset. As discussed prior, this duplication caused training to drastically over-weight the features from these emotes. This could be observed in the generated emotes from the last training\u00a0run.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/139/1*eqa_m5ZATLritsVYnDRuyg.png\" /></figure><p>The reason that these were not able to be filtered out during the previous image-deduplication was that they were uploaded many days apart. As such, their drastically different <em>emote_ids</em> would fall outside of the 1000 emote width window function when the duplication detection code was run. These were also removed from the dataset and training was\u00a0re-run.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Jxz3gC87PlbN2GwjFhQKaw.png\" /><figcaption>Generated emotes after removing extreme scores from the training\u00a0data</figcaption></figure><p>I wonder if this approach of leveraging the trained discriminator to provide useful work outside of the training backpropagation step could be applied more broadly for other aspects of GAN training. One potential use of the trained discriminator is automatically adjusting the composition of the data during training in order to speed GAN convergence. Being able to identify which specific training examples are providing most of the \u201clearning\u201d would allow you to dis-proportionally feed these though the GAN, potentially improving the training\u00a0rate.</p><p>At this point, I felt as though the improvements in generated emote quality had slowed enough that small iterative changes was unlikely to lead to further realism. As such, I chose to move on and create new GAN training datasets using the lessons learned from trying to synthesize realistic faces.</p><p><strong>5.6 Cartoon Emotes and Wide\u00a0Emotes</strong></p><p>Up next was attempting to generate cartoon-style emotes. The approach for these was generally similar to the one described for realistic face emotes, with one important exception\u200a\u2014\u200aemotes were only included in the training dataset if they (1) had a low number of distinct colors and (2) had a large fraction of the total image space composed of only a few of distinct colors. These two rules were remarkably effective at filtering cartoon-style emotes. The results of this are shown\u00a0below:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*r5L5667czWGQ_tk8xW32lw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QKaI9B-8V5rI-_PP4ntMXw.png\" /><figcaption>Cartoon-style generated emotes</figcaption></figure><p>Furthermore, the GAN for these emotes was able to linearly interpolate across different input noise vectors with relative smoothness.</p><a href=\"https://medium.com/media/065f08067d0f3b3bfe554e7933ffb91a/href\">https://medium.com/media/065f08067d0f3b3bfe554e7933ffb91a/href</a><a href=\"https://medium.com/media/d55d0eacca9e55ecb6c58cae674a6648/href\">https://medium.com/media/d55d0eacca9e55ecb6c58cae674a6648/href</a><p>Up next was wide emotes. The only main change to the filtering rules for this was removing the prior face size and whitespace restrictions and prioritizing faces whose bounding box filled almost all of the\u00a0image.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7zHSf_X3Z5xn-Wlu660fiQ.png\" /><figcaption>Generated \u201cwide\u201d\u00a0emotes</figcaption></figure><p>These emotes actually had the most smooth linear interpolations, as the placement of facial features was very consistent across all\u00a0emotes.</p><a href=\"https://medium.com/media/15eb666ca2e7f42f37ec9bc0083a3b74/href\">https://medium.com/media/15eb666ca2e7f42f37ec9bc0083a3b74/href</a><p><strong>6. Next steps and final reflections</strong></p><p>In total, what I originally estimated as a short 2 week project ended up taking about 2 months by the time the last GAN was finished training. This brings me to the last major lesson learned from this\u00a0project:</p><p><strong>Many small improvements can combine together to create a great result, focus on making one good change at a\u00a0time</strong></p><p>Given the initial lack of high quality results with both my custom GAN implementation and the progressive growing GAN, it was tempting to shelve the project. I knew that there was a lot of work that needed to be done, and I didn\u2019t have clear steps forward on what would be the best approach. Instead of trying complicated ideas to fix all the problems at once, focusing on making single iterative improvements (1) unblocked progress and (2) stopped any analysis paralysis.</p><p>Overall I am quite happy with how this project has turned out and the diversity of emotes that were able to be synthesized. I don\u2019t think I\u2019ll be able to compete with human emote artists anytime soon, but maybe with some dedicated research dollars we can change this. In the meantime, I\u2019ll say bye in the most succinct way I\u00a0can.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/128/1*BhepSwAT9jGre1rEMf6ZHQ.png\" /></figure><p>If you enjoyed this, feel free to <a href=\"https://medium.com/@agnolek\">follow me on Medium</a> or <a href=\"https://www.linkedin.com/in/averygnolek/\">connect on LinkedIn</a>!</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a742b6354b73\" width=\"1\" /><hr /><p><a href=\"https://medium.com/twitch-news/thisemotedoesnotexist-training-a-gan-for-twitch-emotes-a742b6354b73\">ThisEmoteDoesNotExist: Training a GAN for Twitch Emotes</a> was originally published in <a href=\"https://medium.com/twitch-news\">Twitch Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xSaxmCkvWhkftSwuNv3tFA.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9Vd2r97WwGL_4v4kHGCnNg.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*__bFFGZ2NwhsHqcmkitzww.png\" /></figure><p>The idea for this project began when a coworker and I were talking about NVIDIA\u2019s photo-realistic generated human faces using StyleGAN and they mentioned \u201cI wish someone made one of those for Twitch emotes.\u201d I had always wanted to take some time to learn more about convolution neural networks and was in the middle of a machine learning project for work, so it seemed like trying to build this would be a quick and relevant personal\u00a0project.</p><p><strong>The original plan (with my time estimates):</strong></p><ol><li>Scrape all of the Twitch emote image assets (1\u00a0day)</li><li>Write a progressive growing GAN implementation using Keras as a proof of concept (1\u00a0week)</li><li>Adapt the emote dataset for use with a real research-caliber GAN implementation (1\u20132\u00a0days)</li><li>Train the GAN on the emote dataset (1\u00a0day)</li></ol><p><strong>1\u00a0. Scrape all of the emote image\u00a0assets</strong></p><p>This part of the project was actually quite straightforward. Twitch stores all of the emote images on a CDN using a monotonically increasing numeric <em>emote_id. </em>Each emote is available in three different sizes (1.0, 2.0, 3.0) corresponding to the resolutions of 28x28, 56x56, and\u00a0112x112.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/224/1*OJoswWAIcMqT7q2eIqhAlw.png\" /><figcaption><a href=\"https://static-cdn.jtvnw.net/emoticons/v1/778927/1.0\">emoticons/778927/1.0</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/224/1*ms3xJb9u0CSr2Xgn9bsjJQ.png\" /><figcaption><a href=\"https://static-cdn.jtvnw.net/emoticons/v1/778927/2.0\">emoticons/778927/2.0</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/224/1*xGZnSkVqweVUGUxeO-d3eQ.png\" /><figcaption><a href=\"https://static-cdn.jtvnw.net/emoticons/v1/778927/3.0\">emoticons/v1/778927/3.0</a></figcaption></figure><p>I wrote a quick python scraper which would go through ~2 million <em>emote_ids </em>of three different sizes and download the images locally. Even at a modest 200 requests per second, this was able to finish overnight. In fact, I think the limiting factor for the speed of this step was actually writing the image files to my HDD, not the network requests themselves. So far, I was right on track with my time estimate.</p><p><strong>2. Write a progressive growing GAN implementation using Keras as a proof of\u00a0concept</strong></p><p>As I had no experience with CNNs or deep learning before this project, I wanted to at least attempt to write a progressive growing GAN myself as a way to learn before switching to an existing implementation. As Twitch emotes are not even power of two sizes, it was not possible to exactly replicate the 4x4 pixel to 128x128 pixel growing architecture used by <a href=\"https://arxiv.org/pdf/1710.10196.pdf\">Karras</a>. Instead, I chose to start off with a 7x7 base convolution layer, and then gradually double the image size up to 112x112 pixels using repeated Upsample + 3x3 Conv + 3x3 Conv block layers. The higher resolution layers were slowly faded in using a weight factor as the GAN increased output resolutions. The mirror of this architecture was used for the discriminator. This GAN used a random 200k sample of the 2 million emotes as the training\u00a0data.</p><p>The low resolution images produced by this GAN showed some promise. They had a rough visually consistent color scheme within each generated emote and displayed early signs of creating faces. You can see this in the bottom-right corner generated emote in the figure below. When the generated emotes were compared side-by-side with down-scaled real emotes, it was not trivial to determine if an emote was generated or came from the training\u00a0data.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/594/1*iFhffMognATJ2wpnyYc1tQ.png\" /><figcaption>Generated emotes (Left) and down-scaled real emotes (Right) at 7x7 pixel resolution</figcaption></figure><p>With promising results on the lowest resolution, I began to allow my GAN to grow to larger sized emotes. At this resolution, the generated emotes were definitely more discernible from the training data. However, they were also developing more complex shapes and the beginnings of real faces. I attempted to continue to grow the output resolution of the\u00a0GAN.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lakCc5RehVa6XKiNR3D5wA.png\" /><figcaption>Generated Emotes after Stage 1 (7x7, Left) and Stage 2 (14x14,\u00a0Right)</figcaption></figure><p>However, my architecture was not able to reliably grow the generated image resolution above 14x14 pixels. All attempts to grow the generator to produce 28x28 pixel images led to generator collapse. At this time, I decided to move to an existing GAN implementation to see how the results would compare. Looking back, my original implementation was fading in the weights for the new higher resolution layers much too rapidly. However, later attempts to correct this after the fact by increasing the fade in time were not able to prevent the collapse. Instead, this just prolonged how long it took for the collapse to\u00a0occur.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1dG99hx0bupdOEOeE54qag.png\" /><figcaption>Generator collapse during Stage 3 growth\u00a0(28x28)</figcaption></figure><p>Although this step was unsuccessful at being able to produce full resolution emotes, I felt as though it gave me a necessary introduction to CNNs and was good preparation for the rest of the\u00a0project.</p><p>In total, this section took ~3 weeks from end-to-end. A majority of this was spent developing the initial custom network architecture and trying to correct GAN collapse problems.</p><p><strong>3. Adapt the emote dataset for use with a real research-caliber GAN implementation</strong></p><p>I decided to use the Tensorflow implementation of a progressive growing GAN provided <a href=\"https://github.com/tkarras/progressive_growing_of_gans#progressive-growing-of-gans-for-improved-quality-stability-and-variation-official-tensorflow-implementation-of-the-iclr-2018-paper\">here</a>. There were three main reasons for picking this specific GAN, given the huge diversity of different GAN architectures available.</p><p>The first reason was that this implementation had a proven history of being able to generate very high resolution images on diverse datasets, far above the resolution of what I would need for my emote dataset. Given the trouble I had consistently growing the output resolution of my own GAN, I wanted to see if this more complex implementation would be able to resolve these\u00a0issues.</p><p>Secondly, this GAN\u2019s ability to progressively grow the generator\u2019s image output resolution would dramatically reduce the training time, as the first few low resolution stages would complete very quickly. For reference, it took an equal amount of time to grow the GAN from an output resolution of 4x4 to 64x64 as it took to grow from 64x64 to 128x128. This meant that I could very quickly inspect low resolution results before committing to continue training the GAN up to much higher resolutions.</p><p>Finally, this GAN had significant tooling already in place for dataset generation and output visualization that I would be able to leverage. This made it easier to compose new datasets and validate results. This allowed me to create the first version of the of the training dataset in one\u00a0night.</p><p>As this GAN required square image sizes, I choose to pad the Twitch emotes from 112x112 to 128x128 with white background. For the first test, I choose another random 200k sample of the full dataset and started the training.</p><p><strong>4. Train the GAN on the emote\u00a0dataset</strong></p><p>After 72 hours of training locally on my GTX 1070, the GAN had grown to the full output resolution of 128x128. I opened up the results directory, awaiting my emotes. The actual results\u00a0were\u2026</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*wTFZvZqafU700om0A8IZsA.png\" /></figure><p>\u2026 a bit of a mess. These were certainly far better than what my GAN was able to achieve, but most of the generated emotes were composed of disjointed text, blurred blob faces, and a melting mix of colors. Not exactly the photo-realism that I had been promised!</p><p>I realized very quickly that the problem wasn\u2019t the GAN itself, but the training\u00a0set.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rfnIo7SwuSCOj9apvEdTyQ.png\" /><figcaption>Sample of the initial training\u00a0dataset</figcaption></figure><p>After pulling together a sample of the training emotes actually being fed into the neural network, it was clear that this jumble of unrelated images did not provide a clear set of features which could be learned by the GAN. The mix of cartoon-style faces, \u201crealistic\u201d faces, text, anthropomorphic random objects and hearts had so much variety that the GAN was forced to over-generalize to all styles, leaving it unable to produce high quality images within a specific style. <strong>A GAN is not magic, it still requires a clear visual pattern which can be learned in order to produce high quality\u00a0images.</strong></p><p>One interesting idea for future GAN research is developing an algorithm to train Progressive GANs that learns to automatically cluster implicit styles in the training data. This would allow GANs to be trained on mixed-style datasets directly, instead of requiring additional filtering steps to separate these datasets into their component styles before training.</p><p>I believe this issue was further exacerbated due to the GAN including a minibatch standard deviation layer at the end of the discriminator. This layer was meant to increase the variation in the images generated by the GAN by allowing the discriminator to easily discriminate against generated minibatches of images which have low variation. This was included in the original implementation to prevent the GAN from converging to a single local optimum face when trained on sets of human faces (Celeba-HQ) which were all visually similar. Given the huge variation of the emote training dataset, this layer effectively forced the generator to over-generalize, sacrificing image quality and visual consistency for image diversity.</p><p>With this in mind, I decided to create a more consistent dataset for a subset of the emotes available.</p><p><strong>5.1 Moving towards a more consistent dataset</strong></p><p>On Twitch, there are two main parts of metadata about an emote. The first, <em>emote_id </em>is the actual unique id that is used to reference an emote and was used for the data scraping in step 1. This id is never exposed to an actual Twitch user, as it is only used on the backend. Instead, there is a second identifier; <em>emote_code, </em>which is what users type in chat to get an emote to show up. This <em>emote_code</em> is actually composed of two parts, the <em>emote_prefix</em> and <em>the_part_that_isnt_the_prefix (emote_suffix? emote_remainder?).</em> All <em>emote_codes</em> for a given Twitch broadcaster will share the same <em>emote_prefix</em>. However, the rest of the <em>emote_code </em>is customizable<strong> </strong>by the broadcaster when they upload an new\u00a0emote.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/607/1*XClsxoFJO5zIpbK9Ugc8Dg.png\" /><figcaption>Three emotes for <a href=\"https://www.twitch.tv/thesushidragon\">thesushidragon</a> showing the consistent emote_prefix</figcaption></figure><p>What you will quickly realize using Twitch is that many different broadcasters have emotes with the same <em>emote_suffix.</em> Although the exact emotes can be very different, the general visual styles appeared to be roughly consistent. My first thought was using these shared <em>emote_suffixes </em>to build a better dataset upon which to train the GAN. The only concern was that there would not be enough emotes with the exact same <em>emote_suffix </em>to allow the GAN to learn a generalized emote style instead of learning to reproduce the exact training images from the limited dataset as closely as possible. After a few SUBSTRINGs and GROUP BYs, I had the following table:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/188/1*KLVrtrpMAfLf8NeX5VdoxA.png\" /></figure><p>The top few <em>emote_suffixes </em>would definitely have enough data, so I chose \u201cHype\u201d as the first <em>emote_suffix </em>to try and rebuilt another dataset with just those emotes. A sample of that training dataset follows\u00a0below:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-wIYLCtJtJTu3LTDlV1vog.png\" /><figcaption>Sample of the \u201cHype\u201d training\u00a0data</figcaption></figure><p>Although there was still a significant amount of variation between different emotes, this was looking a lot better and I felt confident to try it as a proof of concept. I fed these into the GAN and came back after a day to look at the partially trained 64x64 resolution network.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JLrehJs0bJNR4S0xdx_RMw.png\" /><figcaption>Generated images from the partially trained 64x64 resolution \u201cHype\u201d\u00a0dataset</figcaption></figure><p>These were developing faces and the \u201chype\u201d text was clearly recognizable, so this was definitely better than the first training attempt. However, many of generated emotes had the \u201chype\u201d text mirrored from right-to-left instead of left-to-right. This didn\u2019t occur in the training dataset at all, and it was very clearly the whole word reversed, not just a single letter. This told me that there was something wrong within the GAN itself. After digging through the code, I found a config parameter called <em>train_mirror_augment</em> which should have defaulted to <em>false </em>but was accidentally overridden to <em>true </em>when I copied configuration data from another dataset\u2019s configuration. This brings me to the first major lesson learned from this\u00a0project:</p><h3>Validate the configuration parameters match exactly what you expect before every single training\u00a0run.</h3><p>This was the first of multiple times I had to spend a bunch of time on issues that were caused by improper configuration. Many of these caused performance problems that were not immediately noticed, wasting both my debugging time and potential GAN training time. Although it may seem excessive, breaking out the debugger and stepping right up to the first training epoch to inspect any configuration data for the first few training cycles will help catch a lot of small problems that would otherwise stick around for a while. In the words of\u00a0<a href=\"https://karpathy.github.io/2019/04/25/recipe/\">Andrej</a>:</p><blockquote>Neural net training fails\u00a0silently</blockquote><blockquote>When you break or misconfigure code you will often get some kind of an exception. You plugged in an integer where something expected a string. The function only expected 3 arguments. This import failed. That key does not exist. The number of elements in the two lists isn\u2019t equal. In addition, it\u2019s often possible to create unit tests for a certain functionality.</blockquote><blockquote>This is just a start when it comes to training neural nets. Everything could be correct syntactically, but the whole thing isn\u2019t arranged properly, and it\u2019s really hard to tell. The \u201cpossible error surface\u201d is large, logical (as opposed to syntactic), and very tricky to unit test\u00a0\u2026 Therefore, your misconfigured neural net will throw exceptions only if you\u2019re lucky; Most of the time it will train but silently work a bit\u00a0worse.</blockquote><p>With the mirror augment fixed, I fired up another training iteration.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YmwZt9p4tO1cGT7Jn2Ouqw.png\" /><figcaption>Generated \u201cHype\u201d emotes, round\u00a02</figcaption></figure><p>The text direction was fixed and it was actually pretty readable, but the remainder of the image still had that amorphous blob look. In general, the training emotes fell into three different categories:</p><ol><li>\u201cHype\u201d on the top of the image with something below\u00a0it</li><li>\u201cHype\u201d or \u201cSub Hype\u201d all alone on a white background</li><li>\u201cHype\u201d on the bottom of the image with something above\u00a0it</li></ol><p>As as last ditch effort, I manually curated a dataset of only emotes from category 3, the retrained the GAN on this. This greatly stabilized the general structure of the generated emotes, even if a faces were still blurry\u00a0messes.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PwNLLoMyUFkBjuFnNZquIw.png\" /></figure><p><strong>5.2 Just the faces,\u00a0please</strong></p><p>Seeing how a more consistent training dataset had been able to stabilize the generated hype emotes, my next goal was removing all of non-faces from the original dataset. I pulled down the <a href=\"https://github.com/ageitgey/face_recognition\">face_recognition</a> python library, with uses a pre-trained CNN to detect the position of faces in an image. After running this for a few hours, I was left with a filtered dataset of ~400k images each containing exactly one face. This collection of images will subsequently be referred to as the \u201cface dataset\u201d and formed the base for the remainder of this project. The strength of this library is that it not only provides a bounding box for the face, but also the locations of 68 specific landmark points. These can be used for further filtering on the details of the\u00a0image.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/414/1*96UT-D8uSXjlnyvs9DZTog.png\" /><figcaption>Landmark points provided by face_recognition</figcaption></figure><p>For most emotes, the locations of these landmark points were highly accurate.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/243/1*3uWlmcKaviPrGV2ZnUvuag.png\" /><figcaption>\u201cKappaHD\u201d before and after being run through face_recognition</figcaption></figure><p>I chose specific locations for the left eye, right eye, and bottom of the chin (points 36, 45, and 8 in the diagram above), then filtered the face dataset to only emotes which had similar locations for their corresponding facial landmarks. My intuition was that these emotes would all share similar poses, even if the exact content of the emote was different. I kicked off the GAN training, and in three days came back to a bunch of people looking\u00a0left.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EqBunLTLbulmSYY4RGywOg.png\" /><figcaption>Generated emotes from the GAN trained on one single consistent pose</figcaption></figure><p><em>People </em>may have been a bit of an exaggeration, but these were looking better than anything I had been able to produce before. The removal of emotes with no faces as well as the consistent pose had really improved the quality. In fact, some of them were looking <em>too\u00a0</em>good.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/233/1*nxFIeoseFfVb4c6UxdgfJw.png\" /></figure><p>Somehow the GAN had been able to create nearly pixel-perfect replications of this emote. I had remembered seeing the yellow haired emote in the training dataset, but there was no clear reason at first why this one looked so much better. However, the fact that I could even remember the emote from the dataset was weird, since I definitely didn\u2019t remember nearly any of the other thousands of\u00a0emotes.</p><p>Digging in more, the problem revealed itself\u200a\u2014\u200aduplication. Since Twitch has no validation to ensure that emotes were distinct, there were multiples copies of many emotes. This duplication would most frequently occur if someone uploaded an new emote multiple times, slightly adjusting the cropping or color when testing what it would look like. This particular yellow-haired emote was massively duplicated, being fed through the GAN during training far more than the typical emote. This over-weighting was strong enough converge the GAN to a local optimum, producing a near perfect replication of this specific\u00a0emote.</p><p>Luckily, face_recognition provides a way to detect similar faces. Along with the position of <em>face_landmarks</em>, a <em>face_encoding </em>is output which should be nearly identical for all faces of the same person. You can read more about the ResNet CNN which is behind this encoding <a href=\"http://blog.dlib.net/2017/02/high-quality-face-recognition-with-deep.html\">here</a>. Since duplicate faces are likely to have similar <em>emote_ids </em>(due to being uploaded at nearly the same time), I ran a window function over the images sorted by <em>emote_id. </em>This compared the <em>face_encoding </em>values for all faces within a 1000 emote window to detect those which were near identical. The window size of 1000 was chosen empirically based on the max difference in observed <em>emote_ids </em>for duplicated emotes.</p><p>Out the ~400k face emotes, this identified ~20k which were duplicated. After confirming these were actually duplicates via brief visual inspection, these emotes were purged from the\u00a0dataset.</p><p><strong>5.3 Filters, Filters,\u00a0Filters</strong></p><p>After seeing how filtering the dataset based on the position of specific <em>face_landmarks </em>was<em> </em>able to stabilize the training, I removed the original <em>face_landmarks </em>filter and created four new\u00a0rules:</p><ol><li>Emotes should include between 20% and 50% white space. Emotes with more than 50% white space were usually text miscategorized as faces or were just the outlines of faces. Emotes with less than 20% whitespace were too zoomed in or had large colored backgrounds.</li><li>The chin position of the face (point 8) should be roughly vertically centered and near the bottom of the emote. Although this would filter out a few good training images which had slightly strange face positions, many of the faces which failed this rule had small faces with vertical text next to\u00a0them.</li><li>The size of the bounding box for each face should be between 50x50 and 90x90 pixels. Faces smaller than 50x50 were usually not the main focus of the emote. Faces larger than 90x90 were too zoomed in to be\u00a0usable.</li><li>None of the <em>face_landmark </em>points should fall outside of the bounds of the emote (112x112 pixels). This was also adapted to combat very zoomed in faces or emotes which had highly cropped\u00a0faces.</li></ol><p>The intersection of these rules formed a new dataset. These were composed into a new training set and I soon began to see much more promising results.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Ga28Duqn4wFsYGEHS4FQLA.png\" /><figcaption>First attempt at a rules-based approach for dataset filtering</figcaption></figure><p>I was particularly happy with these six, as they were either highly realistic or showed the ability of the GAN to generalize non-face features (headphones and sunglasses)</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/714/1*ZhKeIdAmYHO8jXxLHQ8rDg.png\" /></figure><p>This brings me to my second major lesson learned from this\u00a0project:</p><p><strong>Training dataset inspection is incredibly helpful at identifying sources of problems and can drastically improve the results generated by a\u00a0GAN</strong></p><p>When you do this, it is very easy to determine if you (as a human) can see a consistent pattern across most of the training data. If there are training images which you think are not good representative examples or are unlikely to contribute to the GAN\u2019s generalization learning, build an algorithm to filter them\u00a0out.</p><p>Of course, this approach works best when you have significantly more data than you actually need for training and can be picky about which subset of the dataset to train on. Since the de-duplicated face dataset had ~390k images to choose from and only ~30k or less were needed for training, it was worthwhile to trade recall for precision and create loose rules which would potentially filter out \u201cgood\u201d emotes, so long as the majority of emotes removed by a rule were \u201cbad\u201d. In doing this, the relative proportion of \u201cgood\u201d emotes in the training dataset would increase with the addition of each additional rule. Adding new rules followed this general\u00a0pattern:</p><ol><li>Look through the training data and find a few instances of emotes which are not high quality faces or have other noise that would likely degrade the quality of the generated GAN\u00a0emotes</li><li>Create a rule which would filter these\u00a0out</li><li>Run the rule against the entire remaining dataset and keep track of all emotes which would be filtered out by the new\u00a0rule</li><li>Quickly visually inspect the filtered out emotes to make sure a majority of them were\u00a0\u201cbad\u201d</li><li>Run the rule against the entire remaining dataset and keep only the emotes which would <em>not</em> be filtered out by the new\u00a0rule</li><li>Repeat steps 1 -5 until the quality and consistency of the training data has improved enough that you feel confident rerunning the GAN\u00a0training</li></ol><p>As a next step, two new rules were added. These were aimed at stabilizing the color scheme of the dataset by requiring that 90% of the pixels in every image be made of white, black, or skin-tone colors. In addition, no large portion of any emote could be gray. These rules were remarkable effective at improving the stability and realism of the generated emotes:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qDOqx8vt492U5MSQF3KdeA.png\" /><figcaption>Generated emotes after filtering very vivid colored emotes out of the training\u00a0data</figcaption></figure><p>One interesting realization from this is that the generated emotes with their entire faces blurred are actually <em>intentionally </em>produced by the GAN, as these blurry emotes occur with some frequency in the training dataset. The reason for this is that not all Twitch broadcasters provide full 112x112 resolution images for their emotes. Twitch requires uploading all three image resolutions when creating an emote, but some people choose to just upscale low resolution images instead of providing native 112x112 resolution assets. This degraded image quality is then replicated by the\u00a0GAN.</p><p>In addition, some generated emotes still had strange block-like artifacts. I believed that these artifacts were caused by the presence of text within emotes in the training dataset. Although emotes which were <em>only </em>text had almost entirely been filtered out by the addition of the prior rules, there were still some emotes that had small portions of text within the emote, usually above or below the\u00a0face.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/792/1*o2d4Fv4Y9D21lVRbgcV6eA.png\" /><figcaption>Generated Emotes with Artifacts (Left) and face emotes EAST identified as containing text (Right). The teal outlines show the bounding boxes for the detected\u00a0text</figcaption></figure><p>To remove these text emotes, I ran <a href=\"https://github.com/argman/EAST\">this implementation</a> of <a href=\"https://arxiv.org/abs/1704.03155v2\">EAST</a> over the training dataset, then removed any emotes which were detected to contain text. EAST is an <strong>E</strong>fficient and <strong>A</strong>ccurate<strong> S</strong>cene <strong>T</strong>ext detector which uses a combination of both a CNN and NMS merging stage to detect text at any orientation. This filtered out ~1k face emotes which also contained some text. The GAN was then retrained, but the results did not show much of a significant change after the removal of the text. The majority of the artifacts were gone, but it appeared that question marks alone were not detected by EAST, as one of the generated emotes showed this\u00a0feature.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zIF4a3KllqwkwOAdloAJng.png\" /><figcaption>Generated emotes after removing text from training\u00a0images</figcaption></figure><p><strong>5.4 Moving training to the cloud with AWS Deep learning\u00a0AMIs</strong></p><p>Prior to this point, I had been training on my home computer using a GTX 1070. This took ~1 day to grow the resolution of the GAN output to 64x64, and a further 2 days to grow to 128x128. This meant that I was unable to rapidly iterate on new training datasets or try multiple examples at\u00a0once.</p><p><strong>More importantly, I had to turn my graphics settings to <em>low </em>when playing video games.</strong> The graphics card was unable to handle 70% CUDA utilization and high resolution gaming at the same time, as it would frequently run into GPU memory allocation issues which required me to restart GAN training from the last checkpoint.</p><p>Because of this, I moved to training using AWS deep learning AMIs on GPU-accelerated EC2 instances. I choose to use thep3.2xlarge instance type, which includes one NVIDIA\u00ae V100 GPU. This reduced my training time from the aforementioned 3 days to almost exactly 24\u00a0hours.</p><p>However, this also increased my training cost from $0/hour to $3.06/hour. Although this is inexpensive compared to buying a V100 for <a href=\"https://www.amazon.com/PNY-TCSV100MPCIE-PB-Nvidia-Tesla-v100/dp/B076P84525\">$6718</a>, at ~75$ for each end-to-end training I certainly began to put more focus on pre-training dataset validation and testing. After moving to AWS, my new training workflow\u00a0became:</p><ol><li>Create dataset locally, push to\u00a0S3</li><li>Start the EC2 deep learning instance and ssh into\u00a0it</li><li>Pull down the dataset from S3 onto the instance, git clone the GAN repo, start training using\u00a0<a href=\"https://linux.die.net/man/1/screen\">screen</a></li><li>Come back in 24 hours, copy the trained NN checkpoint files to my local machine using\u00a0pscp</li><li>Kill the EC2\u00a0instance</li></ol><p>A significant amount of this manual work could have been automated, but I never expected to run so many different training iterations that the cost of automating this would have paid\u00a0off.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/404/1*r_-_ZWam5n6mQn0o121-6g.png\" /><figcaption><a href=\"https://xkcd.com/1319/\">https://xkcd.com/1319/</a></figcaption></figure><p>Outside of the improved training performance, the strong advantage I saw from using EC2 with deep learning AMIs is that all of the configuration work was already complete. The only thing left to do when connecting to any of the hosts was run source activate tensorflow_p36 then python train.py. This was a stark contrast to the many early hours I spent on this project properly installing the CUDA toolkit, getting the correct drivers, and managing python packages and their own dependencies on specific Tensorflow and CUDA versions. I considered using a Tensorflow Docker image to simplify this configuration work, but at that point I already had everything working locally and the thought of making any new changes which could potentially tip over the house of cards that was my local development stack seemed unattractive.</p><p><strong>5.5 Using the discriminator to improve data\u00a0quality</strong></p><p>At this point, I started struggling with new programmatic ways to improve the dataset quality. New rule-based approaches had low precision, filtering out too many good emotes along with the bad. However, there was still a non-trivial proportion of low quality emotes, far too many to remove by hand. The goal was to build a more complex system to be able to detect these and remove them from the training dataset. While coming up with ideas, I realized that I already had something that could work for this\u00a0task.</p><p>Although the GAN trained two neural networks, a discriminator and generator, only the generator was actually used. The discriminator was discarded after training, as it was no longer needed to synthesize emotes.</p><p>While training a GAN, the purpose of the discriminator is to detect which emotes come from the training set and which are generated by the generator. As such, the discriminator become very adapt at detecting \u201cstrange\u201d images which do not match the patterns found in the majority of the training data. This is used during training to update the generator\u2019s weight to produce better quality\u00a0images.</p><p>I took the training dataset and fed every emote through the trained discriminator. The output of this was a score for each emote ranging from -100 to 100. This score indicated the discriminator\u2019s belief that the emote came from the training dataset (100) or was generated (-100). The scores for the training emotes were roughly normally distributed, having a large center cluster and tail of outliers with both very positive and very negative scores. Interestingly, the mean score for the training emotes was only weakly positive.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/965/1*DlROP2WFq9X53U86JEzdew.png\" /></figure><p>I then visually inspected the emotes which were scored at the extreme ends of this range. Training emotes which scored very low (below 0) were generally overly simplified, heavily rotated, did not have a very clear face in the image, or had text in the image that EAST had missed. These were removed from the\u00a0dataset.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/568/1*UKQfVhq-dMaJTirdbKlWbw.png\" /><figcaption>Low-scored Emotes using the discriminator</figcaption></figure><p>On the opposite side, the very high-scored emotes were also useful to remove. Although these were generally high quality faces, they were plagued by another problem\u200a\u2014\u200aduplication.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/419/1*Ftz9bH5H4JxgB0d5_NDADA.png\" /><figcaption>High-scored emotes using the discriminator</figcaption></figure><p>Each of these emotes were duplicated dozens of times in the dataset. As discussed prior, this duplication caused training to drastically over-weight the features from these emotes. This could be observed in the generated emotes from the last training\u00a0run.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/139/1*eqa_m5ZATLritsVYnDRuyg.png\" /></figure><p>The reason that these were not able to be filtered out during the previous image-deduplication was that they were uploaded many days apart. As such, their drastically different <em>emote_ids</em> would fall outside of the 1000 emote width window function when the duplication detection code was run. These were also removed from the dataset and training was\u00a0re-run.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Jxz3gC87PlbN2GwjFhQKaw.png\" /><figcaption>Generated emotes after removing extreme scores from the training\u00a0data</figcaption></figure><p>I wonder if this approach of leveraging the trained discriminator to provide useful work outside of the training backpropagation step could be applied more broadly for other aspects of GAN training. One potential use of the trained discriminator is automatically adjusting the composition of the data during training in order to speed GAN convergence. Being able to identify which specific training examples are providing most of the \u201clearning\u201d would allow you to dis-proportionally feed these though the GAN, potentially improving the training\u00a0rate.</p><p>At this point, I felt as though the improvements in generated emote quality had slowed enough that small iterative changes was unlikely to lead to further realism. As such, I chose to move on and create new GAN training datasets using the lessons learned from trying to synthesize realistic faces.</p><p><strong>5.6 Cartoon Emotes and Wide\u00a0Emotes</strong></p><p>Up next was attempting to generate cartoon-style emotes. The approach for these was generally similar to the one described for realistic face emotes, with one important exception\u200a\u2014\u200aemotes were only included in the training dataset if they (1) had a low number of distinct colors and (2) had a large fraction of the total image space composed of only a few of distinct colors. These two rules were remarkably effective at filtering cartoon-style emotes. The results of this are shown\u00a0below:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*r5L5667czWGQ_tk8xW32lw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QKaI9B-8V5rI-_PP4ntMXw.png\" /><figcaption>Cartoon-style generated emotes</figcaption></figure><p>Furthermore, the GAN for these emotes was able to linearly interpolate across different input noise vectors with relative smoothness.</p><a href=\"https://medium.com/media/065f08067d0f3b3bfe554e7933ffb91a/href\">https://medium.com/media/065f08067d0f3b3bfe554e7933ffb91a/href</a><a href=\"https://medium.com/media/d55d0eacca9e55ecb6c58cae674a6648/href\">https://medium.com/media/d55d0eacca9e55ecb6c58cae674a6648/href</a><p>Up next was wide emotes. The only main change to the filtering rules for this was removing the prior face size and whitespace restrictions and prioritizing faces whose bounding box filled almost all of the\u00a0image.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7zHSf_X3Z5xn-Wlu660fiQ.png\" /><figcaption>Generated \u201cwide\u201d\u00a0emotes</figcaption></figure><p>These emotes actually had the most smooth linear interpolations, as the placement of facial features was very consistent across all\u00a0emotes.</p><a href=\"https://medium.com/media/15eb666ca2e7f42f37ec9bc0083a3b74/href\">https://medium.com/media/15eb666ca2e7f42f37ec9bc0083a3b74/href</a><p><strong>6. Next steps and final reflections</strong></p><p>In total, what I originally estimated as a short 2 week project ended up taking about 2 months by the time the last GAN was finished training. This brings me to the last major lesson learned from this\u00a0project:</p><p><strong>Many small improvements can combine together to create a great result, focus on making one good change at a\u00a0time</strong></p><p>Given the initial lack of high quality results with both my custom GAN implementation and the progressive growing GAN, it was tempting to shelve the project. I knew that there was a lot of work that needed to be done, and I didn\u2019t have clear steps forward on what would be the best approach. Instead of trying complicated ideas to fix all the problems at once, focusing on making single iterative improvements (1) unblocked progress and (2) stopped any analysis paralysis.</p><p>Overall I am quite happy with how this project has turned out and the diversity of emotes that were able to be synthesized. I don\u2019t think I\u2019ll be able to compete with human emote artists anytime soon, but maybe with some dedicated research dollars we can change this. In the meantime, I\u2019ll say bye in the most succinct way I\u00a0can.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/128/1*BhepSwAT9jGre1rEMf6ZHQ.png\" /></figure><p>If you enjoyed this, feel free to <a href=\"https://medium.com/@agnolek\">follow me on Medium</a> or <a href=\"https://www.linkedin.com/in/averygnolek/\">connect on LinkedIn</a>!</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a742b6354b73\" width=\"1\" /><hr /><p><a href=\"https://medium.com/twitch-news/thisemotedoesnotexist-training-a-gan-for-twitch-emotes-a742b6354b73\">ThisEmoteDoesNotExist: Training a GAN for Twitch Emotes</a> was originally published in <a href=\"https://medium.com/twitch-news\">Twitch Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Zumba": {
    "title": "Zumbatech takes on #hackforchange",
    "xmlUrl": "http://feeds.feedburner.com/zumba_engineering",
    "htmlUrl": "http://tech.zumba.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://feeds.feedburner.com/zumba_engineering",
      "value": "Zumbatech takes on #hackforchange"
    },
    "summary": "How Zumbatech contributed to Hackforchange utilizing opensource tools.",
    "summary_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://feeds.feedburner.com/zumba_engineering",
      "value": "How Zumbatech contributed to Hackforchange utilizing opensource tools."
    },
    "links": [
      {
        "href": "http://tech.zumba.com/2015/06/15/zumbatech-at-hackforchange//",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "link": "http://tech.zumba.com/2015/06/15/zumbatech-at-hackforchange//",
    "authors": [
      {
        "name": "Chris Saylor",
        "email": "christopher.saylor@zumba.com"
      }
    ],
    "author_detail": {
      "name": "Chris Saylor",
      "email": "christopher.saylor@zumba.com"
    },
    "author": "Chris Saylor (christopher.saylor@zumba.com)",
    "updated": "2015-06-15T00:00:00+00:00",
    "updated_parsed": [
      2015,
      6,
      15,
      0,
      0,
      0,
      0,
      166,
      0
    ],
    "id": "http://tech.zumba.com/2015/06/15/zumbatech-at-hackforchange",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "http://feeds.feedburner.com/zumba_engineering",
        "value": "<p>On June 6, 2015, a team of engineers from Zumbatech decided to contribute in\nan all-day hackathon event called <a href=\"http://hackforchange.org/\">Hackforchange</a>.\nThis is a national effort for civic hacking that brings engineers and designers\ntogether to make a positive impact in our communities.</p>\n\n<h2 id=\"lets-not-re-invent-the-wheel\">Let\u2019s not re-invent the wheel</h2>\n\n<p>The day before the event, our team got together to figure out what we were going to work\non that would give the most impact to our community. We chose to work on generating visualizations\nof Florida vendor transactions. The first thing we noticed is that a couple of projects had\nalready been underway to create restful APIs and alternate data formats for this data. We decided\nthat an API that is specific to this data set wouldn\u2019t be very reusable for other data sets, <em>and</em>\nit would still take an engineer\u2019s effort to visualize the data from those APIs.</p>\n\n<p>We wanted to make something that is generic enough to work with any sort of data set,\nbe flexible enough for other engineers to create tools and visualizations via an API,\nand be easy enough for non-engineers to construct visualizations that fit their needs.\nA daunting task, especially for it to be <em>mostly</em> completed in a single hackathon.\nAfter some planning and discussion, we came up with a solution ready for hacking!</p>\n\n<h2 id=\"hackathon\">Hackathon</h2>\n\n<p>Bright and early on that Saturday morning, we arrived in the <a href=\"http://thelabmiami.com/\">LAB Miami</a> offices to\nwork on a project we called <a href=\"https://github.com/cjsaylor/datamnom\">Datamnom</a>. The idea\nof the project is to make a generic ingestion program that can take in multiple data sources and\npopulate an <a href=\"https://www.elastic.co/products/elasticsearch\">Elasticsearch</a> index. Once the data\nis in Elasticsearch, a tool called <a href=\"https://www.elastic.co/products/kibana\">Kibana</a> can be hooked\nup to the Elasticsearch index we populated to create visualizations.</p>\n\n<p>After writing a prototype <a href=\"https://nodejs.org\">nodejs</a> program and setting up a <a href=\"https://www.vagrantup.com/\">Vagrant</a>\nenvironment, we had Kibana up and running with data to visualize:</p>\n\n<p><img alt=\"Kibana running FL Vendor data\" class=\"img-responsive\" src=\"http://feeds.feedburner.com/img/blog/visualization1.png\" /></p>\n\n<p>Here is team Zumba demoing our work to the Florida CFO, Jeff Atwater:</p>\n\n<p><img alt=\"Team Zumba demoing Datamnom to Jeff Atwater and others\" class=\"img-responsive\" src=\"http://feeds.feedburner.com/img/blog/miamiherald-hackathon.jpg\" /></p>\n\n<p>via <a href=\"http://miamiherald.typepad.com/the-starting-gate/2015/06/florida-cfo-jeff-atwater-spent-the-morning-with-a-coworking-space-full-of-young-hackers-this-is-dress-down-day-for-me.html\">Miami Herald</a></p>\n\n<h2 id=\"presentation-and-reception\">Presentation and Reception</h2>\n\n<p>After importing about 8 years worth of Florida Vendor transactions, the team presented our idea and applications\nto the group. Other groups that were working with this data set decided to use our tools to make their own visualizations.</p>\n\n<div class=\"row\">\n    <div class=\"col-md-6\">\n        <blockquote class=\"twitter-tweet\" lang=\"en\"><p dir=\"ltr\" lang=\"en\">Team <a href=\"https://twitter.com/zumbatech\">@zumbatech</a> presents FL State Payments API and visualization app. <a href=\"https://twitter.com/hashtag/hackforchange?src=hash\">#hackforchange</a> <a href=\"http://t.co/R48vs6AnUZ\">pic.twitter.com/R48vs6AnUZ</a></p>&mdash; Code For Miami (@CodeForMiami) <a href=\"https://twitter.com/CodeForMiami/status/607296202191872000\">June 6, 2015</a></blockquote>\n        \n    </div>\n    <div class=\"col-md-6\">\n        <blockquote class=\"twitter-tweet\" lang=\"en\"><p dir=\"ltr\" lang=\"en\">Using <a href=\"https://twitter.com/zumbatech\">@zumbatech</a>'s Payments API, <a href=\"https://twitter.com/robdotd\">@robdotd</a> and team visualize printing costs across FL departments. <a href=\"https://twitter.com/hashtag/hackforchange?src=hash\">#hackforchange</a> <a href=\"http://t.co/eB0BpAgpyV\">pic.twitter.com/eB0BpAgpyV</a></p>&mdash; Code For Miami (@CodeForMiami) <a href=\"https://twitter.com/CodeForMiami/status/607297271928131585\">June 6, 2015</a></blockquote>\n        \n    </div>\n</div>\n<div class=\"row\">\n    <div class=\"col-md-6\">\n        <blockquote class=\"twitter-tweet\" lang=\"en\"><p dir=\"ltr\" lang=\"en\">State challenge group is visualizing Vendor Data in a bunch of different ways and automating new viz. <a href=\"https://twitter.com/hashtag/hackforchange?src=hash\">#hackforchange</a> <a href=\"http://t.co/ZGZYnUrcS6\">pic.twitter.com/ZGZYnUrcS6</a></p>&mdash; Code For Miami (@CodeForMiami) <a href=\"https://twitter.com/CodeForMiami/status/607218433437089792\">June 6, 2015</a></blockquote>\n        \n    </div>\n    <div class=\"col-md-6\">\n        <blockquote class=\"twitter-tweet\" lang=\"en\"><p dir=\"ltr\" lang=\"en\">Great presentation from <a href=\"https://twitter.com/CodeforFTL\">@CodeforFTL</a> and group! <a href=\"https://twitter.com/hashtag/hackforchange?src=hash\">#hackforchange</a> <a href=\"https://twitter.com/knightfdn\">@knightfdn</a> <a href=\"https://twitter.com/CFJBLaw\">@CFJBLaw</a> <a href=\"https://twitter.com/wyncode\">@wyncode</a> <a href=\"https://twitter.com/socrata\">@socrata</a> <a href=\"http://t.co/sEidId7pE9\">pic.twitter.com/sEidId7pE9</a></p>&mdash; Code For Miami (@CodeForMiami) <a href=\"https://twitter.com/CodeForMiami/status/607297689525481473\">June 6, 2015</a></blockquote>\n        \n    </div>\n</div>\n\n<h1 id=\"conclusion\">Conclusion</h1>\n\n<p>We had a fun time at LAB Miami hacking together a project we think can really help\nlawmakers, researchers, and reporters visualize public data in a way that allows them\nto ask the right questions and help our communities.</p>"
      }
    ]
  },
  "Grab": {
    "title": "Kafka on Kubernetes: Reloaded for fault tolerance",
    "xmlUrl": "http://engineering.grab.com/feed.xml",
    "htmlUrl": "http://engineering.grab.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.grab.com/feed.xml",
      "value": "Kafka on Kubernetes: Reloaded for fault tolerance"
    },
    "summary": "<h2 id=\"introduction\">Introduction</h2>\n\n<p>Coban - Grab\u2019s real-time data streaming platform - has been operating <a href=\"https://kafka.apache.org/\">Kafka</a> on <a href=\"https://kubernetes.io/\">Kubernetes</a> with <a href=\"https://strimzi.io/\">Strimzi</a> in \nproduction for about two years. In a previous article (<a href=\"https://engineering.grab.com/zero-trust-with-kafka\">Zero trust with Kafka</a>), we explained how we leveraged Strimzi to enhance the security of our data streaming offering.</p>\n\n<p>In this article, we are going to describe how we improved the fault tolerance of our initial design, to the point where we no longer need to intervene if a Kafka broker is unexpectedly terminated.</p>\n\n<h2 id=\"problem-statement\">Problem statement</h2>\n\n<p>We operate Kafka in the AWS Cloud. For the Kafka on Kubernetes design described in this article, we rely on <a href=\"https://aws.amazon.com/eks/\">Amazon Elastic Kubernetes Service</a> (EKS), the managed Kubernetes offering by AWS, with the worker nodes deployed as <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/worker.html\">self-managed nodes</a> on <a href=\"https://aws.amazon.com/ec2/\">Amazon Elastic Compute Cloud</a> (EC2).</p>\n\n<p>To make our operations easier and limit the blast radius of any incidents, we deploy exactly one Kafka cluster for each EKS cluster. We also give a full worker node to each Kafka broker. In terms of storage, we initially relied on EC2 instances with <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html\">non-volatile memory express (NVMe) instance store volumes</a> for \nmaximal I/O performance. Also, each Kafka cluster is accessible beyond its own <a href=\"https://aws.amazon.com/vpc/\">Virtual Private Cloud</a> (VPC) via a <a href=\"https://docs.aws.amazon.com/vpc/latest/privatelink/privatelink-share-your-services.html\">VPC Endpoint Service</a>.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image5.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 1 Initial design of a 3-node Kafka cluster running on Kubernetes.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 1 shows a logical view of our initial design of a 3-node Kafka on Kubernetes cluster, as typically run by Coban. The Zookeeper and Cruise-Control components are not shown for clarity.</p>\n\n<p>There are four Kubernetes services (1): one for the initial connection - referred to as \u201cbootstrap\u201d - that redirects incoming traffic to any Kafka pods, plus one for each Kafka pod, for the clients to target each Kafka broker individually (a requirement to produce or consume from/to a partition that resides on any particular Kafka broker). Four different listeners on the Network Load Balancer (NLB) listening on four different TCP ports, enable the Kafka clients to target either the bootstrap \nservice or any particular Kafka broker they need to reach. This is very similar to what we previously described in <a href=\"https://engineering.grab.com/exposing-kafka-cluster\">Exposing a Kafka Cluster via a VPC Endpoint Service</a>.</p>\n\n<p>Each worker node hosts a single Kafka pod (2). The NVMe instance store volume is used to create a Kubernetes Persistent Volume (PV), attached to a pod via a Kubernetes Persistent Volume Claim (PVC).</p>\n\n<p>Lastly, the worker nodes belong to <a href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html\">Auto-Scaling Groups</a> (ASG) (3), one by <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-availability-zones\">Availability Zone</a> (AZ). Strimzi adds in node affinity to make sure that the brokers are evenly distributed across AZs. In this initial design, ASGs are not for auto-scaling though, because we want to keep the size of the cluster under control. We only use ASGs - with a fixed size - to facilitate manual scaling operation and to automatically replace the terminated worker nodes.</p>\n\n<p>With this initial design, let us see what happens in case of such a worker node termination.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image4.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 2 Representation of a worker node termination. Node C is terminated and replaced by node D. However the Kafka broker 3 pod is unable to restart on node D.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 2 shows the worker node C being terminated along with its NVMe instance store volume C, and replaced (by the ASG) by a new worker node D and its new, empty NVMe instance store volume D. On start-up, the worker node D automatically joins the Kubernetes cluster. The Kafka broker 3 pod that was running on the faulty worker node C is scheduled to restart on the new worker node D.</p>\n\n<p>Although the NVMe instance store volume C is terminated along with the worker node C, there is no data loss because all of our Kafka topics are configured with a minimum of three replicas. The data is poised to be copied over from the surviving Kafka brokers 1 and 2 back to Kafka broker 3, as soon as Kafka broker 3 is effectively restarted on the worker node D.</p>\n\n<p>However, there are three fundamental issues with this initial design:</p>\n\n<ol>\n  <li>The Kafka clients that were in the middle of producing or consuming to/from the partition leaders of Kafka broker 3 are suddenly facing connection errors, because the broker was not gracefully demoted beforehand.</li>\n  <li>The target groups of the NLB for both the bootstrap connection and Kafka broker 3 still point to the worker node C. Therefore, the network communication from the NLB to Kafka broker 3 is broken. A manual reconfiguration of the target groups is required.</li>\n  <li>The PVC associating the Kafka broker 3 pod with its instance store PV is unable to automatically switch to the new NVMe instance store volume of the worker node D. Indeed, static provisioning is an intrinsic characteristic of Kubernetes <a href=\"https://kubernetes.io/docs/concepts/storage/volumes/#local\">local volumes</a>. The PVC is still in <em>Bound</em> state, so Kubernetes does not take any action. However, the actual storage beneath the PV does not exist anymore. Without any storage, the Kafka broker 3 pod is unable to start.</li>\n</ol>\n\n<p>At this stage, the Kafka cluster is running in a degraded state with only two out of three brokers, until a Coban engineer intervenes to reconfigure the target groups of the NLB and delete the zombie PVC (this, in turn, triggers its re-creation by Strimzi, this time using the new instance store PV).</p>\n\n<p>In the next section, we will see how we have managed to address the three issues mentioned above to make this design fault-tolerant.</p>\n\n<h2 id=\"solution\">Solution</h2>\n\n<h3 id=\"graceful-kafka-shutdown\">Graceful Kafka shutdown</h3>\n\n<p>To minimise the disruption for the Kafka clients, we leveraged the <a href=\"https://aws-quickstart.github.io/cdk-eks-blueprints/addons/aws-node-termination-handler/\">AWS Node Termination Handler</a> (NTH). This component provided by AWS for Kubernetes environments is able to cordon and drain a worker node that is going to be terminated. This draining, in turn, triggers a graceful shutdown of the Kafka \nprocess by sending a polite <a href=\"https://www.gnu.org/software/libc/manual/html_node/Termination-Signals.html\">SIGTERM</a> signal to all pods running on the worker node that is being drained (instead of the brutal <a href=\"https://www.gnu.org/software/libc/manual/html_node/Termination-Signals.html\">SIGKILL</a> of a normal termination).</p>\n\n<p>The termination events of interest that are captured by the NTH are:</p>\n\n<ul>\n  <li>Scale-in operations by an ASG.</li>\n  <li>Manual termination of an instance.</li>\n  <li>AWS maintenance events, typically EC2 instances scheduled for upcoming retirement.</li>\n</ul>\n\n<p>This suffices for most of the disruptions our clusters can face in normal times and our common maintenance operations, such as terminating a worker node to refresh it. Only sudden hardware failures (AWS issue events) would fall through the cracks and still trigger errors on the Kafka client side.</p>\n\n<p>The NTH comes in two modes: <a href=\"https://github.com/aws/aws-node-termination-handler#major-features\">Instance Metadata Service (IMDS) and Queue Processor</a>. We chose to go with the latter as it is able to capture a broader range of events, widening the fault tolerance capability.</p>\n\n<h4 id=\"scale-in-operations-by-an-asg\">Scale-in operations by an ASG</h4>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image2.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 3 Architecture of the NTH with the Queue Processor.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 3 shows the NTH with the Queue Processor in action, and how it reacts to a scale-in operation (typically triggered manually, during a maintenance operation):</p>\n\n<ol>\n  <li>As soon as the scale-in operation is triggered, an <a href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html\">Auto Scaling lifecycle hook</a> is invoked to pause the termination of the instance.</li>\n  <li>Simultaneously, an Auto Scaling lifecycle hook event is issued to an <a href=\"https://aws.amazon.com/sqs/\">Amazon Simple Queue Service</a> (SQS) queue. In Fig. 3, we have also materialised EC2 events (e.g. manual termination of an instance, AWS maintenance events, etc.) that transit via <a href=\"https://aws.amazon.com/eventbridge/\">Amazon EventBridge</a> to eventually end up in the same SQS queue. We will discuss EC2 events in the next two sections.</li>\n  <li>The NTH, a pod running in the Kubernetes cluster itself, constantly polls that SQS queue.</li>\n  <li>When a scale-in event pertaining to a worker node of the Kubernetes cluster is read from the SQS queue, the NTH sends to the Kubernetes API the instruction to <a href=\"https://kubernetes.io/docs/concepts/architecture/nodes/#manual-node-administration\">cordon</a> and <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/\">drain</a> the impacted worker node.</li>\n  <li>On draining, Kubernetes sends a SIGTERM signal to the Kafka pod residing on the worker node.</li>\n  <li>Upon receiving the SIGTERM signal, the Kafka pod gracefully migrates the leadership of its leader partitions to other brokers of the cluster before shutting down, in a transparent manner for the clients. This behaviour is ensured by the <a href=\"https://kafka.apache.org/documentation/#basic_ops_restarting\"><code class=\"language-plaintext highlighter-rouge\">controlled.shutdown.enable</code></a> parameter of Kafka, which is enabled by default.</li>\n  <li>Once the impacted worker node has been drained, the NTH eventually resumes the termination of the instance.</li>\n</ol>\n\n<p>Strimzi also comes with a <code class=\"language-plaintext highlighter-rouge\">terminationGracePeriodSeconds</code> parameter, which we have set to 180 seconds to give the Kafka pods enough time to migrate all of their partition leaders gracefully on termination. We have verified that this is enough to migrate all partition leaders on our Kafka clusters (about 60 seconds for 600 partition leaders).</p>\n\n<h4 id=\"manual-termination-of-an-instance\">Manual termination of an instance</h4>\n\n<p>The Auto Scaling lifecycle hook that pauses the termination of an instance (Fig. 3, step 1) as well as the corresponding resuming by the NTH (Fig. 3, step 7) are invoked only for ASG scaling events.</p>\n\n<p>In case of a manual termination of an EC2 instance, the termination is captured as an EC2 event that also reaches the NTH. Upon receiving that event, the NTH cordons and drains the impacted worker node. However, the instance is immediately terminated, most likely before the leadership of all of its Kafka partition leaders has had the time to get migrated to other brokers.</p>\n\n<p>To work around this and let a manual termination of an EC2 instance also benefit from the ASG lifecycle hook, the instance must be terminated using the <a href=\"https://docs.aws.amazon.com/cli/latest/reference/autoscaling/terminate-instance-in-auto-scaling-group.html\"><code class=\"language-plaintext highlighter-rouge\">terminate-instance-in-auto-scaling-group</code></a> AWS CLI command.</p>\n\n<h4 id=\"aws-maintenance-events\">AWS maintenance events</h4>\n\n<p>For AWS maintenance events such as instances scheduled for upcoming retirement, the NTH acts immediately when the event is first received (typically adequately in advance). It cordons and drains the soon-to-be-retired worker node, which in turn triggers the SIGTERM signal and the graceful termination of Kafka as described above. At this stage, the impacted instance is not terminated, so the Kafka partition leaders have plenty of time to complete their migration to other brokers.</p>\n\n<p>However, the evicted Kafka pod has nowhere to go. There is a need for spinning up a new worker node for it to be able to eventually restart somewhere.</p>\n\n<p>To make this happen seamlessly, we doubled the maximum size of each of our ASGs and installed the <a href=\"https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md\">Kubernetes Cluster Autoscaler</a>. With that, when such a maintenance event is received:</p>\n\n<ul>\n  <li>The worker node scheduled for retirement is cordoned and drained by the NTH. The state of the impacted Kafka pod becomes <em>Pending</em>.</li>\n  <li>The Kubernetes Cluster Autoscaler comes into play and triggers the corresponding ASG to spin up a new EC2 instance that joins the Kubernetes cluster as a new worker node.</li>\n  <li>The impacted Kafka pod restarts on the new worker node.</li>\n  <li>The Kubernetes Cluster Autoscaler detects that the previous worker node is now under-utilised and terminates it.</li>\n</ul>\n\n<p>In this scenario, the impacted Kafka pod only remains in <em>Pending</em> state for about four minutes in total.</p>\n\n<p>In case of multiple simultaneous AWS maintenance events, the Kubernetes scheduler would honour our <a href=\"https://kubernetes.io/docs/tasks/run-application/configure-pdb/\">PodDisruptionBudget</a> and not evict more than one Kafka pod at a time.</p>\n\n<h3 id=\"dynamic-nlb-configuration\">Dynamic NLB configuration</h3>\n\n<p>To automatically map the NLB\u2019s target groups with a newly spun up EC2 instance, we leveraged the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html\">AWS Load Balancer Controller</a> (LBC).</p>\n\n<p>Let us see how it works.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image6.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 4 Architecture of the LBC managing the NLB's target groups via TargetGroupBinding custom resources.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 4 shows how the LBC automates the reconfiguration of the NLB\u2019s target groups:</p>\n\n<ol>\n  <li>It first retrieves the desired state described in Kubernetes <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">custom resources</a> (CR) of type <a href=\"https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/guide/targetgroupbinding/targetgroupbinding\">TargetGroupBinding</a>. There is one such resource per target group to maintain. Each TargetGroupBinding CR associates its respective target group with a Kubernetes service.</li>\n  <li>The LBC then watches over the changes of the Kubernetes services that are referenced in the TargetGroupBinding CRs\u2019 definition, specifically the private IP addresses exposed by their respective <a href=\"https://kubernetes.io/docs/concepts/services-networking/service/#endpoints\">Endpoints resources</a>.</li>\n  <li>When a change is detected, it dynamically updates the corresponding NLB\u2019s target groups with those IP addresses as well as the TCP port of the target containers (<code class=\"language-plaintext highlighter-rouge\">containerPort</code>).</li>\n</ol>\n\n<p>This automated design sets up the NLB\u2019s target groups with IP addresses (<code class=\"language-plaintext highlighter-rouge\">targetType: ip</code>) instead of EC2 instance IDs (<code class=\"language-plaintext highlighter-rouge\">targetType: instance</code>). Although the LBC can handle both target types, the IP address approach is actually more straightforward in our case, since each pod has a routable private IP address in the AWS subnet, thanks to the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/managing-vpc-cni.html\">AWS Container Networking Interface</a> (CNI) plug-in.</p>\n\n<p>This dynamic NLB configuration design comes with a challenge. Whenever we need to update the Strimzi CR, the rollout of the change to each Kafka pod in a rolling update fashion is happening too fast for the NLB. This is because the NLB inherently takes some time to mark each target as healthy before enabling it. The Kafka brokers that have just been rolled out start advertising their broker-specific endpoints to the Kafka clients via the bootstrap service, but those \nendpoints are actually not immediately available because the NLB is still checking their health. To mitigate this, we have reduced the <code class=\"language-plaintext highlighter-rouge\">HealthCheckIntervalSeconds</code> and <code class=\"language-plaintext highlighter-rouge\">HealthyThresholdCount</code> parameters of each target group to their minimum values of 5 and 2 respectively. This reduces the maximum delay for the NLB to detect that a target has become healthy to 10 seconds. In addition, we have configured the LBC with a <a href=\"https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/deploy/pod_readiness_gate/\">Pod Readiness Gate</a>. This feature makes the Strimzi rolling deployment wait for the health check of the NLB to pass, before marking the current pod as <em>Ready</em> and proceeding with the next pod.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image7.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 5 Steps for a Strimzi rolling deployment with a Pod Readiness Gate. Only one Kafka broker and one NLB listener and target group are shown for simplicity.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 5 shows how the Pod Readiness Gate works during a Strimzi rolling deployment:</p>\n\n<ol>\n  <li>The old Kafka pod is terminated.</li>\n  <li>The new Kafka pod starts up and joins the Kafka cluster. Its individual endpoint for direct access via the NLB is immediately advertised by the Kafka cluster. However, at this stage, it is not reachable, as the target group of the NLB still points to the IP address of the old Kafka pod.</li>\n  <li>The LBC updates the target group of the NLB with the IP address of the new Kafka pod, but the NLB health check has not yet passed, so the traffic is not forwarded to the new Kafka pod just yet.</li>\n  <li>The LBC then waits for the NLB health check to pass, which takes 10 seconds. Once the NLB health check has passed, the NLB resumes forwarding the traffic to the Kafka pod.</li>\n  <li>Finally, the LBC updates the pod readiness gate of the new Kafka pod. This informs Strimzi that it can proceed with the next pod of the rolling deployment.</li>\n</ol>\n\n<h3 id=\"data-persistence-with-ebs\">Data persistence with EBS</h3>\n\n<p>To address the challenge of the residual PV and PVC of the old worker node preventing Kubernetes from mounting the local storage of the new worker node after a node rotation, we adopted <a href=\"https://aws.amazon.com/ebs/\">Elastic Block Store</a> (EBS) volumes instead of NVMe instance store volumes. Contrary to the latter, EBS volumes can conveniently be attached and detached. The trade-off is that their performance is significantly lower.</p>\n\n<p>However, relying on EBS comes with additional benefits:</p>\n\n<ul>\n  <li>The cost per GB is lower, compared to NVMe instance store volumes.</li>\n  <li>Using EBS decouples the size of an instance in terms of CPU and memory from its storage capacity, leading to further cost savings by independently right-sizing the instance type and its storage. Such a separation of concerns also opens the door to new use cases requiring disproportionate amounts of storage.</li>\n  <li>After a worker node rotation, the time needed for the new node to get back in sync is faster, as it only needs to catch up the data that was produced during the downtime. This leads to shorter maintenance operations and higher iteration speed. Incidentally, the associated inter-AZ traffic cost is also lower, since there is less data to transfer among brokers during this time.</li>\n  <li>Increasing the storage capacity is an online operation.</li>\n  <li>Data backup is supported by taking snapshots of EBS volumes.</li>\n</ul>\n\n<p>We have verified with our historical monitoring data that the performance of <a href=\"https://aws.amazon.com/ebs/general-purpose/\">EBS General Purpose 3</a> (gp3) volumes is significantly above our maximum historical values for both throughput and I/O per second (IOPS), and we have successfully benchmarked a test EBS-based Kafka cluster. We have also set up new monitors to be alerted in case we need to \nprovision either additional throughput or IOPS, beyond the baseline of EBS gp3 volumes.</p>\n\n<p>With that, we updated our instance types from storage optimised instances to either general purpose or memory optimised instances. We added the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html\">Amazon EBS Container Storage Interface (CSI) driver</a> to the Kubernetes cluster and created a new Kubernetes <a href=\"https://kubernetes.io/docs/concepts/storage/storage-classes/\">storage class</a> to let the cluster dynamically provision EBS gp3 volumes.</p>\n\n<p>We configured Strimzi to use that storage class to create any new PVCs. This makes Strimzi able to automatically create the EBS volumes it needs, typically when the cluster is first set up, but also to attach/detach the volumes to/from the EC2 instances whenever a Kafka pod is relocated to a different worker node.</p>\n\n<p>Note that the EBS volumes are not part of any ASG <a href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-templates.html\">Launch Template</a>, nor do they scale automatically with the ASGs.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image3.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 6 Steps for the Strimzi Operator to create an EBS volume and attach it to a new Kafka pod.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 6 illustrates how this works when Strimzi sets up a new Kafka broker, for example the first broker of the cluster in the initial setup:</p>\n\n<ol>\n  <li>The <a href=\"https://strimzi.io/docs/operators/latest/overview#overview-components-cluster-operator-str\">Strimzi Cluster Operator</a> first creates a new PVC, specifying a volume size and EBS gp3 as its storage class. The storage class is configured with the EBS CSI Driver as the volume provisioner, so that volumes are dynamically provisioned <a href=\"https://engineering.grab.com/feed.xml#1\">[1]</a>. However, because it is also set up with <code class=\"language-plaintext highlighter-rouge\">volumeBindingMode: WaitForFirstConsumer</code>, the volume is not yet provisioned until a pod actually claims the PVC.</li>\n  <li>The Strimzi Cluster Operator then creates the Kafka pod, with a reference to the newly created PVC. The pod is scheduled to start, which in turn claims the PVC.</li>\n  <li>This triggers the EBS CSI Controller. As the volume provisioner, it dynamically creates a new EBS volume in the AWS VPC, in the AZ of the worker node where the pod has been scheduled to start.</li>\n  <li>It then attaches the newly created EBS volume to the corresponding EC2 instance.</li>\n  <li>After that, it creates a Kubernetes PV with <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#node-affinity\">nodeAffinity</a> and <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#reserving-a-persistentvolume\">claimRef</a> specifications, making sure that the PV is reserved for the Kafka broker 1 pod.</li>\n  <li>Lastly, it updates the PVC with the reference of the newly created PV. The PVC is now in <em>Bound</em> state and the Kafka pod can start.</li>\n</ol>\n\n<p>One important point to take note of is that EBS volumes can only be attached to EC2 instances residing in their own AZ. Therefore, when rotating a worker node, the EBS volume can only be re-attached to the new instance if both old and new instances reside in the same AZ. A simple way to guarantee this is to set up one ASG per AZ, instead of a single ASG spanning across 3 AZs.</p>\n\n<p>Also, when such a rotation occurs, the new broker only needs to synchronise the recent data produced during the brief downtime, which is typically an order of magnitude faster than replicating the entire volume (depending on the overall retention period of the hosted Kafka topics).</p>\n\n<table class=\"table\">\n<caption style=\"text-align: center;\">Table 1 Comparison of the resynchronization of the Kafka data after a broker rotation between the initial design and the new design with EBS volumes.</caption>\n<thead>\n  <tr>\n    <th></th>\n    <th>Initial design (NVMe instance store volumes)</th>\n    <th>New design (EBS volumes)</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td>Data to synchronise</td>\n    <td>All of the data</td>\n    <td>Recent data produced during the brief downtime</td>\n  </tr>\n  <tr>\n    <td>Function of (primarily)</td>\n    <td>Retention period</td>\n    <td>Downtime</td>\n  </tr>\n  <tr>\n    <td>Typical duration</td>\n    <td>Hours</td>\n    <td>Minutes</td>\n  </tr>\n</tbody>\n</table>\n\n<h2 id=\"outcome\">Outcome</h2>\n\n<p>With all that, let us revisit the initial scenario, where a malfunctioning worker node is being replaced by a fresh new node.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image1.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 7 Representation of a worker node termination after implementing the solution. Node C is terminated and replaced by node D. This time, the Kafka broker 3 pod is able to start and serve traffic.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 7 shows the worker node C being terminated and replaced (by the ASG) by a new worker node D, similar to what we have described in the initial problem statement. The worker node D automatically joins the Kubernetes cluster on start-up.</p>\n\n<p>However, this time, a seamless failover takes place:</p>\n\n<ol>\n  <li>The Kafka clients that were in the middle of producing or consuming to/from the partition leaders of Kafka broker 3 are gracefully redirected to Kafka brokers 1 and 2, where Kafka has migrated the leadership of its leader partitions.</li>\n  <li>The target groups of the NLB for both the bootstrap connection and Kafka broker 3 are automatically updated by the LBC. The connectivity between the NLB and Kafka broker 3 is immediately restored.</li>\n  <li>Triggered by the creation of the Kafka broker 3 pod, the Amazon EBS CSI driver running on the worker node D re-attaches the EBS volume 3 that was previously attached to the worker node C, to the worker node D instead. This enables Kubernetes to automatically re-bind the corresponding PV and PVC to Kafka broker 3 pod. With its storage dependency resolved, Kafka broker 3 is able to start successfully and re-join the Kafka cluster. From there, it only needs to catch up with the new data that was produced \nduring its short downtime, by replicating it from Kafka brokers 1 and 2.</li>\n</ol>\n\n<p>With this fault-tolerant design, when an EC2 instance is being retired by AWS, no particular action is required from our end.</p>\n\n<p>Similarly, our EKS version upgrades, as well as any operations that require rotating all worker nodes of the cluster in general, are:</p>\n\n<ul>\n  <li><strong>Simpler and less error-prone</strong>: We only need to rotate each instance in sequence, with no need for manually reconfiguring the target groups of the NLB and deleting the zombie PVCs anymore.</li>\n  <li><strong>Faster</strong>: The time between each instance rotation is limited to the short amount of time it takes for the restarted Kafka broker to catch up with the new data.</li>\n  <li><strong>More cost-efficient</strong>: There is less data to transfer across AZs (which is charged by AWS).</li>\n</ul>\n\n<p>It is worth noting that we have chosen to omit Zookeeper and Cruise Control in this article, for the sake of clarity and simplicity. In reality, all pods in the Kubernetes cluster - including Zookeeper and Cruise Control - now benefit from the same graceful stop, triggered by the AWS termination events and the NTH. Similarly, the EBS CSI driver improves the fault tolerance of any pods that use EBS volumes for persistent storage, which includes the Zookeeper pods.</p>\n\n<h2 id=\"challenges-faced\">Challenges faced</h2>\n\n<p>One challenge that we are facing with this design lies in the EBS volumes\u2019 management.</p>\n\n<p>On the one hand, the size of EBS volumes cannot be increased consecutively before the end of a cooldown period (minimum of 6 hours and can exceed 24 hours in some cases <a href=\"https://engineering.grab.com/feed.xml#2\">[2]</a>). Therefore, when we need to urgently extend some EBS volumes because the size of a Kafka topic is suddenly growing, we need to be relatively generous when sizing the new required capacity and add a comfortable security margin, to make sure that we are not running out of storage in the short run.</p>\n\n<p>On the other hand, shrinking a Kubernetes PV is not a supported operation. This can affect the cost efficiency of our design if we overprovision the storage capacity by too much, or in case the workload of a particular cluster organically diminishes.</p>\n\n<p>One way to mitigate this challenge is to tactically scale the cluster horizontally (ie. adding new brokers) when there is a need for more storage and the existing EBS volumes are stuck in a cooldown period, or when the new storage need is only temporary.</p>\n\n<h2 id=\"whats-next\">What\u2019s next?</h2>\n\n<p>In the future, we can improve the NTH\u2019s capability by utilising webhooks. Upon receiving events from SQS, the NTH can also forward the events to the specified webhook URLs.</p>\n\n<p>This can potentially benefit us in a few ways, e.g.:</p>\n\n<ul>\n  <li>Proactively spinning up a new instance without waiting for the old one to be terminated, whenever a termination event is received. This would shorten the rotation time even further.</li>\n  <li>Sending Slack notifications to Coban engineers to keep them informed of any actions taken by the NTH.</li>\n</ul>\n\n<p>We would need to develop and maintain an application that receives webhook events from the NTH and performs the necessary actions.</p>\n\n<p>In addition, we are also rolling out <a href=\"https://karpenter.sh/\">Karpenter</a> to replace the Kubernetes Cluster Autoscaler, as it is able to spin up new instances slightly faster, helping reduce the four minutes delay a Kafka pod remains in <em>Pending</em> state during a node rotation. Incidentally, Karpenter also removes the need for setting up one ASG by AZ, as it is able to deterministically provision instances in a specific AZ, for example where a particular EBS volume resides.</p>\n\n<p>Lastly, to ensure that the performance of our EBS gp3 volumes is both sufficient and cost-efficient, we want to explore autoscaling their throughput and IOPS beyond the baseline, based on the usage metrics collected by our monitoring stack.</p>\n\n<h2 id=\"references\">References</h2>\n\n<p><a href=\"https://engineering.grab.com/feed.xml#1\" name=\"1\">[1]</a> <a href=\"https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/\">Dynamic Volume Provisioning | Kubernetes</a></p>\n\n<p><a href=\"https://engineering.grab.com/feed.xml#2\" name=\"2\">[2]</a> <a href=\"https://repost.aws/knowledge-center/ebs-volume-stuck-optimizing-on-modification\">Troubleshoot EBS volume stuck in Optimizing state during modification | AWS re:Post</a></p>\n\n<p><small class=\"credits\">We would like to thank our team members and Grab Kubernetes gurus that helped review and improve this blog before publication: Will Ho, Gable Heng, Dewin Goh, Vinnson Lee, Siddharth Pandey, Shi Kai Ng, Quang Minh Tran, Yong Liang Oh, Leon Tay, Tuan Anh Vu. </small></p>\n\n<h1 id=\"join-us\">Join us</h1>\n\n<p>Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.</p>\n\n<p>Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, <a href=\"https://grab.careers/\">join our team</a> today!</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.grab.com/feed.xml",
      "value": "<h2 id=\"introduction\">Introduction</h2>\n\n<p>Coban - Grab\u2019s real-time data streaming platform - has been operating <a href=\"https://kafka.apache.org/\">Kafka</a> on <a href=\"https://kubernetes.io/\">Kubernetes</a> with <a href=\"https://strimzi.io/\">Strimzi</a> in \nproduction for about two years. In a previous article (<a href=\"https://engineering.grab.com/zero-trust-with-kafka\">Zero trust with Kafka</a>), we explained how we leveraged Strimzi to enhance the security of our data streaming offering.</p>\n\n<p>In this article, we are going to describe how we improved the fault tolerance of our initial design, to the point where we no longer need to intervene if a Kafka broker is unexpectedly terminated.</p>\n\n<h2 id=\"problem-statement\">Problem statement</h2>\n\n<p>We operate Kafka in the AWS Cloud. For the Kafka on Kubernetes design described in this article, we rely on <a href=\"https://aws.amazon.com/eks/\">Amazon Elastic Kubernetes Service</a> (EKS), the managed Kubernetes offering by AWS, with the worker nodes deployed as <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/worker.html\">self-managed nodes</a> on <a href=\"https://aws.amazon.com/ec2/\">Amazon Elastic Compute Cloud</a> (EC2).</p>\n\n<p>To make our operations easier and limit the blast radius of any incidents, we deploy exactly one Kafka cluster for each EKS cluster. We also give a full worker node to each Kafka broker. In terms of storage, we initially relied on EC2 instances with <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html\">non-volatile memory express (NVMe) instance store volumes</a> for \nmaximal I/O performance. Also, each Kafka cluster is accessible beyond its own <a href=\"https://aws.amazon.com/vpc/\">Virtual Private Cloud</a> (VPC) via a <a href=\"https://docs.aws.amazon.com/vpc/latest/privatelink/privatelink-share-your-services.html\">VPC Endpoint Service</a>.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image5.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 1 Initial design of a 3-node Kafka cluster running on Kubernetes.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 1 shows a logical view of our initial design of a 3-node Kafka on Kubernetes cluster, as typically run by Coban. The Zookeeper and Cruise-Control components are not shown for clarity.</p>\n\n<p>There are four Kubernetes services (1): one for the initial connection - referred to as \u201cbootstrap\u201d - that redirects incoming traffic to any Kafka pods, plus one for each Kafka pod, for the clients to target each Kafka broker individually (a requirement to produce or consume from/to a partition that resides on any particular Kafka broker). Four different listeners on the Network Load Balancer (NLB) listening on four different TCP ports, enable the Kafka clients to target either the bootstrap \nservice or any particular Kafka broker they need to reach. This is very similar to what we previously described in <a href=\"https://engineering.grab.com/exposing-kafka-cluster\">Exposing a Kafka Cluster via a VPC Endpoint Service</a>.</p>\n\n<p>Each worker node hosts a single Kafka pod (2). The NVMe instance store volume is used to create a Kubernetes Persistent Volume (PV), attached to a pod via a Kubernetes Persistent Volume Claim (PVC).</p>\n\n<p>Lastly, the worker nodes belong to <a href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html\">Auto-Scaling Groups</a> (ASG) (3), one by <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-availability-zones\">Availability Zone</a> (AZ). Strimzi adds in node affinity to make sure that the brokers are evenly distributed across AZs. In this initial design, ASGs are not for auto-scaling though, because we want to keep the size of the cluster under control. We only use ASGs - with a fixed size - to facilitate manual scaling operation and to automatically replace the terminated worker nodes.</p>\n\n<p>With this initial design, let us see what happens in case of such a worker node termination.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image4.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 2 Representation of a worker node termination. Node C is terminated and replaced by node D. However the Kafka broker 3 pod is unable to restart on node D.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 2 shows the worker node C being terminated along with its NVMe instance store volume C, and replaced (by the ASG) by a new worker node D and its new, empty NVMe instance store volume D. On start-up, the worker node D automatically joins the Kubernetes cluster. The Kafka broker 3 pod that was running on the faulty worker node C is scheduled to restart on the new worker node D.</p>\n\n<p>Although the NVMe instance store volume C is terminated along with the worker node C, there is no data loss because all of our Kafka topics are configured with a minimum of three replicas. The data is poised to be copied over from the surviving Kafka brokers 1 and 2 back to Kafka broker 3, as soon as Kafka broker 3 is effectively restarted on the worker node D.</p>\n\n<p>However, there are three fundamental issues with this initial design:</p>\n\n<ol>\n  <li>The Kafka clients that were in the middle of producing or consuming to/from the partition leaders of Kafka broker 3 are suddenly facing connection errors, because the broker was not gracefully demoted beforehand.</li>\n  <li>The target groups of the NLB for both the bootstrap connection and Kafka broker 3 still point to the worker node C. Therefore, the network communication from the NLB to Kafka broker 3 is broken. A manual reconfiguration of the target groups is required.</li>\n  <li>The PVC associating the Kafka broker 3 pod with its instance store PV is unable to automatically switch to the new NVMe instance store volume of the worker node D. Indeed, static provisioning is an intrinsic characteristic of Kubernetes <a href=\"https://kubernetes.io/docs/concepts/storage/volumes/#local\">local volumes</a>. The PVC is still in <em>Bound</em> state, so Kubernetes does not take any action. However, the actual storage beneath the PV does not exist anymore. Without any storage, the Kafka broker 3 pod is unable to start.</li>\n</ol>\n\n<p>At this stage, the Kafka cluster is running in a degraded state with only two out of three brokers, until a Coban engineer intervenes to reconfigure the target groups of the NLB and delete the zombie PVC (this, in turn, triggers its re-creation by Strimzi, this time using the new instance store PV).</p>\n\n<p>In the next section, we will see how we have managed to address the three issues mentioned above to make this design fault-tolerant.</p>\n\n<h2 id=\"solution\">Solution</h2>\n\n<h3 id=\"graceful-kafka-shutdown\">Graceful Kafka shutdown</h3>\n\n<p>To minimise the disruption for the Kafka clients, we leveraged the <a href=\"https://aws-quickstart.github.io/cdk-eks-blueprints/addons/aws-node-termination-handler/\">AWS Node Termination Handler</a> (NTH). This component provided by AWS for Kubernetes environments is able to cordon and drain a worker node that is going to be terminated. This draining, in turn, triggers a graceful shutdown of the Kafka \nprocess by sending a polite <a href=\"https://www.gnu.org/software/libc/manual/html_node/Termination-Signals.html\">SIGTERM</a> signal to all pods running on the worker node that is being drained (instead of the brutal <a href=\"https://www.gnu.org/software/libc/manual/html_node/Termination-Signals.html\">SIGKILL</a> of a normal termination).</p>\n\n<p>The termination events of interest that are captured by the NTH are:</p>\n\n<ul>\n  <li>Scale-in operations by an ASG.</li>\n  <li>Manual termination of an instance.</li>\n  <li>AWS maintenance events, typically EC2 instances scheduled for upcoming retirement.</li>\n</ul>\n\n<p>This suffices for most of the disruptions our clusters can face in normal times and our common maintenance operations, such as terminating a worker node to refresh it. Only sudden hardware failures (AWS issue events) would fall through the cracks and still trigger errors on the Kafka client side.</p>\n\n<p>The NTH comes in two modes: <a href=\"https://github.com/aws/aws-node-termination-handler#major-features\">Instance Metadata Service (IMDS) and Queue Processor</a>. We chose to go with the latter as it is able to capture a broader range of events, widening the fault tolerance capability.</p>\n\n<h4 id=\"scale-in-operations-by-an-asg\">Scale-in operations by an ASG</h4>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image2.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 3 Architecture of the NTH with the Queue Processor.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 3 shows the NTH with the Queue Processor in action, and how it reacts to a scale-in operation (typically triggered manually, during a maintenance operation):</p>\n\n<ol>\n  <li>As soon as the scale-in operation is triggered, an <a href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html\">Auto Scaling lifecycle hook</a> is invoked to pause the termination of the instance.</li>\n  <li>Simultaneously, an Auto Scaling lifecycle hook event is issued to an <a href=\"https://aws.amazon.com/sqs/\">Amazon Simple Queue Service</a> (SQS) queue. In Fig. 3, we have also materialised EC2 events (e.g. manual termination of an instance, AWS maintenance events, etc.) that transit via <a href=\"https://aws.amazon.com/eventbridge/\">Amazon EventBridge</a> to eventually end up in the same SQS queue. We will discuss EC2 events in the next two sections.</li>\n  <li>The NTH, a pod running in the Kubernetes cluster itself, constantly polls that SQS queue.</li>\n  <li>When a scale-in event pertaining to a worker node of the Kubernetes cluster is read from the SQS queue, the NTH sends to the Kubernetes API the instruction to <a href=\"https://kubernetes.io/docs/concepts/architecture/nodes/#manual-node-administration\">cordon</a> and <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/\">drain</a> the impacted worker node.</li>\n  <li>On draining, Kubernetes sends a SIGTERM signal to the Kafka pod residing on the worker node.</li>\n  <li>Upon receiving the SIGTERM signal, the Kafka pod gracefully migrates the leadership of its leader partitions to other brokers of the cluster before shutting down, in a transparent manner for the clients. This behaviour is ensured by the <a href=\"https://kafka.apache.org/documentation/#basic_ops_restarting\"><code class=\"language-plaintext highlighter-rouge\">controlled.shutdown.enable</code></a> parameter of Kafka, which is enabled by default.</li>\n  <li>Once the impacted worker node has been drained, the NTH eventually resumes the termination of the instance.</li>\n</ol>\n\n<p>Strimzi also comes with a <code class=\"language-plaintext highlighter-rouge\">terminationGracePeriodSeconds</code> parameter, which we have set to 180 seconds to give the Kafka pods enough time to migrate all of their partition leaders gracefully on termination. We have verified that this is enough to migrate all partition leaders on our Kafka clusters (about 60 seconds for 600 partition leaders).</p>\n\n<h4 id=\"manual-termination-of-an-instance\">Manual termination of an instance</h4>\n\n<p>The Auto Scaling lifecycle hook that pauses the termination of an instance (Fig. 3, step 1) as well as the corresponding resuming by the NTH (Fig. 3, step 7) are invoked only for ASG scaling events.</p>\n\n<p>In case of a manual termination of an EC2 instance, the termination is captured as an EC2 event that also reaches the NTH. Upon receiving that event, the NTH cordons and drains the impacted worker node. However, the instance is immediately terminated, most likely before the leadership of all of its Kafka partition leaders has had the time to get migrated to other brokers.</p>\n\n<p>To work around this and let a manual termination of an EC2 instance also benefit from the ASG lifecycle hook, the instance must be terminated using the <a href=\"https://docs.aws.amazon.com/cli/latest/reference/autoscaling/terminate-instance-in-auto-scaling-group.html\"><code class=\"language-plaintext highlighter-rouge\">terminate-instance-in-auto-scaling-group</code></a> AWS CLI command.</p>\n\n<h4 id=\"aws-maintenance-events\">AWS maintenance events</h4>\n\n<p>For AWS maintenance events such as instances scheduled for upcoming retirement, the NTH acts immediately when the event is first received (typically adequately in advance). It cordons and drains the soon-to-be-retired worker node, which in turn triggers the SIGTERM signal and the graceful termination of Kafka as described above. At this stage, the impacted instance is not terminated, so the Kafka partition leaders have plenty of time to complete their migration to other brokers.</p>\n\n<p>However, the evicted Kafka pod has nowhere to go. There is a need for spinning up a new worker node for it to be able to eventually restart somewhere.</p>\n\n<p>To make this happen seamlessly, we doubled the maximum size of each of our ASGs and installed the <a href=\"https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md\">Kubernetes Cluster Autoscaler</a>. With that, when such a maintenance event is received:</p>\n\n<ul>\n  <li>The worker node scheduled for retirement is cordoned and drained by the NTH. The state of the impacted Kafka pod becomes <em>Pending</em>.</li>\n  <li>The Kubernetes Cluster Autoscaler comes into play and triggers the corresponding ASG to spin up a new EC2 instance that joins the Kubernetes cluster as a new worker node.</li>\n  <li>The impacted Kafka pod restarts on the new worker node.</li>\n  <li>The Kubernetes Cluster Autoscaler detects that the previous worker node is now under-utilised and terminates it.</li>\n</ul>\n\n<p>In this scenario, the impacted Kafka pod only remains in <em>Pending</em> state for about four minutes in total.</p>\n\n<p>In case of multiple simultaneous AWS maintenance events, the Kubernetes scheduler would honour our <a href=\"https://kubernetes.io/docs/tasks/run-application/configure-pdb/\">PodDisruptionBudget</a> and not evict more than one Kafka pod at a time.</p>\n\n<h3 id=\"dynamic-nlb-configuration\">Dynamic NLB configuration</h3>\n\n<p>To automatically map the NLB\u2019s target groups with a newly spun up EC2 instance, we leveraged the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html\">AWS Load Balancer Controller</a> (LBC).</p>\n\n<p>Let us see how it works.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image6.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 4 Architecture of the LBC managing the NLB's target groups via TargetGroupBinding custom resources.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 4 shows how the LBC automates the reconfiguration of the NLB\u2019s target groups:</p>\n\n<ol>\n  <li>It first retrieves the desired state described in Kubernetes <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">custom resources</a> (CR) of type <a href=\"https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/guide/targetgroupbinding/targetgroupbinding\">TargetGroupBinding</a>. There is one such resource per target group to maintain. Each TargetGroupBinding CR associates its respective target group with a Kubernetes service.</li>\n  <li>The LBC then watches over the changes of the Kubernetes services that are referenced in the TargetGroupBinding CRs\u2019 definition, specifically the private IP addresses exposed by their respective <a href=\"https://kubernetes.io/docs/concepts/services-networking/service/#endpoints\">Endpoints resources</a>.</li>\n  <li>When a change is detected, it dynamically updates the corresponding NLB\u2019s target groups with those IP addresses as well as the TCP port of the target containers (<code class=\"language-plaintext highlighter-rouge\">containerPort</code>).</li>\n</ol>\n\n<p>This automated design sets up the NLB\u2019s target groups with IP addresses (<code class=\"language-plaintext highlighter-rouge\">targetType: ip</code>) instead of EC2 instance IDs (<code class=\"language-plaintext highlighter-rouge\">targetType: instance</code>). Although the LBC can handle both target types, the IP address approach is actually more straightforward in our case, since each pod has a routable private IP address in the AWS subnet, thanks to the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/managing-vpc-cni.html\">AWS Container Networking Interface</a> (CNI) plug-in.</p>\n\n<p>This dynamic NLB configuration design comes with a challenge. Whenever we need to update the Strimzi CR, the rollout of the change to each Kafka pod in a rolling update fashion is happening too fast for the NLB. This is because the NLB inherently takes some time to mark each target as healthy before enabling it. The Kafka brokers that have just been rolled out start advertising their broker-specific endpoints to the Kafka clients via the bootstrap service, but those \nendpoints are actually not immediately available because the NLB is still checking their health. To mitigate this, we have reduced the <code class=\"language-plaintext highlighter-rouge\">HealthCheckIntervalSeconds</code> and <code class=\"language-plaintext highlighter-rouge\">HealthyThresholdCount</code> parameters of each target group to their minimum values of 5 and 2 respectively. This reduces the maximum delay for the NLB to detect that a target has become healthy to 10 seconds. In addition, we have configured the LBC with a <a href=\"https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/deploy/pod_readiness_gate/\">Pod Readiness Gate</a>. This feature makes the Strimzi rolling deployment wait for the health check of the NLB to pass, before marking the current pod as <em>Ready</em> and proceeding with the next pod.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image7.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 5 Steps for a Strimzi rolling deployment with a Pod Readiness Gate. Only one Kafka broker and one NLB listener and target group are shown for simplicity.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 5 shows how the Pod Readiness Gate works during a Strimzi rolling deployment:</p>\n\n<ol>\n  <li>The old Kafka pod is terminated.</li>\n  <li>The new Kafka pod starts up and joins the Kafka cluster. Its individual endpoint for direct access via the NLB is immediately advertised by the Kafka cluster. However, at this stage, it is not reachable, as the target group of the NLB still points to the IP address of the old Kafka pod.</li>\n  <li>The LBC updates the target group of the NLB with the IP address of the new Kafka pod, but the NLB health check has not yet passed, so the traffic is not forwarded to the new Kafka pod just yet.</li>\n  <li>The LBC then waits for the NLB health check to pass, which takes 10 seconds. Once the NLB health check has passed, the NLB resumes forwarding the traffic to the Kafka pod.</li>\n  <li>Finally, the LBC updates the pod readiness gate of the new Kafka pod. This informs Strimzi that it can proceed with the next pod of the rolling deployment.</li>\n</ol>\n\n<h3 id=\"data-persistence-with-ebs\">Data persistence with EBS</h3>\n\n<p>To address the challenge of the residual PV and PVC of the old worker node preventing Kubernetes from mounting the local storage of the new worker node after a node rotation, we adopted <a href=\"https://aws.amazon.com/ebs/\">Elastic Block Store</a> (EBS) volumes instead of NVMe instance store volumes. Contrary to the latter, EBS volumes can conveniently be attached and detached. The trade-off is that their performance is significantly lower.</p>\n\n<p>However, relying on EBS comes with additional benefits:</p>\n\n<ul>\n  <li>The cost per GB is lower, compared to NVMe instance store volumes.</li>\n  <li>Using EBS decouples the size of an instance in terms of CPU and memory from its storage capacity, leading to further cost savings by independently right-sizing the instance type and its storage. Such a separation of concerns also opens the door to new use cases requiring disproportionate amounts of storage.</li>\n  <li>After a worker node rotation, the time needed for the new node to get back in sync is faster, as it only needs to catch up the data that was produced during the downtime. This leads to shorter maintenance operations and higher iteration speed. Incidentally, the associated inter-AZ traffic cost is also lower, since there is less data to transfer among brokers during this time.</li>\n  <li>Increasing the storage capacity is an online operation.</li>\n  <li>Data backup is supported by taking snapshots of EBS volumes.</li>\n</ul>\n\n<p>We have verified with our historical monitoring data that the performance of <a href=\"https://aws.amazon.com/ebs/general-purpose/\">EBS General Purpose 3</a> (gp3) volumes is significantly above our maximum historical values for both throughput and I/O per second (IOPS), and we have successfully benchmarked a test EBS-based Kafka cluster. We have also set up new monitors to be alerted in case we need to \nprovision either additional throughput or IOPS, beyond the baseline of EBS gp3 volumes.</p>\n\n<p>With that, we updated our instance types from storage optimised instances to either general purpose or memory optimised instances. We added the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html\">Amazon EBS Container Storage Interface (CSI) driver</a> to the Kubernetes cluster and created a new Kubernetes <a href=\"https://kubernetes.io/docs/concepts/storage/storage-classes/\">storage class</a> to let the cluster dynamically provision EBS gp3 volumes.</p>\n\n<p>We configured Strimzi to use that storage class to create any new PVCs. This makes Strimzi able to automatically create the EBS volumes it needs, typically when the cluster is first set up, but also to attach/detach the volumes to/from the EC2 instances whenever a Kafka pod is relocated to a different worker node.</p>\n\n<p>Note that the EBS volumes are not part of any ASG <a href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-templates.html\">Launch Template</a>, nor do they scale automatically with the ASGs.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image3.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 6 Steps for the Strimzi Operator to create an EBS volume and attach it to a new Kafka pod.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 6 illustrates how this works when Strimzi sets up a new Kafka broker, for example the first broker of the cluster in the initial setup:</p>\n\n<ol>\n  <li>The <a href=\"https://strimzi.io/docs/operators/latest/overview#overview-components-cluster-operator-str\">Strimzi Cluster Operator</a> first creates a new PVC, specifying a volume size and EBS gp3 as its storage class. The storage class is configured with the EBS CSI Driver as the volume provisioner, so that volumes are dynamically provisioned <a href=\"https://engineering.grab.com/feed.xml#1\">[1]</a>. However, because it is also set up with <code class=\"language-plaintext highlighter-rouge\">volumeBindingMode: WaitForFirstConsumer</code>, the volume is not yet provisioned until a pod actually claims the PVC.</li>\n  <li>The Strimzi Cluster Operator then creates the Kafka pod, with a reference to the newly created PVC. The pod is scheduled to start, which in turn claims the PVC.</li>\n  <li>This triggers the EBS CSI Controller. As the volume provisioner, it dynamically creates a new EBS volume in the AWS VPC, in the AZ of the worker node where the pod has been scheduled to start.</li>\n  <li>It then attaches the newly created EBS volume to the corresponding EC2 instance.</li>\n  <li>After that, it creates a Kubernetes PV with <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#node-affinity\">nodeAffinity</a> and <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#reserving-a-persistentvolume\">claimRef</a> specifications, making sure that the PV is reserved for the Kafka broker 1 pod.</li>\n  <li>Lastly, it updates the PVC with the reference of the newly created PV. The PVC is now in <em>Bound</em> state and the Kafka pod can start.</li>\n</ol>\n\n<p>One important point to take note of is that EBS volumes can only be attached to EC2 instances residing in their own AZ. Therefore, when rotating a worker node, the EBS volume can only be re-attached to the new instance if both old and new instances reside in the same AZ. A simple way to guarantee this is to set up one ASG per AZ, instead of a single ASG spanning across 3 AZs.</p>\n\n<p>Also, when such a rotation occurs, the new broker only needs to synchronise the recent data produced during the brief downtime, which is typically an order of magnitude faster than replicating the entire volume (depending on the overall retention period of the hosted Kafka topics).</p>\n\n<table class=\"table\">\n<caption style=\"text-align: center;\">Table 1 Comparison of the resynchronization of the Kafka data after a broker rotation between the initial design and the new design with EBS volumes.</caption>\n<thead>\n  <tr>\n    <th></th>\n    <th>Initial design (NVMe instance store volumes)</th>\n    <th>New design (EBS volumes)</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td>Data to synchronise</td>\n    <td>All of the data</td>\n    <td>Recent data produced during the brief downtime</td>\n  </tr>\n  <tr>\n    <td>Function of (primarily)</td>\n    <td>Retention period</td>\n    <td>Downtime</td>\n  </tr>\n  <tr>\n    <td>Typical duration</td>\n    <td>Hours</td>\n    <td>Minutes</td>\n  </tr>\n</tbody>\n</table>\n\n<h2 id=\"outcome\">Outcome</h2>\n\n<p>With all that, let us revisit the initial scenario, where a malfunctioning worker node is being replaced by a fresh new node.</p>\n\n<div class=\"post-image-section\"><figure>\n  <img alt=\"\" src=\"https://engineering.grab.com/img/kafka-on-kubernetes/image1.png\" style=\"width: 80%;\" /><figcaption align=\"middle\">Fig. 7 Representation of a worker node termination after implementing the solution. Node C is terminated and replaced by node D. This time, the Kafka broker 3 pod is able to start and serve traffic.</figcaption>\n  </figure>\n</div>\n\n<p>Fig. 7 shows the worker node C being terminated and replaced (by the ASG) by a new worker node D, similar to what we have described in the initial problem statement. The worker node D automatically joins the Kubernetes cluster on start-up.</p>\n\n<p>However, this time, a seamless failover takes place:</p>\n\n<ol>\n  <li>The Kafka clients that were in the middle of producing or consuming to/from the partition leaders of Kafka broker 3 are gracefully redirected to Kafka brokers 1 and 2, where Kafka has migrated the leadership of its leader partitions.</li>\n  <li>The target groups of the NLB for both the bootstrap connection and Kafka broker 3 are automatically updated by the LBC. The connectivity between the NLB and Kafka broker 3 is immediately restored.</li>\n  <li>Triggered by the creation of the Kafka broker 3 pod, the Amazon EBS CSI driver running on the worker node D re-attaches the EBS volume 3 that was previously attached to the worker node C, to the worker node D instead. This enables Kubernetes to automatically re-bind the corresponding PV and PVC to Kafka broker 3 pod. With its storage dependency resolved, Kafka broker 3 is able to start successfully and re-join the Kafka cluster. From there, it only needs to catch up with the new data that was produced \nduring its short downtime, by replicating it from Kafka brokers 1 and 2.</li>\n</ol>\n\n<p>With this fault-tolerant design, when an EC2 instance is being retired by AWS, no particular action is required from our end.</p>\n\n<p>Similarly, our EKS version upgrades, as well as any operations that require rotating all worker nodes of the cluster in general, are:</p>\n\n<ul>\n  <li><strong>Simpler and less error-prone</strong>: We only need to rotate each instance in sequence, with no need for manually reconfiguring the target groups of the NLB and deleting the zombie PVCs anymore.</li>\n  <li><strong>Faster</strong>: The time between each instance rotation is limited to the short amount of time it takes for the restarted Kafka broker to catch up with the new data.</li>\n  <li><strong>More cost-efficient</strong>: There is less data to transfer across AZs (which is charged by AWS).</li>\n</ul>\n\n<p>It is worth noting that we have chosen to omit Zookeeper and Cruise Control in this article, for the sake of clarity and simplicity. In reality, all pods in the Kubernetes cluster - including Zookeeper and Cruise Control - now benefit from the same graceful stop, triggered by the AWS termination events and the NTH. Similarly, the EBS CSI driver improves the fault tolerance of any pods that use EBS volumes for persistent storage, which includes the Zookeeper pods.</p>\n\n<h2 id=\"challenges-faced\">Challenges faced</h2>\n\n<p>One challenge that we are facing with this design lies in the EBS volumes\u2019 management.</p>\n\n<p>On the one hand, the size of EBS volumes cannot be increased consecutively before the end of a cooldown period (minimum of 6 hours and can exceed 24 hours in some cases <a href=\"https://engineering.grab.com/feed.xml#2\">[2]</a>). Therefore, when we need to urgently extend some EBS volumes because the size of a Kafka topic is suddenly growing, we need to be relatively generous when sizing the new required capacity and add a comfortable security margin, to make sure that we are not running out of storage in the short run.</p>\n\n<p>On the other hand, shrinking a Kubernetes PV is not a supported operation. This can affect the cost efficiency of our design if we overprovision the storage capacity by too much, or in case the workload of a particular cluster organically diminishes.</p>\n\n<p>One way to mitigate this challenge is to tactically scale the cluster horizontally (ie. adding new brokers) when there is a need for more storage and the existing EBS volumes are stuck in a cooldown period, or when the new storage need is only temporary.</p>\n\n<h2 id=\"whats-next\">What\u2019s next?</h2>\n\n<p>In the future, we can improve the NTH\u2019s capability by utilising webhooks. Upon receiving events from SQS, the NTH can also forward the events to the specified webhook URLs.</p>\n\n<p>This can potentially benefit us in a few ways, e.g.:</p>\n\n<ul>\n  <li>Proactively spinning up a new instance without waiting for the old one to be terminated, whenever a termination event is received. This would shorten the rotation time even further.</li>\n  <li>Sending Slack notifications to Coban engineers to keep them informed of any actions taken by the NTH.</li>\n</ul>\n\n<p>We would need to develop and maintain an application that receives webhook events from the NTH and performs the necessary actions.</p>\n\n<p>In addition, we are also rolling out <a href=\"https://karpenter.sh/\">Karpenter</a> to replace the Kubernetes Cluster Autoscaler, as it is able to spin up new instances slightly faster, helping reduce the four minutes delay a Kafka pod remains in <em>Pending</em> state during a node rotation. Incidentally, Karpenter also removes the need for setting up one ASG by AZ, as it is able to deterministically provision instances in a specific AZ, for example where a particular EBS volume resides.</p>\n\n<p>Lastly, to ensure that the performance of our EBS gp3 volumes is both sufficient and cost-efficient, we want to explore autoscaling their throughput and IOPS beyond the baseline, based on the usage metrics collected by our monitoring stack.</p>\n\n<h2 id=\"references\">References</h2>\n\n<p><a href=\"https://engineering.grab.com/feed.xml#1\" name=\"1\">[1]</a> <a href=\"https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/\">Dynamic Volume Provisioning | Kubernetes</a></p>\n\n<p><a href=\"https://engineering.grab.com/feed.xml#2\" name=\"2\">[2]</a> <a href=\"https://repost.aws/knowledge-center/ebs-volume-stuck-optimizing-on-modification\">Troubleshoot EBS volume stuck in Optimizing state during modification | AWS re:Post</a></p>\n\n<p><small class=\"credits\">We would like to thank our team members and Grab Kubernetes gurus that helped review and improve this blog before publication: Will Ho, Gable Heng, Dewin Goh, Vinnson Lee, Siddharth Pandey, Shi Kai Ng, Quang Minh Tran, Yong Liang Oh, Leon Tay, Tuan Anh Vu. </small></p>\n\n<h1 id=\"join-us\">Join us</h1>\n\n<p>Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.</p>\n\n<p>Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, <a href=\"https://grab.careers/\">join our team</a> today!</p>"
    },
    "published": "Tue, 26 Dec 2023 00:10:10 +0000",
    "published_parsed": [
      2023,
      12,
      26,
      0,
      10,
      10,
      1,
      360,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.grab.com/kafka-on-kubernetes"
      }
    ],
    "link": "https://engineering.grab.com/kafka-on-kubernetes",
    "id": "https://engineering.grab.com/kafka-on-kubernetes",
    "guidislink": false,
    "tags": [
      {
        "term": "Kafka",
        "scheme": null,
        "label": null
      },
      {
        "term": "Kubernetes",
        "scheme": null,
        "label": null
      },
      {
        "term": "AWS",
        "scheme": null,
        "label": null
      },
      {
        "term": "Data Streaming",
        "scheme": null,
        "label": null
      },
      {
        "term": "Engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "Data Science",
        "scheme": null,
        "label": null
      }
    ]
  },
  "PicCollage": {
    "title": "Life at PicCollage: A Look at Our Dev Sessions and Workshops",
    "xmlUrl": "https://tech.pic-collage.com/feed",
    "htmlUrl": "https://tech.pic-collage.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.pic-collage.com/feed",
      "value": "Life at PicCollage: A Look at Our Dev Sessions and Workshops"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.pic-collage.com/life-at-piccollage-a-look-at-our-dev-sessions-and-workshops-ebe1f768e335?source=rss----3819a69148cb---4"
      }
    ],
    "link": "https://tech.pic-collage.com/life-at-piccollage-a-look-at-our-dev-sessions-and-workshops-ebe1f768e335?source=rss----3819a69148cb---4",
    "id": "https://medium.com/p/ebe1f768e335",
    "guidislink": false,
    "tags": [
      {
        "term": "docker-compose",
        "scheme": null,
        "label": null
      },
      {
        "term": "developer",
        "scheme": null,
        "label": null
      },
      {
        "term": "product-development",
        "scheme": null,
        "label": null
      },
      {
        "term": "learning",
        "scheme": null,
        "label": null
      },
      {
        "term": "machine-learning",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "PicCollage"
      }
    ],
    "author": "PicCollage",
    "author_detail": {
      "name": "PicCollage"
    },
    "published": "Fri, 15 Dec 2023 07:36:48 GMT",
    "published_parsed": [
      2023,
      12,
      15,
      7,
      36,
      48,
      4,
      349,
      0
    ],
    "updated": "2023-12-15T07:36:47.911Z",
    "updated_parsed": [
      2023,
      12,
      15,
      7,
      36,
      47,
      4,
      349,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://tech.pic-collage.com/feed",
        "value": "<p>Written by: <a href=\"https://www.linkedin.com/in/mrlaurencejames?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA7E94MBRkqtSMvPssZ2w2ev2ZFlkdTTfXg\">Laurence James</a>, Operations Specialist</p><p>At PicCollage Company, we think that an \u2018Always-Be-Learning\u2019 mindset is a key ingredient in building great products. Our new, monthly Dev Sharing Sessions are just one example of how our team does knowledge exchange\u00a0\ud83d\udc69\ud83c\udf93</p><p>Developers from different teams come together to teach and learn from one another. We share relevant insights that can quickly be applied into our work. For example, Android Dev Patrik recently showcased how to use pre-configured GPTs, using multiple, relevant data sources to better respond to your needs and save time. Data Scientist, Maso also talked about Hopter\u200a\u2014\u200aa platform we built internally that simplifies development, deployment, and monitoring for machine learning \ud83e\udd16 models in a scalable, production ready environment.</p><p>As well as these short, sharp sharing sessions, we also hold regular workshops which go much deeper into topics that are highly relevant to our members. Most recently, Weihang, our Lead Backend Developer, did a deep dive \ud83e\udd3f on Dockerfiles and docker-compose, helping our devs become more efficient in containerization and deployment!</p><p>Our learning activities do more than just build domain expertise, they also bring our team closer together. With better relationships comes increased innovation, helping us Win As a\u00a0Team!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2IBJkWqs0pdz_IoYf1c4xw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*VGDx3u6FdpqNZmzLOVk3jw.jpeg\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ebe1f768e335\" width=\"1\" /><hr /><p><a href=\"https://tech.pic-collage.com/life-at-piccollage-a-look-at-our-dev-sessions-and-workshops-ebe1f768e335\">Life at PicCollage: A Look at Our Dev Sessions and Workshops</a> was originally published in <a href=\"https://tech.pic-collage.com\">PicCollage Company Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>Written by: <a href=\"https://www.linkedin.com/in/mrlaurencejames?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA7E94MBRkqtSMvPssZ2w2ev2ZFlkdTTfXg\">Laurence James</a>, Operations Specialist</p><p>At PicCollage Company, we think that an \u2018Always-Be-Learning\u2019 mindset is a key ingredient in building great products. Our new, monthly Dev Sharing Sessions are just one example of how our team does knowledge exchange\u00a0\ud83d\udc69\ud83c\udf93</p><p>Developers from different teams come together to teach and learn from one another. We share relevant insights that can quickly be applied into our work. For example, Android Dev Patrik recently showcased how to use pre-configured GPTs, using multiple, relevant data sources to better respond to your needs and save time. Data Scientist, Maso also talked about Hopter\u200a\u2014\u200aa platform we built internally that simplifies development, deployment, and monitoring for machine learning \ud83e\udd16 models in a scalable, production ready environment.</p><p>As well as these short, sharp sharing sessions, we also hold regular workshops which go much deeper into topics that are highly relevant to our members. Most recently, Weihang, our Lead Backend Developer, did a deep dive \ud83e\udd3f on Dockerfiles and docker-compose, helping our devs become more efficient in containerization and deployment!</p><p>Our learning activities do more than just build domain expertise, they also bring our team closer together. With better relationships comes increased innovation, helping us Win As a\u00a0Team!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2IBJkWqs0pdz_IoYf1c4xw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*VGDx3u6FdpqNZmzLOVk3jw.jpeg\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ebe1f768e335\" width=\"1\" /><hr /><p><a href=\"https://tech.pic-collage.com/life-at-piccollage-a-look-at-our-dev-sessions-and-workshops-ebe1f768e335\">Life at PicCollage: A Look at Our Dev Sessions and Workshops</a> was originally published in <a href=\"https://tech.pic-collage.com\">PicCollage Company Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Hashrocket": {
    "title": "Navigating Efficiently with CDPATH",
    "xmlUrl": "https://hashrocket.com/blog.rss",
    "htmlUrl": "https://hashrocket.com/blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://hashrocket.com/blog/posts.rss",
      "value": "Navigating Efficiently with CDPATH"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://hashrocket.com/blog/posts/navigating-efficiently-with-cdpath"
      }
    ],
    "link": "https://hashrocket.com/blog/posts/navigating-efficiently-with-cdpath",
    "summary": "<p>The <code>CDPATH</code> shell variable is a powerful tool for navigating directories efficiently in your terminal. It defines a search path for the cd command, allowing you to access directories without typing their full path. This is particularly helpful when working with frequently accessed directories in different locations.</p>\n\n<p>Like the <code>PATH</code> variable used for finding executable files, <code>CDPATH</code> stores a colon-separated list of directories. When you issue a cd command with a directory name, the shell first searches for the directory within the current working directory. If not found, it checks each directory listed in <code>CDPATH</code> in order until it finds a match.</p>\n\n<p>For example, imagine your <code>CDPATH</code> is set to <code>.:~/projects:/usr/bin</code>. If you use <code>cd project1</code>, the shell will first look for a directory named <code>project1</code> within the current directory. If it doesn't exist, it will check your <code>~/projects</code> directory and, finally, the <code>/usr/bin directory</code>. If a matching directory is found in any of these locations, you will be switched to that directory.</p>\n\n<p>Setting <code>CDPATH</code> can be particularly useful for developers who frequently switch between project directories or those working with resources scattered across different locations. Instead of typing the full path each time, you can use the directory name and let <code>CDPATH</code> search.</p>\n\n<p>However, it's essential to be mindful of potential security implications. Including sensitive directories in <code>CDPATH</code> could lead to unauthorized access if not correctly configured. Additionally, using a long <code>CDPATH</code> can slow down the <code>cd</code> command as it needs to perform more searches.</p>\n\n<p><code>CDPATH</code> offers a convenient way to navigate directories efficiently, especially for frequently accessed locations. By understanding its functionality and using it judiciously, you can significantly improve your workflow in the terminal.</p>\n\n<p>While <code>CDPATH</code> offers a powerful way to navigate frequently accessed directories, it's not the only tool available. Modern alternatives like <a href=\"https://github.com/gsamokovarov/jump\"><code>jump</code></a> and <a href=\"https://github.com/ajeetdsouza/zoxide\"><code>zoxide</code></a> provide similar functionality with distinct advantages and disadvantages.</p>\n\n<p><strong>CDPATH:</strong></p>\n\n<p><strong>Pros:</strong>\n* Simple to use and configure.\n- Offers consistent behavior across different shells.\n- Works seamlessly with existing cd workflows.</p>\n\n<p><strong>Cons:</strong>\n* Static search path can be inconvenient for dynamic workflows.\n- Requires manual maintenance of the search path.\n- It may introduce security risks if sensitive directories are included.</p>\n\n<p><strong>Jump:</strong></p>\n\n<p><strong>Pros:</strong>\n* Dynamically learns frequently accessed directories.\n- Offers intelligent suggestions and completions.\n- Supports searching through history and bookmarks.</p>\n\n<p><strong>Cons:</strong>\n* Requires separate installation and configuration.\n- It may introduce additional dependencies and complexity.\n- It may not be compatible with all shells or platforms.</p>\n\n<p><strong>Zoxide:</strong></p>\n\n<p><strong>Pros:</strong>\n* High-speed and efficient directory switching.\n- Integrates seamlessly with the cd command.\n- Learns project context and automatically navigates within project directories.</p>\n\n<p><strong>Cons:</strong>\n* Primarily focused on project-based workflows.\n- It may require additional setup for non-project directories.\n- It may be less intuitive than other tools for simple navigation.</p>\n\n<p><strong>Choosing the Right Tool:</strong></p>\n\n<p>The best tool for you depends on your individual needs and preferences. If you prioritize simplicity and familiarity, <code>CDPATH</code> might be a good choice. However, if you desire dynamic learning, intelligent suggestions, or project-specific navigation, <code>jump</code> or <code>zoxide</code> might offer more benefits.</p>\n\n<p>Ultimately, it's recommended to experiment with each tool and see which one best fits your workflow.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://hashrocket.com/blog/posts.rss",
      "value": "<p>The <code>CDPATH</code> shell variable is a powerful tool for navigating directories efficiently in your terminal. It defines a search path for the cd command, allowing you to access directories without typing their full path. This is particularly helpful when working with frequently accessed directories in different locations.</p>\n\n<p>Like the <code>PATH</code> variable used for finding executable files, <code>CDPATH</code> stores a colon-separated list of directories. When you issue a cd command with a directory name, the shell first searches for the directory within the current working directory. If not found, it checks each directory listed in <code>CDPATH</code> in order until it finds a match.</p>\n\n<p>For example, imagine your <code>CDPATH</code> is set to <code>.:~/projects:/usr/bin</code>. If you use <code>cd project1</code>, the shell will first look for a directory named <code>project1</code> within the current directory. If it doesn't exist, it will check your <code>~/projects</code> directory and, finally, the <code>/usr/bin directory</code>. If a matching directory is found in any of these locations, you will be switched to that directory.</p>\n\n<p>Setting <code>CDPATH</code> can be particularly useful for developers who frequently switch between project directories or those working with resources scattered across different locations. Instead of typing the full path each time, you can use the directory name and let <code>CDPATH</code> search.</p>\n\n<p>However, it's essential to be mindful of potential security implications. Including sensitive directories in <code>CDPATH</code> could lead to unauthorized access if not correctly configured. Additionally, using a long <code>CDPATH</code> can slow down the <code>cd</code> command as it needs to perform more searches.</p>\n\n<p><code>CDPATH</code> offers a convenient way to navigate directories efficiently, especially for frequently accessed locations. By understanding its functionality and using it judiciously, you can significantly improve your workflow in the terminal.</p>\n\n<p>While <code>CDPATH</code> offers a powerful way to navigate frequently accessed directories, it's not the only tool available. Modern alternatives like <a href=\"https://github.com/gsamokovarov/jump\"><code>jump</code></a> and <a href=\"https://github.com/ajeetdsouza/zoxide\"><code>zoxide</code></a> provide similar functionality with distinct advantages and disadvantages.</p>\n\n<p><strong>CDPATH:</strong></p>\n\n<p><strong>Pros:</strong>\n* Simple to use and configure.\n- Offers consistent behavior across different shells.\n- Works seamlessly with existing cd workflows.</p>\n\n<p><strong>Cons:</strong>\n* Static search path can be inconvenient for dynamic workflows.\n- Requires manual maintenance of the search path.\n- It may introduce security risks if sensitive directories are included.</p>\n\n<p><strong>Jump:</strong></p>\n\n<p><strong>Pros:</strong>\n* Dynamically learns frequently accessed directories.\n- Offers intelligent suggestions and completions.\n- Supports searching through history and bookmarks.</p>\n\n<p><strong>Cons:</strong>\n* Requires separate installation and configuration.\n- It may introduce additional dependencies and complexity.\n- It may not be compatible with all shells or platforms.</p>\n\n<p><strong>Zoxide:</strong></p>\n\n<p><strong>Pros:</strong>\n* High-speed and efficient directory switching.\n- Integrates seamlessly with the cd command.\n- Learns project context and automatically navigates within project directories.</p>\n\n<p><strong>Cons:</strong>\n* Primarily focused on project-based workflows.\n- It may require additional setup for non-project directories.\n- It may be less intuitive than other tools for simple navigation.</p>\n\n<p><strong>Choosing the Right Tool:</strong></p>\n\n<p>The best tool for you depends on your individual needs and preferences. If you prioritize simplicity and familiarity, <code>CDPATH</code> might be a good choice. However, if you desire dynamic learning, intelligent suggestions, or project-specific navigation, <code>jump</code> or <code>zoxide</code> might offer more benefits.</p>\n\n<p>Ultimately, it's recommended to experiment with each tool and see which one best fits your workflow.</p>"
    },
    "authors": [
      {}
    ],
    "author": "",
    "id": "https://hashrocket.com/blog/posts/navigating-efficiently-with-cdpath",
    "guidislink": false,
    "published": "Thu, 28 Dec 2023 09:00:00 -0500",
    "published_parsed": [
      2023,
      12,
      28,
      14,
      0,
      0,
      3,
      362,
      0
    ],
    "tags": [
      {
        "term": "terminal",
        "scheme": null,
        "label": null
      }
    ]
  },
  "Housing.com": {
    "title": "Module Federation Pipeline\u200a\u2014\u200aPart 1",
    "xmlUrl": "https://medium.com/feed/engineering-housing",
    "htmlUrl": "https://medium.com/engineering-housing",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/engineering-housing",
      "value": "Module Federation Pipeline\u200a\u2014\u200aPart 1"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/engineering-housing/module-federation-pipeline-part-1-6c81ea15fe16?source=rss----3a69e32e2594---4"
      }
    ],
    "link": "https://medium.com/engineering-housing/module-federation-pipeline-part-1-6c81ea15fe16?source=rss----3a69e32e2594---4",
    "id": "https://medium.com/p/6c81ea15fe16",
    "guidislink": false,
    "authors": [
      {
        "name": "Naman Saini"
      }
    ],
    "author": "Naman Saini",
    "author_detail": {
      "name": "Naman Saini"
    },
    "published": "Wed, 07 Jun 2023 07:39:02 GMT",
    "published_parsed": [
      2023,
      6,
      7,
      7,
      39,
      2,
      2,
      158,
      0
    ],
    "updated": "2023-06-07T07:39:02.256Z",
    "updated_parsed": [
      2023,
      6,
      7,
      7,
      39,
      2,
      2,
      158,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/engineering-housing",
        "value": "<h3>Module Federation Pipeline\u200a\u2014\u200aPart\u00a01</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gUjlJp2K2jWSYOpAHy3qYQ.png\" /></figure><h4>What is Module Federation?</h4><p>Module Federation is a feature in modern JavaScript module bundlers like Webpack that allows separate applications or micro-frontends to share code and resources seamlessly. It enables the development of modular and independent components that can be distributed across different applications, allowing for greater flexibility, code reuse, and improved performance.</p><p>With Module Federation, applications can dynamically load and consume modules from other applications, eliminating the need to bundle everything into a single monolithic application. This approach promotes a more scalable and maintainable architecture, as changes or updates to individual modules can be deployed independently without affecting the entire\u00a0system.</p><h4>Current architecture of\u00a0Housing</h4><p>In our current architecture, we utilize module federation exclusively on the client side. This means that any page or route we want to fetch from our server should not be a federated module, but rather a part of the host app that hosts that specific\u00a0route.</p><p>For instance, when opening the homepage of housing.com at <a href=\"https://housing.com/\">https://housing.com/</a>, it is considered a part of our demand application. In this scenario, the demand application is responsible for fetching the container files of all other applications within our micro-frontend setup. This process allows us to obtain different modules from sources other than the demand application.</p><p>You can observe this in action in the screenshot below.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vxzRqfR7rLyyiLcsBadalw.png\" /><figcaption>Other containers being fetched on homepage apart from\u00a0demand</figcaption></figure><p>The container file mentioned above is generated during the build step of Webpack. However, in order for this functionality to work, we need to add a specific plugin and configure it accordingly.</p><p>To achieve this, we include a plugin called ModuleFederationPlugin in our Webpack configuration. This plugin plays a crucial role in enabling module federation. By adding the plugin and specifying its configuration, we can ensure that our applications can share code and resources seamlessly.</p><h4>Implementation steps:</h4><ol><li>In order to enable module federation, we need to add the <a href=\"https://webpack.js.org/plugins/module-federation-plugin/\">ModuleFederationPlugin</a> to the Webpack configuration of each application in our setup. It\u2019s important to note that this configuration is specific to the client build of our application and does not apply to the server side. The reason for this is that the ModuleFederationPlugin is designed to support client-side federation only.</li><li>This plugin requires some configuration, and there are various options available based on our needs. Here are a few important ones. Please refer to the sample configuration code at the\u00a0end.</li></ol><p><strong>i. \u2018name\u2019:</strong> Specifies a unique name for the container (host) project. This name will serve as the key to add this specific container to the window\u00a0object.</p><p><strong>ii. \u2018filename\u2019:</strong> Acts as the filename for the container. When we provide a URL to fetch this container from another app, it will end with\u00a0\u2026${filename}.js.</p><p><strong>iii. \u2018exposes\u2019:</strong> An object that specifies the modules exposed by the current project, making them accessible for remote projects. For example, in the code snippet below, this container exposes a module located at the path \u201c./routes/demandRoutes\u201d with the name \u201cexposedRoutes\u201d.</p><p><strong>iv: \u2018remotes\u2019:</strong> Defines the remote modules consumed by the current project. It allows us to specify the remote entry points and the exposed modules. This is used for static remotes when we want to fetch remote modules statically. For instance, in the code snippet below, whenever Webpack encounters \u2018supply\u2019 in an import path, it fetches the supplyContainer from the URL mentioned in the \u2018remotes\u2019 key and extracts the respective module from this container.</p><p><strong>v: \u2018shared\u2019:</strong> Specifies the shared modules and their versions (using the \u2018requiredVersion\u2019 key). Shared modules are loaded only once, even if multiple projects depend on them. There is also a \u2018singleton\u2019 key that, when set to true, indicates that only a single instance of this shared module will be created among different apps. Otherwise, multiple instances would be created for each federated app, but the code of this module would only be loaded once. For example, in the code snippet below, the \u2018react\u2019 version 18.2.0 is set to be a singleton.</p><pre>const { ModuleFederationPlugin } = require('webpack').container;<br />module.exports = {<br />  plugins: [<br />    new ModuleFederationPlugin({<br />      name: 'demand',<br />      filename: `demndContainer.m.m.js`,<br />      exposes: {<br />        exposedRoutes: &quot;./routes/demandRoutes&quot;<br />      },<br />      remotes: {<br />        supply: 'supply@https://supply-app.com/supplyContainer.js',<br />        inventory: 'inventory@https://inventory-app.com/inventoryContainer.js',<br />      }<br />      shared: {<br />        react: {<br />          singleton: true,<br />          requiredVersion: '18.2.0'<br />        },<br />        'react-redux': {<br />          singleton: true,<br />          requiredVersion: '8.0.2'<br />        },<br />    }),<br />  ],<br />};</pre><p>3. If we have specified the \u2018remotes\u2019 configuration in our ModuleFederationPlugin, there is no need for any additional steps. Webpack will automatically fetch the container and its respective module when it encounters an import statement that matches our\u00a0remotes.</p><p>However, if we haven\u2019t specified \u2018remotes\u2019, it indicates that we want to dynamically fetch containers and their exposed modules. There are multiple ways to fetch an app\u2019s container (let\u2019s say the \u2018demand\u2019 app) based on our specific use case. In our case, we achieve this by creating a script tag with its \u2018src\u2019 attribute set to the path of the demand\u2019s container file. As mentioned earlier, this path ends with\u00a0\u2026${filename}.js, which is defined in the demand's ModuleFederation plugin configuration. When the script tag is executed, the container is added to the window object and can be accessed using the value specified in the 'name' field of the demand's module federation plugin configuration.</p><p>4. Now, we can access the container file to obtain the required module. Each container exposes methods such as \u2018<strong>init</strong>\u2019 and \u2018<strong>get</strong>\u2019. To access a module from the container, we need to first initialize the container within the specified scope using the \u2018init\u2019 function. Only after initialization, we can asynchronously load the module from the container using the \u2018get\u2019 function. For a comprehensive understanding of how this process works, please refer to the following link: <a href=\"https://webpack.js.org/concepts/module-federation/#dynamic-remote-containers\">Webpack Module Federation\u200a\u2014\u200aDynamic Remote Containers</a>. Take a look at the sample code snippet, which does the\u00a0same.</p><pre>const loadComponent = async (app, module) =&gt; {<br />  // Initializes the share scope. This fills it with known provided modules from this build and all remotes<br />  await __webpack_init_sharing__('default')<br /><br />  const container = window[app] // or get the container somewhere else<br />  // Initialize the container, it may provide shared modules<br />  await container.init(__webpack_share_scopes__.default)<br />  const factory = await window[scope].get(module)<br />  const Module = factory()<br />  return Module<br />}</pre><p>The module returned by this function includes a \u2018default\u2019 property that holds the actual module code, which can be accessed and utilized.</p><p>This concludes the current article. In the next part, I will discuss how we successfully implemented module federation for our server-side application and integrated it into our architecture.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6c81ea15fe16\" width=\"1\" /><hr /><p><a href=\"https://medium.com/engineering-housing/module-federation-pipeline-part-1-6c81ea15fe16\">Module Federation Pipeline\u200a\u2014\u200aPart 1</a> was originally published in <a href=\"https://medium.com/engineering-housing\">Engineering @ Housing/Proptiger/Makaan</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h3>Module Federation Pipeline\u200a\u2014\u200aPart\u00a01</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gUjlJp2K2jWSYOpAHy3qYQ.png\" /></figure><h4>What is Module Federation?</h4><p>Module Federation is a feature in modern JavaScript module bundlers like Webpack that allows separate applications or micro-frontends to share code and resources seamlessly. It enables the development of modular and independent components that can be distributed across different applications, allowing for greater flexibility, code reuse, and improved performance.</p><p>With Module Federation, applications can dynamically load and consume modules from other applications, eliminating the need to bundle everything into a single monolithic application. This approach promotes a more scalable and maintainable architecture, as changes or updates to individual modules can be deployed independently without affecting the entire\u00a0system.</p><h4>Current architecture of\u00a0Housing</h4><p>In our current architecture, we utilize module federation exclusively on the client side. This means that any page or route we want to fetch from our server should not be a federated module, but rather a part of the host app that hosts that specific\u00a0route.</p><p>For instance, when opening the homepage of housing.com at <a href=\"https://housing.com/\">https://housing.com/</a>, it is considered a part of our demand application. In this scenario, the demand application is responsible for fetching the container files of all other applications within our micro-frontend setup. This process allows us to obtain different modules from sources other than the demand application.</p><p>You can observe this in action in the screenshot below.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vxzRqfR7rLyyiLcsBadalw.png\" /><figcaption>Other containers being fetched on homepage apart from\u00a0demand</figcaption></figure><p>The container file mentioned above is generated during the build step of Webpack. However, in order for this functionality to work, we need to add a specific plugin and configure it accordingly.</p><p>To achieve this, we include a plugin called ModuleFederationPlugin in our Webpack configuration. This plugin plays a crucial role in enabling module federation. By adding the plugin and specifying its configuration, we can ensure that our applications can share code and resources seamlessly.</p><h4>Implementation steps:</h4><ol><li>In order to enable module federation, we need to add the <a href=\"https://webpack.js.org/plugins/module-federation-plugin/\">ModuleFederationPlugin</a> to the Webpack configuration of each application in our setup. It\u2019s important to note that this configuration is specific to the client build of our application and does not apply to the server side. The reason for this is that the ModuleFederationPlugin is designed to support client-side federation only.</li><li>This plugin requires some configuration, and there are various options available based on our needs. Here are a few important ones. Please refer to the sample configuration code at the\u00a0end.</li></ol><p><strong>i. \u2018name\u2019:</strong> Specifies a unique name for the container (host) project. This name will serve as the key to add this specific container to the window\u00a0object.</p><p><strong>ii. \u2018filename\u2019:</strong> Acts as the filename for the container. When we provide a URL to fetch this container from another app, it will end with\u00a0\u2026${filename}.js.</p><p><strong>iii. \u2018exposes\u2019:</strong> An object that specifies the modules exposed by the current project, making them accessible for remote projects. For example, in the code snippet below, this container exposes a module located at the path \u201c./routes/demandRoutes\u201d with the name \u201cexposedRoutes\u201d.</p><p><strong>iv: \u2018remotes\u2019:</strong> Defines the remote modules consumed by the current project. It allows us to specify the remote entry points and the exposed modules. This is used for static remotes when we want to fetch remote modules statically. For instance, in the code snippet below, whenever Webpack encounters \u2018supply\u2019 in an import path, it fetches the supplyContainer from the URL mentioned in the \u2018remotes\u2019 key and extracts the respective module from this container.</p><p><strong>v: \u2018shared\u2019:</strong> Specifies the shared modules and their versions (using the \u2018requiredVersion\u2019 key). Shared modules are loaded only once, even if multiple projects depend on them. There is also a \u2018singleton\u2019 key that, when set to true, indicates that only a single instance of this shared module will be created among different apps. Otherwise, multiple instances would be created for each federated app, but the code of this module would only be loaded once. For example, in the code snippet below, the \u2018react\u2019 version 18.2.0 is set to be a singleton.</p><pre>const { ModuleFederationPlugin } = require('webpack').container;<br />module.exports = {<br />  plugins: [<br />    new ModuleFederationPlugin({<br />      name: 'demand',<br />      filename: `demndContainer.m.m.js`,<br />      exposes: {<br />        exposedRoutes: &quot;./routes/demandRoutes&quot;<br />      },<br />      remotes: {<br />        supply: 'supply@https://supply-app.com/supplyContainer.js',<br />        inventory: 'inventory@https://inventory-app.com/inventoryContainer.js',<br />      }<br />      shared: {<br />        react: {<br />          singleton: true,<br />          requiredVersion: '18.2.0'<br />        },<br />        'react-redux': {<br />          singleton: true,<br />          requiredVersion: '8.0.2'<br />        },<br />    }),<br />  ],<br />};</pre><p>3. If we have specified the \u2018remotes\u2019 configuration in our ModuleFederationPlugin, there is no need for any additional steps. Webpack will automatically fetch the container and its respective module when it encounters an import statement that matches our\u00a0remotes.</p><p>However, if we haven\u2019t specified \u2018remotes\u2019, it indicates that we want to dynamically fetch containers and their exposed modules. There are multiple ways to fetch an app\u2019s container (let\u2019s say the \u2018demand\u2019 app) based on our specific use case. In our case, we achieve this by creating a script tag with its \u2018src\u2019 attribute set to the path of the demand\u2019s container file. As mentioned earlier, this path ends with\u00a0\u2026${filename}.js, which is defined in the demand's ModuleFederation plugin configuration. When the script tag is executed, the container is added to the window object and can be accessed using the value specified in the 'name' field of the demand's module federation plugin configuration.</p><p>4. Now, we can access the container file to obtain the required module. Each container exposes methods such as \u2018<strong>init</strong>\u2019 and \u2018<strong>get</strong>\u2019. To access a module from the container, we need to first initialize the container within the specified scope using the \u2018init\u2019 function. Only after initialization, we can asynchronously load the module from the container using the \u2018get\u2019 function. For a comprehensive understanding of how this process works, please refer to the following link: <a href=\"https://webpack.js.org/concepts/module-federation/#dynamic-remote-containers\">Webpack Module Federation\u200a\u2014\u200aDynamic Remote Containers</a>. Take a look at the sample code snippet, which does the\u00a0same.</p><pre>const loadComponent = async (app, module) =&gt; {<br />  // Initializes the share scope. This fills it with known provided modules from this build and all remotes<br />  await __webpack_init_sharing__('default')<br /><br />  const container = window[app] // or get the container somewhere else<br />  // Initialize the container, it may provide shared modules<br />  await container.init(__webpack_share_scopes__.default)<br />  const factory = await window[scope].get(module)<br />  const Module = factory()<br />  return Module<br />}</pre><p>The module returned by this function includes a \u2018default\u2019 property that holds the actual module code, which can be accessed and utilized.</p><p>This concludes the current article. In the next part, I will discuss how we successfully implemented module federation for our server-side application and integrated it into our architecture.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6c81ea15fe16\" width=\"1\" /><hr /><p><a href=\"https://medium.com/engineering-housing/module-federation-pipeline-part-1-6c81ea15fe16\">Module Federation Pipeline\u200a\u2014\u200aPart 1</a> was originally published in <a href=\"https://medium.com/engineering-housing\">Engineering @ Housing/Proptiger/Makaan</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Sensible": {
    "title": "SSH Tunnel - Local and Remote Port Forwarding Explained With Examples",
    "xmlUrl": "http://blog.sensible.io/rss",
    "htmlUrl": "http://blog.sensible.io/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.sensible.io/rss",
      "value": "SSH Tunnel - Local and Remote Port Forwarding Explained With Examples"
    },
    "links": [
      {
        "rel": "alternate",
        "href": "https://blog.sensible.io/2014/05/17/ssh-tunnel-local-and-remote-port-forwarding-explained-with-examples.html",
        "type": "text/html"
      }
    ],
    "link": "https://blog.sensible.io/2014/05/17/ssh-tunnel-local-and-remote-port-forwarding-explained-with-examples.html",
    "id": "https://blog.sensible.io/2014/05/17/ssh-tunnel-local-and-remote-port-forwarding-explained-with-examples.html",
    "guidislink": false,
    "published": "2014-05-17T17:57:00Z",
    "published_parsed": [
      2014,
      5,
      17,
      17,
      57,
      0,
      5,
      137,
      0
    ],
    "updated": "2014-05-17T17:57:00Z",
    "updated_parsed": [
      2014,
      5,
      17,
      17,
      57,
      0,
      5,
      137,
      0
    ],
    "authors": [
      {
        "name": "sensible.io team"
      }
    ],
    "author_detail": {
      "name": "sensible.io team"
    },
    "author": "sensible.io team",
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.sensible.io/rss",
        "value": "<p>There are two ways to create an SSH tunnel, local and remote port\nforwarding (there&rsquo;s also dynamic forwarding, but we won&rsquo;t cover that\nhere). The best way to understand these is by an example, let&rsquo;s start\nwith local port forwarding.</p>\n\n<p>Imagine you&rsquo;re on a private network which doesn&rsquo;t allow connections to a\nspecific server. Let&rsquo;s say you&rsquo;re at work and imgur.com is being\nblocked. To get around this we can create a tunnel through a server\nwhich isn&rsquo;t on our network and thus can access Imgur.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ ssh -L 9000:imgur.com:80 user@example.com\n</code></pre></div>\n<p>The key here is <code>-L</code> which says we&rsquo;re doing local port forwarding. Then\nit says we&rsquo;re forwarding our local port <code>9000</code> to <code>imgur.com:80</code>,\nwhich is the default port for HTTP. Now open your browser and go to\n<a href=\"http://localhost:9000\">http://localhost:9000</a>.</p>\n\n<p>The awesome thing about SSH tunnels is that they are encrypted. Nobody\nis going to see what sites you&rsquo;re visiting, they&rsquo;ll only see an SSH\nconnection to your server.</p>\n\n<h2>Connecting to a database behind a firewall</h2>\n\n<p>Another good example is if you need to access a port on your server\nwhich can only be accessed from <code>localhost</code> and not remotely.</p>\n\n<p>An example here is when you need to connect to a database console, which\nonly allows local connection for security reasons. Let&rsquo;s say you&rsquo;re\nrunning PostgreSQL on your server, which by default listens on the port\n<code>5432</code>.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ ssh -L 9000:localhost:5432 user@example.com\n</code></pre></div>\n<p>The part that changed here is the <code>localhost:5432</code>, which says to\nforward connections from your local port <code>9000</code> to <code>localhost:5432</code> on\nyour server. Now we can simply connect to our database.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ psql -h localhost -p 9000\n</code></pre></div>\n<p>Now let&rsquo;s stop here for a little bit an explain what is actually going\non. In the first example the <code>9000:imgur.com:80</code> is actually saying\n<code>forward my local port 9000 to imgur.com at port 80</code>. You can imagine\nSSH on your server actually making a connection (a tunnel) between those\ntwo ports, one on your local machine, and one on the target destination.</p>\n\n<p>If we however say something like <code>9000:localhost:5432</code>, it means\n<code>localhost</code> from the server&rsquo;s perspective, not localhost on your\nmachine. This means <code>forward my local port 9000 to port 5432 on\nthe server</code>, because when you&rsquo;re on the server, <code>localhost</code> means the\nserver itself.</p>\n\n<p>This might be a bit confusing, but it is important to understand what\nthe syntax actually means here.</p>\n\n<h2>Remote port forwarding</h2>\n\n<p>Now comes the second part of this tutorial, which is remote port\nforwarding. This is again best to explain with an example.</p>\n\n<p>Say that you&rsquo;re developing a Rails application on your local machine,\nand you&rsquo;d like to show it to a friend. Unfortunately your ISP didn&rsquo;t\nprovide you with a public IP address, so it&rsquo;s not possible to connect\nto your machine directly via the internet.</p>\n\n<p>Sometimes this can be solved by configuring NAT (Network Address\nTranslation) on your router, but this doesn&rsquo;t always work, and it\nrequires you to change the configuration on your router, which isn&rsquo;t\nalways desirable. This solution also doesn&rsquo;t work when you don&rsquo;t have\nadmin access on your network.</p>\n\n<p>To fix this problem you need to have another computer, which is publicly\naccessible and have SSH access to it. It can be any server on the\ninternet, as long as you can connect to it. We&rsquo;ll tell SSH to make a\ntunnel that opens up a new port on the server, and connects it to a\nlocal port on your machine.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ ssh -R 3000:localhost:9000 user@example.com\n</code></pre></div>\n<p>The syntax here is very similar to local port forwarding, with a\nsingle change of <code>-L</code> for <code>-R</code>. But as with local port forwarding, the\nsyntax remains the same.</p>\n\n<p>First you need to specify a local port on your machine which you wish\nto expose publicly, which in this case is <code>3000</code>. Next there is the\naddress on which the server should listen to, and a port on which the\nserver should listen to, which in this case is <code>9000</code>.</p>\n\n<p>There is one more thing you need to do to enable this. SSH doesn&rsquo;t by\ndefault allow remote hosts to forwarded ports. To enable this open\n<code>/etc/ssh/sshd_config</code> and add the following line somewhere in that\nconfig file.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>GatewayPorts yes\n</code></pre></div>\n<p>Make sure you add it only once!</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ sudo vim /etc/ssh/sshd_config\n</code></pre></div>\n<p>And restart SSH</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ sudo service ssh restart\n</code></pre></div>\n<p>After this you should be able to connect to the server remotely, even\nfrom your local machine. The way this would work is that you would\nfirst create an SSH tunnel that forwards traffic from the server on\nport <code>9000</code> to your local machine on port <code>3000</code>. This means that if\nyou connect to the server on port <code>9000</code> from your local machine,\nyou&rsquo;ll actually make a request to your machine through the SSH tunnel.</p>\n\n<h2>A few closing tips</h2>\n\n<p>You might have noticed that every time we create a tunnel you also SSH\ninto the server and get a shell. This isn&rsquo;t usually necessary, as you&rsquo;re\njust trying to create a tunnel. To avoid this we can run SSH with the\n<code>-nNT</code> flags, such as the following, which will cause SSH to not\nallocate a tty and only do the port forwarding.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ ssh -nNT -L 9000:imgur.com:80 user@example.com\n</code></pre></div>\n<p>SSH has a huge number of features, so I&rsquo;d recommend you to checkout the\nmanual page at <code>man ssh</code>, which contains even more tips.</p>\n\n<p>There&rsquo;s also an amazing talk called <a href=\"http://vimeo.com/54505525\">The Black Magic of SSH / SSH Can Do\nThat?</a>, which I really recommend you to\nwatch.</p>"
      }
    ],
    "summary": "<p>There are two ways to create an SSH tunnel, local and remote port\nforwarding (there&rsquo;s also dynamic forwarding, but we won&rsquo;t cover that\nhere). The best way to understand these is by an example, let&rsquo;s start\nwith local port forwarding.</p>\n\n<p>Imagine you&rsquo;re on a private network which doesn&rsquo;t allow connections to a\nspecific server. Let&rsquo;s say you&rsquo;re at work and imgur.com is being\nblocked. To get around this we can create a tunnel through a server\nwhich isn&rsquo;t on our network and thus can access Imgur.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ ssh -L 9000:imgur.com:80 user@example.com\n</code></pre></div>\n<p>The key here is <code>-L</code> which says we&rsquo;re doing local port forwarding. Then\nit says we&rsquo;re forwarding our local port <code>9000</code> to <code>imgur.com:80</code>,\nwhich is the default port for HTTP. Now open your browser and go to\n<a href=\"http://localhost:9000\">http://localhost:9000</a>.</p>\n\n<p>The awesome thing about SSH tunnels is that they are encrypted. Nobody\nis going to see what sites you&rsquo;re visiting, they&rsquo;ll only see an SSH\nconnection to your server.</p>\n\n<h2>Connecting to a database behind a firewall</h2>\n\n<p>Another good example is if you need to access a port on your server\nwhich can only be accessed from <code>localhost</code> and not remotely.</p>\n\n<p>An example here is when you need to connect to a database console, which\nonly allows local connection for security reasons. Let&rsquo;s say you&rsquo;re\nrunning PostgreSQL on your server, which by default listens on the port\n<code>5432</code>.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ ssh -L 9000:localhost:5432 user@example.com\n</code></pre></div>\n<p>The part that changed here is the <code>localhost:5432</code>, which says to\nforward connections from your local port <code>9000</code> to <code>localhost:5432</code> on\nyour server. Now we can simply connect to our database.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ psql -h localhost -p 9000\n</code></pre></div>\n<p>Now let&rsquo;s stop here for a little bit an explain what is actually going\non. In the first example the <code>9000:imgur.com:80</code> is actually saying\n<code>forward my local port 9000 to imgur.com at port 80</code>. You can imagine\nSSH on your server actually making a connection (a tunnel) between those\ntwo ports, one on your local machine, and one on the target destination.</p>\n\n<p>If we however say something like <code>9000:localhost:5432</code>, it means\n<code>localhost</code> from the server&rsquo;s perspective, not localhost on your\nmachine. This means <code>forward my local port 9000 to port 5432 on\nthe server</code>, because when you&rsquo;re on the server, <code>localhost</code> means the\nserver itself.</p>\n\n<p>This might be a bit confusing, but it is important to understand what\nthe syntax actually means here.</p>\n\n<h2>Remote port forwarding</h2>\n\n<p>Now comes the second part of this tutorial, which is remote port\nforwarding. This is again best to explain with an example.</p>\n\n<p>Say that you&rsquo;re developing a Rails application on your local machine,\nand you&rsquo;d like to show it to a friend. Unfortunately your ISP didn&rsquo;t\nprovide you with a public IP address, so it&rsquo;s not possible to connect\nto your machine directly via the internet.</p>\n\n<p>Sometimes this can be solved by configuring NAT (Network Address\nTranslation) on your router, but this doesn&rsquo;t always work, and it\nrequires you to change the configuration on your router, which isn&rsquo;t\nalways desirable. This solution also doesn&rsquo;t work when you don&rsquo;t have\nadmin access on your network.</p>\n\n<p>To fix this problem you need to have another computer, which is publicly\naccessible and have SSH access to it. It can be any server on the\ninternet, as long as you can connect to it. We&rsquo;ll tell SSH to make a\ntunnel that opens up a new port on the server, and connects it to a\nlocal port on your machine.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ ssh -R 3000:localhost:9000 user@example.com\n</code></pre></div>\n<p>The syntax here is very similar to local port forwarding, with a\nsingle change of <code>-L</code> for <code>-R</code>. But as with local port forwarding, the\nsyntax remains the same.</p>\n\n<p>First you need to specify a local port on your machine which you wish\nto expose publicly, which in this case is <code>3000</code>. Next there is the\naddress on which the server should listen to, and a port on which the\nserver should listen to, which in this case is <code>9000</code>.</p>\n\n<p>There is one more thing you need to do to enable this. SSH doesn&rsquo;t by\ndefault allow remote hosts to forwarded ports. To enable this open\n<code>/etc/ssh/sshd_config</code> and add the following line somewhere in that\nconfig file.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>GatewayPorts yes\n</code></pre></div>\n<p>Make sure you add it only once!</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ sudo vim /etc/ssh/sshd_config\n</code></pre></div>\n<p>And restart SSH</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ sudo service ssh restart\n</code></pre></div>\n<p>After this you should be able to connect to the server remotely, even\nfrom your local machine. The way this would work is that you would\nfirst create an SSH tunnel that forwards traffic from the server on\nport <code>9000</code> to your local machine on port <code>3000</code>. This means that if\nyou connect to the server on port <code>9000</code> from your local machine,\nyou&rsquo;ll actually make a request to your machine through the SSH tunnel.</p>\n\n<h2>A few closing tips</h2>\n\n<p>You might have noticed that every time we create a tunnel you also SSH\ninto the server and get a shell. This isn&rsquo;t usually necessary, as you&rsquo;re\njust trying to create a tunnel. To avoid this we can run SSH with the\n<code>-nNT</code> flags, such as the following, which will cause SSH to not\nallocate a tty and only do the port forwarding.</p>\n<div class=\"highlight\"><pre class=\"highlight plaintext\"><code>$ ssh -nNT -L 9000:imgur.com:80 user@example.com\n</code></pre></div>\n<p>SSH has a huge number of features, so I&rsquo;d recommend you to checkout the\nmanual page at <code>man ssh</code>, which contains even more tips.</p>\n\n<p>There&rsquo;s also an amazing talk called <a href=\"http://vimeo.com/54505525\">The Black Magic of SSH / SSH Can Do\nThat?</a>, which I really recommend you to\nwatch.</p>"
  },
  "RetailMeNot": {
    "title": "RetailMeNot  GraphQL Federation",
    "xmlUrl": "https://medium.com/feed/retailmenot-engineering",
    "htmlUrl": "https://medium.com/retailmenot-engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/retailmenot-engineering",
      "value": "RetailMeNot  GraphQL Federation"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.ziffmedia.com/retailmenot-graphql-federation-3bb36dac5aaa?source=rss----d6bb34696ef5---4"
      }
    ],
    "link": "https://engineering.ziffmedia.com/retailmenot-graphql-federation-3bb36dac5aaa?source=rss----d6bb34696ef5---4",
    "id": "https://medium.com/p/3bb36dac5aaa",
    "guidislink": false,
    "tags": [
      {
        "term": "ziff-davis",
        "scheme": null,
        "label": null
      },
      {
        "term": "retailmenot",
        "scheme": null,
        "label": null
      },
      {
        "term": "graphql",
        "scheme": null,
        "label": null
      },
      {
        "term": "graphql-federation",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Kartik Kumar Gujarati"
      }
    ],
    "author": "Kartik Kumar Gujarati",
    "author_detail": {
      "name": "Kartik Kumar Gujarati"
    },
    "published": "Fri, 08 Oct 2021 15:01:45 GMT",
    "published_parsed": [
      2021,
      10,
      8,
      15,
      1,
      45,
      4,
      281,
      0
    ],
    "updated": "2021-10-08T15:01:43.826Z",
    "updated_parsed": [
      2021,
      10,
      8,
      15,
      1,
      43,
      4,
      281,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/retailmenot-engineering",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EsIGT9FlKgd3kshxqu5waA.png\" /></figure><p>Did you ever have to maintain multiple versions of a REST API because the change you needed to make would break existing clients? Does your native app have to call multiple REST endpoints to get all the data it needs? This blog post is about how we addressed these common problems using GraphQL and our transition to GraphQL Federation at RetailMeNot.</p><p><a href=\"https://www.retailmenot.com/\">RetailMeNot</a>, part of <a href=\"https://ziffmedia.com/\">Ziff Media, Inc</a>, makes everyday life more affordable for shoppers. We are a leading savings destination providing online and in-store coupons and cashback offers to our users. Today, we serve millions of monthly active users from our desktop, mobile web, native (<a href=\"https://apps.apple.com/us/app/retailmenot-coupons-cashback/id521207075\">iOS</a> &amp; <a href=\"https://play.google.com/store/apps/details?id=com.whaleshark.retailmenot\">Android</a>) apps, and <a href=\"https://www.retailmenot.com/dealfinder\">browser extension</a> (Deal Finder\u2122) experiences.</p><p>For the last 10 years, RetailMeNot\u2019s engineering teams have built several highly performant, scalable, and efficient systems to bring savings data to our users through our experiences. And like many companies, RetailMeNot used REST APIs to serve the data. However, as the company and the systems grew, we started to experience problems like versioning, over-fetching, and under-fetching with REST APIs. For more details on the classic problems that arise from REST services and how GraphQL solves them, see <a href=\"https://www.howtographql.com/basics/1-graphql-is-the-better-rest/\">this blog post</a>. For an introduction to GraphQL, see <a href=\"https://hasura.io/learn/graphql/react/intro-to-graphql/\">this blog\u00a0post</a>.</p><h3>How it started: A Monolithic Graph</h3><p>In 2019, we took a step back to rethink where we are headed in terms of our tech stack and how to best serve future experiences. We decided to rewrite our native Android and iOS apps and the backend that supports them. In addition to this, we also built a brand new browser extension (Deal Finder\u2122) and re-wrote several parts of our core\u00a0website.</p><p>As we started to rebuild our native apps, we wanted to solve the above problems we faced with REST APIs. GraphQL seemed like a great solution for\u00a0this.</p><p>Enter GraphQL. In our first iteration with GraphQL, we built a GraphQL monolith.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fTGG_A3J1y_HYCpWbwd1QA.png\" /><figcaption>Monolith Graph</figcaption></figure><p>The GraphQL Monolith at RetailMeNot was a single GraphQL Server used by our Native Android, iOS, desktop, and mobile web clients. A single team (Graph API team) was responsible for \u201cgatekeeping\u201d and defining standards for this new RetailMeNot data\u00a0graph.</p><p>To allow the client teams to develop and iterate faster, they were given autonomy to contribute to this monolith and expand the graph based on their needs. This, however, soon overwhelmed the Graph API team, and they became a bottleneck for getting new changes published to the graph. It was clear that we needed a new solution where the client teams could have the autonomy to expand the unified graph at their own pace and not be limited by a centralized team.</p><h3>Escaping the Monolith with GraphQL Federation:</h3><p>Enter GraphQL Federation.</p><p>The premise behind Federation is that each subgraph team is responsible for building and maintaining their portion of the unified graph schema. This allows the subgraph teams to iterate faster as they are decoupled from the rest of the\u00a0graph.</p><p>Setting up a reliable and highly scalable federated GraphQL architecture is not easy. There are several things to consider:</p><ol><li>How to prevent a subgraph from introducing a breaking change to the\u00a0graph?</li><li>How to make sure the GraphQL gateway always reflects the most up-to-date schema?</li><li>How to monitor the health and performance of all the queries that are served from the\u00a0graph?</li></ol><p>To help us address these concerns, we partnered with Apollo GraphQL and leveraged their <a href=\"https://www.apollographql.com/docs/federation/managed-federation/overview/\">Managed Federation</a> architecture.</p><p>In order to maintain backward compatibility and ensure zero downtime during the migration from a monolithic architecture to a federated architecture, it was very critical for us to adopt an \u201cincremental migration\u201d approach.</p><p>Here are the incremental steps that we took for this migration:</p><ol><li>First, we transformed the existing GraphQL schema in the monolithic service to support federation specifications. This allowed us to support both the federation spec and schema stitching in the same service. <a href=\"https://www.apollographql.com/docs/federation/other-servers/\">Here are the open-source libraries</a> that provide support for federation spec.</li><li>We then set up a new Gateway service that simply forwarded the traffic to the monolithic service.</li><li>Using a weighted routing technique, we then controlled the amount of traffic that would hit the new Gateway service vs the monolithic service. Once we were confident with the changes and validations in our lower environments (stage/pre-production), we then switched over to 100% of our traffic going through the Gateway service in the production. At this point, our monolithic service was completely behind the\u00a0gateway.</li><li>Finally, we started to break apart the schema in our monolithic service (which now became a subgraph) and <a href=\"https://www.apollographql.com/docs/federation/entities/#migrating-entities-and-fields-advanced\">migrated the entities</a> over to more cohesive and smaller subgraph services.</li></ol><h3>How it\u2019s going: A Federated Graph</h3><p>Here is what the GraphQL architecture at RetailMeNot looks like\u00a0today:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BL6OIW2kFqGNXmppKSTHXw.png\" /><figcaption>Federated Graph</figcaption></figure><p>Currently, our unified data graph at RetailMeNot consists of several fully federated and highly cohesive subgraph services that are being actively worked on by different teams independently.</p><p><strong>Adoption and lessons\u00a0learned:</strong></p><p>We had a very quick adoption of the new federated architecture internally. Multiple teams wanted to join the new federated graph immediately after it was available. This was a huge win for the Graph API team. However, as we began to incorporate new subgraph services across various teams into the federated graph, it became a bit of a wild west with subgraph design and maintenance inconsistencies. Here are some of the lessons we learned from our early adopting\u00a0teams:</p><ul><li>Use a standard naming convention</li><li>Standardize a schema review\u00a0process</li><li>Be very intentional about field nullability</li><li>Document the schema definition</li><li>Always prioritize clients\u2019\u00a0needs</li></ul><p><strong>Graph Stewardship:</strong></p><p>To address the above lessons we learned, we set up a \u201cvirtual\u201d guild. This virtual guild consists of one member from each subgraph team. The main responsibilities of this guild\u00a0are:</p><ul><li>Setting up best practices for RetailMeNot\u2019s unified graph and enforcing them</li><li>Reviewing schema changes from each sub-graph and providing feedback</li><li>Helping onboard new subgraph\u00a0teams</li><li>Sharing what they learn with broader teams at RetailMeNot and drive GraphQL adoption across the\u00a0company</li></ul><p><strong>So, how did moving to a federated architecture help\u00a0us?</strong></p><ul><li><strong>Faster product iteration</strong>: The user-facing application teams can move much faster as the bottleneck from a single \u201cGraphQL API team\u201d is\u00a0removed.</li><li><strong>Concern-based separation</strong>: Moving to a federated architecture enabled different teams to work on different product areas without affecting/blocking each other while contributing to a single\u00a0graph.</li><li><strong>Similar tech-stack across services</strong>: Moving to a federated architecture helped us standardize the tech-stack across multiple services at RetailMeNot. This also led to high collaboration across\u00a0teams.</li><li><strong>Developer experience</strong>: With standardized tooling and a common tech stack, developer experience has been improved a\u00a0lot.</li></ul><p>Here are some of the responses to the same question above from a few members of our organization:</p><blockquote>\u201cFederation enabled our teams to iterate over the deliverables with minimal dependencies. Teams have clear ownership and this has empowered the product and UX teams to iterate over new features, evaluate the market reach, and keep customers happy.\u201d</blockquote><blockquote>\u201cBy utilizing Federated GraphQL, we have been able to improve the cohesion of our backend services and hide the migration of subgraph responsibilities from our client applications.\u201d</blockquote><blockquote>\u201cFederation allowed our teams to iterate on features faster and more independently, while at the same time pushing us to improve cross-team communication and collaboration in order to effectively manage the unified\u00a0graph.\u201d</blockquote><blockquote>\u201cAt an org level, GraphQL and federation specifically forced us to come to a mutual understanding of the data types and terminology that are used across our different services. Because of this, we were able to have meaningful conversations more quickly.\u201d</blockquote><p>Finally,</p><p>RetailMeNot + GraphQL Federation = Greatness</p><p>A big thanks to everyone who helped me put this blog together. Special thanks to the members of the GraphQL guild at RetailMeNot, the teams at Apollo GraphQL, and the broader GraphQL community for helping us reach where we\u00a0are.</p><p>Interested in solving complex problems at scale? Check out our <a href=\"https://jobs.jobvite.com/retailmenot\">careers page</a> or reach out directly if you have any questions.</p><p><strong>About Ziff Media,\u00a0Inc:</strong></p><p>Ziff Media, Inc. is a portfolio of leading digital properties in tech, culture, and shopping. Our brands include Mashable, PCMag, RetailMeNot, Offers.com, BlackFriday.com, BestBlackFriday.com, ExtremeTech, AskMen, and TechBargains.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3bb36dac5aaa\" width=\"1\" /><hr /><p><a href=\"https://engineering.ziffmedia.com/retailmenot-graphql-federation-3bb36dac5aaa\">RetailMeNot \ud83d\udc9c GraphQL Federation</a> was originally published in <a href=\"https://engineering.ziffmedia.com\">Ziff Media Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EsIGT9FlKgd3kshxqu5waA.png\" /></figure><p>Did you ever have to maintain multiple versions of a REST API because the change you needed to make would break existing clients? Does your native app have to call multiple REST endpoints to get all the data it needs? This blog post is about how we addressed these common problems using GraphQL and our transition to GraphQL Federation at RetailMeNot.</p><p><a href=\"https://www.retailmenot.com/\">RetailMeNot</a>, part of <a href=\"https://ziffmedia.com/\">Ziff Media, Inc</a>, makes everyday life more affordable for shoppers. We are a leading savings destination providing online and in-store coupons and cashback offers to our users. Today, we serve millions of monthly active users from our desktop, mobile web, native (<a href=\"https://apps.apple.com/us/app/retailmenot-coupons-cashback/id521207075\">iOS</a> &amp; <a href=\"https://play.google.com/store/apps/details?id=com.whaleshark.retailmenot\">Android</a>) apps, and <a href=\"https://www.retailmenot.com/dealfinder\">browser extension</a> (Deal Finder\u2122) experiences.</p><p>For the last 10 years, RetailMeNot\u2019s engineering teams have built several highly performant, scalable, and efficient systems to bring savings data to our users through our experiences. And like many companies, RetailMeNot used REST APIs to serve the data. However, as the company and the systems grew, we started to experience problems like versioning, over-fetching, and under-fetching with REST APIs. For more details on the classic problems that arise from REST services and how GraphQL solves them, see <a href=\"https://www.howtographql.com/basics/1-graphql-is-the-better-rest/\">this blog post</a>. For an introduction to GraphQL, see <a href=\"https://hasura.io/learn/graphql/react/intro-to-graphql/\">this blog\u00a0post</a>.</p><h3>How it started: A Monolithic Graph</h3><p>In 2019, we took a step back to rethink where we are headed in terms of our tech stack and how to best serve future experiences. We decided to rewrite our native Android and iOS apps and the backend that supports them. In addition to this, we also built a brand new browser extension (Deal Finder\u2122) and re-wrote several parts of our core\u00a0website.</p><p>As we started to rebuild our native apps, we wanted to solve the above problems we faced with REST APIs. GraphQL seemed like a great solution for\u00a0this.</p><p>Enter GraphQL. In our first iteration with GraphQL, we built a GraphQL monolith.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fTGG_A3J1y_HYCpWbwd1QA.png\" /><figcaption>Monolith Graph</figcaption></figure><p>The GraphQL Monolith at RetailMeNot was a single GraphQL Server used by our Native Android, iOS, desktop, and mobile web clients. A single team (Graph API team) was responsible for \u201cgatekeeping\u201d and defining standards for this new RetailMeNot data\u00a0graph.</p><p>To allow the client teams to develop and iterate faster, they were given autonomy to contribute to this monolith and expand the graph based on their needs. This, however, soon overwhelmed the Graph API team, and they became a bottleneck for getting new changes published to the graph. It was clear that we needed a new solution where the client teams could have the autonomy to expand the unified graph at their own pace and not be limited by a centralized team.</p><h3>Escaping the Monolith with GraphQL Federation:</h3><p>Enter GraphQL Federation.</p><p>The premise behind Federation is that each subgraph team is responsible for building and maintaining their portion of the unified graph schema. This allows the subgraph teams to iterate faster as they are decoupled from the rest of the\u00a0graph.</p><p>Setting up a reliable and highly scalable federated GraphQL architecture is not easy. There are several things to consider:</p><ol><li>How to prevent a subgraph from introducing a breaking change to the\u00a0graph?</li><li>How to make sure the GraphQL gateway always reflects the most up-to-date schema?</li><li>How to monitor the health and performance of all the queries that are served from the\u00a0graph?</li></ol><p>To help us address these concerns, we partnered with Apollo GraphQL and leveraged their <a href=\"https://www.apollographql.com/docs/federation/managed-federation/overview/\">Managed Federation</a> architecture.</p><p>In order to maintain backward compatibility and ensure zero downtime during the migration from a monolithic architecture to a federated architecture, it was very critical for us to adopt an \u201cincremental migration\u201d approach.</p><p>Here are the incremental steps that we took for this migration:</p><ol><li>First, we transformed the existing GraphQL schema in the monolithic service to support federation specifications. This allowed us to support both the federation spec and schema stitching in the same service. <a href=\"https://www.apollographql.com/docs/federation/other-servers/\">Here are the open-source libraries</a> that provide support for federation spec.</li><li>We then set up a new Gateway service that simply forwarded the traffic to the monolithic service.</li><li>Using a weighted routing technique, we then controlled the amount of traffic that would hit the new Gateway service vs the monolithic service. Once we were confident with the changes and validations in our lower environments (stage/pre-production), we then switched over to 100% of our traffic going through the Gateway service in the production. At this point, our monolithic service was completely behind the\u00a0gateway.</li><li>Finally, we started to break apart the schema in our monolithic service (which now became a subgraph) and <a href=\"https://www.apollographql.com/docs/federation/entities/#migrating-entities-and-fields-advanced\">migrated the entities</a> over to more cohesive and smaller subgraph services.</li></ol><h3>How it\u2019s going: A Federated Graph</h3><p>Here is what the GraphQL architecture at RetailMeNot looks like\u00a0today:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BL6OIW2kFqGNXmppKSTHXw.png\" /><figcaption>Federated Graph</figcaption></figure><p>Currently, our unified data graph at RetailMeNot consists of several fully federated and highly cohesive subgraph services that are being actively worked on by different teams independently.</p><p><strong>Adoption and lessons\u00a0learned:</strong></p><p>We had a very quick adoption of the new federated architecture internally. Multiple teams wanted to join the new federated graph immediately after it was available. This was a huge win for the Graph API team. However, as we began to incorporate new subgraph services across various teams into the federated graph, it became a bit of a wild west with subgraph design and maintenance inconsistencies. Here are some of the lessons we learned from our early adopting\u00a0teams:</p><ul><li>Use a standard naming convention</li><li>Standardize a schema review\u00a0process</li><li>Be very intentional about field nullability</li><li>Document the schema definition</li><li>Always prioritize clients\u2019\u00a0needs</li></ul><p><strong>Graph Stewardship:</strong></p><p>To address the above lessons we learned, we set up a \u201cvirtual\u201d guild. This virtual guild consists of one member from each subgraph team. The main responsibilities of this guild\u00a0are:</p><ul><li>Setting up best practices for RetailMeNot\u2019s unified graph and enforcing them</li><li>Reviewing schema changes from each sub-graph and providing feedback</li><li>Helping onboard new subgraph\u00a0teams</li><li>Sharing what they learn with broader teams at RetailMeNot and drive GraphQL adoption across the\u00a0company</li></ul><p><strong>So, how did moving to a federated architecture help\u00a0us?</strong></p><ul><li><strong>Faster product iteration</strong>: The user-facing application teams can move much faster as the bottleneck from a single \u201cGraphQL API team\u201d is\u00a0removed.</li><li><strong>Concern-based separation</strong>: Moving to a federated architecture enabled different teams to work on different product areas without affecting/blocking each other while contributing to a single\u00a0graph.</li><li><strong>Similar tech-stack across services</strong>: Moving to a federated architecture helped us standardize the tech-stack across multiple services at RetailMeNot. This also led to high collaboration across\u00a0teams.</li><li><strong>Developer experience</strong>: With standardized tooling and a common tech stack, developer experience has been improved a\u00a0lot.</li></ul><p>Here are some of the responses to the same question above from a few members of our organization:</p><blockquote>\u201cFederation enabled our teams to iterate over the deliverables with minimal dependencies. Teams have clear ownership and this has empowered the product and UX teams to iterate over new features, evaluate the market reach, and keep customers happy.\u201d</blockquote><blockquote>\u201cBy utilizing Federated GraphQL, we have been able to improve the cohesion of our backend services and hide the migration of subgraph responsibilities from our client applications.\u201d</blockquote><blockquote>\u201cFederation allowed our teams to iterate on features faster and more independently, while at the same time pushing us to improve cross-team communication and collaboration in order to effectively manage the unified\u00a0graph.\u201d</blockquote><blockquote>\u201cAt an org level, GraphQL and federation specifically forced us to come to a mutual understanding of the data types and terminology that are used across our different services. Because of this, we were able to have meaningful conversations more quickly.\u201d</blockquote><p>Finally,</p><p>RetailMeNot + GraphQL Federation = Greatness</p><p>A big thanks to everyone who helped me put this blog together. Special thanks to the members of the GraphQL guild at RetailMeNot, the teams at Apollo GraphQL, and the broader GraphQL community for helping us reach where we\u00a0are.</p><p>Interested in solving complex problems at scale? Check out our <a href=\"https://jobs.jobvite.com/retailmenot\">careers page</a> or reach out directly if you have any questions.</p><p><strong>About Ziff Media,\u00a0Inc:</strong></p><p>Ziff Media, Inc. is a portfolio of leading digital properties in tech, culture, and shopping. Our brands include Mashable, PCMag, RetailMeNot, Offers.com, BlackFriday.com, BestBlackFriday.com, ExtremeTech, AskMen, and TechBargains.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3bb36dac5aaa\" width=\"1\" /><hr /><p><a href=\"https://engineering.ziffmedia.com/retailmenot-graphql-federation-3bb36dac5aaa\">RetailMeNot \ud83d\udc9c GraphQL Federation</a> was originally published in <a href=\"https://engineering.ziffmedia.com\">Ziff Media Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Squarespace": {
    "title": "Outro: What You Did and What\u2019s Next",
    "xmlUrl": "https://engineering.squarespace.com/blog?format=RSS",
    "htmlUrl": "https://engineering.squarespace.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.squarespace.com/blog?format=RSS",
      "value": "Outro: What You Did and What\u2019s Next"
    },
    "authors": [
      {
        "name": "Anila Zaidi"
      }
    ],
    "author": "Anila Zaidi",
    "author_detail": {
      "name": "Anila Zaidi"
    },
    "published": "Wed, 06 Dec 2023 19:22:00 +0000",
    "published_parsed": [
      2023,
      12,
      6,
      19,
      22,
      0,
      2,
      340,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.squarespace.com/blog/2023/outro-what-you-did-whats-next"
      }
    ],
    "link": "https://engineering.squarespace.com/blog/2023/outro-what-you-did-whats-next",
    "id": "56ab961ecbced617ccd2461e:56aba24fc6fc08c6cb69a290:64b567b02de24c1628440234",
    "guidislink": false,
    "summary": "The outro recaps what you did \u2013 write technical documentation! \u2013 and \nintroduces next steps like organizing a collection of documentation, \nrevising existing content, and expanding your technical writing skills by \njoining the technical writing community.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.squarespace.com/blog?format=RSS",
      "value": "The outro recaps what you did \u2013 write technical documentation! \u2013 and \nintroduces next steps like organizing a collection of documentation, \nrevising existing content, and expanding your technical writing skills by \njoining the technical writing community."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.squarespace.com/blog?format=RSS",
        "value": "<p class=\"\"><em>This is the last post for a five part series on Technical Writing. To learn more, see the </em><a href=\"https://engineering.squarespace.com/blog/2023/technical-writing-how-to-start\"><em>Intro</em></a><em> post and Parts </em><a href=\"https://engineering.squarespace.com/blog/2023/part-1-learn-the-different-types-of-technical-documentation\"><em>1</em></a><em>, </em><a href=\"https://engineering.squarespace.com/blog/2023/part-2-use-good-headings-and-structure\"><em>2</em></a><em>, </em><a href=\"https://engineering.squarespace.com/blog/2023/part-3-accurate-consistent-concise-content\"><em>3</em></a><em>, and </em><a href=\"https://engineering.squarespace.com/blog/2023/part-4-test-edit-and-publish-content\"><em>4</em></a><em> of the tutorial.</em></p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n<hr />\n\n\n  <p class=\"\">KEY TERMS</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n<ul class=\"accordion-items-container\">\n  \n    <li class=\"accordion-item\">\n\n      \n        \n          \n        \n      \n\n      <h3 class=\"\n          accordion-item__title-wrapper\n          \n          \n          \n        \">\n        <button class=\"accordion-item__click-target\" style=\"padding-top: 5px; padding-bottom: 5px; padding-left: 0px; padding-right: 0px;\">\n          <span class=\"accordion-item__title\">\n            App\n          </span>\n          \n            \n              \n                \n              \n            \n          \n        </button>\n      </h3>\n      \n        \n          <p class=\"\">In this tutorial, an app represents a single piece of software that\u2019s provided for others to use. This could be a mobile app, a web app, a microservice, a database, an API, a Figma component library, a React component library, a script, and so forth.</p>\n        \n      \n\n      \n        \n      \n\n    </li>\n  \n    <li class=\"accordion-item\">\n\n      \n        \n      \n\n      <h3 class=\"\n          accordion-item__title-wrapper\n          \n          \n          \n        \">\n        <button class=\"accordion-item__click-target\" style=\"padding-top: 5px; padding-bottom: 5px; padding-left: 0px; padding-right: 0px;\">\n          <span class=\"accordion-item__title\">\n            Target audience\n          </span>\n          \n            \n              \n                \n              \n            \n          \n        </button>\n      </h3>\n      \n        \n          <p class=\"\">The group of people who are most likely to use the app. For example, if the app is an API, the target audience is likely to be only developers. Whereas the target audience for a Figma component library is designers.</p>\n        \n      \n\n      \n        \n      \n\n    </li>\n  \n    <li class=\"accordion-item\">\n\n      \n        \n      \n\n      <h3 class=\"\n          accordion-item__title-wrapper\n          \n          \n          \n        \">\n        <button class=\"accordion-item__click-target\" style=\"padding-top: 5px; padding-bottom: 5px; padding-left: 0px; padding-right: 0px;\">\n          <span class=\"accordion-item__title\">\n            Technical documentation\n          </span>\n          \n            \n              \n                \n              \n            \n          \n        </button>\n      </h3>\n      \n        \n          <p class=\"\">Any piece of writing that includes technical writing.</p>\n        \n      \n\n      \n        \n      \n\n    </li>\n  \n</ul>\n\n\n\n  <h2>What you did</h2><p class=\"\"><strong>Congratulations \ud83c\udf89 You just drafted, revised, and published a piece of technical documentation that will help your reader\u2019s get the most out of your app.</strong> And you should feel confident in this statement because your technical documentation is:</p><ul><li><p class=\"\">Specific to your reader\u2019s goal</p></li><li><p class=\"\">Organized and structured</p></li><li><p class=\"\">Accurate, consistent, and concise</p></li><li><p class=\"\">Polished because you tested and edited it </p></li></ul><p class=\"\">But as you worked on your document, you might have thought:</p><ul><li><p class=\"\"><em>It\u2019s clear I need to create more documents\u2026 but how should I </em><strong><em>organize</em></strong><em> them?</em></p></li><li><p class=\"\"><em>All this is great for new documentation\u2026 but what about </em><strong><em>existing documentation</em></strong><em>?</em></p></li><li><p class=\"\"><em>I\u2019m sure there\u2019s more to learn\u2026 is there a </em><strong><em>course on technical writing</em></strong><em>?</em></p></li></ul><p class=\"\">Well, fret not!</p><h2>What\u2019s next</h2><h3>How to organize a collection of documents</h3><p class=\"\">Organizing a collection of documents under labels is known as <strong>information architecture</strong> (IA)\u00b9. To start, use this basic IA for your app. Notice how the labels mirror the content types. For demo purposes:</p><ul><li><p class=\"\">Directories or folders have a forward slash like <code>/a-directory</code></p></li><li><p class=\"\">Files or pages use the format <code>a-page.ext</code></p></li></ul>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n<pre class=\"source-code\">Basic IA\n------------------------------------\nget-started.ext\n/tutorials\n  \u21b3 a-tutorial.ext\n  \u21b3 another-tutorial.ext\n/how-tos\n  \u21b3 a-how-to.ext\n  \u21b3 another-how-to.ext\n/explanations (or /topic, /concepts)\n  \u21b3 a-concept.ext\n  \u21b3 a-topic.ext\n/reference\n  \u21b3 an-element.ext\n  \u21b3 another-element.ext\ntroubleshooting.ext\nsupport.ext\nglossary.ext</pre>\n\n\n  <p class=\"\">Notice how there\u2019s a <strong>Support</strong> page.  A support page details how readers can reach the team who supports the app. This page isn\u2019t a content type, but it\u2019s strongly recommended in any IA.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n  <h3>How to revise existing documentation</h3>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n  <p class=\"\">Revising existing documentation is a little tricky because a simple, <em>\u201cMaybe I\u2019ll just move this here\u2026\u201d</em> can morph into an <em>\u201cOMG, I need to rewrite every. single. word.\u201d</em>  To prevent this, I recommend the following approach:</p><ul><li><p class=\"\"><strong>Determine the target audience for the documentation;</strong> doing this will make your content updates much more focused.</p></li><li><p class=\"\"><strong>Determine the goal of the documentation;</strong> this will help you determine the true\u00b2 content type.</p><ul><li><p class=\"\">Is it to get started? \u2192 Getting started </p></li><li><p class=\"\">Is it to teach or demo something? \u2192 Tutorial</p></li><li><p class=\"\">Is it to provide instructions for a specific task? \u2192 How-to</p></li><li><p class=\"\">Is it to explain a topic or concept? \u2192 Explanation </p></li><li><p class=\"\">Is it to provide specifications about a software element? \u2192 Reference  </p></li><li><p class=\"\">Is it to provide solutions for errors? \u2192 Troubleshooting</p></li></ul></li><li><p class=\"\"><strong>Reorganize the existing content;</strong> use the skills you learned in <a href=\"https://engineering.squarespace.com/blog/2023/part-2-use-good-headings-and-structure\">Part 2</a>.</p></li><li><p class=\"\"><strong>Update the existing content;</strong> use the guidelines you learned in <a href=\"https://engineering.squarespace.com/blog/2023/part-3-accurate-consistent-concise-content\">Part 3</a>.</p></li><li><p class=\"\"><strong>Revise and publish the updated\u00b3 content;</strong> use the process from <a href=\"https://engineering.squarespace.com/blog/2023/part-4-test-edit-and-publish-content\">Part 4</a><strong>.</strong></p></li></ul><p class=\"\">The approach doesn\u2019t include creating a glossary \u2013 this is on purpose. In my god-awful experience, the minute I decide to create a glossary, my updates to a single piece of technical documentation <em>balloons</em> across the entire documentation set and much more. \ud83d\ude29 <strong>Creating a glossary and updating any related documentation should be a separate, focused effort.</strong></p><h3>How to expand your technical writing skills</h3><p class=\"\">Here are some of my favorite resources; also recommended by many peers.</p><ul><li><p class=\"\"><a href=\"https://developers.google.com/tech-writing\">Technical Writing for Developers</a>; a free, self-paced course by Google</p></li><li><p class=\"\"><a href=\"https://docsfordevelopers.com\">Docs for Developers: An Engineer\u2019s field guide to Technical Writing</a>; great, approachable book</p></li><li><p class=\"\"><a href=\"https://www.amazon.com/Modern-Technical-Writing-Introduction-Documentation-ebook/dp/B01A2QL9SS\">Modern Technical Writing</a>; \u201cDon\u2019t write\u201d as the third heading in the table of contents had me verklempt</p></li></ul><p class=\"\">If you\u2019d like to practice your writing skills in the real world, I think <a href=\"https://developers.google.com/season-of-docs\">Google Season of Docs</a> is a fantastic way to get started with the open-source community.</p><p class=\"\"><strong>Another way to expand your skills is through the technical writing community.</strong> I wholeheartedly encourage you to join the WriteTheDocs <a href=\"https://www.writethedocs.org/slack/\">Slack</a> network even if you\u2019re shy about your skills. I\u2019m always learning and relearning by the discussions in the various channels. I\u2019ve also sent technical writing bloggers such as Tom Johnson emails about challenging documentation projects and have received thoughtful, sincere feedback.</p><p class=\"\">As long as you\u2019re engaged in the technical writing community, you\u2019ll still grow as a technical writer even if you\u2019re not actively writing. \ud83e\udd29</p><h2>Last words</h2><p class=\"\">I hope this tutorial on technical writing was approachable and amusing. If you\u2019d like to know more about the field in general, or if you\u2019d like to befriend someone who <em>loves</em> Oxford commas and can debate the logic behind it, feel free to <a href=\"mailto:azaidi@squarespace.com\">send a note</a>!</p><p class=\"\">I have to end this series with a note to others:  Youenn Pennarun, Casey Brown, Robb Romans, Eva Parish, Mark Marchione, and Tom Drapeau for working your magic to make this happen. You\u2019re all rock stars \ud83d\udd7afor helping me with words #englishishard</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n<hr />\n\n\n  <p class=\"\">\u00b9 <em>That\u2019s the definition I provided for this tutorial \u2013 there are many definitions for information architecture (IA). It\u2019s because the field intersects technology, design, and science and merits its own </em><a href=\"https://www.worldiaday.org\"><em>World IA Day</em></a><em>. For what it\u2019s worth, we learn to </em><a href=\"https://abbycovert.com/writing/early-childhood-ia/\"><em>organize and label something before speaking</em></a><em> \u2013 who knew?! (Thank you Abby Covert for making IA less intimidating.)</em></p><p class=\"\">\u00b2 <em>In my experience, most existing documentation tries to meet more than one reader\u2019s goal. When this happens, documentation is verbose, difficult to scan, and not specific. This is why a reader may become frustrated with documentation, and in turn, the app.</em></p><p class=\"\">\u00b3 <em>After you update a single piece of existing documentation, you may be beset with a strong desire to revamp the \u201cwhole shebang\u201d. Documentation revamps are better known as </em><strong><em>content inventory and audits</em></strong><em>. The Nielsen Norman Group has a thorough </em><a href=\"https://www.nngroup.com/articles/content-audits/\"><em>article</em></a><em> on the process.</em></p>"
      }
    ],
    "media_content": [
      {
        "type": "image/png",
        "url": "https://images.squarespace-cdn.com/content/v1/56ab961ecbced617ccd2461e/1699287539883-T5LB1010JB6VCA2GJWPE/chalkboard-congratulations.png?format=1500w",
        "medium": "image",
        "isdefault": "true",
        "width": "940",
        "height": "788"
      }
    ]
  },
  "Skyscanner": {
    "title": "What Happened?",
    "xmlUrl": "https://medium.com/feed/@SkyscannerEng",
    "htmlUrl": "http://codevoyagers.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/@SkyscannerEng",
      "value": "What Happened?"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/@SkyscannerEng/what-happened-f7c06f078a64?source=rss-401f3b3c958f------2"
      }
    ],
    "link": "https://medium.com/@SkyscannerEng/what-happened-f7c06f078a64?source=rss-401f3b3c958f------2",
    "id": "https://medium.com/p/f7c06f078a64",
    "guidislink": false,
    "authors": [
      {
        "name": "Skyscanner Engineering"
      }
    ],
    "author": "Skyscanner Engineering",
    "author_detail": {
      "name": "Skyscanner Engineering"
    },
    "published": "Tue, 21 Nov 2023 11:36:51 GMT",
    "published_parsed": [
      2023,
      11,
      21,
      11,
      36,
      51,
      1,
      325,
      0
    ],
    "updated": "2023-11-24T10:47:54.855Z",
    "updated_parsed": [
      2023,
      11,
      24,
      10,
      47,
      54,
      4,
      328,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/@SkyscannerEng",
        "value": "<h3>How recursion brought down flight search at Skyscanner</h3><p>On 14th September, 2023 8:05 AM UTC (all timestamps in UTC) there was a critical bug in the output of our geo data pipeline which resulted in a number of geo locations being set as parents of themselves. This caused disruption to our service, and for this we\u2019re sorry. It gave us the opportunity to evaluate what went wrong, what we learned, and ways we could prevent a situation like this from happening again.</p><p>Let\u2019s take a deep dive and explain things\u00a0further.</p><h3>What is Geo\u00a0Data?</h3><p>Geo data is a key dataset at Skyscanner which is used to provide systems, industry partners and travellers with a complete and accurate representation of the world. In simpler terms, any time you see an Airport, City, Region or Country used in Skyscanner, it\u2019s originating from this dataset. The most visible example across our offering can be seen when searching for flights where you will specify an airport, city or country for your\u00a0journey.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*dJ_JXjGpthEGPaCPFp2kNA.png\" /></figure><p><em>We use the geo data to populate origins/destinations and look for\u00a0flights</em></p><h3>What was the\u00a0issue?</h3><p>Skyscanner has been on a journey to upgrade our geo data set. At this time there are two versions,<strong> two geo models</strong>, running in parallel. Flights generally need to know about airports, cities, countries, contrary to other parts of the business where we need to model more complex relations such as districts, countries, islands, etc. Those relationships form a <strong>complex graph</strong> where locations are related to each others as <em>parents</em> and <em>children</em>.</p><p>For this reason we kept our original \u201c<strong>heritage</strong>\u201d data set, merged it with our <strong>canonical</strong> dataset, our source of truth. We then basically generate (or reconstruct) our heritage dataset from the canonical data every day at 8am UTC. This generation is referred to as <em>materialisation.</em></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/843/1*IZOP28NY3yKEKxn7yUkJVA.png\" /><figcaption>The Materialisation Process</figcaption></figure><p>On 14th September, a bug in the <em>materialisation</em> process updated some locations to be the <strong>parent</strong> of themselves. For example Scotland is now parent of Scotland. We\u2019ve created a <strong>loop in the geo hierarchy</strong>.</p><p>You can immediately see how this is a problem when our libraries and systems expect some structure in the parent/children relationships.</p><h3>How did this impact flight\u00a0search?</h3><p>The flight stack (our critical systems involved in flight search) loads this geo data and uses it for <strong>every search</strong> coming in from travellers. Because we serve lots of travellers, we scale the stack to multiple Kubernetes clusters in multiple regions in the world, <strong>totalling several hundreds of pods</strong> throughout the\u00a0world.</p><p>Anytime a search involving the affected entity came in, a thread was stuck in an infinite loop searching for the parent entity. This happened in all the pods with corrupted dataset.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4oxr6NA-sCe0zhvbEASRZA.png\" /></figure><p><em>Every request with affected entity stole one thread from the\u00a0service</em></p><p>Every stuck thread made the CPU work harder with memory also not being released by threads and as a result became unavailable. This resulted in <strong>CPU throttling</strong>, which in turn caused our <strong>autoscaler</strong> to provision more pods to cope up with new requests.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/720/1*pyfxQvXgRg1KdXFnzH8rvw.png\" /></figure><p><strong>CPU Throttling</strong></p><p>To make matters worse, an upstream service as part of a warmup request, was using an affected location giving our systems no chance to even start up and serve requests successfully.</p><p>All of this created <strong>the perfect storm</strong>, and the strain was felt throughout all our systems which were fighting for resources or depending on one of the affected systems as\u00a0well.</p><h3>What was the\u00a0impact?</h3><p>Our flight search was degraded for travellers. The error profile looked like this. In total, we served over one million errors to travellers searching for\u00a0flights.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/743/1*aZwu7cdtFe-NiGC9_wJ_cQ.png\" /></figure><h3>How did we fix\u00a0it?</h3><p>Once the data issue was identified, we were able to output the correct data after re-running the pipeline. The key thing here is the long time it took us to diagnose the root cause. Let\u2019s talk about\u00a0that.</p><h3>It took us a long time to diagnose the root cause\u00a0\u2026</h3><ul><li><strong>Bias</strong></li><li>We have a bias towards performance issues which led us to a diverse set of investigations away from the\u00a0cause.</li><li>A particular service was a source of previous incidents and all our efforts were concentrated on this service through the addition of more computing resources to alleviate the pressure.</li></ul><p><strong>Telemetry</strong></p><ul><li>We relied heavily on existing telemetry (metrics, traces, logs) which is the right thing to do but\u00a0\u2026</li><li>\u2026 it can only get you so far when things don\u2019t crash. We ended up attaching <strong>a JVM profiler </strong>to obtain thread dumps and finally identify the infinite\u00a0loop!</li></ul><p><strong>What did we\u00a0learn?</strong></p><ul><li><strong>Treat data changes like code changes</strong>: We did not immediately audit all the data changes which might have affected production. This should have been included in our analysis at step\u00a01.</li><li><strong>Beware of recency bias: </strong>Our recent incidents originated from a single service. Our attention immediately focused on recovering this service also in distress.</li><li><strong>Practice running large incidents frequently: </strong>As we\u2019ve matured our platform and services have become more resilient. This reliability resulted in fewer, less impactful incidents. While our engineers do frequently run their own wargames their scope is often limited by experience and imagination.</li><li><strong>Look at all the signals:</strong> Thinking about mitigation is correct but don\u2019t increase compute resources without establishing if you\u2019ve experienced a genuine increase in requests.</li><li><strong>Recap: </strong>For longer-running incidents take regular timeouts to step back and recap on what we\u2019ve\u00a0learnt.</li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f7c06f078a64\" width=\"1\" />"
      }
    ],
    "summary": "<h3>How recursion brought down flight search at Skyscanner</h3><p>On 14th September, 2023 8:05 AM UTC (all timestamps in UTC) there was a critical bug in the output of our geo data pipeline which resulted in a number of geo locations being set as parents of themselves. This caused disruption to our service, and for this we\u2019re sorry. It gave us the opportunity to evaluate what went wrong, what we learned, and ways we could prevent a situation like this from happening again.</p><p>Let\u2019s take a deep dive and explain things\u00a0further.</p><h3>What is Geo\u00a0Data?</h3><p>Geo data is a key dataset at Skyscanner which is used to provide systems, industry partners and travellers with a complete and accurate representation of the world. In simpler terms, any time you see an Airport, City, Region or Country used in Skyscanner, it\u2019s originating from this dataset. The most visible example across our offering can be seen when searching for flights where you will specify an airport, city or country for your\u00a0journey.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*dJ_JXjGpthEGPaCPFp2kNA.png\" /></figure><p><em>We use the geo data to populate origins/destinations and look for\u00a0flights</em></p><h3>What was the\u00a0issue?</h3><p>Skyscanner has been on a journey to upgrade our geo data set. At this time there are two versions,<strong> two geo models</strong>, running in parallel. Flights generally need to know about airports, cities, countries, contrary to other parts of the business where we need to model more complex relations such as districts, countries, islands, etc. Those relationships form a <strong>complex graph</strong> where locations are related to each others as <em>parents</em> and <em>children</em>.</p><p>For this reason we kept our original \u201c<strong>heritage</strong>\u201d data set, merged it with our <strong>canonical</strong> dataset, our source of truth. We then basically generate (or reconstruct) our heritage dataset from the canonical data every day at 8am UTC. This generation is referred to as <em>materialisation.</em></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/843/1*IZOP28NY3yKEKxn7yUkJVA.png\" /><figcaption>The Materialisation Process</figcaption></figure><p>On 14th September, a bug in the <em>materialisation</em> process updated some locations to be the <strong>parent</strong> of themselves. For example Scotland is now parent of Scotland. We\u2019ve created a <strong>loop in the geo hierarchy</strong>.</p><p>You can immediately see how this is a problem when our libraries and systems expect some structure in the parent/children relationships.</p><h3>How did this impact flight\u00a0search?</h3><p>The flight stack (our critical systems involved in flight search) loads this geo data and uses it for <strong>every search</strong> coming in from travellers. Because we serve lots of travellers, we scale the stack to multiple Kubernetes clusters in multiple regions in the world, <strong>totalling several hundreds of pods</strong> throughout the\u00a0world.</p><p>Anytime a search involving the affected entity came in, a thread was stuck in an infinite loop searching for the parent entity. This happened in all the pods with corrupted dataset.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4oxr6NA-sCe0zhvbEASRZA.png\" /></figure><p><em>Every request with affected entity stole one thread from the\u00a0service</em></p><p>Every stuck thread made the CPU work harder with memory also not being released by threads and as a result became unavailable. This resulted in <strong>CPU throttling</strong>, which in turn caused our <strong>autoscaler</strong> to provision more pods to cope up with new requests.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/720/1*pyfxQvXgRg1KdXFnzH8rvw.png\" /></figure><p><strong>CPU Throttling</strong></p><p>To make matters worse, an upstream service as part of a warmup request, was using an affected location giving our systems no chance to even start up and serve requests successfully.</p><p>All of this created <strong>the perfect storm</strong>, and the strain was felt throughout all our systems which were fighting for resources or depending on one of the affected systems as\u00a0well.</p><h3>What was the\u00a0impact?</h3><p>Our flight search was degraded for travellers. The error profile looked like this. In total, we served over one million errors to travellers searching for\u00a0flights.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/743/1*aZwu7cdtFe-NiGC9_wJ_cQ.png\" /></figure><h3>How did we fix\u00a0it?</h3><p>Once the data issue was identified, we were able to output the correct data after re-running the pipeline. The key thing here is the long time it took us to diagnose the root cause. Let\u2019s talk about\u00a0that.</p><h3>It took us a long time to diagnose the root cause\u00a0\u2026</h3><ul><li><strong>Bias</strong></li><li>We have a bias towards performance issues which led us to a diverse set of investigations away from the\u00a0cause.</li><li>A particular service was a source of previous incidents and all our efforts were concentrated on this service through the addition of more computing resources to alleviate the pressure.</li></ul><p><strong>Telemetry</strong></p><ul><li>We relied heavily on existing telemetry (metrics, traces, logs) which is the right thing to do but\u00a0\u2026</li><li>\u2026 it can only get you so far when things don\u2019t crash. We ended up attaching <strong>a JVM profiler </strong>to obtain thread dumps and finally identify the infinite\u00a0loop!</li></ul><p><strong>What did we\u00a0learn?</strong></p><ul><li><strong>Treat data changes like code changes</strong>: We did not immediately audit all the data changes which might have affected production. This should have been included in our analysis at step\u00a01.</li><li><strong>Beware of recency bias: </strong>Our recent incidents originated from a single service. Our attention immediately focused on recovering this service also in distress.</li><li><strong>Practice running large incidents frequently: </strong>As we\u2019ve matured our platform and services have become more resilient. This reliability resulted in fewer, less impactful incidents. While our engineers do frequently run their own wargames their scope is often limited by experience and imagination.</li><li><strong>Look at all the signals:</strong> Thinking about mitigation is correct but don\u2019t increase compute resources without establishing if you\u2019ve experienced a genuine increase in requests.</li><li><strong>Recap: </strong>For longer-running incidents take regular timeouts to step back and recap on what we\u2019ve\u00a0learnt.</li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f7c06f078a64\" width=\"1\" />"
  },
  "Ebay": {
    "title": "New Social Caption Generator Uses AI to Help Sellers Post More Easily",
    "xmlUrl": "https://www.ebayinc.com/stories/blogs/tech/rss/ ",
    "htmlUrl": "https://www.ebayinc.com/stories/blogs/tech/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://innovation.ebayinc.com/tech/rss",
      "value": "New Social Caption Generator Uses AI to Help Sellers Post More Easily"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://innovation.ebayinc.com/tech/product/new-social-caption-generator-uses-ai-to-help-sellers-post-more-easily/"
      }
    ],
    "link": "https://innovation.ebayinc.com/tech/product/new-social-caption-generator-uses-ai-to-help-sellers-post-more-easily/",
    "inc_shortlink": "https://ebayinc.to/48qCEKm",
    "inc_hubexclude": "0",
    "summary": "<div style=\"margin-bottom: 10px;\"><img alt=\"New Social Caption Generator Uses AI to Help Sellers Post More Easily\" height=\"115\" src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTVd/Screen-Shot-2023-12-19-at-9.47.19-AM-copycrop.jpg\" width=\"200\" /></div><div>eBay sellers now have a new tool to make social sharing easier, all powered by AI.</div>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://innovation.ebayinc.com/tech/rss",
      "value": "<div style=\"margin-bottom: 10px;\"><img alt=\"New Social Caption Generator Uses AI to Help Sellers Post More Easily\" height=\"115\" src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTVd/Screen-Shot-2023-12-19-at-9.47.19-AM-copycrop.jpg\" width=\"200\" /></div><div>eBay sellers now have a new tool to make social sharing easier, all powered by AI.</div>"
    },
    "published": "Mon, 18 Dec 2023 00:00:00 -0800",
    "published_parsed": [
      2023,
      12,
      18,
      8,
      0,
      0,
      0,
      352,
      0
    ],
    "authors": [
      {
        "name": "eBay News Team"
      }
    ],
    "author": "eBay News Team",
    "author_detail": {
      "name": "eBay News Team"
    },
    "media_thumbnail": [
      {
        "url": "https://static.ebayinc.com/api/assets/Uploads/Blog/Posts/_resampled/FitWzkwMCw1MThd/Screen-Shot-2023-12-19-at-9.47.19-AM-copycrop.jpg",
        "width": "900",
        "height": "518"
      }
    ],
    "href": "",
    "tags": [
      {
        "term": "article",
        "scheme": null,
        "label": null
      }
    ],
    "inc_topic": {
      "id": "154"
    },
    "inc_topics": "Artificial Intelligence",
    "inc_tag": {
      "id": "103"
    },
    "inc_tags": "Automation",
    "id": "https://innovation.ebayinc.com/tech/product/new-social-caption-generator-uses-ai-to-help-sellers-post-more-easily/",
    "guidislink": false
  },
  "Toptal": {
    "title": "The No-code Future: Innovating With Drag-and-Drop Application Development",
    "xmlUrl": "https://www.toptal.com/blog.rss",
    "htmlUrl": "https://www.toptal.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.toptal.com/blog.rss",
      "value": "The No-code Future: Innovating With Drag-and-Drop Application Development"
    },
    "summary": "A suite of tools can empower nontechnical users to create mobile applications without writing a line of code. Discover whether these no-code options are right for your next product.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.toptal.com/blog.rss",
      "value": "A suite of tools can empower nontechnical users to create mobile applications without writing a line of code. Discover whether these no-code options are right for your next product."
    },
    "published": "Wed, 10 Jan 2024 05:00:00 +0000",
    "published_parsed": [
      2024,
      1,
      10,
      5,
      0,
      0,
      2,
      10,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.toptal.com/product-managers/product-management/no-code-application-development"
      }
    ],
    "link": "https://www.toptal.com/product-managers/product-management/no-code-application-development",
    "id": "no-code-application-development",
    "guidislink": false,
    "authors": [
      {
        "name": "ALEX HUDYM, CHIEF OPERATING OFFICER @ WELOVENOCODE"
      }
    ],
    "author": "ALEX HUDYM, CHIEF OPERATING OFFICER @ WELOVENOCODE",
    "author_detail": {
      "name": "ALEX HUDYM, CHIEF OPERATING OFFICER @ WELOVENOCODE"
    },
    "media_content": [
      {
        "url": "https://bs-uploads.toptal.io/blackfish-uploads/components/blog_post_page/content/cover_image_file/cover_image/1321702/retina_1708x683_Untitled-892e6d750a8d370774ab137fe4eb5d82.png",
        "medium": "image"
      }
    ]
  },
  "Envoy": {
    "title": "Hackweek 2018 Recap",
    "xmlUrl": "https://envoy.engineering/feed",
    "htmlUrl": "https://envoy.engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://envoy.engineering/feed",
      "value": "Hackweek 2018 Recap"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://envoy.engineering/hackweek-2018-recap-bd47dd0441f8?source=rss----d8aa51f79fb---4"
      }
    ],
    "link": "https://envoy.engineering/hackweek-2018-recap-bd47dd0441f8?source=rss----d8aa51f79fb---4",
    "id": "https://medium.com/p/bd47dd0441f8",
    "guidislink": false,
    "tags": [
      {
        "term": "product",
        "scheme": null,
        "label": null
      },
      {
        "term": "design",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "hackathons",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Bill Heaton"
      }
    ],
    "author": "Bill Heaton",
    "author_detail": {
      "name": "Bill Heaton"
    },
    "published": "Thu, 04 Oct 2018 00:06:36 GMT",
    "published_parsed": [
      2018,
      10,
      4,
      0,
      6,
      36,
      3,
      277,
      0
    ],
    "updated": "2018-10-04T00:06:36.016Z",
    "updated_parsed": [
      2018,
      10,
      4,
      0,
      6,
      36,
      3,
      277,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://envoy.engineering/feed",
        "value": "<p>A story from the Engineering, Product and Design crew at Envoy,\u00a0Inc.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PvWHEaCyvf3YfT4dx44OHQ.jpeg\" /><figcaption>Challenge the Status\u00a0Quo</figcaption></figure><p>This summer \u26f1 we paused our current development for one week to focus on innovation. This focus was an opportunity to invest in both our engineering, product, and design staff, as well as invest in future product ideas. We worked on new product ideas to extend our product\u2019s use cases, applications for internal tools, new products to make our own workplace better, improving our current technology, and improving user experiences, e.g. accessibility.</p><p>Why stop forward development to experiment? Well, work should be fun, creativity should be common, a good idea \ud83d\udca1 can come from anyone. So, why not build something we believe will be\u00a0great?</p><h4>Orchestrating a hackweek\u00a0\u2692</h4><p>Our staff pitched their ideas/projects then organized by teaming up based on personal interest. We posted internal <em>help wanted</em> notices on a shared spreadsheet. Next we teamed up and joined project channels in our Slack chat. To create time to hack, we paused our current work in progress, likewise our scheduled ceremonies. This provided the freedom to hack on the ideas which our people believe will make a better future for our mission, to challenge the status quo of workplace technology. We focus on creating a better and safer workplace; and deliver solutions for visitor and employee experiences in the office that stand out. So our aim was to challenge ourselves to build and demo as many prototypes of <em>something awesome</em> we can, in about a\u00a0week.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/905/1*54Q5kJ7M5FLRQ0_kYr72FQ.png\" /></figure><p>How can our technology make a difference? Can we expand upon our platform to transform mundane tasks and even make complex tasks more efficient? Our application services for mobile apps and back office tools include a variety of software choices, we experimented to discover where we might fill gaps and expand our capabilities. We asked ourselves\u2026 Can we do better with data? Can our complex and automated solutions get faster and more accurate? Do we have any use cases that surround our existing solutions that we should explore? What can we quickly prototype or even build a MVP for? What\u2019s missing in our office? (Lets build an app for\u00a0that.)</p><p>At the end of the week we demoed\u00a0\ud83c\udfac</p><ul><li>\ud83d\ude32 Improvements to streamline our visitor sign-in with TouchId/FaceID.</li><li>\ud83c\udfed A new application for tracking facilities maintenance tasks.</li><li>\ud83d\udea7 An icon repository for our graphic\u00a0library.</li><li>\ud83c\udfa1 A queues app for managing a wait\u00a0list.</li><li>\ud83d\udde3 Improvements for accessibility of our dashboard application.</li><li>\ud83c\udf9b Machine learning to leverage patterns for improving OCR recognition.</li><li>\ud83d\uddd3 Event registration and\u00a0sign-in.</li><li>\ud83d\udcf7 Facial recognition capabilities to by-pass manual\u00a0checkin.</li><li>\ud83d\udea2 A new deployment solution for our dashboard application.</li></ul><p>\u2026what a great demo this was\u00a0\ud83d\udc4f</p><p>A quote coined while demoing our A11y improvements:</p><blockquote>\u201cWorkplaces must be accessible. So too must workplace technology.\u201d <br />\u2014 <a href=\"https://twitter.com/steveszc/status/1030564331006517248\">Steve Szczecina</a></blockquote><p>A few screenshots from our live demo to close out the\u00a0week\u2026</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/894/1*w9bcefRLruMZ90o0Aj7_og.png\" /><figcaption>iOS app to\u00a0fixit</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/864/1*pfoad0a9lFvIW-4R-GTUBg.png\" /><figcaption>Exploring machine\u00a0learning</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/641/1*39TYG2Hj1YDeGKJes5vcsg.png\" /><figcaption>Facial recognition app</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/907/1*e1Bfd1FdENLqTPGFSgM2rg.png\" /><figcaption>Event registration app</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/904/1*bf1BruihLIJmgWzXAUDRew.png\" /><figcaption>Learning from data to improve\u00a0features</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/907/1*BFAvi1ivaZQ5mg3xWhJdqA.png\" /><figcaption>Queues app sending live\u00a0text</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/865/1*Gi4KMWikASO6pdW5DWx29g.png\" /><figcaption>Icon library</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/792/1*92DGio2F8lGihOfY0UIyVg.png\" /><figcaption>Deployment app to activate a\u00a0release</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/907/1*mOwdi35XOXIE4VYg8ipwJQ.png\" /><figcaption>Using face\u00a0ID</figcaption></figure><p>As the week finished, a few questions arose\u2026</p><ul><li>What can we\u00a0ship?</li><li>What can we use internally?</li><li>Which ideas can be segmented for beta testing by an existing customer, or even a new customer?</li><li>How can we make work always feel like a hackweek?</li></ul><p>We do not have all the answers yet, only time will tell. One thing we know for sure is\u200a\u2014\u200awe want to do this again\u00a0:)</p><p>When we take action through experimentation we discover that we can make the impact we strive for, to make workplaces <strong>better</strong>, <strong>safer</strong>, <strong>more fun</strong>, and do so <strong>with style</strong>. We will able to ship some of the internal projects so that we may learn more; and iterate. Also, we made plans to iterate upon some of the prototypes we\u00a0demoed.</p><p>Since we innovate for the office, we strive to solve problems that meet our own interests. Likewise, we strive to develop solutions for the challenges that our customers experience. We are a <a href=\"https://envoy.engineering/building-our-remote-distributed-engineering-culture-2cfe9721ab4b\">distributed</a> company, meeting together for our hackweek and demoing solutions was a rewarding experience. Our team had plenty of fun when we all met up at our headquarters in San Francisco, and it was a pleasure to connect and work together onsite. We rolled up our sleeves and built solutions not only for our own distributed office \ud83c\udfe2 but also for the workplaces of the tomorrow \ud83d\ude80. We would love to ship some of the prototypes that we presented at the close of our hackweek\u200a\u2014\u200atime will tell which become winning solutions as we iterate \ud83d\udcd0and experiment \u2697.</p><p>A few observations from our experience hacking together\u2026</p><p><em>What were your initial expectations for the hackweek?</em></p><p>- I figured that it would be fun \ud83c\udfaa, but was uncertain if we\u2019d finish anything. What happens if we get pulled back on an issue for ongoing work? I was optimistic that we could build something cool to demo at the end of the week. I was not sure yet if I would have something valuable to contribute as a new member on the engineering team but hopeful to make a contribution.</p><p>- Building a half-working product that is \ud83d\udc1d buggy and unusable.</p><p><em>What were the highlights, what stood\u00a0out?</em></p><p>- The fact that all week long, ceremonies for organizing work were not really needed, we met as needed and at impromptu times of the day. We skipped formal processes in favor of just organizing ourselves. There was plenty to demo at the end of the week. I really liked the fact that many of the projects were something that we could actually put into play after the week was over. I was impressed by a mobile solution that simplified the steps users had to take by using features baked into the OS which created a streamlined and more natural experience. The efforts made on the dashboard project to apply changes to make the application more accessible to users was great, a demo with voice-over \ud83c\udf99 helped us understand the experience of users who rely on voice over features to use a web application.</p><p>- Being able to see potential of our teams\u200a\u2014\u200abuilding \ud83c\udfd7 a new features in a week, explore different solutions for a\u00a0goal.</p><p><em>What made you\u00a0laugh?</em></p><p>- During a demo an engineer mentioned \u201cwhen you have a problem\u2026\u201d and at the same time the camera \ud83c\udfa5 used in the demo was pointed at a specific individual, the presenter started giggling and the crowd broke out in laughter \ud83e\udd23. Not because the person was problematic, instead that as a group the team already knows how to work through problems and this individual proves that\u00a0point.</p><p>- \ud83d\udc36 Dogs in the office.\u00a0:D</p><p><em>What did you enjoy about the demos, or team\u00a0effort?</em></p><p>- I was fortunate to be on a team with a designer, product lead, API engineer and an iOS engineer. I contributed to the user interface portion of the feature. I was impressed that, as a newly formed team, we were able to identify the specific outcome we wanted to demo\u200a\u2014\u200aeven an ambitions scope of work. We were able to demo a full experience that involved coordination between multiple devices \ud83d\udcf1 and users. It was fun to explore the possibilities of what we could deliver as a prototype in only a few days. As a new engineering team member, it was a pleasure to work with people I have not yet had the privilege to work aside yet. I enjoyed the collaboration with individuals from our product and design teams. The variety of demos was impressive, from internal tools to solutions our which customers may benefit\u00a0from.</p><p>- To see how far our team can go in one\u00a0week.</p><p><em>Where there any risks you took and/or challenges you\u00a0faced?</em></p><p>- I thought it was pretty risky to take on the scope of the prototype that we wanted to demo/present in only a few days. Along with other <em>all-hands</em> \ud83d\ude4c activities \ud83c\udf7b \ud83c\udf77 \ud83c\udf69 \ud83c\udf79 \ud83c\udf89 occurring the same week - we only had a few days of focus. I tried out a library for a small mobile web app which I had not used before. It appeared to have the tooling I needed to move quickly and provided testing as well (I favor test driven development). Our designer did a great job, I knew I may not have the time to apply all the polish that would make the design really shine. But I made the effort to keep up with the iterations of the designs; while also developing a solution.</p><p>- Not being able to socialize as much as want to for all-hands week because I was focusing on hackweek project\u00a0\ud83d\udea7.</p><p><em>What did you\u00a0learn?</em></p><p>- I learned that the leadership team values experimentation and discovering solutions for the workplace; even by looking for solutions in our own environment \ud83d\udd75\ufe0f\u200d. I learned that talented people will do the right things to reach their goals, they will collaborate and have fun while taking on an ambitious goal. I learned how to use Glimmer.js for a small mobile web application and also tried out Tailwind CSS, a utility first\u00a0library.</p><p>- How to build an iOS\u00a0app.</p><p><em>What did you take away from the experience?</em></p><p>- I would like to ship \ud83d\udef3 the project we worked on, I know it was only a prototype but I think we did show a viable solution. I\u2019ll lean on our product team to know if that solution is also desirable for our customer base or even new customers. It was a pleasure to see the innovation that resulted from dedicating a week toward hacking on ideas brought up throughout the engineering, product and design teams. I would enjoy doing this again. I think I also have less reliance on the ceremonies we keep for producing software and instead a stronger reliance on the people to do so. We pulled off a nice prototype/demo without any traditional agile ceremony, just ad-hoc meeting and syncing up as questions arose.</p><p>- Learning new things and being able to work with different people \ud83d\udc7e\u00a0\ud83d\udc69\u200d\ud83d\ude80.</p><h4>In Closing\u2026</h4><p>Hopefully sharing our hackweek experience can provide some insight into the kind of people we employ at Envoy, as well as the values we hold. It\u2019s a pretty accurate snapshot \ud83d\uddbc of our internal culture that we hope inspires other teams to experiment, to create margin for innovation, and to attract like-minded product owners, designers and software engineers to work with\u00a0too.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=bd47dd0441f8\" width=\"1\" /><hr /><p><a href=\"https://envoy.engineering/hackweek-2018-recap-bd47dd0441f8\">Hackweek 2018 Recap</a> was originally published in <a href=\"https://envoy.engineering\">Envoy Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>A story from the Engineering, Product and Design crew at Envoy,\u00a0Inc.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PvWHEaCyvf3YfT4dx44OHQ.jpeg\" /><figcaption>Challenge the Status\u00a0Quo</figcaption></figure><p>This summer \u26f1 we paused our current development for one week to focus on innovation. This focus was an opportunity to invest in both our engineering, product, and design staff, as well as invest in future product ideas. We worked on new product ideas to extend our product\u2019s use cases, applications for internal tools, new products to make our own workplace better, improving our current technology, and improving user experiences, e.g. accessibility.</p><p>Why stop forward development to experiment? Well, work should be fun, creativity should be common, a good idea \ud83d\udca1 can come from anyone. So, why not build something we believe will be\u00a0great?</p><h4>Orchestrating a hackweek\u00a0\u2692</h4><p>Our staff pitched their ideas/projects then organized by teaming up based on personal interest. We posted internal <em>help wanted</em> notices on a shared spreadsheet. Next we teamed up and joined project channels in our Slack chat. To create time to hack, we paused our current work in progress, likewise our scheduled ceremonies. This provided the freedom to hack on the ideas which our people believe will make a better future for our mission, to challenge the status quo of workplace technology. We focus on creating a better and safer workplace; and deliver solutions for visitor and employee experiences in the office that stand out. So our aim was to challenge ourselves to build and demo as many prototypes of <em>something awesome</em> we can, in about a\u00a0week.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/905/1*54Q5kJ7M5FLRQ0_kYr72FQ.png\" /></figure><p>How can our technology make a difference? Can we expand upon our platform to transform mundane tasks and even make complex tasks more efficient? Our application services for mobile apps and back office tools include a variety of software choices, we experimented to discover where we might fill gaps and expand our capabilities. We asked ourselves\u2026 Can we do better with data? Can our complex and automated solutions get faster and more accurate? Do we have any use cases that surround our existing solutions that we should explore? What can we quickly prototype or even build a MVP for? What\u2019s missing in our office? (Lets build an app for\u00a0that.)</p><p>At the end of the week we demoed\u00a0\ud83c\udfac</p><ul><li>\ud83d\ude32 Improvements to streamline our visitor sign-in with TouchId/FaceID.</li><li>\ud83c\udfed A new application for tracking facilities maintenance tasks.</li><li>\ud83d\udea7 An icon repository for our graphic\u00a0library.</li><li>\ud83c\udfa1 A queues app for managing a wait\u00a0list.</li><li>\ud83d\udde3 Improvements for accessibility of our dashboard application.</li><li>\ud83c\udf9b Machine learning to leverage patterns for improving OCR recognition.</li><li>\ud83d\uddd3 Event registration and\u00a0sign-in.</li><li>\ud83d\udcf7 Facial recognition capabilities to by-pass manual\u00a0checkin.</li><li>\ud83d\udea2 A new deployment solution for our dashboard application.</li></ul><p>\u2026what a great demo this was\u00a0\ud83d\udc4f</p><p>A quote coined while demoing our A11y improvements:</p><blockquote>\u201cWorkplaces must be accessible. So too must workplace technology.\u201d <br />\u2014 <a href=\"https://twitter.com/steveszc/status/1030564331006517248\">Steve Szczecina</a></blockquote><p>A few screenshots from our live demo to close out the\u00a0week\u2026</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/894/1*w9bcefRLruMZ90o0Aj7_og.png\" /><figcaption>iOS app to\u00a0fixit</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/864/1*pfoad0a9lFvIW-4R-GTUBg.png\" /><figcaption>Exploring machine\u00a0learning</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/641/1*39TYG2Hj1YDeGKJes5vcsg.png\" /><figcaption>Facial recognition app</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/907/1*e1Bfd1FdENLqTPGFSgM2rg.png\" /><figcaption>Event registration app</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/904/1*bf1BruihLIJmgWzXAUDRew.png\" /><figcaption>Learning from data to improve\u00a0features</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/907/1*BFAvi1ivaZQ5mg3xWhJdqA.png\" /><figcaption>Queues app sending live\u00a0text</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/865/1*Gi4KMWikASO6pdW5DWx29g.png\" /><figcaption>Icon library</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/792/1*92DGio2F8lGihOfY0UIyVg.png\" /><figcaption>Deployment app to activate a\u00a0release</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/907/1*mOwdi35XOXIE4VYg8ipwJQ.png\" /><figcaption>Using face\u00a0ID</figcaption></figure><p>As the week finished, a few questions arose\u2026</p><ul><li>What can we\u00a0ship?</li><li>What can we use internally?</li><li>Which ideas can be segmented for beta testing by an existing customer, or even a new customer?</li><li>How can we make work always feel like a hackweek?</li></ul><p>We do not have all the answers yet, only time will tell. One thing we know for sure is\u200a\u2014\u200awe want to do this again\u00a0:)</p><p>When we take action through experimentation we discover that we can make the impact we strive for, to make workplaces <strong>better</strong>, <strong>safer</strong>, <strong>more fun</strong>, and do so <strong>with style</strong>. We will able to ship some of the internal projects so that we may learn more; and iterate. Also, we made plans to iterate upon some of the prototypes we\u00a0demoed.</p><p>Since we innovate for the office, we strive to solve problems that meet our own interests. Likewise, we strive to develop solutions for the challenges that our customers experience. We are a <a href=\"https://envoy.engineering/building-our-remote-distributed-engineering-culture-2cfe9721ab4b\">distributed</a> company, meeting together for our hackweek and demoing solutions was a rewarding experience. Our team had plenty of fun when we all met up at our headquarters in San Francisco, and it was a pleasure to connect and work together onsite. We rolled up our sleeves and built solutions not only for our own distributed office \ud83c\udfe2 but also for the workplaces of the tomorrow \ud83d\ude80. We would love to ship some of the prototypes that we presented at the close of our hackweek\u200a\u2014\u200atime will tell which become winning solutions as we iterate \ud83d\udcd0and experiment \u2697.</p><p>A few observations from our experience hacking together\u2026</p><p><em>What were your initial expectations for the hackweek?</em></p><p>- I figured that it would be fun \ud83c\udfaa, but was uncertain if we\u2019d finish anything. What happens if we get pulled back on an issue for ongoing work? I was optimistic that we could build something cool to demo at the end of the week. I was not sure yet if I would have something valuable to contribute as a new member on the engineering team but hopeful to make a contribution.</p><p>- Building a half-working product that is \ud83d\udc1d buggy and unusable.</p><p><em>What were the highlights, what stood\u00a0out?</em></p><p>- The fact that all week long, ceremonies for organizing work were not really needed, we met as needed and at impromptu times of the day. We skipped formal processes in favor of just organizing ourselves. There was plenty to demo at the end of the week. I really liked the fact that many of the projects were something that we could actually put into play after the week was over. I was impressed by a mobile solution that simplified the steps users had to take by using features baked into the OS which created a streamlined and more natural experience. The efforts made on the dashboard project to apply changes to make the application more accessible to users was great, a demo with voice-over \ud83c\udf99 helped us understand the experience of users who rely on voice over features to use a web application.</p><p>- Being able to see potential of our teams\u200a\u2014\u200abuilding \ud83c\udfd7 a new features in a week, explore different solutions for a\u00a0goal.</p><p><em>What made you\u00a0laugh?</em></p><p>- During a demo an engineer mentioned \u201cwhen you have a problem\u2026\u201d and at the same time the camera \ud83c\udfa5 used in the demo was pointed at a specific individual, the presenter started giggling and the crowd broke out in laughter \ud83e\udd23. Not because the person was problematic, instead that as a group the team already knows how to work through problems and this individual proves that\u00a0point.</p><p>- \ud83d\udc36 Dogs in the office.\u00a0:D</p><p><em>What did you enjoy about the demos, or team\u00a0effort?</em></p><p>- I was fortunate to be on a team with a designer, product lead, API engineer and an iOS engineer. I contributed to the user interface portion of the feature. I was impressed that, as a newly formed team, we were able to identify the specific outcome we wanted to demo\u200a\u2014\u200aeven an ambitions scope of work. We were able to demo a full experience that involved coordination between multiple devices \ud83d\udcf1 and users. It was fun to explore the possibilities of what we could deliver as a prototype in only a few days. As a new engineering team member, it was a pleasure to work with people I have not yet had the privilege to work aside yet. I enjoyed the collaboration with individuals from our product and design teams. The variety of demos was impressive, from internal tools to solutions our which customers may benefit\u00a0from.</p><p>- To see how far our team can go in one\u00a0week.</p><p><em>Where there any risks you took and/or challenges you\u00a0faced?</em></p><p>- I thought it was pretty risky to take on the scope of the prototype that we wanted to demo/present in only a few days. Along with other <em>all-hands</em> \ud83d\ude4c activities \ud83c\udf7b \ud83c\udf77 \ud83c\udf69 \ud83c\udf79 \ud83c\udf89 occurring the same week - we only had a few days of focus. I tried out a library for a small mobile web app which I had not used before. It appeared to have the tooling I needed to move quickly and provided testing as well (I favor test driven development). Our designer did a great job, I knew I may not have the time to apply all the polish that would make the design really shine. But I made the effort to keep up with the iterations of the designs; while also developing a solution.</p><p>- Not being able to socialize as much as want to for all-hands week because I was focusing on hackweek project\u00a0\ud83d\udea7.</p><p><em>What did you\u00a0learn?</em></p><p>- I learned that the leadership team values experimentation and discovering solutions for the workplace; even by looking for solutions in our own environment \ud83d\udd75\ufe0f\u200d. I learned that talented people will do the right things to reach their goals, they will collaborate and have fun while taking on an ambitious goal. I learned how to use Glimmer.js for a small mobile web application and also tried out Tailwind CSS, a utility first\u00a0library.</p><p>- How to build an iOS\u00a0app.</p><p><em>What did you take away from the experience?</em></p><p>- I would like to ship \ud83d\udef3 the project we worked on, I know it was only a prototype but I think we did show a viable solution. I\u2019ll lean on our product team to know if that solution is also desirable for our customer base or even new customers. It was a pleasure to see the innovation that resulted from dedicating a week toward hacking on ideas brought up throughout the engineering, product and design teams. I would enjoy doing this again. I think I also have less reliance on the ceremonies we keep for producing software and instead a stronger reliance on the people to do so. We pulled off a nice prototype/demo without any traditional agile ceremony, just ad-hoc meeting and syncing up as questions arose.</p><p>- Learning new things and being able to work with different people \ud83d\udc7e\u00a0\ud83d\udc69\u200d\ud83d\ude80.</p><h4>In Closing\u2026</h4><p>Hopefully sharing our hackweek experience can provide some insight into the kind of people we employ at Envoy, as well as the values we hold. It\u2019s a pretty accurate snapshot \ud83d\uddbc of our internal culture that we hope inspires other teams to experiment, to create margin for innovation, and to attract like-minded product owners, designers and software engineers to work with\u00a0too.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=bd47dd0441f8\" width=\"1\" /><hr /><p><a href=\"https://envoy.engineering/hackweek-2018-recap-bd47dd0441f8\">Hackweek 2018 Recap</a> was originally published in <a href=\"https://envoy.engineering\">Envoy Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Bandcamp": {
    "title": "Be careful how you rsyslog",
    "xmlUrl": "https://bandcamptech.wordpress.com/feed/",
    "htmlUrl": "https://bandcamptech.wordpress.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://bandcamptech.wordpress.com/feed/",
      "value": "Be careful how you rsyslog"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://bandcamptech.wordpress.com/2015/04/28/be-careful-how-you-rsyslog/"
      }
    ],
    "link": "https://bandcamptech.wordpress.com/2015/04/28/be-careful-how-you-rsyslog/",
    "comments": "https://bandcamptech.wordpress.com/2015/04/28/be-careful-how-you-rsyslog/#comments",
    "authors": [
      {
        "name": "Leigh Dyer"
      }
    ],
    "author": "Leigh Dyer",
    "author_detail": {
      "name": "Leigh Dyer"
    },
    "published": "Tue, 28 Apr 2015 18:29:22 +0000",
    "published_parsed": [
      2015,
      4,
      28,
      18,
      29,
      22,
      1,
      118,
      0
    ],
    "tags": [
      {
        "term": "Uncategorized",
        "scheme": null,
        "label": null
      }
    ],
    "id": "http://bandcamptech.wordpress.com/?p=302",
    "guidislink": false,
    "summary": "Bandcamp was offline briefly yesterday due to what I like to call an unexpected single point of failure. Good systems design is all about addressing single points of failure, making sure you have redundancies in place, but sometimes you discover single points of failure that you didn\u2019t realise you had. Yesterday\u2019s problem was caused by [&#8230;]",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://bandcamptech.wordpress.com/feed/",
      "value": "Bandcamp was offline briefly yesterday due to what I like to call an unexpected single point of failure. Good systems design is all about addressing single points of failure, making sure you have redundancies in place, but sometimes you discover single points of failure that you didn\u2019t realise you had. Yesterday\u2019s problem was caused by [&#8230;]"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://bandcamptech.wordpress.com/feed/",
        "value": "<p>Bandcamp was offline briefly yesterday due to what I like to call an <em>unexpected single point of failure</em>. Good systems design is all about addressing single points of failure, making sure you have redundancies in place, but sometimes you discover single points of failure that you didn\u2019t realise you had.</p>\n<p>Yesterday\u2019s problem was caused by maintenance on our central rsyslog server, which we use to collect analytics from our application servers. When that central server went down, it set a chain of events in motion:</p>\n<ul>\n<li>Remote logging from our app servers blocked, since we have rsyslog configured to use TCP, which attempts to guarantee delivery.</li>\n<li>Those blocked messages blocked <em>all</em> syslog logging on the app servers, since the default rsyslog configuration puts all logging in to a single delivery queue.</li>\n<li>Within minutes that delivery queue filled up, causing all subsequent logging requests to block, freezing not just our apps but also system services like sshd. So, no logging in.</li>\n</ul>\n<p>In the course of responding to the outage we quickly decided it was prudent to reboot the affected servers before continuing to investigate the root cause. We didn&#8217;t know at the time that once we restarted our apps the countdown clock started ticking. Fortunately we got to the bottom of the problem before the servers froze up again.</p>\n<p>Lesson learned! Our rsyslog configuration now uses a dedicated queue for remote logging, and that queue spills over to disk if it fills up, preventing rsyslog from blocking logging if the central server goes offline. Here&#8217;s the relevant code:</p>\n<blockquote>\n<pre>\n$ActionQueueType LinkedList\n$ActionQueueFileName apptimer\n$ActionResumeRetryCount -1\n$ActionQueueSaveOnShutdown on\nlocal0.* @@rsyslogserver:10514\n</pre>\n</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;<em><small>Leigh Dyer is the Lead Engineer of the Systems Team at Bandcamp, Inc.</small></em></p>"
      }
    ],
    "wfw_commentrss": "https://bandcamptech.wordpress.com/2015/04/28/be-careful-how-you-rsyslog/feed/",
    "slash_comments": "1",
    "media_content": [
      {
        "url": "https://2.gravatar.com/avatar/8fcad6350f0310b03b1464efe4559b9dda76a8bfffcf0e16ce2bdad5096d0417?s=96&d=https%3A%2F%2F2.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96&r=G",
        "medium": "image"
      }
    ]
  },
  "Deezer": {
    "title": "Deez is la tech\u200a\u2014\u200aS02E02\u200a\u2014\u200aEn t\u00eate-\u00e0-t\u00eate avec des SRE\u00a0: missions, quotidien et challenges",
    "xmlUrl": "https://deezer.io/feed",
    "htmlUrl": "https://deezer.io/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://deezer.io/feed",
      "value": "Deez is la tech\u200a\u2014\u200aS02E02\u200a\u2014\u200aEn t\u00eate-\u00e0-t\u00eate avec des SRE\u00a0: missions, quotidien et challenges"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://deezer.io/deez-is-la-tech-s02e02-en-t%C3%AAte-%C3%A0-t%C3%AAte-avec-des-sre-missions-quotidien-et-challenges-7a45e4bdd1f3?source=rss----2ab7e077175a---4"
      }
    ],
    "link": "https://deezer.io/deez-is-la-tech-s02e02-en-t%C3%AAte-%C3%A0-t%C3%AAte-avec-des-sre-missions-quotidien-et-challenges-7a45e4bdd1f3?source=rss----2ab7e077175a---4",
    "id": "https://medium.com/p/7a45e4bdd1f3",
    "guidislink": false,
    "tags": [
      {
        "term": "site-reliability-engineer",
        "scheme": null,
        "label": null
      },
      {
        "term": "devops",
        "scheme": null,
        "label": null
      },
      {
        "term": "deezer",
        "scheme": null,
        "label": null
      },
      {
        "term": "deez-is-la-tech",
        "scheme": null,
        "label": null
      },
      {
        "term": "sre",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Pauline Munier"
      }
    ],
    "author": "Pauline Munier",
    "author_detail": {
      "name": "Pauline Munier"
    },
    "published": "Wed, 15 Nov 2023 10:04:21 GMT",
    "published_parsed": [
      2023,
      11,
      15,
      10,
      4,
      21,
      2,
      319,
      0
    ],
    "updated": "2023-11-15T10:04:21.317Z",
    "updated_parsed": [
      2023,
      11,
      15,
      10,
      4,
      21,
      2,
      319,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://deezer.io/feed",
        "value": "<h3>Deez is la tech\u200a\u2014\u200aS02E02\u200a\u2014\u200aEn t\u00eate-\u00e0-t\u00eate avec des SRE\u00a0: missions, quotidien et challenges</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2TgeGcHY2b5U6Jw8thioIA.png\" /></figure><p>SRE. Trois lettres qui soul\u00e8vent autant d\u2019int\u00e9r\u00eat que de questionnement.</p><p>SRE pour \u201cSite Reliability Engineering\u201d, ou ing\u00e9nierie de fiabilit\u00e9 des sites dans la langue de Moli\u00e8re. Et c\u2019est \u00e0 cette discipline, aujourd\u2019hui devenue un m\u00e9tier \u00e0 part enti\u00e8re, que s\u2019int\u00e9resse ce nouvel \u00e9pisode du podcast Deez is la\u00a0tech.</p><p>En quoi consiste le Site Reliability Engineering\u00a0? Quelle est la place du SRE en entreprise\u00a0? Quels sont les missions, t\u00e2ches quotidiennes et d\u00e9fis d\u2019un Site Reliability Engineer\u00a0? Quel est le profil id\u00e9al du SRE\u00a0? Apprenez-en plus ci-dessous gr\u00e2ce \u00e0 nos trois invit\u00e9s\u00a0!</p><p><em>Note: This post accompanies the release of the second episode of the second season of \u201cDeez is la tech\u201d, a podcast created by Deezer\u2019s Product &amp; Tech teams\u200a\u2014\u200ain French only for now. You can still find English content on </em><a href=\"https://deezer.io/\"><em>deezer.io</em></a><em> though. Go check it\u00a0out!</em></p><h3>R\u00e9sum\u00e9 de l\u2019\u00e9pisode</h3><p>Vingt ans apr\u00e8s sa th\u00e9orisation, le Site Reliability Engineering continue d\u2019intriguer et reste un concept encore flou pour beaucoup. Derri\u00e8re le sigle SRE se cachent, en effet, diverses d\u00e9finitions et r\u00e9alit\u00e9s.</p><p>Mais qu\u2019est-ce donc que le SRE\u00a0? Quel rapport avec DevOps\u00a0? Que font concr\u00e8tement les Site Reliability Engineers chez Deezer et \u00e0 quels d\u00e9fis sont-ils confront\u00e9s\u00a0? Enfin, comment devient-on SRE\u00a0?</p><p>Une fois n\u2019est pas coutume, Lo\u00efc Doubinine (@<a href=\"https://twitter.com/Ztec6/\">ztec6</a>) et Vincent Lepot (@<a href=\"https://twitter.com/neozibok\">neozibok</a>), tous deux Senior Expert Backend SRE, sont les invit\u00e9s de cet \u00e9pisode anim\u00e9 par <a href=\"https://www.linkedin.com/in/stephanebachelet/\">St\u00e9phane Bachelet</a> (Senior Coach Agile) et <a href=\"https://www.linkedin.com/in/pauline-m-b8703048/\">Pauline Munier</a> (Knowledge Manager). En compagnie de <a href=\"https://medium.com/u/1df55d0db6c5\">Denis GERMAIN</a> (Senior Expert Infrastructure Engineer\u200a\u2014\u200a@<a href=\"https://twitter.com/zwindler\">zwindler</a>), ils rappellent les pr\u00e9ceptes fondateurs du Site Reliability Engineering avant de d\u00e9tailler leur application au quotidien au sein des \u00e9quipes de Deezer. Entre automatisation et \u00e9vang\u00e9lisation, et au moyen d\u2019indicateurs et d\u2019error budget notamment, le SRE se r\u00e9v\u00e8le \u00eatre le v\u00e9ritable garant des bonnes pratiques des d\u00e9veloppeurs et des op\u00e9rationnels, de la qualit\u00e9 logicielle et de la fiabilit\u00e9 du\u00a0site.</p><a href=\"https://medium.com/media/af45cbb8cdf1f96b84a10de34802ec90/href\">https://medium.com/media/af45cbb8cdf1f96b84a10de34802ec90/href</a><p><em>\u00c9pisode \u00e9galement disponible sur </em><a href=\"https://deezer.page.link/svHKRDwnr7kfUp337\"><em>Deezer</em></a><em> | </em><a href=\"https://podcasts.apple.com/fr/podcast/deez-is-la-tech/id1648116961?i=1000634842642\"><em>Apple Podcasts</em></a><em> | </em><a href=\"https://open.spotify.com/episode/49W8hfAY0qiMnWAo20Vvjw?si=izIodKjeSY2gkKc20Hrtnw\"><em>Spotify</em></a><em> | </em><a href=\"https://music.amazon.de/podcasts/c0253c4d-c100-46d9-a660-d1b5f93cc69f/episodes/7cc28600-cba7-48e4-8e74-b4bc73b62fba/deez-is-la-tech-s02e02---en-t%C3%AAte-%C3%A0-t%C3%AAte-avec-des-sre-missions-quotidien-et-challenges\"><em>Amazon\u00a0Music</em></a><em>.</em></p><h3>Transcription</h3><p><strong>[00:00:06.720]\u200a\u2014\u200aVincent\u00a0: </strong>Bonjour et bienvenue dans Deez is la tech, le podcast qui n\u2019p\u00e8te ni les plombs, ni les crons\u00a0! Cr\u00e9\u00e9 et anim\u00e9 par les \u00e9quipes Product &amp; Tech de Deezer, ce programme aborde des sujets relatifs aux mondes de la tech et du streaming musical, et vous fait occasionnellement d\u00e9couvrir les coulisses de certaines des fonctionnalit\u00e9s phares de Deezer. Rejoignez-nous chaque mois pour une nouvelle discussion entre coll\u00e8gues et pairs, en tout d\u00e9contraction, m\u00ealant partages d\u2019exp\u00e9riences, bonnes pratiques et r\u00e9flexions sur les tendances futures. Pr\u00eats pour un nouvel \u00e9pisode\u00a0? Chaussez vos \u00e9couteurs, \u00e7a commence maintenant\u00a0!</p><p><strong>[00:00:43.150]\u200a\u2014\u200aSt\u00e9phane\u00a0: </strong>Le sigle \u201cSRE\u201d a le vent en poupe depuis quelques ann\u00e9es et \u00e0 en juger par les descriptions de postes sur le march\u00e9 de l\u2019emploi, son r\u00f4le et ses missions semblent diff\u00e9rer d\u2019une entreprise \u00e0 l\u2019autre. Il ne serait pas totalement erron\u00e9 de dire qu\u2019il y a quasiment autant de d\u00e9finitions du SRE qu\u2019il n\u2019y a d\u2019entreprises en recherche. Qu\u2019est-ce vraiment que le SRE et quels en sont les principes fondamentaux\u00a0? Quelle place occupe le SRE dans une entreprise, et plus particuli\u00e8rement chez Deezer\u00a0? Quels outils utilise-t-on en tant que SRE et \u00e0 quels d\u00e9fis fait-on face\u00a0? Enfin, comment devient- on SRE\u00a0? Je suis St\u00e9phane Bachelet, Coach Agile chez Deezer, et avec ma coll\u00e8gue Pauline Munier, Knowledge Manager et productrice de ce podcast, nous accueillons aujourd\u2019hui Lo\u00efc Doubinine, Denis Germain et Vincent Lepot afin de d\u00e9mystifier le r\u00f4le de\u00a0SRE.</p><p><strong>[00:01:29.900]\u200a\u2014\u200aPauline\u00a0:</strong> Salut Denis\u00a0! On est ravi de t\u2019accueillir dans Deez is la tech. Peux-tu te pr\u00e9senter en quelques mots\u00a0?</p><p><strong>[00:01:35.550]\u200a\u2014\u200aDenis\u00a0: </strong>Je m\u2019appelle Denis Germain, je suis Site Reliability Engineer chez Deezer. Je connais un petit peu le m\u00e9tier donc je me suis dit que \u00e7a pouvait \u00eatre une bonne id\u00e9e d\u2019en\u00a0parler.</p><p><strong>[00:01:44.310]\u200a\u2014\u200aPauline\u00a0:</strong> Merci\u00a0! \u00c0 tes c\u00f4t\u00e9s se trouvent deux habitu\u00e9s du podcast car ils en sont, en temps normal, les animateurs. Je vous laisse en dire un peu plus sur\u00a0vous.</p><p><strong>[00:01:52.400]\u200a\u2014\u200aVincent\u00a0: </strong>Bonjour\u00a0! Effectivement, \u00e7a fait bizarre d\u2019\u00eatre de l\u2019autre c\u00f4t\u00e9. Vincent Lepot, je suis\u200a\u2014\u200aje vais essayer de le dire aussi bien que Denis\u200a\u2014\u200aSite Reliability Engineer Proxy\u200a\u2014\u200aon pourra revenir un peu plus sur le \u201cproxy\u201d pendant le podcast\u200a\u2014\u200aapr\u00e8s avoir \u00e9t\u00e9 d\u00e9veloppeur back-end pendant tr\u00e8s longtemps.</p><p><strong>[00:02:10.660]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Moi, c\u2019est Lo\u00efc Doubinine. Mon titre complet officiel, c\u2019est Senior Expert Back End SRE, donc en gros, d\u00e9veloppeur SRE back-end.</p><p><strong>[00:02:20.550]\u200a\u2014\u200aPauline\u00a0:</strong> Merci \u00e0 tous les trois de vous joindre \u00e0 nous aujourd\u2019hui pour parler de SRE ou <em>SRE [prononc\u00e9 en anglais]</em> pour les bilingues. D\u00e9j\u00e0, qu\u2019est-ce que le SRE\u00a0?</p><p><strong>[00:02:29.630]\u200a\u2014\u200aDenis\u00a0: </strong>C\u2019est une philosophie, une fa\u00e7on de travailler qui a \u00e9t\u00e9 invent\u00e9e par des gens chez Google. C\u2019est assez vieux, \u00e7a date de 2003. En fait, il y avait un nouveau service, il fallait le maintenir en condition op\u00e9rationnelle et ils ont demand\u00e9 \u00e0 un VP Engineering chez Google de s\u2019en occuper. Chez Google, c\u2019est surtout des software engineers. La personne en question avait un background de software engineer, pas d\u2019op\u00e9rationnel. Il s\u2019est dit qu\u2019il allait faire les choses un peu diff\u00e9remment, donc \u00e0 contre-courant de ce qui se faisait \u00e0 l\u2019\u00e9poque. Il a dit qu\u2019il allait faire de l\u2019infra comme le feraient des d\u00e9veloppeurs. Il y a tout un tas de pr\u00e9ceptes qui ont \u00e9t\u00e9 mis sur papier bien plus tard\u200a\u2014\u200aen 2016 je crois\u200a\u2014\u200adans le \u201c<em>SRE Book\u201d</em> dont on va pouvoir parler. Grosso modo, c\u2019est une philosophie un petit peu diff\u00e9rente sur la fa\u00e7on dont on va g\u00e9rer l\u2019infrastructure, plus comme le ferait un d\u00e9veloppeur et pas comme le ferait un op\u00e9rationnel\u200a\u2014\u200am\u00eame si le terme est peut-\u00eatre un peu exag\u00e9r\u00e9 dans l\u2019\u00e9crit de\u00a0Google.</p><p><strong>[00:03:27.690]\u200a\u2014\u200aVincent\u00a0: </strong>On a beaucoup entendu parler de \u201cDevOps\u201d pendant tr\u00e8s longtemps et on va dire que le SRE est une mani\u00e8re de l\u2019impl\u00e9menter qu\u2019a mis en place Google il y a effectivement, maintenant, quelques ann\u00e9es\u200a\u2014\u200a\u00e7a fait pas loin de 20 ans. C\u2019est beaucoup autour de l\u2019automatisation, du suivi d\u2019indicateurs\u200a\u2014\u200ades choses qui nous paraissent maintenant assez naturelles, on va dire, mais qui ne l\u2019\u00e9taient pas quand Google a mis \u00e7a en place il y a une vingtaine d\u2019ann\u00e9es.</p><p><strong>[00:03:52.390]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>En gros, c\u2019est passer de serveurs g\u00e9r\u00e9s \u00e0 la main, avec des commandes qu\u2019on ex\u00e9cute \u00e0 la main, soit pour un installer ou mettre \u00e0 jour, ou g\u00e9n\u00e9ralement plus pour r\u00e9parer quand \u00e7a s\u2019est cass\u00e9 la tronche, \u00e0 une approche o\u00f9 l\u2019on automatise, o\u00f9 ce sont des robots qui font \u00e7a pour nous et o\u00f9 l\u2019on n\u2019a limite plus besoin de le faire \u00e0 la main et \u00e7a se fait tout\u00a0seul.</p><p><strong>[00:04:14.370]\u200a\u2014\u200aDenis\u00a0: </strong>Oui, l\u2019ennemi num\u00e9ro 1 de l\u2019Ops, selon les personnes qui ont cr\u00e9\u00e9 le SRE chez Google, c\u2019est le travail r\u00e9p\u00e9titif, le travail manuel, le travail qui pourrait \u00eatre automatis\u00e9, qui n\u2019a pas de valeur ajout\u00e9e. Et ce travail-l\u00e0, moi qui viens du monde de l\u2019infra avant d\u2019avoir fait du SRE, je l\u2019ai connu. J\u2019ai \u00e9crit des proc\u00e9dures pour installer des serveurs dans des Word, dans des documents Docs, o\u00f9 il fallait refaire tout le document d\u00e8s qu\u2019il y avait la moindre version qui changeait, o\u00f9 il fallait copier-coller les commandes \u00e0 la main\u200a\u2014\u200ala moiti\u00e9 du temps, on se plantait, on installait les mauvais trucs. C\u2019\u00e9tait la cata\u00a0! Ce monde o\u00f9 les serveurs avaient des petits noms mignons\u200a\u2014\u200aj\u2019adore cette p\u00e9riode mais ce n\u2019\u00e9tait pas du tout efficace. On parle de \u201cpet\u201d versus \u201ccattle\u201d, donc on parlait d\u2019animaux de compagnie avant et maintenant de \u201ccattle\u201d, c\u2019est-\u00e0-dire du b\u00e9tail\u00a0: ce sont des vaches, elles ont des num\u00e9ros sur l\u2019oreille et quand il y en a une qui meurt, ce n\u2019est pas grave, on en ach\u00e8te une autre et on la remplace.</p><p><strong>[00:05:16.210]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Tous les v\u00e9g\u00e9tariens sont en train de se retourner\u00a0!</p><p><strong>[00:05:18.940]\u200a\u2014\u200aDenis\u00a0: </strong>Oui\u00a0! Malheureusement, ce sont les termes de l\u2019industrie, mais c\u2019est vrai que ce n\u2019est pas tr\u00e8s bien pour le bien-\u00eatre animal.</p><p><strong>[00:05:24.780]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Mais par contre, on voit bien cette diff\u00e9rence de taille. Il y a une dizaine ou une quinzaine d\u2019ann\u00e9es, on g\u00e9rait un ou deux serveurs, ils \u00e9taient dans le placard derri\u00e8re ou potentiellement dans le sous-sol parce qu\u2019on voulait l\u2019avoir pas loin et qu\u2019il fallait mettre la clim. Maintenant, c\u2019est dans des data centers, on parle de centaines et de centaines de machines. Ce n\u2019est plus du tout la m\u00eame chose. On ne peut plus humainement se permettre d\u2019installer, de configurer ces centaines de machines probablement tous les jours. Avant, on le faisait pour un serveur. C\u2019\u00e9tait possible parce qu\u2019on le faisait une fois dans l\u2019ann\u00e9e, une fois dans l\u2019ann\u00e9e on faisait une petite campagne de mise \u00e0 jour. On avait deux machines donc \u00e7a allait, c\u2019\u00e9tait humainement g\u00e9rable. Maintenant, ce n\u2019est plus possible. On ferait \u00e7a toute la journ\u00e9e et on n\u2019arriverait encore m\u00eame pas \u00e0 suivre les cadences\u200a\u2014\u200aparce que les machines qu\u2019on rajoute dans des data centers, c\u2019est par palettes enti\u00e8res maintenant. Il faut que \u00e7a se fasse tout seul, et comme \u00e7a doit se faire tout seul, \u00e7a doit s\u2019automatiser. Et les d\u00e9veloppeurs ont quand m\u00eame apport\u00e9 beaucoup de choses pour l\u2019automatisation, avec beaucoup de pr\u00e9ceptes\u200a\u2014\u200aparce que c\u2019est quelque chose que l\u2019on fait depuis longtemps. C\u2019est ce qui s\u2019est infus\u00e9 dans l\u2019Ops, dans la gestion d\u2019infrastructures, ce qui a justement amen\u00e9 \u00e0 cette th\u00e9orisation, de mani\u00e8re \u00e0 mettre des mots et des r\u00e8gles sur cet entre-deux\u200a\u2014\u200aentre ce que faisaient les d\u00e9veloppeurs et ce que faisaient les Ops\u200a\u2014\u200ahistoire d\u2019avoir un langage commun\u200a\u2014\u200ace que l\u2019on a souvent appel\u00e9 DevOps, sans jamais le\u00a0d\u00e9finir.</p><p><strong>[00:06:51.680]\u200a\u2014\u200aDenis\u00a0:</strong> Oui, c\u2019est \u00e7a. Ce que j\u2019aime bien rappeler, c\u2019est que DevOps est arriv\u00e9 apr\u00e8s le SRE. C\u2019est assez amusant puisque nous\u200a\u2014\u200aen tout cas en Europe\u200a\u2014\u200aon l\u2019a d\u00e9couvert bien apr\u00e8s. C\u2019est-\u00e0-dire que Google faisait d\u00e9j\u00e0 du DevOps bien avant le DevOps. Devops a \u00e9t\u00e9 th\u00e9oris\u00e9 par un Belge, Patrick Debois, en 2008\u20132009 il me semble. C\u2019est l\u00e0 o\u00f9 on parle des cycles courts, de tout tester, de donner plus d\u2019autonomie aux d\u00e9veloppeurs, de rassembler les \u00e9quipes\u2026 Et tous ces pr\u00e9ceptes-l\u00e0, on les retrouve aussi dans SRE. C\u2019est pour \u00e7a que les gens confondent souvent un petit peu les deux, puisque les visions sont assez proches. Google avait essay\u00e9 de brander un peu en disant \u201cSRE implement DevOps\u201d. C\u2019est une fa\u00e7on de dire que c\u2019est la m\u00eame chose, mais fait diff\u00e9remment.</p><p><strong>[00:07:39.400]\u200a\u2014\u200aSt\u00e9phane\u00a0:</strong> Et du coup, quelle est la place du SRE dans une entreprise de d\u00e9veloppement logiciel, et notamment chez Deezer\u00a0?</p><p><strong>[00:07:46.140]\u200a\u2014\u200aVincent\u00a0:</strong> Je dirais que \u00e7a va un peu d\u00e9pendre des visions. Souvent, on imagine surtout que le SRE devrait \u00eatre\u200a\u2014\u200aen tout cas, c\u2019est notre position, ce que l\u2019on essaie de pousser mais ce qui est assez compliqu\u00e9 dans les organisations, c\u2019est de se dire que le SRE devrait \u00eatre au c\u0153ur de l\u2019\u00e9quipe. C\u2019est-\u00e0-dire que contrairement \u00e0 des \u00e9quipes d\u2019infrastructures vraiment tr\u00e8s \u201cplatform\u201d o\u00f9 l\u2019on va avoir des gens qui s\u2019occupent de racker des serveurs, de mettre \u00e0 disposition des choses, etc., le SRE a plut\u00f4t comme vocation d\u2019essayer d\u2019\u00eatre en accompagnement des \u00e9quipes de d\u00e9veloppement et d\u2019essayer de les accompagner dans le quotidien d\u2019une application, dans la maintenance d\u2019une application et d\u2019essayer de les aider \u00e0 suivre des m\u00e9triques, \u00e0 mettre en place de l\u2019automatisation, etc.</p><p><strong>[00:08:28.710]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Oui, apporter des concepts pour les aider. Dans le d\u00e9veloppement, on a beaucoup de pratiques qui viennent naturellement parce qu\u2019on a l\u2019habitude, on va d\u00e9velopper, on va coder, on va envoyer notre programme sur le serveur pour le faire tourner. Et comme on l\u2019a dit, \u00e7a n\u2019est plus possible aujourd\u2019hui. Du coup, on a des nouveaux outils pour pouvoir mettre le code qu\u2019on a compil\u00e9 en production. Mais ces nouveaux outils viennent aussi avec leurs contraintes, leurs complexit\u00e9s, parce que l\u2019on ne compile plus nous- m\u00eames les binaires que l\u2019on envoie en production par exemple. Il y a toute une cha\u00eene qui a \u00e9t\u00e9 mise en place pour le faire, mais c\u2019est une cha\u00eene qui, pour un junior par exemple, ou pour un d\u00e9veloppeur qui ne conna\u00eet pas ces cha\u00eenes-l\u00e0, n\u00e9cessite d\u2019\u00eatre apprivois\u00e9e, d\u2019\u00eatre comprise et d\u2019\u00eatre un peu manipul\u00e9e pour pouvoir \u00eatre utilis\u00e9e efficacement. \u00c7a vient aussi avec certaines pertes\u00a0: l\u00e0 o\u00f9 avant, le d\u00e9veloppeur pouvait potentiellement envoyer en prod et observer en production directement au travers de logs ou au travers d\u2019acc\u00e8s directs parfois, maintenant on va avoir des outils interm\u00e9diaires pour faire du debugging, du monitoring, etc. Et pareil, il faut apprendre \u00e0 les utiliser efficacement pour en tirer tout le b\u00e9n\u00e9fice, pour se rendre compte que notre projet fonctionne bien\u200a\u2014\u200aou pas\u200a\u2014\u200aquand on l\u2019envoie en production.</p><p><strong>[00:09:49.540]\u200a\u2014\u200aPauline\u00a0:</strong> Comment se mat\u00e9rialise cet accompagnement, concr\u00e8tement\u00a0?</p><p><strong>[00:09:53.140]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>C\u2019est la grande question, je pense. Il y a une part purement technique de connaissance et de capacit\u00e9 \u00e0 \u00eatre entre les deux milieux. On parle de DevOps et le mot en lui-m\u00eame, c\u2019est \u201cOps\u201d et \u201cDev\u201d accol\u00e9s ensemble. L\u2019id\u00e9e, c\u2019est d\u2019avoir un set de comp\u00e9tences et de connaissances sur les deux aspects, sans forc\u00e9ment \u00eatre parfait dans les deux. Il y aura toujours des experts des deux c\u00f4t\u00e9s et c\u2019est normal. Par contre, avoir suffisamment de connaissances pour faire le pont permet justement d\u2019avoir le dialogue. C\u2019est \u00e7a, je pense, qui est le plus important. Comme disait Vincent, d\u2019\u00eatre dans les \u00e9quipes et d\u2019\u00eatre capable de parler avec les \u00e9quipes de d\u00e9veloppement. C\u2019est donc avoir le dialogue, les mots, la p\u00e9dagogie pour pouvoir discuter avec des d\u00e9veloppeurs, tout en ayant aussi la capacit\u00e9 d\u2019avoir les mots, d\u2019avoir la p\u00e9dagogie, de discuter avec des op\u00e9rationnels. C\u2019est faire ce pont entre ces deux mondes qui\u2026 On a tendance \u00e0 troller en disant qu\u2019ils sont irr\u00e9conciliables. Mais l\u2019id\u00e9e, c\u2019est justement de les r\u00e9concilier, de faire en sorte que les deux avancent en m\u00eame temps. Et donc, c\u2019est \u00eatre concr\u00e8tement dans les \u00e9quipes, transmettre les probl\u00e9matiques des D\u00e9vs aux Ops, transmettre les probl\u00e9matiques des Ops aux D\u00e9vs, transmettre les nouveaux concepts qui permettent \u00e0 la fois aux Ops et aux D\u00e9vs de comprendre les deux autres\u00a0aspects.</p><p><strong>[00:11:08.710]\u200a\u2014\u200aDenis\u00a0: </strong>Le r\u00f4le du SRE, finalement, c\u2019est d\u2019\u00eatre l\u2019\u00e9vang\u00e9liste de toutes les bonnes pratiques, aussi bien les bonnes pratiques de d\u00e9v que les bonnes pratiques des op\u00e9rationnels. Quand on va dans les \u00e9quipes, on est un petit peu le consultant, on est un petit peu la personne qui va permettre de r\u00e9parer les petits probl\u00e8mes, de s\u2019assurer que tout est bien s\u00e9curis\u00e9, que tout est bien surveill\u00e9, monitor\u00e9. C\u2019est la personne qui va amener aux \u00e9quipes le petit bout de comp\u00e9tence qui leur manque pour d\u00e9livrer du logiciel de meilleure qualit\u00e9, et donc plus fiable. Puisque c\u2019est \u00e7a le but, c\u2019est de rendre l\u2019infrastructure et le site plus\u00a0fiables.</p><p><strong>[00:11:47.240]\u200a\u2014\u200aSt\u00e9phane\u00a0: </strong>Je reviens sur ce que tu disais tout \u00e0 l\u2019heure, Vincent. Tu as fait la diff\u00e9rence entre SRE et SRE Proxy. Est-ce que justement, cette proximit\u00e9 s\u2019apparente \u00e0\u2026\u00a0?</p><p><strong>[00:11:57.190]\u200a\u2014\u200aVincent\u00a0: </strong>C\u2019est \u00e7a. Chez Deezer, on a s\u00e9par\u00e9 deux r\u00f4les qui sont normalement assez li\u00e9s. Typiquement, comme le disait Lo\u00efc tout \u00e0 l\u2019heure, on est issu, lui et moi, du monde du d\u00e9v. On est plus proche des \u00e9quipes de d\u00e9veloppement, avec une app\u00e9tence pour tout ce qui est syst\u00e8me et tout ce qui est installation, mais c\u2019est vrai que l\u2019on ne vient pas forc\u00e9ment de l\u2019ops. En \u00e7a, on retrouve un peu la d\u00e9marche de Ben Treynor Sloss quand il a mis en place son \u00e9quipe SRE chez Google il y a une vingtaine d\u2019ann\u00e9es. Nous, on est plut\u00f4t orient\u00e9 d\u00e9v et on n\u2019a pas forc\u00e9ment vocation \u00e0 s\u2019occuper de la plateforme, \u00e0 \u00eatre d\u2019astreinte par exemples\u200a\u2014\u200ales SRE, normalement, ont cette notion d\u2019astreinte. On a plus cet objectif d\u2019\u00eatre proche des \u00e9quipes. Lo\u00efc et moi sommes normalement rattach\u00e9s \u00e0 certaines \u00e9quipes en particulier, pour justement comprendre leurs probl\u00e9matiques, essayer de discuter avec eux, leur amener l\u2019\u00e9vang\u00e9lisation autour de tous les principes du SRE\u200a\u2014\u200al\u2019observabilit\u00e9, la d\u00e9livrabilit\u00e9, etc.\u200a\u2014\u200al\u00e0 o\u00f9 pour l\u2019instant, c\u00f4t\u00e9 SRE, ils ont aussi en charge la plateforme\u200a\u2014\u200adonc la mise \u00e0 disposition de la plateforme\u200a\u2014\u200atout en n\u2019\u00e9tant pas compl\u00e8tement \u00e9loign\u00e9s des d\u00e9veloppeurs. Voil\u00e0, on fait un peu ce pont \u00e0 l\u2019heure actuelle.</p><p><strong>[00:13:12.450]\u200a\u2014\u200aDenis\u00a0: </strong>Oui, dans l\u2019\u00e9quipe dans laquelle je travaille, on est vraiment tr\u00e8s proche des serveurs, tr\u00e8s proche des stacks de bases de donn\u00e9es ou des middlewares, et on s\u2019apparente probablement plus \u00e0 ce que l\u2019on appellerait aujourd\u2019hui une \u00e9quipe \u201cplatform\u201d, m\u00eame si ce sont des labels que l\u2019on colle sur des gens. Mais si certains d\u2019entre vous ont lu le livre <em>\u201cTeam Topologies\u201d</em>, \u00e7a serait plus une \u00e9quipe platform, m\u00eame si je me sens totalement SRE comme mes deux coll\u00e8gues. Eux sont peut-\u00eatre plus ce que l\u2019on appelle des SRE au jour le\u00a0jour.</p><p><strong>[00:13:44.050]\u200a\u2014\u200aVincent\u00a0: </strong>Voil\u00e0, dans <em>\u201cTeam Topologies\u201d</em>, on serait les \u201cEnablers\u201d.</p><p><strong>[00:13:46.500]\u200a\u2014\u200aDenis\u00a0: </strong>Oui, les \u201cEnablers\u201d, exactement.</p><p><strong>[00:13:57.530]\u200a\u2014\u200aSt\u00e9phane\u00a0: </strong>Quels outils utilise-t-on chez Deezer pour r\u00e9aliser cette mission\u00a0?</p><p><strong>[00:14:01.430]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> Il y en a plein. Il y a plein d\u2019objectifs. Je pense qu\u2019il faut d\u00e9couper en diff\u00e9rents objectifs. On a parl\u00e9 de fiabilit\u00e9, on a donc besoin d\u2019outils pour pouvoir mesurer cette fiabilit\u00e9. Dans les outils que l\u2019on a, il va y avoir des stacks de monitoring par exemple, o\u00f9 l\u2019on va mettre en place les outils n\u00e9cessaires pour que les \u00e9quipes, quand elles produisent un logiciel, soient en mesure de savoir si ce logiciel fonctionne correctement, de remonter des statistiques, des logs, des outils comme \u00e7a. Si je donne deux ou trois noms, \u00e0 Deezer, on utilise un truc qui s\u2019appelle Prometheus pour tout ce qui est remont\u00e9 de m\u00e9triques, et on utilise la traditionnelle stack ELK\u200a\u2014\u200aun peu tweaked on va dire\u200a\u2014\u200apour la remont\u00e9e de logs. Et apr\u00e8s, l\u00e0 o\u00f9 le r\u00f4le des SRE devient important, c\u2019est sur le comment on utilise ces outils. Parce que les outils sont mis en place, comme le disait Denis, par l\u2019\u00e9quipe \u201cplatform\u201d, les outils sont disponibles. Mais il ne s\u2019agit pas juste d\u2019envoyer des logs et puis c\u2019est bon. Il faut les monitorer. Il faut envoyer les bons logs, il faut les monitorer de la bonne mani\u00e8re, il faut potentiellement mettre en place de l\u2019alerting pour \u00eatre au courant quand il y a un probl\u00e8me. Pour du log, \u00e7a peut \u00eatre d\u00e9tect\u00e9 quand un log en particulier arrive. Par exemple, si l\u2019on g\u00e8re une plateforme de paiement, on peut peut-\u00eatre avoir le nombre de paiements refus\u00e9s et \u00eatre notifi\u00e9 si ce nombre de paiements refus\u00e9s augmente significativement pendant une courte p\u00e9riode de temps. C\u2019est l\u00e0 o\u00f9 l\u2019on va se rendre compte qu\u2019apr\u00e8s on va avoir plein d\u2019autres questions. L\u2019exemple que je viens de vous donner est un exemple tr\u00e8s fonctionnel, c\u2019est tr\u00e8s produit. On a un produit\u00a0: c\u2019est faire du paiement. On a besoin de savoir si ce produit fonctionne pour faire du paiement. Mais l\u00e0 o\u00f9 les \u00e9quipes vont avoir parfois des questions beaucoup plus techniques\u200a\u2014\u200aavant m\u00eame de savoir si le service fait du paiement correctement, il faut d\u00e9j\u00e0 savoir si le service r\u00e9pond, par exemple, aux requ\u00eates qu\u2019on lui envoie. Donc on va aussi avoir besoin de monitorer les temps d\u2019acc\u00e8s, le nombre d\u2019acc\u00e8s, les temps de r\u00e9ponse\u2026 Et l\u2019id\u00e9e, c\u2019est que nous, on arrive avec tout un tas d\u2019\u00e9l\u00e9ments de base qu\u2019on va donner aux \u00e9quipes pour qu\u2019elles les suivent, de mani\u00e8re \u00e0 ce qu\u2019elles aient, presque cl\u00e9 en main, un jeu d\u2019outils pr\u00eats \u00e0 monitorer une application. Donc une \u00e9quipe, demain, quand elle cr\u00e9e un nouveau service en interne, une nouvelle application, saura qu\u2019il faut mesurer\u2026 On fait beaucoup de web services, donc \u00e7a veut dire mesurer le nombre d\u2019appels HTTP, mesurer le temps de r\u00e9ponse, le nombre d\u2019appels par retour HTTP, notamment le nombre d\u2019erreurs, etc. On en parlera peut-\u00eatre apr\u00e8s, mais tout cela est d\u00e9ploy\u00e9 sur une plateforme Kubernetes, donc il faut aussi mesurer comment \u00e7a fonctionne sur la plateforme en elle-m\u00eame\u200a\u2014\u200acombien de nodes sont op\u00e9rationnels, combien ont eu des crashs, etc. Notre objectif, c\u2019est de fournir une esp\u00e8ce de base qui, une fois qu\u2019elle est remplie, permet d\u2019avoir une sorte d\u2019\u00e9tat des lieux d\u2019une application satisfaisant pour pouvoir dire si cette application est op\u00e9rationnelle ou non, et dans le temps, est-ce qu\u2019elle a \u00e9t\u00e9 op\u00e9rationnelle ou non de mani\u00e8re satisfaisante aussi. Parce qu\u2019une application, \u00e7a vit. Les d\u00e9veloppeurs travaillent dessus et il y a des moments o\u00f9 elle peut tr\u00e8s bien fonctionner, puis des moments o\u00f9 les d\u00e9veloppeurs vont faire beaucoup de changements et elle fonctionnera moins bien. C\u2019est int\u00e9ressant de le savoir et de savoir r\u00e9agir en cons\u00e9quence.</p><p><strong>[00:17:28.840]\u200a\u2014\u200aDenis\u00a0: </strong>C\u2019est super parce que tu introduis un autre point hyper important de la th\u00e9orie du SRE, l\u2019un des piliers du Site Reliability Engineering\u00a0: c\u2019est le fait que\u200a\u2014\u200aet c\u2019est aussi pr\u00e9sent dans DevOps\u200a\u2014\u200ales incidents, \u00e7a arrive et c\u2019est normal. Et comme c\u2019est normal et comme on sait que \u00e7a va arriver, il faut d\u00e9terminer pour chacun de nos services\u200a\u2014\u200aun service, \u00e7a va \u00eatre un petit bout de logiciel, tu parlais du paiement tout \u00e0 l\u2019heure\u200a\u2014\u200apour chacune de ces briques logicielles qui composent notre produit, \u00e0 partir de quand les utilisateurs vont d\u00e9terminer que le service fonctionne mal. C\u2019est le truc que j\u2019ai eu le plus de mal \u00e0 accepter quand je suis devenu SRE. C\u2019est le fait que \u00e7a ne sert \u00e0 rien de faire une plateforme la plus solide possible, qui ne plantera jamais, parce qu\u2019elle finira toujours par planter. Il y aura toujours un moment o\u00f9 vous n\u2019aurez pas pr\u00e9vu le truc, etc. \u00c7a va planter. Et donc, tout ce temps d\u2019ing\u00e9nierie que l\u2019on va mettre \u00e0 essayer de fiabiliser un syst\u00e8me qui, de toute fa\u00e7on, finira par planter, c\u2019est du temps perdu. C\u2019est de la fonctionnalit\u00e9 que vous ne pouvez pas donner \u00e0 vos utilisateurs. Et en l\u2019occurrence, l\u00e0, mes utilisateurs ne sont pas les utilisateurs finaux, ce sont les d\u00e9veloppeurs. Une fois que l\u2019on a dit \u00e7a, il faut que l\u2019on prenne le probl\u00e8me \u00e0 l\u2019envers. \u00c0 partir de quand mes utilisateurs d\u00e9cident-ils que le service ne marche pas bien\u00a0? En vrai, les utilisateurs peuvent \u00eatre assez tol\u00e9rants, plus qu\u2019on ne le croit. Parce que moi, si je me connecte \u00e0 Deezer sur mon t\u00e9l\u00e9phone portable et que Deezer plante, je vais me demander\u00a0: \u201cEst-ce que c\u2019est mon smartphone qui bugue\u00a0? Est-ce que c\u2019est l\u2019appli qui bugue\u00a0? Est-ce que c\u2019est la 4G qui bugue\u00a0? Ou est-ce qu\u2019il y a vraiment un souci sur l\u2019appli Deezer elle-m\u00eame ou sur le site\u00a0?\u201d Le temps que je me pose cette question, si le service a d\u00e9j\u00e0 \u00e9t\u00e9 r\u00e9tabli, je m\u2019en fiche en tant qu\u2019utilisateur. Si jamais j\u2019ai pass\u00e9 trop de temps \u00e0 fiabiliser ce syst\u00e8me, c\u2019est du temps que je n\u2019ai pas pass\u00e9 \u00e0 faire autre chose, \u00e0 permettre \u00e0 mes d\u00e9veloppeurs d\u2019aller plus vite, \u00e0 permettre de sortir de nouvelles fonctionnalit\u00e9s, des trucs qui sont diff\u00e9renciants, qui vont faire que du c\u00f4t\u00e9 de la concurrence, ils vont \u00eatre compl\u00e8tement largu\u00e9s et que les utilisateurs vont pr\u00e9f\u00e9rer notre produit. Donc, en fait, pour ceux qui connaissent un petit peu le Joueur Du Grenier\u200a\u2014\u200apeut-\u00eatre que parmi nos auditeurs, il y en a certains qui le connaissent\u200a\u2014\u200a\u00eatre SRE, finalement, c\u2019est un petit peu le David Goodenough de l\u2019infrastructure. On essaye de faire <em>juste</em> bien. Et j\u2019en arrive \u00e0 mes m\u00e9triques dont on parlait tout \u00e0 l\u2019heure\u200a\u2014\u200ad\u00e9sol\u00e9, c\u2019\u00e9tait un petit peu long\u200a\u2014\u200apour chacun de mes services, je vais d\u00e9terminer \u00e0 partir de quand mes utilisateurs ne sont pas contents. \u00c7a va \u00eatre une m\u00e9trique, je vais me fixer un objectif dessus. Si je veux que 99 % des requ\u00eates r\u00e9pondent en moins de 40 millisecondes sur une p\u00e9riode de temps donn\u00e9\u200a\u2014\u200ace que l\u2019on fait assez r\u00e9guli\u00e8rement\u200a\u2014\u200a\u00e7a veut dire qu\u2019il y a 1% des requ\u00eates qui peuvent \u00e9chouer, et ce n\u2019est pas grave. \u00c7a va \u00eatre ce que l\u2019on appelle notre \u201cerror budget\u201d. On prend le probl\u00e8me \u00e0 l\u2019envers en fait, c\u2019est-\u00e0-dire qu\u2019au lieu d\u2019essayer de viser un niveau de disponibilit\u00e9, on vise un niveau d\u2019indisponibilit\u00e9. \u00c0 partir de l\u00e0, \u00e7a va \u00eatre super int\u00e9ressant parce que \u00e7a va nous permettre de faire tout un tas de choses dont on se privait avant. On va pouvoir faire des tests dangereux, on va pouvoir faire des maintenances qui vont provoquer des interruptions. Mais tout \u00e7a, ce n\u2019est pas grave parce que si \u00e7a casse, tant que l\u2019on est dans notre error budget, tant qu\u2019on ne l\u2019a pas cram\u00e9, \u00e7a veut dire que nos utilisateurs ne sont pas m\u00e9contents. Donc ils sont contents.</p><p><strong>[00:20:34.990]\u200a\u2014\u200aVincent\u00a0: </strong>Je pense que c\u2019est un truc sur lequel on essaie de sensibiliser les personnes du Produit\u00a0: tant que l\u2019on est dans notre error budget\u200a\u2014\u200ace que tu dis\u200a\u2014\u200aon peut casser des choses, on peut tenter des trucs, on peut innover m\u00eame. C\u2019est-\u00e0-dire que quand une feature doit sortir, tant que l\u2019on reste dans cet error budget, on peut se permettre de faire des choses. Apr\u00e8s, cet error budget est plus ou moins grand selon la criticit\u00e9 de l\u2019application, de la feature, etc., \u00e9videmment, mais on peut innover. Par contre, d\u00e8s que l\u2019on d\u00e9passe cet error budget, c\u2019est l\u00e0 que l\u2019on vient dire\u00a0: \u201cOK, on a d\u00e9pass\u00e9 notre tampon, donc maintenant il faut fiabiliser le service.\u201d Et c\u2019est l\u00e0 qu\u2019on peut avoir une discussion directement avec des personnes du Produit par exemple. C\u2019est toujours un peu compliqu\u00e9 d\u2019avoir des discussions entre Tech et Product, parce que l\u2019on n\u2019a pas forc\u00e9ment les m\u00eames enjeux, surtout quand on est c\u00f4t\u00e9 plateforme. L\u00e0, on peut leur dire clairement\u200a\u2014\u200ac\u2019est m\u00eame quelque chose que l\u2019on n\u00e9gocie avec eux, c\u2019est-\u00e0-dire que quand on va les voir, on leur dit\u2026 \u00c7a m\u2019est d\u00e9j\u00e0 arriv\u00e9, sur certains projets, de dire\u00a0: \u201c\u00c9coute, on va mettre en place un certain nombre d\u2019indicateurs. Dis-moi, toi\u200a\u2014\u200ace que tu disais, en fait, Denis\u200a\u2014\u200adis-moi, toi, \u00e0 partir de quand on consid\u00e8re que la feature est vraiment dysfonctionnelle\u00a0? Et on se rend compte que parfois, et j\u2019\u00e9tais m\u00eame tr\u00e8s surpris, sur certains projets, de me dire\u00a0: \u201cInstinctivement, je me serais mis un objectif vraiment tr\u00e8s haut par rapport \u00e0 ce que le Produit attend.\u201d Parce que l\u2019on est sur une feature qui n\u2019est pas forc\u00e9ment tr\u00e8s attendue ou parce que l\u2019on est sur le d\u00e9but, on est sur un POC, donc on peut se permettre de rater, on est sur une b\u00eata, etc. Il y a plein de raisons qui peuvent faire que l\u2019on ne se mette pas des objectifs tr\u00e8s compliqu\u00e9s. \u00c7a m\u2019est arriv\u00e9 d\u2019avoir un objectif o\u00f9 j\u2019avais mis un 9, c\u2019est-\u00e0-dire avoir 90% de disponibilit\u00e9\u200a\u2014\u200adonc 10% potentiel d\u2019indisponibilit\u00e9\u200a\u2014\u200ajuste parce que c\u2019\u00e9tait une future qui \u00e9tait, au lancement, pas critique. Et moi, j\u2019\u00e9tais parti sur un 99 ou un 99,9. C\u2019est aussi l\u2019int\u00e9r\u00eat de ce genre de m\u00e9trique, de pouvoir justement \u00e9changer avec des gens du Produit et de se dire\u00a0: \u201cC\u2019est quoi un service qui marche\u00a0? C\u2019est quoi un service qui ne marche pas\u00a0?\u201d Ce n\u2019est pas juste\u00a0: \u201cMon service doit r\u00e9pondre en moins de 100 millisecondes\u201d. Non, c\u2019est\u00a0: \u201cDis-moi ce que tu attends de la feature et de la plateforme. Et derri\u00e8re, on le d\u00e9cline en choses un peu plus \u201ctechniques\u201d, de savoir en combien de temps doit r\u00e9pondre le service, quel est le taux d\u2019erreur que l\u2019on peut accepter, etc.</p><p><strong>[00:22:43.060]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> Si on reprend l\u2019exemple, on peut tr\u00e8s bien imaginer mettre des budgets d\u2019erreur totalement diff\u00e9rents. Sur le paiement, par exemple, on pourrait se dire que \u00e7a reste important. On va mettre un budget d\u2019erreur assez faible et peut-\u00eatre que, comme le dit Vincent, sur une fonctionnalit\u00e9 exp\u00e9rimentale, voire une fonctionnalit\u00e9 que seulement 5% des utilisateurs utilisent, on va \u00eatre plus tol\u00e9rants. \u00c7a permet de varier, et de mani\u00e8re indirecte, \u00e7a permet aussi de varier le co\u00fbt. Parce que rendre fiable \u00e0 100% quoi que ce soit, \u00e7a a un co\u00fbt th\u00e9oriquement infini. \u00c0 un moment donn\u00e9, il faut r\u00e9duire ce co\u00fbt \u00e0 quelque chose qui est soutenable pour l\u2019entreprise ou l\u2019entit\u00e9 qui produit le logiciel. \u00c7a permet de faire varier ce co\u00fbt et parfois, on peut aussi prendre des d\u00e9cisions qui ne sont, certes, pas en faveur de l\u2019utilisateur. Je vais prendre un exemple un petit peu extr\u00eame. Je suis des blogueurs qui h\u00e9bergent leurs blogs sur des Raspberry Pi aliment\u00e9s par des panneaux solaires et dans leur budget d\u2019erreur, c\u2019est\u00a0: pas de soleil, pas de blog. Certes, l\u2019utilisateur final n\u2019est pas content parce qu\u2019il n\u2019y a pas de soleil, il ne peut pas acc\u00e9der au blog. Mais c\u2019est consid\u00e9r\u00e9 comme acceptable parce que l\u2019on a fait varier les co\u00fbts\u200a\u2014\u200al\u00e0, c\u2019est un co\u00fbt \u00e9nerg\u00e9tique direct\u200a\u2014\u200apour dire\u00a0: \u201cJe n\u2019ai pas de quoi assurer ou je ne souhaite pas\u200a\u2014\u200aparce que c\u2019est un souhait plus qu\u2019une possibilit\u00e9\u200a\u2014\u200aassurer la disponibilit\u00e9 du service au-del\u00e0 d\u2019un certain co\u00fbt.\u201d Du coup, \u00e7a coupe. Sans forc\u00e9ment aller jusqu\u2019\u00e0 cet extr\u00eame\u200a\u2014\u200aparce que l\u00e0, on parle de blogs souvent libristes qui sont plus anecdotiques\u200a\u2014\u200apour un service donn\u00e9, \u00e7a peut tr\u00e8s bien se faire. Si on reprend l\u2019exemple \u00e9nerg\u00e9tique, l\u2019ann\u00e9e derni\u00e8re, il y a eu des tensions \u00e9nerg\u00e9tiques, notamment en France et en Europe. On peut tr\u00e8s bien se dire que l\u2019on change ses budgets d\u2019erreur pendant cette p\u00e9riode sur certains aspects pour conserver une partie de l\u2019\u00e9nergie\u200a\u2014\u200ace qui permet de couper des serveurs. Mais de mani\u00e8re indirecte, couper des serveurs, c\u2019est r\u00e9duire la fiabilit\u00e9 globale.</p><p><strong>[00:24:51.550]\u200a\u2014\u200aPauline\u00a0: </strong>On a \u00e9voqu\u00e9 diff\u00e9rents concepts SRE\u00a0: on a parl\u00e9 de budget d\u2019erreur, on a parl\u00e9 d\u2019automatisation des t\u00e2ches r\u00e9p\u00e9titives. Est-ce qu\u2019il y a d\u2019autres concepts qui sont propres au SRE\u00a0?</p><p><strong>[00:25:06.680]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>L\u2019un des principes que l\u2019on pousse \u00e0 Deezer\u200a\u2014\u200aet je ne saurais pas dire si c\u2019est intrins\u00e8que au SRE ou pas\u200a\u2014\u200ac\u2019est l\u2019autonomisation des d\u00e9veloppeurs\u00a0: le fait qu\u2019un d\u00e9veloppeur ait de moins en moins\u200a\u2014\u200avoire plus du tout\u200a\u2014\u200abesoin d\u2019une personne avec \u00e0 la fois des privil\u00e8ges d\u2019autorisation et des connaissances techniques diff\u00e9rentes des siennes\u200a\u2014\u200adonc principalement des Ops g\u00e9n\u00e9ralement\u200a\u2014\u200apour faire \u00e9voluer, d\u00e9ployer, cr\u00e9er, tester\u2026 Et pour \u00e7a, on a besoin d\u2019outils. Pour permettre cette autonomisation, on peut parler de Kubernetes, on peut parler de Docker notamment. Pour faire simple, il y a quelques ann\u00e9es, ce qu\u2019un d\u00e9veloppeur livrait, c\u2019\u00e9tait du code source, peut- \u00eatre parfois du binaire, mais bien souvent, l\u2019objectif \u00e9tait de livrer une version d\u2019un code source qui allait \u00eatre build\u00e9 dans une CI (Continuous Integration), qui allait donc construire un build qui allait souvent \u00eatre d\u00e9ploy\u00e9 par des Ops justement. On a un petit peu chang\u00e9 \u00e7a depuis quelques ann\u00e9es. Le livrable est pass\u00e9 de code \u00e0 une image Docker. L\u2019int\u00e9r\u00eat de changer \u00e7a, c\u2019est que l\u2019image Docker vient \u00e0 la fois avec le code ou le binaire, et une partie de l\u2019infrastructure. Et il y avait notamment beaucoup de conflits. Nous, \u00e0 Deezer, on est en PHP, donc les conflits les plus fr\u00e9quents \u00e9taient par exemple\u00a0: \u201csur mon environnement de d\u00e9veloppement, j\u2019ai tel module qui est install\u00e9 sur PHP, j\u2019ai telle version de PHP, et en production pas du tout\u201d, \u201cje n\u2019ai pas le module GD, il n\u2019\u00e9tait pas install\u00e9 en production\u201d ou \u201cce n\u2019\u00e9tait pas la bonne version\u201d. Du coup, j\u2019avais des probl\u00e9matiques de bugs qui \u00e9taient relativement fr\u00e9quentes parce qu\u2019il y avait des divergences entre mes environnements de production et de d\u00e9veloppement. Docker permet de r\u00e9soudre beaucoup de ces probl\u00e8mes-l\u00e0 parce que maintenant, ce que je donne \u00e0 livrer contient toutes ces d\u00e9pendances ou une grande partie de ces d\u00e9pendances. Mais pour pouvoir faire \u00e7a, il y a eu besoin de d\u00e9ployer ces containers, ces images Docker, en production. Et c\u2019est l\u00e0 o\u00f9 Kubernetes notamment\u200a\u2014\u200aqui, maintenant, est quand m\u00eame la r\u00e9ponse h\u00e9g\u00e9monique \u00e0 cette probl\u00e9matique d\u2019orchestration d\u2019images Docker\u200a\u2014\u200aest venue r\u00e9soudre, mettre une interface technique entre les Ops qui vont fournir la plateforme\u200a\u2014\u200aplateforme qui rend le service de d\u00e9ployer des containers\u200a\u2014\u200aet les d\u00e9veloppeurs qui vont \u00eatre capables d\u2019appeler cette plateforme, de l\u2019utiliser pour pouvoir d\u00e9ployer des containers. Et \u00e7a va notamment leur permettre de d\u00e9ployer des containers sur des applications qu\u2019ils connaissent, mais potentiellement des nouvelles applications aussi pour pouvoir faire des tests, pour tester des nouvelles fonctionnalit\u00e9s, pour tester des nouveaux \u00e9l\u00e9ments techniques, peu importe. \u00c7a permet d\u2019avoir un langage qui est \u00e0 la fois technique et presque \u201chumain\u201d. On va parler beaucoup de containers, de tous les langages qui sont autour de Kubernetes, entre les Ops et les D\u00e9vs. Il y a des D\u00e9vs qui vont avoir la capacit\u00e9 de quasiment tout faire tous seuls. Et quand il y a besoin de discuter avec des Ops parce qu\u2019il y a des trucs qui n\u00e9cessitent plus de compr\u00e9hension ou des trucs un peu exotiques, il y aura un langage qui permettra de discuter, qui sera beaucoup plus standardis\u00e9\u200a\u2014\u200astandardis\u00e9, parce que techniquement mis en place dans un logiciel.</p><p><strong>[00:28:25.020]\u200a\u2014\u200aDenis\u00a0: </strong>Ce que j\u2019ai trouv\u00e9 vraiment int\u00e9ressant avec l\u2019arriv\u00e9e de Docker\u200a\u2014\u200aparce que tu en parles\u200a\u2014\u200ac\u2019est que c\u2019est vraiment l\u2019outil, je pense, qui a le plus aid\u00e9 les d\u00e9veloppeurs \u00e0 faire, avec du code, de l\u2019infra. Parce que finalement, le Dockerfile\u200a\u2014\u200adonc le fichier que livre le d\u00e9veloppeur\u200a\u2014\u200aqu\u2019est-ce que c\u2019est\u00a0? C\u2019est un fichier texte qui dit\u00a0: \u201cQu\u2019est-ce que je veux comme d\u00e9pendance\u00a0? O\u00f9 est-ce que je mets le binaire qui a \u00e9t\u00e9 construit par ma CI\u00a0? Comment je package tout \u00e7a\u200a\u2014\u200adonc le binaire et ses d\u00e9pendances ou le code et ses d\u00e9pendances, peu importe\u200a\u2014\u200aet comment je l\u2019envoie en production\u00a0?\u201d \u00c7a, c\u2019\u00e9tait vraiment la premi\u00e8re \u00e9tape. Il y avait d\u2019autres outils pour faire de l\u2019infrastructure as code avant Docker, mais pas vraiment utilis\u00e9s, en tout cas pas de mani\u00e8re h\u00e9g\u00e9monique par les d\u00e9veloppeurs. Docker est arriv\u00e9 autour de 2014, si je ne dis pas de b\u00eatises, et a vraiment chang\u00e9 radicalement la fa\u00e7on dont les D\u00e9vs ont vu l\u2019infrastructure. D\u2019un coup, d\u2019un seul, ils n\u2019avaient plus besoin de demander\u200a\u2014\u200aparce que \u00e7a aussi, je l\u2019ai v\u00e9cu\u200a\u2014\u200aun serveur web qui mettait trois semaines \u00e0 \u00eatre livr\u00e9 par les Ops. Et le temps que les Ops livrent le serveur web dans leur catalogue de templates, la version \u00e9tait d\u00e9j\u00e0 obsol\u00e8te. Donc \u00e7a, c\u2019\u00e9tait fini, les d\u00e9veloppeurs avaient la main l\u00e0-dessus. Le probl\u00e8me, c\u2019est que les Ops, pendant un moment\u200a\u2014\u200amoi compris\u200a\u2014\u200aont voulu mettre un coup de frein parce que derri\u00e8re, qu\u2019est-ce qu\u2019on en fait de ce container\u00a0? C\u2019est pour \u00e7a que des outils comme Kubernetes sont arriv\u00e9s, comme tu le citais. Et l\u00e0, on va encore plus loin dans la description de l\u2019infrastructure. Non seulement, on d\u00e9crit avec le Dockerfile l\u2019appli et son environnement d\u2019ex\u00e9cution, mais avec Kubernetes, on va beaucoup plus loin. On va d\u00e9ployer, on va d\u00e9crire des load balancers, des reverse proxies, des disques, des r\u00e9plicas\u200a\u2014\u200acombien je veux en envoyer. Tout \u00e7a est g\u00e9r\u00e9 par des API. C\u2019est manipul\u00e9 avec du YAML\u200a\u2014\u200aon peut dire ce qu\u2019on veut sur le YAML ou pas, mais il y a quelque chose de magique dans le fait de monter toute une infrastructure avec quelques dizaines ou quelques centaines de lignes de YAML. Pour quelqu\u2019un qui vient du monde de l\u2019infra, pour moi, c\u2019est vraiment magique. C\u2019est un truc incroyable\u00a0! \u00c7a g\u00e8re la haute dispo automatiquement\u2026 Donc, Kubernetes, c\u2019est vraiment\u00a0: donner la main, les cl\u00e9s du camion, de l\u2019infrastructure aux d\u00e9veloppeurs. \u00c7a vient avec d\u2019autres contraintes parce que les bonnes pratiques de s\u00e9curit\u00e9, les bonnes pratiques de fiabilit\u00e9 que les Ops avaient, les d\u00e9veloppeurs ne les ont pas forc\u00e9ment. Donc si on leur donne de l\u2019autonomie, il faut aussi soit les \u00e9duquer, soit les guider. Et on en revient encore au r\u00f4le d\u2019\u00e9vang\u00e9liste du SRE. Il est l\u00e0 pour apporter toutes ces bonnes pratiques que n\u2019ont pas forc\u00e9ment des d\u00e9veloppeurs parce que ce n\u2019est pas leur m\u00e9tier, parce qu\u2019ils n\u2019ont pas besoin de savoir tout non plus et ils n\u2019ont pas forc\u00e9ment int\u00e9r\u00eat d\u2019ailleurs\u200a\u2014\u200ail vaut mieux \u00eatre bon en un seul domaine que nul en tout, c\u2019est quand m\u00eame mieux\u00a0! Donc Kubernetes est vraiment l\u2019outil qui va nous permettre de donner de l\u2019autonomie aux d\u00e9veloppeurs. \u00c7a ne fait pas tout. Il y a encore des fois o\u00f9 les gens de l\u2019infra\u200a\u2014\u200aou \u201cplatform\u201d, peu importe comment on l\u2019appelle\u200a\u2014\u200asont sur le chemin critique. R\u00e9cemment, avec des coll\u00e8gues, on a fait un atelier Mikado o\u00f9 l\u2019on a essay\u00e9 de prendre toutes les t\u00e2ches qu\u2019il fallait pour cr\u00e9er une nouvelle application en tant que d\u00e9veloppeur, en se pla\u00e7ant dans le contexte le plus d\u00e9favorable possible. Toutes les t\u00e2ches que l\u2019on a vues, qui sont potentiellement pour certaines avec l\u2019infrastructure sur le chemin critique, qui ralentissent la v\u00e9locit\u00e9 des d\u00e9veloppeurs, on a essay\u00e9 de les automatiser, de les r\u00e9duire, de les rendre plus simples, de mani\u00e8re \u00e0 donner encore plus d\u2019autonomie aux d\u00e9veloppeurs. Et plus on leur donne d\u2019autonomie, moins on passe de temps \u00e0 travailler l\u00e0-dessus. C\u2019est plus de temps pour mettre en place d\u2019autres outillages, pour justement s\u2019assurer que les bonnes pratiques, par exemple, sont respect\u00e9es\u200a\u2014\u200anotamment les bonnes pratiques de s\u00e9curit\u00e9, avec de l\u2019outillage qui va v\u00e9rifier que les conteneurs ne tournent pas avec des privil\u00e8ges trop importants, que l\u2019infrastructure qui est d\u00e9ploy\u00e9e avec le YAML dans Kubernetes correspond bien \u00e0 nos standards\u2026 Finalement, c\u2019est un cercle vertueux. Le SRE est vraiment dans cette optique de ne pas perdre du temps sur des choses qui n\u2019ont pas de valeur et de passer justement le plus de temps possible pour d\u00e9livrer de la valeur pour les d\u00e9veloppeurs.</p><p><strong>[00:32:29.260]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Et les pratiques qu\u2019avaient les Ops, notamment quand on parle de s\u00e9curit\u00e9, c\u2019est quand m\u00eame un truc assez fondamental dans les \u00e9quipes Ops de g\u00e9rer la s\u00e9curit\u00e9 d\u2019un service, ce n\u2019est pas quelque chose qui est facile \u00e0 faire et en plus, c\u2019est quelque chose qui change du jour au lendemain parce qu\u2019il y a des informations qui sont r\u00e9v\u00e9l\u00e9es parfois, qui n\u00e9cessitent des op\u00e9rations cons\u00e9quentes sur beaucoup d\u2019aspects de l\u2019infrastructure. On peut penser aux failles Heartbleed et compagnie, ou \u00e0 la plus importante peut-\u00eatre r\u00e9cemment, Log4j, qui a n\u00e9cessit\u00e9 que les Ops et les D\u00e9veloppeurs se parlent et se synchronisent pour se d\u00e9barrasser de cette vuln\u00e9rabilit\u00e9.</p><p><strong>[00:33:09.180]\u200a\u2014\u200aDenis\u00a0: </strong>Qui \u00e9tait pr\u00e9sente quasiment partout.</p><p><strong>[00:33:10.610]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Oui, qui \u00e9tait vraiment \u00e0 tous les \u00e9tages, m\u00eame si on n\u2019utilisait pas de Java. \u00c7a permet notamment d\u2019am\u00e9liorer la qualit\u00e9 de la s\u00e9curit\u00e9 en soi. Parce qu\u2019encore une fois, les outils que l\u2019on met en place sont automatis\u00e9s et vont se mettre, de mani\u00e8re un petit peu \u201cfroide\u201d, \u00e0 tout analyser. L\u00e0 o\u00f9 avant un op\u00e9rationnel maintenait ses serveurs \u00e0 jour, s\u2019assurait de la s\u00e9curit\u00e9 et regardait, presque \u00e0 l\u2019\u0153il nu, l\u2019\u00e9tat de sa plateforme en termes de s\u00e9curit\u00e9, maintenant on a des robots qui passent et qui, \u00e0 la moindre librairie qui a une CVE <em>(Common Vulnerability &amp; Exposure)</em> qui est d\u00e9clar\u00e9e quelque part\u200a\u2014\u200aune librairie Python, Node, PHP, peu importe\u200a\u2014\u200aremontent une alerte. On le sait quasiment tout de suite. Les Ops peuvent le savoir mais surtout, \u00e7a redescend quasiment directement\u200a\u2014\u200aou \u00e7a peut redescendre directement\u200a\u2014\u200ajusqu\u2019au d\u00e9veloppeur qui est concern\u00e9, qui a utilis\u00e9 cette librairie qui a une vuln\u00e9rabilit\u00e9. Le d\u00e9veloppeur peut avoir une action dessus directement, sans m\u00eame que l\u2019Ops aille s\u2019inqui\u00e9ter r\u00e9ellement du sujet. Donc on a toujours les cas un peu g\u00e9n\u00e9riques comme Log4j, qui \u00e9tait vraiment un cas exceptionnel, mais les vuln\u00e9rabilit\u00e9s de s\u00e9curit\u00e9 ne sont pas vraiment ces exceptions-l\u00e0, ce sont plut\u00f4t la myriade de vuln\u00e9rabilit\u00e9s qui ont lieu partout dans un syst\u00e8me complexe, qui sont tr\u00e8s difficilement mesurables. Et en fait, on a m\u00eame permis d\u2019am\u00e9liorer la s\u00e9curit\u00e9 l\u00e0 o\u00f9 c\u2019est contre intuitif, parce que Kubernetes, avec Docker notamment, est souvent cri\u00e9 pour son aspect non s\u00e9curitaire d\u2019un point de vue technique\u00a0: \u00e7a ouvre beaucoup de failles de s\u00e9curit\u00e9 \u00e0 plein d\u2019endroits et ce sont des critiques qui sont r\u00e9elles et justifiables\u200a\u2014\u200ajustifi\u00e9es m\u00eame\u200a\u2014\u200apour autant, \u00e7a permet de syst\u00e9matiser \u00e9norm\u00e9ment de comblements de trous de s\u00e9curit\u00e9 par ailleurs. Donc la balance finale, l\u2019apport en termes de s\u00e9curit\u00e9, est probablement plus en faveur de ces outils-l\u00e0, si trait\u00e9 convenablement et si les \u00e9quipes Ops ont le temps de mettre en place ce qui est permis par l\u2019autonomisation des d\u00e9veloppeurs\u200a\u2014\u200a\u00e7a leur permet d\u2019avoir le temps de mettre en place tous ces outils. \u00c0 la fin, je pense que l\u2019on a m\u00eame une meilleure s\u00e9curit\u00e9 de nos plateformes malgr\u00e9 la complexit\u00e9 qui, elle, est incommensurable par rapport \u00e0 ce que l\u2019on avait il y a vingt\u00a0ans.</p><p><strong>[00:35:14.920]\u200a\u2014\u200aVincent\u00a0: </strong>L\u2019enjeu est de se dire que c\u2019est de l\u2019autonomie que l\u2019on donne aux d\u00e9veloppeurs, mais par contre, c\u2019est aussi de la responsabilisation. Et du coup, il y a aussi un accompagnement. Il faut vraiment aller vers eux pour leur dire\u00a0: \u201cMaintenant, c\u2019est ton application.\u201d C\u2019est le fameux \u201cYou build it, you run it\u201d, c\u2019est-\u00e0-dire que vous cr\u00e9ez les applications, vous les d\u00e9ployez, etc. mais par contre, vous g\u00e9rez aussi les mont\u00e9es de version, ce qui tourne r\u00e9ellement en production, ce que vous envoyez avec votre application. C\u2019est aussi un changement de mindset qui n\u2019est pas toujours \u00e9vident \u00e0 faire passer. C\u2019est vrai qu\u2019il y a beaucoup de d\u00e9veloppeurs qui sont en mode\u00a0: \u201cmoi, je veux juste d\u00e9livrer ma feature, je clique sur le bouton, c\u2019est en prod.\u201d Oui, mais tout \u00e7a, ce sont des choses qu\u2019il faut prendre en compte. Apr\u00e8s, ce sont aussi des choses sur lesquelles ils ont plus de libert\u00e9. Typiquement, on parlait de mont\u00e9e de version\u200a\u2014\u200ad\u2019un framework, d\u2019un socle technique, peu importe\u200a\u2014\u200ace sont des choses sur lesquelles ils ont la main, ce qui n\u2019\u00e9tait pas le cas avant. Avant, comme le disait Denis, il fallait attendre, il fallait que le serveur soit livr\u00e9, que la bonne version de PHP, par exemple, soit dessus, avec les bons modules, etc. Avant, c\u2019\u00e9tait compliqu\u00e9, \u00e7a demandait de la synchro entre \u00e9quipes, etc. Maintenant, ce sont eux qui peuvent faire la mont\u00e9e de version dans leur coin, v\u00e9rifier que \u00e7a marche et si \u00e7a marche, ils livrent en prod et c\u2019est\u00a0fini.</p><p><strong>[00:36:29.660]\u200a\u2014\u200aSt\u00e9phane\u00a0:</strong> Je pense que vous avez commenc\u00e9 \u00e0 les dresser un peu, mais si vous deviez r\u00e9sumer, quels sont les principaux challenges que vous avez \u00e0 relever en tant que SRE et les pi\u00e8ges que vous avez \u00e0 \u00e9viter\u00a0?</p><p><strong>[00:36:50.260]\u200a\u2014\u200aVincent\u00a0:</strong> Le premier, c\u2019est vraiment le syndrome\u00a0: \u201cNon, je ne veux pas savoir comment \u00e7a tourne, je livre mon code et il faut que \u00e7a marche.\u201d C\u2019est vraiment le truc le plus compliqu\u00e9 \u00e0 bypasser dans la logique des gens. On met toujours en balance ce c\u00f4t\u00e9\u00a0: \u201cOui mais en faisant comme \u00e7a, tu auras plus de fluidit\u00e9, tu pourras livrer plus souvent et tu seras ma\u00eetre de ton truc. C\u2019est ton service, tu livres ce que tu veux, avec le socle que tu veux. Si tu veux passer en PHP+++ \u00e0 la sortie du langage, libre \u00e0 toi.\u201d Ce qui n\u2019\u00e9tait pas le cas avant. Avant, on ne sortait que sur des versions bien stabilis\u00e9es, qui \u00e9taient ma\u00eetris\u00e9es par les \u00e9quipes de la plateforme, etc. Donc le plus gros probl\u00e8me, c\u2019est vraiment \u00e7a, le \u201cmoi, \u00e7a ne m\u2019int\u00e9resse pas de savoir comment \u00e7a tourne, je livre ma feature et je veux que \u00e7a marche.\u201d Et en m\u00eame temps, quand ils avaient un probl\u00e8me en production avant, ils n\u2019\u00e9taient pas capables de l\u2019observer, ils n\u2019avaient pas de capacit\u00e9 \u00e0 suivre les r\u00e9gressions de leurs bugs, etc. Il y a beaucoup de choses qui ont \u00e9t\u00e9 apport\u00e9es par ces principes, \u00e0 la fois du DevOps et du SRE, qui nous permettent d\u2019avoir une esp\u00e8ce de levier pour dire\u00a0: \u201cOn te donne les moyens d\u2019aller plus loin et de faire ce que tu as envie de faire. \u00c7a vient avec la \u201ccontrainte\u201d avec de grands guillemets\u200a\u2014\u200apuisque ce ne sont pas non plus des contraintes de fou\u200a\u2014\u200ade suivre ce que tu envoies en production.\u201d</p><p><strong>[00:38:17.410]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> J\u2019ai tendance \u00e0 comparer \u00e7a \u00e0 une \u00e9volution de nos m\u00e9tiers. Il y a une vingtaine d\u2019ann\u00e9es, le d\u00e9veloppeur faisait tout, de l\u2019interface jusqu\u2019\u00e0 la gestion de la base de donn\u00e9es quasiment. Maintenant, on a des \u00e9quipes qui sont tr\u00e8s sp\u00e9cialis\u00e9es\u00a0: on a des d\u00e9veloppeurs front-end web, des d\u00e9veloppeurs mobile iOS / Android, des d\u00e9veloppeurs back-end, parfois on a m\u00eame des d\u00e9veloppeurs back-end Go / Python\u2026 Nos m\u00e9tiers ont \u00e9volu\u00e9. Par contre, les principes SRE sont communs \u00e0 tout le monde. On les applique de la m\u00eame mani\u00e8re pour quasiment toutes les \u00e9quipes\u200a\u2014\u200aou en tout cas, c\u2019est l\u2019objectif\u200a\u2014\u200aparce qu\u2019on veut les m\u00eames b\u00e9n\u00e9fices. Mais \u00e7a vient avec les m\u00eames inconv\u00e9nients, on va dire. Donc, effectivement, tous les corps de m\u00e9tier se sont vus avoir une \u00e9volution qui ne les concerne pas directement de prime abord, n\u00e9cessaire pour travailler dans des environnements comme celui de Deezer, pour pouvoir assurer la qualit\u00e9, la fiabilit\u00e9 et la s\u00e9curit\u00e9 notamment. Ce qui veut dire que dans une entreprise comme Deezer, qui doit g\u00e9rer une plateforme et une application tr\u00e8s complexes \u00e0 l\u2019\u00e9chelle humaine, il faut imp\u00e9rativement monter en comp\u00e9tence sur certains aspects. On parlait notamment de certains outils qui sont devenus h\u00e9g\u00e9moniques\u200a\u2014\u200aKubernetes en est un. On peut tout faire pour essayer de le rendre le plus facilement utilisable mais, comme je le disais, \u00e7a reste un langage commun avec les diff\u00e9rents niveaux d\u2019\u00e9quipes ou de personnes, et m\u00eame si l\u2019on peut faire de l\u2019abstraction, \u00e0 un moment donn\u00e9, \u00e7a restera le langage de discussion. L\u2019\u00e9quipe front-end, par exemple, va devoir d\u00e9ployer son application React, et pour la d\u00e9ployer et la rendre disponible \u00e0 des clients, \u00e0 un moment donn\u00e9, il faut la mettre sur des serveurs et il va falloir que l\u2019\u00e9quipe front-end parle avec les Ops pour dire\u00a0: \u201cO\u00f9 est-ce que je mets mon application\u00a0?\u201d \u201cTu utilises Kubernetes et tu as les outils pour le faire.\u201d \u00c7a veut dire qu\u2019il faut les apprendre, il faut les utiliser, alors m\u00eame que l\u2019on pourrait se dire qu\u2019un d\u00e9veloppeur front-end n\u2019a rien \u00e0 faire avec un serveur. Mais en fait, c\u2019est une approche qui est intrins\u00e8que \u00e0 son m\u00e9tier d\u2019aujourd\u2019hui. Certes, ce n\u2019\u00e9tait pas comme \u00e7a il y a vingt ans, maintenant, \u00e7a l\u2019est\u200a\u2014\u200aou en tout cas, \u00e7a l\u2019est dans des contextes tels que des applications comme Deezer. Ce qui veut aussi dire qu\u2019il y a des contextes qui ne n\u00e9cessitent pas tout \u00e7a. Le SRE n\u2019est\u00a0pas\u2026</p><p><strong>[00:40:35.380]\u200a\u2014\u200aDenis\u00a0: </strong>Ce n\u2019est pas une r\u00e9ponse universelle.</p><p><strong>[00:40:36.530]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Oui, voil\u00e0, c\u2019est \u00e7a. Il faut \u00e0 chaque fois l\u2019adapter et on ne peut pas mettre en place, par exemple, un Kubernetes pour une application monolithique avec cinq utilisateurs pour faire un site vitrine d\u2019une boucherie. Je pense que ce n\u2019est pas tr\u00e8s utile, pas forc\u00e9ment proportionn\u00e9. Par contre, si vous \u00eates une plateforme qui h\u00e9berge des sites web et que vous faites les sites de toutes les boucheries du monde, peut-\u00eatre que \u00e7a devient int\u00e9ressant et n\u00e9cessaire de l\u2019apprendre. J\u2019ai tendance \u00e0 comparer \u00e7a\u2026 Dans le pass\u00e9 du d\u00e9veloppeur, il y a un autre changement qui est devenu assez h\u00e9g\u00e9monique, c\u2019est celui de l\u2019utilisation de gestionnaires de code, et notamment d\u2019un gestionnaire de code en particulier. Il y a vingt ans, on uploadait nos fichiers, on avait des versions finales, des versions finales V2, etc., on envoyait tout \u00e7a par mail et par FTP. On a fait \u00e9voluer tout \u00e7a vers des gestionnaires de code comme SVN, CVS ou d\u2019autres. Aujourd\u2019hui, quoi qu\u2019on dise, il y en a un qui a gagn\u00e9, c\u2019est Git. Il est utilis\u00e9 partout et \u00e7a ne viendrait pas \u00e0 l\u2019id\u00e9e d\u2019un d\u00e9veloppeur Cobol, front-end ou PHP de dire\u00a0: \u201cNon, ce n\u2019est pas mon m\u00e9tier, je n\u2019ai pas \u00e0 apprendre Git.\u201d \u00c7a fait partie des outils. J\u2019ai besoin de conna\u00eetre un minimum Git pour pouvoir travailler en tant que d\u00e9veloppeur aujourd\u2019hui dans certains contextes. Si c\u2019est un projet perso, peut-\u00eatre que je n\u2019en ai pas besoin, mais dans le contexte professionnel, c\u2019est le\u00a0cas.</p><p><strong>[00:41:57.600]\u200a\u2014\u200aDenis\u00a0:</strong> Cet exemple est assez dr\u00f4le parce que cette critique de gens qui ne veulent pas apprendre Git, on la retrouve chez les op\u00e9rationnels, justement. Je vois un peu un parall\u00e8le\u2026 D\u2019une certaine mani\u00e8re, il y a les d\u00e9veloppeurs qui, avant, il y a tr\u00e8s longtemps, connaissaient tr\u00e8s bien l\u2019infrastructure puisque, comme tu le disais, ils \u00e9taient oblig\u00e9s de faire tout, de la cave au grenier. On s\u2019est ultra sp\u00e9cialis\u00e9. On a s\u00e9par\u00e9 les \u00e9quipes, d\u2019abord entre op\u00e9rationnels, puis apr\u00e8s d\u00e9veloppeurs. Et puis apr\u00e8s d\u00e9veloppeurs, c\u2019est devenu, comme tu dis, back-end, front-end, extr\u00eamement sp\u00e9cialis\u00e9. Du coup, parfois, il y a des d\u00e9veloppeurs\u200a\u2014\u200apas forc\u00e9ment chez Deezer\u200a\u2014\u200aqui disent\u00a0: \u201cNon, d\u00e9sol\u00e9, l\u2019infrastructure, ce n\u2019est pas mon boulot. Je n\u2019ai pas envie de savoir sur quel port tourne mon application.\u201d Au m\u00eame titre que moi, parfois, j\u2019entends aussi des op\u00e9rationnels dire\u00a0: \u201cNon, je ne vais pas apprendre Git, je ne suis pas d\u00e9veloppeur.\u201d En fait, si. On est dans un monde aujourd\u2019hui o\u00f9 savoir manier Git fait partie des comp\u00e9tences que l\u2019on attend aussi d\u2019un op\u00e9rationnel. Et \u00e0 l\u2019inverse, savoir manier les concepts basiques de l\u2019infrastructure, des cloud providers ou autre\u200a\u2014\u200aparce qu\u2019on a parl\u00e9 beaucoup de Kubernetes mais il y a d\u2019autres fa\u00e7ons de le faire\u200a\u2014\u200asont des choses qui sont aussi attendues des d\u00e9veloppeurs. Au moins de comprendre les concepts.</p><p><strong>[00:43:09.160]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> Et l\u2019\u00e9quipe SRE est l\u00e0 pour aider, en gros. On est l\u00e0 pour faire monter en comp\u00e9tence tous les d\u00e9veloppeurs ou toutes les personnes qui le souhaitent sur ces concepts-l\u00e0, de mani\u00e8re \u00e0 ce qu\u2019\u00e0 la fin, les d\u00e9veloppeurs aient les comp\u00e9tences suffisantes pour pouvoir dialoguer avec une personne Ops au sujet des outils techniques qu\u2019on utilise et des process qu\u2019on peut\u00a0avoir.</p><p><strong>[00:43:29.810]\u200a\u2014\u200aVincent\u00a0: </strong>Le mot-cl\u00e9, c\u2019est l\u2019accompagnement. \u00c0 la fois, on donne des guidelines, on essaie de donner des outils, etc. et en m\u00eame temps, il faut accompagner les gens pour les amener \u00e0 ce que l\u2019application tourne r\u00e9ellement, et faire en sorte que, petit \u00e0 petit, les \u00e9quipes soient de plus en plus autonomes pour le faire, leur donner les outils pour qu\u2019il y ait de moins en moins d\u2019adh\u00e9rence avec les \u00e9quipes plateformes, les SRE,\u00a0etc.</p><p><strong>[00:43:52.540]\u200a\u2014\u200aPauline\u00a0: </strong>Et justement, comment peut-on mesurer l\u2019impact d\u2019une \u00e9quipe SRE\u00a0?</p><p><strong>[00:43:56.920]\u200a\u2014\u200aDenis\u00a0: </strong>Si le site ne tombe pas trop souvent en panne\u00a0?</p><p><strong>[00:43:59.210]\u200a\u2014\u200aVincent\u00a0: </strong>C\u2019est \u00e7a\u00a0! Dans \u201cSRE\u201d, il y a \u201creliability\u201d.</p><p><strong>[00:44:02.070]\u200a\u2014\u200aDenis\u00a0: </strong>Au-del\u00e0 de la blague, si plus de choses sont automatis\u00e9es, si on a plus d\u2019indicateurs, si, quand le site tombe en panne, ce n\u2019est pas la panique parce que tout a \u00e9t\u00e9 document\u00e9, parce qu\u2019on a l\u2019habitude que \u00e7a tombe en panne, la fiabilit\u00e9 viendra derri\u00e8re. Mais globalement, les gens seront juste plus sereins. Alors, comment mesure-t-on le fait que les gens soient sereins\u00a0? Je ne vais pas \u00eatre capable de r\u00e9pondre\u00a0! Je ne pense pas que l\u2019on va pouvoir mettre un indicateur chiffr\u00e9. Mais comme je le disais, c\u2019est un cercle vertueux donc les choses ne font que s\u2019am\u00e9liorer si l\u2019on respecte ces principes-l\u00e0.</p><p><strong>[00:44:35.230]\u200a\u2014\u200aVincent\u00a0: </strong>Apr\u00e8s, il existe des m\u00e9triques qui essayent de montrer si l\u2019on va dans un bon sens ou pas. Ce sont les fameuses \u201c4 key metrics\u201d qui sont pouss\u00e9es par Google. Je ne vais pas forc\u00e9ment rentrer dans le d\u00e9tail maintenant parce qu\u2019on pourrait faire une \u00e9mission compl\u00e8te sur le sujet. Mais globalement, il y a des m\u00e9triques qui nous permettent de savoir si les envois en production sont fluides, le temps que \u00e7a prend et l\u2019impact que \u00e7a a quand c\u2019est mis en production, et quand il y a un incident, combien de temps il dure, en gros. \u00c0 partir de ces indicateurs-l\u00e0, on peut voir si on va dans un bon sens. Ce sont vraiment des indicateurs qui ont vocation \u00e0 \u00eatre l\u00e0 pour donner une esp\u00e8ce d\u2019\u00e9toile du Nord qu\u2019on essaie de\u00a0suivre.</p><p><strong>[00:45:11.860]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Il y a un autre indicateur qui est pas mal, qui est tr\u00e8s subjectif aussi, donc ce n\u2019est pas du tout mesurable. C\u2019est le fait que des \u00e9quipes s\u2019approprient l\u2019application sur tous les aspects. Avant, \u00e0 Deezer, quand il y avait un probl\u00e8me, comme tu le disais Denis, c\u2019\u00e9tait \u201cpanique \u00e0 bord\u201d. Et de toute fa\u00e7on, c\u2019\u00e9tait le probl\u00e8me des Ops. Donc il y avait une personne qui avait tendance \u00e0 faire un rollback ou un revert, et apr\u00e8s c\u2019\u00e9tait le probl\u00e8me des D\u00e9vs. Aujourd\u2019hui, on est pass\u00e9 \u00e0 un mode un peu diff\u00e9rent o\u00f9 les \u00e9quipes, d\u00e9j\u00e0, se rendent compte elles-m\u00eames qu\u2019il y a un probl\u00e8me parce qu\u2019il y a des alertes. On parlait de mesurer des choses et maintenant, les \u00e9quipes savent quand il y a un probl\u00e8me. Elles le savent bien souvent avant les Ops\u200a\u2014\u200ales Ops, parfois, ne le voient pas passer\u200a\u2014\u200aet elles sont capables de r\u00e9agir. Les \u00e9quipes vont, de mani\u00e8re totalement autonome, voir qu\u2019il y a un probl\u00e8me, l\u2019analyser, apporter une solution. La solution peut \u00eatre un rollback instantan\u00e9 ou \u00e7a peut \u00eatre \u201con prend le temps\u201d, justement vis-\u00e0-vis de ces questions d\u2019error budget. Parce que oui, on peut avoir un truc qui est cass\u00e9 en production, mais c\u2019est cass\u00e9 sur un petit bout\u2026 On peut prendre le temps\u200a\u2014\u200ale temps peut \u00eatre dix minutes, deux heures, \u00e7a d\u00e9pend\u200a\u2014\u200apour passer un fix, par exemple. L\u2019\u00e9quipe le fait toute seule. Il n\u2019y a plus besoin d\u2019avoir ni un SRE ni un Ops pour que l\u2019\u00e9quipe fasse tout ce travail-l\u00e0. Et on a d\u00e9j\u00e0 eu des situations o\u00f9 l\u2019on a d\u00fb dire, par exemple, aux Ops\u00a0: \u201cNon, laissez les \u00e9quipes, elles sont capables de le faire toutes seules. Vous n\u2019avez pas besoin, vous n\u2019avez plus besoin en tout cas, ni de les alerter, ni de leur mettre la pression.\u201d Parce que l\u2019\u00e9quipe va se mettre la pression qu\u2019elle doit se mettre toute seule vis-\u00e0-vis de ces notions d\u2019error budget et d\u2019indicateurs. Quelques \u00e9quipes ont \u00e9norm\u00e9ment chang\u00e9 \u00e0 Deezer, par exemple. Il y a des \u00e9quipes qui sont justement pass\u00e9es de ce mode absolument pas autonome \u00e0 compl\u00e8tement autonome. Et \u00e7a se voit dans la gestion de crise mais aussi dans la gestion de mises \u00e0 jour. On a quand m\u00eame beaucoup de PHP \u00e0 Deezer; il y a certains projets qui sont ce qu\u2019on appelle du \u201clegacy\u201d, qui sont tr\u00e8s compliqu\u00e9s \u00e0 mettre \u00e0 jour, notamment dans les mont\u00e9es de version de PHP en lui-m\u00eame et de certains grands frameworks qu\u2019on utilise, et il y a des \u00e9quipes qui sont capables de le faire toutes seules en une journ\u00e9e ou deux. Elles n\u2019ont besoin de personne. \u00c0 un moment donn\u00e9, c\u2019est\u00a0: \u201cAh, il y a une nouvelle version qui est sortie\u00a0!\u201d On communique entre nous parce qu\u2019on est dans la m\u00eame entreprise\u200a\u2014\u200ail y a un peu de fluidit\u00e9 de communication entre les \u00e9quipes\u200a\u2014\u200amais on voit tout de suite les \u00e9quipes qui ont r\u00e9ussi ce changement parce que deux jours apr\u00e8s\u00a0: \u201cOui, c\u2019est bon, on est sur la nouvelle version de PHP, \u00e7a tourne, c\u2019est en prod, il n\u2019y a pas de probl\u00e8me.\u201d Ou m\u00eame mieux\u00a0: \u201cOn a eu ce probl\u00e8me-l\u00e0, on vous le dit, n\u2019ayez pas le m\u00eame souci que nous.\u201d Et on en a quelques- unes comme \u00e7a \u00e0 Deezer maintenant.</p><p><strong>[00:47:45.260]\u200a\u2014\u200aSt\u00e9phane\u00a0: </strong>Vous avez fait une belle description du m\u00e9tier de SRE et du coup, ma question, c\u2019est\u00a0: comment devient-on SRE\u00a0?</p><p><strong>[00:47:52.900]\u200a\u2014\u200aDenis\u00a0:</strong> Si l\u2019on vient plut\u00f4t du monde op\u00e9rationnel, je pense que ce qui est important, c\u2019est d\u00e9j\u00e0 de s\u2019int\u00e9resser au code, notamment de ses d\u00e9veloppeurs. Il faut avoir cette app\u00e9tence pour le code, pour l\u2019outillage, l\u2019automatisation. Il va falloir tester, il va falloir apprendre. Il va falloir \u00eatre p\u00e9dagogue, empathique\u200a\u2014\u200aparce qu\u2019on ne rapproche pas les gens si l\u2019on n\u2019essaye pas de se mettre \u00e0 leur place. Voil\u00e0, p\u00e9dagogie, empathie, envie d\u2019apprendre et envie de transmettre. \u00c7a, c\u2019est plus pour ce qu\u2019on appelle les \u201csoft\u00a0skills\u201d.</p><p><strong>[00:48:27.940]\u200a\u2014\u200aVincent\u00a0:</strong> Quand on fait le chemin inverse, il y a beaucoup de choses qui sont un peu identiques. Comme tu le disais, il faut de l\u2019\u00e9coute, il faut de la curiosit\u00e9, il faut essayer de s\u2019int\u00e9resser \u00e0 l\u2019autre. C\u00f4t\u00e9 D\u00e9v, il faut avoir cette app\u00e9tence de vouloir savoir comment \u00e7a tourne sous le capot. C\u2019est vraiment l\u2019envie d\u2019ouvrir et de regarder, pas juste \u201cj\u2019envoie mon code et \u00e7a marche.\u201d C\u2019est \u201cOK, \u00e7a marche, mais pourquoi\u00a0?\u201d Moi qui suis un peu vieille \u00e9cole, comme vous le disiez, c\u2019\u00e9tait un peu mon mode de fonctionnement quand j\u2019ai commenc\u00e9. C\u2019est vrai que c\u2019est peut-\u00eatre moins vrai maintenant qu\u2019on se sp\u00e9cialise et je pense que c\u2019est vraiment ce crit\u00e8re-l\u00e0 qui fait qu\u2019on peut se lancer dans ce genre de poste de\u00a0SRE.</p><p><strong>[00:49:02.550]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Je pense que la cl\u00e9, c\u2019est la polyvalence\u200a\u2014\u200asans arriver \u00e0 la caricature d\u2019\u00eatre nul en tout\u00a0! Un SRE n\u2019est, pour moi, pas un sp\u00e9cialiste dans un truc en particulier. Il va avoir un domaine de pr\u00e9dilection. C\u2019est pour \u00e7a que l\u2019on a plusieurs profils ici\u00a0: on a des gens qui sont plus orient\u00e9s Ops, plus orient\u00e9s D\u00e9veloppeurs. Mais dans l\u2019id\u00e9e, on est en mesure de comprendre de mani\u00e8re assez fine le m\u00e9tier de l\u2019autre. \u00c7a veut dire qu\u2019on est potentiellement all\u00e9 s\u2019y frotter. Peut-\u00eatre pas directement\u200a\u2014\u200apersonnellement, je n\u2019ai jamais \u00e9t\u00e9 Ops, je n\u2019ai jamais eu la responsabilit\u00e9 de g\u00e9rer de l\u2019infrastructure de production d\u2019une entreprise mais je me suis int\u00e9ress\u00e9 sur comment \u00e7a marche et sur quels sont les outils qui sont mis en place, quelles sont notamment les contraintes, comment un Ops vit une astreinte\u2026 C\u2019est un truc tout b\u00eate mais je n\u2019ai jamais \u00e9t\u00e9 d\u2019astreinte, donc c\u2019est difficile pour moi de me repr\u00e9senter ce que c\u2019est que d\u2019\u00eatre d\u2019astreinte. C\u2019est quand m\u00eame avoir le droit de vie ou de mort quasiment instantan\u00e9 sur une plateforme. L\u2019objectif \u00e9tant de la faire vivre\u00a0!</p><p><strong>[00:50:07.520]\u200a\u2014\u200aVincent\u00a0: </strong>C\u2019est un peu comme quand tu es r\u00e9veill\u00e9 par ton b\u00e9b\u00e9 qui vient de na\u00eetre et qui demande son\u00a0biberon.</p><p><strong>[00:50:12.040]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> Je ne suis pas parent donc je ne peux pas non plus\u00a0!</p><p><strong>[00:50:13.760]\u200a\u2014\u200aVincent\u00a0: </strong>Tu pourrais faire comme si tu n\u2019avais rien entendu, mais en g\u00e9n\u00e9ral, tu y vas\u00a0!</p><p><strong>[00:50:17.570]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Voil\u00e0, en gros, c\u2019est avoir une capacit\u00e9, une empathie envers les autres m\u00e9tiers et s\u2019y int\u00e9resser. Je pense que l\u2019id\u00e9al, ce serait une personne qui soit aussi bien des deux c\u00f4t\u00e9s, mais c\u2019est un id\u00e9al de trajectoire plus qu\u2019une r\u00e9alit\u00e9\u200a\u2014\u200aparce que je pense que ce n\u2019est pas vraiment possible. C\u2019est cette id\u00e9e d\u2019\u00eatre capable de comprendre les deux mondes de mani\u00e8re suffisamment fine et profonde pour pouvoir, ensuite, l\u2019expliquer aux autres. Un peu comme quand on dit qu\u2019un professeur doit bien conna\u00eetre son sujet pour pouvoir l\u2019enseigner. C\u2019est un peu la m\u00eame chose. Quand on parle \u00e0 des d\u00e9veloppeurs, on a \u00e0 comprendre, un peu plus qu\u2019un d\u00e9veloppeur, l\u2019infrastructure\u200a\u2014\u200am\u00eame si l\u2019on n\u2019a pas besoin de comprendre l\u2019infrastructure au point d\u2019un Ops parce qu\u2019on n\u2019a pas non plus \u00e0 l\u2019enseigner \u00e0 un Ops, mais on a besoin d\u2019en savoir un peu plus pour avoir la capacit\u00e9 de dire des choses qui sont justes, tout en \u00e9tant p\u00e9dagogue.</p><p><strong>[00:51:08.610]\u200a\u2014\u200aPauline\u00a0: </strong>Eh bien merci\u00a0! Je pense que l\u2019on a fait un beau tour d\u2019horizon du SRE et on va maintenant passer \u00e0 la rubrique \u201cCoups de\u00a0c\u0153ur\u201d.</p><p><strong>[00:51:25.980]\u200a\u2014\u200aVincent\u00a0:</strong> Un titre que j\u2019ai \u00e9cout\u00e9 tr\u00e8s r\u00e9cemment et que j\u2019aime beaucoup\u2026 C\u2019est de l\u2019\u00e9lectronique, c\u2019est un artiste qui s\u2019appelle Spada, qui a sorti un titre qui s\u2019appelle <em>\u201cBeirut\u201d</em>, que je trouve tr\u00e8s sympa et que j\u2019\u00e9coute dans le m\u00e9tro en bougeant un peu. C\u2019est tr\u00e8s rythm\u00e9. C\u2019est le genre de rythme qui me fait vibrer en ce\u00a0moment.</p><p><strong>[00:51:46.390]\u200a\u2014\u200aDenis\u00a0:</strong> De mon c\u00f4t\u00e9, dans les d\u00e9couvertes que j\u2019ai faites il n\u2019y a pas longtemps, en cherchant la bande originale d\u2019un film\u200a\u2014\u200ade Kick Ass 2, pour dire le titre du film\u200a\u2014\u200aje suis tomb\u00e9 sur une track qui s\u2019appelle <em>\u201cKorobeiniki\u201d</em>. Il se trouve que c\u2019est le m\u00eame th\u00e8me que Tetris \u00e0 la guitare \u00e9lectrique. Sauf qu\u2019en fait, c\u2019est Tetris qui a repris une chanson traditionnelle russe qui s\u2019appelle <em>\u201cKorobeiniki\u201d</em>.</p><p><strong>[00:52:13.190]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>C\u2019est l\u2019origine de Tetris\u00a0!</p><p><strong>[00:52:14.830]\u200a\u2014\u200aDenis\u00a0: </strong>Exactement.</p><p><strong>[00:52:16.000]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>D\u2019accord. Moi, d\u2019habitude, je partage plus du jazz, mais aujourd\u2019hui, je vais partager un artiste fran\u00e7ais, de la vari\u00e9t\u00e9 fran\u00e7aise. \u00c7a s\u2019appelle Oscar les vacances. C\u2019est un peu loufoque, un peu d\u00e9lire. Je vous recommande \u00e0 tous d\u2019aller \u00e9couter sur Deezer ce qu\u2019il\u00a0fait.</p><p><strong>[00:52:33.320]\u200a\u2014\u200aSt\u00e9phane\u00a0:</strong> Pour ma part, Flow m\u2019a pouss\u00e9 The Datsuns avec <em>\u201cSittin\u2019</em> <em>Pretty\u201d</em>. C\u2019est un titre qui bouge bien, qui est plut\u00f4t sympathique et que j\u2019adore en ce\u00a0moment.</p><p><strong>[00:52:41.640]\u200a\u2014\u200aPauline\u00a0:</strong> Et moi, je ne vais pas vous faire une reco de titre. Je vais faire une reco, ce sont mes \u201call-time favorite\u201d, comme on dit. C\u2019est un groupe qui s\u2019appelle White Lies, c\u2019est un groupe de rock anglais avec des influences post-punk. Tous leurs albums sont g\u00e9niaux, en particulier le premier\u200a\u2014\u200apour moi, il n\u2019y a rien \u00e0 jeter dedans. Le premier, c\u2019est <em>\u201cTo Lose My\u00a0Life\u201d</em>.</p><p><strong>[00:53:01.586]\u200a\u2014\u200aVincent\u00a0: </strong>Nice\u00a0!</p><p><strong>[00:53:01.820]\u200a\u2014\u200aPauline\u00a0:</strong> Voil\u00e0\u00a0! Merci \u00e0 tous les trois pour vos \u00e9clairages et vos partages d\u2019exp\u00e9rience, et on se retrouve bient\u00f4t pour un nouvel \u00e9pisode\u00a0!</p><p><strong>[00:53:10.010]\u200a\u2014\u200aVincent\u00a0: </strong>Vous venez d\u2019\u00e9couter un \u00e9pisode de Deez is la tech et nous esp\u00e9rons que vous avez pass\u00e9 un bon moment en notre compagnie. N\u2019h\u00e9sitez pas \u00e0 nous attribuer quelques \u00e9toiles si votre application de podcast le permet, et \u00e0 nous faire part de vos retours via les r\u00e9seaux sociaux et notre compte @DeezerDevs. Ceux-ci nous aideront \u00e0 am\u00e9liorer notre contenu afin de le rendre plus utile, enrichissant et plaisant \u00e0 \u00e9couter. Enfin, n\u2019oubliez pas que toutes les transcriptions de nos \u00e9pisodes, ainsi que les coups de c\u0153ur de nos invit\u00e9s, sont disponibles sur notre blog deezer.io. \u00c0 tr\u00e8s vite pour un nouvel \u00e9pisode et d\u2019ici l\u00e0, ne p\u00e9tez ni les plombs, ni les crons\u00a0!</p><h3>R\u00e9f\u00e9rences</h3><ul><li>Site Reliability Engineering\u00a0: <a href=\"https://en.wikipedia.org/wiki/Site_reliability_engineering\">Wikipedia</a></li><li>Livres sur le SRE par Google\u00a0: <a href=\"https://sre.google/books/\">SRE\u00a0books</a></li><li>DevOps\u00a0: <a href=\"https://en.wikipedia.org/wiki/DevOps\">Wikipedia</a></li><li><a href=\"https://teamtopologies.com/book\"><em>Team Topologies</em></a> de Matthew Skelton et Manuel\u00a0Pais</li><li><a href=\"https://prometheus.io/\">Prometheus</a>\u200a\u2014\u200atoolkit open-source de monitoring et d\u2019alerting syst\u00e8me)</li><li>Stack ELK\u00a0: <a href=\"https://www.elastic.co/fr/elasticsearch\">Elasticsearch</a>, <a href=\"https://www.elastic.co/fr/logstash\">Logstash</a> et <a href=\"https://www.elastic.co/fr/kibana\">Kibana</a>\u200a\u2014\u200asolutions open-source de monitoring et de gestion des\u00a0logs</li><li><a href=\"https://www.youtube.com/user/joueurdugrenier\">Le joueur du grenier</a> (cha\u00eene YouTube)\u200a\u2014\u200a<a href=\"https://joueur-du-grenier.fandom.com/fr/wiki/David_Goodenough\">David Goodenough</a></li><li><a href=\"https://kubernetes.io/fr/\">Kubernetes</a>\u200a\u2014\u200aplateforme open-source de gestion de workloads et de services conteneuris\u00e9s)</li><li><a href=\"https://www.docker.com/\">Docker</a>\u200a\u2014\u200aplateforme permettant aux d\u00e9veloppeurs de concevoir, partager et d\u00e9ployer des applications \u00e0 l\u2019aide de conteneurs | <a href=\"https://docs.docker.com/engine/reference/builder/\">Dockerfile</a></li><li><a href=\"https://heartbleed.com/\">Vuln\u00e9rabilit\u00e9 Heartbleed</a></li><li>Vuln\u00e9rabilit\u00e9 Log4j\u00a0: <a href=\"https://en.wikipedia.org/wiki/Log4Shell\">Wikipedia</a></li><li><a href=\"https://git-scm.com/\">Git</a>\u200a\u2014\u200alogiciel open-source de gestion de versions d\u00e9centralis\u00e9</li><li>Coups de coeur\u00a0:<br />- \u201c<a href=\"https://deezer.page.link/nsNj7PyYoRXZrTGR9\"><em>Beirut</em></a>\u201d de Spada &amp; Mardra\u00fcs<br />- \u201c<a href=\"https://deezer.page.link/4vWCwtDjf3EUVfmC8\"><em>Korobeiniki</em></a>\u201d de Ozma<br />- <a href=\"https://deezer.page.link/b79ZwJowWvSuVkM36\">Oscar les vacances</a><br />- \u201c<a href=\"https://deezer.page.link/nRPqgedPAH56uGkj8\"><em>Sittin\u2019 Pretty</em></a>\u201d de The Datsuns<br />- <em>\u201c</em><a href=\"https://deezer.page.link/R5S7mr998sT25ZKA9\"><em>To Lose My Life</em></a><em>\u201d</em> de White\u00a0Lies</li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7a45e4bdd1f3\" width=\"1\" /><hr /><p><a href=\"https://deezer.io/deez-is-la-tech-s02e02-en-t%C3%AAte-%C3%A0-t%C3%AAte-avec-des-sre-missions-quotidien-et-challenges-7a45e4bdd1f3\">Deez is la tech\u200a\u2014\u200aS02E02\u200a\u2014\u200aEn t\u00eate-\u00e0-t\u00eate avec des SRE\u00a0: missions, quotidien et challenges</a> was originally published in <a href=\"https://deezer.io\">Deezer I/O</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h3>Deez is la tech\u200a\u2014\u200aS02E02\u200a\u2014\u200aEn t\u00eate-\u00e0-t\u00eate avec des SRE\u00a0: missions, quotidien et challenges</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2TgeGcHY2b5U6Jw8thioIA.png\" /></figure><p>SRE. Trois lettres qui soul\u00e8vent autant d\u2019int\u00e9r\u00eat que de questionnement.</p><p>SRE pour \u201cSite Reliability Engineering\u201d, ou ing\u00e9nierie de fiabilit\u00e9 des sites dans la langue de Moli\u00e8re. Et c\u2019est \u00e0 cette discipline, aujourd\u2019hui devenue un m\u00e9tier \u00e0 part enti\u00e8re, que s\u2019int\u00e9resse ce nouvel \u00e9pisode du podcast Deez is la\u00a0tech.</p><p>En quoi consiste le Site Reliability Engineering\u00a0? Quelle est la place du SRE en entreprise\u00a0? Quels sont les missions, t\u00e2ches quotidiennes et d\u00e9fis d\u2019un Site Reliability Engineer\u00a0? Quel est le profil id\u00e9al du SRE\u00a0? Apprenez-en plus ci-dessous gr\u00e2ce \u00e0 nos trois invit\u00e9s\u00a0!</p><p><em>Note: This post accompanies the release of the second episode of the second season of \u201cDeez is la tech\u201d, a podcast created by Deezer\u2019s Product &amp; Tech teams\u200a\u2014\u200ain French only for now. You can still find English content on </em><a href=\"https://deezer.io/\"><em>deezer.io</em></a><em> though. Go check it\u00a0out!</em></p><h3>R\u00e9sum\u00e9 de l\u2019\u00e9pisode</h3><p>Vingt ans apr\u00e8s sa th\u00e9orisation, le Site Reliability Engineering continue d\u2019intriguer et reste un concept encore flou pour beaucoup. Derri\u00e8re le sigle SRE se cachent, en effet, diverses d\u00e9finitions et r\u00e9alit\u00e9s.</p><p>Mais qu\u2019est-ce donc que le SRE\u00a0? Quel rapport avec DevOps\u00a0? Que font concr\u00e8tement les Site Reliability Engineers chez Deezer et \u00e0 quels d\u00e9fis sont-ils confront\u00e9s\u00a0? Enfin, comment devient-on SRE\u00a0?</p><p>Une fois n\u2019est pas coutume, Lo\u00efc Doubinine (@<a href=\"https://twitter.com/Ztec6/\">ztec6</a>) et Vincent Lepot (@<a href=\"https://twitter.com/neozibok\">neozibok</a>), tous deux Senior Expert Backend SRE, sont les invit\u00e9s de cet \u00e9pisode anim\u00e9 par <a href=\"https://www.linkedin.com/in/stephanebachelet/\">St\u00e9phane Bachelet</a> (Senior Coach Agile) et <a href=\"https://www.linkedin.com/in/pauline-m-b8703048/\">Pauline Munier</a> (Knowledge Manager). En compagnie de <a href=\"https://medium.com/u/1df55d0db6c5\">Denis GERMAIN</a> (Senior Expert Infrastructure Engineer\u200a\u2014\u200a@<a href=\"https://twitter.com/zwindler\">zwindler</a>), ils rappellent les pr\u00e9ceptes fondateurs du Site Reliability Engineering avant de d\u00e9tailler leur application au quotidien au sein des \u00e9quipes de Deezer. Entre automatisation et \u00e9vang\u00e9lisation, et au moyen d\u2019indicateurs et d\u2019error budget notamment, le SRE se r\u00e9v\u00e8le \u00eatre le v\u00e9ritable garant des bonnes pratiques des d\u00e9veloppeurs et des op\u00e9rationnels, de la qualit\u00e9 logicielle et de la fiabilit\u00e9 du\u00a0site.</p><a href=\"https://medium.com/media/af45cbb8cdf1f96b84a10de34802ec90/href\">https://medium.com/media/af45cbb8cdf1f96b84a10de34802ec90/href</a><p><em>\u00c9pisode \u00e9galement disponible sur </em><a href=\"https://deezer.page.link/svHKRDwnr7kfUp337\"><em>Deezer</em></a><em> | </em><a href=\"https://podcasts.apple.com/fr/podcast/deez-is-la-tech/id1648116961?i=1000634842642\"><em>Apple Podcasts</em></a><em> | </em><a href=\"https://open.spotify.com/episode/49W8hfAY0qiMnWAo20Vvjw?si=izIodKjeSY2gkKc20Hrtnw\"><em>Spotify</em></a><em> | </em><a href=\"https://music.amazon.de/podcasts/c0253c4d-c100-46d9-a660-d1b5f93cc69f/episodes/7cc28600-cba7-48e4-8e74-b4bc73b62fba/deez-is-la-tech-s02e02---en-t%C3%AAte-%C3%A0-t%C3%AAte-avec-des-sre-missions-quotidien-et-challenges\"><em>Amazon\u00a0Music</em></a><em>.</em></p><h3>Transcription</h3><p><strong>[00:00:06.720]\u200a\u2014\u200aVincent\u00a0: </strong>Bonjour et bienvenue dans Deez is la tech, le podcast qui n\u2019p\u00e8te ni les plombs, ni les crons\u00a0! Cr\u00e9\u00e9 et anim\u00e9 par les \u00e9quipes Product &amp; Tech de Deezer, ce programme aborde des sujets relatifs aux mondes de la tech et du streaming musical, et vous fait occasionnellement d\u00e9couvrir les coulisses de certaines des fonctionnalit\u00e9s phares de Deezer. Rejoignez-nous chaque mois pour une nouvelle discussion entre coll\u00e8gues et pairs, en tout d\u00e9contraction, m\u00ealant partages d\u2019exp\u00e9riences, bonnes pratiques et r\u00e9flexions sur les tendances futures. Pr\u00eats pour un nouvel \u00e9pisode\u00a0? Chaussez vos \u00e9couteurs, \u00e7a commence maintenant\u00a0!</p><p><strong>[00:00:43.150]\u200a\u2014\u200aSt\u00e9phane\u00a0: </strong>Le sigle \u201cSRE\u201d a le vent en poupe depuis quelques ann\u00e9es et \u00e0 en juger par les descriptions de postes sur le march\u00e9 de l\u2019emploi, son r\u00f4le et ses missions semblent diff\u00e9rer d\u2019une entreprise \u00e0 l\u2019autre. Il ne serait pas totalement erron\u00e9 de dire qu\u2019il y a quasiment autant de d\u00e9finitions du SRE qu\u2019il n\u2019y a d\u2019entreprises en recherche. Qu\u2019est-ce vraiment que le SRE et quels en sont les principes fondamentaux\u00a0? Quelle place occupe le SRE dans une entreprise, et plus particuli\u00e8rement chez Deezer\u00a0? Quels outils utilise-t-on en tant que SRE et \u00e0 quels d\u00e9fis fait-on face\u00a0? Enfin, comment devient- on SRE\u00a0? Je suis St\u00e9phane Bachelet, Coach Agile chez Deezer, et avec ma coll\u00e8gue Pauline Munier, Knowledge Manager et productrice de ce podcast, nous accueillons aujourd\u2019hui Lo\u00efc Doubinine, Denis Germain et Vincent Lepot afin de d\u00e9mystifier le r\u00f4le de\u00a0SRE.</p><p><strong>[00:01:29.900]\u200a\u2014\u200aPauline\u00a0:</strong> Salut Denis\u00a0! On est ravi de t\u2019accueillir dans Deez is la tech. Peux-tu te pr\u00e9senter en quelques mots\u00a0?</p><p><strong>[00:01:35.550]\u200a\u2014\u200aDenis\u00a0: </strong>Je m\u2019appelle Denis Germain, je suis Site Reliability Engineer chez Deezer. Je connais un petit peu le m\u00e9tier donc je me suis dit que \u00e7a pouvait \u00eatre une bonne id\u00e9e d\u2019en\u00a0parler.</p><p><strong>[00:01:44.310]\u200a\u2014\u200aPauline\u00a0:</strong> Merci\u00a0! \u00c0 tes c\u00f4t\u00e9s se trouvent deux habitu\u00e9s du podcast car ils en sont, en temps normal, les animateurs. Je vous laisse en dire un peu plus sur\u00a0vous.</p><p><strong>[00:01:52.400]\u200a\u2014\u200aVincent\u00a0: </strong>Bonjour\u00a0! Effectivement, \u00e7a fait bizarre d\u2019\u00eatre de l\u2019autre c\u00f4t\u00e9. Vincent Lepot, je suis\u200a\u2014\u200aje vais essayer de le dire aussi bien que Denis\u200a\u2014\u200aSite Reliability Engineer Proxy\u200a\u2014\u200aon pourra revenir un peu plus sur le \u201cproxy\u201d pendant le podcast\u200a\u2014\u200aapr\u00e8s avoir \u00e9t\u00e9 d\u00e9veloppeur back-end pendant tr\u00e8s longtemps.</p><p><strong>[00:02:10.660]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Moi, c\u2019est Lo\u00efc Doubinine. Mon titre complet officiel, c\u2019est Senior Expert Back End SRE, donc en gros, d\u00e9veloppeur SRE back-end.</p><p><strong>[00:02:20.550]\u200a\u2014\u200aPauline\u00a0:</strong> Merci \u00e0 tous les trois de vous joindre \u00e0 nous aujourd\u2019hui pour parler de SRE ou <em>SRE [prononc\u00e9 en anglais]</em> pour les bilingues. D\u00e9j\u00e0, qu\u2019est-ce que le SRE\u00a0?</p><p><strong>[00:02:29.630]\u200a\u2014\u200aDenis\u00a0: </strong>C\u2019est une philosophie, une fa\u00e7on de travailler qui a \u00e9t\u00e9 invent\u00e9e par des gens chez Google. C\u2019est assez vieux, \u00e7a date de 2003. En fait, il y avait un nouveau service, il fallait le maintenir en condition op\u00e9rationnelle et ils ont demand\u00e9 \u00e0 un VP Engineering chez Google de s\u2019en occuper. Chez Google, c\u2019est surtout des software engineers. La personne en question avait un background de software engineer, pas d\u2019op\u00e9rationnel. Il s\u2019est dit qu\u2019il allait faire les choses un peu diff\u00e9remment, donc \u00e0 contre-courant de ce qui se faisait \u00e0 l\u2019\u00e9poque. Il a dit qu\u2019il allait faire de l\u2019infra comme le feraient des d\u00e9veloppeurs. Il y a tout un tas de pr\u00e9ceptes qui ont \u00e9t\u00e9 mis sur papier bien plus tard\u200a\u2014\u200aen 2016 je crois\u200a\u2014\u200adans le \u201c<em>SRE Book\u201d</em> dont on va pouvoir parler. Grosso modo, c\u2019est une philosophie un petit peu diff\u00e9rente sur la fa\u00e7on dont on va g\u00e9rer l\u2019infrastructure, plus comme le ferait un d\u00e9veloppeur et pas comme le ferait un op\u00e9rationnel\u200a\u2014\u200am\u00eame si le terme est peut-\u00eatre un peu exag\u00e9r\u00e9 dans l\u2019\u00e9crit de\u00a0Google.</p><p><strong>[00:03:27.690]\u200a\u2014\u200aVincent\u00a0: </strong>On a beaucoup entendu parler de \u201cDevOps\u201d pendant tr\u00e8s longtemps et on va dire que le SRE est une mani\u00e8re de l\u2019impl\u00e9menter qu\u2019a mis en place Google il y a effectivement, maintenant, quelques ann\u00e9es\u200a\u2014\u200a\u00e7a fait pas loin de 20 ans. C\u2019est beaucoup autour de l\u2019automatisation, du suivi d\u2019indicateurs\u200a\u2014\u200ades choses qui nous paraissent maintenant assez naturelles, on va dire, mais qui ne l\u2019\u00e9taient pas quand Google a mis \u00e7a en place il y a une vingtaine d\u2019ann\u00e9es.</p><p><strong>[00:03:52.390]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>En gros, c\u2019est passer de serveurs g\u00e9r\u00e9s \u00e0 la main, avec des commandes qu\u2019on ex\u00e9cute \u00e0 la main, soit pour un installer ou mettre \u00e0 jour, ou g\u00e9n\u00e9ralement plus pour r\u00e9parer quand \u00e7a s\u2019est cass\u00e9 la tronche, \u00e0 une approche o\u00f9 l\u2019on automatise, o\u00f9 ce sont des robots qui font \u00e7a pour nous et o\u00f9 l\u2019on n\u2019a limite plus besoin de le faire \u00e0 la main et \u00e7a se fait tout\u00a0seul.</p><p><strong>[00:04:14.370]\u200a\u2014\u200aDenis\u00a0: </strong>Oui, l\u2019ennemi num\u00e9ro 1 de l\u2019Ops, selon les personnes qui ont cr\u00e9\u00e9 le SRE chez Google, c\u2019est le travail r\u00e9p\u00e9titif, le travail manuel, le travail qui pourrait \u00eatre automatis\u00e9, qui n\u2019a pas de valeur ajout\u00e9e. Et ce travail-l\u00e0, moi qui viens du monde de l\u2019infra avant d\u2019avoir fait du SRE, je l\u2019ai connu. J\u2019ai \u00e9crit des proc\u00e9dures pour installer des serveurs dans des Word, dans des documents Docs, o\u00f9 il fallait refaire tout le document d\u00e8s qu\u2019il y avait la moindre version qui changeait, o\u00f9 il fallait copier-coller les commandes \u00e0 la main\u200a\u2014\u200ala moiti\u00e9 du temps, on se plantait, on installait les mauvais trucs. C\u2019\u00e9tait la cata\u00a0! Ce monde o\u00f9 les serveurs avaient des petits noms mignons\u200a\u2014\u200aj\u2019adore cette p\u00e9riode mais ce n\u2019\u00e9tait pas du tout efficace. On parle de \u201cpet\u201d versus \u201ccattle\u201d, donc on parlait d\u2019animaux de compagnie avant et maintenant de \u201ccattle\u201d, c\u2019est-\u00e0-dire du b\u00e9tail\u00a0: ce sont des vaches, elles ont des num\u00e9ros sur l\u2019oreille et quand il y en a une qui meurt, ce n\u2019est pas grave, on en ach\u00e8te une autre et on la remplace.</p><p><strong>[00:05:16.210]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Tous les v\u00e9g\u00e9tariens sont en train de se retourner\u00a0!</p><p><strong>[00:05:18.940]\u200a\u2014\u200aDenis\u00a0: </strong>Oui\u00a0! Malheureusement, ce sont les termes de l\u2019industrie, mais c\u2019est vrai que ce n\u2019est pas tr\u00e8s bien pour le bien-\u00eatre animal.</p><p><strong>[00:05:24.780]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Mais par contre, on voit bien cette diff\u00e9rence de taille. Il y a une dizaine ou une quinzaine d\u2019ann\u00e9es, on g\u00e9rait un ou deux serveurs, ils \u00e9taient dans le placard derri\u00e8re ou potentiellement dans le sous-sol parce qu\u2019on voulait l\u2019avoir pas loin et qu\u2019il fallait mettre la clim. Maintenant, c\u2019est dans des data centers, on parle de centaines et de centaines de machines. Ce n\u2019est plus du tout la m\u00eame chose. On ne peut plus humainement se permettre d\u2019installer, de configurer ces centaines de machines probablement tous les jours. Avant, on le faisait pour un serveur. C\u2019\u00e9tait possible parce qu\u2019on le faisait une fois dans l\u2019ann\u00e9e, une fois dans l\u2019ann\u00e9e on faisait une petite campagne de mise \u00e0 jour. On avait deux machines donc \u00e7a allait, c\u2019\u00e9tait humainement g\u00e9rable. Maintenant, ce n\u2019est plus possible. On ferait \u00e7a toute la journ\u00e9e et on n\u2019arriverait encore m\u00eame pas \u00e0 suivre les cadences\u200a\u2014\u200aparce que les machines qu\u2019on rajoute dans des data centers, c\u2019est par palettes enti\u00e8res maintenant. Il faut que \u00e7a se fasse tout seul, et comme \u00e7a doit se faire tout seul, \u00e7a doit s\u2019automatiser. Et les d\u00e9veloppeurs ont quand m\u00eame apport\u00e9 beaucoup de choses pour l\u2019automatisation, avec beaucoup de pr\u00e9ceptes\u200a\u2014\u200aparce que c\u2019est quelque chose que l\u2019on fait depuis longtemps. C\u2019est ce qui s\u2019est infus\u00e9 dans l\u2019Ops, dans la gestion d\u2019infrastructures, ce qui a justement amen\u00e9 \u00e0 cette th\u00e9orisation, de mani\u00e8re \u00e0 mettre des mots et des r\u00e8gles sur cet entre-deux\u200a\u2014\u200aentre ce que faisaient les d\u00e9veloppeurs et ce que faisaient les Ops\u200a\u2014\u200ahistoire d\u2019avoir un langage commun\u200a\u2014\u200ace que l\u2019on a souvent appel\u00e9 DevOps, sans jamais le\u00a0d\u00e9finir.</p><p><strong>[00:06:51.680]\u200a\u2014\u200aDenis\u00a0:</strong> Oui, c\u2019est \u00e7a. Ce que j\u2019aime bien rappeler, c\u2019est que DevOps est arriv\u00e9 apr\u00e8s le SRE. C\u2019est assez amusant puisque nous\u200a\u2014\u200aen tout cas en Europe\u200a\u2014\u200aon l\u2019a d\u00e9couvert bien apr\u00e8s. C\u2019est-\u00e0-dire que Google faisait d\u00e9j\u00e0 du DevOps bien avant le DevOps. Devops a \u00e9t\u00e9 th\u00e9oris\u00e9 par un Belge, Patrick Debois, en 2008\u20132009 il me semble. C\u2019est l\u00e0 o\u00f9 on parle des cycles courts, de tout tester, de donner plus d\u2019autonomie aux d\u00e9veloppeurs, de rassembler les \u00e9quipes\u2026 Et tous ces pr\u00e9ceptes-l\u00e0, on les retrouve aussi dans SRE. C\u2019est pour \u00e7a que les gens confondent souvent un petit peu les deux, puisque les visions sont assez proches. Google avait essay\u00e9 de brander un peu en disant \u201cSRE implement DevOps\u201d. C\u2019est une fa\u00e7on de dire que c\u2019est la m\u00eame chose, mais fait diff\u00e9remment.</p><p><strong>[00:07:39.400]\u200a\u2014\u200aSt\u00e9phane\u00a0:</strong> Et du coup, quelle est la place du SRE dans une entreprise de d\u00e9veloppement logiciel, et notamment chez Deezer\u00a0?</p><p><strong>[00:07:46.140]\u200a\u2014\u200aVincent\u00a0:</strong> Je dirais que \u00e7a va un peu d\u00e9pendre des visions. Souvent, on imagine surtout que le SRE devrait \u00eatre\u200a\u2014\u200aen tout cas, c\u2019est notre position, ce que l\u2019on essaie de pousser mais ce qui est assez compliqu\u00e9 dans les organisations, c\u2019est de se dire que le SRE devrait \u00eatre au c\u0153ur de l\u2019\u00e9quipe. C\u2019est-\u00e0-dire que contrairement \u00e0 des \u00e9quipes d\u2019infrastructures vraiment tr\u00e8s \u201cplatform\u201d o\u00f9 l\u2019on va avoir des gens qui s\u2019occupent de racker des serveurs, de mettre \u00e0 disposition des choses, etc., le SRE a plut\u00f4t comme vocation d\u2019essayer d\u2019\u00eatre en accompagnement des \u00e9quipes de d\u00e9veloppement et d\u2019essayer de les accompagner dans le quotidien d\u2019une application, dans la maintenance d\u2019une application et d\u2019essayer de les aider \u00e0 suivre des m\u00e9triques, \u00e0 mettre en place de l\u2019automatisation, etc.</p><p><strong>[00:08:28.710]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Oui, apporter des concepts pour les aider. Dans le d\u00e9veloppement, on a beaucoup de pratiques qui viennent naturellement parce qu\u2019on a l\u2019habitude, on va d\u00e9velopper, on va coder, on va envoyer notre programme sur le serveur pour le faire tourner. Et comme on l\u2019a dit, \u00e7a n\u2019est plus possible aujourd\u2019hui. Du coup, on a des nouveaux outils pour pouvoir mettre le code qu\u2019on a compil\u00e9 en production. Mais ces nouveaux outils viennent aussi avec leurs contraintes, leurs complexit\u00e9s, parce que l\u2019on ne compile plus nous- m\u00eames les binaires que l\u2019on envoie en production par exemple. Il y a toute une cha\u00eene qui a \u00e9t\u00e9 mise en place pour le faire, mais c\u2019est une cha\u00eene qui, pour un junior par exemple, ou pour un d\u00e9veloppeur qui ne conna\u00eet pas ces cha\u00eenes-l\u00e0, n\u00e9cessite d\u2019\u00eatre apprivois\u00e9e, d\u2019\u00eatre comprise et d\u2019\u00eatre un peu manipul\u00e9e pour pouvoir \u00eatre utilis\u00e9e efficacement. \u00c7a vient aussi avec certaines pertes\u00a0: l\u00e0 o\u00f9 avant, le d\u00e9veloppeur pouvait potentiellement envoyer en prod et observer en production directement au travers de logs ou au travers d\u2019acc\u00e8s directs parfois, maintenant on va avoir des outils interm\u00e9diaires pour faire du debugging, du monitoring, etc. Et pareil, il faut apprendre \u00e0 les utiliser efficacement pour en tirer tout le b\u00e9n\u00e9fice, pour se rendre compte que notre projet fonctionne bien\u200a\u2014\u200aou pas\u200a\u2014\u200aquand on l\u2019envoie en production.</p><p><strong>[00:09:49.540]\u200a\u2014\u200aPauline\u00a0:</strong> Comment se mat\u00e9rialise cet accompagnement, concr\u00e8tement\u00a0?</p><p><strong>[00:09:53.140]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>C\u2019est la grande question, je pense. Il y a une part purement technique de connaissance et de capacit\u00e9 \u00e0 \u00eatre entre les deux milieux. On parle de DevOps et le mot en lui-m\u00eame, c\u2019est \u201cOps\u201d et \u201cDev\u201d accol\u00e9s ensemble. L\u2019id\u00e9e, c\u2019est d\u2019avoir un set de comp\u00e9tences et de connaissances sur les deux aspects, sans forc\u00e9ment \u00eatre parfait dans les deux. Il y aura toujours des experts des deux c\u00f4t\u00e9s et c\u2019est normal. Par contre, avoir suffisamment de connaissances pour faire le pont permet justement d\u2019avoir le dialogue. C\u2019est \u00e7a, je pense, qui est le plus important. Comme disait Vincent, d\u2019\u00eatre dans les \u00e9quipes et d\u2019\u00eatre capable de parler avec les \u00e9quipes de d\u00e9veloppement. C\u2019est donc avoir le dialogue, les mots, la p\u00e9dagogie pour pouvoir discuter avec des d\u00e9veloppeurs, tout en ayant aussi la capacit\u00e9 d\u2019avoir les mots, d\u2019avoir la p\u00e9dagogie, de discuter avec des op\u00e9rationnels. C\u2019est faire ce pont entre ces deux mondes qui\u2026 On a tendance \u00e0 troller en disant qu\u2019ils sont irr\u00e9conciliables. Mais l\u2019id\u00e9e, c\u2019est justement de les r\u00e9concilier, de faire en sorte que les deux avancent en m\u00eame temps. Et donc, c\u2019est \u00eatre concr\u00e8tement dans les \u00e9quipes, transmettre les probl\u00e9matiques des D\u00e9vs aux Ops, transmettre les probl\u00e9matiques des Ops aux D\u00e9vs, transmettre les nouveaux concepts qui permettent \u00e0 la fois aux Ops et aux D\u00e9vs de comprendre les deux autres\u00a0aspects.</p><p><strong>[00:11:08.710]\u200a\u2014\u200aDenis\u00a0: </strong>Le r\u00f4le du SRE, finalement, c\u2019est d\u2019\u00eatre l\u2019\u00e9vang\u00e9liste de toutes les bonnes pratiques, aussi bien les bonnes pratiques de d\u00e9v que les bonnes pratiques des op\u00e9rationnels. Quand on va dans les \u00e9quipes, on est un petit peu le consultant, on est un petit peu la personne qui va permettre de r\u00e9parer les petits probl\u00e8mes, de s\u2019assurer que tout est bien s\u00e9curis\u00e9, que tout est bien surveill\u00e9, monitor\u00e9. C\u2019est la personne qui va amener aux \u00e9quipes le petit bout de comp\u00e9tence qui leur manque pour d\u00e9livrer du logiciel de meilleure qualit\u00e9, et donc plus fiable. Puisque c\u2019est \u00e7a le but, c\u2019est de rendre l\u2019infrastructure et le site plus\u00a0fiables.</p><p><strong>[00:11:47.240]\u200a\u2014\u200aSt\u00e9phane\u00a0: </strong>Je reviens sur ce que tu disais tout \u00e0 l\u2019heure, Vincent. Tu as fait la diff\u00e9rence entre SRE et SRE Proxy. Est-ce que justement, cette proximit\u00e9 s\u2019apparente \u00e0\u2026\u00a0?</p><p><strong>[00:11:57.190]\u200a\u2014\u200aVincent\u00a0: </strong>C\u2019est \u00e7a. Chez Deezer, on a s\u00e9par\u00e9 deux r\u00f4les qui sont normalement assez li\u00e9s. Typiquement, comme le disait Lo\u00efc tout \u00e0 l\u2019heure, on est issu, lui et moi, du monde du d\u00e9v. On est plus proche des \u00e9quipes de d\u00e9veloppement, avec une app\u00e9tence pour tout ce qui est syst\u00e8me et tout ce qui est installation, mais c\u2019est vrai que l\u2019on ne vient pas forc\u00e9ment de l\u2019ops. En \u00e7a, on retrouve un peu la d\u00e9marche de Ben Treynor Sloss quand il a mis en place son \u00e9quipe SRE chez Google il y a une vingtaine d\u2019ann\u00e9es. Nous, on est plut\u00f4t orient\u00e9 d\u00e9v et on n\u2019a pas forc\u00e9ment vocation \u00e0 s\u2019occuper de la plateforme, \u00e0 \u00eatre d\u2019astreinte par exemples\u200a\u2014\u200ales SRE, normalement, ont cette notion d\u2019astreinte. On a plus cet objectif d\u2019\u00eatre proche des \u00e9quipes. Lo\u00efc et moi sommes normalement rattach\u00e9s \u00e0 certaines \u00e9quipes en particulier, pour justement comprendre leurs probl\u00e9matiques, essayer de discuter avec eux, leur amener l\u2019\u00e9vang\u00e9lisation autour de tous les principes du SRE\u200a\u2014\u200al\u2019observabilit\u00e9, la d\u00e9livrabilit\u00e9, etc.\u200a\u2014\u200al\u00e0 o\u00f9 pour l\u2019instant, c\u00f4t\u00e9 SRE, ils ont aussi en charge la plateforme\u200a\u2014\u200adonc la mise \u00e0 disposition de la plateforme\u200a\u2014\u200atout en n\u2019\u00e9tant pas compl\u00e8tement \u00e9loign\u00e9s des d\u00e9veloppeurs. Voil\u00e0, on fait un peu ce pont \u00e0 l\u2019heure actuelle.</p><p><strong>[00:13:12.450]\u200a\u2014\u200aDenis\u00a0: </strong>Oui, dans l\u2019\u00e9quipe dans laquelle je travaille, on est vraiment tr\u00e8s proche des serveurs, tr\u00e8s proche des stacks de bases de donn\u00e9es ou des middlewares, et on s\u2019apparente probablement plus \u00e0 ce que l\u2019on appellerait aujourd\u2019hui une \u00e9quipe \u201cplatform\u201d, m\u00eame si ce sont des labels que l\u2019on colle sur des gens. Mais si certains d\u2019entre vous ont lu le livre <em>\u201cTeam Topologies\u201d</em>, \u00e7a serait plus une \u00e9quipe platform, m\u00eame si je me sens totalement SRE comme mes deux coll\u00e8gues. Eux sont peut-\u00eatre plus ce que l\u2019on appelle des SRE au jour le\u00a0jour.</p><p><strong>[00:13:44.050]\u200a\u2014\u200aVincent\u00a0: </strong>Voil\u00e0, dans <em>\u201cTeam Topologies\u201d</em>, on serait les \u201cEnablers\u201d.</p><p><strong>[00:13:46.500]\u200a\u2014\u200aDenis\u00a0: </strong>Oui, les \u201cEnablers\u201d, exactement.</p><p><strong>[00:13:57.530]\u200a\u2014\u200aSt\u00e9phane\u00a0: </strong>Quels outils utilise-t-on chez Deezer pour r\u00e9aliser cette mission\u00a0?</p><p><strong>[00:14:01.430]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> Il y en a plein. Il y a plein d\u2019objectifs. Je pense qu\u2019il faut d\u00e9couper en diff\u00e9rents objectifs. On a parl\u00e9 de fiabilit\u00e9, on a donc besoin d\u2019outils pour pouvoir mesurer cette fiabilit\u00e9. Dans les outils que l\u2019on a, il va y avoir des stacks de monitoring par exemple, o\u00f9 l\u2019on va mettre en place les outils n\u00e9cessaires pour que les \u00e9quipes, quand elles produisent un logiciel, soient en mesure de savoir si ce logiciel fonctionne correctement, de remonter des statistiques, des logs, des outils comme \u00e7a. Si je donne deux ou trois noms, \u00e0 Deezer, on utilise un truc qui s\u2019appelle Prometheus pour tout ce qui est remont\u00e9 de m\u00e9triques, et on utilise la traditionnelle stack ELK\u200a\u2014\u200aun peu tweaked on va dire\u200a\u2014\u200apour la remont\u00e9e de logs. Et apr\u00e8s, l\u00e0 o\u00f9 le r\u00f4le des SRE devient important, c\u2019est sur le comment on utilise ces outils. Parce que les outils sont mis en place, comme le disait Denis, par l\u2019\u00e9quipe \u201cplatform\u201d, les outils sont disponibles. Mais il ne s\u2019agit pas juste d\u2019envoyer des logs et puis c\u2019est bon. Il faut les monitorer. Il faut envoyer les bons logs, il faut les monitorer de la bonne mani\u00e8re, il faut potentiellement mettre en place de l\u2019alerting pour \u00eatre au courant quand il y a un probl\u00e8me. Pour du log, \u00e7a peut \u00eatre d\u00e9tect\u00e9 quand un log en particulier arrive. Par exemple, si l\u2019on g\u00e8re une plateforme de paiement, on peut peut-\u00eatre avoir le nombre de paiements refus\u00e9s et \u00eatre notifi\u00e9 si ce nombre de paiements refus\u00e9s augmente significativement pendant une courte p\u00e9riode de temps. C\u2019est l\u00e0 o\u00f9 l\u2019on va se rendre compte qu\u2019apr\u00e8s on va avoir plein d\u2019autres questions. L\u2019exemple que je viens de vous donner est un exemple tr\u00e8s fonctionnel, c\u2019est tr\u00e8s produit. On a un produit\u00a0: c\u2019est faire du paiement. On a besoin de savoir si ce produit fonctionne pour faire du paiement. Mais l\u00e0 o\u00f9 les \u00e9quipes vont avoir parfois des questions beaucoup plus techniques\u200a\u2014\u200aavant m\u00eame de savoir si le service fait du paiement correctement, il faut d\u00e9j\u00e0 savoir si le service r\u00e9pond, par exemple, aux requ\u00eates qu\u2019on lui envoie. Donc on va aussi avoir besoin de monitorer les temps d\u2019acc\u00e8s, le nombre d\u2019acc\u00e8s, les temps de r\u00e9ponse\u2026 Et l\u2019id\u00e9e, c\u2019est que nous, on arrive avec tout un tas d\u2019\u00e9l\u00e9ments de base qu\u2019on va donner aux \u00e9quipes pour qu\u2019elles les suivent, de mani\u00e8re \u00e0 ce qu\u2019elles aient, presque cl\u00e9 en main, un jeu d\u2019outils pr\u00eats \u00e0 monitorer une application. Donc une \u00e9quipe, demain, quand elle cr\u00e9e un nouveau service en interne, une nouvelle application, saura qu\u2019il faut mesurer\u2026 On fait beaucoup de web services, donc \u00e7a veut dire mesurer le nombre d\u2019appels HTTP, mesurer le temps de r\u00e9ponse, le nombre d\u2019appels par retour HTTP, notamment le nombre d\u2019erreurs, etc. On en parlera peut-\u00eatre apr\u00e8s, mais tout cela est d\u00e9ploy\u00e9 sur une plateforme Kubernetes, donc il faut aussi mesurer comment \u00e7a fonctionne sur la plateforme en elle-m\u00eame\u200a\u2014\u200acombien de nodes sont op\u00e9rationnels, combien ont eu des crashs, etc. Notre objectif, c\u2019est de fournir une esp\u00e8ce de base qui, une fois qu\u2019elle est remplie, permet d\u2019avoir une sorte d\u2019\u00e9tat des lieux d\u2019une application satisfaisant pour pouvoir dire si cette application est op\u00e9rationnelle ou non, et dans le temps, est-ce qu\u2019elle a \u00e9t\u00e9 op\u00e9rationnelle ou non de mani\u00e8re satisfaisante aussi. Parce qu\u2019une application, \u00e7a vit. Les d\u00e9veloppeurs travaillent dessus et il y a des moments o\u00f9 elle peut tr\u00e8s bien fonctionner, puis des moments o\u00f9 les d\u00e9veloppeurs vont faire beaucoup de changements et elle fonctionnera moins bien. C\u2019est int\u00e9ressant de le savoir et de savoir r\u00e9agir en cons\u00e9quence.</p><p><strong>[00:17:28.840]\u200a\u2014\u200aDenis\u00a0: </strong>C\u2019est super parce que tu introduis un autre point hyper important de la th\u00e9orie du SRE, l\u2019un des piliers du Site Reliability Engineering\u00a0: c\u2019est le fait que\u200a\u2014\u200aet c\u2019est aussi pr\u00e9sent dans DevOps\u200a\u2014\u200ales incidents, \u00e7a arrive et c\u2019est normal. Et comme c\u2019est normal et comme on sait que \u00e7a va arriver, il faut d\u00e9terminer pour chacun de nos services\u200a\u2014\u200aun service, \u00e7a va \u00eatre un petit bout de logiciel, tu parlais du paiement tout \u00e0 l\u2019heure\u200a\u2014\u200apour chacune de ces briques logicielles qui composent notre produit, \u00e0 partir de quand les utilisateurs vont d\u00e9terminer que le service fonctionne mal. C\u2019est le truc que j\u2019ai eu le plus de mal \u00e0 accepter quand je suis devenu SRE. C\u2019est le fait que \u00e7a ne sert \u00e0 rien de faire une plateforme la plus solide possible, qui ne plantera jamais, parce qu\u2019elle finira toujours par planter. Il y aura toujours un moment o\u00f9 vous n\u2019aurez pas pr\u00e9vu le truc, etc. \u00c7a va planter. Et donc, tout ce temps d\u2019ing\u00e9nierie que l\u2019on va mettre \u00e0 essayer de fiabiliser un syst\u00e8me qui, de toute fa\u00e7on, finira par planter, c\u2019est du temps perdu. C\u2019est de la fonctionnalit\u00e9 que vous ne pouvez pas donner \u00e0 vos utilisateurs. Et en l\u2019occurrence, l\u00e0, mes utilisateurs ne sont pas les utilisateurs finaux, ce sont les d\u00e9veloppeurs. Une fois que l\u2019on a dit \u00e7a, il faut que l\u2019on prenne le probl\u00e8me \u00e0 l\u2019envers. \u00c0 partir de quand mes utilisateurs d\u00e9cident-ils que le service ne marche pas bien\u00a0? En vrai, les utilisateurs peuvent \u00eatre assez tol\u00e9rants, plus qu\u2019on ne le croit. Parce que moi, si je me connecte \u00e0 Deezer sur mon t\u00e9l\u00e9phone portable et que Deezer plante, je vais me demander\u00a0: \u201cEst-ce que c\u2019est mon smartphone qui bugue\u00a0? Est-ce que c\u2019est l\u2019appli qui bugue\u00a0? Est-ce que c\u2019est la 4G qui bugue\u00a0? Ou est-ce qu\u2019il y a vraiment un souci sur l\u2019appli Deezer elle-m\u00eame ou sur le site\u00a0?\u201d Le temps que je me pose cette question, si le service a d\u00e9j\u00e0 \u00e9t\u00e9 r\u00e9tabli, je m\u2019en fiche en tant qu\u2019utilisateur. Si jamais j\u2019ai pass\u00e9 trop de temps \u00e0 fiabiliser ce syst\u00e8me, c\u2019est du temps que je n\u2019ai pas pass\u00e9 \u00e0 faire autre chose, \u00e0 permettre \u00e0 mes d\u00e9veloppeurs d\u2019aller plus vite, \u00e0 permettre de sortir de nouvelles fonctionnalit\u00e9s, des trucs qui sont diff\u00e9renciants, qui vont faire que du c\u00f4t\u00e9 de la concurrence, ils vont \u00eatre compl\u00e8tement largu\u00e9s et que les utilisateurs vont pr\u00e9f\u00e9rer notre produit. Donc, en fait, pour ceux qui connaissent un petit peu le Joueur Du Grenier\u200a\u2014\u200apeut-\u00eatre que parmi nos auditeurs, il y en a certains qui le connaissent\u200a\u2014\u200a\u00eatre SRE, finalement, c\u2019est un petit peu le David Goodenough de l\u2019infrastructure. On essaye de faire <em>juste</em> bien. Et j\u2019en arrive \u00e0 mes m\u00e9triques dont on parlait tout \u00e0 l\u2019heure\u200a\u2014\u200ad\u00e9sol\u00e9, c\u2019\u00e9tait un petit peu long\u200a\u2014\u200apour chacun de mes services, je vais d\u00e9terminer \u00e0 partir de quand mes utilisateurs ne sont pas contents. \u00c7a va \u00eatre une m\u00e9trique, je vais me fixer un objectif dessus. Si je veux que 99 % des requ\u00eates r\u00e9pondent en moins de 40 millisecondes sur une p\u00e9riode de temps donn\u00e9\u200a\u2014\u200ace que l\u2019on fait assez r\u00e9guli\u00e8rement\u200a\u2014\u200a\u00e7a veut dire qu\u2019il y a 1% des requ\u00eates qui peuvent \u00e9chouer, et ce n\u2019est pas grave. \u00c7a va \u00eatre ce que l\u2019on appelle notre \u201cerror budget\u201d. On prend le probl\u00e8me \u00e0 l\u2019envers en fait, c\u2019est-\u00e0-dire qu\u2019au lieu d\u2019essayer de viser un niveau de disponibilit\u00e9, on vise un niveau d\u2019indisponibilit\u00e9. \u00c0 partir de l\u00e0, \u00e7a va \u00eatre super int\u00e9ressant parce que \u00e7a va nous permettre de faire tout un tas de choses dont on se privait avant. On va pouvoir faire des tests dangereux, on va pouvoir faire des maintenances qui vont provoquer des interruptions. Mais tout \u00e7a, ce n\u2019est pas grave parce que si \u00e7a casse, tant que l\u2019on est dans notre error budget, tant qu\u2019on ne l\u2019a pas cram\u00e9, \u00e7a veut dire que nos utilisateurs ne sont pas m\u00e9contents. Donc ils sont contents.</p><p><strong>[00:20:34.990]\u200a\u2014\u200aVincent\u00a0: </strong>Je pense que c\u2019est un truc sur lequel on essaie de sensibiliser les personnes du Produit\u00a0: tant que l\u2019on est dans notre error budget\u200a\u2014\u200ace que tu dis\u200a\u2014\u200aon peut casser des choses, on peut tenter des trucs, on peut innover m\u00eame. C\u2019est-\u00e0-dire que quand une feature doit sortir, tant que l\u2019on reste dans cet error budget, on peut se permettre de faire des choses. Apr\u00e8s, cet error budget est plus ou moins grand selon la criticit\u00e9 de l\u2019application, de la feature, etc., \u00e9videmment, mais on peut innover. Par contre, d\u00e8s que l\u2019on d\u00e9passe cet error budget, c\u2019est l\u00e0 que l\u2019on vient dire\u00a0: \u201cOK, on a d\u00e9pass\u00e9 notre tampon, donc maintenant il faut fiabiliser le service.\u201d Et c\u2019est l\u00e0 qu\u2019on peut avoir une discussion directement avec des personnes du Produit par exemple. C\u2019est toujours un peu compliqu\u00e9 d\u2019avoir des discussions entre Tech et Product, parce que l\u2019on n\u2019a pas forc\u00e9ment les m\u00eames enjeux, surtout quand on est c\u00f4t\u00e9 plateforme. L\u00e0, on peut leur dire clairement\u200a\u2014\u200ac\u2019est m\u00eame quelque chose que l\u2019on n\u00e9gocie avec eux, c\u2019est-\u00e0-dire que quand on va les voir, on leur dit\u2026 \u00c7a m\u2019est d\u00e9j\u00e0 arriv\u00e9, sur certains projets, de dire\u00a0: \u201c\u00c9coute, on va mettre en place un certain nombre d\u2019indicateurs. Dis-moi, toi\u200a\u2014\u200ace que tu disais, en fait, Denis\u200a\u2014\u200adis-moi, toi, \u00e0 partir de quand on consid\u00e8re que la feature est vraiment dysfonctionnelle\u00a0? Et on se rend compte que parfois, et j\u2019\u00e9tais m\u00eame tr\u00e8s surpris, sur certains projets, de me dire\u00a0: \u201cInstinctivement, je me serais mis un objectif vraiment tr\u00e8s haut par rapport \u00e0 ce que le Produit attend.\u201d Parce que l\u2019on est sur une feature qui n\u2019est pas forc\u00e9ment tr\u00e8s attendue ou parce que l\u2019on est sur le d\u00e9but, on est sur un POC, donc on peut se permettre de rater, on est sur une b\u00eata, etc. Il y a plein de raisons qui peuvent faire que l\u2019on ne se mette pas des objectifs tr\u00e8s compliqu\u00e9s. \u00c7a m\u2019est arriv\u00e9 d\u2019avoir un objectif o\u00f9 j\u2019avais mis un 9, c\u2019est-\u00e0-dire avoir 90% de disponibilit\u00e9\u200a\u2014\u200adonc 10% potentiel d\u2019indisponibilit\u00e9\u200a\u2014\u200ajuste parce que c\u2019\u00e9tait une future qui \u00e9tait, au lancement, pas critique. Et moi, j\u2019\u00e9tais parti sur un 99 ou un 99,9. C\u2019est aussi l\u2019int\u00e9r\u00eat de ce genre de m\u00e9trique, de pouvoir justement \u00e9changer avec des gens du Produit et de se dire\u00a0: \u201cC\u2019est quoi un service qui marche\u00a0? C\u2019est quoi un service qui ne marche pas\u00a0?\u201d Ce n\u2019est pas juste\u00a0: \u201cMon service doit r\u00e9pondre en moins de 100 millisecondes\u201d. Non, c\u2019est\u00a0: \u201cDis-moi ce que tu attends de la feature et de la plateforme. Et derri\u00e8re, on le d\u00e9cline en choses un peu plus \u201ctechniques\u201d, de savoir en combien de temps doit r\u00e9pondre le service, quel est le taux d\u2019erreur que l\u2019on peut accepter, etc.</p><p><strong>[00:22:43.060]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> Si on reprend l\u2019exemple, on peut tr\u00e8s bien imaginer mettre des budgets d\u2019erreur totalement diff\u00e9rents. Sur le paiement, par exemple, on pourrait se dire que \u00e7a reste important. On va mettre un budget d\u2019erreur assez faible et peut-\u00eatre que, comme le dit Vincent, sur une fonctionnalit\u00e9 exp\u00e9rimentale, voire une fonctionnalit\u00e9 que seulement 5% des utilisateurs utilisent, on va \u00eatre plus tol\u00e9rants. \u00c7a permet de varier, et de mani\u00e8re indirecte, \u00e7a permet aussi de varier le co\u00fbt. Parce que rendre fiable \u00e0 100% quoi que ce soit, \u00e7a a un co\u00fbt th\u00e9oriquement infini. \u00c0 un moment donn\u00e9, il faut r\u00e9duire ce co\u00fbt \u00e0 quelque chose qui est soutenable pour l\u2019entreprise ou l\u2019entit\u00e9 qui produit le logiciel. \u00c7a permet de faire varier ce co\u00fbt et parfois, on peut aussi prendre des d\u00e9cisions qui ne sont, certes, pas en faveur de l\u2019utilisateur. Je vais prendre un exemple un petit peu extr\u00eame. Je suis des blogueurs qui h\u00e9bergent leurs blogs sur des Raspberry Pi aliment\u00e9s par des panneaux solaires et dans leur budget d\u2019erreur, c\u2019est\u00a0: pas de soleil, pas de blog. Certes, l\u2019utilisateur final n\u2019est pas content parce qu\u2019il n\u2019y a pas de soleil, il ne peut pas acc\u00e9der au blog. Mais c\u2019est consid\u00e9r\u00e9 comme acceptable parce que l\u2019on a fait varier les co\u00fbts\u200a\u2014\u200al\u00e0, c\u2019est un co\u00fbt \u00e9nerg\u00e9tique direct\u200a\u2014\u200apour dire\u00a0: \u201cJe n\u2019ai pas de quoi assurer ou je ne souhaite pas\u200a\u2014\u200aparce que c\u2019est un souhait plus qu\u2019une possibilit\u00e9\u200a\u2014\u200aassurer la disponibilit\u00e9 du service au-del\u00e0 d\u2019un certain co\u00fbt.\u201d Du coup, \u00e7a coupe. Sans forc\u00e9ment aller jusqu\u2019\u00e0 cet extr\u00eame\u200a\u2014\u200aparce que l\u00e0, on parle de blogs souvent libristes qui sont plus anecdotiques\u200a\u2014\u200apour un service donn\u00e9, \u00e7a peut tr\u00e8s bien se faire. Si on reprend l\u2019exemple \u00e9nerg\u00e9tique, l\u2019ann\u00e9e derni\u00e8re, il y a eu des tensions \u00e9nerg\u00e9tiques, notamment en France et en Europe. On peut tr\u00e8s bien se dire que l\u2019on change ses budgets d\u2019erreur pendant cette p\u00e9riode sur certains aspects pour conserver une partie de l\u2019\u00e9nergie\u200a\u2014\u200ace qui permet de couper des serveurs. Mais de mani\u00e8re indirecte, couper des serveurs, c\u2019est r\u00e9duire la fiabilit\u00e9 globale.</p><p><strong>[00:24:51.550]\u200a\u2014\u200aPauline\u00a0: </strong>On a \u00e9voqu\u00e9 diff\u00e9rents concepts SRE\u00a0: on a parl\u00e9 de budget d\u2019erreur, on a parl\u00e9 d\u2019automatisation des t\u00e2ches r\u00e9p\u00e9titives. Est-ce qu\u2019il y a d\u2019autres concepts qui sont propres au SRE\u00a0?</p><p><strong>[00:25:06.680]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>L\u2019un des principes que l\u2019on pousse \u00e0 Deezer\u200a\u2014\u200aet je ne saurais pas dire si c\u2019est intrins\u00e8que au SRE ou pas\u200a\u2014\u200ac\u2019est l\u2019autonomisation des d\u00e9veloppeurs\u00a0: le fait qu\u2019un d\u00e9veloppeur ait de moins en moins\u200a\u2014\u200avoire plus du tout\u200a\u2014\u200abesoin d\u2019une personne avec \u00e0 la fois des privil\u00e8ges d\u2019autorisation et des connaissances techniques diff\u00e9rentes des siennes\u200a\u2014\u200adonc principalement des Ops g\u00e9n\u00e9ralement\u200a\u2014\u200apour faire \u00e9voluer, d\u00e9ployer, cr\u00e9er, tester\u2026 Et pour \u00e7a, on a besoin d\u2019outils. Pour permettre cette autonomisation, on peut parler de Kubernetes, on peut parler de Docker notamment. Pour faire simple, il y a quelques ann\u00e9es, ce qu\u2019un d\u00e9veloppeur livrait, c\u2019\u00e9tait du code source, peut- \u00eatre parfois du binaire, mais bien souvent, l\u2019objectif \u00e9tait de livrer une version d\u2019un code source qui allait \u00eatre build\u00e9 dans une CI (Continuous Integration), qui allait donc construire un build qui allait souvent \u00eatre d\u00e9ploy\u00e9 par des Ops justement. On a un petit peu chang\u00e9 \u00e7a depuis quelques ann\u00e9es. Le livrable est pass\u00e9 de code \u00e0 une image Docker. L\u2019int\u00e9r\u00eat de changer \u00e7a, c\u2019est que l\u2019image Docker vient \u00e0 la fois avec le code ou le binaire, et une partie de l\u2019infrastructure. Et il y avait notamment beaucoup de conflits. Nous, \u00e0 Deezer, on est en PHP, donc les conflits les plus fr\u00e9quents \u00e9taient par exemple\u00a0: \u201csur mon environnement de d\u00e9veloppement, j\u2019ai tel module qui est install\u00e9 sur PHP, j\u2019ai telle version de PHP, et en production pas du tout\u201d, \u201cje n\u2019ai pas le module GD, il n\u2019\u00e9tait pas install\u00e9 en production\u201d ou \u201cce n\u2019\u00e9tait pas la bonne version\u201d. Du coup, j\u2019avais des probl\u00e9matiques de bugs qui \u00e9taient relativement fr\u00e9quentes parce qu\u2019il y avait des divergences entre mes environnements de production et de d\u00e9veloppement. Docker permet de r\u00e9soudre beaucoup de ces probl\u00e8mes-l\u00e0 parce que maintenant, ce que je donne \u00e0 livrer contient toutes ces d\u00e9pendances ou une grande partie de ces d\u00e9pendances. Mais pour pouvoir faire \u00e7a, il y a eu besoin de d\u00e9ployer ces containers, ces images Docker, en production. Et c\u2019est l\u00e0 o\u00f9 Kubernetes notamment\u200a\u2014\u200aqui, maintenant, est quand m\u00eame la r\u00e9ponse h\u00e9g\u00e9monique \u00e0 cette probl\u00e9matique d\u2019orchestration d\u2019images Docker\u200a\u2014\u200aest venue r\u00e9soudre, mettre une interface technique entre les Ops qui vont fournir la plateforme\u200a\u2014\u200aplateforme qui rend le service de d\u00e9ployer des containers\u200a\u2014\u200aet les d\u00e9veloppeurs qui vont \u00eatre capables d\u2019appeler cette plateforme, de l\u2019utiliser pour pouvoir d\u00e9ployer des containers. Et \u00e7a va notamment leur permettre de d\u00e9ployer des containers sur des applications qu\u2019ils connaissent, mais potentiellement des nouvelles applications aussi pour pouvoir faire des tests, pour tester des nouvelles fonctionnalit\u00e9s, pour tester des nouveaux \u00e9l\u00e9ments techniques, peu importe. \u00c7a permet d\u2019avoir un langage qui est \u00e0 la fois technique et presque \u201chumain\u201d. On va parler beaucoup de containers, de tous les langages qui sont autour de Kubernetes, entre les Ops et les D\u00e9vs. Il y a des D\u00e9vs qui vont avoir la capacit\u00e9 de quasiment tout faire tous seuls. Et quand il y a besoin de discuter avec des Ops parce qu\u2019il y a des trucs qui n\u00e9cessitent plus de compr\u00e9hension ou des trucs un peu exotiques, il y aura un langage qui permettra de discuter, qui sera beaucoup plus standardis\u00e9\u200a\u2014\u200astandardis\u00e9, parce que techniquement mis en place dans un logiciel.</p><p><strong>[00:28:25.020]\u200a\u2014\u200aDenis\u00a0: </strong>Ce que j\u2019ai trouv\u00e9 vraiment int\u00e9ressant avec l\u2019arriv\u00e9e de Docker\u200a\u2014\u200aparce que tu en parles\u200a\u2014\u200ac\u2019est que c\u2019est vraiment l\u2019outil, je pense, qui a le plus aid\u00e9 les d\u00e9veloppeurs \u00e0 faire, avec du code, de l\u2019infra. Parce que finalement, le Dockerfile\u200a\u2014\u200adonc le fichier que livre le d\u00e9veloppeur\u200a\u2014\u200aqu\u2019est-ce que c\u2019est\u00a0? C\u2019est un fichier texte qui dit\u00a0: \u201cQu\u2019est-ce que je veux comme d\u00e9pendance\u00a0? O\u00f9 est-ce que je mets le binaire qui a \u00e9t\u00e9 construit par ma CI\u00a0? Comment je package tout \u00e7a\u200a\u2014\u200adonc le binaire et ses d\u00e9pendances ou le code et ses d\u00e9pendances, peu importe\u200a\u2014\u200aet comment je l\u2019envoie en production\u00a0?\u201d \u00c7a, c\u2019\u00e9tait vraiment la premi\u00e8re \u00e9tape. Il y avait d\u2019autres outils pour faire de l\u2019infrastructure as code avant Docker, mais pas vraiment utilis\u00e9s, en tout cas pas de mani\u00e8re h\u00e9g\u00e9monique par les d\u00e9veloppeurs. Docker est arriv\u00e9 autour de 2014, si je ne dis pas de b\u00eatises, et a vraiment chang\u00e9 radicalement la fa\u00e7on dont les D\u00e9vs ont vu l\u2019infrastructure. D\u2019un coup, d\u2019un seul, ils n\u2019avaient plus besoin de demander\u200a\u2014\u200aparce que \u00e7a aussi, je l\u2019ai v\u00e9cu\u200a\u2014\u200aun serveur web qui mettait trois semaines \u00e0 \u00eatre livr\u00e9 par les Ops. Et le temps que les Ops livrent le serveur web dans leur catalogue de templates, la version \u00e9tait d\u00e9j\u00e0 obsol\u00e8te. Donc \u00e7a, c\u2019\u00e9tait fini, les d\u00e9veloppeurs avaient la main l\u00e0-dessus. Le probl\u00e8me, c\u2019est que les Ops, pendant un moment\u200a\u2014\u200amoi compris\u200a\u2014\u200aont voulu mettre un coup de frein parce que derri\u00e8re, qu\u2019est-ce qu\u2019on en fait de ce container\u00a0? C\u2019est pour \u00e7a que des outils comme Kubernetes sont arriv\u00e9s, comme tu le citais. Et l\u00e0, on va encore plus loin dans la description de l\u2019infrastructure. Non seulement, on d\u00e9crit avec le Dockerfile l\u2019appli et son environnement d\u2019ex\u00e9cution, mais avec Kubernetes, on va beaucoup plus loin. On va d\u00e9ployer, on va d\u00e9crire des load balancers, des reverse proxies, des disques, des r\u00e9plicas\u200a\u2014\u200acombien je veux en envoyer. Tout \u00e7a est g\u00e9r\u00e9 par des API. C\u2019est manipul\u00e9 avec du YAML\u200a\u2014\u200aon peut dire ce qu\u2019on veut sur le YAML ou pas, mais il y a quelque chose de magique dans le fait de monter toute une infrastructure avec quelques dizaines ou quelques centaines de lignes de YAML. Pour quelqu\u2019un qui vient du monde de l\u2019infra, pour moi, c\u2019est vraiment magique. C\u2019est un truc incroyable\u00a0! \u00c7a g\u00e8re la haute dispo automatiquement\u2026 Donc, Kubernetes, c\u2019est vraiment\u00a0: donner la main, les cl\u00e9s du camion, de l\u2019infrastructure aux d\u00e9veloppeurs. \u00c7a vient avec d\u2019autres contraintes parce que les bonnes pratiques de s\u00e9curit\u00e9, les bonnes pratiques de fiabilit\u00e9 que les Ops avaient, les d\u00e9veloppeurs ne les ont pas forc\u00e9ment. Donc si on leur donne de l\u2019autonomie, il faut aussi soit les \u00e9duquer, soit les guider. Et on en revient encore au r\u00f4le d\u2019\u00e9vang\u00e9liste du SRE. Il est l\u00e0 pour apporter toutes ces bonnes pratiques que n\u2019ont pas forc\u00e9ment des d\u00e9veloppeurs parce que ce n\u2019est pas leur m\u00e9tier, parce qu\u2019ils n\u2019ont pas besoin de savoir tout non plus et ils n\u2019ont pas forc\u00e9ment int\u00e9r\u00eat d\u2019ailleurs\u200a\u2014\u200ail vaut mieux \u00eatre bon en un seul domaine que nul en tout, c\u2019est quand m\u00eame mieux\u00a0! Donc Kubernetes est vraiment l\u2019outil qui va nous permettre de donner de l\u2019autonomie aux d\u00e9veloppeurs. \u00c7a ne fait pas tout. Il y a encore des fois o\u00f9 les gens de l\u2019infra\u200a\u2014\u200aou \u201cplatform\u201d, peu importe comment on l\u2019appelle\u200a\u2014\u200asont sur le chemin critique. R\u00e9cemment, avec des coll\u00e8gues, on a fait un atelier Mikado o\u00f9 l\u2019on a essay\u00e9 de prendre toutes les t\u00e2ches qu\u2019il fallait pour cr\u00e9er une nouvelle application en tant que d\u00e9veloppeur, en se pla\u00e7ant dans le contexte le plus d\u00e9favorable possible. Toutes les t\u00e2ches que l\u2019on a vues, qui sont potentiellement pour certaines avec l\u2019infrastructure sur le chemin critique, qui ralentissent la v\u00e9locit\u00e9 des d\u00e9veloppeurs, on a essay\u00e9 de les automatiser, de les r\u00e9duire, de les rendre plus simples, de mani\u00e8re \u00e0 donner encore plus d\u2019autonomie aux d\u00e9veloppeurs. Et plus on leur donne d\u2019autonomie, moins on passe de temps \u00e0 travailler l\u00e0-dessus. C\u2019est plus de temps pour mettre en place d\u2019autres outillages, pour justement s\u2019assurer que les bonnes pratiques, par exemple, sont respect\u00e9es\u200a\u2014\u200anotamment les bonnes pratiques de s\u00e9curit\u00e9, avec de l\u2019outillage qui va v\u00e9rifier que les conteneurs ne tournent pas avec des privil\u00e8ges trop importants, que l\u2019infrastructure qui est d\u00e9ploy\u00e9e avec le YAML dans Kubernetes correspond bien \u00e0 nos standards\u2026 Finalement, c\u2019est un cercle vertueux. Le SRE est vraiment dans cette optique de ne pas perdre du temps sur des choses qui n\u2019ont pas de valeur et de passer justement le plus de temps possible pour d\u00e9livrer de la valeur pour les d\u00e9veloppeurs.</p><p><strong>[00:32:29.260]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Et les pratiques qu\u2019avaient les Ops, notamment quand on parle de s\u00e9curit\u00e9, c\u2019est quand m\u00eame un truc assez fondamental dans les \u00e9quipes Ops de g\u00e9rer la s\u00e9curit\u00e9 d\u2019un service, ce n\u2019est pas quelque chose qui est facile \u00e0 faire et en plus, c\u2019est quelque chose qui change du jour au lendemain parce qu\u2019il y a des informations qui sont r\u00e9v\u00e9l\u00e9es parfois, qui n\u00e9cessitent des op\u00e9rations cons\u00e9quentes sur beaucoup d\u2019aspects de l\u2019infrastructure. On peut penser aux failles Heartbleed et compagnie, ou \u00e0 la plus importante peut-\u00eatre r\u00e9cemment, Log4j, qui a n\u00e9cessit\u00e9 que les Ops et les D\u00e9veloppeurs se parlent et se synchronisent pour se d\u00e9barrasser de cette vuln\u00e9rabilit\u00e9.</p><p><strong>[00:33:09.180]\u200a\u2014\u200aDenis\u00a0: </strong>Qui \u00e9tait pr\u00e9sente quasiment partout.</p><p><strong>[00:33:10.610]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Oui, qui \u00e9tait vraiment \u00e0 tous les \u00e9tages, m\u00eame si on n\u2019utilisait pas de Java. \u00c7a permet notamment d\u2019am\u00e9liorer la qualit\u00e9 de la s\u00e9curit\u00e9 en soi. Parce qu\u2019encore une fois, les outils que l\u2019on met en place sont automatis\u00e9s et vont se mettre, de mani\u00e8re un petit peu \u201cfroide\u201d, \u00e0 tout analyser. L\u00e0 o\u00f9 avant un op\u00e9rationnel maintenait ses serveurs \u00e0 jour, s\u2019assurait de la s\u00e9curit\u00e9 et regardait, presque \u00e0 l\u2019\u0153il nu, l\u2019\u00e9tat de sa plateforme en termes de s\u00e9curit\u00e9, maintenant on a des robots qui passent et qui, \u00e0 la moindre librairie qui a une CVE <em>(Common Vulnerability &amp; Exposure)</em> qui est d\u00e9clar\u00e9e quelque part\u200a\u2014\u200aune librairie Python, Node, PHP, peu importe\u200a\u2014\u200aremontent une alerte. On le sait quasiment tout de suite. Les Ops peuvent le savoir mais surtout, \u00e7a redescend quasiment directement\u200a\u2014\u200aou \u00e7a peut redescendre directement\u200a\u2014\u200ajusqu\u2019au d\u00e9veloppeur qui est concern\u00e9, qui a utilis\u00e9 cette librairie qui a une vuln\u00e9rabilit\u00e9. Le d\u00e9veloppeur peut avoir une action dessus directement, sans m\u00eame que l\u2019Ops aille s\u2019inqui\u00e9ter r\u00e9ellement du sujet. Donc on a toujours les cas un peu g\u00e9n\u00e9riques comme Log4j, qui \u00e9tait vraiment un cas exceptionnel, mais les vuln\u00e9rabilit\u00e9s de s\u00e9curit\u00e9 ne sont pas vraiment ces exceptions-l\u00e0, ce sont plut\u00f4t la myriade de vuln\u00e9rabilit\u00e9s qui ont lieu partout dans un syst\u00e8me complexe, qui sont tr\u00e8s difficilement mesurables. Et en fait, on a m\u00eame permis d\u2019am\u00e9liorer la s\u00e9curit\u00e9 l\u00e0 o\u00f9 c\u2019est contre intuitif, parce que Kubernetes, avec Docker notamment, est souvent cri\u00e9 pour son aspect non s\u00e9curitaire d\u2019un point de vue technique\u00a0: \u00e7a ouvre beaucoup de failles de s\u00e9curit\u00e9 \u00e0 plein d\u2019endroits et ce sont des critiques qui sont r\u00e9elles et justifiables\u200a\u2014\u200ajustifi\u00e9es m\u00eame\u200a\u2014\u200apour autant, \u00e7a permet de syst\u00e9matiser \u00e9norm\u00e9ment de comblements de trous de s\u00e9curit\u00e9 par ailleurs. Donc la balance finale, l\u2019apport en termes de s\u00e9curit\u00e9, est probablement plus en faveur de ces outils-l\u00e0, si trait\u00e9 convenablement et si les \u00e9quipes Ops ont le temps de mettre en place ce qui est permis par l\u2019autonomisation des d\u00e9veloppeurs\u200a\u2014\u200a\u00e7a leur permet d\u2019avoir le temps de mettre en place tous ces outils. \u00c0 la fin, je pense que l\u2019on a m\u00eame une meilleure s\u00e9curit\u00e9 de nos plateformes malgr\u00e9 la complexit\u00e9 qui, elle, est incommensurable par rapport \u00e0 ce que l\u2019on avait il y a vingt\u00a0ans.</p><p><strong>[00:35:14.920]\u200a\u2014\u200aVincent\u00a0: </strong>L\u2019enjeu est de se dire que c\u2019est de l\u2019autonomie que l\u2019on donne aux d\u00e9veloppeurs, mais par contre, c\u2019est aussi de la responsabilisation. Et du coup, il y a aussi un accompagnement. Il faut vraiment aller vers eux pour leur dire\u00a0: \u201cMaintenant, c\u2019est ton application.\u201d C\u2019est le fameux \u201cYou build it, you run it\u201d, c\u2019est-\u00e0-dire que vous cr\u00e9ez les applications, vous les d\u00e9ployez, etc. mais par contre, vous g\u00e9rez aussi les mont\u00e9es de version, ce qui tourne r\u00e9ellement en production, ce que vous envoyez avec votre application. C\u2019est aussi un changement de mindset qui n\u2019est pas toujours \u00e9vident \u00e0 faire passer. C\u2019est vrai qu\u2019il y a beaucoup de d\u00e9veloppeurs qui sont en mode\u00a0: \u201cmoi, je veux juste d\u00e9livrer ma feature, je clique sur le bouton, c\u2019est en prod.\u201d Oui, mais tout \u00e7a, ce sont des choses qu\u2019il faut prendre en compte. Apr\u00e8s, ce sont aussi des choses sur lesquelles ils ont plus de libert\u00e9. Typiquement, on parlait de mont\u00e9e de version\u200a\u2014\u200ad\u2019un framework, d\u2019un socle technique, peu importe\u200a\u2014\u200ace sont des choses sur lesquelles ils ont la main, ce qui n\u2019\u00e9tait pas le cas avant. Avant, comme le disait Denis, il fallait attendre, il fallait que le serveur soit livr\u00e9, que la bonne version de PHP, par exemple, soit dessus, avec les bons modules, etc. Avant, c\u2019\u00e9tait compliqu\u00e9, \u00e7a demandait de la synchro entre \u00e9quipes, etc. Maintenant, ce sont eux qui peuvent faire la mont\u00e9e de version dans leur coin, v\u00e9rifier que \u00e7a marche et si \u00e7a marche, ils livrent en prod et c\u2019est\u00a0fini.</p><p><strong>[00:36:29.660]\u200a\u2014\u200aSt\u00e9phane\u00a0:</strong> Je pense que vous avez commenc\u00e9 \u00e0 les dresser un peu, mais si vous deviez r\u00e9sumer, quels sont les principaux challenges que vous avez \u00e0 relever en tant que SRE et les pi\u00e8ges que vous avez \u00e0 \u00e9viter\u00a0?</p><p><strong>[00:36:50.260]\u200a\u2014\u200aVincent\u00a0:</strong> Le premier, c\u2019est vraiment le syndrome\u00a0: \u201cNon, je ne veux pas savoir comment \u00e7a tourne, je livre mon code et il faut que \u00e7a marche.\u201d C\u2019est vraiment le truc le plus compliqu\u00e9 \u00e0 bypasser dans la logique des gens. On met toujours en balance ce c\u00f4t\u00e9\u00a0: \u201cOui mais en faisant comme \u00e7a, tu auras plus de fluidit\u00e9, tu pourras livrer plus souvent et tu seras ma\u00eetre de ton truc. C\u2019est ton service, tu livres ce que tu veux, avec le socle que tu veux. Si tu veux passer en PHP+++ \u00e0 la sortie du langage, libre \u00e0 toi.\u201d Ce qui n\u2019\u00e9tait pas le cas avant. Avant, on ne sortait que sur des versions bien stabilis\u00e9es, qui \u00e9taient ma\u00eetris\u00e9es par les \u00e9quipes de la plateforme, etc. Donc le plus gros probl\u00e8me, c\u2019est vraiment \u00e7a, le \u201cmoi, \u00e7a ne m\u2019int\u00e9resse pas de savoir comment \u00e7a tourne, je livre ma feature et je veux que \u00e7a marche.\u201d Et en m\u00eame temps, quand ils avaient un probl\u00e8me en production avant, ils n\u2019\u00e9taient pas capables de l\u2019observer, ils n\u2019avaient pas de capacit\u00e9 \u00e0 suivre les r\u00e9gressions de leurs bugs, etc. Il y a beaucoup de choses qui ont \u00e9t\u00e9 apport\u00e9es par ces principes, \u00e0 la fois du DevOps et du SRE, qui nous permettent d\u2019avoir une esp\u00e8ce de levier pour dire\u00a0: \u201cOn te donne les moyens d\u2019aller plus loin et de faire ce que tu as envie de faire. \u00c7a vient avec la \u201ccontrainte\u201d avec de grands guillemets\u200a\u2014\u200apuisque ce ne sont pas non plus des contraintes de fou\u200a\u2014\u200ade suivre ce que tu envoies en production.\u201d</p><p><strong>[00:38:17.410]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> J\u2019ai tendance \u00e0 comparer \u00e7a \u00e0 une \u00e9volution de nos m\u00e9tiers. Il y a une vingtaine d\u2019ann\u00e9es, le d\u00e9veloppeur faisait tout, de l\u2019interface jusqu\u2019\u00e0 la gestion de la base de donn\u00e9es quasiment. Maintenant, on a des \u00e9quipes qui sont tr\u00e8s sp\u00e9cialis\u00e9es\u00a0: on a des d\u00e9veloppeurs front-end web, des d\u00e9veloppeurs mobile iOS / Android, des d\u00e9veloppeurs back-end, parfois on a m\u00eame des d\u00e9veloppeurs back-end Go / Python\u2026 Nos m\u00e9tiers ont \u00e9volu\u00e9. Par contre, les principes SRE sont communs \u00e0 tout le monde. On les applique de la m\u00eame mani\u00e8re pour quasiment toutes les \u00e9quipes\u200a\u2014\u200aou en tout cas, c\u2019est l\u2019objectif\u200a\u2014\u200aparce qu\u2019on veut les m\u00eames b\u00e9n\u00e9fices. Mais \u00e7a vient avec les m\u00eames inconv\u00e9nients, on va dire. Donc, effectivement, tous les corps de m\u00e9tier se sont vus avoir une \u00e9volution qui ne les concerne pas directement de prime abord, n\u00e9cessaire pour travailler dans des environnements comme celui de Deezer, pour pouvoir assurer la qualit\u00e9, la fiabilit\u00e9 et la s\u00e9curit\u00e9 notamment. Ce qui veut dire que dans une entreprise comme Deezer, qui doit g\u00e9rer une plateforme et une application tr\u00e8s complexes \u00e0 l\u2019\u00e9chelle humaine, il faut imp\u00e9rativement monter en comp\u00e9tence sur certains aspects. On parlait notamment de certains outils qui sont devenus h\u00e9g\u00e9moniques\u200a\u2014\u200aKubernetes en est un. On peut tout faire pour essayer de le rendre le plus facilement utilisable mais, comme je le disais, \u00e7a reste un langage commun avec les diff\u00e9rents niveaux d\u2019\u00e9quipes ou de personnes, et m\u00eame si l\u2019on peut faire de l\u2019abstraction, \u00e0 un moment donn\u00e9, \u00e7a restera le langage de discussion. L\u2019\u00e9quipe front-end, par exemple, va devoir d\u00e9ployer son application React, et pour la d\u00e9ployer et la rendre disponible \u00e0 des clients, \u00e0 un moment donn\u00e9, il faut la mettre sur des serveurs et il va falloir que l\u2019\u00e9quipe front-end parle avec les Ops pour dire\u00a0: \u201cO\u00f9 est-ce que je mets mon application\u00a0?\u201d \u201cTu utilises Kubernetes et tu as les outils pour le faire.\u201d \u00c7a veut dire qu\u2019il faut les apprendre, il faut les utiliser, alors m\u00eame que l\u2019on pourrait se dire qu\u2019un d\u00e9veloppeur front-end n\u2019a rien \u00e0 faire avec un serveur. Mais en fait, c\u2019est une approche qui est intrins\u00e8que \u00e0 son m\u00e9tier d\u2019aujourd\u2019hui. Certes, ce n\u2019\u00e9tait pas comme \u00e7a il y a vingt ans, maintenant, \u00e7a l\u2019est\u200a\u2014\u200aou en tout cas, \u00e7a l\u2019est dans des contextes tels que des applications comme Deezer. Ce qui veut aussi dire qu\u2019il y a des contextes qui ne n\u00e9cessitent pas tout \u00e7a. Le SRE n\u2019est\u00a0pas\u2026</p><p><strong>[00:40:35.380]\u200a\u2014\u200aDenis\u00a0: </strong>Ce n\u2019est pas une r\u00e9ponse universelle.</p><p><strong>[00:40:36.530]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Oui, voil\u00e0, c\u2019est \u00e7a. Il faut \u00e0 chaque fois l\u2019adapter et on ne peut pas mettre en place, par exemple, un Kubernetes pour une application monolithique avec cinq utilisateurs pour faire un site vitrine d\u2019une boucherie. Je pense que ce n\u2019est pas tr\u00e8s utile, pas forc\u00e9ment proportionn\u00e9. Par contre, si vous \u00eates une plateforme qui h\u00e9berge des sites web et que vous faites les sites de toutes les boucheries du monde, peut-\u00eatre que \u00e7a devient int\u00e9ressant et n\u00e9cessaire de l\u2019apprendre. J\u2019ai tendance \u00e0 comparer \u00e7a\u2026 Dans le pass\u00e9 du d\u00e9veloppeur, il y a un autre changement qui est devenu assez h\u00e9g\u00e9monique, c\u2019est celui de l\u2019utilisation de gestionnaires de code, et notamment d\u2019un gestionnaire de code en particulier. Il y a vingt ans, on uploadait nos fichiers, on avait des versions finales, des versions finales V2, etc., on envoyait tout \u00e7a par mail et par FTP. On a fait \u00e9voluer tout \u00e7a vers des gestionnaires de code comme SVN, CVS ou d\u2019autres. Aujourd\u2019hui, quoi qu\u2019on dise, il y en a un qui a gagn\u00e9, c\u2019est Git. Il est utilis\u00e9 partout et \u00e7a ne viendrait pas \u00e0 l\u2019id\u00e9e d\u2019un d\u00e9veloppeur Cobol, front-end ou PHP de dire\u00a0: \u201cNon, ce n\u2019est pas mon m\u00e9tier, je n\u2019ai pas \u00e0 apprendre Git.\u201d \u00c7a fait partie des outils. J\u2019ai besoin de conna\u00eetre un minimum Git pour pouvoir travailler en tant que d\u00e9veloppeur aujourd\u2019hui dans certains contextes. Si c\u2019est un projet perso, peut-\u00eatre que je n\u2019en ai pas besoin, mais dans le contexte professionnel, c\u2019est le\u00a0cas.</p><p><strong>[00:41:57.600]\u200a\u2014\u200aDenis\u00a0:</strong> Cet exemple est assez dr\u00f4le parce que cette critique de gens qui ne veulent pas apprendre Git, on la retrouve chez les op\u00e9rationnels, justement. Je vois un peu un parall\u00e8le\u2026 D\u2019une certaine mani\u00e8re, il y a les d\u00e9veloppeurs qui, avant, il y a tr\u00e8s longtemps, connaissaient tr\u00e8s bien l\u2019infrastructure puisque, comme tu le disais, ils \u00e9taient oblig\u00e9s de faire tout, de la cave au grenier. On s\u2019est ultra sp\u00e9cialis\u00e9. On a s\u00e9par\u00e9 les \u00e9quipes, d\u2019abord entre op\u00e9rationnels, puis apr\u00e8s d\u00e9veloppeurs. Et puis apr\u00e8s d\u00e9veloppeurs, c\u2019est devenu, comme tu dis, back-end, front-end, extr\u00eamement sp\u00e9cialis\u00e9. Du coup, parfois, il y a des d\u00e9veloppeurs\u200a\u2014\u200apas forc\u00e9ment chez Deezer\u200a\u2014\u200aqui disent\u00a0: \u201cNon, d\u00e9sol\u00e9, l\u2019infrastructure, ce n\u2019est pas mon boulot. Je n\u2019ai pas envie de savoir sur quel port tourne mon application.\u201d Au m\u00eame titre que moi, parfois, j\u2019entends aussi des op\u00e9rationnels dire\u00a0: \u201cNon, je ne vais pas apprendre Git, je ne suis pas d\u00e9veloppeur.\u201d En fait, si. On est dans un monde aujourd\u2019hui o\u00f9 savoir manier Git fait partie des comp\u00e9tences que l\u2019on attend aussi d\u2019un op\u00e9rationnel. Et \u00e0 l\u2019inverse, savoir manier les concepts basiques de l\u2019infrastructure, des cloud providers ou autre\u200a\u2014\u200aparce qu\u2019on a parl\u00e9 beaucoup de Kubernetes mais il y a d\u2019autres fa\u00e7ons de le faire\u200a\u2014\u200asont des choses qui sont aussi attendues des d\u00e9veloppeurs. Au moins de comprendre les concepts.</p><p><strong>[00:43:09.160]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> Et l\u2019\u00e9quipe SRE est l\u00e0 pour aider, en gros. On est l\u00e0 pour faire monter en comp\u00e9tence tous les d\u00e9veloppeurs ou toutes les personnes qui le souhaitent sur ces concepts-l\u00e0, de mani\u00e8re \u00e0 ce qu\u2019\u00e0 la fin, les d\u00e9veloppeurs aient les comp\u00e9tences suffisantes pour pouvoir dialoguer avec une personne Ops au sujet des outils techniques qu\u2019on utilise et des process qu\u2019on peut\u00a0avoir.</p><p><strong>[00:43:29.810]\u200a\u2014\u200aVincent\u00a0: </strong>Le mot-cl\u00e9, c\u2019est l\u2019accompagnement. \u00c0 la fois, on donne des guidelines, on essaie de donner des outils, etc. et en m\u00eame temps, il faut accompagner les gens pour les amener \u00e0 ce que l\u2019application tourne r\u00e9ellement, et faire en sorte que, petit \u00e0 petit, les \u00e9quipes soient de plus en plus autonomes pour le faire, leur donner les outils pour qu\u2019il y ait de moins en moins d\u2019adh\u00e9rence avec les \u00e9quipes plateformes, les SRE,\u00a0etc.</p><p><strong>[00:43:52.540]\u200a\u2014\u200aPauline\u00a0: </strong>Et justement, comment peut-on mesurer l\u2019impact d\u2019une \u00e9quipe SRE\u00a0?</p><p><strong>[00:43:56.920]\u200a\u2014\u200aDenis\u00a0: </strong>Si le site ne tombe pas trop souvent en panne\u00a0?</p><p><strong>[00:43:59.210]\u200a\u2014\u200aVincent\u00a0: </strong>C\u2019est \u00e7a\u00a0! Dans \u201cSRE\u201d, il y a \u201creliability\u201d.</p><p><strong>[00:44:02.070]\u200a\u2014\u200aDenis\u00a0: </strong>Au-del\u00e0 de la blague, si plus de choses sont automatis\u00e9es, si on a plus d\u2019indicateurs, si, quand le site tombe en panne, ce n\u2019est pas la panique parce que tout a \u00e9t\u00e9 document\u00e9, parce qu\u2019on a l\u2019habitude que \u00e7a tombe en panne, la fiabilit\u00e9 viendra derri\u00e8re. Mais globalement, les gens seront juste plus sereins. Alors, comment mesure-t-on le fait que les gens soient sereins\u00a0? Je ne vais pas \u00eatre capable de r\u00e9pondre\u00a0! Je ne pense pas que l\u2019on va pouvoir mettre un indicateur chiffr\u00e9. Mais comme je le disais, c\u2019est un cercle vertueux donc les choses ne font que s\u2019am\u00e9liorer si l\u2019on respecte ces principes-l\u00e0.</p><p><strong>[00:44:35.230]\u200a\u2014\u200aVincent\u00a0: </strong>Apr\u00e8s, il existe des m\u00e9triques qui essayent de montrer si l\u2019on va dans un bon sens ou pas. Ce sont les fameuses \u201c4 key metrics\u201d qui sont pouss\u00e9es par Google. Je ne vais pas forc\u00e9ment rentrer dans le d\u00e9tail maintenant parce qu\u2019on pourrait faire une \u00e9mission compl\u00e8te sur le sujet. Mais globalement, il y a des m\u00e9triques qui nous permettent de savoir si les envois en production sont fluides, le temps que \u00e7a prend et l\u2019impact que \u00e7a a quand c\u2019est mis en production, et quand il y a un incident, combien de temps il dure, en gros. \u00c0 partir de ces indicateurs-l\u00e0, on peut voir si on va dans un bon sens. Ce sont vraiment des indicateurs qui ont vocation \u00e0 \u00eatre l\u00e0 pour donner une esp\u00e8ce d\u2019\u00e9toile du Nord qu\u2019on essaie de\u00a0suivre.</p><p><strong>[00:45:11.860]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Il y a un autre indicateur qui est pas mal, qui est tr\u00e8s subjectif aussi, donc ce n\u2019est pas du tout mesurable. C\u2019est le fait que des \u00e9quipes s\u2019approprient l\u2019application sur tous les aspects. Avant, \u00e0 Deezer, quand il y avait un probl\u00e8me, comme tu le disais Denis, c\u2019\u00e9tait \u201cpanique \u00e0 bord\u201d. Et de toute fa\u00e7on, c\u2019\u00e9tait le probl\u00e8me des Ops. Donc il y avait une personne qui avait tendance \u00e0 faire un rollback ou un revert, et apr\u00e8s c\u2019\u00e9tait le probl\u00e8me des D\u00e9vs. Aujourd\u2019hui, on est pass\u00e9 \u00e0 un mode un peu diff\u00e9rent o\u00f9 les \u00e9quipes, d\u00e9j\u00e0, se rendent compte elles-m\u00eames qu\u2019il y a un probl\u00e8me parce qu\u2019il y a des alertes. On parlait de mesurer des choses et maintenant, les \u00e9quipes savent quand il y a un probl\u00e8me. Elles le savent bien souvent avant les Ops\u200a\u2014\u200ales Ops, parfois, ne le voient pas passer\u200a\u2014\u200aet elles sont capables de r\u00e9agir. Les \u00e9quipes vont, de mani\u00e8re totalement autonome, voir qu\u2019il y a un probl\u00e8me, l\u2019analyser, apporter une solution. La solution peut \u00eatre un rollback instantan\u00e9 ou \u00e7a peut \u00eatre \u201con prend le temps\u201d, justement vis-\u00e0-vis de ces questions d\u2019error budget. Parce que oui, on peut avoir un truc qui est cass\u00e9 en production, mais c\u2019est cass\u00e9 sur un petit bout\u2026 On peut prendre le temps\u200a\u2014\u200ale temps peut \u00eatre dix minutes, deux heures, \u00e7a d\u00e9pend\u200a\u2014\u200apour passer un fix, par exemple. L\u2019\u00e9quipe le fait toute seule. Il n\u2019y a plus besoin d\u2019avoir ni un SRE ni un Ops pour que l\u2019\u00e9quipe fasse tout ce travail-l\u00e0. Et on a d\u00e9j\u00e0 eu des situations o\u00f9 l\u2019on a d\u00fb dire, par exemple, aux Ops\u00a0: \u201cNon, laissez les \u00e9quipes, elles sont capables de le faire toutes seules. Vous n\u2019avez pas besoin, vous n\u2019avez plus besoin en tout cas, ni de les alerter, ni de leur mettre la pression.\u201d Parce que l\u2019\u00e9quipe va se mettre la pression qu\u2019elle doit se mettre toute seule vis-\u00e0-vis de ces notions d\u2019error budget et d\u2019indicateurs. Quelques \u00e9quipes ont \u00e9norm\u00e9ment chang\u00e9 \u00e0 Deezer, par exemple. Il y a des \u00e9quipes qui sont justement pass\u00e9es de ce mode absolument pas autonome \u00e0 compl\u00e8tement autonome. Et \u00e7a se voit dans la gestion de crise mais aussi dans la gestion de mises \u00e0 jour. On a quand m\u00eame beaucoup de PHP \u00e0 Deezer; il y a certains projets qui sont ce qu\u2019on appelle du \u201clegacy\u201d, qui sont tr\u00e8s compliqu\u00e9s \u00e0 mettre \u00e0 jour, notamment dans les mont\u00e9es de version de PHP en lui-m\u00eame et de certains grands frameworks qu\u2019on utilise, et il y a des \u00e9quipes qui sont capables de le faire toutes seules en une journ\u00e9e ou deux. Elles n\u2019ont besoin de personne. \u00c0 un moment donn\u00e9, c\u2019est\u00a0: \u201cAh, il y a une nouvelle version qui est sortie\u00a0!\u201d On communique entre nous parce qu\u2019on est dans la m\u00eame entreprise\u200a\u2014\u200ail y a un peu de fluidit\u00e9 de communication entre les \u00e9quipes\u200a\u2014\u200amais on voit tout de suite les \u00e9quipes qui ont r\u00e9ussi ce changement parce que deux jours apr\u00e8s\u00a0: \u201cOui, c\u2019est bon, on est sur la nouvelle version de PHP, \u00e7a tourne, c\u2019est en prod, il n\u2019y a pas de probl\u00e8me.\u201d Ou m\u00eame mieux\u00a0: \u201cOn a eu ce probl\u00e8me-l\u00e0, on vous le dit, n\u2019ayez pas le m\u00eame souci que nous.\u201d Et on en a quelques- unes comme \u00e7a \u00e0 Deezer maintenant.</p><p><strong>[00:47:45.260]\u200a\u2014\u200aSt\u00e9phane\u00a0: </strong>Vous avez fait une belle description du m\u00e9tier de SRE et du coup, ma question, c\u2019est\u00a0: comment devient-on SRE\u00a0?</p><p><strong>[00:47:52.900]\u200a\u2014\u200aDenis\u00a0:</strong> Si l\u2019on vient plut\u00f4t du monde op\u00e9rationnel, je pense que ce qui est important, c\u2019est d\u00e9j\u00e0 de s\u2019int\u00e9resser au code, notamment de ses d\u00e9veloppeurs. Il faut avoir cette app\u00e9tence pour le code, pour l\u2019outillage, l\u2019automatisation. Il va falloir tester, il va falloir apprendre. Il va falloir \u00eatre p\u00e9dagogue, empathique\u200a\u2014\u200aparce qu\u2019on ne rapproche pas les gens si l\u2019on n\u2019essaye pas de se mettre \u00e0 leur place. Voil\u00e0, p\u00e9dagogie, empathie, envie d\u2019apprendre et envie de transmettre. \u00c7a, c\u2019est plus pour ce qu\u2019on appelle les \u201csoft\u00a0skills\u201d.</p><p><strong>[00:48:27.940]\u200a\u2014\u200aVincent\u00a0:</strong> Quand on fait le chemin inverse, il y a beaucoup de choses qui sont un peu identiques. Comme tu le disais, il faut de l\u2019\u00e9coute, il faut de la curiosit\u00e9, il faut essayer de s\u2019int\u00e9resser \u00e0 l\u2019autre. C\u00f4t\u00e9 D\u00e9v, il faut avoir cette app\u00e9tence de vouloir savoir comment \u00e7a tourne sous le capot. C\u2019est vraiment l\u2019envie d\u2019ouvrir et de regarder, pas juste \u201cj\u2019envoie mon code et \u00e7a marche.\u201d C\u2019est \u201cOK, \u00e7a marche, mais pourquoi\u00a0?\u201d Moi qui suis un peu vieille \u00e9cole, comme vous le disiez, c\u2019\u00e9tait un peu mon mode de fonctionnement quand j\u2019ai commenc\u00e9. C\u2019est vrai que c\u2019est peut-\u00eatre moins vrai maintenant qu\u2019on se sp\u00e9cialise et je pense que c\u2019est vraiment ce crit\u00e8re-l\u00e0 qui fait qu\u2019on peut se lancer dans ce genre de poste de\u00a0SRE.</p><p><strong>[00:49:02.550]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Je pense que la cl\u00e9, c\u2019est la polyvalence\u200a\u2014\u200asans arriver \u00e0 la caricature d\u2019\u00eatre nul en tout\u00a0! Un SRE n\u2019est, pour moi, pas un sp\u00e9cialiste dans un truc en particulier. Il va avoir un domaine de pr\u00e9dilection. C\u2019est pour \u00e7a que l\u2019on a plusieurs profils ici\u00a0: on a des gens qui sont plus orient\u00e9s Ops, plus orient\u00e9s D\u00e9veloppeurs. Mais dans l\u2019id\u00e9e, on est en mesure de comprendre de mani\u00e8re assez fine le m\u00e9tier de l\u2019autre. \u00c7a veut dire qu\u2019on est potentiellement all\u00e9 s\u2019y frotter. Peut-\u00eatre pas directement\u200a\u2014\u200apersonnellement, je n\u2019ai jamais \u00e9t\u00e9 Ops, je n\u2019ai jamais eu la responsabilit\u00e9 de g\u00e9rer de l\u2019infrastructure de production d\u2019une entreprise mais je me suis int\u00e9ress\u00e9 sur comment \u00e7a marche et sur quels sont les outils qui sont mis en place, quelles sont notamment les contraintes, comment un Ops vit une astreinte\u2026 C\u2019est un truc tout b\u00eate mais je n\u2019ai jamais \u00e9t\u00e9 d\u2019astreinte, donc c\u2019est difficile pour moi de me repr\u00e9senter ce que c\u2019est que d\u2019\u00eatre d\u2019astreinte. C\u2019est quand m\u00eame avoir le droit de vie ou de mort quasiment instantan\u00e9 sur une plateforme. L\u2019objectif \u00e9tant de la faire vivre\u00a0!</p><p><strong>[00:50:07.520]\u200a\u2014\u200aVincent\u00a0: </strong>C\u2019est un peu comme quand tu es r\u00e9veill\u00e9 par ton b\u00e9b\u00e9 qui vient de na\u00eetre et qui demande son\u00a0biberon.</p><p><strong>[00:50:12.040]\u200a\u2014\u200aLo\u00efc\u00a0:</strong> Je ne suis pas parent donc je ne peux pas non plus\u00a0!</p><p><strong>[00:50:13.760]\u200a\u2014\u200aVincent\u00a0: </strong>Tu pourrais faire comme si tu n\u2019avais rien entendu, mais en g\u00e9n\u00e9ral, tu y vas\u00a0!</p><p><strong>[00:50:17.570]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>Voil\u00e0, en gros, c\u2019est avoir une capacit\u00e9, une empathie envers les autres m\u00e9tiers et s\u2019y int\u00e9resser. Je pense que l\u2019id\u00e9al, ce serait une personne qui soit aussi bien des deux c\u00f4t\u00e9s, mais c\u2019est un id\u00e9al de trajectoire plus qu\u2019une r\u00e9alit\u00e9\u200a\u2014\u200aparce que je pense que ce n\u2019est pas vraiment possible. C\u2019est cette id\u00e9e d\u2019\u00eatre capable de comprendre les deux mondes de mani\u00e8re suffisamment fine et profonde pour pouvoir, ensuite, l\u2019expliquer aux autres. Un peu comme quand on dit qu\u2019un professeur doit bien conna\u00eetre son sujet pour pouvoir l\u2019enseigner. C\u2019est un peu la m\u00eame chose. Quand on parle \u00e0 des d\u00e9veloppeurs, on a \u00e0 comprendre, un peu plus qu\u2019un d\u00e9veloppeur, l\u2019infrastructure\u200a\u2014\u200am\u00eame si l\u2019on n\u2019a pas besoin de comprendre l\u2019infrastructure au point d\u2019un Ops parce qu\u2019on n\u2019a pas non plus \u00e0 l\u2019enseigner \u00e0 un Ops, mais on a besoin d\u2019en savoir un peu plus pour avoir la capacit\u00e9 de dire des choses qui sont justes, tout en \u00e9tant p\u00e9dagogue.</p><p><strong>[00:51:08.610]\u200a\u2014\u200aPauline\u00a0: </strong>Eh bien merci\u00a0! Je pense que l\u2019on a fait un beau tour d\u2019horizon du SRE et on va maintenant passer \u00e0 la rubrique \u201cCoups de\u00a0c\u0153ur\u201d.</p><p><strong>[00:51:25.980]\u200a\u2014\u200aVincent\u00a0:</strong> Un titre que j\u2019ai \u00e9cout\u00e9 tr\u00e8s r\u00e9cemment et que j\u2019aime beaucoup\u2026 C\u2019est de l\u2019\u00e9lectronique, c\u2019est un artiste qui s\u2019appelle Spada, qui a sorti un titre qui s\u2019appelle <em>\u201cBeirut\u201d</em>, que je trouve tr\u00e8s sympa et que j\u2019\u00e9coute dans le m\u00e9tro en bougeant un peu. C\u2019est tr\u00e8s rythm\u00e9. C\u2019est le genre de rythme qui me fait vibrer en ce\u00a0moment.</p><p><strong>[00:51:46.390]\u200a\u2014\u200aDenis\u00a0:</strong> De mon c\u00f4t\u00e9, dans les d\u00e9couvertes que j\u2019ai faites il n\u2019y a pas longtemps, en cherchant la bande originale d\u2019un film\u200a\u2014\u200ade Kick Ass 2, pour dire le titre du film\u200a\u2014\u200aje suis tomb\u00e9 sur une track qui s\u2019appelle <em>\u201cKorobeiniki\u201d</em>. Il se trouve que c\u2019est le m\u00eame th\u00e8me que Tetris \u00e0 la guitare \u00e9lectrique. Sauf qu\u2019en fait, c\u2019est Tetris qui a repris une chanson traditionnelle russe qui s\u2019appelle <em>\u201cKorobeiniki\u201d</em>.</p><p><strong>[00:52:13.190]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>C\u2019est l\u2019origine de Tetris\u00a0!</p><p><strong>[00:52:14.830]\u200a\u2014\u200aDenis\u00a0: </strong>Exactement.</p><p><strong>[00:52:16.000]\u200a\u2014\u200aLo\u00efc\u00a0: </strong>D\u2019accord. Moi, d\u2019habitude, je partage plus du jazz, mais aujourd\u2019hui, je vais partager un artiste fran\u00e7ais, de la vari\u00e9t\u00e9 fran\u00e7aise. \u00c7a s\u2019appelle Oscar les vacances. C\u2019est un peu loufoque, un peu d\u00e9lire. Je vous recommande \u00e0 tous d\u2019aller \u00e9couter sur Deezer ce qu\u2019il\u00a0fait.</p><p><strong>[00:52:33.320]\u200a\u2014\u200aSt\u00e9phane\u00a0:</strong> Pour ma part, Flow m\u2019a pouss\u00e9 The Datsuns avec <em>\u201cSittin\u2019</em> <em>Pretty\u201d</em>. C\u2019est un titre qui bouge bien, qui est plut\u00f4t sympathique et que j\u2019adore en ce\u00a0moment.</p><p><strong>[00:52:41.640]\u200a\u2014\u200aPauline\u00a0:</strong> Et moi, je ne vais pas vous faire une reco de titre. Je vais faire une reco, ce sont mes \u201call-time favorite\u201d, comme on dit. C\u2019est un groupe qui s\u2019appelle White Lies, c\u2019est un groupe de rock anglais avec des influences post-punk. Tous leurs albums sont g\u00e9niaux, en particulier le premier\u200a\u2014\u200apour moi, il n\u2019y a rien \u00e0 jeter dedans. Le premier, c\u2019est <em>\u201cTo Lose My\u00a0Life\u201d</em>.</p><p><strong>[00:53:01.586]\u200a\u2014\u200aVincent\u00a0: </strong>Nice\u00a0!</p><p><strong>[00:53:01.820]\u200a\u2014\u200aPauline\u00a0:</strong> Voil\u00e0\u00a0! Merci \u00e0 tous les trois pour vos \u00e9clairages et vos partages d\u2019exp\u00e9rience, et on se retrouve bient\u00f4t pour un nouvel \u00e9pisode\u00a0!</p><p><strong>[00:53:10.010]\u200a\u2014\u200aVincent\u00a0: </strong>Vous venez d\u2019\u00e9couter un \u00e9pisode de Deez is la tech et nous esp\u00e9rons que vous avez pass\u00e9 un bon moment en notre compagnie. N\u2019h\u00e9sitez pas \u00e0 nous attribuer quelques \u00e9toiles si votre application de podcast le permet, et \u00e0 nous faire part de vos retours via les r\u00e9seaux sociaux et notre compte @DeezerDevs. Ceux-ci nous aideront \u00e0 am\u00e9liorer notre contenu afin de le rendre plus utile, enrichissant et plaisant \u00e0 \u00e9couter. Enfin, n\u2019oubliez pas que toutes les transcriptions de nos \u00e9pisodes, ainsi que les coups de c\u0153ur de nos invit\u00e9s, sont disponibles sur notre blog deezer.io. \u00c0 tr\u00e8s vite pour un nouvel \u00e9pisode et d\u2019ici l\u00e0, ne p\u00e9tez ni les plombs, ni les crons\u00a0!</p><h3>R\u00e9f\u00e9rences</h3><ul><li>Site Reliability Engineering\u00a0: <a href=\"https://en.wikipedia.org/wiki/Site_reliability_engineering\">Wikipedia</a></li><li>Livres sur le SRE par Google\u00a0: <a href=\"https://sre.google/books/\">SRE\u00a0books</a></li><li>DevOps\u00a0: <a href=\"https://en.wikipedia.org/wiki/DevOps\">Wikipedia</a></li><li><a href=\"https://teamtopologies.com/book\"><em>Team Topologies</em></a> de Matthew Skelton et Manuel\u00a0Pais</li><li><a href=\"https://prometheus.io/\">Prometheus</a>\u200a\u2014\u200atoolkit open-source de monitoring et d\u2019alerting syst\u00e8me)</li><li>Stack ELK\u00a0: <a href=\"https://www.elastic.co/fr/elasticsearch\">Elasticsearch</a>, <a href=\"https://www.elastic.co/fr/logstash\">Logstash</a> et <a href=\"https://www.elastic.co/fr/kibana\">Kibana</a>\u200a\u2014\u200asolutions open-source de monitoring et de gestion des\u00a0logs</li><li><a href=\"https://www.youtube.com/user/joueurdugrenier\">Le joueur du grenier</a> (cha\u00eene YouTube)\u200a\u2014\u200a<a href=\"https://joueur-du-grenier.fandom.com/fr/wiki/David_Goodenough\">David Goodenough</a></li><li><a href=\"https://kubernetes.io/fr/\">Kubernetes</a>\u200a\u2014\u200aplateforme open-source de gestion de workloads et de services conteneuris\u00e9s)</li><li><a href=\"https://www.docker.com/\">Docker</a>\u200a\u2014\u200aplateforme permettant aux d\u00e9veloppeurs de concevoir, partager et d\u00e9ployer des applications \u00e0 l\u2019aide de conteneurs | <a href=\"https://docs.docker.com/engine/reference/builder/\">Dockerfile</a></li><li><a href=\"https://heartbleed.com/\">Vuln\u00e9rabilit\u00e9 Heartbleed</a></li><li>Vuln\u00e9rabilit\u00e9 Log4j\u00a0: <a href=\"https://en.wikipedia.org/wiki/Log4Shell\">Wikipedia</a></li><li><a href=\"https://git-scm.com/\">Git</a>\u200a\u2014\u200alogiciel open-source de gestion de versions d\u00e9centralis\u00e9</li><li>Coups de coeur\u00a0:<br />- \u201c<a href=\"https://deezer.page.link/nsNj7PyYoRXZrTGR9\"><em>Beirut</em></a>\u201d de Spada &amp; Mardra\u00fcs<br />- \u201c<a href=\"https://deezer.page.link/4vWCwtDjf3EUVfmC8\"><em>Korobeiniki</em></a>\u201d de Ozma<br />- <a href=\"https://deezer.page.link/b79ZwJowWvSuVkM36\">Oscar les vacances</a><br />- \u201c<a href=\"https://deezer.page.link/nRPqgedPAH56uGkj8\"><em>Sittin\u2019 Pretty</em></a>\u201d de The Datsuns<br />- <em>\u201c</em><a href=\"https://deezer.page.link/R5S7mr998sT25ZKA9\"><em>To Lose My Life</em></a><em>\u201d</em> de White\u00a0Lies</li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7a45e4bdd1f3\" width=\"1\" /><hr /><p><a href=\"https://deezer.io/deez-is-la-tech-s02e02-en-t%C3%AAte-%C3%A0-t%C3%AAte-avec-des-sre-missions-quotidien-et-challenges-7a45e4bdd1f3\">Deez is la tech\u200a\u2014\u200aS02E02\u200a\u2014\u200aEn t\u00eate-\u00e0-t\u00eate avec des SRE\u00a0: missions, quotidien et challenges</a> was originally published in <a href=\"https://deezer.io\">Deezer I/O</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Mozilla Release Engineering": {
    "title": "Making pip installations faster with wheel",
    "xmlUrl": "http://planet.mozilla.org/releng/atom.xml",
    "htmlUrl": "https://planet.mozilla.org/releng/",
    "id": "https://medium.com/p/e41bed129993",
    "guidislink": true,
    "link": "https://armenzg.medium.com/making-pip-installations-faster-with-wheel-e41bed129993?source=rss-d4d8839a88ef------2",
    "links": [
      {
        "href": "https://armenzg.medium.com/making-pip-installations-faster-with-wheel-e41bed129993?source=rss-d4d8839a88ef------2",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://planet.mozilla.org/releng/atom.xml",
      "value": "Making pip installations faster with wheel"
    },
    "content": [
      {
        "type": "application/xhtml+xml",
        "language": null,
        "base": "https://planet.mozilla.org/releng/atom.xml",
        "value": "<p>I recently noticed the following message in Sentry\u2019s pip installation step:</p><blockquote>Using legacy \u2018setup.py install\u2019 for openapi-core, since package \u2018wheel\u2019 is not installed.</blockquote><p>Upon some investigation, I noticed that the package <a href=\"https://pypi.org/project/wheel/\">wheel</a> was not being installed. After making <a href=\"https://github.com/getsentry/sentry/commit/d830eb47b4c60ae45994464e157587b5880cce53\">some changes</a>, I can now guarantee that our development environment installs it by default and it\u2019s given us about 40\u201350% speed\u00a0gain.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CemfvXzbNdKZu80G7cHFRA.png\" />&lt;figcaption&gt;Timings from before and after installing wheel&lt;/figcaption&gt;</figure><p>The screenshot above shows the steps from two different Github workflows; it installs Sentry\u2019s Python packages inside of a fresh virtualenv and the pip cache is available.</p><p>If you see a message saying that wheelpackage is not installed, make sure to attend to\u00a0it!</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e41bed129993\" width=\"1\" />"
      }
    ],
    "summary": "<p>I recently noticed the following message in Sentry\u2019s pip installation step:</p><blockquote>Using legacy \u2018setup.py install\u2019 for openapi-core, since package \u2018wheel\u2019 is not installed.</blockquote><p>Upon some investigation, I noticed that the package <a href=\"https://pypi.org/project/wheel/\">wheel</a> was not being installed. After making <a href=\"https://github.com/getsentry/sentry/commit/d830eb47b4c60ae45994464e157587b5880cce53\">some changes</a>, I can now guarantee that our development environment installs it by default and it\u2019s given us about 40\u201350% speed\u00a0gain.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CemfvXzbNdKZu80G7cHFRA.png\" />&lt;figcaption&gt;Timings from before and after installing wheel&lt;/figcaption&gt;</figure><p>The screenshot above shows the steps from two different Github workflows; it installs Sentry\u2019s Python packages inside of a fresh virtualenv and the pip cache is available.</p><p>If you see a message saying that wheelpackage is not installed, make sure to attend to\u00a0it!</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e41bed129993\" width=\"1\" />",
    "updated": "2021-02-18T16:24:18Z",
    "updated_parsed": [
      2021,
      2,
      18,
      16,
      24,
      18,
      3,
      49,
      0
    ],
    "published": "2021-02-18T16:24:18Z",
    "published_parsed": [
      2021,
      2,
      18,
      16,
      24,
      18,
      3,
      49,
      0
    ],
    "tags": [
      {
        "term": "python",
        "scheme": null,
        "label": null
      },
      {
        "term": "developer-tools",
        "scheme": null,
        "label": null
      },
      {
        "term": "pip",
        "scheme": null,
        "label": null
      },
      {
        "term": "sentryio",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Armen Zambrano"
      }
    ],
    "author_detail": {
      "name": "Armen Zambrano"
    },
    "author": "Armen Zambrano",
    "source": {
      "id": "https://medium.com/@armenzg?source=rss-d4d8839a88ef------2",
      "guidislink": true,
      "link": "https://medium.com/@armenzg?source=rss-d4d8839a88ef------2",
      "logo": "https://cdn-images-1.medium.com/fit/c/150/150/1*gOZWu3-dbYJt8Bd72C7Gkw.jpeg",
      "links": [
        {
          "href": "https://medium.com/@armenzg?source=rss-d4d8839a88ef------2",
          "rel": "alternate",
          "type": "text/html"
        },
        {
          "href": "https://medium.com/@armenzg/feed",
          "rel": "self",
          "type": "application/rss+xml"
        },
        {
          "href": "http://medium.superfeedr.com",
          "rel": "hub",
          "type": "text/html"
        }
      ],
      "subtitle": "Stories by Armen Zambrano on Medium",
      "subtitle_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://planet.mozilla.org/releng/atom.xml",
        "value": "Stories by Armen Zambrano on Medium"
      },
      "title": "Stories by Armen Zambrano on Medium",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://planet.mozilla.org/releng/atom.xml",
        "value": "Stories by Armen Zambrano on Medium"
      },
      "updated": "2024-01-07T05:30:48Z",
      "updated_parsed": [
        2024,
        1,
        7,
        5,
        30,
        48,
        6,
        7,
        0
      ]
    }
  },
  "AdRoll": {
    "title": "Celebrating Innovation - NextRoll's Hack Week 2023 H2 Winners",
    "xmlUrl": "http://tech.adroll.com/feed.xml",
    "htmlUrl": "http://tech.adroll.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.nextroll.com/feed.xml",
      "value": "Celebrating Innovation - NextRoll's Hack Week 2023 H2 Winners"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.nextroll.com/blog/hackweek/2023/09/15/hack-week.html"
      }
    ],
    "link": "https://tech.nextroll.com/blog/hackweek/2023/09/15/hack-week.html",
    "published": "Fri, 15 Sep 2023 00:00:00 -0700",
    "published_parsed": [
      2023,
      9,
      15,
      7,
      0,
      0,
      4,
      258,
      0
    ],
    "authors": [
      {}
    ],
    "author": "",
    "id": "https://tech.nextroll.com/blog/hackweek/2023/09/15/hack-week",
    "guidislink": false,
    "summary": "<p>NextRoll\u2019s Hack Week 2023 was a week filled with ingenuity, collaboration, and groundbreaking ideas. From AI-powered solutions to production optimization, our teams went above and beyond to showcase their talents. Without further ado, let\u2019s dive into the winning projects!</p>\n\n<h1 id=\"aiml-award-the-future-is-now\">AI/ML Award: The Future is Now!</h1>\n\n<h3 id=\"smartdoc\">SmartDoc</h3>\n<p><strong>Winners: Federico Della Rovere, Lorenzo Savini</strong></p>\n\n<p>SmartDoc is more than an AI-powered document management system. By leveraging machine learning, it categorizes, sorts, and manages documents with unprecedented accuracy, significantly reducing manual labor and improving data retrieval processes. This innovation is a step forward in automating administrative tasks, allowing teams to focus on more strategic activities.</p>\n\n<p><img alt=\"SmartDoc\" src=\"https://tech.nextroll.com/images/post_images/smartdoc.png\" /></p>\n\n<h2 id=\"product-award-figma-plugin-for-ad-production-optimization\">Product Award: Figma Plugin for Ad Production Optimization</h2>\n<p><strong>Winners: Jake Burroughs, Jose Hernandez, Joris Korbee, Aasif Shabbir, Eurico Nicacio</strong></p>\n\n<p>This Figma Plugin transforms ad production by enabling the generation of HTML5 ads in formats beyond the standard sizes. Its AI-supported animated ad templates not only enhance creativity but also speed up the production process, offering our clients more variety and quicker turnaround times. This is a significant leap in ad customization and efficiency.</p>\n\n<p><img alt=\"HTML5 Ad Generator Figma Plugin\" src=\"https://tech.nextroll.com/images/post_images/figma_plugin.png\" /></p>\n\n<h2 id=\"technical-award-puertagma\">Technical Award: Puertagma</h2>\n<p><strong>Winners: Oscar Arbelaez, Peter Kuimelis, Cristian Rojas, Christopher Ramirez, Alvaro Tuso</strong></p>\n\n<p>Puertagma is not just another API. It\u2019s the culmination of our learnings from past projects, crafted into a robust and efficient tool. Written in Go, this API is set to become the backbone of our future integrations, promising enhanced performance and scalability. This project represents a significant stride in our technical capabilities, paving the way for more seamless and powerful integrations.</p>\n\n<p>Congratulations to all the winners and participants! Your hard work, innovative thinking, and focus on impactful solutions are what continue to drive NextRoll forward as a leader in the ad tech industry.</p>\n\n<p><img alt=\"Puertagma\" src=\"https://tech.nextroll.com/images/post_images/puertagma.png\" /></p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://tech.nextroll.com/feed.xml",
      "value": "<p>NextRoll\u2019s Hack Week 2023 was a week filled with ingenuity, collaboration, and groundbreaking ideas. From AI-powered solutions to production optimization, our teams went above and beyond to showcase their talents. Without further ado, let\u2019s dive into the winning projects!</p>\n\n<h1 id=\"aiml-award-the-future-is-now\">AI/ML Award: The Future is Now!</h1>\n\n<h3 id=\"smartdoc\">SmartDoc</h3>\n<p><strong>Winners: Federico Della Rovere, Lorenzo Savini</strong></p>\n\n<p>SmartDoc is more than an AI-powered document management system. By leveraging machine learning, it categorizes, sorts, and manages documents with unprecedented accuracy, significantly reducing manual labor and improving data retrieval processes. This innovation is a step forward in automating administrative tasks, allowing teams to focus on more strategic activities.</p>\n\n<p><img alt=\"SmartDoc\" src=\"https://tech.nextroll.com/images/post_images/smartdoc.png\" /></p>\n\n<h2 id=\"product-award-figma-plugin-for-ad-production-optimization\">Product Award: Figma Plugin for Ad Production Optimization</h2>\n<p><strong>Winners: Jake Burroughs, Jose Hernandez, Joris Korbee, Aasif Shabbir, Eurico Nicacio</strong></p>\n\n<p>This Figma Plugin transforms ad production by enabling the generation of HTML5 ads in formats beyond the standard sizes. Its AI-supported animated ad templates not only enhance creativity but also speed up the production process, offering our clients more variety and quicker turnaround times. This is a significant leap in ad customization and efficiency.</p>\n\n<p><img alt=\"HTML5 Ad Generator Figma Plugin\" src=\"https://tech.nextroll.com/images/post_images/figma_plugin.png\" /></p>\n\n<h2 id=\"technical-award-puertagma\">Technical Award: Puertagma</h2>\n<p><strong>Winners: Oscar Arbelaez, Peter Kuimelis, Cristian Rojas, Christopher Ramirez, Alvaro Tuso</strong></p>\n\n<p>Puertagma is not just another API. It\u2019s the culmination of our learnings from past projects, crafted into a robust and efficient tool. Written in Go, this API is set to become the backbone of our future integrations, promising enhanced performance and scalability. This project represents a significant stride in our technical capabilities, paving the way for more seamless and powerful integrations.</p>\n\n<p>Congratulations to all the winners and participants! Your hard work, innovative thinking, and focus on impactful solutions are what continue to drive NextRoll forward as a leader in the ad tech industry.</p>\n\n<p><img alt=\"Puertagma\" src=\"https://tech.nextroll.com/images/post_images/puertagma.png\" /></p>"
    }
  },
  "Cloudflare": {
    "title": "DDoS threat report for 2023 Q4",
    "xmlUrl": "https://blog.cloudflare.com/rss/",
    "htmlUrl": "https://blog.cloudflare.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.cloudflare.com/rss",
      "value": "DDoS threat report for 2023 Q4"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.cloudflare.com/ddos-threat-report-2023-q4"
      }
    ],
    "link": "https://blog.cloudflare.com/ddos-threat-report-2023-q4",
    "published": "Tue, 09 Jan 2024 14:00:25 GMT",
    "published_parsed": [
      2024,
      1,
      9,
      14,
      0,
      25,
      1,
      9,
      0
    ],
    "summary": "Welcome to the sixteenth edition of Cloudflare\u2019s DDoS Threat Report. This edition covers DDoS trends and key findings for the fourth and final quarter of the year 2023, complete with a review of major trends throughout the year",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.cloudflare.com/rss",
      "value": "Welcome to the sixteenth edition of Cloudflare\u2019s DDoS Threat Report. This edition covers DDoS trends and key findings for the fourth and final quarter of the year 2023, complete with a review of major trends throughout the year"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.cloudflare.com/rss",
        "value": "<p><small>This post is also available in <a>\u7b80\u4f53\u4e2d\u6587</a>, <a>Deutsch</a>, <a>Espa\u00f1ol</a>, <a>Fran\u00e7ais</a> and <a>Portugu\u00eas</a>.</small></p>\n<figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/image14-1.png\" /></figure><p>Welcome to the sixteenth edition of Cloudflare\u2019s DDoS Threat Report. This edition covers DDoS trends and key findings for the fourth and final quarter of the year 2023, complete with a review of major trends throughout the year.</p><h2>What are DDoS attacks?</h2><p>DDoS attacks, or <a>distributed denial-of-service attacks</a>, are a type of cyber attack that aims to disrupt websites and online services for users, making them unavailable by overwhelming them with more traffic than they can handle. They are similar to car gridlocks that jam roads, preventing drivers from getting to their destination.</p><p>There are three main types of DDoS attacks that we will cover in this report. The first is an <a>HTTP request</a> intensive DDoS attack that aims to overwhelm HTTP servers with more requests than they can handle to cause a denial of service event. The second is an <a>IP packet</a> intensive DDoS attack that aims to overwhelm in-line appliances such as routers, firewalls, and servers with more packets than they can handle. The third is a bit-intensive attack that aims to saturate and clog the Internet link causing that \u2018gridlock\u2019 that we discussed. In this report, we will highlight various techniques and insights on all three types of attacks.</p><p>Previous editions of the report can be found <a>here</a>, and are also available on our interactive hub, <a>Cloudflare Radar</a>. Cloudflare Radar showcases global Internet traffic, attacks, and technology trends and insights, with drill-down and filtering capabilities for zooming in on insights of specific countries, industries, and service providers. Cloudflare Radar also offers a <a>free API</a> allowing academics, data sleuths, and other web enthusiasts to investigate Internet usage across the globe.</p><p>To learn how we prepare this report, refer to our <a>Methodologies</a>.</p><h2>Key findings</h2><ol><li>In Q4, we observed a 117% year-over-year increase in network-layer DDoS attacks, and overall increased DDoS activity targeting retail, shipment and public relations websites during and around Black Friday and the holiday season.</li><li>In Q4, DDoS attack traffic targeting Taiwan registered a 3,370% growth, compared to the previous year, amidst the upcoming general election and reported tensions with China. The percentage of DDoS attack traffic targeting Israeli websites grew by 27% quarter-over-quarter, and the percentage of DDoS attack traffic targeting Palestinian websites grew by 1,126% quarter-over-quarter \u2014 as the military conflict between Israel and Hamas continues.</li><li>In Q4, there was a staggering 61,839% surge in DDoS attack traffic targeting Environmental Services websites compared to the previous year, coinciding with the 28th United Nations Climate Change Conference (COP 28).</li></ol><p>For an in-depth analysis of these key findings and additional insights that could redefine your understanding of current cybersecurity challenges, read on!</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/image1.png\" /><figcaption>Illustration of a DDoS attack</figcaption></figure><h2>Hyper-volumetric HTTP DDoS attacks</h2><p>2023 was the year of uncharted territories. DDoS attacks reached new heights \u2014 in size and sophistication. The wider Internet community, including Cloudflare, faced a persistent and deliberately engineered campaign of thousands of hyper-volumetric DDoS attacks at never before seen rates.</p><p>These attacks were highly complex and exploited an <a>HTTP/2 vulnerability</a>. Cloudflare developed purpose-built technology to mitigate the vulnerability\u2019s effect and worked with others in the industry to responsibly disclose it.</p><p>As part of this DDoS campaign, in Q3 our systems mitigated the largest attack we\u2019ve ever seen \u2014 201 million requests per second (rps). That\u2019s almost 8 times larger than our previous 2022 record of 26 million rps.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0.png\" /><figcaption>Largest HTTP DDoS attacks as seen by Cloudflare, by year</figcaption></figure><h2>Growth in network-layer DDoS attacks</h2><p>After the hyper-volumetric campaign subsided, we saw an unexpected drop in HTTP DDoS attacks. Overall in 2023, our automated defenses mitigated over 5.2 million HTTP DDoS attacks consisting of over 26 trillion requests. That averages at 594 HTTP DDoS attacks and 3 billion mitigated requests every hour.</p><p>Despite these astronomical figures, the amount of HTTP DDoS attack requests actually declined by 20% compared to 2022. This decline was not just annual but was also observed in 2023 Q4 where the number of HTTP DDoS attack requests decreased by 7% YoY and 18% QoQ.</p><p>On the network-layer, we saw a completely different trend. Our automated defenses mitigated 8.7 million network-layer DDoS attacks in 2023. This represents an 85% increase compared to 2022.</p><p>In 2023 Q4, Cloudflare\u2019s automated defenses mitigated over 80 petabytes of network-layer attacks. On average, our systems auto-mitigated 996 network-layer DDoS attacks and 27 terabytes every hour. The number of network-layer DDoS attacks in 2023 Q4 increased by 175% YoY and 25% QoQ.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/HTTP-and-Network-layer-DDoS-attacks-by-quarter-1.png\" /><figcaption>HTTP and Network-layer DDoS attacks by quarter</figcaption></figure><h3>DDoS attacks increase during and around COP 28</h3><p>In the final quarter of 2023, the landscape of cyber threats witnessed a significant shift. While the Cryptocurrency sector was initially leading in terms of the volume of HTTP DDoS attack requests, a new target emerged as a primary victim. The Environmental Services industry experienced an unprecedented surge in HTTP DDoS attacks, with these attacks constituting half of all its HTTP traffic. This marked a staggering 618-fold increase compared to the previous year, highlighting a disturbing trend in the cyber threat landscape.</p><p>This surge in cyber attacks coincided with COP 28, which ran from November 30th to December 12th, 2023. The conference was a pivotal event, signaling what many considered the <a>'beginning of the end' for the fossil fuel era</a>. It was observed that in the period leading up to COP 28, there was a noticeable spike in HTTP attacks targeting Environmental Services websites. This pattern wasn't isolated to this event alone.</p><p>Looking back at historical data, particularly during COP 26 and COP 27, as well as other UN environment-related resolutions or announcements, a similar pattern emerges. Each of these events was accompanied by a corresponding increase in cyber attacks aimed at Environmental Services websites.</p><p>In February and March 2023, significant environmental events like the UN's resolution on <a>climate justice</a> and the launch of United Nations Environment Programme\u2019s <a>Freshwater Challenge</a> potentially heightened the profile of environmental websites, possibly correlating with an increase in attacks on these sites\u200b\u200b\u200b\u200b.</p><p>This recurring pattern underscores the growing intersection between environmental issues and cyber security, a nexus that is increasingly becoming a focal point for attackers in the digital age.</p><h2>DDoS attacks and Iron Swords</h2><p>It\u2019s not just UN resolutions that trigger DDoS attacks. Cyber attacks, and particularly DDoS attacks, have long been a tool of war and disruption. We witnessed an increase in DDoS attack activity in the Ukraine-Russia war, and now we\u2019re also witnessing it in the Israel-Hamas war. We first reported the cyber activity in our report <a>Cyber attacks in the Israel-Hamas war</a>, and we continued to monitor the activity throughout Q4.</p><p>Operation \u201cIron Swords\u201d is the <a>military offensive launched by Israel against Hamas</a> following the <a>Hamas-led 7 October attack</a>. During this ongoing armed conflict, we continue to see DDoS attacks targeting both sides.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--1-.png\" /><figcaption>DDoS attacks targeting Israeli and Palestinian websites, by industry</figcaption></figure><p>Relative to each region's traffic, the Palestinian territories was the second most attacked region by HTTP DDoS attacks in Q4. Over 10% of all HTTP requests towards Palestinian websites were DDoS attacks, a total of 1.3 billion DDoS requests \u2014 representing a 1,126% increase in QoQ. 90% of these DDoS attacks targeted Palestinian Banking websites. Another 8% targeted Information Technology and Internet platforms.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--2-.png\" /><figcaption>Top attacked Palestinian industries</figcaption></figure><p>Similarly, our systems automatically mitigated over 2.2 billion HTTP DDoS requests targeting Israeli websites. While 2.2 billion represents a decrease compared to the previous quarter and year, it did amount to a larger percentage out of the total Israel-bound traffic. This normalized figure represents a 27% increase QoQ but a 92% decrease YoY. Notwithstanding the larger amount of attack traffic, Israel was the 77th most attacked region relative to its own traffic. It was also the 33rd most attacked by total volume of attacks, whereas the Palestinian territories was 42nd.</p><p>Of those Israeli websites attacked, Newspaper &amp; Media were the main target \u2014 receiving almost 40% of all Israel-bound HTTP DDoS attacks. The second most attacked industry was the Computer Software industry. The Banking, Financial Institutions, and Insurance (BFSI) industry came in third.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--3-.png\" /><figcaption>Top attacked Israeli industries</figcaption></figure><p>On the network layer, we see the same trend. Palestinian networks were targeted by 470 terabytes of attack traffic \u2014 accounting for over 68% of all traffic towards Palestinian networks. Surpassed only by China, this figure placed the Palestinian territories as the second most attacked region in the world, by network-layer DDoS attack, relative to all Palestinian territories-bound traffic. By absolute volume of traffic, it came in third. Those 470 terabytes accounted for approximately 1% of all DDoS traffic that Cloudflare mitigated.</p><p>Israeli networks, though, were targeted by only 2.4 terabytes of attack traffic, placing it as the 8th most attacked country by network-layer DDoS attacks (normalized). Those 2.4 terabytes accounted for almost 10% of all traffic towards Israeli networks.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--5-.png\" /><figcaption>Top attacked countries</figcaption></figure><p>When we turned the picture around, we saw that 3% of all bytes that were ingested in our Israeli-based data centers were network-layer DDoS attacks. In our Palestinian-based data centers, that figure was significantly higher \u2014 approximately 17% of all bytes.</p><p>On the application layer, we saw that 4% of HTTP requests originating from Palestinian IP addresses were DDoS attacks, and almost 2% of HTTP requests originating from Israeli IP addresses were DDoS attacks as well.</p><h2>Main sources of DDoS attacks</h2><p>In the third quarter of 2022, China was the largest source of HTTP DDoS attack traffic. However, since the fourth quarter of 2022, the US took the first place as the largest source of HTTP DDoS attacks and has maintained that undesirable position for five consecutive quarters. Similarly, our data centers in the US are the ones ingesting the most network-layer DDoS attack traffic \u2014 over 38% of all attack bytes.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/imageLikeEmbed.png\" /><figcaption>HTTP DDoS attacks originating from China and the US by quarter</figcaption></figure><p>Together, China and the US account for a little over a quarter of all HTTP DDoS attack traffic in the world. Brazil, Germany, Indonesia, and Argentina account for the next twenty-five percent.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--6-.png\" /><figcaption>Top source of HTTP DDoS attacks</figcaption></figure><p>These large figures usually correspond to large markets. For this reason, we also normalize the attack traffic originating from each country by comparing their outbound traffic. When we do this, we often get small island nations or smaller market countries that a disproportionate amount of attack traffic originates from. In Q4, 40% of Saint Helena\u2019s outbound traffic were HTTP DDoS attacks \u2014 placing it at the top. Following the \u2018<a>remote volcanic tropical island</a>\u2019, Libya came in second, <a>Swaziland</a> (also known as Eswatini) in third. Argentina and Egypt follow in fourth and fifth place.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--7-.png\" /><figcaption>Top source of HTTP DDoS attacks with respect to each country\u2019s traffic</figcaption></figure><p>On the network layer, Zimbabwe came in first place. Almost 80% of all traffic we ingested in our Zimbabwe-based data center was malicious. In second place, Paraguay, and Madagascar in third.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--8-.png\" /><figcaption>Top source of Network-layer DDoS attacks with respect to each country\u2019s traffic</figcaption></figure><h2>Most attacked industries</h2><p>By volume of attack traffic, Cryptocurrency was the most attacked industry in Q4. Over 330 billion HTTP requests targeted it. This figure accounts for over 4% of all HTTP DDoS traffic for the quarter. The second most attacked industry was Gaming &amp; Gambling. These industries are known for being coveted targets and attract a lot of traffic and attacks.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--9-.png\" /><figcaption>Top industries targeted by HTTP DDoS attacks</figcaption></figure><p>On the network layer, the Information Technology and Internet industry was the most attacked \u2014 over 45% of all network-layer DDoS attack traffic was aimed at it. Following far behind were the Banking, Financial Services and Insurance (BFSI), Gaming &amp; Gambling, and Telecommunications industries.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--10-.png\" /><figcaption>Top industries targeted by Network-layer DDoS attacks</figcaption></figure><p>To change perspectives, here too, we normalized the attack traffic by the total traffic for a specific industry. When we do that, we get a different picture.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/Top-Attacked-Industry-by-Region-Q4-2023.png\" /><figcaption>Top attacked industries by HTTP DDoS attacks, by region</figcaption></figure><p>We already mentioned in the beginning of this report that the Environmental Services industry was the most attacked relative to its own traffic. In second place was the Packaging and Freight Delivery industry, which is interesting because of its timely correlation with online shopping during Black Friday and the winter holiday season. Purchased gifts and goods need to get to their destination somehow, and it seems as though attackers tried to interfere with that. On a similar note, DDoS attacks on retail companies increased by 16% compared to the previous year.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--11-.png\" /><figcaption>Top industries targeted by HTTP DDoS attacks with respect to each industry\u2019s traffic</figcaption></figure><p>On the network layer, Public Relations and Communications was the most targeted industry \u2014 36% of its traffic was malicious. This too is very interesting given its timing. Public Relations and Communications companies are usually linked to managing public perception and communication. Disrupting their operations can have immediate and widespread reputational impacts which becomes even more critical during the Q4 holiday season. This quarter often sees increased PR and communication activities due to holidays, end-of-year summaries, and preparation for the new year, making it a critical operational period \u2014 one that some may want to disrupt.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--12-.png\" /><figcaption>Top industries targeted by Network-layer DDoS attacks with respect to each industry\u2019s traffic</figcaption></figure><h2>Most attacked countries and regions</h2><p>Singapore was the main target of HTTP DDoS attacks in Q4. Over 317 billion HTTP requests, 4% of all global DDoS traffic, were aimed at Singaporean websites. The US followed closely in second and Canada in third. Taiwan came in as the fourth most attacked region \u2014 amidst the upcoming <a>general elections and the tensions with China</a>. Taiwan-bound attacks in Q4 traffic increased by 847% compared to the previous year, and 2,858% compared to the previous quarter. This increase is not limited to the absolute values. When normalized, the percentage of HTTP DDoS attack traffic targeting Taiwan relative to all Taiwan-bound traffic also significantly increased. It increased by 624% quarter-over-quarter and 3,370% year-over-year.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--13-.png\" /><figcaption>Top targeted countries by HTTP DDoS attacks</figcaption></figure><p>While China came in as the ninth most attacked country by HTTP DDoS attacks, it's the number one most attacked country by network-layer attacks. 45% of all network-layer DDoS traffic that Cloudflare mitigated globally was China-bound. The rest of the countries were so far behind that it is almost negligible.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--14-.png\" /><figcaption>Top targeted countries by Network-layer DDoS attacks</figcaption></figure><p>When normalizing the data, Iraq, Palestinian territories, and Morocco take the lead as the most attacked regions with respect to their total inbound traffic. What\u2019s interesting is that Singapore comes up as fourth. So not only did Singapore face the largest amount of HTTP DDoS attack traffic, but that traffic also made up a significant amount of the total Singapore-bound traffic. By contrast, the US was second most attacked by volume (per the application-layer graph above), but came in the fiftieth place with respect to the total US-bound traffic.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--15-.png\" /><figcaption>Top targeted countries by HTTP DDoS attacks with respect to each country\u2019s traffic</figcaption></figure><p>Similar to Singapore, but arguably more dramatic, China is both the number one most attacked country by network-layer DDoS attack traffic, and also with respect to all China-bound traffic. Almost 86% of all China-bound traffic was mitigated by Cloudflare as network-layer DDoS attacks. The Palestinian territories, Brazil, Norway, and again Singapore followed with large percentages of attack traffic.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--16-.png\" /><figcaption>Top targeted countries by Network-layer DDoS attacks with respect to each country\u2019s traffic</figcaption></figure><h2>Attack vectors and attributes</h2><p>The majority of DDoS attacks are short and small relative to Cloudflare\u2019s scale. However, unprotected websites and networks can still suffer disruption from short and small attacks without proper inline automated protection \u2014 underscoring the need for organizations to be proactive in adopting a robust security posture.</p><p>In 2023 Q4, 91% of attacks ended within 10 minutes, 97% peaked below 500 megabits per second (mbps), and 88% never exceeded 50 thousand packets per second (pps).</p><p>Two out of every 100 network-layer DDoS attacks lasted more than an hour, and exceeded 1 gigabit per second (gbps). One out of every 100 attacks exceeded 1 million packets per second. Furthermore, the amount of network-layer DDoS attacks exceeding 100 million packets per second increased by 15% quarter-over-quarter.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/DDoS-attacks-stats-2023-Q4_a.png\" /><figcaption>DDoS attack stats you should know</figcaption></figure><p>One of those large attacks was a Mirai-botnet attack that peaked at 160 million packets per second. The packet per second rate was not the largest we\u2019ve ever seen. The largest we\u2019ve ever seen was <a>754 million packets per second</a>. That attack occurred in 2020, and we have yet to see anything larger.</p><p>This more recent attack, though, was unique in its bits per second rate. This was the largest network-layer DDoS attack we\u2019ve seen in Q4. It peaked at 1.9 terabits per second and originated from a <a>Mirai botnet</a>. It was a multi-vector attack, meaning it combined multiple attack methods. Some of those methods included UDP fragments flood, UDP/Echo flood, SYN Flood, ACK Flood, and TCP malformed flags.</p><p>This attack targeted a known European Cloud Provider and originated from over 18 thousand unique IP addresses that are assumed to be <a>spoofed</a>. It was automatically detected and mitigated by Cloudflare\u2019s defenses.</p><p>This goes to show that even the largest attacks end very quickly. Previous large attacks we\u2019ve seen ended within seconds \u2014 underlining the need for an in-line automated defense system. Though still rare, attacks in the terabit range are becoming more and more prominent.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--17-.png\" /><figcaption>1.9 Terabit per second Mirai DDoS attacks</figcaption></figure><p>The use of Mirai-variant botnets is still very common. In Q4, almost 3% of all attacks originate from Mirai. Though, of all attack methods, DNS-based attacks remain the attackers\u2019 favorite. Together, DNS Floods and DNS Amplification attacks account for almost 53% of all attacks in Q4. <a>SYN Flood</a> follows in second and <a>UDP floods</a> in third. We\u2019ll cover the two DNS attack types here, and you can visit the hyperlinks to learn more about UDP and SYN floods in our Learning Center.</p><h3>DNS floods and amplification attacks</h3><p>DNS floods and DNS amplification attacks both exploit the <a>Domain Name System (DNS)</a>, but they operate differently. DNS is like a phone book for the Internet, translating human-friendly domain names like \"www.cloudfare.com\" into numerical IP addresses that computers use to identify each other on the network.</p><p>Simply put, DNS-based DDoS attacks comprise the method computers and servers used to identify one another to cause an outage or disruption, without actually \u2018taking down\u2019 a server. For example, a server may be up and running, but the DNS server is down. So clients won't be able to connect to it and will experience it as an outage.</p><p>A <strong>DNS flood</strong> attack bombards a DNS server with an overwhelming number of DNS queries. This is usually done using a <a>DDoS botnet</a>. The sheer volume of queries can overwhelm the DNS server, making it difficult or impossible for it to respond to legitimate queries. This can result in the aforementioned service disruptions, delays or even an outage for those trying to access the websites or services that rely on the targeted DNS server.</p><p>On the other hand, a <strong>DNS amplification</strong> attack involves sending a small query with a spoofed IP address (the address of the victim) to a DNS server. The trick here is that the DNS response is significantly larger than the request. The server then sends this large response to the victim's IP address. By exploiting open DNS resolvers, the attacker can amplify the volume of traffic sent to the victim, leading to a much more significant impact. This type of attack not only disrupts the victim but also can congest entire networks.</p><p>In both cases, the attacks exploit the critical role of DNS in network operations. Mitigation strategies typically include securing DNS servers against misuse, implementing rate limiting to manage traffic, and filtering DNS traffic to identify and block malicious requests.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--18--1.png\" /><figcaption>Top attack vectors</figcaption></figure><p>Amongst the emerging threats we track, we recorded a 1,161% increase in ACK-RST Floods as well as a 515% increase in CLDAP floods, and a 243% increase in SPSS floods, in each case as compared to last quarter. Let\u2019s walk through some of these attacks and how they\u2019re meant to cause disruption.</p><figure><img src=\"http://blog.cloudflare.com/content/images/2024/01/pasted-image-0--19-.png\" /><figcaption>Top emerging attack vectors</figcaption></figure><h3>ACK-RST floods</h3><p>An ACK-RST Flood exploits the <a>Transmission Control Protocol (TCP)</a> by sending numerous ACK and RST packets to the victim. This overwhelms the victim's ability to process and respond to these packets, leading to service disruption. The attack is effective because each ACK or RST packet prompts a response from the victim\u2019s system, consuming its resources. ACK-RST Floods are often difficult to filter since they mimic legitimate traffic, making detection and mitigation challenging.</p><h3>CLDAP floods</h3><p>CLDAP (Connectionless Lightweight Directory Access Protocol) is a variant of LDAP (Lightweight Directory Access Protocol). It's used for querying and modifying directory services running over IP networks. CLDAP is connectionless, using UDP instead of TCP, making it faster but less reliable. Because it uses UDP, there\u2019s no handshake requirement which allows attackers to spoof the IP address thus allowing attackers to exploit it as a reflection vector. In these attacks, small queries are sent with a spoofed source IP address (the victim's IP), causing servers to send large responses to the victim, overwhelming it. Mitigation involves filtering and monitoring unusual CLDAP traffic.</p><h3>SPSS floods</h3><p>Floods abusing the SPSS (Source Port Service Sweep) protocol is a network attack method that involves sending packets from numerous random or spoofed source ports to various destination ports on a targeted system or network. The aim of this attack is two-fold: first, to overwhelm the victim's processing capabilities, causing service disruptions or network outages, and second, it can be used to scan for open ports and identify vulnerable services. The flood is achieved by sending a large volume of packets, which can saturate the victim's network resources and exhaust the capacities of its firewalls and intrusion detection systems. To mitigate such attacks, it's essential to leverage in-line automated detection capabilities.</p><h2>Cloudflare is here to help - no matter the attack type, size, or duration</h2><p>Cloudflare\u2019s mission is to help build a better Internet, and we believe that a better Internet is one that is secure, performant, and available to all. No matter the attack type, the attack size, the attack duration or the motivation behind the attack, Cloudflare\u2019s defenses stand strong. Since we pioneered <a>unmetered DDoS Protection in 2017</a>, we\u2019ve made and kept our commitment to make enterprise-grade DDoS protection free for all organizations alike \u2014 and of course, without compromising performance. This is made possible by our <a>unique technology</a> and robust network architecture.</p><p>It\u2019s important to remember that security is a process, not a single product or flip of a switch. Atop of our automated DDoS protection systems, we offer comprehensive bundled features such as <a>firewall</a>, <a>bot detection</a>, <a>API protection</a>, and <a>caching</a> to bolster your defenses. Our multi-layered approach optimizes your security posture and minimizes potential impact. We\u2019ve also put together a <a>list of recommendations</a> to help you optimize your defenses against DDoS attacks, and you can follow our step-by-step wizards to <a>secure your applications</a> and <a>prevent DDoS attacks</a>. And, if you\u2019d like to benefit from our easy to use, best-in-class protection against DDoS and other attacks on the Internet, you can sign up \u2014 for free! \u2014 at <a>cloudflare.com</a>. If you\u2019re under attack, register or call the cyber emergency hotline number shown <a>here</a> for a rapid response.</p>"
      }
    ],
    "tags": [
      {
        "term": "DDoS",
        "scheme": null,
        "label": null
      },
      {
        "term": "Attacks",
        "scheme": null,
        "label": null
      },
      {
        "term": "Cloudflare Radar",
        "scheme": null,
        "label": null
      },
      {
        "term": "DDoS Reports",
        "scheme": null,
        "label": null
      },
      {
        "term": "Insights",
        "scheme": null,
        "label": null
      },
      {
        "term": "Trends",
        "scheme": null,
        "label": null
      },
      {
        "term": "Black Friday",
        "scheme": null,
        "label": null
      },
      {
        "term": "DNS",
        "scheme": null,
        "label": null
      },
      {
        "term": "China",
        "scheme": null,
        "label": null
      },
      {
        "term": "Israel",
        "scheme": null,
        "label": null
      },
      {
        "term": "Operation Iron Swords",
        "scheme": null,
        "label": null
      },
      {
        "term": "Palestinian territories",
        "scheme": null,
        "label": null
      }
    ],
    "id": "659c158caa281c000a8acd88",
    "guidislink": false,
    "authors": [
      {
        "name": "Omer Yoachimik http://blog.cloudflare.com/author/omer/"
      },
      {
        "name": "Jorge Pacheco http://blog.cloudflare.com/author/jorge/"
      }
    ],
    "author": "Jorge Pacheco http://blog.cloudflare.com/author/jorge/",
    "author_detail": {
      "name": "Omer Yoachimik http://blog.cloudflare.com/author/omer/"
    }
  },
  "Advanced Web Machinery": {
    "title": "How to use CloudFront signed cookies to serve MPD or HLS videos",
    "xmlUrl": "https://advancedweb.hu/atom.xml",
    "htmlUrl": "https://advancedweb.hu/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://advancedweb.hu/atom.xml",
      "value": "How to use CloudFront signed cookies to serve MPD or HLS videos"
    },
    "links": [
      {
        "href": "https://advancedweb.hu/how-to-use-cloudfront-signed-cookies-to-serve-mpd-or-hls-videos/",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "link": "https://advancedweb.hu/how-to-use-cloudfront-signed-cookies-to-serve-mpd-or-hls-videos/",
    "updated": "2024-01-09T00:00:00+00:00",
    "updated_parsed": [
      2024,
      1,
      9,
      0,
      0,
      0,
      1,
      9,
      0
    ],
    "id": "https://advancedweb.hu/how-to-use-cloudfront-signed-cookies-to-serve-mpd-or-hls-videos",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://advancedweb.hu/atom.xml",
        "value": "<a href=\"https://advancedweb.hu/how-to-use-cloudfront-signed-cookies-to-serve-mpd-or-hls-videos/\">(Read this article on the blog)</a><h2 id=\"signed-urls\" tabindex=\"-1\">Signed URLs</h2>\n<p>Signed URLs is a mechanism to securely give access to protected content. It works by the backend generating a signature that the clients then can use directly\nwith S3 or CloudFront to get the content. It's the primary way to offer downloads and uploads in serverless applications.</p>\n<p>For example, if an image is stored at <code>images/abc.jpg</code> then a signed URL for it would be <code>images/abc.jpg?x-id=GetObject&...</code>.</p>\n<p>Notice that URL for the file is changed. This is usually not a problem, as when the user clicks the \"download\" button, there is no expectation about where the\nfile is downloaded from so the backend is free to return a signed URL.</p>\n<h2 id=\"segmented-video-formats\" tabindex=\"-1\">Segmented video formats</h2>\n<p>But in some cases, the client expects the file to have a specific URL. One of the most common examples for this is segmented video files, such as HLS or MPD.\nHere, the video stream is broken up to segments and a manifest file defines where the individual files can be found.</p>\n<p>For example, an MPD manifest looks like this:</p>\n<pre class=\"highlight\"><code>\n\t\n\t\t\n\t\t\t<s>\n\t\t\t<s>\n\t\t\n\t\n\n</code></pre>\n<p>When the client reads this and plays the video, it knows how to download the segments:</p>\n<ul>\n<li><code>chunk-stream0-00001.m4s</code></li>\n<li><code>chunk-stream0-00002.m4s</code></li>\n<li><code>chunk-stream0-00003.m4s</code></li>\n<li>...</li>\n</ul>\n<p>But then it does not work with signed URLs anymore as the client can not possibly calculate the signature for each file.</p>\n<p>This is where signed cookies are useful.</p>\n<h2 id=\"cloudfront-signed-cookies\" tabindex=\"-1\">CloudFront signed cookies</h2>\n<p>Signed cookies is another mechanism to give controlled access to protected files. Instead of modifying a URL, the backend returns a set of cookies for the\nclient. By the standard, these cookies are attached to the requests automatically by the browser, which means there is no change needed on the client.</p>\n<p>An example set of signed cookies:</p>\n<pre class=\"highlight\"><code><span class=\"hljs-punctuation\">{</span>\n\t<span class=\"hljs-attr\">\"CloudFront-Key-Pair-Id\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"KJX6ADYM9FBCS\"</span><span class=\"hljs-punctuation\">,</span>\n\t<span class=\"hljs-attr\">\"CloudFront-Signature\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"kAqF32fiDKmOUpDPUNQ...\"</span><span class=\"hljs-punctuation\">,</span>\n\t<span class=\"hljs-attr\">\"CloudFront-Policy\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"eyJTdGF0ZW1lbnQiOlt7IlJlc29...\"</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre>\n<p>The signature can contain wildcards for signed cookies, in practice that means that it's possible to sign them for all files under a directory. This gives an\neasy-to-use structure where each video can be stored in a folder and the signature can give access to a specific one the client wants to play.</p>\n<p>For example, the S3 bucket can contain two videos:</p>\n<pre class=\"highlight\"><code>bunny/bunny.mpd\nbunny/chunk-stream0-00001.m4s\nbunny/chunk-stream0-00002.m4s\nbunny/chunk-stream1-00001.m4s\nbunny/chunk-stream1-00002.m4s\nbunny/init-stream0.m4s\nbunny/init-stream1.m4s\n\nsintel/sintel.mpd\nsintel/chunk-stream0-00001.m4s\nsintel/chunk-stream0-00002.m4s\nsintel/chunk-stream1-00001.m4s\nsintel/chunk-stream1-00002.m4s\nsintel/init-stream0.m4s\nsintel/init-stream1.m4s\n</code></pre>\n<p>This S3 bucket is then used as an origin for the CloudFront distribution and mapped to a path, let's say <code>/videos/*</code></p>\n<p>During signing, the backend generates the cookies for a specific folder under this path:</p>\n<pre class=\"highlight\"><code><span class=\"hljs-keyword\">import</span> {getSignedCookies} <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"@aws-sdk/cloudfront-signer\"</span>;\n\n<span class=\"hljs-keyword\">return</span> <span class=\"hljs-title function_\">getSignedCookies</span>({\n\t<span class=\"hljs-attr\">keyPairId</span>: process.<span class=\"hljs-property\">env</span>.<span class=\"hljs-property\">KEYPAIR_ID</span>,\n\t<span class=\"hljs-attr\">privateKey</span>: (<span class=\"hljs-keyword\">await</span> <span class=\"hljs-title function_\">getCfPrivateKey</span>()).<span class=\"hljs-property\">Parameter</span>.<span class=\"hljs-property\">Value</span>,\n\t<span class=\"hljs-attr\">policy</span>: <span class=\"hljs-title class_\">JSON</span>.<span class=\"hljs-title function_\">stringify</span>({\n\t\t<span class=\"hljs-title class_\">Statement</span>: [\n\t\t\t{\n\t\t\t\t<span class=\"hljs-title class_\">Resource</span>:\n\t<span class=\"hljs-string\">`https://<span class=\"hljs-subst\">${process.env.DISTRIBUTION_DOMAIN}</span>/videos/<span class=\"hljs-subst\">${video}</span>/*`</span>,\n\t\t\t\t<span class=\"hljs-title class_\">Condition</span>: {\n\t\t\t\t\t<span class=\"hljs-title class_\">DateLessThan</span>: {\n\t\t\t\t\t\t<span class=\"hljs-string\">\"AWS:EpochTime\"</span>:\n\t\t\t\t\t\t\t<span class=\"hljs-title class_\">Math</span>.<span class=\"hljs-title function_\">round</span>(\n\t\t\t\t\t\t\t\t<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">Date</span>(\n\t\t\t\t\t\t\t\t\t<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">Date</span>().<span class=\"hljs-title function_\">getTime</span>() + <span class=\"hljs-number\">60</span> * <span class=\"hljs-number\">60</span> * <span class=\"hljs-number\">1000</span>\n\t\t\t\t\t\t\t\t).<span class=\"hljs-title function_\">getTime</span>() / <span class=\"hljs-number\">1000</span>\n\t\t\t\t\t\t\t),\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t]\n\t})\n});\n</code></pre>\n<p>The only thing left is to set the cookies in the HTTP response:</p>\n<pre class=\"highlight\"><code><span class=\"hljs-keyword\">return</span> {\n\t<span class=\"hljs-attr\">statusCode</span>: <span class=\"hljs-number\">307</span>,\n\t<span class=\"hljs-attr\">cookies</span>: <span class=\"hljs-title class_\">Object</span>.<span class=\"hljs-title function_\">entries</span>(signedCookies).<span class=\"hljs-title function_\">map</span>(<span class=\"hljs-function\">(<span class=\"hljs-params\">[name, value]</span>) =></span> {\n\t\t<span class=\"hljs-keyword\">return</span> [\n\t\t\t<span class=\"hljs-string\">`<span class=\"hljs-subst\">${name}</span>=<span class=\"hljs-subst\">${value}</span>`</span>,\n\t\t\t<span class=\"hljs-string\">\"HttpOnly\"</span>,\n\t\t\t<span class=\"hljs-string\">`Path=/videos/<span class=\"hljs-subst\">${videoName}</span>`</span>,\n\t\t\t<span class=\"hljs-string\">\"SameSite=Strict\"</span>,\n\t\t\t<span class=\"hljs-string\">\"Secure\"</span>,\n\t\t].<span class=\"hljs-title function_\">join</span>(<span class=\"hljs-string\">\"; \"</span>);\n\t}),\n\t<span class=\"hljs-attr\">headers</span>: {\n\t\t<span class=\"hljs-title class_\">Location</span>: <span class=\"hljs-string\">`/videos/<span class=\"hljs-subst\">${videoName}</span>/<span class=\"hljs-subst\">${videoName}</span>.mpd`</span>,\n\t},\n};\n</code></pre>\n<p>Notice the <code>Path</code> here: since the name of the cookies are fixed, setting them on the <code>/</code> would overwrite earlier cookies. That could cause problems when\nthe client plays multiple videos in parallel, such as using several tabs. The best practice here is to use the most specific path for the cookies.</p>"
      }
    ],
    "summary": "<a href=\"https://advancedweb.hu/how-to-use-cloudfront-signed-cookies-to-serve-mpd-or-hls-videos/\">(Read this article on the blog)</a><h2 id=\"signed-urls\" tabindex=\"-1\">Signed URLs</h2>\n<p>Signed URLs is a mechanism to securely give access to protected content. It works by the backend generating a signature that the clients then can use directly\nwith S3 or CloudFront to get the content. It's the primary way to offer downloads and uploads in serverless applications.</p>\n<p>For example, if an image is stored at <code>images/abc.jpg</code> then a signed URL for it would be <code>images/abc.jpg?x-id=GetObject&...</code>.</p>\n<p>Notice that URL for the file is changed. This is usually not a problem, as when the user clicks the \"download\" button, there is no expectation about where the\nfile is downloaded from so the backend is free to return a signed URL.</p>\n<h2 id=\"segmented-video-formats\" tabindex=\"-1\">Segmented video formats</h2>\n<p>But in some cases, the client expects the file to have a specific URL. One of the most common examples for this is segmented video files, such as HLS or MPD.\nHere, the video stream is broken up to segments and a manifest file defines where the individual files can be found.</p>\n<p>For example, an MPD manifest looks like this:</p>\n<pre class=\"highlight\"><code>\n\t\n\t\t\n\t\t\t<s>\n\t\t\t<s>\n\t\t\n\t\n\n</code></pre>\n<p>When the client reads this and plays the video, it knows how to download the segments:</p>\n<ul>\n<li><code>chunk-stream0-00001.m4s</code></li>\n<li><code>chunk-stream0-00002.m4s</code></li>\n<li><code>chunk-stream0-00003.m4s</code></li>\n<li>...</li>\n</ul>\n<p>But then it does not work with signed URLs anymore as the client can not possibly calculate the signature for each file.</p>\n<p>This is where signed cookies are useful.</p>\n<h2 id=\"cloudfront-signed-cookies\" tabindex=\"-1\">CloudFront signed cookies</h2>\n<p>Signed cookies is another mechanism to give controlled access to protected files. Instead of modifying a URL, the backend returns a set of cookies for the\nclient. By the standard, these cookies are attached to the requests automatically by the browser, which means there is no change needed on the client.</p>\n<p>An example set of signed cookies:</p>\n<pre class=\"highlight\"><code><span class=\"hljs-punctuation\">{</span>\n\t<span class=\"hljs-attr\">\"CloudFront-Key-Pair-Id\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"KJX6ADYM9FBCS\"</span><span class=\"hljs-punctuation\">,</span>\n\t<span class=\"hljs-attr\">\"CloudFront-Signature\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"kAqF32fiDKmOUpDPUNQ...\"</span><span class=\"hljs-punctuation\">,</span>\n\t<span class=\"hljs-attr\">\"CloudFront-Policy\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"eyJTdGF0ZW1lbnQiOlt7IlJlc29...\"</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre>\n<p>The signature can contain wildcards for signed cookies, in practice that means that it's possible to sign them for all files under a directory. This gives an\neasy-to-use structure where each video can be stored in a folder and the signature can give access to a specific one the client wants to play.</p>\n<p>For example, the S3 bucket can contain two videos:</p>\n<pre class=\"highlight\"><code>bunny/bunny.mpd\nbunny/chunk-stream0-00001.m4s\nbunny/chunk-stream0-00002.m4s\nbunny/chunk-stream1-00001.m4s\nbunny/chunk-stream1-00002.m4s\nbunny/init-stream0.m4s\nbunny/init-stream1.m4s\n\nsintel/sintel.mpd\nsintel/chunk-stream0-00001.m4s\nsintel/chunk-stream0-00002.m4s\nsintel/chunk-stream1-00001.m4s\nsintel/chunk-stream1-00002.m4s\nsintel/init-stream0.m4s\nsintel/init-stream1.m4s\n</code></pre>\n<p>This S3 bucket is then used as an origin for the CloudFront distribution and mapped to a path, let's say <code>/videos/*</code></p>\n<p>During signing, the backend generates the cookies for a specific folder under this path:</p>\n<pre class=\"highlight\"><code><span class=\"hljs-keyword\">import</span> {getSignedCookies} <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"@aws-sdk/cloudfront-signer\"</span>;\n\n<span class=\"hljs-keyword\">return</span> <span class=\"hljs-title function_\">getSignedCookies</span>({\n\t<span class=\"hljs-attr\">keyPairId</span>: process.<span class=\"hljs-property\">env</span>.<span class=\"hljs-property\">KEYPAIR_ID</span>,\n\t<span class=\"hljs-attr\">privateKey</span>: (<span class=\"hljs-keyword\">await</span> <span class=\"hljs-title function_\">getCfPrivateKey</span>()).<span class=\"hljs-property\">Parameter</span>.<span class=\"hljs-property\">Value</span>,\n\t<span class=\"hljs-attr\">policy</span>: <span class=\"hljs-title class_\">JSON</span>.<span class=\"hljs-title function_\">stringify</span>({\n\t\t<span class=\"hljs-title class_\">Statement</span>: [\n\t\t\t{\n\t\t\t\t<span class=\"hljs-title class_\">Resource</span>:\n\t<span class=\"hljs-string\">`https://<span class=\"hljs-subst\">${process.env.DISTRIBUTION_DOMAIN}</span>/videos/<span class=\"hljs-subst\">${video}</span>/*`</span>,\n\t\t\t\t<span class=\"hljs-title class_\">Condition</span>: {\n\t\t\t\t\t<span class=\"hljs-title class_\">DateLessThan</span>: {\n\t\t\t\t\t\t<span class=\"hljs-string\">\"AWS:EpochTime\"</span>:\n\t\t\t\t\t\t\t<span class=\"hljs-title class_\">Math</span>.<span class=\"hljs-title function_\">round</span>(\n\t\t\t\t\t\t\t\t<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">Date</span>(\n\t\t\t\t\t\t\t\t\t<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">Date</span>().<span class=\"hljs-title function_\">getTime</span>() + <span class=\"hljs-number\">60</span> * <span class=\"hljs-number\">60</span> * <span class=\"hljs-number\">1000</span>\n\t\t\t\t\t\t\t\t).<span class=\"hljs-title function_\">getTime</span>() / <span class=\"hljs-number\">1000</span>\n\t\t\t\t\t\t\t),\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t]\n\t})\n});\n</code></pre>\n<p>The only thing left is to set the cookies in the HTTP response:</p>\n<pre class=\"highlight\"><code><span class=\"hljs-keyword\">return</span> {\n\t<span class=\"hljs-attr\">statusCode</span>: <span class=\"hljs-number\">307</span>,\n\t<span class=\"hljs-attr\">cookies</span>: <span class=\"hljs-title class_\">Object</span>.<span class=\"hljs-title function_\">entries</span>(signedCookies).<span class=\"hljs-title function_\">map</span>(<span class=\"hljs-function\">(<span class=\"hljs-params\">[name, value]</span>) =></span> {\n\t\t<span class=\"hljs-keyword\">return</span> [\n\t\t\t<span class=\"hljs-string\">`<span class=\"hljs-subst\">${name}</span>=<span class=\"hljs-subst\">${value}</span>`</span>,\n\t\t\t<span class=\"hljs-string\">\"HttpOnly\"</span>,\n\t\t\t<span class=\"hljs-string\">`Path=/videos/<span class=\"hljs-subst\">${videoName}</span>`</span>,\n\t\t\t<span class=\"hljs-string\">\"SameSite=Strict\"</span>,\n\t\t\t<span class=\"hljs-string\">\"Secure\"</span>,\n\t\t].<span class=\"hljs-title function_\">join</span>(<span class=\"hljs-string\">\"; \"</span>);\n\t}),\n\t<span class=\"hljs-attr\">headers</span>: {\n\t\t<span class=\"hljs-title class_\">Location</span>: <span class=\"hljs-string\">`/videos/<span class=\"hljs-subst\">${videoName}</span>/<span class=\"hljs-subst\">${videoName}</span>.mpd`</span>,\n\t},\n};\n</code></pre>\n<p>Notice the <code>Path</code> here: since the name of the cookies are fixed, setting them on the <code>/</code> would overwrite earlier cookies. That could cause problems when\nthe client plays multiple videos in parallel, such as using several tabs. The best practice here is to use the most specific path for the cookies.</p>"
  },
  "Capgemini": {
    "title": "Keeping Spring Boot Apps Secure With HashiCorp Vault",
    "xmlUrl": "https://capgemini.github.io/feed.xml",
    "htmlUrl": "https://capgemini.github.io/",
    "title_detail": {
      "type": "text/html",
      "language": "en",
      "base": "https://capgemini.github.io/feed.xml",
      "value": "Keeping Spring Boot Apps Secure With HashiCorp Vault"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://capgemini.github.io/cloud%20native/spring-cloud-vault-kubernetes/"
      }
    ],
    "link": "https://capgemini.github.io/cloud%20native/spring-cloud-vault-kubernetes/",
    "id": "https://capgemini.github.io/cloud%20native/spring-cloud-vault-kubernetes",
    "guidislink": false,
    "published": "2023-07-07T00:00:00+01:00",
    "published_parsed": [
      2023,
      7,
      6,
      23,
      0,
      0,
      3,
      187,
      0
    ],
    "updated": "2023-07-07T00:00:00+01:00",
    "updated_parsed": [
      2023,
      7,
      6,
      23,
      0,
      0,
      3,
      187,
      0
    ],
    "authors": [
      {
        "name": "Greg Wolverson",
        "href": "https://capgemini.github.io/authors#author-greg-wolverson"
      }
    ],
    "author_detail": {
      "name": "Greg Wolverson",
      "href": "https://capgemini.github.io/authors#author-greg-wolverson"
    },
    "href": "https://capgemini.github.io/authors#author-greg-wolverson",
    "author": "Greg Wolverson",
    "tags": [
      {
        "term": "Kubernetes",
        "scheme": "https://capgemini.github.io/tags/#Kubernetes",
        "label": null
      },
      {
        "term": "Cloud Native",
        "scheme": "https://capgemini.github.io/tags/#Cloud%20Native",
        "label": null
      },
      {
        "term": "Containers",
        "scheme": "https://capgemini.github.io/tags/#Containers",
        "label": null
      },
      {
        "term": "Spring Boot",
        "scheme": "https://capgemini.github.io/tags/#Spring%20Boot",
        "label": null
      },
      {
        "term": "Security",
        "scheme": "https://capgemini.github.io/tags/#Security",
        "label": null
      },
      {
        "term": "Vault",
        "scheme": "https://capgemini.github.io/tags/#Vault",
        "label": null
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": "en",
        "base": "https://capgemini.github.io/feed.xml",
        "value": "<p>I have previously written <a href=\"https://capgemini.github.io/engineering/securing-spring-boot-config-with-kubernetes/\">blog posts</a> about securing Spring Boot configuration with standard Kubernetes resources. In this post I\u2019m going to take it a step further with a more productionised pattern of securing Spring Boot microservices with Vault in Kubernetes.</p>\n\n<h2 id=\"keep-it-secret-keep-it-safe\">Keep It Secret, Keep It Safe</h2>\n\n<p>As a famous wizard once said; <em>keep it secret, keep it safe</em>. Whilst this applies to rings and other precious objects, it also applies to the sensitive data that we keep within our applications.</p>\n\n<p>Security is paramount in productionised applications, often being one of the more challenging patterns to implement correctly.</p>\n\n<h2 id=\"not-all-secret-stores-were-created-equal\">Not All Secret Stores Were Created Equal</h2>\n\n<p>As I spoke about in my <a href=\"https://capgemini.github.io/engineering/securing-spring-boot-config-with-kubernetes/#keeping-secrets\">previous post</a>, using Kubernetes secrets for storing sensitive data is considered bad practice for two main reasons:</p>\n\n<ol>\n  <li>The secrets themselves are stored in base64 format, which provides minimal security on its own.</li>\n  <li>By default, secrets are <a href=\"https://kubernetes.io/docs/concepts/configuration/secret/\">stored unencrypted</a> in the underlying API\u2019s data store (etd), meaning anyone with API access can retrieve and modify them.</li>\n</ol>\n\n<p>There are several alternatives to using Kubernetes default secrets, and one of the most widely used tools is <a href=\"https://www.vaultproject.io/\">HashiCorp Vault</a>. Vault is an identity-based secrets and encryption management system, that provides encryption services protected by authentication and authorization mechanisms. This makes it a much more secure way to store sensitive data. Additionally, Vault offers integration and authentication mechanisms <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes\">with Kubernetes</a> out-of-the-box, providing a proven and secure approach to managing secrets within your Kubernetes cluster.</p>\n\n<h2 id=\"secure-doesnt-mean-complex\">Secure Doesn\u2019t Mean Complex</h2>\n\n<p>Whilst being a challenging pattern to get right, security doesn\u2019t need to be complex. Let\u2019s walk through a simple example of how to set up the Kubernetes auth method locally, and retrieve secrets from a Spring Boot application using <a href=\"https://cloud.spring.io/spring-cloud-vault/reference/html/\">Spring Cloud Vault</a>.</p>\n\n<h3 id=\"configuring-vault\">Configuring Vault</h3>\n\n<p>To begin with, we will configure Vault locally. HashiCorp has a <a href=\"https://helm.releases.hashicorp.com/\">set of available helm charts</a> that you can apply, in order to test and work with Vault. For our example, we will be using the <a href=\"https://github.com/hashicorp/vault-helm\">vault helm chart</a>.</p>\n\n<p>We will use <a href=\"https://github.com/Praqma/helmsman#what-is-helmsman\">Helmsman</a> to manage our helm deployments. If you are interested in learning more about Helmsman, I recently wrote a <a href=\"https://capgemini.github.io/kubernetes/introduction-to-helmsman/\">blog post</a> about it.</p>\n\n<p>Our <code class=\"language-plaintext highlighter-rouge\">dev</code> state file looks like this:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>helmRepos:\n  vault: https://helm.releases.hashicorp.com\n\napps:\n  ...\n  vault:\n    namespace: dev\n    enabled: true\n    chart: vault/vault\n    version: 0.24.1\n    valuesFile: values/vault/values-dev.yaml\n</code></pre></div></div>\n\n<p>This will tell Helmsman to deploy the <code class=\"language-plaintext highlighter-rouge\">vault</code> helm chart into our local dev namespace using the values file located at <code class=\"language-plaintext highlighter-rouge\">values/vault/values-dev.yml</code>. The values file contains some simple overriding configuration to enable <a href=\"https://github.com/hashicorp/vault-helm/blob/main/values.yaml#L746\">development mode</a> for Vault. In doing so, it allows us to experiment with Vault without needing to unseal or store keys against it (Note: This should not be done in a production environment).</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>server:\n  dev:\n    enabled: true\n</code></pre></div></div>\n\n<h4 id=\"kube-auth-method\">Kube Auth Method</h4>\n\n<p>After applying the helmsman state file, we can proceed with configuring the Vault instance. There are two main ways to configure Vault: through the Vault UI or programatically via the CLI. Since we prefer repeatable processes, having our Vault configuration in code is a better approach. Taking it a step further, we could use the <a href=\"https://registry.terraform.io/providers/hashicorp/vault/latest/docs\">Vault Terraform</a> approach to treat this configuration as infrastructure-as-code. However, that goes beyond the scope of this example.</p>\n\n<h4 id=\"configuration\">Configuration</h4>\n\n<p>Next we need to enable the Kube auth method. The easiest way to do this (programatically) is via the Vault CLI (which comes pre-installed in the Vault container from the installed helm chart).</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">vault auth enable kubernetes</code></p>\n\n<p>After enabling this feature, we need to configure the auth method to work with our local kubernetes cluster. There are several ways to configure this, but with the <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes#kubernetes-1-21\">changes introduced in Kubernetes 1.21</a>, there are some documented and recommended approaches. It\u2019s worth reading through the different approaches and understanding their differences. However, for the purpose of this example, we will be using a <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes#use-local-service-account-token-as-the-reviewer-jwt\">local service account as the reviewer JWT</a> because we have Vault running locally in a pod within our cluster.</p>\n\n<p>To enable this configuration, we can run the following command:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">vault write auth/kubernetes/config kubernetes_host=https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT</code></p>\n\n<p>This configures the Vault auth method to use the service account token running in the Vault pod itself. This works because the Vault pod is running in our local cluster, the <em>same</em> cluster that Vault will be authenticating against later on when we send requests from our sample service. If Vault was running as an externally managed service (which is typical in a production environment), this approach wouldn\u2019t work, and we\u2019d have to configure the auth method using a more robust approach, such as <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes#use-the-vault-client-s-jwt-as-the-reviewer-jwt\">using the Vault client\u2019s JWT as the reviewer token</a> or possibly <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes#use-the-vault-client-s-jwt-as-the-reviewer-jwt\">using long-lived tokens</a>.</p>\n\n<h4 id=\"roles\">Roles</h4>\n\n<p>Now that we have enabled and configured our auth method, we can proceed to add the other important pieces of configuration. Firstly, we need to configure the role against the authentication method. We will create a role that allows our Spring Boot application to retrieve secrets from our Vault instance.</p>\n\n<p>`\nvault write auth/kubernetes/role/demo bound_service_account_names=\u2019*\u2019 bound_service_account_namespaces=dev policies=spring-boot-demo<br />\n`</p>\n\n<p>The role above will be called <code class=\"language-plaintext highlighter-rouge\">demo</code>, and it will be bound to any service account (for finer grained security you would usually limit this to a specific account), it will be bound to our <code class=\"language-plaintext highlighter-rouge\">dev</code> namespace and will have a policy attached to it named <code class=\"language-plaintext highlighter-rouge\">spring-boot-demo</code> (more on this later).</p>\n\n<p>Each Kubernetes auth method can have any number of roles created against it. The purpose of these roles is to restrict each integrating service to a specific set of secrets through roles and policies. The <code class=\"language-plaintext highlighter-rouge\">role</code> component of this configuration determines which service(s), bound to which service account(s) can authenticate against this method (the auth aspect). The attached <a href=\"https://developer.hashicorp.com/vault/docs/concepts/policies\">policy</a> determines which secrets that service account(s) (and consequently service(s)) can access.</p>\n\n<h4 id=\"policies\">Policies</h4>\n\n<p>Vault policies define the fine grained, path based access to specific secrets held within Vault itself. The policy we\u2019re using for this example looks like this:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>path \"kv/spring-boot-demo\" {\n  capabilities = [\"read\"]\n}\n\npath \"kv/spring-boot-demo/dev\" {\n  capabilities = [\"read\"]\n}\n\npath \"auth/token/lookup-self\" {\n  capabilities = [\"read\"]\n}\n\npath \"auth/token/create\" {\n  capabilities = [\"create\", \"read\", \"update\", \"list\"]\n}\n</code></pre></div></div>\n\n<p>This policy will give access to secrets held at <code class=\"language-plaintext highlighter-rouge\">kv/spring-boot-demo</code> and <code class=\"language-plaintext highlighter-rouge\">kv/spring-boot-demo/dev</code>, it also has some default Vault policies which allows the JWT token lookup to occur during login and authentication. For secret lookups, we only need to provide <code class=\"language-plaintext highlighter-rouge\">read</code> access because our service will only be trying to <code class=\"language-plaintext highlighter-rouge\">get</code> specific secrets, not create or update them.</p>\n\n<p>The following diagram gives a high-level view as to how Policy look-ups and authorisation occur.</p>\n\n<p><img alt=\"Vault policy access\" src=\"https://capgemini.github.io/images/2023-06-21-spring-cloud-vault-kubernetes/vault-policy.png\" /></p>\n\n<h4 id=\"secrets\">Secrets</h4>\n\n<p>Lastly, we need to enable a secrets engine and create a secret for our application to use. For this example, we will be using the <a href=\"https://developer.hashicorp.com/vault/docs/secrets/kv\">Key-Value secrets engine</a>. The following CLI command will enable the KV engine for us, with a name of <code class=\"language-plaintext highlighter-rouge\">kv</code> (this should look familiar from our policy outlined earlier).</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">vault secrets enable kv</code></p>\n\n<p>Next, we can put a secret into our new kv store:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">vault kv put kv/spring-boot-demo/dev admin=password</code></p>\n\n<p>Now that we have our Vault instance configured with the kube auth method, a role, an appropriate policy and secret data, we can integrate a sample application to test it.</p>\n\n<h3 id=\"spring-cloud-vault\">Spring Cloud Vault</h3>\n\n<p>To test our Vault configuration and close the loop with our example setup, we will use a Spring Boot microservice, which has endpoint security configured with Spring Security. For this demo, we will be using <a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html\">actuator</a> which only <a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.endpoints.security\">exposes <code class=\"language-plaintext highlighter-rouge\">/health</code> by default for security reasons</a>. Let\u2019s expose some actuator endpoints that could contain sensitive information such as <code class=\"language-plaintext highlighter-rouge\">/env</code> and <code class=\"language-plaintext highlighter-rouge\">/heapdump</code>, and secure them with spring security.</p>\n\n<h4 id=\"securing-our-endpoints\">Securing Our Endpoints</h4>\n\n<p>In Spring Boot it\u2019s fairly straightforward to enable various actuator endpoints. Spring provides a <code class=\"language-plaintext highlighter-rouge\">management</code> config block, which allows developers finer-grained control over which endpoints are exposed, and also which sub-sets of information are exposed at those levels.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>management:\n  endpoint:\n    ...\n    env:\n      enabled: true\n    heapdump:\n      enabled: true\n</code></pre></div></div>\n\n<p>We will be enabling the <code class=\"language-plaintext highlighter-rouge\">env</code> and <code class=\"language-plaintext highlighter-rouge\">heapdump</code> endpoints as mentioned above, this means we <em>could</em> be exposing sensitive information about our service if not secured correctly.</p>\n\n<p>In order to secure the actuator routes properly we need to implement spring security. A simple pattern I like to follow is to split my routes into secure and insecure, allowing pass-through traffic for any non-secure route, and then handling secure routes with appropriate <a href=\"https://auth0.com/docs/manage-users/access-control/rbac\">role-based access controls</a>. Our configuration will look like as follows, including a \u2018management\u2019 style user for access purposes.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">application.yml</code></p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>appsecurity:\n  management:\n    username: ADMIN\n    password: ${admin:test}\n\nsecuredroutes:\n  management:\n    - \"/actuator/shutdown\"\n    - \"/actuator/loggers/**\"\n    - \"/actuator/heapdump\"\n    - \"/actuator/env\"\n  unprotected:\n    - \"/actuator/info\"\n    - \"/actuator/prometheus\"\n    - \"/actuator/health/**\"\n    - \"/hello\"\n</code></pre></div></div>\n\n<p>The config above allows us to use a <a href=\"https://docs.spring.io/spring-boot/docs/2.0.0.M3/reference/html/howto-properties-and-configuration.html#howto-use-short-command-line-arguments\">placeholder value</a> for our management user password. This is useful for unit test purposes where we don\u2019t want to create another <code class=\"language-plaintext highlighter-rouge\">application.yml</code> test resource file. If we don\u2019t supply a value at runtime, the default value of <code class=\"language-plaintext highlighter-rouge\">test</code> will be used.</p>\n\n<p>In order for our application to use this configuration, simple configuration properties can be used to map the values to a configuration class:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>@Getter\n@Setter\n@Configuration\n@ConfigurationProperties(prefix = \"securedroutes\")\npublic class SecuredRoutesConfig {\n\n  private String[] management;\n  private String[] unprotected;\n}\n</code></pre></div></div>\n\n<p>Our Spring security config will configure our application to allow any requests accessing non-secure routes to pass-through without any auth checks, whereas any requests to our secured routes will be subject to authentication and authorisation checks. An example of this config is show below.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>private final SecuredRoutesConfig securedRoutesConfig;\n\n@Value(\"${appsecurity.management.username}\")\nprivate String managementUsername;\n\n@Value(\"${appsecurity.management.password}\")\nprivate String managementPassword;\n\n@Bean\npublic PasswordEncoder encoder() {\nreturn new BCryptPasswordEncoder();\n}\n\n@Bean\npublic SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\nhttp\n    .formLogin().disable()\n    .csrf().disable()\n    .authorizeHttpRequests((requests) -&gt; requests\n        .requestMatchers(securedRoutesConfig.getUnprotected()).permitAll()\n        .requestMatchers(securedRoutesConfig.getManagement()).hasRole(ROLE_MANAGEMENT_USER)\n    )\n    .httpBasic(withDefaults());\n\nreturn http.build();\n}\n\n@Bean\npublic UserDetailsService userDetailsService() {\nUserDetails user =\n    User.builder()\n        .username(managementUsername)\n        .password(encoder().encode(managementPassword))\n        .roles(ROLE_MANAGEMENT_USER)\n        .build();\n\nreturn new InMemoryUserDetailsManager(user);\n}\n</code></pre></div></div>\n\n<h4 id=\"configuring-vault-1\">Configuring Vault</h4>\n\n<p>In order to configure our Spring Boot service to integrate with Vault, we need two key parts; the Spring Cloud Vault library and our application configuration to integrate with Vault itself.</p>\n\n<p>Adding the following library to the POM file gives us the full spring-cloud-vault implementation:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-vault-config&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre></div></div>\n\n<p>And the following configuration enables our application to integrate with Vault:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>spring:\n  config:\n    import: optional:vault://\n  cloud:\n    vault:\n      enabled: ${vault-enabled:false}\n      application-name: spring-boot-demo\n      connection-timeout: ${vault-connection-timeout:5000}\n      read-timeout: ${vault-read-timeout:15000}\n      authentication: KUBERNETES\n      kv:\n        backend: kv\n        enabled: true\n        profile-separator: '/'\n        application-name: spring-boot-demo\n        default-context: spring-boot-demo\n        profiles: dev\n</code></pre></div></div>\n\n<p>Some of the configuration above might already start to make sense based on how we configured our Vault instance earlier. The main aspects to point out are the <code class=\"language-plaintext highlighter-rouge\">kv</code> engine configuration;</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">backend: kv</code> - this tells Spring Boot the name of the kv secrets engine to lookup in Vault</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">profile-separator: '/'</code> - this tells Spring Boot the path separator used in the secrets engine, e.g. <code class=\"language-plaintext highlighter-rouge\">kv/</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">application-name: spring-boot-demo</code> - this tells Spring Boot the naming convention of the secret lookup, e.g. kv/spring-boot-demo</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">profiles: dev</code> - this refers to the active profile Spring Boot is running, as Spring Cloud Vault uses that profile to determine the secret path to use, so dev would give us <code class=\"language-plaintext highlighter-rouge\">kv/spring-boot-demo/dev</code>.</li>\n</ul>\n\n<h3 id=\"bringing-it-all-together\">Bringing It All Together</h3>\n\n<p>Given that we have a local Vault instance set up and a Spring Boot service to integrate with it, we can deploy our app and test the successful retrieval of secrets to secure our application.</p>\n\n<p>Firstly, we will add our Spring Boot service to our Helmsman desired state file.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>apps:\n  spring-boot-demo:\n    namespace: dev\n    enabled: true\n    chart: '../service-helm-chart'\n    version: 1.0.0\n    valuesFile: values/service/values-dev.yaml    \n  vault:\n    ...\n</code></pre></div></div>\n\n<p>Then we can apply the updated state file:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">helmsman --apply -f dev.yaml</code></p>\n\n<p>Once the new Spring Boot service is running successfully, we can test the actuator endpoint has been secured properly with our secret we set up in Vault.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; kubectl get deploy -n dev\nNAME                     READY   UP-TO-DATE   AVAILABLE   AGE\nvault-agent-injector     1/1     1            1           64s\nspring-boot-vault-demo   1/1     1            1           65s\n</code></pre></div></div>\n\n<p>We can <a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/#forward-a-local-port-to-a-port-on-the-pod\">port-forward</a> to the running pod to establish a localhost connection and conduct some basic cURL tests. When calling a secure endpoint without any authentication using cURL, we should receive a 401 response.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">kubectl port-forward deploy/spring-boot-vault-demo 8080:8080 -n dev</code></p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; curl http://localhost:8080/actuator/env -v\n*   Trying 127.0.0.1:8080...\n* Connected to localhost (127.0.0.1) port 8080 (#0)\n&gt; GET /actuator/env HTTP/1.1\n&gt; Host: localhost:8080\n&gt; User-Agent: curl/7.79.1\n&gt; Accept: */*\n&gt;\n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 401\n...\n</code></pre></div></div>\n\n<p>Now, when we use cURL to call the same endpoint while providing the authentication secret stored in Vault, we should receive a 200 response, along with the JSON payload that outlines the environment properties stored in the service.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; curl http://localhost:8080/actuator/env --user ADMIN:password -v\n*   Trying 127.0.0.1:8080...\n* Connected to localhost (127.0.0.1) port 8080 (#0)\n* Server auth using Basic with user 'ADMIN'\n&gt; GET /actuator/env HTTP/1.1\n&gt; Host: localhost:8080\n&gt; Authorization: Basic QURNSU46cGFzc3dvcmQ=\n&gt; User-Agent: curl/7.79.1\n&gt; Accept: */*\n&gt;\n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200\n...\n{\"activeProfiles\":[\"dev\"],\"propertySources\":[{\"name\":\"server.ports\",\"properties\":{\"local.server.port\":{\"value\":\"******\"}}},...\n</code></pre></div></div>\n\n<p>And that\u2019s it! All working as expected.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Keeping sensitive information secure in production systems is paramount. With the <a href=\"https://www.itgovernance.co.uk/blog/data-breaches-and-cyber-attacks-in-2022-408-million-breached-records\">vast number of data breaches last year</a>, which caused chaos for those who fell victim, ensuring data security and mitigating attack vectors is critical for engineering robust, well-designed systems. While this post has outlined a simpler approach to integrating a Spring Boot microservice with a secrets management solution, it hopefully demonstrates that it doesn\u2019t have to be incredibly complex to get it right.</p>\n\n<p>You can see all the code to accompany this post <a href=\"https://github.com/gwolverson/vault-kubernetes-example\">over on my github</a>.</p>\n\n\n    \n    <p><a href=\"https://capgemini.github.io/cloud%20native/spring-cloud-vault-kubernetes/\">Keeping Spring Boot Apps Secure With HashiCorp Vault</a> was originally published by Capgemini at <a href=\"https://capgemini.github.io\">Capgemini Software Engineering</a> on July 07, 2023.</p>"
      }
    ],
    "summary": "<p>I have previously written <a href=\"https://capgemini.github.io/engineering/securing-spring-boot-config-with-kubernetes/\">blog posts</a> about securing Spring Boot configuration with standard Kubernetes resources. In this post I\u2019m going to take it a step further with a more productionised pattern of securing Spring Boot microservices with Vault in Kubernetes.</p>\n\n<h2 id=\"keep-it-secret-keep-it-safe\">Keep It Secret, Keep It Safe</h2>\n\n<p>As a famous wizard once said; <em>keep it secret, keep it safe</em>. Whilst this applies to rings and other precious objects, it also applies to the sensitive data that we keep within our applications.</p>\n\n<p>Security is paramount in productionised applications, often being one of the more challenging patterns to implement correctly.</p>\n\n<h2 id=\"not-all-secret-stores-were-created-equal\">Not All Secret Stores Were Created Equal</h2>\n\n<p>As I spoke about in my <a href=\"https://capgemini.github.io/engineering/securing-spring-boot-config-with-kubernetes/#keeping-secrets\">previous post</a>, using Kubernetes secrets for storing sensitive data is considered bad practice for two main reasons:</p>\n\n<ol>\n  <li>The secrets themselves are stored in base64 format, which provides minimal security on its own.</li>\n  <li>By default, secrets are <a href=\"https://kubernetes.io/docs/concepts/configuration/secret/\">stored unencrypted</a> in the underlying API\u2019s data store (etd), meaning anyone with API access can retrieve and modify them.</li>\n</ol>\n\n<p>There are several alternatives to using Kubernetes default secrets, and one of the most widely used tools is <a href=\"https://www.vaultproject.io/\">HashiCorp Vault</a>. Vault is an identity-based secrets and encryption management system, that provides encryption services protected by authentication and authorization mechanisms. This makes it a much more secure way to store sensitive data. Additionally, Vault offers integration and authentication mechanisms <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes\">with Kubernetes</a> out-of-the-box, providing a proven and secure approach to managing secrets within your Kubernetes cluster.</p>\n\n<h2 id=\"secure-doesnt-mean-complex\">Secure Doesn\u2019t Mean Complex</h2>\n\n<p>Whilst being a challenging pattern to get right, security doesn\u2019t need to be complex. Let\u2019s walk through a simple example of how to set up the Kubernetes auth method locally, and retrieve secrets from a Spring Boot application using <a href=\"https://cloud.spring.io/spring-cloud-vault/reference/html/\">Spring Cloud Vault</a>.</p>\n\n<h3 id=\"configuring-vault\">Configuring Vault</h3>\n\n<p>To begin with, we will configure Vault locally. HashiCorp has a <a href=\"https://helm.releases.hashicorp.com/\">set of available helm charts</a> that you can apply, in order to test and work with Vault. For our example, we will be using the <a href=\"https://github.com/hashicorp/vault-helm\">vault helm chart</a>.</p>\n\n<p>We will use <a href=\"https://github.com/Praqma/helmsman#what-is-helmsman\">Helmsman</a> to manage our helm deployments. If you are interested in learning more about Helmsman, I recently wrote a <a href=\"https://capgemini.github.io/kubernetes/introduction-to-helmsman/\">blog post</a> about it.</p>\n\n<p>Our <code class=\"language-plaintext highlighter-rouge\">dev</code> state file looks like this:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>helmRepos:\n  vault: https://helm.releases.hashicorp.com\n\napps:\n  ...\n  vault:\n    namespace: dev\n    enabled: true\n    chart: vault/vault\n    version: 0.24.1\n    valuesFile: values/vault/values-dev.yaml\n</code></pre></div></div>\n\n<p>This will tell Helmsman to deploy the <code class=\"language-plaintext highlighter-rouge\">vault</code> helm chart into our local dev namespace using the values file located at <code class=\"language-plaintext highlighter-rouge\">values/vault/values-dev.yml</code>. The values file contains some simple overriding configuration to enable <a href=\"https://github.com/hashicorp/vault-helm/blob/main/values.yaml#L746\">development mode</a> for Vault. In doing so, it allows us to experiment with Vault without needing to unseal or store keys against it (Note: This should not be done in a production environment).</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>server:\n  dev:\n    enabled: true\n</code></pre></div></div>\n\n<h4 id=\"kube-auth-method\">Kube Auth Method</h4>\n\n<p>After applying the helmsman state file, we can proceed with configuring the Vault instance. There are two main ways to configure Vault: through the Vault UI or programatically via the CLI. Since we prefer repeatable processes, having our Vault configuration in code is a better approach. Taking it a step further, we could use the <a href=\"https://registry.terraform.io/providers/hashicorp/vault/latest/docs\">Vault Terraform</a> approach to treat this configuration as infrastructure-as-code. However, that goes beyond the scope of this example.</p>\n\n<h4 id=\"configuration\">Configuration</h4>\n\n<p>Next we need to enable the Kube auth method. The easiest way to do this (programatically) is via the Vault CLI (which comes pre-installed in the Vault container from the installed helm chart).</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">vault auth enable kubernetes</code></p>\n\n<p>After enabling this feature, we need to configure the auth method to work with our local kubernetes cluster. There are several ways to configure this, but with the <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes#kubernetes-1-21\">changes introduced in Kubernetes 1.21</a>, there are some documented and recommended approaches. It\u2019s worth reading through the different approaches and understanding their differences. However, for the purpose of this example, we will be using a <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes#use-local-service-account-token-as-the-reviewer-jwt\">local service account as the reviewer JWT</a> because we have Vault running locally in a pod within our cluster.</p>\n\n<p>To enable this configuration, we can run the following command:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">vault write auth/kubernetes/config kubernetes_host=https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT</code></p>\n\n<p>This configures the Vault auth method to use the service account token running in the Vault pod itself. This works because the Vault pod is running in our local cluster, the <em>same</em> cluster that Vault will be authenticating against later on when we send requests from our sample service. If Vault was running as an externally managed service (which is typical in a production environment), this approach wouldn\u2019t work, and we\u2019d have to configure the auth method using a more robust approach, such as <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes#use-the-vault-client-s-jwt-as-the-reviewer-jwt\">using the Vault client\u2019s JWT as the reviewer token</a> or possibly <a href=\"https://developer.hashicorp.com/vault/docs/auth/kubernetes#use-the-vault-client-s-jwt-as-the-reviewer-jwt\">using long-lived tokens</a>.</p>\n\n<h4 id=\"roles\">Roles</h4>\n\n<p>Now that we have enabled and configured our auth method, we can proceed to add the other important pieces of configuration. Firstly, we need to configure the role against the authentication method. We will create a role that allows our Spring Boot application to retrieve secrets from our Vault instance.</p>\n\n<p>`\nvault write auth/kubernetes/role/demo bound_service_account_names=\u2019*\u2019 bound_service_account_namespaces=dev policies=spring-boot-demo<br />\n`</p>\n\n<p>The role above will be called <code class=\"language-plaintext highlighter-rouge\">demo</code>, and it will be bound to any service account (for finer grained security you would usually limit this to a specific account), it will be bound to our <code class=\"language-plaintext highlighter-rouge\">dev</code> namespace and will have a policy attached to it named <code class=\"language-plaintext highlighter-rouge\">spring-boot-demo</code> (more on this later).</p>\n\n<p>Each Kubernetes auth method can have any number of roles created against it. The purpose of these roles is to restrict each integrating service to a specific set of secrets through roles and policies. The <code class=\"language-plaintext highlighter-rouge\">role</code> component of this configuration determines which service(s), bound to which service account(s) can authenticate against this method (the auth aspect). The attached <a href=\"https://developer.hashicorp.com/vault/docs/concepts/policies\">policy</a> determines which secrets that service account(s) (and consequently service(s)) can access.</p>\n\n<h4 id=\"policies\">Policies</h4>\n\n<p>Vault policies define the fine grained, path based access to specific secrets held within Vault itself. The policy we\u2019re using for this example looks like this:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>path \"kv/spring-boot-demo\" {\n  capabilities = [\"read\"]\n}\n\npath \"kv/spring-boot-demo/dev\" {\n  capabilities = [\"read\"]\n}\n\npath \"auth/token/lookup-self\" {\n  capabilities = [\"read\"]\n}\n\npath \"auth/token/create\" {\n  capabilities = [\"create\", \"read\", \"update\", \"list\"]\n}\n</code></pre></div></div>\n\n<p>This policy will give access to secrets held at <code class=\"language-plaintext highlighter-rouge\">kv/spring-boot-demo</code> and <code class=\"language-plaintext highlighter-rouge\">kv/spring-boot-demo/dev</code>, it also has some default Vault policies which allows the JWT token lookup to occur during login and authentication. For secret lookups, we only need to provide <code class=\"language-plaintext highlighter-rouge\">read</code> access because our service will only be trying to <code class=\"language-plaintext highlighter-rouge\">get</code> specific secrets, not create or update them.</p>\n\n<p>The following diagram gives a high-level view as to how Policy look-ups and authorisation occur.</p>\n\n<p><img alt=\"Vault policy access\" src=\"https://capgemini.github.io/images/2023-06-21-spring-cloud-vault-kubernetes/vault-policy.png\" /></p>\n\n<h4 id=\"secrets\">Secrets</h4>\n\n<p>Lastly, we need to enable a secrets engine and create a secret for our application to use. For this example, we will be using the <a href=\"https://developer.hashicorp.com/vault/docs/secrets/kv\">Key-Value secrets engine</a>. The following CLI command will enable the KV engine for us, with a name of <code class=\"language-plaintext highlighter-rouge\">kv</code> (this should look familiar from our policy outlined earlier).</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">vault secrets enable kv</code></p>\n\n<p>Next, we can put a secret into our new kv store:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">vault kv put kv/spring-boot-demo/dev admin=password</code></p>\n\n<p>Now that we have our Vault instance configured with the kube auth method, a role, an appropriate policy and secret data, we can integrate a sample application to test it.</p>\n\n<h3 id=\"spring-cloud-vault\">Spring Cloud Vault</h3>\n\n<p>To test our Vault configuration and close the loop with our example setup, we will use a Spring Boot microservice, which has endpoint security configured with Spring Security. For this demo, we will be using <a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html\">actuator</a> which only <a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.endpoints.security\">exposes <code class=\"language-plaintext highlighter-rouge\">/health</code> by default for security reasons</a>. Let\u2019s expose some actuator endpoints that could contain sensitive information such as <code class=\"language-plaintext highlighter-rouge\">/env</code> and <code class=\"language-plaintext highlighter-rouge\">/heapdump</code>, and secure them with spring security.</p>\n\n<h4 id=\"securing-our-endpoints\">Securing Our Endpoints</h4>\n\n<p>In Spring Boot it\u2019s fairly straightforward to enable various actuator endpoints. Spring provides a <code class=\"language-plaintext highlighter-rouge\">management</code> config block, which allows developers finer-grained control over which endpoints are exposed, and also which sub-sets of information are exposed at those levels.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>management:\n  endpoint:\n    ...\n    env:\n      enabled: true\n    heapdump:\n      enabled: true\n</code></pre></div></div>\n\n<p>We will be enabling the <code class=\"language-plaintext highlighter-rouge\">env</code> and <code class=\"language-plaintext highlighter-rouge\">heapdump</code> endpoints as mentioned above, this means we <em>could</em> be exposing sensitive information about our service if not secured correctly.</p>\n\n<p>In order to secure the actuator routes properly we need to implement spring security. A simple pattern I like to follow is to split my routes into secure and insecure, allowing pass-through traffic for any non-secure route, and then handling secure routes with appropriate <a href=\"https://auth0.com/docs/manage-users/access-control/rbac\">role-based access controls</a>. Our configuration will look like as follows, including a \u2018management\u2019 style user for access purposes.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">application.yml</code></p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>appsecurity:\n  management:\n    username: ADMIN\n    password: ${admin:test}\n\nsecuredroutes:\n  management:\n    - \"/actuator/shutdown\"\n    - \"/actuator/loggers/**\"\n    - \"/actuator/heapdump\"\n    - \"/actuator/env\"\n  unprotected:\n    - \"/actuator/info\"\n    - \"/actuator/prometheus\"\n    - \"/actuator/health/**\"\n    - \"/hello\"\n</code></pre></div></div>\n\n<p>The config above allows us to use a <a href=\"https://docs.spring.io/spring-boot/docs/2.0.0.M3/reference/html/howto-properties-and-configuration.html#howto-use-short-command-line-arguments\">placeholder value</a> for our management user password. This is useful for unit test purposes where we don\u2019t want to create another <code class=\"language-plaintext highlighter-rouge\">application.yml</code> test resource file. If we don\u2019t supply a value at runtime, the default value of <code class=\"language-plaintext highlighter-rouge\">test</code> will be used.</p>\n\n<p>In order for our application to use this configuration, simple configuration properties can be used to map the values to a configuration class:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>@Getter\n@Setter\n@Configuration\n@ConfigurationProperties(prefix = \"securedroutes\")\npublic class SecuredRoutesConfig {\n\n  private String[] management;\n  private String[] unprotected;\n}\n</code></pre></div></div>\n\n<p>Our Spring security config will configure our application to allow any requests accessing non-secure routes to pass-through without any auth checks, whereas any requests to our secured routes will be subject to authentication and authorisation checks. An example of this config is show below.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>private final SecuredRoutesConfig securedRoutesConfig;\n\n@Value(\"${appsecurity.management.username}\")\nprivate String managementUsername;\n\n@Value(\"${appsecurity.management.password}\")\nprivate String managementPassword;\n\n@Bean\npublic PasswordEncoder encoder() {\nreturn new BCryptPasswordEncoder();\n}\n\n@Bean\npublic SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\nhttp\n    .formLogin().disable()\n    .csrf().disable()\n    .authorizeHttpRequests((requests) -&gt; requests\n        .requestMatchers(securedRoutesConfig.getUnprotected()).permitAll()\n        .requestMatchers(securedRoutesConfig.getManagement()).hasRole(ROLE_MANAGEMENT_USER)\n    )\n    .httpBasic(withDefaults());\n\nreturn http.build();\n}\n\n@Bean\npublic UserDetailsService userDetailsService() {\nUserDetails user =\n    User.builder()\n        .username(managementUsername)\n        .password(encoder().encode(managementPassword))\n        .roles(ROLE_MANAGEMENT_USER)\n        .build();\n\nreturn new InMemoryUserDetailsManager(user);\n}\n</code></pre></div></div>\n\n<h4 id=\"configuring-vault-1\">Configuring Vault</h4>\n\n<p>In order to configure our Spring Boot service to integrate with Vault, we need two key parts; the Spring Cloud Vault library and our application configuration to integrate with Vault itself.</p>\n\n<p>Adding the following library to the POM file gives us the full spring-cloud-vault implementation:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-vault-config&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre></div></div>\n\n<p>And the following configuration enables our application to integrate with Vault:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>spring:\n  config:\n    import: optional:vault://\n  cloud:\n    vault:\n      enabled: ${vault-enabled:false}\n      application-name: spring-boot-demo\n      connection-timeout: ${vault-connection-timeout:5000}\n      read-timeout: ${vault-read-timeout:15000}\n      authentication: KUBERNETES\n      kv:\n        backend: kv\n        enabled: true\n        profile-separator: '/'\n        application-name: spring-boot-demo\n        default-context: spring-boot-demo\n        profiles: dev\n</code></pre></div></div>\n\n<p>Some of the configuration above might already start to make sense based on how we configured our Vault instance earlier. The main aspects to point out are the <code class=\"language-plaintext highlighter-rouge\">kv</code> engine configuration;</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">backend: kv</code> - this tells Spring Boot the name of the kv secrets engine to lookup in Vault</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">profile-separator: '/'</code> - this tells Spring Boot the path separator used in the secrets engine, e.g. <code class=\"language-plaintext highlighter-rouge\">kv/</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">application-name: spring-boot-demo</code> - this tells Spring Boot the naming convention of the secret lookup, e.g. kv/spring-boot-demo</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">profiles: dev</code> - this refers to the active profile Spring Boot is running, as Spring Cloud Vault uses that profile to determine the secret path to use, so dev would give us <code class=\"language-plaintext highlighter-rouge\">kv/spring-boot-demo/dev</code>.</li>\n</ul>\n\n<h3 id=\"bringing-it-all-together\">Bringing It All Together</h3>\n\n<p>Given that we have a local Vault instance set up and a Spring Boot service to integrate with it, we can deploy our app and test the successful retrieval of secrets to secure our application.</p>\n\n<p>Firstly, we will add our Spring Boot service to our Helmsman desired state file.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>apps:\n  spring-boot-demo:\n    namespace: dev\n    enabled: true\n    chart: '../service-helm-chart'\n    version: 1.0.0\n    valuesFile: values/service/values-dev.yaml    \n  vault:\n    ...\n</code></pre></div></div>\n\n<p>Then we can apply the updated state file:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">helmsman --apply -f dev.yaml</code></p>\n\n<p>Once the new Spring Boot service is running successfully, we can test the actuator endpoint has been secured properly with our secret we set up in Vault.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; kubectl get deploy -n dev\nNAME                     READY   UP-TO-DATE   AVAILABLE   AGE\nvault-agent-injector     1/1     1            1           64s\nspring-boot-vault-demo   1/1     1            1           65s\n</code></pre></div></div>\n\n<p>We can <a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/#forward-a-local-port-to-a-port-on-the-pod\">port-forward</a> to the running pod to establish a localhost connection and conduct some basic cURL tests. When calling a secure endpoint without any authentication using cURL, we should receive a 401 response.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">kubectl port-forward deploy/spring-boot-vault-demo 8080:8080 -n dev</code></p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; curl http://localhost:8080/actuator/env -v\n*   Trying 127.0.0.1:8080...\n* Connected to localhost (127.0.0.1) port 8080 (#0)\n&gt; GET /actuator/env HTTP/1.1\n&gt; Host: localhost:8080\n&gt; User-Agent: curl/7.79.1\n&gt; Accept: */*\n&gt;\n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 401\n...\n</code></pre></div></div>\n\n<p>Now, when we use cURL to call the same endpoint while providing the authentication secret stored in Vault, we should receive a 200 response, along with the JSON payload that outlines the environment properties stored in the service.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; curl http://localhost:8080/actuator/env --user ADMIN:password -v\n*   Trying 127.0.0.1:8080...\n* Connected to localhost (127.0.0.1) port 8080 (#0)\n* Server auth using Basic with user 'ADMIN'\n&gt; GET /actuator/env HTTP/1.1\n&gt; Host: localhost:8080\n&gt; Authorization: Basic QURNSU46cGFzc3dvcmQ=\n&gt; User-Agent: curl/7.79.1\n&gt; Accept: */*\n&gt;\n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200\n...\n{\"activeProfiles\":[\"dev\"],\"propertySources\":[{\"name\":\"server.ports\",\"properties\":{\"local.server.port\":{\"value\":\"******\"}}},...\n</code></pre></div></div>\n\n<p>And that\u2019s it! All working as expected.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Keeping sensitive information secure in production systems is paramount. With the <a href=\"https://www.itgovernance.co.uk/blog/data-breaches-and-cyber-attacks-in-2022-408-million-breached-records\">vast number of data breaches last year</a>, which caused chaos for those who fell victim, ensuring data security and mitigating attack vectors is critical for engineering robust, well-designed systems. While this post has outlined a simpler approach to integrating a Spring Boot microservice with a secrets management solution, it hopefully demonstrates that it doesn\u2019t have to be incredibly complex to get it right.</p>\n\n<p>You can see all the code to accompany this post <a href=\"https://github.com/gwolverson/vault-kubernetes-example\">over on my github</a>.</p>\n\n\n    \n    <p><a href=\"https://capgemini.github.io/cloud%20native/spring-cloud-vault-kubernetes/\">Keeping Spring Boot Apps Secure With HashiCorp Vault</a> was originally published by Capgemini at <a href=\"https://capgemini.github.io\">Capgemini Software Engineering</a> on July 07, 2023.</p>"
  },
  "Strava": {
    "title": "AN EVENTFUL SUMMER AT STRAVA",
    "xmlUrl": "https://medium.com/feed/strava-engineering",
    "htmlUrl": "https://medium.com/strava-engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/strava-engineering",
      "value": "AN EVENTFUL SUMMER AT STRAVA"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/strava-engineering/an-eventful-summer-at-strava-5692882e5f4f?source=rss----89d4108ce2a3---4"
      }
    ],
    "link": "https://medium.com/strava-engineering/an-eventful-summer-at-strava-5692882e5f4f?source=rss----89d4108ce2a3---4",
    "id": "https://medium.com/p/5692882e5f4f",
    "guidislink": false,
    "tags": [
      {
        "term": "software-engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "data-platforms",
        "scheme": null,
        "label": null
      },
      {
        "term": "data-engineering",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Bisman Sodhi"
      }
    ],
    "author": "Bisman Sodhi",
    "author_detail": {
      "name": "Bisman Sodhi"
    },
    "published": "Mon, 08 Jan 2024 20:19:46 GMT",
    "published_parsed": [
      2024,
      1,
      8,
      20,
      19,
      46,
      0,
      8,
      0
    ],
    "updated": "2024-01-08T20:19:46.882Z",
    "updated_parsed": [
      2024,
      1,
      8,
      20,
      19,
      46,
      0,
      8,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/strava-engineering",
        "value": "<p>Hi my name is Bisman and I studied Computer Science at University of California, Santa Barbara. During summer of 2022, I had the most amazing experience working as a Software Engineer Intern on Strava\u2019s Data Platform Team. In the first fews weeks, I learned the tools my team uses and then spent the rest of the time working on my\u00a0project.</p><h3>TRACKING BAD\u00a0EVENTS</h3><p>For my major summer project, I created a data pipeline that pulls user behavior data out of external storage and persists it in our data warehouse. Strava uses a service called <a href=\"https://snowplow.io\">Snowplow</a> to collect this user behavior data, like loading a club page or uploading a profile photo. Sometimes, this data fails to match the schema that we\u2019ve set, and a piece of data that fails this schema validation is called a bad event. Previously, these bad events were temporarily stored in an Elastic Search. Persisting this data in <a href=\"https://www.snowflake.com/en/\">Snowflake</a>, our data warehouse, makes it accessible to a wider audience. It also makes it easier to incorporate the bad events data with other services used at\u00a0Strava.</p><p>To start my project, I created a directed acyclic graph in <a href=\"https://airflow.apache.org\">Apache Airflow</a>, a scheduling framework, using python that extracts bad events data from the <a href=\"https://aws.amazon.com/s3/\">S3</a>, AWS\u2019s storage service, buckets on a daily cadence. This data was stored as gzip files on S3 which I decompressed and stored the data as JSON blobs. As I was working with billions of rows of data, it was important to maintain data integrity and take measures in case data failed to load from S3. Therefore, I loaded data into a staging table in Snowflake. The staging table ensured that if loading from S3 failed, the production table would remain untouched. This data was then loaded into the production table free of any partial data. After all the data was loaded into the production table, I created six view tables because there were six different types of bad events stored in the production table.</p><p>I collaborated with our stakeholders\u200a\u2014\u200adata analysts\u200a\u2014\u200athroughout this process to craft tables based on their inputs. Since the JSON information in each of the bad events data contained different schemas, I extracted unique information from each type. I chose to materialize them as SQL view tables to reduce redundancy of data and decrease latency to query the data. After data was aggregated in the appropriate tables, I created a dashboard on Tableau that creates visuals on the number of bad events and displays important metrics. I collaborated with all members of my team throughout my project to discuss timelines, progress, road blocks, and next\u00a0steps.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/465/0*ZoeX3C7NaP2wOOOf\" /><figcaption>Visual representation of the\u00a0pipeline</figcaption></figure><h3>TRACKING GOOD \u2018EVENTS\u2019, TOO</h3><p>My internship was not all about bad events. There were plenty of opportunities to enjoy good events like JAMS and my team\u2019s offsite meet up in the San Francisco office.</p><p>JAMS is Strava\u2019s week-long hackathon. Everyone at Strava enthusiastically participates at JAMS and creates features that range from super useful for the app to something just for fun. It was an incredible experience where I worked with engineers and interns across different teams to integrate Spotify to Strava. The other interns and I would hop on a zoom call together and try to debug scala code, which I also learnt during JAMS! I also created a database to store an athlete\u2019s information, the activity during which they played a song, and a list of songs they have played so\u00a0far.</p><p>Although this internship was fully remote, my team organized a week long offsite meeting at the San Francisco office. The Strava office is beautiful and exactly how you would imagine it\u200a\u2014\u200aindoor gym, a room full of bikes and too many snacks and coffee flavors. During this time, my team and I worked in the mornings, then spent the afternoons making wood boards as a team building exercise, and later enjoying dinner together.</p><p>This internship was an intense and rewarding experience filled with opportunities to learn skills beyond my project guidelines, develop non-technical skills and learn about how my team\u2019s work supports\u00a0Strava.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/465/0*H7cMF8yaZALykpSc\" /><figcaption>Great events</figcaption></figure><h3>Acknowledgement</h3><p>Thank you to my manager, Kau, for guiding throughout my internship, trusting me to lead the discussions with our stakeholder, giving me opportunities beyond programming to grow and setting me up for\u00a0success.</p><p>Thank you Alaena for mentoring me, reviewing my code, providing me clarity on the project, and always being there to guide\u00a0me.</p><p>Shoutout to the rest of the team\u200a\u2014\u200aDaniel, Eric, Alex and Stephen for making my internship a memorable experience, reviewing my PRs, answering all my questions on Slack and Zoom, and for all the wonderful memories during the team\u2019s offsite meet up in San Francisco.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5692882e5f4f\" width=\"1\" /><hr /><p><a href=\"https://medium.com/strava-engineering/an-eventful-summer-at-strava-5692882e5f4f\">AN EVENTFUL SUMMER AT STRAVA</a> was originally published in <a href=\"https://medium.com/strava-engineering\">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>Hi my name is Bisman and I studied Computer Science at University of California, Santa Barbara. During summer of 2022, I had the most amazing experience working as a Software Engineer Intern on Strava\u2019s Data Platform Team. In the first fews weeks, I learned the tools my team uses and then spent the rest of the time working on my\u00a0project.</p><h3>TRACKING BAD\u00a0EVENTS</h3><p>For my major summer project, I created a data pipeline that pulls user behavior data out of external storage and persists it in our data warehouse. Strava uses a service called <a href=\"https://snowplow.io\">Snowplow</a> to collect this user behavior data, like loading a club page or uploading a profile photo. Sometimes, this data fails to match the schema that we\u2019ve set, and a piece of data that fails this schema validation is called a bad event. Previously, these bad events were temporarily stored in an Elastic Search. Persisting this data in <a href=\"https://www.snowflake.com/en/\">Snowflake</a>, our data warehouse, makes it accessible to a wider audience. It also makes it easier to incorporate the bad events data with other services used at\u00a0Strava.</p><p>To start my project, I created a directed acyclic graph in <a href=\"https://airflow.apache.org\">Apache Airflow</a>, a scheduling framework, using python that extracts bad events data from the <a href=\"https://aws.amazon.com/s3/\">S3</a>, AWS\u2019s storage service, buckets on a daily cadence. This data was stored as gzip files on S3 which I decompressed and stored the data as JSON blobs. As I was working with billions of rows of data, it was important to maintain data integrity and take measures in case data failed to load from S3. Therefore, I loaded data into a staging table in Snowflake. The staging table ensured that if loading from S3 failed, the production table would remain untouched. This data was then loaded into the production table free of any partial data. After all the data was loaded into the production table, I created six view tables because there were six different types of bad events stored in the production table.</p><p>I collaborated with our stakeholders\u200a\u2014\u200adata analysts\u200a\u2014\u200athroughout this process to craft tables based on their inputs. Since the JSON information in each of the bad events data contained different schemas, I extracted unique information from each type. I chose to materialize them as SQL view tables to reduce redundancy of data and decrease latency to query the data. After data was aggregated in the appropriate tables, I created a dashboard on Tableau that creates visuals on the number of bad events and displays important metrics. I collaborated with all members of my team throughout my project to discuss timelines, progress, road blocks, and next\u00a0steps.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/465/0*ZoeX3C7NaP2wOOOf\" /><figcaption>Visual representation of the\u00a0pipeline</figcaption></figure><h3>TRACKING GOOD \u2018EVENTS\u2019, TOO</h3><p>My internship was not all about bad events. There were plenty of opportunities to enjoy good events like JAMS and my team\u2019s offsite meet up in the San Francisco office.</p><p>JAMS is Strava\u2019s week-long hackathon. Everyone at Strava enthusiastically participates at JAMS and creates features that range from super useful for the app to something just for fun. It was an incredible experience where I worked with engineers and interns across different teams to integrate Spotify to Strava. The other interns and I would hop on a zoom call together and try to debug scala code, which I also learnt during JAMS! I also created a database to store an athlete\u2019s information, the activity during which they played a song, and a list of songs they have played so\u00a0far.</p><p>Although this internship was fully remote, my team organized a week long offsite meeting at the San Francisco office. The Strava office is beautiful and exactly how you would imagine it\u200a\u2014\u200aindoor gym, a room full of bikes and too many snacks and coffee flavors. During this time, my team and I worked in the mornings, then spent the afternoons making wood boards as a team building exercise, and later enjoying dinner together.</p><p>This internship was an intense and rewarding experience filled with opportunities to learn skills beyond my project guidelines, develop non-technical skills and learn about how my team\u2019s work supports\u00a0Strava.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/465/0*H7cMF8yaZALykpSc\" /><figcaption>Great events</figcaption></figure><h3>Acknowledgement</h3><p>Thank you to my manager, Kau, for guiding throughout my internship, trusting me to lead the discussions with our stakeholder, giving me opportunities beyond programming to grow and setting me up for\u00a0success.</p><p>Thank you Alaena for mentoring me, reviewing my code, providing me clarity on the project, and always being there to guide\u00a0me.</p><p>Shoutout to the rest of the team\u200a\u2014\u200aDaniel, Eric, Alex and Stephen for making my internship a memorable experience, reviewing my PRs, answering all my questions on Slack and Zoom, and for all the wonderful memories during the team\u2019s offsite meet up in San Francisco.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5692882e5f4f\" width=\"1\" /><hr /><p><a href=\"https://medium.com/strava-engineering/an-eventful-summer-at-strava-5692882e5f4f\">AN EVENTFUL SUMMER AT STRAVA</a> was originally published in <a href=\"https://medium.com/strava-engineering\">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Doximity": {
    "title": "Modularizing Rails Monoliths One Bite at a Time",
    "xmlUrl": "https://engineering.doximity.com/feed",
    "htmlUrl": "https://engineering.doximity.com",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://technology.doximity.com:443/feed",
      "value": "Modularizing Rails Monoliths One Bite at a Time"
    },
    "authors": "mreynolds@doximity.com (Marc Reynolds)",
    "published": "Tue, 05 Dec 2023 13:00:00 +0000",
    "published_parsed": [
      2023,
      12,
      5,
      13,
      0,
      0,
      1,
      339,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://technology.doximity.com/articles/modularizing-rails-monoliths-one-bite-at-a-time"
      }
    ],
    "link": "https://technology.doximity.com/articles/modularizing-rails-monoliths-one-bite-at-a-time",
    "id": "https://technology.doximity.com/articles/modularizing-rails-monoliths-one-bite-at-a-time",
    "guidislink": false,
    "summary": "<p><img src=\"https://res.cloudinary.com/dhttas9u5/image/upload/c_fill,dpr_2,fl_progressive,h_800,q_auto,w_1600/mpcipjslp66ugbjrlcds.jpg\" /></p>\n<p>As Rails monoliths grow, coupling becomes increasingly difficult to manage. Developers often reach for microservices to help simplify things, but instead find higher complexity. The Modular Monolith approach is a proven, lightweight alternative that offers the benefits of enforced boundaries without being cumbersome. I spoke at the 2023 Rocky Mountain Ruby conference on how teams can use a phased approach to refactoring toward this style using the <a href=\"https://github.com/Shopify/packwerk\">packwerk</a> gem. At Doximity, we've used this gem and a phased approach to break some of our most critical rails applications into modules that are easier for our teams to work with.</p>\n\n\n\n<p>In November, 2023, I also chatted with Elise Shaffer on <a href=\"https://www.therubyonrailspodcast.com/495\">The Ruby on Rails Podcast</a> about our experience with application modularization at Doximity.</p>\n\n\n\n<hr />\n\n<p>Be sure to follow <a href=\"https://twitter.com/doximity_tech\">@doximity_tech</a> if you'd like to be notified about new blog posts.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://technology.doximity.com:443/feed",
      "value": "<p><img src=\"https://res.cloudinary.com/dhttas9u5/image/upload/c_fill,dpr_2,fl_progressive,h_800,q_auto,w_1600/mpcipjslp66ugbjrlcds.jpg\" /></p>\n<p>As Rails monoliths grow, coupling becomes increasingly difficult to manage. Developers often reach for microservices to help simplify things, but instead find higher complexity. The Modular Monolith approach is a proven, lightweight alternative that offers the benefits of enforced boundaries without being cumbersome. I spoke at the 2023 Rocky Mountain Ruby conference on how teams can use a phased approach to refactoring toward this style using the <a href=\"https://github.com/Shopify/packwerk\">packwerk</a> gem. At Doximity, we've used this gem and a phased approach to break some of our most critical rails applications into modules that are easier for our teams to work with.</p>\n\n\n\n<p>In November, 2023, I also chatted with Elise Shaffer on <a href=\"https://www.therubyonrailspodcast.com/495\">The Ruby on Rails Podcast</a> about our experience with application modularization at Doximity.</p>\n\n\n\n<hr />\n\n<p>Be sure to follow <a href=\"https://twitter.com/doximity_tech\">@doximity_tech</a> if you'd like to be notified about new blog posts.</p>"
    }
  },
  "Speedledger": {
    "title": "DevSum 2018 and the next steps on my journey",
    "xmlUrl": "http://engineering.speedledger.com/feed/",
    "htmlUrl": "http://engineering.speedledger.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://engineering.speedledger.com/feed/",
      "value": "DevSum 2018 and the next steps on my journey"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "http://engineering.speedledger.com/devsum-2018-and-the-next-steps-on-my-journey/"
      }
    ],
    "link": "http://engineering.speedledger.com/devsum-2018-and-the-next-steps-on-my-journey/",
    "comments": "http://engineering.speedledger.com/devsum-2018-and-the-next-steps-on-my-journey/#comments",
    "authors": [
      {
        "name": "Magnus H\u00e4rlin"
      }
    ],
    "author": "Magnus H\u00e4rlin",
    "author_detail": {
      "name": "Magnus H\u00e4rlin"
    },
    "published": "Mon, 02 Jul 2018 11:37:27 +0000",
    "published_parsed": [
      2018,
      7,
      2,
      11,
      37,
      27,
      0,
      183,
      0
    ],
    "tags": [
      {
        "term": "Conferences",
        "scheme": null,
        "label": null
      }
    ],
    "id": "http://engineering.speedledger.com/?p=249",
    "guidislink": false,
    "summary": "I really like conference driven development, where you choose an interesting subject, submit it to a conference and you are forced (in a good way) to get a much deeper understanding of the topic to make it into a interesting session. I presented \u2018Scala for Java Developers\u2019 at DevSum 2018 which is based on my [&#8230;]",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "http://engineering.speedledger.com/feed/",
      "value": "I really like conference driven development, where you choose an interesting subject, submit it to a conference and you are forced (in a good way) to get a much deeper understanding of the topic to make it into a interesting session. I presented \u2018Scala for Java Developers\u2019 at DevSum 2018 which is based on my [&#8230;]"
    },
    "wfw_commentrss": "http://engineering.speedledger.com/devsum-2018-and-the-next-steps-on-my-journey/feed/",
    "slash_comments": "1"
  },
  "Wingify": {
    "title": "How we are writing modern Javascript with AngularJs",
    "xmlUrl": "http://engineering.wingify.com/atom.xml",
    "htmlUrl": "http://engineering.wingify.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.wingify.com/atom.xml",
      "value": "How we are writing modern Javascript with AngularJs"
    },
    "summary": "Preface Writing slick user interfaces has never been so delightful as it is now. You\u2019ve got amazing frameworks, state management patterns\u2026",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.wingify.com/atom.xml",
      "value": "Preface Writing slick user interfaces has never been so delightful as it is now. You\u2019ve got amazing frameworks, state management patterns\u2026"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.wingify.com//posts/how-we-writing-modern-javascript-with-angularjs-1-x/"
      }
    ],
    "link": "https://engineering.wingify.com//posts/how-we-writing-modern-javascript-with-angularjs-1-x/",
    "id": "https://engineering.wingify.com//posts/how-we-writing-modern-javascript-with-angularjs-1-x/",
    "guidislink": false,
    "published": "Wed, 22 Mar 2023 00:00:00 GMT",
    "published_parsed": [
      2023,
      3,
      22,
      0,
      0,
      0,
      2,
      81,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.wingify.com/atom.xml",
        "value": "<div class=\"img-wrapper\" style=\"text-align: center;\">\n    <img alt=\"Angular sword meme\" src=\"https://engineering.wingify.com/images/2023/01/angular-sword.jpeg\" width=\"40%\" />\n</div>\n<h2 id=\"preface\"><a class=\"anchor before\" href=\"https://engineering.wingify.com/atom.xml#preface\"><svg height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\" fill-rule=\"evenodd\"></path></svg></a>Preface</h2>\n<p>Writing slick user interfaces has never been so delightful as it is now. You\u2019ve got amazing frameworks, state management patterns that are easy to reason about, development tools, awesome community support, and all the tools around the whole Javascript world. The <em>Developer Experience (DX)</em> you get today, no matter what modern stack you choose, is simply great. Features like <em>compile-time error detection</em>, <em>pre-processors</em>, and <em>hot-reload</em> are just taken for granted and undoubtedly cut development time by a large margin.</p>\n<p>Unfortunately, not every software product has the advantage of being developed in such an ideal setting. This shiny JS world was just lit by a few stars like <em>AngularJS</em> when we started writing the new user interface for VWO which now has evolved into a very large codebase with uncountable features and has been consistently updated and maintained over the years. </p>\n<p>With AngularJS 1.x, we were required to develop our own build system and use custom pre-processors and transpilers to achieve the same capabilities that modern frameworks provide natively. In short, we had to handle the <em>developer experience</em> aspect internally, and we have managed to do so quite effectively.</p>\n<p>Although AngularJs is too old to be used for any web application today, over time we have learned how to use it in a modern way.</p>\n<p>In this blog post, we will discuss how we write modern Javascript along with AngularJS 1.x and discuss some of the key features and tools that we leverage to make development more efficient and maintainable.</p>\n<h2 id=\"typescript\"><a class=\"anchor before\" href=\"https://engineering.wingify.com/atom.xml#typescript\"><svg height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\" fill-rule=\"evenodd\"></path></svg></a>Typescript</h2>\n<p>Using JavaScript for web-dev is like playing on hardcore-mode.\nYou've allowed friendly-fire. If you want to shoot yourself in the foot, you can shoot yourself in the foot.\nWe're not up for that. We love our foot and also want to keep VWO running bug-free and that is why we use Typescript.</p>\n<p>Typescript needs no introduction and we started the process of migrating our app codebase to TS around 3 years back, although it wasn\u2019t straightforward as we had been using a lot of legacy patterns like <em>AMD (asynchronous module definition)</em> with <em>requireJS</em> and a very custom build process that involved <em>Grunt</em> and older version of <em>NodeJs</em> to build it.</p>\n<p>We wanted to use <em>ES import syntax</em> with strong types but all we saw was:</p>\n<div class=\"img-wrapper\" style=\"text-align: center;\">\n    <img alt=\"DEFINE DEFINE EVERYWHERE\" src=\"https://engineering.wingify.com/images/2023/01/define-define.jpg\" width=\"40%\" />\n</div>\n<p>We analyzed the <a href=\"https://www.typescriptlang.org/docs/handbook/compiler-options.html\" target=\"_blank\">tscompiler options</a> and set the <a href=\"https://www.typescriptlang.org/tsconfig/#target\" target=\"_blank\">target</a> to AMD and wrote a custom process to rename all JS files to TS and applied <a href=\"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-7.html#-ts-nocheck-in-typescript-files\" target=\"_blank\"><code class=\"language-text\">// @ts-nocheck</code> directive</a> on the top without touching the source code at all. This way the whole team could write TS for new files and writing TS was opt-in for older files.</p>\n<p>Although, we had to keep <code class=\"language-text\">tsconfig.json</code> very lenient at the start with compiler options that enforced strict code had to be turned off. New files could be written with the modern ES import syntax and older files could be manually translated.</p>\n<p>After some time, we realized that manual translation from AMD to ES would take an eternity to complete, we looked for solutions and luckily found a <a href=\"https://github.com/facebook/jscodeshift\" target=\"_blank\">JScodeshift</a> that could <a href=\"https://github.com/5to6/5to6-codemod\" target=\"_blank\">transform AMD to ES</a></p>\n<p>As time passed by, our team gradually adopted Typescript and leveraged its countless features, resulting in a codebase that is exceptionally type-safe.</p>\n<p>For example, the <a href=\"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-7.html#optional-chaining\" target=\"_blank\">optional chaining operator</a> allows us to access the properties of an object without worrying about whether the object is null or undefined. This can save a lot of time and effort when working with complex objects, as it eliminates the need to check for null or undefined values at every level.</p>\n<p>We also wrote <em>TS decorators</em> for class methods and they just work wonders for us.</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-ts\"><code class=\"language-ts\">@<span class=\"token function\">memoize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span> cacheKeyResolver<span class=\"token operator\">:</span> <span class=\"token constant\">JSON</span><span class=\"token punctuation\">.</span>stringify <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n@<span class=\"token function\">batchify</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n\tbatchKey<span class=\"token operator\">:</span> <span class=\"token string\">'ids'</span><span class=\"token punctuation\">,</span>\n\tmaxBatchCapacity<span class=\"token operator\">:</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n\tmaxWait<span class=\"token operator\">:</span> <span class=\"token number\">1000</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n@<span class=\"token function\">asyncThrottle</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span> MaxRequestCount<span class=\"token operator\">:</span> <span class=\"token number\">12</span><span class=\"token punctuation\">,</span> isLIFO<span class=\"token operator\">:</span> <span class=\"token boolean\">true</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n<span class=\"token function\">getCampaignsDetails</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">params<span class=\"token operator\">:</span> QueryForListParams</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\t<span class=\"token keyword\">return</span>  <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>CampaignResource<span class=\"token punctuation\">.</span><span class=\"token function\">queryForCampaignsList</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">null</span><span class=\"token punctuation\">,</span> params<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>We use multiple decorators as shown above which help us separate out the business logics and performance improvements. Not only this helps us maintain the code, but also makes the code easy to follow and <strong>self-documenting</strong>. </p>\n<blockquote>\n<p> <strong>Code is like humor. When you have to explain it, it's bad!</strong> </p>\n</blockquote>\n<p>Apart from this, we utilize <code class=\"language-text\">enums</code> and the new <a href=\"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-4-9.html#the-satisfies-operator\" target=\"_blank\"><code class=\"language-text\">satisfies</code></a> operator to make <strong>deeply typesafe code.</strong></p>\n<div class=\"gatsby-highlight\"><pre class=\"language-ts\"><code class=\"language-ts\"><span class=\"token keyword\">enum</span> SessionPlatform <span class=\"token punctuation\">{</span>\n\t<span class=\"token constant\">MOBILE</span> <span class=\"token operator\">=</span> <span class=\"token string\">'mobile'</span><span class=\"token punctuation\">,</span>\n\t<span class=\"token constant\">TABLET</span> <span class=\"token operator\">=</span> <span class=\"token string\">'tablet'</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">const</span>  SessionPlatformDetails  <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n\t<span class=\"token punctuation\">[</span>SessionPlatform<span class=\"token punctuation\">.</span><span class=\"token constant\">MOBILE</span><span class=\"token punctuation\">]</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n\t\ticon<span class=\"token operator\">:</span> IconEnum<span class=\"token punctuation\">.</span><span class=\"token constant\">MOBILE_ICON</span><span class=\"token punctuation\">,</span>\n\t\ttitle<span class=\"token operator\">:</span> <span class=\"token string\">'Mobile'</span>\n\t<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n\t<span class=\"token punctuation\">[</span>SessionPlatform<span class=\"token punctuation\">.</span><span class=\"token constant\">TABLET</span><span class=\"token punctuation\">]</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n\t\ticon<span class=\"token operator\">:</span> IconEnum<span class=\"token punctuation\">.</span><span class=\"token constant\">IPAD_ICON</span><span class=\"token punctuation\">,</span>\n\t\ttitle<span class=\"token operator\">:</span> <span class=\"token string\">'Tablet'</span>\n\t<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">as</span> <span class=\"token keyword\">const</span> satisfies Record<span class=\"token operator\">&lt;</span>SessionPlatformSupportedEnum<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span>\n\ticon<span class=\"token operator\">:</span> IconEnum<span class=\"token punctuation\">,</span> \n\ttitle<span class=\"token operator\">:</span> <span class=\"token builtin\">string</span>\n<span class=\"token punctuation\">}</span><span class=\"token operator\">></span><span class=\"token punctuation\">;</span></code></pre></div>\n<div style=\"text-align: center; font-size: 12px; margin-bottom: 20px;\">\nThe code as above ensures that if a new <code class=\"language-text\">SessionPlatform</code> is added, the developer never misses adding the details in <code class=\"language-text\">SessionPlatformDetails</code>.\n</div>\n<p>Recently, we also learnt about writing <a href=\"https://medium.com/technogise/type-safe-and-exhaustive-switch-statements-aka-pattern-matching-in-typescript-e3febd433a7a\" target=\"_blank\">exhaustive switch cases with TS</a> that basically eliminates any missed cases on compile-time itself.</p>\n<h3 id=\"async-await-support\"><a class=\"anchor before\" href=\"https://engineering.wingify.com/atom.xml#async-await-support\"><svg height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\" fill-rule=\"evenodd\"></path></svg></a>Async-await support</h3>\n<p>AngularJs uses it's own <code class=\"language-text\">$q</code> service which is a first-class Promise implementation, but along with that it ensures that angular's digest cycle triggers automatically on promise status change.\nThis works well until the developer ensures that native <code class=\"language-text\">Promise</code> is NOT used anywhere and only <code class=\"language-text\">$q</code> is used for any async operation, but easily falls apart if they use <code class=\"language-text\">async-await</code> which uses native <code class=\"language-text\">Promise</code> internally and digest cycles are missed.\nTo mitigate this, we use <code class=\"language-text\">target</code> for TScompiler is <code class=\"language-text\">ES5</code> which transpiles ES5+ code down to ES5 and polyfill the new features with tslib/ts_helpers. The <code class=\"language-text\">async-await</code> code is transpiled down to using Native Promise.\nNow that is a small issue as the transpiled code directly depends on global <code class=\"language-text\">Promise</code> and we wanted the transpiled code to use <code class=\"language-text\">$q</code>. To fix this, we did a smart hack, by ensuring the global <code class=\"language-text\">Promise</code> always points to <code class=\"language-text\">$q</code> in the <code class=\"language-text\">app.run</code> block.</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-ts\"><code class=\"language-ts\">Object<span class=\"token punctuation\">.</span><span class=\"token function\">defineProperty</span><span class=\"token punctuation\">(</span>window<span class=\"token punctuation\">,</span> <span class=\"token string\">'Promise'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span>\n\t<span class=\"token keyword\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\t\t<span class=\"token keyword\">return</span> $q<span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n\t<span class=\"token keyword\">set</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\t\t<span class=\"token comment\">// ignore any other code trying to replace global Promise</span>\n\t<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>Now, we have complete clean async-await support without worrying about missing digest and no promise-hells \ud83d\ude09.</p>\n<p>I can keep on blabbering about how amazing typescript is (because it <strong>really is</strong>), but I'll move on.</p>\n<h2 id=\"tuning-angularjs\"><a class=\"anchor before\" href=\"https://engineering.wingify.com/atom.xml#tuning-angularjs\"><svg height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\" fill-rule=\"evenodd\"></path></svg></a>Tuning AngularJS</h2>\n<p>Everything around AngularJS is legacy now, be it available packages, community support, or answers over stackoverflow.\nOver the course of last few years, we upgraded the version of AngularJS in our VWO app from 1.2.x to 1.8.3 (last version of 1.x that Angular team left us with \ud83e\udd72).\nThis upgrade also was gradual and version-by-version as we had to go through the complete changelog of AngularJS. We were also at risk of depending on any deprecated undocumented APIs, hence extra care was needed.</p>\n<p>However, everything eventually worked and we were running the latest version. We also upgraded few of the other related packages and <code class=\"language-text\">@types/angular</code> package for best typing support from TS.</p>\n<h3 id=\"importable-angularjs-services\"><a class=\"anchor before\" href=\"https://engineering.wingify.com/atom.xml#importable-angularjs-services\"><svg height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\" fill-rule=\"evenodd\"></path></svg></a>Importable AngularJS services</h3>\n<p>AngularJS came with it's own dependency injection system because at that time, no particular module system was there in place in browsers. Developers usually used to mess-up the global namespace for code-sharing and hence dependency injection was a welcome move by Angular.\nAlthough, the way it had to be used was cumbersome where developer had to ensure the exact name with order in <code class=\"language-text\">$inject</code> and the order in the method being injected.\nWe have moved on from that as we have ES module system in place (thanks to TS) and now we create and export instance of AngularJS services as soon as they get created. </p>\n<p>We've exported all the native angular services like <code class=\"language-text\">$http</code> from a single file named <code class=\"language-text\">ngImports</code>. This basically helps us evade the dependency injection and import services as if another ES module.\nHere is how it works:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-ts\"><code class=\"language-ts\"><span class=\"token comment\">/** ngImports.ts */</span>\n<span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> ng <span class=\"token keyword\">from</span> <span class=\"token string\">'angular'</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> app <span class=\"token keyword\">from</span> <span class=\"token string\">'app'</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// app is our angular module's instance</span>\n\napp<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'$injector'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token parameter\">$i<span class=\"token operator\">:</span> ng<span class=\"token punctuation\">.</span>auto<span class=\"token punctuation\">.</span>IInjectorService</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n\t\t$http <span class=\"token operator\">=</span> $i<span class=\"token punctuation\">.</span><span class=\"token keyword\">get</span><span class=\"token punctuation\">(</span><span class=\"token string\">'$http'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token comment\">// and so on for every other native service...</span>\n\t<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">export</span> <span class=\"token keyword\">let</span> $http<span class=\"token operator\">:</span> ng<span class=\"token punctuation\">.</span>IHttpService<span class=\"token punctuation\">;</span></code></pre></div>\n<p>For our custom services, we have been writing TS classes which create strongly-typed injectables. We export custom services instance from the definition file itself.\nHere is an example:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-ts\"><code class=\"language-ts\"><span class=\"token comment\">/** importHelpers.ts */</span>\n<span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> ng <span class=\"token keyword\">from</span> <span class=\"token string\">'angular'</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> app <span class=\"token keyword\">from</span> <span class=\"token string\">'app'</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">let</span> $injector<span class=\"token operator\">:</span> ng<span class=\"token punctuation\">.</span>auto<span class=\"token punctuation\">.</span>IInjectorService<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">export</span> <span class=\"token keyword\">function</span> getInjectable<span class=\"token operator\">&lt;</span><span class=\"token constant\">T</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>injectable<span class=\"token operator\">:</span> <span class=\"token builtin\">string</span><span class=\"token punctuation\">,</span> <span class=\"token function-variable function\">callback</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">(</span><span class=\"token parameter\">instance<span class=\"token operator\">:</span> <span class=\"token constant\">T</span></span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token keyword\">void</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>$injector<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\t\t<span class=\"token function\">callback</span><span class=\"token punctuation\">(</span>$injector<span class=\"token punctuation\">.</span><span class=\"token keyword\">get</span><span class=\"token operator\">&lt;</span><span class=\"token constant\">T</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>injectable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n\t\tapp<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'$injector'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token parameter\">$injector<span class=\"token operator\">:</span> ng<span class=\"token punctuation\">.</span>auto<span class=\"token punctuation\">.</span>IInjectorService</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n\t\t\t\t<span class=\"token function\">callback</span><span class=\"token punctuation\">(</span>$injector<span class=\"token punctuation\">.</span><span class=\"token keyword\">get</span><span class=\"token operator\">&lt;</span><span class=\"token constant\">T</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>injectable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">}</span>\n\t\t<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n\n<span class=\"token comment\">/** CampaignService.ts */</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CampaignService</span> <span class=\"token punctuation\">{</span>\n\t<span class=\"token comment\">// implementation here...</span>\n<span class=\"token punctuation\">}</span>\n\napp<span class=\"token punctuation\">.</span><span class=\"token function\">service</span><span class=\"token punctuation\">(</span><span class=\"token string\">'campaignService'</span><span class=\"token punctuation\">,</span> CampaignService<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">export</span> <span class=\"token keyword\">let</span> campaignService<span class=\"token operator\">:</span> CampaignService<span class=\"token punctuation\">;</span>\ngetInjectable<span class=\"token operator\">&lt;</span>CampaignService<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token string\">'campaignService'</span><span class=\"token punctuation\">,</span> <span class=\"token parameter\">instance</span> <span class=\"token operator\">=></span> campaignService <span class=\"token operator\">=</span> instance<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>In the code above, <code class=\"language-text\">campaignService</code> is the instance of <code class=\"language-text\">CampaignService</code> that becomes directly importable anywhere throughout the codebase without going through the hassles of injection and preserves the type-safety automatically. </p>\n<h3 id=\"component-based-and-intelligent-attribute-directives\"><a class=\"anchor before\" href=\"https://engineering.wingify.com/atom.xml#component-based-and-intelligent-attribute-directives\"><svg height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\" fill-rule=\"evenodd\"></path></svg></a>Component-based and intelligent attribute directives</h3>\n<p>AngularJS always had the component-based architecture available at hand but under the disguise of isolated scope directives.\nIn fact, isolated scope directives are much more powerful as you have access to everything, from requiring other controllers up the chain, having access to element using <code class=\"language-text\">$element</code> and the least appreciated feature - Transclusion.</p>\n<p>Transclusion is probably the most underrated feature that AngularJs provides. This is basically analogous to <em>slots</em> in VueJS. This allows us build components that can take parts of the template as input from the consumer of component, letting us make very generic components that only encapsulate javascript logic, and the styling and the content can be outsourced to consumer.</p>\n<p>For example, here we're using our select-box component which handles everything that a select-box should, but along with that, the consumer of component has complete control on how options should look (like icons, tooltips).\nThis is probably as powerful as any other modern framework.</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-html\"><code class=\"language-html\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>vwo-select-box</span>\n\t<span class=\"token attr-name\">options</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>vm.selectBoxOptions<span class=\"token punctuation\">\"</span></span>\n\t<span class=\"token attr-name\">ng-model</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>vm.ngModelSelectBox<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>selected-value-slot</span><span class=\"token punctuation\">></span></span>\n\t\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>span</span><span class=\"token punctuation\">></span></span>Selected - {{$slot.option.name}}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>span</span><span class=\"token punctuation\">></span></span>\n\t\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>vwo-icon</span>\n\t\t  <span class=\"token attr-name\">vwo-dynamic-tooltip-next</span>\n\t\t  <span class=\"token attr-name\">icon-size</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>20<span class=\"token punctuation\">\"</span></span> \n\t\t  <span class=\"token attr-name\">icon-name</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>icon--info<span class=\"token punctuation\">\"</span></span> \n\t\t  <span class=\"token attr-name\">class</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>icon text--highlight<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n\t\t\t  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>tooltip-content</span><span class=\"token punctuation\">></span></span>\n\t\t\t\t  This just shows what you have selected. \n\t\t\t\t  You have selected '{{$slot.option.name}}'\n\t\t\t  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>tooltip-content</span><span class=\"token punctuation\">></span></span>\n\t\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>vwo-icon</span><span class=\"token punctuation\">></span></span>\n\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>selected-value-slot</span><span class=\"token punctuation\">></span></span>\n\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>option-slot</span><span class=\"token punctuation\">></span></span>\n\t\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>span</span><span class=\"token punctuation\">></span></span>{{$slot.option.name}}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>span</span><span class=\"token punctuation\">></span></span>\n\t\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>vwo-icon</span>\n\t\t  <span class=\"token attr-name\">vwo-dynamic-tooltip-next</span>\n\t\t  <span class=\"token attr-name\">icon-size</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>20<span class=\"token punctuation\">\"</span></span> \n\t\t  <span class=\"token attr-name\">icon-name</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>icon--info<span class=\"token punctuation\">\"</span></span> \n\t\t  <span class=\"token attr-name\">class</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>icon text--highlight<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n\t\t\t  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>tooltip-content</span><span class=\"token punctuation\">></span></span>\n\t\t\t    Clicking on this option will select {{$slot.option.name}}\n\t\t\t  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>tooltip-content</span><span class=\"token punctuation\">></span></span>\n\t\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>vwo-icon</span><span class=\"token punctuation\">></span></span>\n\t<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>option-slot</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>vwo-select-box</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>Modern frameworks provide a component-only approach to UI development, while AngularJS provides a full flexibility around that and which is taken to the next level with attribute based directives.\nAttribute based directives have a complete access to the whole life-cycle of an element and can modify it's behavior at any point of time. We use these directives very frequently to easily add reusable behaviors anywhere we'd want.</p>\n<p>For example, there is a very generic requirement to ellipsize texts in limited screen-estate, but along with ellipsizing, it also becomes a requirement to add title for screen-readers or for looking at complete text when hovered. We have been able to encapsulate all of this covering every edge-case in a very simple attribute that would ellipsize wherever required, automatically.</p>\n<p>For example:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-html\"><code class=\"language-html\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>span</span> <span class=\"token attr-name\">class</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>Miw(0)<span class=\"token punctuation\">\"</span></span> <span class=\"token attr-name\">vwo-ellipsize</span><span class=\"token punctuation\">></span></span>{{ session.platformName }}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>span</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>We use Mutation Observers, Resize Observers, real-time space availability checks, etc to decide the truncation of text and ensuring the element has title only if truncated. All of this wrapped in a cute-little attribute that we can put anywhere the text could grow. </p>\n<p>See, AngularJS is not so bad after all \ud83d\ude05!</p>\n<h3 id=\"hot-module-replacement\"><a class=\"anchor before\" href=\"https://engineering.wingify.com/atom.xml#hot-module-replacement\"><svg height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\" fill-rule=\"evenodd\"></path></svg></a>Hot Module Replacement</h3>\n<p>Hot Module Replacement (HMR) is taken for granted these days with such incredible tooling at hand, and with native framework support, it becomes a breeze to develop user interfaces at an incredible pace. The feedback loop is almost friction-less and you get to see things on-screen as you type and save.</p>\n<div class=\"img-wrapper\" style=\"text-align: center;\">\n    <img alt=\"HMR meme\" src=\"https://engineering.wingify.com/images/2023/01/laxman-hmr.jpeg\" width=\"50%\" />\n</div>\n<p>HMR is a fancy new thing and wasn't even a feature back then. With our archaic build process using grunt, loading modules using requireJS (AMD) and AngularJS with it's own cluttered dependency injection pattern, HMR was only a dream for us (at least until recently). This was more like looking for a Torque Converter in our stick-shift manual. </p>\n<p>Although, it was need of the hour, as a full-reload of the app on every code change was wasting a lot of time of our developers.\nWe started thinking around ways that could refresh the app with updated code in a jiffy without a full-reload.</p>\n<p>There were multiple challenges and multiple iterations, but we were able to create a solution. Our latest HMR system streams all your HTML/TS/CSS changes to your browser in less than a second and the repaint is virtually flicker-free.\nThe system uses multiple nuances of requireJs, AngularJS, TS and DOM along with a lot of intelligent caching and batching to make this possible under a second and flicker-free.</p>\n<p>Don't tell, just show? Here you go \ud83d\ude80:</p>\n<div class=\"img-wrapper\" style=\"text-align: center;\">\n    <video alt=\"HMR Video Preview\" controls=\"true\" loop=\"true\" src=\"https://engineering.wingify.com/images/2023/01/hmr-edit.mp4\" width=\"80%\">\n</div>\n<br />\n<p>A detailed blog post around how this system works is on the way. So, stay tuned!</p>\n<h2 id=\"whats-next\"><a class=\"anchor before\" href=\"https://engineering.wingify.com/atom.xml#whats-next\"><svg height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\" fill-rule=\"evenodd\"></path></svg></a>What's next</h2>\n<p>We have been evolving our frontend engineering consistently to make it on-par with the new technologies and frameworks emerging all the time and shared some of the key tips and tricks in this post.</p>\n<div class=\"img-wrapper\" style=\"text-align: center;\">\n    <img alt=\"Tension meme\" src=\"https://engineering.wingify.com/images/2023/01/tension.jpeg\" width=\"40%\" />\n    <img alt=\"Tension sorted meme\" src=\"https://engineering.wingify.com/images/2023/01/tension-sorted.jpeg\" width=\"40%\" />\n</div>\n<p>Despite these advancements, there are still some challenges that we need to overcome, such as build process speed and the need to optimize for performance and actually a new framework. Looking to the future, it's clear that we probably need to move on from AngularJS one day and we already have laid the stepping stones for that.\nWe're in the process of moving away from our age old grunt to a newer build process (probably using <a href=\"https://vitejs.dev/\" target=\"_blank\">Vite</a>) which will provide us with the latest tooling, faster build and path to upgrade to a modern framework.</p>\n<p>We'll share our progress around that in another blog post.\nTill then keep innovating and keep experimenting!</p>\n<p><em>PS: We're not too far \ud83d\ude09, and already have an alpha ready with Vite \ud83d\udd25.</em></p>"
      }
    ],
    "authors": [
      {
        "name": "Pranav Jindal"
      }
    ],
    "author": "Pranav Jindal",
    "author_detail": {
      "name": "Pranav Jindal"
    }
  },
  "Instagram": {
    "title": "The Instagram Engineering Blog has a new location",
    "xmlUrl": "https://instagram-engineering.com/feed",
    "htmlUrl": "https://engineering.instagram.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://instagram-engineering.com/feed",
      "value": "The Instagram Engineering Blog has a new location"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://instagram-engineering.com/the-instagram-engineering-blog-has-a-new-location-85de9ab8d90f?source=rss----37dc2a3034f2---4"
      }
    ],
    "link": "https://instagram-engineering.com/the-instagram-engineering-blog-has-a-new-location-85de9ab8d90f?source=rss----37dc2a3034f2---4",
    "id": "https://medium.com/p/85de9ab8d90f",
    "guidislink": false,
    "tags": [
      {
        "term": "software-engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "instagram",
        "scheme": null,
        "label": null
      },
      {
        "term": "computer-science",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Ryan Peterman"
      }
    ],
    "author": "Ryan Peterman",
    "author_detail": {
      "name": "Ryan Peterman"
    },
    "published": "Tue, 12 Jul 2022 17:00:22 GMT",
    "published_parsed": [
      2022,
      7,
      12,
      17,
      0,
      22,
      1,
      193,
      0
    ],
    "updated": "2022-07-12T17:00:22.186Z",
    "updated_parsed": [
      2022,
      7,
      12,
      17,
      0,
      22,
      1,
      193,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://instagram-engineering.com/feed",
        "value": "<p>In order to streamline our internal blog operations, all future Instagram Engineering content will be posted on the <a href=\"https://engineering.fb.com/instagram/\">Engineering at Meta blog located\u00a0here.</a></p><p>This will allow us to post more regularly about the novel engineering work being done at Instagram.</p><p>To stay connected for future content, you can follow our socials\u00a0here:</p><ul><li><a href=\"https://twitter.com/fb_engineering\">Engineering @ Meta\u00a0Twitter</a></li><li><a href=\"https://www.facebook.com/Engineering/\">Engineering @ Meta Facebook\u00a0Page</a></li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=85de9ab8d90f\" width=\"1\" /><hr /><p><a href=\"https://instagram-engineering.com/the-instagram-engineering-blog-has-a-new-location-85de9ab8d90f\">The Instagram Engineering Blog has a new location</a> was originally published in <a href=\"https://instagram-engineering.com\">Instagram Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>In order to streamline our internal blog operations, all future Instagram Engineering content will be posted on the <a href=\"https://engineering.fb.com/instagram/\">Engineering at Meta blog located\u00a0here.</a></p><p>This will allow us to post more regularly about the novel engineering work being done at Instagram.</p><p>To stay connected for future content, you can follow our socials\u00a0here:</p><ul><li><a href=\"https://twitter.com/fb_engineering\">Engineering @ Meta\u00a0Twitter</a></li><li><a href=\"https://www.facebook.com/Engineering/\">Engineering @ Meta Facebook\u00a0Page</a></li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=85de9ab8d90f\" width=\"1\" /><hr /><p><a href=\"https://instagram-engineering.com/the-instagram-engineering-blog-has-a-new-location-85de9ab8d90f\">The Instagram Engineering Blog has a new location</a> was originally published in <a href=\"https://instagram-engineering.com\">Instagram Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Findmypast": {
    "title": "DevOps at Findmypast: How Spanners implement DevOps Practices",
    "xmlUrl": "https://tech.findmypast.com/feed.xml",
    "htmlUrl": "http://tech.findmypast.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.findmypast.com/feed.xml",
      "value": "DevOps at Findmypast: How Spanners implement DevOps Practices"
    },
    "summary": "<p><strong>Introduction</strong></p>\n\n<p>There are many ways to define DevOps and even more ways to implement its core principles within an organisation. To the Spanners team, DevOps is an iterative and collaborative approach to the development, testing, deployment and monitoring of software services. Overall, there is a great deal of alignment with the thoughts outlined by <a href=\"https://theagileadmin.com/what-is-devops/\">Mueller</a> and <a href=\"https://www.chef.io/blog/what-devops-means-to-me\">Willis</a> regarding what DevOps is, and how it is best implemented.</p>\n\n<p>Spanners see our role within the wider engineering cohort at <a href=\"https://www.findmypast.com/\">Findmypast</a> as advocates for DevOps principles and practices, and the vehicle through which those practices can be implemented day-to-day. Spanners operate as an autonomous team, but our efforts centre around providing feature teams with the processes and tools they need to reap the rewards of following a DevOps approach when developing and maintaining services.</p>\n\n<div align=\"center\">\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/atlassian-devops.png\" width=\"900\" />\n</div>\n<div align=\"center\">\n  <p>Source: <a href=\"https://www.atlassian.com/devops/what-is-devops\">Atlassian</a></p>\n</div>\n\n<p><strong>Team Goals</strong></p>\n\n<p>Our goals always trace back to wider organisation goals that in turn align with the expected company and department behaviours. For Spanners our quarterly team goals generally focus on how we improve five key areas in terms of software delivery across the engineering teams:</p>\n\n<ul>\n  <li><strong>Speed of Deployment</strong> \u2013 The rate of code deployments and the speed with which code can be built, tested and deployed to our environments.</li>\n  <li><strong>Collaboration</strong> \u2013 Enable teams to investigate issues and monitor services and systems using a well-defined and trusted series of tools. Providing a framework for teams to take Ownership of the service pipelines (sometimes described as \u201cYou build it, you run it\u201d).</li>\n  <li><strong>Quality</strong> \u2013 Enable teams to continually improve upon their service/s through automation in the form of CI/CD pipelines, and quickly identify issues and shortcomings in those implementations.</li>\n  <li><strong>Reliability</strong> \u2013 Reduce variables when it comes to the building, testing and deployment of code changes, and provide near real-time feedback (measurement) of the effectiveness of those code changes.</li>\n  <li><strong>Security</strong> \u2013 We strive to manage everything as code and provide the tools and means for all engineers to do their jobs with minimal friction, building security and accountability into everything we deliver.</li>\n</ul>\n\n<p><strong>The Team</strong></p>\n\n<p>The Spanners team comprises eight engineers, supporting a wider engineering cohort of roughly 120 engineers and management.  Backgrounds within the team vary, some members having more of an operations background, whilst others have more of a development background.  The Spanners team is truly multi-disciplinary, with a variety of skill levels ranging from senior to junior, and a variety of specialisms within the team.  This breadth of knowledge enables Spanners to provide a one-stop-shop for support of the product build pipelines and underpinning technologies.</p>\n\n<p>Spanners operate like any other feature team within the wider engineering group.  We follow an agile methodology built around a fortnightly sprint cycle, and follow a regular cadence of planning, refining and retrospective meetings.</p>\n\n<p>To ensure queries from the wider engineering group are answered in good time, we operate a support rota, whereby a team member is assigned as an initial point-of-contact for queries.  This ensures that the team is always on hand to collaborate with a feature team on a request or an incident.</p>\n\n<p><strong>The Challenge</strong></p>\n\n<p>One underappreciated aspect of software development is the need to integrate new team members into the engineering cohort.  Without a smooth on-boarding process both the new and existing team members can become bogged down in the configuration of systems, tools and certificates. Ultimately, this results in a negative impact to the speed of deployment, reliability and security key areas that we as a team are constantly striving to improve.</p>\n\n<div align=\"center\">\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/aboard.webp\" width=\"900\" />\n</div>\n\n<p><strong>The Solution</strong></p>\n\n<p>From our initial investigations we identified that all systems that teams were interfacing with during the on/off-boarding process could be interacted with using RESTful APIs, so the obvious solution was to wrap these interactions in a higher-level API provided by a single service.</p>\n\n<div align=\"center\">\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/victorops-logo.png\" width=\"200\" />\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/github-logo.png\" width=\"200\" />\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/docker-icon.png\" width=\"200\" />\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/node-js.svg\" width=\"200\" />\n</div>\n<div align=\"center\">\n  <p><em>A sample of the systems and tools we configure for new starters</em></p>\n</div>\n\n<p>The catalyst for prioritising the development of the service was a rapid growth in the engineering team cohort, which included new engineers joining the Spanners team.  This meant that we began to see first-hand the shortcomings in the existing processes, the pressure this placed upon feature teams, and the detrimental effects for new starters.</p>\n\n<p>Working in sprint cycles meant we had allocated time to define, refine and plan for tickets that would deliver upon the prescribed solution to reduce friction for the on-boarding and off-boarding processes.  Quickly <a href=\"https://asana.com/resources/t-shirt-sizing\">T-shirt sizing</a> the initial tickets we could see this would be more than just a trivial task, and as such we defined an Epic, and made it our quarterly goal.</p>\n\n<p>We started by engaging stakeholders responsible for the on/off-boarding processes, and development got underway at the beginning of the next quarter.  Within four weeks we had our minimal viable product (MVP) ready for demonstration to stakeholders.</p>\n\n<div align=\"center\">\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/staff-swagger.png\" width=\"900\" />\n</div>\n<div align=\"center\">\n  <p><em>Service Swagger Interface</em></p>\n</div>\n\n<p>Scaffolding up the service, repository and build pipeline was very straightforward thanks to a pre-existing service developed by Spanners.  This service bootstraps a microservice from nothing but a name to a fully deployable project, interfacing with Github and Teamcity (our CI/CD solution) to define a repository, populate it with templates and define a build pipeline.  This scaffolding service is another example of how Spanners have applied DevOps principles and practices to find a solution to a business problem.</p>\n\n<p>The on/off-boarding MVP configured access to several of our systems (Jira, VictorOps, Launch Darkly, Github and Teamcity), as well as configured the user\u2019s device, installing applications and CLI tools (VS Code, NPM, docker etc.) required for them to do their job on either Linux, Mac or Windows OS.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>installHelm<span class=\"o\">()</span> <span class=\"o\">{</span> \n<span class=\"nb\">cd</span> /tmp \n<span class=\"c\"># Check for installed version of Helm </span>\n<span class=\"nv\">CUR_HELM_VER</span><span class=\"o\">=</span><span class=\"sb\">`</span>/usr/local/bin/helm version 2&gt; /dev/null | <span class=\"nb\">grep</span> <span class=\"s2\">\"Version:\"</span> | <span class=\"nb\">cut</span> <span class=\"nt\">-d</span> <span class=\"s2\">\",\"</span> <span class=\"nt\">-f</span> 1 | <span class=\"nb\">cut</span> <span class=\"nt\">-d</span> <span class=\"s2\">\":\"</span> <span class=\"nt\">-f</span> 2 | <span class=\"nb\">sed</span> <span class=\"s1\">'s/\"//g'</span><span class=\"sb\">`</span> \n<span class=\"k\">if</span> <span class=\"o\">[[</span> <span class=\"nv\">$CUR_HELM_VER</span> <span class=\"o\">==</span> <span class=\"nv\">$HELM_VER</span> <span class=\"o\">]]</span> \n<span class=\"k\">then \n</span>log <span class=\"s2\">\"Helm already installed, and at the correct version.\"</span> \n<span class=\"k\">else \n</span>log <span class=\"s2\">\"Installing helm: </span><span class=\"k\">${</span><span class=\"nv\">HELM_VER</span><span class=\"k\">}</span><span class=\"s2\">\"</span> \ncurl <span class=\"nt\">-LO</span> https://get.helm.sh/helm-<span class=\"k\">${</span><span class=\"nv\">HELM_VER</span><span class=\"k\">}</span><span class=\"nt\">-linux-amd64</span>.tar.gz \n<span class=\"nb\">tar</span> <span class=\"nt\">-zxf</span> helm-<span class=\"k\">${</span><span class=\"nv\">HELM_VER</span><span class=\"k\">}</span><span class=\"nt\">-linux-amd64</span>.tar.gz \n\n<span class=\"c\"># Install Helm executable  </span>\n<span class=\"nb\">sudo mv</span> ./linux-amd64/helm /usr/local/bin \nlog <span class=\"s2\">\"Helm successfully installed to version </span><span class=\"k\">${</span><span class=\"nv\">HELM_VER</span><span class=\"k\">}</span><span class=\"s2\">.\"</span> \n<span class=\"k\">fi</span> \n<span class=\"o\">}</span> \n</code></pre></div></div>\n\n<p><em>Extract of our Linux (Ubuntu) setup script</em></p>\n\n<p>It also fulfilled the off-boarding requirement, enabling administrators to clean-up user accounts when an engineer left the company.</p>\n\n<p>In a commitment to \u201c<a href=\"https://www.dynatrace.com/news/blog/what-is-shift-left-and-what-is-shift-right/#what-does-shift-left-mean-in-devops\">shift left</a>\u201d, most of the service codebase was developed with unit and integration tests from the very start. Unit tests are run using the <a href=\"https://jestjs.io/\">jest</a> framework, and triggered locally on a pre-push hook, whilst integration tests are run on each and every build.  All build pipeline configuration to run tests is pre-configured in our build pipelines, and all of it bootstrapped by our scaffolding service.</p>\n\n<p>As the services need to interface with systems (both internal and external) at an administrative level securing the credentials to interface with these systems is of course required.  This was not much of an issue to implement though, as we already operate an on-premise <a href=\"https://www.vaultproject.io/\">Vault cluster</a> and our scaffolded build pipelines have pre-defined secure methods to interact with this Vault instance.</p>\n\n<p>Spanners regularly deliver workshop sessions to the Engineering cohort in which we take a deep dive in to recent or upcoming changes to processes and technology.  Following completion of the MVP we delivered one such workshop session regarding the new service.  The feedback gathered resulted in several tickets being defined, and as they were executed incremental improvements were made to the scripts and endpoints of the service.   Due to changes being applied directly to the trunk branch, and test automation in the build pipeline, each change could be verified by stakeholders, and benefits realised immediately.</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">module</span><span class=\"p\">.</span><span class=\"nx\">exports</span><span class=\"p\">.</span><span class=\"nx\">createAccount</span> <span class=\"o\">=</span> <span class=\"k\">async</span> <span class=\"p\">({</span> <span class=\"nx\">username</span> <span class=\"p\">})</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nx\">callApi</span><span class=\"p\">(</span>\n    <span class=\"s2\">`members`</span><span class=\"p\">,</span>\n    <span class=\"dl\">'</span><span class=\"s1\">POST</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n    <span class=\"nx\">JSON</span><span class=\"p\">.</span><span class=\"nx\">stringify</span><span class=\"p\">([</span>\n      <span class=\"p\">{</span>\n        <span class=\"na\">email</span><span class=\"p\">:</span> <span class=\"s2\">`</span><span class=\"p\">${</span><span class=\"nx\">username</span><span class=\"p\">}${</span><span class=\"nx\">fmpEmail</span><span class=\"p\">}</span><span class=\"s2\">`</span><span class=\"p\">,</span>\n        <span class=\"na\">role</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">writer</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n      <span class=\"p\">},</span>\n    <span class=\"p\">])</span>\n  <span class=\"p\">);</span>\n\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"p\">[</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">201</span><span class=\"p\">].</span><span class=\"nx\">includes</span><span class=\"p\">(</span><span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">status</span><span class=\"p\">))</span> <span class=\"p\">{</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">error</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">text</span><span class=\"p\">();</span>\n    <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nx\">StaffAPIError</span><span class=\"p\">({</span>\n      <span class=\"na\">message</span><span class=\"p\">:</span> <span class=\"s2\">`Failed to setup new joiner </span><span class=\"p\">${</span><span class=\"nx\">username</span><span class=\"p\">}</span><span class=\"s2\"> with access to Launch Darkly`</span><span class=\"p\">,</span>\n      <span class=\"nx\">error</span><span class=\"p\">,</span>\n      <span class=\"na\">statusCode</span><span class=\"p\">:</span> <span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">status</span><span class=\"p\">,</span>\n    <span class=\"p\">});</span>\n  <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n    <span class=\"nx\">logger</span><span class=\"p\">.</span><span class=\"nx\">info</span><span class=\"p\">(</span><span class=\"s2\">`A Launch Darkly account for new joiner </span><span class=\"p\">${</span><span class=\"nx\">username</span><span class=\"p\">}</span><span class=\"s2\"> has been made successfully!`</span><span class=\"p\">);</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">};</span>\n</code></pre></div></div>\n<p><em>Example on-boarding API call</em></p>\n\n<p>The service was shortly thereafter demonstrated to the wider engineering team, and flagged as the replacement to previous on/off-boarding procedures. Documentation throughout our codebase was updated to signpost the new service as the one-stop-shop for on/off-boarding staff.</p>\n\n<p>Migration to use of the script was very smooth, due to the engineering cohort now being able to self-serve on/off-boarding requests.</p>\n\n<p><strong>What are Spanners working on now?</strong></p>\n\n<p>Working on the service opened the teams eyes to security loopholes and blind spots within our environment, which put us on the path to improving the role based access controls (RBAC) provided to the engineering cohort. We are in the process of improving security within our network by implementing RBAC for engineer access to servers (via SSH &amp; RDP) and Kubernetes resources.</p>\n\n<p><strong>Conclusion</strong></p>\n\n<p>I hope the above has given you an idea of how Spanners implement DevOps principles within the wider Engineering cohort at Findmypast. The values held by the company and the behaviours expected from staff, lay a great foundation for the adoption of DevOps practices by the entire Engineering cohort.  Behavioural expectations at the organisational level such as \u201cWe use data to fail fast and learn how to do it differently next time\u201d, and \u201cWe share our knowledge to empower the people around us\u201d, really resonate with the DevOps principles of continuous improvement and collaboration respectively.  In practice these principles mean that new engineers very easily adopt DevOps practices. Yielding improved outcomes for both the individual and the business, with teams acting autonomously to experiment and deliver product enhancements at a rapid pace.</p>\n\n<p>We may be looking for engineers to join our team. If you\u2019re interested <a href=\"https://www.findmypast.co.uk/help/contact\">contact us</a>, or check out our <a href=\"https://findmypast.pinpointhq.com/\">current vacancies</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://tech.findmypast.com/feed.xml",
      "value": "<p><strong>Introduction</strong></p>\n\n<p>There are many ways to define DevOps and even more ways to implement its core principles within an organisation. To the Spanners team, DevOps is an iterative and collaborative approach to the development, testing, deployment and monitoring of software services. Overall, there is a great deal of alignment with the thoughts outlined by <a href=\"https://theagileadmin.com/what-is-devops/\">Mueller</a> and <a href=\"https://www.chef.io/blog/what-devops-means-to-me\">Willis</a> regarding what DevOps is, and how it is best implemented.</p>\n\n<p>Spanners see our role within the wider engineering cohort at <a href=\"https://www.findmypast.com/\">Findmypast</a> as advocates for DevOps principles and practices, and the vehicle through which those practices can be implemented day-to-day. Spanners operate as an autonomous team, but our efforts centre around providing feature teams with the processes and tools they need to reap the rewards of following a DevOps approach when developing and maintaining services.</p>\n\n<div align=\"center\">\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/atlassian-devops.png\" width=\"900\" />\n</div>\n<div align=\"center\">\n  <p>Source: <a href=\"https://www.atlassian.com/devops/what-is-devops\">Atlassian</a></p>\n</div>\n\n<p><strong>Team Goals</strong></p>\n\n<p>Our goals always trace back to wider organisation goals that in turn align with the expected company and department behaviours. For Spanners our quarterly team goals generally focus on how we improve five key areas in terms of software delivery across the engineering teams:</p>\n\n<ul>\n  <li><strong>Speed of Deployment</strong> \u2013 The rate of code deployments and the speed with which code can be built, tested and deployed to our environments.</li>\n  <li><strong>Collaboration</strong> \u2013 Enable teams to investigate issues and monitor services and systems using a well-defined and trusted series of tools. Providing a framework for teams to take Ownership of the service pipelines (sometimes described as \u201cYou build it, you run it\u201d).</li>\n  <li><strong>Quality</strong> \u2013 Enable teams to continually improve upon their service/s through automation in the form of CI/CD pipelines, and quickly identify issues and shortcomings in those implementations.</li>\n  <li><strong>Reliability</strong> \u2013 Reduce variables when it comes to the building, testing and deployment of code changes, and provide near real-time feedback (measurement) of the effectiveness of those code changes.</li>\n  <li><strong>Security</strong> \u2013 We strive to manage everything as code and provide the tools and means for all engineers to do their jobs with minimal friction, building security and accountability into everything we deliver.</li>\n</ul>\n\n<p><strong>The Team</strong></p>\n\n<p>The Spanners team comprises eight engineers, supporting a wider engineering cohort of roughly 120 engineers and management.  Backgrounds within the team vary, some members having more of an operations background, whilst others have more of a development background.  The Spanners team is truly multi-disciplinary, with a variety of skill levels ranging from senior to junior, and a variety of specialisms within the team.  This breadth of knowledge enables Spanners to provide a one-stop-shop for support of the product build pipelines and underpinning technologies.</p>\n\n<p>Spanners operate like any other feature team within the wider engineering group.  We follow an agile methodology built around a fortnightly sprint cycle, and follow a regular cadence of planning, refining and retrospective meetings.</p>\n\n<p>To ensure queries from the wider engineering group are answered in good time, we operate a support rota, whereby a team member is assigned as an initial point-of-contact for queries.  This ensures that the team is always on hand to collaborate with a feature team on a request or an incident.</p>\n\n<p><strong>The Challenge</strong></p>\n\n<p>One underappreciated aspect of software development is the need to integrate new team members into the engineering cohort.  Without a smooth on-boarding process both the new and existing team members can become bogged down in the configuration of systems, tools and certificates. Ultimately, this results in a negative impact to the speed of deployment, reliability and security key areas that we as a team are constantly striving to improve.</p>\n\n<div align=\"center\">\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/aboard.webp\" width=\"900\" />\n</div>\n\n<p><strong>The Solution</strong></p>\n\n<p>From our initial investigations we identified that all systems that teams were interfacing with during the on/off-boarding process could be interacted with using RESTful APIs, so the obvious solution was to wrap these interactions in a higher-level API provided by a single service.</p>\n\n<div align=\"center\">\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/victorops-logo.png\" width=\"200\" />\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/github-logo.png\" width=\"200\" />\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/docker-icon.png\" width=\"200\" />\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/node-js.svg\" width=\"200\" />\n</div>\n<div align=\"center\">\n  <p><em>A sample of the systems and tools we configure for new starters</em></p>\n</div>\n\n<p>The catalyst for prioritising the development of the service was a rapid growth in the engineering team cohort, which included new engineers joining the Spanners team.  This meant that we began to see first-hand the shortcomings in the existing processes, the pressure this placed upon feature teams, and the detrimental effects for new starters.</p>\n\n<p>Working in sprint cycles meant we had allocated time to define, refine and plan for tickets that would deliver upon the prescribed solution to reduce friction for the on-boarding and off-boarding processes.  Quickly <a href=\"https://asana.com/resources/t-shirt-sizing\">T-shirt sizing</a> the initial tickets we could see this would be more than just a trivial task, and as such we defined an Epic, and made it our quarterly goal.</p>\n\n<p>We started by engaging stakeholders responsible for the on/off-boarding processes, and development got underway at the beginning of the next quarter.  Within four weeks we had our minimal viable product (MVP) ready for demonstration to stakeholders.</p>\n\n<div align=\"center\">\n<img src=\"https://tech.findmypast.com/images/2023-08-22-how-spanners-implement-devops/staff-swagger.png\" width=\"900\" />\n</div>\n<div align=\"center\">\n  <p><em>Service Swagger Interface</em></p>\n</div>\n\n<p>Scaffolding up the service, repository and build pipeline was very straightforward thanks to a pre-existing service developed by Spanners.  This service bootstraps a microservice from nothing but a name to a fully deployable project, interfacing with Github and Teamcity (our CI/CD solution) to define a repository, populate it with templates and define a build pipeline.  This scaffolding service is another example of how Spanners have applied DevOps principles and practices to find a solution to a business problem.</p>\n\n<p>The on/off-boarding MVP configured access to several of our systems (Jira, VictorOps, Launch Darkly, Github and Teamcity), as well as configured the user\u2019s device, installing applications and CLI tools (VS Code, NPM, docker etc.) required for them to do their job on either Linux, Mac or Windows OS.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>installHelm<span class=\"o\">()</span> <span class=\"o\">{</span> \n<span class=\"nb\">cd</span> /tmp \n<span class=\"c\"># Check for installed version of Helm </span>\n<span class=\"nv\">CUR_HELM_VER</span><span class=\"o\">=</span><span class=\"sb\">`</span>/usr/local/bin/helm version 2&gt; /dev/null | <span class=\"nb\">grep</span> <span class=\"s2\">\"Version:\"</span> | <span class=\"nb\">cut</span> <span class=\"nt\">-d</span> <span class=\"s2\">\",\"</span> <span class=\"nt\">-f</span> 1 | <span class=\"nb\">cut</span> <span class=\"nt\">-d</span> <span class=\"s2\">\":\"</span> <span class=\"nt\">-f</span> 2 | <span class=\"nb\">sed</span> <span class=\"s1\">'s/\"//g'</span><span class=\"sb\">`</span> \n<span class=\"k\">if</span> <span class=\"o\">[[</span> <span class=\"nv\">$CUR_HELM_VER</span> <span class=\"o\">==</span> <span class=\"nv\">$HELM_VER</span> <span class=\"o\">]]</span> \n<span class=\"k\">then \n</span>log <span class=\"s2\">\"Helm already installed, and at the correct version.\"</span> \n<span class=\"k\">else \n</span>log <span class=\"s2\">\"Installing helm: </span><span class=\"k\">${</span><span class=\"nv\">HELM_VER</span><span class=\"k\">}</span><span class=\"s2\">\"</span> \ncurl <span class=\"nt\">-LO</span> https://get.helm.sh/helm-<span class=\"k\">${</span><span class=\"nv\">HELM_VER</span><span class=\"k\">}</span><span class=\"nt\">-linux-amd64</span>.tar.gz \n<span class=\"nb\">tar</span> <span class=\"nt\">-zxf</span> helm-<span class=\"k\">${</span><span class=\"nv\">HELM_VER</span><span class=\"k\">}</span><span class=\"nt\">-linux-amd64</span>.tar.gz \n\n<span class=\"c\"># Install Helm executable  </span>\n<span class=\"nb\">sudo mv</span> ./linux-amd64/helm /usr/local/bin \nlog <span class=\"s2\">\"Helm successfully installed to version </span><span class=\"k\">${</span><span class=\"nv\">HELM_VER</span><span class=\"k\">}</span><span class=\"s2\">.\"</span> \n<span class=\"k\">fi</span> \n<span class=\"o\">}</span> \n</code></pre></div></div>\n\n<p><em>Extract of our Linux (Ubuntu) setup script</em></p>\n\n<p>It also fulfilled the off-boarding requirement, enabling administrators to clean-up user accounts when an engineer left the company.</p>\n\n<p>In a commitment to \u201c<a href=\"https://www.dynatrace.com/news/blog/what-is-shift-left-and-what-is-shift-right/#what-does-shift-left-mean-in-devops\">shift left</a>\u201d, most of the service codebase was developed with unit and integration tests from the very start. Unit tests are run using the <a href=\"https://jestjs.io/\">jest</a> framework, and triggered locally on a pre-push hook, whilst integration tests are run on each and every build.  All build pipeline configuration to run tests is pre-configured in our build pipelines, and all of it bootstrapped by our scaffolding service.</p>\n\n<p>As the services need to interface with systems (both internal and external) at an administrative level securing the credentials to interface with these systems is of course required.  This was not much of an issue to implement though, as we already operate an on-premise <a href=\"https://www.vaultproject.io/\">Vault cluster</a> and our scaffolded build pipelines have pre-defined secure methods to interact with this Vault instance.</p>\n\n<p>Spanners regularly deliver workshop sessions to the Engineering cohort in which we take a deep dive in to recent or upcoming changes to processes and technology.  Following completion of the MVP we delivered one such workshop session regarding the new service.  The feedback gathered resulted in several tickets being defined, and as they were executed incremental improvements were made to the scripts and endpoints of the service.   Due to changes being applied directly to the trunk branch, and test automation in the build pipeline, each change could be verified by stakeholders, and benefits realised immediately.</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">module</span><span class=\"p\">.</span><span class=\"nx\">exports</span><span class=\"p\">.</span><span class=\"nx\">createAccount</span> <span class=\"o\">=</span> <span class=\"k\">async</span> <span class=\"p\">({</span> <span class=\"nx\">username</span> <span class=\"p\">})</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nx\">callApi</span><span class=\"p\">(</span>\n    <span class=\"s2\">`members`</span><span class=\"p\">,</span>\n    <span class=\"dl\">'</span><span class=\"s1\">POST</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n    <span class=\"nx\">JSON</span><span class=\"p\">.</span><span class=\"nx\">stringify</span><span class=\"p\">([</span>\n      <span class=\"p\">{</span>\n        <span class=\"na\">email</span><span class=\"p\">:</span> <span class=\"s2\">`</span><span class=\"p\">${</span><span class=\"nx\">username</span><span class=\"p\">}${</span><span class=\"nx\">fmpEmail</span><span class=\"p\">}</span><span class=\"s2\">`</span><span class=\"p\">,</span>\n        <span class=\"na\">role</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">writer</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n      <span class=\"p\">},</span>\n    <span class=\"p\">])</span>\n  <span class=\"p\">);</span>\n\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"p\">[</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">201</span><span class=\"p\">].</span><span class=\"nx\">includes</span><span class=\"p\">(</span><span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">status</span><span class=\"p\">))</span> <span class=\"p\">{</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">error</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">text</span><span class=\"p\">();</span>\n    <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nx\">StaffAPIError</span><span class=\"p\">({</span>\n      <span class=\"na\">message</span><span class=\"p\">:</span> <span class=\"s2\">`Failed to setup new joiner </span><span class=\"p\">${</span><span class=\"nx\">username</span><span class=\"p\">}</span><span class=\"s2\"> with access to Launch Darkly`</span><span class=\"p\">,</span>\n      <span class=\"nx\">error</span><span class=\"p\">,</span>\n      <span class=\"na\">statusCode</span><span class=\"p\">:</span> <span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">status</span><span class=\"p\">,</span>\n    <span class=\"p\">});</span>\n  <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n    <span class=\"nx\">logger</span><span class=\"p\">.</span><span class=\"nx\">info</span><span class=\"p\">(</span><span class=\"s2\">`A Launch Darkly account for new joiner </span><span class=\"p\">${</span><span class=\"nx\">username</span><span class=\"p\">}</span><span class=\"s2\"> has been made successfully!`</span><span class=\"p\">);</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">};</span>\n</code></pre></div></div>\n<p><em>Example on-boarding API call</em></p>\n\n<p>The service was shortly thereafter demonstrated to the wider engineering team, and flagged as the replacement to previous on/off-boarding procedures. Documentation throughout our codebase was updated to signpost the new service as the one-stop-shop for on/off-boarding staff.</p>\n\n<p>Migration to use of the script was very smooth, due to the engineering cohort now being able to self-serve on/off-boarding requests.</p>\n\n<p><strong>What are Spanners working on now?</strong></p>\n\n<p>Working on the service opened the teams eyes to security loopholes and blind spots within our environment, which put us on the path to improving the role based access controls (RBAC) provided to the engineering cohort. We are in the process of improving security within our network by implementing RBAC for engineer access to servers (via SSH &amp; RDP) and Kubernetes resources.</p>\n\n<p><strong>Conclusion</strong></p>\n\n<p>I hope the above has given you an idea of how Spanners implement DevOps principles within the wider Engineering cohort at Findmypast. The values held by the company and the behaviours expected from staff, lay a great foundation for the adoption of DevOps practices by the entire Engineering cohort.  Behavioural expectations at the organisational level such as \u201cWe use data to fail fast and learn how to do it differently next time\u201d, and \u201cWe share our knowledge to empower the people around us\u201d, really resonate with the DevOps principles of continuous improvement and collaboration respectively.  In practice these principles mean that new engineers very easily adopt DevOps practices. Yielding improved outcomes for both the individual and the business, with teams acting autonomously to experiment and deliver product enhancements at a rapid pace.</p>\n\n<p>We may be looking for engineers to join our team. If you\u2019re interested <a href=\"https://www.findmypast.co.uk/help/contact\">contact us</a>, or check out our <a href=\"https://findmypast.pinpointhq.com/\">current vacancies</a>.</p>"
    },
    "published": "Mon, 21 Aug 2023 17:30:00 +0000",
    "published_parsed": [
      2023,
      8,
      21,
      17,
      30,
      0,
      0,
      233,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.findmypast.com/how-spanners-implement-devops/"
      }
    ],
    "link": "https://tech.findmypast.com/how-spanners-implement-devops/",
    "id": "https://tech.findmypast.com/how-spanners-implement-devops/",
    "guidislink": false,
    "tags": [
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      }
    ]
  },
  "Bigcommerce": {
    "title": "Kyiv Hackathon Winners: API Test Automation Based Upon Playwright",
    "xmlUrl": "https://www.bigeng.io/rss/",
    "htmlUrl": "http://www.bigeng.io/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.bigeng.io/rss/",
      "value": "Kyiv Hackathon Winners: API Test Automation Based Upon Playwright"
    },
    "summary": "Meet Kostiantyn Serediuk, winner of the Hard Worker award.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.bigeng.io/rss/",
      "value": "Meet Kostiantyn Serediuk, winner of the Hard Worker award."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.bigeng.io/api-test-automation/"
      }
    ],
    "link": "https://www.bigeng.io/api-test-automation/",
    "id": "65380420b2e67b0001ce6cba",
    "guidislink": false,
    "tags": [
      {
        "term": "hackathon",
        "scheme": null,
        "label": null
      },
      {
        "term": "api",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Grace Estle"
      }
    ],
    "author": "Grace Estle",
    "author_detail": {
      "name": "Grace Estle"
    },
    "published": "Fri, 03 Nov 2023 13:37:14 GMT",
    "published_parsed": [
      2023,
      11,
      3,
      13,
      37,
      14,
      4,
      307,
      0
    ],
    "media_content": [
      {
        "url": "https://www.bigeng.io/content/images/2023/11/Kostiantyn-Header.jpg",
        "medium": "image"
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.bigeng.io/rss/",
        "value": "<img alt=\"Kyiv Hackathon Winners: API Test Automation Based Upon Playwright\" src=\"https://www.bigeng.io/content/images/2023/11/Kostiantyn-Header.jpg\" /><p>You&apos;ve had a chance to <a href=\"https://www.bigeng.io/tag/hackathon/\" rel=\"noreferrer\">meet our Hackathon winners</a> from the US and Australia. Now, we&apos;re traveling to another continent to introduce you to the winners from our Kyiv office.</p><p><strong>Related Articles: <a href=\"https://www.bigeng.io/tag/hackathon/\"><strong>Meet Our Hackathon Winners</strong></a></strong></p><p>Today, you&apos;ll meet Kostiantyn Serediuk, winner of the Hard Worker Award. Kostiantyn&apos;s project revolved around implementing API test automation based upon <a href=\"https://playwright.dev/docs/api-testing?ref=bigeng.io\" rel=\"noreferrer\">Playwright</a>. </p><p>Before we discuss this project with Kostiantyn, let&apos;s take a moment to learn a little more about him.</p><div class=\"kg-card kg-header-card kg-v2 kg-width-full kg-content-wide \" style=\"background-color: #000000;\">\n            \n            <div class=\"kg-header-card-content\">\n                \n                <div class=\"kg-header-card-text kg-align-center\">\n                    <h2 class=\"kg-header-card-heading\" id=\"meet-kostiantyn\" style=\"color: #FFFFFF;\"><span style=\"white-space: pre-wrap;\">Meet Kostiantyn</span></h2>\n                    \n                    \n                </div>\n            </div>\n        </div><h3 id=\"software-development-engineer-in-test-ii-on-the-localization-durable-team\">Software Development Engineer in Test II on the&#xa0;Localization Durable Team</h3><figure class=\"kg-card kg-image-card\"><img alt=\"Kyiv Hackathon Winners: API Test Automation Based Upon Playwright\" class=\"kg-image\" height=\"557\" src=\"https://www.bigeng.io/content/images/2023/10/Kostiantyn.jpg\" width=\"1067\" /></figure><p><strong>Background</strong>: I joined BigCommerce four years ago as a member of the Translation Team that has transformed into the Localization Team. We are responsible not only for translations, but also for the store localization settings, shopper and merchant-facing emails, geo service, and more.&#xa0;</p><p><strong>Fun fact</strong>: I love hiking in the mountains, but I tried it for the first time only several years ago.</p><p><a href=\"https://www.linkedin.com/in/kostiantyn-serediuk-884137226?ref=bigeng.io\" rel=\"noreferrer\">Connect</a> with Kostiantyn on LinkedIn.</p><div class=\"kg-card kg-header-card kg-v2 kg-width-full kg-content-wide \" style=\"background-color: #000000;\">\n            \n            <div class=\"kg-header-card-content\">\n                \n                <div class=\"kg-header-card-text kg-align-center\">\n                    <h2 class=\"kg-header-card-heading\" id=\"kostiantyns-project\" style=\"color: #FFFFFF;\"><span style=\"white-space: pre-wrap;\">Kostiantyn&apos;s Project</span></h2>\n                    \n                    \n                </div>\n            </div>\n        </div><h3 id=\"please-describe-your-project\">Please describe your project.</h3><p>The goal of the project was to implement API test automation based upon Playwright, which is an open-source, flexible and progressive framework, and to check how it could be applied to our scopes.</p><h3 id=\"what-inspired-you-to-choose-this-project\">What inspired you to choose this project?</h3><figure class=\"kg-card kg-image-card\"><img alt=\"Kyiv Hackathon Winners: API Test Automation Based Upon Playwright\" class=\"kg-image\" height=\"557\" src=\"https://www.bigeng.io/content/images/2023/10/Quality.jpg\" width=\"1067\" /></figure><p>My main responsibility as a Quality Specialist is to check and ensure that everything is working expectedly within development and improvement of the platform. Because of this, there are a lot of testing tasks that are repeated from release to release, in particular, API functionality.</p><h3 id=\"which-pain-points-does-your-project-solve\">Which pain points does your project solve?</h3><p>Some of the testing tasks mentioned above are solved manually on a regular basis. It is wonderful to have a system functionality that performs checks automatically. It will contribute to the solution of two typical pain points: high testing costs and developer downtime. Developers can just run auto test suite(s) by themselves. As a bonus, this will free up time to work on other equally important but more interesting tasks.</p><h3 id=\"what%E2%80%99s-your-favorite-part-of-this-project-why-is-it-your-favorite\">What&#x2019;s your favorite part of this project? Why is it your favorite?</h3><p>My favorite part was when implementation ran successfully for the first time. I believe that everyone is happy when something created from scratch starts working. It is a basis for the next steps of development and scaling up the project.</p><h3 id=\"which-challenges-did-you-face-while-you-were-developing-your-project\">Which challenges did you face while you were developing your project?</h3><p>The main challenge for me was that I did not have enough experience with API tests based upon the Playwright framework before starting the project. That&apos;s why I had to spend time and effort working and studying at the same time.&#xa0;</p><h3 id=\"how-did-you-overcome-these-challenges\">How did you overcome these challenges?</h3><figure class=\"kg-card kg-image-card\"><img alt=\"Kyiv Hackathon Winners: API Test Automation Based Upon Playwright\" class=\"kg-image\" height=\"557\" src=\"https://www.bigeng.io/content/images/2023/10/Teamwork-1.jpg\" width=\"1067\" /></figure><p>Fortunately, my experienced colleagues and teammates helped me. Using this chance, I would like to say, &quot;Many thanks&quot; to them once again.</p><p>One more helpful thing was the <a href=\"https://playwright.dev/docs/api/class-playwright?ref=bigeng.io\" rel=\"noreferrer\">clear documentation</a> of the framework.</p><p><strong>Open Roles: <a href=\"https://careers.bigcommerce.com/teams/engineering/?utm_medium=organic-social&amp;utm_source=organic-social&amp;utm_campaign=oth_global_all_all_dvp_b2b_partner_ct_2023_q4_bigengblog\" rel=\"noreferrer\"><strong>Explore Your Next Engineering Opportunity</strong></a></strong></p><h3 id=\"what%E2%80%99s-the-one-thing-you%E2%80%99d-change-about-this-project\">What&#x2019;s the one thing you&#x2019;d change about this project?</h3><p>If I had a chance, I would spend more time carefully planning the project to make it more flexible and universal. This would allow the implemented idea to be used in other scopes of our domain.</p><h3 id=\"if-an-engineer-wanted-to-create-a-project-similar-to-yours-what-advice-would-you-give-that-person\">If an engineer wanted to create a project similar to yours, what advice would you give that person?</h3><p>I suggest collaborating with others already involved and to take a look at ready-made solutions on the platform. It&apos;s possible that some of them are connected to a new idea/project and are ready to use.</p><h3 id=\"what-advice-would-you-give-to-an-engineer-who-is-about-to-participate-in-a-hackathon\">What advice would you give to an engineer who is about to participate in a Hackathon?</h3><p>Please double check if you have the right experience and competencies. Think about future efforts.</p><p>And remember, absence of knowledge is not a blocker &#x2014; where there is a will, there is a way.</p>"
      }
    ]
  },
  "Firmafon": {
    "title": "New Pub/sub API",
    "xmlUrl": "https://dev.firmafon.dk/blog/feed.xml",
    "htmlUrl": "https://dev.firmafon.dk/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://dev.relatel.dk/blog/feed.xml",
      "value": "New Pub/sub API"
    },
    "links": [
      {
        "rel": "alternate",
        "href": "https://dev.relatel.dk/blog/new-pubsub-api/",
        "type": "text/html"
      }
    ],
    "link": "https://dev.relatel.dk/blog/new-pubsub-api/",
    "id": "https://dev.relatel.dk/blog/new-pubsub-api/",
    "guidislink": false,
    "published": "2016-10-27T08:30:00Z",
    "published_parsed": [
      2016,
      10,
      27,
      8,
      30,
      0,
      3,
      301,
      0
    ],
    "updated": "2023-06-27T13:13:51+00:00",
    "updated_parsed": [
      2023,
      6,
      27,
      13,
      13,
      51,
      1,
      178,
      0
    ],
    "authors": [
      {
        "name": "Kasper Timm Hansen"
      }
    ],
    "author_detail": {
      "name": "Kasper Timm Hansen"
    },
    "author": "Kasper Timm Hansen",
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://dev.relatel.dk/blog/feed.xml",
        "value": "<p>Today we&rsquo;ve got a new thing for people who use our API: a pubsub variant. This variant gives your apps near real time\nupdates about what happens on a Relatel account.</p>\n\n<p>Our Pub/sub works with any Faye, and thereby any Bayeux, clients. You install a client and open a WebSocket connection\nto our servers. Then you <code>sub</code>scribe to channels and whenever we <code>pub</code>lish on that channel, you get events!</p>\n\n<p>You&rsquo;ve got these channels to subscribe to:</p>\n\n<ol>\n<li>Presence events for employees and employee groups on a company basis.</li>\n<li>General call events on a company, when new calls come in etc.</li>\n</ol>\n\n<p>Start digging into our <a href=\"https://dev.relatel.dk/api-v2/pubsub/\">Pub/sub guide</a>.</p>"
      }
    ],
    "summary": "<p>Today we&rsquo;ve got a new thing for people who use our API: a pubsub variant. This variant gives your apps near real time\nupdates about what happens on a Relatel account.</p>\n\n<p>Our Pub/sub works with any Faye, and thereby any Bayeux, clients. You install a client and open a WebSocket connection\nto our servers. Then you <code>sub</code>scribe to channels and whenever we <code>pub</code>lish on that channel, you get events!</p>\n\n<p>You&rsquo;ve got these channels to subscribe to:</p>\n\n<ol>\n<li>Presence events for employees and employee groups on a company basis.</li>\n<li>General call events on a company, when new calls come in etc.</li>\n</ol>\n\n<p>Start digging into our <a href=\"https://dev.relatel.dk/api-v2/pubsub/\">Pub/sub guide</a>.</p>"
  },
  "Criteo": {
    "title": "R&D Community Awards 2023 Recap",
    "xmlUrl": "https://medium.com/feed/criteo-labs",
    "htmlUrl": "https://medium.com/criteo-labs",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/criteo-labs",
      "value": "R&D Community Awards 2023 Recap"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/criteo-engineering/r-d-community-awards-2023-recap-dda0158ca10b?source=rss----fc3ea5a64a12---4"
      }
    ],
    "link": "https://medium.com/criteo-engineering/r-d-community-awards-2023-recap-dda0158ca10b?source=rss----fc3ea5a64a12---4",
    "id": "https://medium.com/p/dda0158ca10b",
    "guidislink": false,
    "tags": [
      {
        "term": "culture",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering-culture",
        "scheme": null,
        "label": null
      },
      {
        "term": "criteo",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "community",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Criteo Engineering"
      }
    ],
    "author": "Criteo Engineering",
    "author_detail": {
      "name": "Criteo Engineering"
    },
    "published": "Thu, 11 Jan 2024 08:22:14 GMT",
    "published_parsed": [
      2024,
      1,
      11,
      8,
      22,
      14,
      3,
      11,
      0
    ],
    "updated": "2024-01-11T08:22:14.374Z",
    "updated_parsed": [
      2024,
      1,
      11,
      8,
      22,
      14,
      3,
      11,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/criteo-labs",
        "value": "<h4>We celebrated everything we achieved during the year and recognized the Criteo R&amp;D Ambassadors involved.</h4><p>The R&amp;D Community is a key pillar for Criteo and represents our culture embracing Criteo\u2019s<a href=\"https://www.criteo.com/company/\"> values</a>. To recognize that, we have celebrated our first Community Awards, where we reviewed everything we have achieved this year and witnessed the finalists and winners for 2023\u00a0\ud83c\udf89</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*q4XHjlzds_UnbD07aCvgcA.png\" /><figcaption>The ceremony was hosted by Kini (DevRel) &amp; Diarmuid\u00a0(CTO)</figcaption></figure><p>As we bid farewell to another remarkable year within our vibrant R&amp;D community, it\u2019s only fitting to come together to celebrate the collective achievements, innovations, and unwavering passion that define us. Last December marked a pivotal moment as we hosted the R&amp;D Community Awards ceremony, a grand occasion dedicated to acknowledging the exceptional contributions that have propelled us\u00a0forward.</p><p>With a spirit of camaraderie and a sense of shared accomplishment, the ceremony aimed to recognize individual brilliance and honor the collaborative spirit that defines our community. From groundbreaking research to inspiring talks and open-source projects, the R&amp;D Community Awards served as a platform to applaud the diverse talents and pursuits that make our community thrive.</p><h3>2023 at a\u00a0glance</h3><p>Before we delve into the heart of the R&amp;D Community Awards ceremony, let\u2019s take a moment to reflect on the sheer magnitude of our collective accomplishments over the past year. These numbers not only tell a story of growth but also stand as a testament to the dedication and enthusiasm of our vibrant community.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*AmBaxZP67T-e38rkPoeo4g.png\" /><figcaption>We participated in so many activities during\u00a02023</figcaption></figure><p>Throughout the year, our community actively participated in a multitude of conferences and meetups. We\u2019re proud to share that we had more than twenty speakers sharing their insights and knowledge at various events, solidifying our presence on the global\u00a0stage.</p><p>Facilitating in-person connections, we hosted fifteen remarkable meetups and supported (attending/sponsoring) more than ten conferences throughout the year. These gatherings provided opportunities for networking, knowledge exchange, and fostering a sense of community that goes beyond digital interactions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*qImmho30AZ8kySYBYKj6-A.png\" /><figcaption>Numbers from last\u00a0year</figcaption></figure><p>The pursuit of knowledge is at the core of our community, and this is reflected in the more than twenty-five papers we presented at different conferences. These papers, authored by our talented members, explored cutting-edge ideas, challenged conventions, and contributed to the ongoing dialogue in their respective fields.</p><p>Last but not least, our Medium publication has become a hub for sharing insights, research findings, and thought leadership within the community. In the past year, we published an impressive fifty articles on diverse topics, showcasing the depth and breadth of expertise within our ranks. The impact of our community extends beyond our immediate circles, as evidenced by the growing audience on our Medium publication.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*j5kBSsPhk553nBRTmzhrqQ.png\" /><figcaption>Metrics from our Medium publication</figcaption></figure><p>As we celebrate the achievements of our community in the R&amp;D Community Awards ceremony, let these numbers serve as a reminder of the collective strength and impact we\u2019ve achieved together. Each statistic represents a story, an idea, and a contribution that has shaped the narrative of our community over the past\u00a0year.</p><h3>Awards Ceremony</h3><p>The awards were presented in five categories: Best Speaker of the Year, Best Article of the Year, Best Paper of the Year, Best Community Builder of the Year, and Best Open Source Project of the Year. The tech leads voted for the winners among finalists, picked by <a href=\"https://www.linkedin.com/in/kinisoftware/\">Kini</a>, our\u00a0DevRel.</p><h4>Best Speaker of the\u00a0Year</h4><p>The three finalists were selected considering their impact, internally and externally, because of the number of talks they had delivered, the conferences\u2019 relevance, and their involvement in activities as R&amp;D ambassadors.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*J5xbEEBpCH6mq6kAvw6e2A.png\" /><figcaption>The finalists for the \u201cSpeaker of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://www.linkedin.com/in/lagarde-henry/\"><strong>Henry</strong></a> presented at three big conferences this year: DevoxxUK, DevoxxBE, and DevoxxMA. He was also accepted for some other events. He is already applying for talks for\u00a02024.</li><li><a href=\"https://www.linkedin.com/in/pmokari/\"><strong>Pooneh</strong></a> presented in several places this year (plus DevoxxBE last year) and was invited to RivieraDev (France) as a keynoter. She\u2019s very involved in Women in Tech events/conferences, such as European Women In Tech 2023, where she was also a\u00a0speaker.</li><li><a href=\"https://www.linkedin.com/in/%E2%9B%A9%EF%B8%8F-sylvain-dedieu-b97788a1/\"><strong>Sylvain</strong></a> is one of our most active speakers, has been accepted in conferences this year (VoxxedDays Luxemburgo, a few DevFest, etc.), and will keep applying for talks in\u00a02024.</li></ul><h4>Best Article of the\u00a0Year</h4><p>The three finalists were selected by the number of reads they had. The three articles here are the ones that had the most significant impact this year, being boosted even for the Medium platform among its\u00a0members.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*-B6qXe-ZBFZfzTtDj-qJaA.png\" /><figcaption>The finalists for the \u201cArticle of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://medium.com/criteo-engineering/how-we-compute-data-lineage-at-criteo-b3f09fc5c577\">How we compute data lineage at Criteo</a></li><li><a href=\"https://medium.com/criteo-engineering/building-better-apis-with-chatgpt-9d3350beaf51\">Building better APIs with chatGPT</a></li><li><a href=\"https://medium.com/criteo-engineering/how-we-reduced-our-prometheus-infrastructure-footprint-by-a-third-8bf8171e46b1\">How we reduced our Prometheus infrastructure footprint by a third</a></li></ul><h4>Best Paper of the\u00a0Year</h4><p>Our commitment to staying at the forefront of industry trends and innovations was evident as we presented many papers. Our research community is always eager to learn, share, and engage with the broader research and development landscape. These three papers were selected by <a href=\"https://www.linkedin.com/in/livaralaivola/\">Liva</a>, our VP of Research, among all our outstanding contributions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*XI3RZS8hqUJ3hvFLkaNKEQ.png\" /><figcaption>The finalists for the \u201cPaper of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://github.com/White-Link/gpm\">Unifying GANs and Score-Based Diffusion as Generative Particle Models</a> (Jean-Yves Franceschi, Mike Gartrell, Ludovic Dos Santos, Thibaut Issenhuth, Emmanuel de B\u00e9zenac, Micka\u00ebl Chen, Alain Rakotomamonjy), to appear at NeurIPS\u00a02023.</li><li><a href=\"https://arxiv.org/abs/2305.15877\">Exponential Smoothing for Off-Policy Learning</a> (Imad Aouali, Victor-Emmanuel Brunel, David Rohde, Anna Korba), to appear at ICML\u00a02023.</li><li><a href=\"https://medium.com/criteo-engineering/learning-from-multiple-sources-for-data-to-text-and-text-to-data-4a6819588986\">Learning from Multiple Sources for Data-to-Text and Text-to-Data</a> (Song Duong, Alberto Lumbreras, Mike Gartrell, Patrick Gallinari), to appear at AISTATS\u00a02023.</li></ul><h4>Best Community Builder of the\u00a0Year</h4><p>Community building is key to success in our outreach activities. The finalists for this category were selected based on their implication, proactivity, energy, and impact. Each is involved in internal and external communities at different levels.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*GI_9-cuV-kPRuE9Blzvq4w.png\" /><figcaption>The finalists for the \u201cCommunity Builder of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://www.linkedin.com/in/khanh-tuong-maudoux-11b92b19/\"><strong>Khanh</strong></a> is involved with our speakers\u2019 community, both internally and externally. He\u2019s constantly communicating about CFPs, helping speakers with their proposals, creating opportunities with external communities (such as <a href=\"https://www.meetup.com/fr-FR/modern-data-stack-france/\">ModernDataStack</a> or <a href=\"https://www.parisjug.org/\">ParisJUG</a>), etc.</li><li><a href=\"https://www.linkedin.com/in/alejandraparedesceballos/\"><strong>Alejandra</strong></a> is the person behind the WomenDoTechToo initiative. Thanks to that, we have organized several meetups in different locations where we provide a safe space for our Woman at Tech in Criteo to share their expertise and technical knowledge.</li><li><a href=\"https://www.linkedin.com/in/%E2%9B%A9%EF%B8%8F-sylvain-dedieu-b97788a1/\"><strong>Sylvain</strong></a> joined Criteo recently, but he\u2019s already making a significant impact in Grenoble. He is helping to restart Criteo Meetups there, contacting possible guest speakers, promoting the events among the tech community there,\u00a0etc.</li></ul><h4>Best Open Source Project of the\u00a0Year</h4><p>Open Source is at the code of Criteo. We have built our products using many technologies supported by communities and open-source initiatives. It\u2019s time to provide value and make some noise about <a href=\"https://criteo.github.io/\">our projects</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*8sPCAtSUBF4jdp0aQrbelg.png\" /><figcaption>The finalists for the \u201cOpen Source project of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://medium.com/criteo-engineering/it-is-time-to-show-more-love-to-command-line-tools-eecb48e3e63c\">It is time to show more love to command-line tools</a></li><li><a href=\"https://medium.com/criteo-engineering/introducing-openapi-comparator-an-open-source-tool-to-detect-breaking-changes-in-your-api-7f705bb972b0\">Introducing OpenAPI Comparator: an open-source tool to detect breaking changes in your API</a></li><li><a href=\"https://medium.com/criteo-engineering/do-you-probe-your-network-a00c0ea1f994\">Do you probe your network?</a></li></ul><h4>And the winner\u00a0is\u2026</h4><ul><li>Speaker of the Year: <strong>Pooneh Mokariasl</strong>.</li><li>Article of the Year: <strong>How we reduced our Prometheus infrastructure footprint by a\u00a0third</strong>.</li><li>Community Builder of the Year: <strong>Alejandra Paredes</strong>.</li><li>Paper of the Year: <strong>Unifying GANs and Score-Based Diffusion as Generative Particle\u00a0Models</strong>.</li><li>Open Source Project of the Year: <strong>OpenAPI Comparator</strong>.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/760/0*BqZg572J5GOLnfbN\" /><figcaption>The winners!\u00a0\ud83d\udc4f</figcaption></figure><p>The R&amp;D Community Awards ceremony was a great success, and we are proud of all the finalists and winners. The ceremony was a testament to our community\u2019s hard work and dedication, and we hope that this recognition will inspire everyone to continue their pursuit of innovation.</p><p>Congratulations to all the winners and finalists! \ud83c\udfc6</p><p><a href=\"https://careers.criteo.com/en/teams/engineering/\">Engineering</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=dda0158ca10b\" width=\"1\" /><hr /><p><a href=\"https://medium.com/criteo-engineering/r-d-community-awards-2023-recap-dda0158ca10b\">R&amp;D Community Awards 2023 Recap</a> was originally published in <a href=\"https://medium.com/criteo-engineering\">Criteo R&amp;D Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h4>We celebrated everything we achieved during the year and recognized the Criteo R&amp;D Ambassadors involved.</h4><p>The R&amp;D Community is a key pillar for Criteo and represents our culture embracing Criteo\u2019s<a href=\"https://www.criteo.com/company/\"> values</a>. To recognize that, we have celebrated our first Community Awards, where we reviewed everything we have achieved this year and witnessed the finalists and winners for 2023\u00a0\ud83c\udf89</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*q4XHjlzds_UnbD07aCvgcA.png\" /><figcaption>The ceremony was hosted by Kini (DevRel) &amp; Diarmuid\u00a0(CTO)</figcaption></figure><p>As we bid farewell to another remarkable year within our vibrant R&amp;D community, it\u2019s only fitting to come together to celebrate the collective achievements, innovations, and unwavering passion that define us. Last December marked a pivotal moment as we hosted the R&amp;D Community Awards ceremony, a grand occasion dedicated to acknowledging the exceptional contributions that have propelled us\u00a0forward.</p><p>With a spirit of camaraderie and a sense of shared accomplishment, the ceremony aimed to recognize individual brilliance and honor the collaborative spirit that defines our community. From groundbreaking research to inspiring talks and open-source projects, the R&amp;D Community Awards served as a platform to applaud the diverse talents and pursuits that make our community thrive.</p><h3>2023 at a\u00a0glance</h3><p>Before we delve into the heart of the R&amp;D Community Awards ceremony, let\u2019s take a moment to reflect on the sheer magnitude of our collective accomplishments over the past year. These numbers not only tell a story of growth but also stand as a testament to the dedication and enthusiasm of our vibrant community.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*AmBaxZP67T-e38rkPoeo4g.png\" /><figcaption>We participated in so many activities during\u00a02023</figcaption></figure><p>Throughout the year, our community actively participated in a multitude of conferences and meetups. We\u2019re proud to share that we had more than twenty speakers sharing their insights and knowledge at various events, solidifying our presence on the global\u00a0stage.</p><p>Facilitating in-person connections, we hosted fifteen remarkable meetups and supported (attending/sponsoring) more than ten conferences throughout the year. These gatherings provided opportunities for networking, knowledge exchange, and fostering a sense of community that goes beyond digital interactions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*qImmho30AZ8kySYBYKj6-A.png\" /><figcaption>Numbers from last\u00a0year</figcaption></figure><p>The pursuit of knowledge is at the core of our community, and this is reflected in the more than twenty-five papers we presented at different conferences. These papers, authored by our talented members, explored cutting-edge ideas, challenged conventions, and contributed to the ongoing dialogue in their respective fields.</p><p>Last but not least, our Medium publication has become a hub for sharing insights, research findings, and thought leadership within the community. In the past year, we published an impressive fifty articles on diverse topics, showcasing the depth and breadth of expertise within our ranks. The impact of our community extends beyond our immediate circles, as evidenced by the growing audience on our Medium publication.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*j5kBSsPhk553nBRTmzhrqQ.png\" /><figcaption>Metrics from our Medium publication</figcaption></figure><p>As we celebrate the achievements of our community in the R&amp;D Community Awards ceremony, let these numbers serve as a reminder of the collective strength and impact we\u2019ve achieved together. Each statistic represents a story, an idea, and a contribution that has shaped the narrative of our community over the past\u00a0year.</p><h3>Awards Ceremony</h3><p>The awards were presented in five categories: Best Speaker of the Year, Best Article of the Year, Best Paper of the Year, Best Community Builder of the Year, and Best Open Source Project of the Year. The tech leads voted for the winners among finalists, picked by <a href=\"https://www.linkedin.com/in/kinisoftware/\">Kini</a>, our\u00a0DevRel.</p><h4>Best Speaker of the\u00a0Year</h4><p>The three finalists were selected considering their impact, internally and externally, because of the number of talks they had delivered, the conferences\u2019 relevance, and their involvement in activities as R&amp;D ambassadors.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*J5xbEEBpCH6mq6kAvw6e2A.png\" /><figcaption>The finalists for the \u201cSpeaker of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://www.linkedin.com/in/lagarde-henry/\"><strong>Henry</strong></a> presented at three big conferences this year: DevoxxUK, DevoxxBE, and DevoxxMA. He was also accepted for some other events. He is already applying for talks for\u00a02024.</li><li><a href=\"https://www.linkedin.com/in/pmokari/\"><strong>Pooneh</strong></a> presented in several places this year (plus DevoxxBE last year) and was invited to RivieraDev (France) as a keynoter. She\u2019s very involved in Women in Tech events/conferences, such as European Women In Tech 2023, where she was also a\u00a0speaker.</li><li><a href=\"https://www.linkedin.com/in/%E2%9B%A9%EF%B8%8F-sylvain-dedieu-b97788a1/\"><strong>Sylvain</strong></a> is one of our most active speakers, has been accepted in conferences this year (VoxxedDays Luxemburgo, a few DevFest, etc.), and will keep applying for talks in\u00a02024.</li></ul><h4>Best Article of the\u00a0Year</h4><p>The three finalists were selected by the number of reads they had. The three articles here are the ones that had the most significant impact this year, being boosted even for the Medium platform among its\u00a0members.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*-B6qXe-ZBFZfzTtDj-qJaA.png\" /><figcaption>The finalists for the \u201cArticle of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://medium.com/criteo-engineering/how-we-compute-data-lineage-at-criteo-b3f09fc5c577\">How we compute data lineage at Criteo</a></li><li><a href=\"https://medium.com/criteo-engineering/building-better-apis-with-chatgpt-9d3350beaf51\">Building better APIs with chatGPT</a></li><li><a href=\"https://medium.com/criteo-engineering/how-we-reduced-our-prometheus-infrastructure-footprint-by-a-third-8bf8171e46b1\">How we reduced our Prometheus infrastructure footprint by a third</a></li></ul><h4>Best Paper of the\u00a0Year</h4><p>Our commitment to staying at the forefront of industry trends and innovations was evident as we presented many papers. Our research community is always eager to learn, share, and engage with the broader research and development landscape. These three papers were selected by <a href=\"https://www.linkedin.com/in/livaralaivola/\">Liva</a>, our VP of Research, among all our outstanding contributions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*XI3RZS8hqUJ3hvFLkaNKEQ.png\" /><figcaption>The finalists for the \u201cPaper of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://github.com/White-Link/gpm\">Unifying GANs and Score-Based Diffusion as Generative Particle Models</a> (Jean-Yves Franceschi, Mike Gartrell, Ludovic Dos Santos, Thibaut Issenhuth, Emmanuel de B\u00e9zenac, Micka\u00ebl Chen, Alain Rakotomamonjy), to appear at NeurIPS\u00a02023.</li><li><a href=\"https://arxiv.org/abs/2305.15877\">Exponential Smoothing for Off-Policy Learning</a> (Imad Aouali, Victor-Emmanuel Brunel, David Rohde, Anna Korba), to appear at ICML\u00a02023.</li><li><a href=\"https://medium.com/criteo-engineering/learning-from-multiple-sources-for-data-to-text-and-text-to-data-4a6819588986\">Learning from Multiple Sources for Data-to-Text and Text-to-Data</a> (Song Duong, Alberto Lumbreras, Mike Gartrell, Patrick Gallinari), to appear at AISTATS\u00a02023.</li></ul><h4>Best Community Builder of the\u00a0Year</h4><p>Community building is key to success in our outreach activities. The finalists for this category were selected based on their implication, proactivity, energy, and impact. Each is involved in internal and external communities at different levels.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*GI_9-cuV-kPRuE9Blzvq4w.png\" /><figcaption>The finalists for the \u201cCommunity Builder of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://www.linkedin.com/in/khanh-tuong-maudoux-11b92b19/\"><strong>Khanh</strong></a> is involved with our speakers\u2019 community, both internally and externally. He\u2019s constantly communicating about CFPs, helping speakers with their proposals, creating opportunities with external communities (such as <a href=\"https://www.meetup.com/fr-FR/modern-data-stack-france/\">ModernDataStack</a> or <a href=\"https://www.parisjug.org/\">ParisJUG</a>), etc.</li><li><a href=\"https://www.linkedin.com/in/alejandraparedesceballos/\"><strong>Alejandra</strong></a> is the person behind the WomenDoTechToo initiative. Thanks to that, we have organized several meetups in different locations where we provide a safe space for our Woman at Tech in Criteo to share their expertise and technical knowledge.</li><li><a href=\"https://www.linkedin.com/in/%E2%9B%A9%EF%B8%8F-sylvain-dedieu-b97788a1/\"><strong>Sylvain</strong></a> joined Criteo recently, but he\u2019s already making a significant impact in Grenoble. He is helping to restart Criteo Meetups there, contacting possible guest speakers, promoting the events among the tech community there,\u00a0etc.</li></ul><h4>Best Open Source Project of the\u00a0Year</h4><p>Open Source is at the code of Criteo. We have built our products using many technologies supported by communities and open-source initiatives. It\u2019s time to provide value and make some noise about <a href=\"https://criteo.github.io/\">our projects</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*8sPCAtSUBF4jdp0aQrbelg.png\" /><figcaption>The finalists for the \u201cOpen Source project of the Year\u201d\u00a0category</figcaption></figure><ul><li><a href=\"https://medium.com/criteo-engineering/it-is-time-to-show-more-love-to-command-line-tools-eecb48e3e63c\">It is time to show more love to command-line tools</a></li><li><a href=\"https://medium.com/criteo-engineering/introducing-openapi-comparator-an-open-source-tool-to-detect-breaking-changes-in-your-api-7f705bb972b0\">Introducing OpenAPI Comparator: an open-source tool to detect breaking changes in your API</a></li><li><a href=\"https://medium.com/criteo-engineering/do-you-probe-your-network-a00c0ea1f994\">Do you probe your network?</a></li></ul><h4>And the winner\u00a0is\u2026</h4><ul><li>Speaker of the Year: <strong>Pooneh Mokariasl</strong>.</li><li>Article of the Year: <strong>How we reduced our Prometheus infrastructure footprint by a\u00a0third</strong>.</li><li>Community Builder of the Year: <strong>Alejandra Paredes</strong>.</li><li>Paper of the Year: <strong>Unifying GANs and Score-Based Diffusion as Generative Particle\u00a0Models</strong>.</li><li>Open Source Project of the Year: <strong>OpenAPI Comparator</strong>.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/760/0*BqZg572J5GOLnfbN\" /><figcaption>The winners!\u00a0\ud83d\udc4f</figcaption></figure><p>The R&amp;D Community Awards ceremony was a great success, and we are proud of all the finalists and winners. The ceremony was a testament to our community\u2019s hard work and dedication, and we hope that this recognition will inspire everyone to continue their pursuit of innovation.</p><p>Congratulations to all the winners and finalists! \ud83c\udfc6</p><p><a href=\"https://careers.criteo.com/en/teams/engineering/\">Engineering</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=dda0158ca10b\" width=\"1\" /><hr /><p><a href=\"https://medium.com/criteo-engineering/r-d-community-awards-2023-recap-dda0158ca10b\">R&amp;D Community Awards 2023 Recap</a> was originally published in <a href=\"https://medium.com/criteo-engineering\">Criteo R&amp;D Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "BenefitFocus": {
    "title": "One Place 2023 - Update",
    "xmlUrl": "https://www.benefitfocus.com/rss.xml",
    "htmlUrl": "https://www.benefitfocus.com/blogs/design-engineering",
    "title_detail": {
      "type": "text/plain",
      "language": "en",
      "base": "https://www.benefitfocus.com/",
      "value": "One Place 2023 - Update"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.benefitfocus.com/node/4794"
      }
    ],
    "link": "https://www.benefitfocus.com/node/4794",
    "summary": "<span>One Place 2023 - Update</span>\n<span><span lang=\"\" xml:lang=\"\">sarah.goldberg\u2026</span></span>\n<span><time datetime=\"2022-10-11T08:28:56-04:00\" title=\"Tuesday, October 11, 2022 - 08:28\">Tue, 10/11/2022 - 08:28</time></span>\n\n\n\t<p>We are reimagining our One Place event and actively planning new ways to deliver value and better meet the needs of our client and partner community in 2023.\u00a0</p>\n\n<p>Stay tuned for more details!</p>\n\n\n\tAll\n\n\n\t<a href=\"https://www.benefitfocus.com/taxonomy/term/1474\" hreflang=\"en\">Virtual</a>\n\n\n\t<a href=\"https://www.benefitfocus.com/media/5878/edit\" hreflang=\"en\">OnePlace-reimagined_Site_Thumbnail_Update_v1.jpg</a>\n\n\n\tYes",
    "summary_detail": {
      "type": "text/html",
      "language": "en",
      "base": "https://www.benefitfocus.com/",
      "value": "<span>One Place 2023 - Update</span>\n<span><span lang=\"\" xml:lang=\"\">sarah.goldberg\u2026</span></span>\n<span><time datetime=\"2022-10-11T08:28:56-04:00\" title=\"Tuesday, October 11, 2022 - 08:28\">Tue, 10/11/2022 - 08:28</time></span>\n\n\n\t<p>We are reimagining our One Place event and actively planning new ways to deliver value and better meet the needs of our client and partner community in 2023.\u00a0</p>\n\n<p>Stay tuned for more details!</p>\n\n\n\tAll\n\n\n\t<a href=\"https://www.benefitfocus.com/taxonomy/term/1474\" hreflang=\"en\">Virtual</a>\n\n\n\t<a href=\"https://www.benefitfocus.com/media/5878/edit\" hreflang=\"en\">OnePlace-reimagined_Site_Thumbnail_Update_v1.jpg</a>\n\n\n\tYes"
    },
    "published": "Tue, 11 Oct 2022 12:28:56 +0000",
    "published_parsed": [
      2022,
      10,
      11,
      12,
      28,
      56,
      1,
      284,
      0
    ],
    "authors": [
      {
        "email": "sarah.goldberg@benefitfocus.com"
      }
    ],
    "author": "sarah.goldberg@benefitfocus.com",
    "author_detail": {
      "email": "sarah.goldberg@benefitfocus.com"
    },
    "id": "4794 at https://www.benefitfocus.com",
    "guidislink": false
  },
  "Riot Games": {
    "title": "Reviving Nexus Blitz",
    "xmlUrl": "https://engineering.riotgames.com/rss.xml",
    "htmlUrl": "https://engineering.riotgames.com/",
    "title_detail": {
      "type": "text/plain",
      "language": "en",
      "base": "https://technology.riotgames.com/",
      "value": "Reviving Nexus Blitz"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://technology.riotgames.com/news/reviving-nexus-blitz"
      }
    ],
    "link": "https://technology.riotgames.com/news/reviving-nexus-blitz",
    "summary": "<img alt=\"\" height=\"494\" src=\"https://technology.riotgames.com/sites/default/files/articles/133/nb-tb.jpg\" width=\"1600\" />\n<p>In this article, we explore some of the challenges the team faced when reviving the Nexus Blitz game mode this year, from upgrading older systems to making them more accessible for future developers.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": "en",
      "base": "https://technology.riotgames.com/",
      "value": "<img alt=\"\" height=\"494\" src=\"https://technology.riotgames.com/sites/default/files/articles/133/nb-tb.jpg\" width=\"1600\" />\n<p>In this article, we explore some of the challenges the team faced when reviving the Nexus Blitz game mode this year, from upgrading older systems to making them more accessible for future developers.</p>"
    },
    "id": "133 at https://technology.riotgames.com",
    "guidislink": false,
    "published": "Tue, 28 Nov 2023 10:50:13 -0800",
    "published_parsed": [
      2023,
      11,
      28,
      18,
      50,
      13,
      1,
      332,
      0
    ],
    "source": {
      "href": "https://technology.riotgames.com/news/feed",
      "title": "Riot Games Tech Blog News Feed"
    },
    "authors": [
      {
        "name": "Derek Nguyen"
      }
    ],
    "author": "Derek Nguyen",
    "author_detail": {
      "name": "Derek Nguyen"
    }
  },
  "Soundcloud": {
    "title": "Android Large Screen Optimization",
    "xmlUrl": "https://developers.soundcloud.com/blog.rss",
    "htmlUrl": "https://developers.soundcloud.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://developers.soundcloud.com/blog/blog.rss",
      "value": "Android Large Screen Optimization"
    },
    "summary": "Large Screen Devices - The New Frontier SoundCloud large screen optimized Recently, the Android team at SoundCloud took on a project to\u2026",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://developers.soundcloud.com/blog/blog.rss",
      "value": "Large Screen Devices - The New Frontier SoundCloud large screen optimized Recently, the Android team at SoundCloud took on a project to\u2026"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://developers.soundcloud.com/blog/soundcloud-android-large-screen"
      }
    ],
    "link": "https://developers.soundcloud.com/blog/soundcloud-android-large-screen",
    "id": "https://developers.soundcloud.com/blog/soundcloud-android-large-screen",
    "guidislink": false,
    "published": "Mon, 31 Jul 2023 00:00:00 GMT",
    "published_parsed": [
      2023,
      7,
      31,
      0,
      0,
      0,
      0,
      212,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://developers.soundcloud.com/blog/blog.rss",
        "value": "<h1>Large Screen Devices - The New Frontier</h1>\n<p><img alt=\"SoundCloud large screen optimized\" src=\"https://developers.soundcloud.com/blog/49926d7e44d44ca3f84a67148412ba7b/after_vid_.gif\" /></p>\n<p>Recently, the Android team at SoundCloud took on a project to optimize the Android app for large screen devices. With the increasing use of devices like tablets, foldables, and Chromebooks, we decided to provide better support for them.</p>\n<p>The data showed us users were adopting these devices rapidly. What is more, both Google and Samsung had been vocal about the importance of optimizing for larger screens.</p>\n<p>Google is even launching a new <a href=\"https://android-developers.googleblog.com/2023/07/introducing-new-play-store-for-large-screens.html?m=1r\">Playstore</a> for large screen optimized apps only.</p>\n<p>In this blog post, we\u2019ll go through some of the challenges we faced, the UX and UI changes we made, and the code implementation. We hope our experiences will help you in your own large-screen adventures.</p>\n<h2>Why did we invest in Large Screens?</h2>\n<p>We saw a trend among our users - more and more of them were using SoundCloud on their tablets, foldable devices, and Chromebooks. And it wasn\u2019t just happening in <em>our</em> user base. Google and Samsung have been going all-in on large screens, bringing them more into the mainstream.</p>\n<p>When Google rolled out their Pixel Tablet, well-known tech reviewer Marques Brownlee pointed out that SoundCloud stood out from the crowd. He appreciated that we didn\u2019t just stretch our phone app to fit the larger screen, but instead, we crafted an experience that fully utilized the extra space. If you\u2019re interested, you can check out the video <a href=\"https://www.youtube.com/watch?v=aTf7AMVOoDY\">here</a>.</p>\n<h2>Our Investigation</h2>\n<h3>Where and how is music on large screens heard?</h3>\n<p><strong>Fun fact</strong>: People listen to music on their Tablets mostly while cooking.</p>\n<p>Imagine you\u2019re in the middle of preparing a meal, your hands are busy, but you can still easily control your music - that\u2019s convenience at its best.</p>\n<p>But it\u2019s not just about individual experiences. Tablets come into play during social events as well. The larger screen makes it simpler for everyone to engage with the music, whether it\u2019s to see what\u2019s currently playing or to add their favorite track to the queue.</p>\n<p>Through understanding these usage scenarios, we can better tailor our services to enhance the music listening experiences of our users. Be it cooking dinner or hosting a gathering, SoundCloud is there to make those moments even better with great music.</p>\n<h2>Google\u2019s and Samsung\u2019s Large Screens Guide</h2>\n<p><a href=\"https://developer.android.com/large-screens/\">Google\u2019s</a> and <a href=\"https://developer.samsung.com/one-ui/foldable-and-largescreen/intro.html\">Samsung\u2019s</a> large screen guides are roadmaps for developers wanting to optimize their apps for large screens. It encourages using scalable images and responsive and dynamic layouts for a consistent user experience across different screen sizes.</p>\n<p>Google also highlights using the extra space for features like split-screen views, and emphasizes touch target sizing, clear text, and intuitive navigation. Following these best practices ensures apps are user-friendly and competitive in the large screen devices market.</p>\n<h2>Google\u2019s Large Screen Compatibility Checklist</h2>\n<p><a href=\"https://developer.android.com/docs/quality-guidelines/large-screen-app-quality\">Google\u2019s Large Screen Checklist</a>, available in their Android developer documentation, provides developers with a <strong>tier-based framework</strong> for ensuring high-quality app experiences on large screen devices. The checklist encompasses not only UI design but also considerations for navigation, keyboard/stylus input, and overall app usage.</p>\n<p>The checklist is divided into tiers, offering developers a structured approach to prioritize and implement essential features and optimizations based on the level of support desired for large screen devices. The tiers range from basic support to more advanced features and functionalities that fully leverage the potential of large screens.</p>\n<h2>The SoundCloud App</h2>\n<p>When we reviewed Google\u2019s checklist it was clear that the SoundCloud app fell short in certain areas, particularly in terms of adapting the screen layout. The app\u2019s tendency to merely stretch the phone layout to fit larger screens resulted in a less than optimal user interface. This realization was our call to action.</p>\n<p>In the upcoming sections, we\u2019ll take you on a visual tour of these components, accompanied by code snippets and technical explanations to provide you with an inside look at our optimization process.</p>\n<h3>Bottom Navigation Bar</h3>\n<p>Before: \u274c <strong>Horizontally stretched phone layout bottom navigation bar</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/c475858b665c881f250318b6bfdb3de9/2e21e/nav_before.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"Before\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/c475858b665c881f250318b6bfdb3de9/8ff1e/nav_before.png\" title=\"Before\" />\n  </a>\n    </span></p>\n<p>Traditionally, SoundCloud\u2019s Android app utilized a bottom navigation bar in a phone layout, which was stretched horizontally to fit larger screen sizes. This approach was straightforward, but it proved ineffective for larger screens. The extended navigation bar made it difficult for users to navigate the app, as it required them to move their focus from one end of the screen to the other.</p>\n<p>After: \u2705 <strong>Nav bar rail optimized for large screens</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/13e9bbfb388b3e17460827288d4cb7a0/2e21e/nav_after_home.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"After\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/13e9bbfb388b3e17460827288d4cb7a0/8ff1e/nav_after_home.png\" title=\"After\" />\n  </a>\n    </span></p>\n<p>To remedy this, we adopted a vertical navigation rail for large screen layouts, aligning it to the side of the screen. This is recommended by Google as it provides a more comfortable browsing experience. The menu options are now neatly stacked in a column, making them accessible without the need for extensive eye or cursor movement.</p>\n<h3>Code Implementation</h3>\n<p><strong>Before: BottomNavigationView</strong></p>\n<p>Previously, the SoundCloud Android app used a <code class=\"language-text\">BottomNavigationView</code> to create the bottom navigation bar. This worked well on smaller devices but led to a stretched UI on larger screens.</p>\n<p><strong>After: NavigationRailView</strong> </p>\n<p>To address this, we replaced the <code class=\"language-text\">BottomNavigationView</code> with <code class=\"language-text\">NavigationRailView</code> for larger screens. Both these classes implement the <code class=\"language-text\">NavigationBarView</code> interface. This allows for a smooth transition with minimal code changes.</p>\n<p>To differentiate between smaller and larger screens, we created two separate layout files. One uses the <code class=\"language-text\">BottomNavigationView</code>, and the other uses the <code class=\"language-text\">NavigationRailView</code>. In Kotlin, we dynamically set the layout file based on the size of the device.</p>\n<h3>Identifying Large Devices</h3>\n<p>We identify whether a device is large or small by using a boolean variable, <code class=\"language-text\">is_tablet</code>, defined in three separate XML value files based on the screen width.</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-text\"><code class=\"language-text\">// res/values-sw600dp/booleans.xml\n&lt;bool name=&quot;is_tablet&quot;&gt;true&lt;/bool&gt;\n\n// res/values-sw370dp/booleans.xml\n&lt;bool name=&quot;is_tablet&quot;&gt;false&lt;/bool&gt;\n\n// res/values/booleans.xml\n&lt;bool name=&quot;is_tablet&quot;&gt;false&lt;/bool&gt;</code></pre></div>\n<p>In Kotlin, we check the <code class=\"language-text\">is_tablet</code> boolean value and set the layout file accordingly. This is done using the following code:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-text\"><code class=\"language-text\">val isTablet = context.resources.getBoolean(R.bool.is_tablet)\n\nif(isTablet) {\n    setContentView(R.layout.tablet_layout)\n} else {\n    setContentView(R.layout.phone_layout)\n}</code></pre></div>\n<p>Hardcoding resources is not the best solution. Google\u2019s documentation provides some great insights on supporting different screen sizes, including the concept of Window Size Classes. Window Sizes allow the UI to adapt to various window configurations on foldable and large screen devices. Here\u2019s the link for more details: <a href=\"https://developer.android.com/guide/topics/large-screens/support-different-screen-sizes\">Window Size Classes</a>.</p>\n<h3>Unit Testing and A/B Testing</h3>\n<p>To enable testing, we added a wrapper class around the <code class=\"language-text\">isTablet</code> boolean. We also leveraged feature flags to conduct A/B testing of our new layout. We introduced a class <code class=\"language-text\">NavRailExperiment</code> to check both the device type and the feature flag state:\nHere\u2019s a look at our implementation of this approach:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-text\"><code class=\"language-text\">class NavRailExperiment(private val appFeatures: AppFeatures) {\n    val isEnabled: Boolean\n        get() = context.resources.getBoolean(R.bool.is_tablet) &amp;&amp; appFeatures.isNavRailEnabled()\n}</code></pre></div>\n<h2>Mini Player</h2>\n<p>Transitioning from a Stretched Phone Layout Mini Player to a Right-Aligned Mini Player</p>\n<p>Before: \u274c <strong>Horizontally stretched phone layout Mini Player</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/db8d1462c7be8c5a7e441da0c1c48304/2e21e/before_mini_player.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"Before\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/db8d1462c7be8c5a7e441da0c1c48304/8ff1e/before_mini_player.png\" title=\"Before\" />\n  </a>\n    </span></p>\n<p>In the past, SoundCloud\u2019s Android app featured a Mini Player stretched horizontally across the screen. While this design worked for smaller screens, it resulted in a suboptimal user experience on larger devices due to the extended reach required to interact with it.</p>\n<p>After: \u2705 <strong>Small right-aligned Mini Player optimized for large screens</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/498099e599a4bc9f37ca666f575b477e/2e21e/after_mini_player.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"After\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/498099e599a4bc9f37ca666f575b477e/8ff1e/after_mini_player.png\" title=\"After\" />\n  </a>\n    </span></p>\n<p>To provide a more user-friendly interface we opted for a small Mini Player on the right side of the screen. This ensures controls are comfortably within thumb reach.</p>\n<h3>Code Implementation</h3>\n<p>The Player is a BottomSheet with a ViewPager, the Mini Player is a view inside each page of the ViewPager. We use a <code class=\"language-text\">BottomSheetBehavior</code> to support  collapsed and expanded states. In the expanded state the player shows the full width and height of the ViewPager.\nIn collapsed state it shows only the Mini Player view, and the height is collapsed to 50dp. The width was always <code class=\"language-text\">match_parent</code>, but since we want it to be small, we set the width of the <code class=\"language-text\">BottomSheet</code> to <code class=\"language-text\">200dp</code>.</p>\n<p>The class <code class=\"language-text\">BottomSheetBehavior</code> provides us with a method <code class=\"language-text\">setMaxWidth</code> which we use to set the width while animating the collapse and expansion of the BottomSheet Player.\nThe other issue here is that we also have to set the width on the ViewPager and the ViewPager\u2019s visible page.\nAdditionally, we must move the player to the right side thus setting the left margin on layout params on each player transition.</p>\n<p>The<code class=\"language-text\">BottomSheetBehavior</code> also has a <code class=\"language-text\">BottomSheetBehavior.BottomSheetCallback</code> field.\nThe <code class=\"language-text\">BottomSheetBehavior.BottomSheetCallback</code> has an onSlide method which allows us to set the width and left margin on the <code class=\"language-text\">BottomSheet</code> and the <code class=\"language-text\">ViewPager</code>\u2019s visible page.</p>\n<p>Below is the code: </p>\n<div class=\"gatsby-highlight\"><pre class=\"language-text\"><code class=\"language-text\">bottomSheetBehavior.bottomSheetCallback = BottomSheetBehavior.BottomSheetCallback() {         \n    val miniplayerWidth = screenWidth * offset\n    val leftMargin = screenWidth - miniplayerWidth\n        \n    setLeftMargin(viewPager.views(), leftMargin)\n        \n    setWidth(viewPager.views(), bottomSheet, miniplayerWidth)\n};</code></pre></div>\n<h2>Comments &#x26; Playqueue on Player</h2>\n<p>The SoundCloud Android app hosts two main features on its player screen - the comments and the Playqueue. Before, when a user accessed either of these features, a new screen would open, occupying the entire display and obstructing interaction with the player.</p>\n<p>Before: \u274c <strong>Horizontally stretched phone comments layout</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/19374224f0bdc7ef165020ac60d56db3/8b984/before_comments.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"Before Comments\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/19374224f0bdc7ef165020ac60d56db3/8ff1e/before_comments.png\" title=\"Before Comments\" />\n  </a>\n    </span></p>\n<p>Before: \u274c <strong>Horizontally stretched phone playqueue layout</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/7a887c6c3962884e45e3367c0309b415/8b984/before_playqueue.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"Before Playqueue\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/7a887c6c3962884e45e3367c0309b415/8ff1e/before_playqueue.png\" title=\"Before Playqueue\" />\n  </a>\n    </span></p>\n<p>We revamped this experience in the following ways: Instead of taking up the whole screen, the Comments and Playqueue sections now open on the right side of the player. This allows users to engage with these features and interact with the player simultaneously.</p>\n<p>Additionally, the buttons to access the comments and Playqueue were originally at the bottom of the screen. To increase accessibility and free up space at the bottom, we moved them to the left side.</p>\n<p>After: \u2705 <strong>Right-aligned comments optimized for large screen</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/3184394bbe2a94f7516f6486199f2b0a/8b984/after_comments.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"After Comments\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/3184394bbe2a94f7516f6486199f2b0a/8ff1e/after_comments.png\" title=\"After Comments\" />\n  </a>\n    </span></p>\n<p>After: \u2705 <strong>Right-aligned playqueue optimized for large screen</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/72076ee0eca4a4ae0974d95592447184/8b984/after_playqueue.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"After Playqueue\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/72076ee0eca4a4ae0974d95592447184/8ff1e/after_playqueue.png\" title=\"After Playqueue\" />\n  </a>\n    </span></p>\n<p>Repositioning the UI elements in this way contributes to a more ergonomic and intuitive user experience on larger screens, reinforcing our commitment to delivering the best listening experience across all devices.</p>\n<h3>Addressing User Experience (UX) Challenges</h3>\n<p>Our changes to the UI introduced some UX challenges, especially related to the comments feature. Two major questions emerged:</p>\n<ul>\n<li>When a track changes, should the comments update to correspond to the new track, or should it continue displaying comments from the previous track?</li>\n<li>What should happen to a comment a user is currently writing if the track changes?</li>\n</ul>\n<p>To tackle the first issue, we opted to update the comments to align with the new track. We believe this adjustment is more in line with user expectations, as it helps keep the entire screen contextually relevant.</p>\n<p>For the second scenario, we implemented a solution where the comments section doesn\u2019t update if the text field is currently in focus. This prevents any in-progress comments being lost, thereby providing a more user-friendly commenting experience.</p>\n<h3>Code Implementation</h3>\n<p>To integrate the comments and Playqueue screens over the player, we introduced a new <code class=\"language-text\">FrameLayout</code> named <code class=\"language-text\">player_side_fragment_holder</code>. This frame holds the additional features and ensures they are displayed without disrupting the main player.</p>\n<p>This side fragment holder is positioned above the player and is assigned a transparent background along with a width of 400dp. Consequently, when the user taps on the comments or Playqueue button, the respective screen appears over the player. This is made possible by a secondary <code class=\"language-text\">FragmentManager</code> which adds either the <code class=\"language-text\">CommentsFragment</code> or the <code class=\"language-text\">PlayqueueFragment</code> to the <code class=\"language-text\">FrameLayout</code>.</p>\n<p>Here\u2019s how the layout is structured:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>FrameLayout</span>\n    <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_width</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span>\n    <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_height</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Player</span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_width</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_height</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span> <span class=\"token punctuation\">/></span></span>\n\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>FrameLayout</span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>id</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>@+id/player_side_fragment_holder<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_width</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>400dp<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_height</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_gravity</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>right<span class=\"token punctuation\">\"</span></span> <span class=\"token punctuation\">/></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>FrameLayout</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>In this layout configuration, the <code class=\"language-text\">player_side_fragment_holder</code> is specified to align on the right side, allowing it to overlay the player when comments or the Playqueue are invoked. This approach ensures that the main player remains interactive while users are interacting with these features.</p>\n<h2>Search</h2>\n<p>In our drive to optimize the large screen experience, we revamped the search screen to offer both search suggestions and top results side by side. The updated design splits the screen into two sections when users begin a search. One side displays real-time search suggestions, while the other showcases the top results. This allows users to compare suggestions and top results instantly, leading to a more seamless and enriched search experience.</p>\n<p>Before: \u274c <strong>Horizontally stretched search suggestions</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/c298f1017b36e2595b16b92b46094967/8b984/before_search.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"Before\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/c298f1017b36e2595b16b92b46094967/8ff1e/before_search.png\" title=\"Before\" />\n  </a>\n    </span></p>\n<p>After: \u2705 <strong>Split search suggestions and search results</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/ed5a8acfc859406cbe248bb2dca3e1d4/8b984/after_search.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"After\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/ed5a8acfc859406cbe248bb2dca3e1d4/8ff1e/after_search.png\" title=\"After\" />\n  </a>\n    </span></p>\n<h3>Code Implementation</h3>\n<p><strong>Code Implementation for Split Search Screen</strong></p>\n<p>In order to implement our split-screen search feature, we use <code class=\"language-text\">ConstraintLayout</code>. This offers the ability to create layouts based on percentages, which we use to divide the screen between search suggestions and top results.</p>\n<p>To split the screen, we defined a width constraint of 40% for the search suggestions, leaving the remaining 60% for the top results:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-xml\"><code class=\"language-xml\">app:layout_constraintWidth_default=\"percent\"\napp:layout_constraintWidth_percent=\".4\"</code></pre></div>\n<p>Here is the full code for the side-by-side layout:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>androidx.constraintlayout.widget.ConstraintLayout</span>\n    <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_width</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span>\n    <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_height</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>FrameLayout</span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>id</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>@+id/search_container<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_width</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>0dp<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_height</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintWidth_default</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>percent<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintWidth_percent</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>.4<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintBottom_toBottomOf</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>parent<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintStart_toStartOf</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>parent<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintTop_toTopOf</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>parent<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>androidx.fragment.app.FragmentContainerView</span>\n            <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>id</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>@+id/search_suggestions<span class=\"token punctuation\">\"</span></span>\n            <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_width</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span>\n            <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_height</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>match_parent<span class=\"token punctuation\">\"</span></span> <span class=\"token punctuation\">/></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>FrameLayout</span><span class=\"token punctuation\">></span></span>\n\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>androidx.recyclerview.widget.RecyclerView</span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>id</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>@+id/section_results_top_items<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_width</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>0dp<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">android:</span>layout_height</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>wrap_content<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintBottom_toBottomOf</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>parent<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintEnd_toEndOf</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>parent<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintStart_toEndOf</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>@id/search_container<span class=\"token punctuation\">\"</span></span>\n        <span class=\"token attr-name\"><span class=\"token namespace\">app:</span>layout_constraintTop_toTopOf</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>parent<span class=\"token punctuation\">\"</span></span> <span class=\"token punctuation\">/></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>androidx.constraintlayout.widget.ConstraintLayout</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>This layout allocates 40% of the screen width to a <code class=\"language-text\">FrameLayout</code> which houses the search suggestions, while the remaining space is assigned to a <code class=\"language-text\">RecyclerView</code> for displaying top results. The constraints ensure the proper positioning and responsiveness of these elements, providing a dynamic, user-friendly search interface.</p>\n<h2>Artist</h2>\n<p>Our previous design for the Artist screen wasn\u2019t well-optimized for larger screens. The result was a horizontally stretched layout with excessive padding and white space around the artist details. As a consequence, users had to scroll vertically to access tracks or albums from the artist.</p>\n<p>Before: \u274c <strong>Stretched artist profile</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/da9926b27e5fefb202eeea7723d2dc2a/8b984/before_artist.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"Before\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/da9926b27e5fefb202eeea7723d2dc2a/8ff1e/before_artist.png\" title=\"Before\" />\n  </a>\n    </span>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/b3626ab90587e09b1591b266cab88e68/8b984/before_artist_1.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"Before Page 2\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/b3626ab90587e09b1591b266cab88e68/8ff1e/before_artist_1.png\" title=\"Before Page 2\" />\n  </a>\n    </span></p>\n<p>To improve this, we took advantage of the space available on larger screens. We moved the Artist details to the left side of the screen and displayed them more compactly. This makes all the necessary information immediately visible and reduces unnecessary scrolling.</p>\n<p>Simultaneously, the right side of the screen is dedicated to displaying the artist\u2019s tracks and albums. This clear separation of content means that users can quickly view and interact with the artist\u2019s music. Through this design, we\u2019ve been able to optimize space and present a well-structured layout that enhances the navigation and interaction for our users on large screen devices.</p>\n<p>After: \u2705 <strong>Compact artist profile</strong>\n<span class=\"gatsby-resp-image-wrapper\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n      <a class=\"gatsby-resp-image-link\" href=\"https://developers.soundcloud.com/blog/static/b752ae17a90a4cfe30dba209d5ad8ed7/8b984/after_artist.png\" rel=\"noopener\" style=\"display: block;\" target=\"_blank\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"display: block;\"></span>\n  <img alt=\"After\" class=\"gatsby-resp-image-image\" src=\"https://developers.soundcloud.com/blog/static/b752ae17a90a4cfe30dba209d5ad8ed7/8ff1e/after_artist.png\" title=\"After\" />\n  </a>\n    </span></p>\n<h2>Keyboard Tab Navigation</h2>\n<p>We needed to support keyboard tab navigation for devices that have keyboards attached. You can easily test your apps by connecting a bluetooth keyboard.</p>\n<p>If you are using <code class=\"language-text\">AppBarLayout</code> you might end up not navigating through the toolbar icons.\nWe had to set <code class=\"language-text\">touchscreenBlocksFocus = false</code> to our <code class=\"language-text\">AppBarLayout</code> in order to allow navigating through the toolbar icons.</p>\n<p>At first, we had problems navigating the player using a keyboard. The default navigation did not work correctly so we had to force set the navigation flow.\nTo do this we use the <a href=\"https://developer.android.com/develop/ui/views/touch-and-input/keyboard-input/navigation\">xml attribute</a> <code class=\"language-text\">android:nextFocusForward</code>. </p>\n<p>For better understanding, here\u2019s the specified order for tab key navigation in the player:</p>\n<ol>\n<li>First, the focus lands on the artist\u2019s name.</li>\n<li>Then, it moves to the track name.</li>\n<li>Next, it goes to the option to minimize the player.</li>\n<li>After that, it directs to the \u2018Follow artist\u2019 option.</li>\n<li>It subsequently moves through options like \u2018Like\u2019, \u2018Comments\u2019, \u2018Share\u2019, \u2018Playqueue\u2019, and \u2018More\u2019 buttons.</li>\n<li>Lastly, it settles on the \u2018Play/Pause\u2019 button.</li>\n</ol>\n<h2>Space bar toggles playback - Only for media playback apps</h2>\n<p>One of the requirements from Google is to support playback toggling through the space bar key. This feature allows users to play or pause music just by hitting the space bar on their keyboards, irrespective of their current position in the app.</p>\n<p>The implementation of this functionality can be achieved by overriding the <code class=\"language-text\">onKeyUp</code> method. On detection of a key press, it verifies if the pressed key corresponds to the space bar, and if so it toggles the playback and returns <code class=\"language-text\">true</code>.</p>\n<p>In all the <code class=\"language-text\">Activity</code> classes where the play/pause button is present, the <code class=\"language-text\">onKeyUp</code> method is overridden as shown below:</p>\n<div class=\"gatsby-highlight\"><pre class=\"language-kotlin\"><code class=\"language-kotlin\"><span class=\"token keyword\">override</span> <span class=\"token keyword\">fun</span> <span class=\"token function\">onKeyUp</span><span class=\"token punctuation\">(</span>keyCode<span class=\"token operator\">:</span> Int<span class=\"token punctuation\">,</span> event<span class=\"token operator\">:</span> KeyEvent<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> Boolean <span class=\"token punctuation\">{</span>\n    <span class=\"token function\">takeKeyEvents</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>keyCode <span class=\"token operator\">==</span> KeyEvent<span class=\"token punctuation\">.</span>KEYCODE_SPACE<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token boolean\">true</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">super</span><span class=\"token punctuation\">.</span><span class=\"token function\">onKeyUp</span><span class=\"token punctuation\">(</span>keyCode<span class=\"token punctuation\">,</span> event<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>It\u2019s worth noting that we used the <code class=\"language-text\">takeKeyEvents(true)</code> method to ensure that the current activity can handle key events.</p>\n<p>Finally, to make sure the play/pause button is the default focus, we set <code class=\"language-text\">android:focusedByDefault=&quot;true&quot;</code> on the button. This is done to prevent other views from gaining focus by default, which could intercept the space bar key press event.</p>\n<h2>Testing on Emulators and Devices</h2>\n<p>When it comes to testing on large screens, we found the Desktop emulator to be the most suitable option. The key benefit is its ability to swiftly resize the app window, mirroring the actions performed on a typical device. This allows us to test responsive behavior on different devices like phones, tablets, and desktops.</p>\n<p>Google also offers support for emulators designed for foldable devices. These emulators can be useful for preliminary testing. However, we mostly relied on a physical device, the Samsung Fold, to conduct tests for foldable devices, as it proved to be more accurate.</p>\n<p>Lastly, to ensure our app supports hover states and keyboard operations efficiently, we used the Samsung S7+ equipped with an S Pen and Keyboard Bundle. This allowed us to simulate an environment similar to a laptop or a tablet with a keyboard.</p>\n<h2>Conclusion</h2>\n<p>Our journey to optimizing for large screens was filled with exciting challenges and insightful discoveries. We realized that providing a seamless experience across a variety of devices - from smartphones to tablets, desktops, TVs, foldables and more - was more than just stretching our existing user interface. It was about reimagining and reconfiguring every element and interaction to deliver a superior music streaming experience.</p>\n<p>In addressing the various UI and UX challenges, we found that each element of our service had the potential to be adapted and improved. We reworked our Player and Search screen, redesigned the Artist screen layout, and made sure that keyboard navigation and hover states were smoothly implemented. This process of continuous improvement reinforced to us how important it is to stay flexible in the face of evolving trends.</p>\n<p>As technology continues to change and expand, we are committed to staying ahead, making sure that SoundCloud remains the leading choice for music streaming, no matter the device.</p>"
      }
    ]
  },
  "Credit Karma": {
    "title": "Karmahack 2021 Recap: What Makes a Good Hackathon?",
    "xmlUrl": "https://engineering.creditkarma.com/feed",
    "htmlUrl": "https://engineering.creditkarma.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.creditkarma.com/feed",
      "value": "Karmahack 2021 Recap: What Makes a Good Hackathon?"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.creditkarma.com/karmahack-2021-recap-what-makes-a-good-hackathon"
      }
    ],
    "link": "https://engineering.creditkarma.com/karmahack-2021-recap-what-makes-a-good-hackathon",
    "authors": [
      {
        "name": "jakebrower"
      }
    ],
    "author": "jakebrower",
    "author_detail": {
      "name": "jakebrower"
    },
    "published": "Mon, 22 Nov 2021 17:17:56 +0000",
    "published_parsed": [
      2021,
      11,
      22,
      17,
      17,
      56,
      0,
      326,
      0
    ],
    "tags": [
      {
        "term": "Uncategorized",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.creditkarma.com/?p=838",
    "guidislink": false,
    "summary": "<p>In 2017, Credit Karma launched Karmahack, its first-ever hackathon. The event brought together more than 100 employees from across the business to develop the most compelling product concept within 72 hours.&#160; This was a time of rapid growth for Credit Karma. We had just launched internationally, expanded into new business verticals, and had grown our [&#8230;]</p>\n<p>The post <a href=\"https://engineering.creditkarma.com/karmahack-2021-recap-what-makes-a-good-hackathon\" rel=\"nofollow\">Karmahack 2021 Recap: What Makes a Good Hackathon?</a> appeared first on <a href=\"https://engineering.creditkarma.com\" rel=\"nofollow\">Credit Karma Engineering Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.creditkarma.com/feed",
      "value": "<p>In 2017, Credit Karma launched Karmahack, its first-ever hackathon. The event brought together more than 100 employees from across the business to develop the most compelling product concept within 72 hours.&#160; This was a time of rapid growth for Credit Karma. We had just launched internationally, expanded into new business verticals, and had grown our [&#8230;]</p>\n<p>The post <a href=\"https://engineering.creditkarma.com/karmahack-2021-recap-what-makes-a-good-hackathon\" rel=\"nofollow\">Karmahack 2021 Recap: What Makes a Good Hackathon?</a> appeared first on <a href=\"https://engineering.creditkarma.com\" rel=\"nofollow\">Credit Karma Engineering Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.creditkarma.com/feed",
        "value": "<p>In 2017, Credit Karma launched Karmahack, its first-ever hackathon. The event brought together more than 100 employees from across the business to develop the most compelling product concept within 72 hours.&nbsp;</p>\n\n\n\n<p>This was a time of rapid growth for Credit Karma. We had just launched internationally, expanded into new business verticals, and had grown our user base to more than 75 million members. At the same time, we were competing for talent with some of the biggest names in tech and looking to build a culture of innovation that could attract top engineers. To do so, we knew we needed to foster innovation from within, leading to the inception of Karmahack, a collaborative forum where employees could come together, exchange ideas and solve problems through technology. What started as a trial run has evolved into an annual tradition, and one of Credit Karma&#8217;s most anticipated events of the year.</p>\n\n\n\n<p>\u201cKarmahack is all about community,\u201d said Krispy Uccello, Sr.SWE L2 and organizer of Karmahack. \u201cIn a sense, we all work together, we share the same space, but not always the same mindshare. Karmahack unites diverse perspectives and ideas from a collection of Karmanauts who are passionate about solving problems beyond their day-to-day work responsibilities.\u201d</p>\n\n\n\n<p>In October, Credit Karma hosted its fourth annual Karmahack, held virtually. While this year\u2019s event looked different than previous years, spirit did not waver as 164 Karmanauts from across the globe banded together virtually to ideate, build and inspire through product development. This year brought forth 22 innovations that incorporated four key themes: velocity, automation, integrations and security.</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"h-what-makes-a-good-hackathon\"><strong>What makes a good hackathon?&nbsp;</strong></h2>\n\n\n\n<p></p>\n\n\n\n<p>As we wrap this year\u2019s Karmahack and reflect on past events, some learnings stand out. Here are a few factors to consider when planning a hackathon:&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\" id=\"h-be-agile-but-have-a-plan\"><strong>Be agile, but have a plan</strong></h4>\n\n\n\n<p>Sufficient preparation goes into supporting a large-scale event like a hackathon. While you should strive to create a fun, laidback environment for participants, having processes in place eliminates potential chaos or confusion. Have a Plan B, but more importantly, have lieutenants you can lean on for support. For example, some of our judges had conflicts arise just before the event, but we had backups that we were able to sub in immediately. We also ran into livestream issues on Google Meet, but designated members on our IT and A/V teams addressed these issues quickly.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\" id=\"h-foster-creativity\"><strong>Foster creativity&nbsp;</strong></h4>\n\n\n\n<p>Generally, engineers build with guardrails in place to maintain product quality and security. While these are imperative principles to adhere to when building an application used by millions of people, it doesn\u2019t always allow for creativity to prosper. A hackathon should enable technologists to break away from typical constraints they\u2019re used to building within, while providing a low-risk environment that encourages ideas and passions to flourish.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\" id=\"h-hackathons-are-for-everyone\"><strong>Hackathons are for everyone</strong></h4>\n\n\n\n<p>It\u2019s often assumed hackathons are reserved for engineers, but some of the most interesting projects conceived from Karmahacks were spearheaded by Karmanauts in non-technical roles. Encouraging employees in other organizations to get involved creates an inclusive culture, which can provide immense value for the business. This is especially true for product-driven companies, as diverse perspectives yield better, more inclusive products for consumers.</p>\n\n\n\n<h4 class=\"wp-block-heading\" id=\"h-get-new-employees-involved\"><strong>Get new employees involved&nbsp;</strong></h4>\n\n\n\n<p>Joining a hackathon might be intimidating for a new hire. That\u2019s why it\u2019s important to have a plan in place for how you and other members of your team will recruit new employees to sign up. This will give new members visibility and internal networking opportunities, while also bringing fresh perspectives and ways of thinking from which the team can benefit.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\" id=\"h-learn-and-iterate\"><strong>Learn and iterate</strong></h4>\n\n\n\n<p>You won\u2019t get everything right the first time. Collect feedback from participants. Learn from that feedback, adjust and iterate. It took us four years to come up with a community voting process that we felt eliminated potential voting bias, and that\u2019s okay because it got us to a solution that we will continue to use.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"h-what-s-your-hackathon-differentiator\"><strong>What\u2019s your hackathon differentiator?&nbsp;</strong></h2>\n\n\n\n<p></p>\n\n\n\n<p>How does your hackathon stand out from others? What makes your company\u2019s culture different and how does that show up in your event?&nbsp;</p>\n\n\n\n<p>\u201cKarmahack has a very friendly and collaborative vibe,\u201d said Uccello. \u201cNot to say it isn\u2019t intense &#8211; participants are putting in long hours and there is a competitive spirit to it, but there are no monetary incentives for winners and we still get an amazing turn out every year.\u201d&nbsp;</p>\n\n\n\n<p>One might say the best things about Karmahack, particularly collaboration, passion and outside-of-the-box thinking has bled into product development at Credit Karma. Karmahack is a volunteer-based event where employees can build things they are passionate about, often trying to solve widespread issues that exist in the real world. This approach to product development has carried over to a number of internal volunteer-led initiatives to tackle social and economic issues exacerbated by the pandemic, including&nbsp; <a href=\"https://www.creditkarma.com/relief\">Relief Roadmap</a> and <a href=\"https://www.creditkarma.com/advice/i/why-credit-karma-voter-registration\" rel=\"noreferrer noopener\" target=\"_blank\">Voter Roadmap</a>.&nbsp;</p>\n\n\n\n<p>\u201cThe thinking and ideas that emerge from Karmahack have a strong cultural and business-oriented effect,\u201d said Uccello. Over the years, several of these innovations have influenced product development at Credit Karma.\u201d</p>\n<p>The post <a href=\"https://engineering.creditkarma.com/karmahack-2021-recap-what-makes-a-good-hackathon\" rel=\"nofollow\">Karmahack 2021 Recap: What Makes a Good Hackathon?</a> appeared first on <a href=\"https://engineering.creditkarma.com\" rel=\"nofollow\">Credit Karma Engineering Blog</a>.</p>"
      }
    ],
    "post-id": "838"
  },
  "HashiCorp": {
    "title": "HashiConf 2024 scholarship program now open for applications",
    "xmlUrl": "https://www.hashicorp.com/blog/feed.xml",
    "htmlUrl": "https://www.hashicorp.com/blog/",
    "title_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.hashicorp.com/blog/feed.xml",
      "value": "HashiConf 2024 scholarship program now open for applications"
    },
    "id": "https://www.hashicorp.com/blog/hashiconf-2024-scholarship-program-now-open-for-applications",
    "guidislink": true,
    "link": "https://www.hashicorp.com/blog/hashiconf-2024-scholarship-program-now-open-for-applications",
    "links": [
      {
        "href": "https://www.hashicorp.com/blog/hashiconf-2024-scholarship-program-now-open-for-applications",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "updated": "2024-01-11T20:00:00.000Z",
    "updated_parsed": [
      2024,
      1,
      11,
      20,
      0,
      0,
      3,
      11,
      0
    ],
    "summary": "Here is your chance to apply for a scholarship to attend HashiConf in Boston, October 14-16.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.hashicorp.com/blog/feed.xml",
      "value": "Here is your chance to apply for a scholarship to attend HashiConf in Boston, October 14-16."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.hashicorp.com/blog/feed.xml",
        "value": "<p>We are pleased to once again offer a scholarship program to support members of our community from all backgrounds to attend <a href=\"https://hashiconf.com/2024/\">HashiConf 2024</a>. This community cloud conference will be held October 14-16 in Boston, Massachusetts.</p>\n\n<p>At HashiCorp, we value diversity and strive to foster an inclusive community. Applicants from all backgrounds in technology, cloud computing, and open source communities are welcome. The <a href=\"https://forms.gle/CpUmtw7std2qd19XA\">scholarship program</a> exists to support members of the technical community who may lack the financial sponsorship or means to attend.</p>\n\n<p><a href=\"https://forms.gle/CpUmtw7std2qd19XA\">Applications</a> will be evaluated according to three criteria:</p>\n\n<ul>\n<li><strong>Need:</strong> Will a scholarship allow the applicant to attend when they otherwise could not?</li>\n<li><strong>Value:</strong> Would the applicant's experience and interests enable them to receive value from attending HashiConf?</li>\n<li><strong>Impact:</strong> Is the applicant likely to make a positive impact on the HashiCorp community by attending HashiConf?</li>\n</ul>\n\n<p>There are three categories of scholarship available, based roughly on where the applicant will be traveling from and therefore how much financial support they will need.</p>\n\n<p>Scholarship winners will be selected by a diverse group of HashiCorp employees. The personal information in applications will remain confidential to the committee during the review process and after scholarships are awarded.</p>\n\n<p><a href=\"https://forms.gle/CpUmtw7std2qd19XA\">Apply now for the HashiCorp scholarship</a> to attend HashiConf 2024. The deadline to apply for the HashiConf 2024 scholarship program is 11:59 p.m. PT on Sunday, March 10, 2024.</p>\n\n<p>We look forward to your applications! Please reach out to <a href=\"mailto:scholarship@hashicorp.com\">scholarship@hashicorp.com</a> if you have any questions.</p>"
      }
    ],
    "authors": [
      {
        "name": "Alexandra Freeman",
        "href": "https://hashicorp.com/blog/authors/alexandra-freeman"
      }
    ],
    "author_detail": {
      "name": "Alexandra Freeman",
      "href": "https://hashicorp.com/blog/authors/alexandra-freeman"
    },
    "href": "https://hashicorp.com/blog/authors/alexandra-freeman",
    "author": "Alexandra Freeman"
  },
  "Red Hat": {
    "title": "Connect a .NET app to an external PostgreSQL database",
    "xmlUrl": "https://developers.redhat.com/blog/feed/atom/",
    "htmlUrl": "https://developers.redhat.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": "en",
      "base": "https://developers.redhat.com/",
      "value": "Connect a .NET app to an external PostgreSQL database"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://developers.redhat.com/articles/2024/01/11/connect-dotnet-app-external-postgresql-database"
      }
    ],
    "link": "https://developers.redhat.com/articles/2024/01/11/connect-dotnet-app-external-postgresql-database",
    "summary": "<p>PostgreSQL databases tend to be robust and reliable. They also work well with <a href=\"https://developers.redhat.com/topics/dotnet/\">.NET</a> applications like Pedal, a sample bike e-commerce app.</p>\n\n<p>As the Pedal app shifts from monolithic to a <a href=\"https://developers.redhat.com/topics/microservices/\">microservices</a>-based application, connecting to an external database helps make managing data more efficient and reliable. The components are loosely coupled, making it more straightforward to organize, secure the data, and scale the database as needed.</p>\n\n<p>This tutorial guides you through setting up the microservice to talk to PostgreSQL, handle data correctly, and maintain optimal performance. You&rsquo;ll learn about networking, managing credentials securely, configuring data access, and ensuring that all components communicate smoothly.</p>\n\n<h2>Examining the .NET microservice</h2>\n\n<p>Pedal was originally a <a href=\"https://developers.redhat.com/java\">Java</a> application. However, one of its microservices, bike-service, is now a .NET microservice. Each Bike entry has the following main code for the Bike model:</p>\n\n<pre>\n<code class=\"language-bash\">using System;\n\nusing System.ComponentModel.DataAnnotations;\n\nusing System.ComponentModel.DataAnnotations.Schema;\n\n\nnamespace RedHatPedalBike.Models\n\n{\n\n    [Table(\"bikes\")]\n\n    public class Bike\n\n    {\n\n        [Key]\n\n        [DatabaseGenerated(DatabaseGeneratedOption.Identity)]\n\n        public long Id { get; set; }\n\n\n        [Required(ErrorMessage = \"Bike's name cannot be empty.\")]\n\n        public string Name { get; set; } = \"\";\n\n\n        [Required(ErrorMessage = \"Bike's model cannot be empty.\")]\n\n        public string Model { get; set; } = \"\";\n\n\n        [Column(\"date_created\")]\n\n        public DateTime DateCreated { get; set; }\n\n\n        [Required(ErrorMessage = \"Bike's price cannot be empty.\")]\n\n        public int Price { get; set; }\n\n\n        public byte[] Image { get; set; }\n\n\n        [Required(ErrorMessage = \"Bike's warranty status cannot be empty.\")]\n\n        [Column(\"warranty_status\")]\n\n        public string WarrantyStatus { get; set; } = \"\";\n\n    }\n\n}</code></pre>\n\n<p>This code represents a bike in Pedal&rsquo;s system, with properties like <code>Name</code>, <code>Model</code>, <code>Price</code>, and <code>WarrantyStatus</code>. It&rsquo;s a classic .NET entity model designed to work seamlessly with a database.</p>\n\n<p>This model forms the basis of the Web API in ASP.NET Core and the connected PostgreSQL web service. Clients can use its endpoints to access and manipulate database data, applying create, read, update, and delete (CRUD) operations</p>\n\n<p>We deployed the microservice to <a href=\"https://developers.redhat.com/products/openshift/overview\">Red Hat OpenShift</a> using the <a href=\"https://docs.openshift.com/container-platform/4.14/openshift_images/using_images/using-s21-images.html\">Source-to-Image (S2I) method</a>, reproducing a ready-to-run source code image. Figure 1 shows the running microservice.</p>\n\n<figure class=\"rhd-u-has-filter-caption\">\n<figure class=\"media media--type-image media--view-mode-article-content rhd-c-figure\"><a href=\"https://developers.redhat.com/sites/default/files/image1_28.png\"><img alt=\"The .NET microservice shown in the OpenShift console.\" height=\"290\" src=\"https://developers.redhat.com/sites/default/files/styles/article_floated/public/image1_28.png?itok=tasGPFPj\" width=\"600\" /></a>\n\n  </figure><figcaption class=\"rhd-c-caption\">Figure 1: The .NET microservice.</figcaption></figure><h2>Prerequisites</h2>\n\n<p>This tutorial requires the following:</p>\n\n<ul><li>A fundamental grasp of Microsoft .NET development</li>\n\t<li>Familiarity with PostgreSQL basics</li>\n\t<li>Free tier access to <a href=\"https://www.elephantsql.com/\">PostgreSQL as a service</a></li>\n\t<li>A <a href=\"https://developers.redhat.com/developer-sandbox\">Developer Sandbox for Red Hat OpenShift trial</a></li>\n\t<li>The <a href=\"https://docs.openshift.com/container-platform/4.7/cli_reference/openshift_cli/getting-started-cli.html\">OpenShift command-line interface (CLI)</a></li>\n\t<li><a href=\"https://visualstudio.microsoft.com/#vs-section\">Visual Studio</a> or <a href=\"https://visualstudio.microsoft.com/#vscode-section\">Visual Studio Code</a> for development. These instructions use Visual Studio.</li>\n\t<li><a href=\"https://dotnet.microsoft.com/en-us/download/dotnet/7.0\">.NET 7 SDK</a></li>\n\t<li>A <a href=\"https://github.com/signup\">GitHub account</a></li>\n</ul><h2>Understanding the external PostgreSQL environment</h2>\n\n<p>When connecting your .NET microservice to an external database, it&rsquo;s important to understand the database setup. This tutorial uses PostgreSQL as a service to avoid the hassle of installing and maintaining a database, including applying backups and updates. This approach lets you focus less on the infrastructure and more on coding</p>\n\n<p>Key considerations when connecting .NET apps to a PostgreSQL as a service include:</p>\n\n<ul><li>Ensuring a secure connection through Secure Sockets Layer and Transport Layer Security (SSL/TLS)</li>\n\t<li>Configuring firewalls and networks for accessibility</li>\n\t<li>Considering the database server&rsquo;s location for data transfer speed</li>\n\t<li>Correctly setting up the connection string in the .NET app&nbsp;</li>\n</ul><p>The optimal setup facilitates a smooth, secure, and scalable database connection for .NET microservices.</p>\n\n<h2>Configuring network access in .NET on Red Hat OpenShift</h2>\n\n<p>Connecting your OpenShift-deployed .NET application to an external PostgreSQL database requires a few vital steps.</p>\n\n<p>A .NET application runs in a containerized environment in OpenShift, adding a layer of networking considerations. OpenShift&rsquo;s platform helps you manage these <a href=\"https://developers.redhat.com/topics/containers\">containers</a> and their network interactions.</p>\n\n<p>You can employ the Npgsql<strong> </strong>library to set up network access for your application to communicate with the PostgreSQL database. Use the NuGet package manager to integrate the Npgsql library into your .NET project.</p>\n\n<p>Next, craft the connection string. It provides all the details to connect your .NET application to the PostgreSQL server, like the example below:</p>\n\n<pre>\n<code class=\"language-bash\">string connectionString = \"Host=my_host;Username=my_user;Password=my_pw;Database=my_db\";</code></pre>\n\n<p>Replace <code>my_host</code>, <code>my_user</code>, <code>my_pw</code>, and <code>my_db</code> with the actual details of your PostgreSQL server.</p>\n\n<p>Running an application in a containerized environment requires using secure connections (like SSL/TLS) and managing resources efficiently. OpenShift&rsquo;s built-in tools route and service configuration help establish secure network communication.</p>\n\n<h2>Establishing secure credential management in .NET</h2>\n\n<p>To ensure your application&rsquo;s security, avoid hardcoding database credentials in the source code. Instead, use environment variables or configuration files not stored in version control.</p>\n\n<p>You can use the <a href=\"https://learn.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-7.0\">Secret Manager</a> tool to create secrets on your local machine. Execute the following command on your local terminal:</p>\n\n<pre>\n<code class=\"language-bash\">dotnet user-secrets set postgres-username replace-with-your-postgres-username\ndotnet user-secrets set postgres-password replace-with-your-postgres-password</code></pre>\n\n<p>You can use the <code>ConfigurationManager</code> class in .NET or the IConfiguration interface in .NET Core to access these values, like in the following code:</p>\n\n<pre>\n<code class=\"language-bash\">var configuration = builder.Configuration;\n\nvar username = configuration[\"postgres-username\"];\n\nvar password = configuration[\"postgres-password\"];\n\n\n// Replace placeholders in the connection string with actual environment variables\n\nvar connectionString = builder.Configuration.GetConnectionString(\"DefaultConnection\")\n\n    .Replace(\"{USERNAME}\", username)\n\n    .Replace(\"{PASSWORD}\", password);</code></pre>\n\n<p>The current approach stores sensitive information in a local machine folder, but you can use OpenShift&rsquo;s <a href=\"https://docs.openshift.com/container-platform/3.11/dev_guide/secrets.html\">secret management</a> capability instead. Create a YAML file like the following:</p>\n\n<pre>\n<code class=\"language-bash\">apiVersion: \"v1\"\n\nkind: \"Secret\"\n\nmetadata:\n\n  name: \"mysecret\"\n\nstringData:\n\n  mysecretconfig: '{\"postgres-username\": \"wllyumrq\",\n\n  \"postgres-password\": \"your-postgres-password\"}'</code></pre>\n\n<p>Then, use an <code>oc</code> command similar to the one below to create the secret:</p>\n\n<pre>\n<code class=\"language-bash\">oc create -f mysecret.yaml</code></pre>\n\n<h2>Setting up .NET data access for PostgreSQL</h2>\n\n<p>Establishing a robust data access layer is fundamental when integrating a .NET application with an external PostgreSQL database. This method involves configuring connection strings and selecting appropriate data providers.</p>\n\n<p>A connection string contains information required to establish a connection to the database. In .NET, you typically define it in a configuration file (like <code>appsettings.json</code> in .NET Core).</p>\n\n<p>Below is an example of a PostgreSQL connection string:</p>\n\n<pre>\n<code class=\"language-bash\">\"ConnectionStrings\": { \"DefaultConnection\": \"Host=pom.db.elephantsql.com;Port=5432;Database=wllyumrq;Username={USERNAME};Password={PASSWORD};Trust Server Certificate=true;\" }</code></pre>\n\n<p>The Entity Framework (EF) Core object-relational mapping (ORM) tool enables .NET developers to use .NET objects to work with a database, eliminating most data-access code. Follow the steps below to set it up.</p>\n\n<h3>Create a model</h3>\n\n<p>Define your data models in C# classes, like the earlier Bike model.</p>\n\n<h3>Use DbContext</h3>\n\n<p>Create a context class inheriting from <code>DbContext</code>. Configure it to use Npgsql with PostgreSQL, like below:</p>\n\n<pre>\n<code class=\"language-bash\">public class BikedbContext : DbContext\n\n    {\n\n        public BikedbContext(DbContextOptions&lt;BikedbContext&gt; options)\n\n            : base(options)\n\n        {\n\n        }\n\n        public virtual DbSet&lt;Bike&gt; Bike { get; set; }\n\n    }</code></pre>\n\n<h3>Manage migrations</h3>\n\n<p>EF Core&rsquo;s migrations help manage database schema changes. Use the following commands to migrate and update your database:</p>\n\n<pre>\n<code class=\"language-bash\">Add-Migration InitCommit</code></pre>\n\n<pre>\n<code class=\"language-bash\">Update-Database</code></pre>\n\n<h2>Implementing the database connection</h2>\n\n<p>To implement a database connection in a .NET 7 application, you&rsquo;ll configure the connection string using EF Core or another ORM for data manipulation and add health checks to monitor the PostgreSQL database.</p>\n\n<p>The following Bike model shows a <code>DbContext</code> class in .NET 7:</p>\n\n<pre>\n<code class=\"language-bash\">using Microsoft.EntityFrameworkCore;\n\nusing RedHatPedalBike.Models;\n\n\npublic class BikedbContext: DbContext\n\n{\n\n    public DbSet&lt;Bike&gt; Bikes { get; set; }\n\n\n    public BikedbContext(DbContextOptions&lt;BikedbContext&gt; options)\n\n        : base(options)\n\n    {\n\n    }\n\n\n    protected override void OnModelCreating(ModelBuilder modelBuilder)\n\n    {\n\n        modelBuilder.Entity&lt;Bike&gt;().ToTable(\"bikes\");\n\n    }\n\n}</code></pre>\n\n<p>To integrate the ORM with your .NET microservice, register the DbContext in .NET Core&rsquo;s dependency injection container. Typically, you do this in the <code>Program.cs</code> file using code like the following:</p>\n\n<pre>\n<code class=\"language-bash\">var builder = WebApplication.CreateBuilder(args);\n\n\n// Add services to the container.\n\nbuilder.Services.AddDbContext&lt;PedalBikeContext&gt;(options =&gt;\n\n    options.UseNpgsql(builder.Configuration.GetConnectionString(\"PedalBikeConnection\")));\n\n\nvar app = builder.Build();\n\n\n// The rest of the code, including the snippets already presented in this article\n\n\napp.Run();</code></pre>\n\n<p>.NET 7 enables adding health checks to monitor the availability and performance of PostgreSQL databases. Add the following code to Program.cs for the health check service:</p>\n\n<pre>\n<code class=\"language-bash\">// Add services to the container.\n\nbuilder.Services.AddHealthChecks()\n\n    .AddNpgSql(connectionString);\n\n\napp.UseEndpoints(endpoints =&gt;\n\n{\n\n    // Map health checks endpoint\n\n    endpoints.MapHealthChecks(\"/health\");\n\n});</code></pre>\n\n<p>This code creates a <code>/health</code> endpoint. When you access the endpoint, it runs health checks and returns the health statuses of the application and database connection.</p>\n\n<h2>Ensuring secure communication</h2>\n\n<p>You can secure PostgreSQL data transmission in .NET 7 by encrypting database connection strings and using SSL/TLS. For example, add the following code to the Program.cs file to set up the data protection services:</p>\n\n<pre>\n<code class=\"language-bash\">   var builder = WebApplication.CreateBuilder(args);\n\n   builder.Services.AddDataProtection();\n\n   // Other services configuration...</code></pre>\n\n<p>Use the following code to encrypt your stored connection string and decrypt it for use:</p>\n\n<pre>\n<code class=\"language-bash\">   var protector = serviceProvider.GetDataProtector(\"ConnectionStrings:Protect\");\n\n   var encryptedConnectionString = protector.Protect(\"your-connection-string\");\n\n   var decryptedConnectionString = protector.Unprotect(encryptedConnectionString);</code></pre>\n\n<p>You can store&nbsp;<code>encryptedConnectionString</code> in your configuration and use <code>decryptedConnectionString</code> to connect to the database.</p>\n\n<p>SSL/TLS is vital to securely transfer data between a .NET application and a PostgreSQL database, necessitating SSL configuration on both sides. To enable SSL connections in PostgreSQL, on the server side, set the <strong>ssl </strong>option to <strong>on </strong>and provide a valid SSL certificate.</p>\n\n<p>To enable SSL in the .NET connection string, modify the string to require SSL as follows:</p>\n\n<pre>\n<code class=\"language-bash\">\"ConnectionStrings\": {\n\n       \"PostgreSqlConnection\": \"Host=myhostname;Port=5432;Database=mydbname;Username=myusername;Password=mypassword;SSL Mode=Require;Trust Server Certificate=true\"</code></pre>\n\n<p>Then, validate the server&rsquo;s SSL certificate during the SSL handshake to ensure secure .NET-to-PostgreSQL connections.</p>\n\n<h2>Verifying the connectivity</h2>\n\n<p>Next, ensure functionality by verifying the .NET 7 application&rsquo;s connection to the PostgreSQL database. Use the configured connection string to conduct a basic test:</p>\n\n<pre>\n<code class=\"language-bash\">using var context = new PedalBikeContext();\n\ntry\n\n{\n\n    context.Database.OpenConnection();\n\n    Console.WriteLine(\"Connection successful.\");\n\n}\n\ncatch (Exception ex)\n\n{\n\n    Console.WriteLine($\"Connection failed: {ex.Message}\");\n\n}\n\nfinally\n\n{\n\n    context.Database.CloseConnection();\n\n}</code></pre>\n\n<p>After establishing basic connectivity, run a simple query like the following:</p>\n\n<pre>\n<code class=\"language-bash\">using var context = new PedalBikeContext();\n\ntry\n\n{\n\n    var bikeCount = context.Bikes.Count();\n\n    Console.WriteLine($\"Number of bikes in the database: {bikeCount}\");\n\n}\n\ncatch (Exception ex)\n\n{\n\n    Console.WriteLine($\"Query failed: {ex.Message}\");\n\n}</code></pre>\n\n<p>The code snippet uses <code>PedalBikeContext</code> to establish a database connection, counts the number of bike entries in the Bikes table, and prints the count (or an error message if the query fails).</p>\n\n<h2>Deploying and building the application on OpenShift</h2>\n\n<p>When you deploy the .NET Pedal microservice to Red Hat OpenShift, use the S2I framework to streamline the build process. This handy build tool automatically converts the application&rsquo;s source code into a deployable container image using the .NET 7 runtime. OpenShift uses the configuration in the source repository and the .NET 7 S2I builder image to efficiently handle the build and deployment, fetching the code and packaging it into a container image.</p>\n\n<p>You can use a <a href=\"https://docs.openshift.com/container-platform/4.14/applications/creating_applications/creating-applications-using-cli.html\">command to build the application</a>&nbsp;as follows.</p>\n\n<pre>\n<code class=\"language-bash\">oc new-app dotnet:7.0~https://github.com/your_project -e DOTNET_STARTUP_PROJECT=your_project.csproj -e DOTNET_ASSEMBLY_NAME=your_project.csproj</code></pre>\n\n<h2>Conclusion</h2>\n\n<p>You&rsquo;ve now walked through the essential steps to connect a .NET 7 application to an external PostgreSQL database. You learned how to configure network access in OpenShift, emphasizing secure connections and correct network policies, and then established secure credential management.</p>\n\n<p>Next, you configured .NET data access for PostgreSQL using Entity Framework, implemented the database connection by integrating an ORM tool with the .NET microservice, and set up health checks. You now know how to secure communication using encrypted connection strings and SSL/TLS and verify the connectivity, ensuring the application can communicate effectively with the database.</p>\n\n<p>Security and efficient data access play a critical role in this microservices architecture, enhancing .NET application performance and reliability in a modern cloud-native environment.</p>\n\n<p>You&rsquo;re now prepared to adapt and extend these practices within your .NET applications. This ensures more robust, secure, and scalable solutions, aligning with the evolving demands of enterprise-level application development. Next, consider exploring other resources for <a href=\"https://developers.redhat.com/products/dotnet/overview\">working with .NET and Red Hat</a>.</p>\n\nThe post <a href=\"https://developers.redhat.com/articles/2024/01/11/connect-dotnet-app-external-postgresql-database\" title=\"Connect a .NET app to an external PostgreSQL database\">Connect a .NET app to an external PostgreSQL database</a> appeared first on <a href=\"https://developers.redhat.com/blog\" title=\"Red Hat Developer\">Red Hat Developer</a>.\n<br /><br />",
    "summary_detail": {
      "type": "text/html",
      "language": "en",
      "base": "https://developers.redhat.com/",
      "value": "<p>PostgreSQL databases tend to be robust and reliable. They also work well with <a href=\"https://developers.redhat.com/topics/dotnet/\">.NET</a> applications like Pedal, a sample bike e-commerce app.</p>\n\n<p>As the Pedal app shifts from monolithic to a <a href=\"https://developers.redhat.com/topics/microservices/\">microservices</a>-based application, connecting to an external database helps make managing data more efficient and reliable. The components are loosely coupled, making it more straightforward to organize, secure the data, and scale the database as needed.</p>\n\n<p>This tutorial guides you through setting up the microservice to talk to PostgreSQL, handle data correctly, and maintain optimal performance. You&rsquo;ll learn about networking, managing credentials securely, configuring data access, and ensuring that all components communicate smoothly.</p>\n\n<h2>Examining the .NET microservice</h2>\n\n<p>Pedal was originally a <a href=\"https://developers.redhat.com/java\">Java</a> application. However, one of its microservices, bike-service, is now a .NET microservice. Each Bike entry has the following main code for the Bike model:</p>\n\n<pre>\n<code class=\"language-bash\">using System;\n\nusing System.ComponentModel.DataAnnotations;\n\nusing System.ComponentModel.DataAnnotations.Schema;\n\n\nnamespace RedHatPedalBike.Models\n\n{\n\n    [Table(\"bikes\")]\n\n    public class Bike\n\n    {\n\n        [Key]\n\n        [DatabaseGenerated(DatabaseGeneratedOption.Identity)]\n\n        public long Id { get; set; }\n\n\n        [Required(ErrorMessage = \"Bike's name cannot be empty.\")]\n\n        public string Name { get; set; } = \"\";\n\n\n        [Required(ErrorMessage = \"Bike's model cannot be empty.\")]\n\n        public string Model { get; set; } = \"\";\n\n\n        [Column(\"date_created\")]\n\n        public DateTime DateCreated { get; set; }\n\n\n        [Required(ErrorMessage = \"Bike's price cannot be empty.\")]\n\n        public int Price { get; set; }\n\n\n        public byte[] Image { get; set; }\n\n\n        [Required(ErrorMessage = \"Bike's warranty status cannot be empty.\")]\n\n        [Column(\"warranty_status\")]\n\n        public string WarrantyStatus { get; set; } = \"\";\n\n    }\n\n}</code></pre>\n\n<p>This code represents a bike in Pedal&rsquo;s system, with properties like <code>Name</code>, <code>Model</code>, <code>Price</code>, and <code>WarrantyStatus</code>. It&rsquo;s a classic .NET entity model designed to work seamlessly with a database.</p>\n\n<p>This model forms the basis of the Web API in ASP.NET Core and the connected PostgreSQL web service. Clients can use its endpoints to access and manipulate database data, applying create, read, update, and delete (CRUD) operations</p>\n\n<p>We deployed the microservice to <a href=\"https://developers.redhat.com/products/openshift/overview\">Red Hat OpenShift</a> using the <a href=\"https://docs.openshift.com/container-platform/4.14/openshift_images/using_images/using-s21-images.html\">Source-to-Image (S2I) method</a>, reproducing a ready-to-run source code image. Figure 1 shows the running microservice.</p>\n\n<figure class=\"rhd-u-has-filter-caption\">\n<figure class=\"media media--type-image media--view-mode-article-content rhd-c-figure\"><a href=\"https://developers.redhat.com/sites/default/files/image1_28.png\"><img alt=\"The .NET microservice shown in the OpenShift console.\" height=\"290\" src=\"https://developers.redhat.com/sites/default/files/styles/article_floated/public/image1_28.png?itok=tasGPFPj\" width=\"600\" /></a>\n\n  </figure><figcaption class=\"rhd-c-caption\">Figure 1: The .NET microservice.</figcaption></figure><h2>Prerequisites</h2>\n\n<p>This tutorial requires the following:</p>\n\n<ul><li>A fundamental grasp of Microsoft .NET development</li>\n\t<li>Familiarity with PostgreSQL basics</li>\n\t<li>Free tier access to <a href=\"https://www.elephantsql.com/\">PostgreSQL as a service</a></li>\n\t<li>A <a href=\"https://developers.redhat.com/developer-sandbox\">Developer Sandbox for Red Hat OpenShift trial</a></li>\n\t<li>The <a href=\"https://docs.openshift.com/container-platform/4.7/cli_reference/openshift_cli/getting-started-cli.html\">OpenShift command-line interface (CLI)</a></li>\n\t<li><a href=\"https://visualstudio.microsoft.com/#vs-section\">Visual Studio</a> or <a href=\"https://visualstudio.microsoft.com/#vscode-section\">Visual Studio Code</a> for development. These instructions use Visual Studio.</li>\n\t<li><a href=\"https://dotnet.microsoft.com/en-us/download/dotnet/7.0\">.NET 7 SDK</a></li>\n\t<li>A <a href=\"https://github.com/signup\">GitHub account</a></li>\n</ul><h2>Understanding the external PostgreSQL environment</h2>\n\n<p>When connecting your .NET microservice to an external database, it&rsquo;s important to understand the database setup. This tutorial uses PostgreSQL as a service to avoid the hassle of installing and maintaining a database, including applying backups and updates. This approach lets you focus less on the infrastructure and more on coding</p>\n\n<p>Key considerations when connecting .NET apps to a PostgreSQL as a service include:</p>\n\n<ul><li>Ensuring a secure connection through Secure Sockets Layer and Transport Layer Security (SSL/TLS)</li>\n\t<li>Configuring firewalls and networks for accessibility</li>\n\t<li>Considering the database server&rsquo;s location for data transfer speed</li>\n\t<li>Correctly setting up the connection string in the .NET app&nbsp;</li>\n</ul><p>The optimal setup facilitates a smooth, secure, and scalable database connection for .NET microservices.</p>\n\n<h2>Configuring network access in .NET on Red Hat OpenShift</h2>\n\n<p>Connecting your OpenShift-deployed .NET application to an external PostgreSQL database requires a few vital steps.</p>\n\n<p>A .NET application runs in a containerized environment in OpenShift, adding a layer of networking considerations. OpenShift&rsquo;s platform helps you manage these <a href=\"https://developers.redhat.com/topics/containers\">containers</a> and their network interactions.</p>\n\n<p>You can employ the Npgsql<strong> </strong>library to set up network access for your application to communicate with the PostgreSQL database. Use the NuGet package manager to integrate the Npgsql library into your .NET project.</p>\n\n<p>Next, craft the connection string. It provides all the details to connect your .NET application to the PostgreSQL server, like the example below:</p>\n\n<pre>\n<code class=\"language-bash\">string connectionString = \"Host=my_host;Username=my_user;Password=my_pw;Database=my_db\";</code></pre>\n\n<p>Replace <code>my_host</code>, <code>my_user</code>, <code>my_pw</code>, and <code>my_db</code> with the actual details of your PostgreSQL server.</p>\n\n<p>Running an application in a containerized environment requires using secure connections (like SSL/TLS) and managing resources efficiently. OpenShift&rsquo;s built-in tools route and service configuration help establish secure network communication.</p>\n\n<h2>Establishing secure credential management in .NET</h2>\n\n<p>To ensure your application&rsquo;s security, avoid hardcoding database credentials in the source code. Instead, use environment variables or configuration files not stored in version control.</p>\n\n<p>You can use the <a href=\"https://learn.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-7.0\">Secret Manager</a> tool to create secrets on your local machine. Execute the following command on your local terminal:</p>\n\n<pre>\n<code class=\"language-bash\">dotnet user-secrets set postgres-username replace-with-your-postgres-username\ndotnet user-secrets set postgres-password replace-with-your-postgres-password</code></pre>\n\n<p>You can use the <code>ConfigurationManager</code> class in .NET or the IConfiguration interface in .NET Core to access these values, like in the following code:</p>\n\n<pre>\n<code class=\"language-bash\">var configuration = builder.Configuration;\n\nvar username = configuration[\"postgres-username\"];\n\nvar password = configuration[\"postgres-password\"];\n\n\n// Replace placeholders in the connection string with actual environment variables\n\nvar connectionString = builder.Configuration.GetConnectionString(\"DefaultConnection\")\n\n    .Replace(\"{USERNAME}\", username)\n\n    .Replace(\"{PASSWORD}\", password);</code></pre>\n\n<p>The current approach stores sensitive information in a local machine folder, but you can use OpenShift&rsquo;s <a href=\"https://docs.openshift.com/container-platform/3.11/dev_guide/secrets.html\">secret management</a> capability instead. Create a YAML file like the following:</p>\n\n<pre>\n<code class=\"language-bash\">apiVersion: \"v1\"\n\nkind: \"Secret\"\n\nmetadata:\n\n  name: \"mysecret\"\n\nstringData:\n\n  mysecretconfig: '{\"postgres-username\": \"wllyumrq\",\n\n  \"postgres-password\": \"your-postgres-password\"}'</code></pre>\n\n<p>Then, use an <code>oc</code> command similar to the one below to create the secret:</p>\n\n<pre>\n<code class=\"language-bash\">oc create -f mysecret.yaml</code></pre>\n\n<h2>Setting up .NET data access for PostgreSQL</h2>\n\n<p>Establishing a robust data access layer is fundamental when integrating a .NET application with an external PostgreSQL database. This method involves configuring connection strings and selecting appropriate data providers.</p>\n\n<p>A connection string contains information required to establish a connection to the database. In .NET, you typically define it in a configuration file (like <code>appsettings.json</code> in .NET Core).</p>\n\n<p>Below is an example of a PostgreSQL connection string:</p>\n\n<pre>\n<code class=\"language-bash\">\"ConnectionStrings\": { \"DefaultConnection\": \"Host=pom.db.elephantsql.com;Port=5432;Database=wllyumrq;Username={USERNAME};Password={PASSWORD};Trust Server Certificate=true;\" }</code></pre>\n\n<p>The Entity Framework (EF) Core object-relational mapping (ORM) tool enables .NET developers to use .NET objects to work with a database, eliminating most data-access code. Follow the steps below to set it up.</p>\n\n<h3>Create a model</h3>\n\n<p>Define your data models in C# classes, like the earlier Bike model.</p>\n\n<h3>Use DbContext</h3>\n\n<p>Create a context class inheriting from <code>DbContext</code>. Configure it to use Npgsql with PostgreSQL, like below:</p>\n\n<pre>\n<code class=\"language-bash\">public class BikedbContext : DbContext\n\n    {\n\n        public BikedbContext(DbContextOptions&lt;BikedbContext&gt; options)\n\n            : base(options)\n\n        {\n\n        }\n\n        public virtual DbSet&lt;Bike&gt; Bike { get; set; }\n\n    }</code></pre>\n\n<h3>Manage migrations</h3>\n\n<p>EF Core&rsquo;s migrations help manage database schema changes. Use the following commands to migrate and update your database:</p>\n\n<pre>\n<code class=\"language-bash\">Add-Migration InitCommit</code></pre>\n\n<pre>\n<code class=\"language-bash\">Update-Database</code></pre>\n\n<h2>Implementing the database connection</h2>\n\n<p>To implement a database connection in a .NET 7 application, you&rsquo;ll configure the connection string using EF Core or another ORM for data manipulation and add health checks to monitor the PostgreSQL database.</p>\n\n<p>The following Bike model shows a <code>DbContext</code> class in .NET 7:</p>\n\n<pre>\n<code class=\"language-bash\">using Microsoft.EntityFrameworkCore;\n\nusing RedHatPedalBike.Models;\n\n\npublic class BikedbContext: DbContext\n\n{\n\n    public DbSet&lt;Bike&gt; Bikes { get; set; }\n\n\n    public BikedbContext(DbContextOptions&lt;BikedbContext&gt; options)\n\n        : base(options)\n\n    {\n\n    }\n\n\n    protected override void OnModelCreating(ModelBuilder modelBuilder)\n\n    {\n\n        modelBuilder.Entity&lt;Bike&gt;().ToTable(\"bikes\");\n\n    }\n\n}</code></pre>\n\n<p>To integrate the ORM with your .NET microservice, register the DbContext in .NET Core&rsquo;s dependency injection container. Typically, you do this in the <code>Program.cs</code> file using code like the following:</p>\n\n<pre>\n<code class=\"language-bash\">var builder = WebApplication.CreateBuilder(args);\n\n\n// Add services to the container.\n\nbuilder.Services.AddDbContext&lt;PedalBikeContext&gt;(options =&gt;\n\n    options.UseNpgsql(builder.Configuration.GetConnectionString(\"PedalBikeConnection\")));\n\n\nvar app = builder.Build();\n\n\n// The rest of the code, including the snippets already presented in this article\n\n\napp.Run();</code></pre>\n\n<p>.NET 7 enables adding health checks to monitor the availability and performance of PostgreSQL databases. Add the following code to Program.cs for the health check service:</p>\n\n<pre>\n<code class=\"language-bash\">// Add services to the container.\n\nbuilder.Services.AddHealthChecks()\n\n    .AddNpgSql(connectionString);\n\n\napp.UseEndpoints(endpoints =&gt;\n\n{\n\n    // Map health checks endpoint\n\n    endpoints.MapHealthChecks(\"/health\");\n\n});</code></pre>\n\n<p>This code creates a <code>/health</code> endpoint. When you access the endpoint, it runs health checks and returns the health statuses of the application and database connection.</p>\n\n<h2>Ensuring secure communication</h2>\n\n<p>You can secure PostgreSQL data transmission in .NET 7 by encrypting database connection strings and using SSL/TLS. For example, add the following code to the Program.cs file to set up the data protection services:</p>\n\n<pre>\n<code class=\"language-bash\">   var builder = WebApplication.CreateBuilder(args);\n\n   builder.Services.AddDataProtection();\n\n   // Other services configuration...</code></pre>\n\n<p>Use the following code to encrypt your stored connection string and decrypt it for use:</p>\n\n<pre>\n<code class=\"language-bash\">   var protector = serviceProvider.GetDataProtector(\"ConnectionStrings:Protect\");\n\n   var encryptedConnectionString = protector.Protect(\"your-connection-string\");\n\n   var decryptedConnectionString = protector.Unprotect(encryptedConnectionString);</code></pre>\n\n<p>You can store&nbsp;<code>encryptedConnectionString</code> in your configuration and use <code>decryptedConnectionString</code> to connect to the database.</p>\n\n<p>SSL/TLS is vital to securely transfer data between a .NET application and a PostgreSQL database, necessitating SSL configuration on both sides. To enable SSL connections in PostgreSQL, on the server side, set the <strong>ssl </strong>option to <strong>on </strong>and provide a valid SSL certificate.</p>\n\n<p>To enable SSL in the .NET connection string, modify the string to require SSL as follows:</p>\n\n<pre>\n<code class=\"language-bash\">\"ConnectionStrings\": {\n\n       \"PostgreSqlConnection\": \"Host=myhostname;Port=5432;Database=mydbname;Username=myusername;Password=mypassword;SSL Mode=Require;Trust Server Certificate=true\"</code></pre>\n\n<p>Then, validate the server&rsquo;s SSL certificate during the SSL handshake to ensure secure .NET-to-PostgreSQL connections.</p>\n\n<h2>Verifying the connectivity</h2>\n\n<p>Next, ensure functionality by verifying the .NET 7 application&rsquo;s connection to the PostgreSQL database. Use the configured connection string to conduct a basic test:</p>\n\n<pre>\n<code class=\"language-bash\">using var context = new PedalBikeContext();\n\ntry\n\n{\n\n    context.Database.OpenConnection();\n\n    Console.WriteLine(\"Connection successful.\");\n\n}\n\ncatch (Exception ex)\n\n{\n\n    Console.WriteLine($\"Connection failed: {ex.Message}\");\n\n}\n\nfinally\n\n{\n\n    context.Database.CloseConnection();\n\n}</code></pre>\n\n<p>After establishing basic connectivity, run a simple query like the following:</p>\n\n<pre>\n<code class=\"language-bash\">using var context = new PedalBikeContext();\n\ntry\n\n{\n\n    var bikeCount = context.Bikes.Count();\n\n    Console.WriteLine($\"Number of bikes in the database: {bikeCount}\");\n\n}\n\ncatch (Exception ex)\n\n{\n\n    Console.WriteLine($\"Query failed: {ex.Message}\");\n\n}</code></pre>\n\n<p>The code snippet uses <code>PedalBikeContext</code> to establish a database connection, counts the number of bike entries in the Bikes table, and prints the count (or an error message if the query fails).</p>\n\n<h2>Deploying and building the application on OpenShift</h2>\n\n<p>When you deploy the .NET Pedal microservice to Red Hat OpenShift, use the S2I framework to streamline the build process. This handy build tool automatically converts the application&rsquo;s source code into a deployable container image using the .NET 7 runtime. OpenShift uses the configuration in the source repository and the .NET 7 S2I builder image to efficiently handle the build and deployment, fetching the code and packaging it into a container image.</p>\n\n<p>You can use a <a href=\"https://docs.openshift.com/container-platform/4.14/applications/creating_applications/creating-applications-using-cli.html\">command to build the application</a>&nbsp;as follows.</p>\n\n<pre>\n<code class=\"language-bash\">oc new-app dotnet:7.0~https://github.com/your_project -e DOTNET_STARTUP_PROJECT=your_project.csproj -e DOTNET_ASSEMBLY_NAME=your_project.csproj</code></pre>\n\n<h2>Conclusion</h2>\n\n<p>You&rsquo;ve now walked through the essential steps to connect a .NET 7 application to an external PostgreSQL database. You learned how to configure network access in OpenShift, emphasizing secure connections and correct network policies, and then established secure credential management.</p>\n\n<p>Next, you configured .NET data access for PostgreSQL using Entity Framework, implemented the database connection by integrating an ORM tool with the .NET microservice, and set up health checks. You now know how to secure communication using encrypted connection strings and SSL/TLS and verify the connectivity, ensuring the application can communicate effectively with the database.</p>\n\n<p>Security and efficient data access play a critical role in this microservices architecture, enhancing .NET application performance and reliability in a modern cloud-native environment.</p>\n\n<p>You&rsquo;re now prepared to adapt and extend these practices within your .NET applications. This ensures more robust, secure, and scalable solutions, aligning with the evolving demands of enterprise-level application development. Next, consider exploring other resources for <a href=\"https://developers.redhat.com/products/dotnet/overview\">working with .NET and Red Hat</a>.</p>\n\nThe post <a href=\"https://developers.redhat.com/articles/2024/01/11/connect-dotnet-app-external-postgresql-database\" title=\"Connect a .NET app to an external PostgreSQL database\">Connect a .NET app to an external PostgreSQL database</a> appeared first on <a href=\"https://developers.redhat.com/blog\" title=\"Red Hat Developer\">Red Hat Developer</a>.\n<br /><br />"
    },
    "time": {
      "datetime": "2024-01-11T07:00:00+00:00"
    },
    "published": "Thu, 11 Jan 2024 07:00:00 +0000",
    "published_parsed": [
      2024,
      1,
      11,
      7,
      0,
      0,
      3,
      11,
      0
    ],
    "authors": [
      {
        "name": "Nikhil Mungale"
      }
    ],
    "author": "Nikhil Mungale",
    "author_detail": {
      "name": "Nikhil Mungale"
    },
    "id": "59b1f1a9-9a2e-4e40-8e44-282bc334442f",
    "guidislink": false
  },
  "MemSQL": {
    "title": "Role-Based Access Control (RBAC) for SingleStore Helios Cloud",
    "xmlUrl": "http://blog.memsql.com/feed/",
    "htmlUrl": "http://blog.memsql.com/content/engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.singlestore.com/blog/feed.xml",
      "value": "Role-Based Access Control (RBAC) for SingleStore Helios Cloud"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.singlestore.com/blog/rbac-for-singlestore-helios-cloud"
      },
      {
        "length": "0",
        "type": "image/png",
        "href": "https://images.contentstack.io/v3/assets/bltac01ee6daa3a1e14/blt78a821daf99ec701/65a02f701f2d0f2bd8ad0cd4/img_blog_BP-BW-MK-Role-Based-Access-Control-(RBAC)-for-SingleStore-Cloud_new-primary_(1).png",
        "rel": "enclosure"
      }
    ],
    "link": "https://www.singlestore.com/blog/rbac-for-singlestore-helios-cloud",
    "id": "https://www.singlestore.com/blog/rbac-for-singlestore-helios-cloud",
    "guidislink": false,
    "published": "Thu, 11 Jan 2024 18:53:14 GMT",
    "published_parsed": [
      2024,
      1,
      11,
      18,
      53,
      14,
      3,
      11,
      0
    ],
    "summary": "In this blog, we will delve into the intricacies of RBAC for SingleStore Helios Cloud, exploring its features, implementation and how it enhances the overall security posture of your database.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.singlestore.com/blog/feed.xml",
      "value": "In this blog, we will delve into the intricacies of RBAC for SingleStore Helios Cloud, exploring its features, implementation and how it enhances the overall security posture of your database."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.singlestore.com/blog/feed.xml",
        "value": "Now generally available. In the dynamic landscape of cloud-based data management, security is paramount. SingleStore recognizes the significance of safeguarding your data and infrastructure, offering a robust security solution through Role-Based Access Control (RBAC). In this blog, we will delve into the intricacies of RBAC for SingleStore Helio..."
      }
    ],
    "tags": [
      {
        "term": "Product",
        "scheme": null,
        "label": null
      }
    ]
  },
  "Trivago": {
    "title": "Accelerating experimentations through Simulations",
    "xmlUrl": "https://tech.trivago.com/index.xml",
    "htmlUrl": "http://tech.trivago.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.trivago.com/rss.xml",
      "value": "Accelerating experimentations through Simulations"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.trivago.com/post/2023-11-20-accelerating-experimentations-through-simulations/"
      }
    ],
    "link": "https://tech.trivago.com/post/2023-11-20-accelerating-experimentations-through-simulations/",
    "id": "https://tech.trivago.com/post/2023-11-20-accelerating-experimentations-through-simulations/",
    "guidislink": false,
    "published": "Mon, 20 Nov 2023 00:00:00 GMT",
    "published_parsed": [
      2023,
      11,
      20,
      0,
      0,
      0,
      0,
      324,
      0
    ]
  },
  "YLD!": {
    "title": "All You Need to Know from My 12-Hour ViteConf23 Marathon",
    "xmlUrl": "https://medium.com/feed/yld-engineering-blog",
    "htmlUrl": "https://blog.yld.io",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/yld-engineering-blog",
      "value": "All You Need to Know from My 12-Hour ViteConf23 Marathon"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/yld-blog/all-you-need-to-know-from-my-12-hour-viteconf23-marathon-ef51df230f5a?source=rss----39c536548b9a---4"
      }
    ],
    "link": "https://medium.com/yld-blog/all-you-need-to-know-from-my-12-hour-viteconf23-marathon-ef51df230f5a?source=rss----39c536548b9a---4",
    "id": "https://medium.com/p/ef51df230f5a",
    "guidislink": false,
    "tags": [
      {
        "term": "frontend",
        "scheme": null,
        "label": null
      },
      {
        "term": "front-end-development",
        "scheme": null,
        "label": null
      },
      {
        "term": "frontend-development",
        "scheme": null,
        "label": null
      },
      {
        "term": "continuous-improvement",
        "scheme": null,
        "label": null
      },
      {
        "term": "collaboration",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "YLD"
      }
    ],
    "author": "YLD",
    "author_detail": {
      "name": "YLD"
    },
    "published": "Fri, 27 Oct 2023 11:16:43 GMT",
    "published_parsed": [
      2023,
      10,
      27,
      11,
      16,
      43,
      4,
      300,
      0
    ],
    "updated": "2023-10-30T13:06:49.442Z",
    "updated_parsed": [
      2023,
      10,
      30,
      13,
      6,
      49,
      0,
      303,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/yld-engineering-blog",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gAXo5ja9KNUeXK8RWLJGJg.jpeg\" /><figcaption><em>Author: Afonso\u00a0Ramos</em></figcaption></figure><p>A well-known quote by Tolstoy is that \u201cthe two most powerful warriors are patience and time\u201d. And although I can say that I have the patience, I definitely do not have the time anymore. This is because I have spent a good amount of time watching all of the ViteConf talks, which lasted for 12 hours, although on a good chunk of them, I was able to watch at 2x speed because even I don\u2019t have that much patience.</p><h3>What is\u00a0\u201cVite\u201d?</h3><p>If you don\u2019t quite know what ViteConf is, you probably don\u2019t know what <em>Vite</em> is either. But that\u2019s okay because you came to the second-best place to learn about it (<a href=\"https://vitejs.dev/\">its documentation being the\u00a0first</a>).</p><p>Before introducing ES modules in web browsers, developers lacked a built-in method for structuring JavaScript code in a modular fashion. Consequently, the practice of \u201cbundling\u201d became commonplace, involving the utilization of tools that would crawl, process, and concatenate source modules into files suitable for browser execution.</p><p>Over time, we witnessed the emergence of tools like <em>webpack</em>, <em>Rollup</em>, and <em>Parcel</em>, which significantly enhanced the development experience for frontend developers. Nonetheless, as our applications grew in complexity, the volume of JavaScript code also surged dramatically. It\u2019s now typical for extensive projects to encompass thousands of modules. This led to a performance bottleneck for <em>JavaScript</em>-based tooling, resulting in prolonged wait times (sometimes extending to minutes) to start a development server. Even with Hot Module Replacement (HMR), changes to files could take several seconds to reflect in the browser. This sluggish feedback loop has a substantial impact on developers\u2019 productivity and overall satisfaction (usually referred to as\u00a0DX).</p><p><em>Vite</em> seeks to tackle these challenges by capitalizing on recent advancements in the ecosystem: the adoption of native ES modules within web browsers and the proliferation of <em>JavaScript</em> tools written in languages that compile to native code (more on that\u00a0later).</p><h3>A Quick Rundown of\u00a0ViteConf</h3><p>With Vite\u2019s rising popularity and far reach in the frontend world, in 2022 ViteConf was born, and this year we got its second iteration. Given the extensive array of talks and discussions, this blog post will take a concise, bullet-point approach as the most suitable format for capturing the essence of the event. So, without further ado, here are my key takeaways:</p><h4>Vite</h4><p>Vite is clearly setting itself to be THE build tool for any and all frameworks by keeping itself lean and keeping the Vite Core small, by leveraging its plugin system for anything that is not \u201ccore\u201d, while maintaining the health of said plugins using an amazing CI workflow that constantly tests these and prevents issues before releases: <a href=\"https://github.com/vitejs/vite-ecosystem-ci\">GitHub\u200a\u2014\u200avitejs/vite-ecosystem-ci</a>;</p><ol><li><strong><em>Vite</em> 5</strong>, which major bump was mainly caused by Rollup\u2019s major bump (<a href=\"https://github.com/rollup/rollup/releases/tag/v4.0.0\">rollup/rollup/releases/tag/v4.0.0 \u00b7 rollup/rollup \u00b7 GitHub</a>), is now in beta: <a href=\"https://github.com/vitejs/vite/blob/main/docs/guide/migration.md\">vite/docs/guide/migration.md at main \u00b7 vitejs/vite \u00b7\u00a0GitHub</a>;</li><li><strong><em>Vite</em> is helping with the push for ESM</strong>, as they are deprecating their CommonJS Node API, which means we\u2019re ever so close to no more node polyfills. However, even though native ESM is now widely supported, shipping unbundled ESM in production is still inefficient (even with HTTP/2, careful with the <a href=\"https://cloud.google.com/blog/products/identity-security/how-it-works-the-novel-http2-rapid-reset-ddos-attack\">Rapid Resets</a>) due to the additional network round trips caused by nested imports. Until this changes, bundling your code with tree-shaking, lazy-loading and common chunk splitting (for better caching) will continue to be the best\u00a0option;</li><li>A quick <strong><em>Vite</em>\u2019s HMR</strong> (Hot Module Reload) presentation reminded everyone to stop using barrel files (index.((js|ts)x?) files) as they affect HMR algorithms\u200a\u2014\u200aa few weeks later, the <em>Next.JS</em> site team took their advice and saw the improvements themselves: <a href=\"https://vercel.com/blog/how-we-optimized-package-imports-in-next-js\">How we optimized package imports in Next.js\u200a\u2014\u200aVercel</a>;</li></ol><h4>Remix</h4><p>Remix is considering moving to <em>Vite</em>, once again signalling its growing popularity: <a href=\"https://github.com/remix-run/remix/discussions/7632\">Just use vite! \u00b7 remix-run remix \u00b7 Discussion #7632 \u00b7\u00a0GitHub</a>;</p><h4>Rolldown</h4><p>Rolldown, a <em>Rust</em> port of <em>Rollup</em> (with a slightly larger scope) is being built by contributors of <em>rspack</em>, with a focus on performance with best-effort compatibility with <em>Rollup</em>, to replace <em>esbuild</em> and <em>Rollup</em> in <em>Vite</em>. Clearly, the focus lately has been to \u201crustify\u201d all the\u00a0tools;</p><h4>Rollup</h4><p>Rollup will still be in active development for the time being, however, so <em>Rolldown</em> will need to do some\u00a0catchup:</p><ol><li>They removed the acorn parser for example for a 40% perf improvement (for a Rust alternative).</li><li>They are also replacing more modules for <em>Rust</em> alternatives for extra perf improvements, which questions the whole <em>Rolldown</em> initiative;</li></ol><h4>Volar</h4><p><a href=\"https://github.com/volarjs/volar.js\">Volar</a>, a LSP / Editor Tooling tool with the same maintainability philosophy of Vite, is now the official VSCode plugin for <em>Vue</em> and\u00a0<em>Astro</em>;</p><h4>Storybook</h4><p>Storybook is getting things ready for its 8th release with great perf gains while dropping webpack for <em>Vite</em>\u00a0users;</p><ol><li>They are also starting work towards testing directly in <em>Storybook</em> with a deep integration with\u00a0<em>Vitest</em>;</li><li><a href=\"https://previewjs.com/\"><strong><em>Preview.js</em></strong></a> is a tool to help you preview any UI component or <em>Storybook</em> story directly in your\u00a0editor;</li><li>Storybook now also <strong>supports <em>Svelte</em> and <em>Solidjs</em></strong>, and will now offer a simplified experience called \u201cStorybook lite\u201d;</li></ol><h4>SolidJS</h4><p>Ryan Carniato (creator of SolidJS) gave a wonderful talk about what it means to be a \u201cmeta-framework\u201d, as well as how they are trying to destroy <em>SolidStart</em> as it is, and rebuilding it with platform agnostic tools such as <em>Vinxi</em>, <em>Nitro</em>, <em>Bling</em> and <em>Vite</em>, reducing the LoC from 10.000 to\u00a01.200;</p><h4>RedwoodJS</h4><p><a href=\"https://github.com/redwoodjs/redwood\">RedwoodJS</a> is becoming more and more interesting\u2026 If you want to build something solid, use the right tools and not worry about tool nitpicks, this is for you! They are also switching to Vite, obviously. However, upon opening Redwood\u2019s repo you will find over 400 open issues, which is expected since they are glueing together a lot of tools, whereas an alternative such as <a href=\"https://adonisjs.com/\"><em>Adonis</em></a>, might signal a more resilient and stable\u00a0product.</p><h4>How to write great documentation</h4><p><a href=\"https://www.youtube.com/watch?v=jcpkVJr-rUw\">A great talk by Sarah Rainberger</a> about <strong>how to write great documentation</strong>. She emphasizes the importance of thinking about the reader\u2019s needs and organizing documentation accordingly. She tries to create sections that can be logically grouped and directed accurately for specific reader needs. She also stresses the importance of clear and correct documentation for the success of a project, and encourages the focus to be on helping rather than \u201cfollowing specific writing rules.\u201d In her discussion about writing effective documentation for <em>Astro</em>\u2019s docs, Rainsberger emphasizes the importance of using simple and direct language, providing clear instructions, focusing on the reader\u2019s context, and using words like \u201cshould\u201d and \u201cmust\u201d carefully. She also highlights the importance of contextual help in making documentation easy for readers to discover and navigate.</p><h4>Astro</h4><p>Astro creator, Fred K Schott, talked about ViewTransitions and how cool they are, and from my point of view, they\u2019re here to shake things up on the MPA vs SPA\u00a0debate;</p><h4>React Router</h4><p>Kent C. Dodds talked about how React Router + Vite is a framework and how he prefers the stronger capabilities of a conf-based router vs a file-based one for customizability;</p><h4>Tauri</h4><p>Tauri v2 is about to enter its beta phase, which heralds an exciting opportunity for <em>iOS</em> and Android app development, in addition to all the benefits that v1 has already brought on. Additionally, the team behind it is actively crafting a suite of tools for tasks such as updates, distribution, and app signing\u200a\u2014\u200aalthough it\u2019s worth noting that these services will for sure be offered on a paid basis. Will it be able to compete with what Expo did with React-Native though? Only time will\u00a0tell\u2026;</p><h4>pnpm</h4><p>A new feature for <strong><em>pnpm</em></strong> is <strong>catalogs</strong>, which was created to help with pinning a version to a whole workspace and better ensure that everyone is using the same one with no\u00a0hassle;</p><h4>Analog</h4><p>Brandon Roberts demonstrated the integration of <em>Vite</em>, <em>Nx</em>, and <em>Nitro</em> in <strong><em>Analog</em>, the <em>Angular</em> meta framework</strong>, with features such as a versatile file-system router supporting various layouts, SSR and SSG capabilities, and file-based syntax for defining API\u00a0routes.</p><p>And that wraps it up! While I couldn\u2019t cover every aspect of ViteConf 2023, I trust that I was able to provide an insightful glimpse into the ever-evolving frontend development landscape.</p><p>With discussions spanning from <em>Vite</em>\u2019s future to the rise of ESM and the introduction of promising tools like <em>Rolldown</em> and <em>Volar</em>, the conference showcased the industry\u2019s dynamic nature. And from <em>Tauri</em>, <em>Rolldown</em> and all the way to <em>Rollup</em>, <em>Rust</em>\u2019s presence is being felt as being a cornerstone language to the frontend tool development ecosystem more and\u00a0more.</p><p>Overall, ViteConf did a wonderful job highlighting the continuous innovation and collaboration that drive this dynamic field forward, and I\u2019m very excited to see what the industry will present next\u00a0year.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ef51df230f5a\" width=\"1\" /><hr /><p><a href=\"https://medium.com/yld-blog/all-you-need-to-know-from-my-12-hour-viteconf23-marathon-ef51df230f5a\">All You Need to Know from My 12-Hour ViteConf23 Marathon</a> was originally published in <a href=\"https://medium.com/yld-blog\">YLD Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gAXo5ja9KNUeXK8RWLJGJg.jpeg\" /><figcaption><em>Author: Afonso\u00a0Ramos</em></figcaption></figure><p>A well-known quote by Tolstoy is that \u201cthe two most powerful warriors are patience and time\u201d. And although I can say that I have the patience, I definitely do not have the time anymore. This is because I have spent a good amount of time watching all of the ViteConf talks, which lasted for 12 hours, although on a good chunk of them, I was able to watch at 2x speed because even I don\u2019t have that much patience.</p><h3>What is\u00a0\u201cVite\u201d?</h3><p>If you don\u2019t quite know what ViteConf is, you probably don\u2019t know what <em>Vite</em> is either. But that\u2019s okay because you came to the second-best place to learn about it (<a href=\"https://vitejs.dev/\">its documentation being the\u00a0first</a>).</p><p>Before introducing ES modules in web browsers, developers lacked a built-in method for structuring JavaScript code in a modular fashion. Consequently, the practice of \u201cbundling\u201d became commonplace, involving the utilization of tools that would crawl, process, and concatenate source modules into files suitable for browser execution.</p><p>Over time, we witnessed the emergence of tools like <em>webpack</em>, <em>Rollup</em>, and <em>Parcel</em>, which significantly enhanced the development experience for frontend developers. Nonetheless, as our applications grew in complexity, the volume of JavaScript code also surged dramatically. It\u2019s now typical for extensive projects to encompass thousands of modules. This led to a performance bottleneck for <em>JavaScript</em>-based tooling, resulting in prolonged wait times (sometimes extending to minutes) to start a development server. Even with Hot Module Replacement (HMR), changes to files could take several seconds to reflect in the browser. This sluggish feedback loop has a substantial impact on developers\u2019 productivity and overall satisfaction (usually referred to as\u00a0DX).</p><p><em>Vite</em> seeks to tackle these challenges by capitalizing on recent advancements in the ecosystem: the adoption of native ES modules within web browsers and the proliferation of <em>JavaScript</em> tools written in languages that compile to native code (more on that\u00a0later).</p><h3>A Quick Rundown of\u00a0ViteConf</h3><p>With Vite\u2019s rising popularity and far reach in the frontend world, in 2022 ViteConf was born, and this year we got its second iteration. Given the extensive array of talks and discussions, this blog post will take a concise, bullet-point approach as the most suitable format for capturing the essence of the event. So, without further ado, here are my key takeaways:</p><h4>Vite</h4><p>Vite is clearly setting itself to be THE build tool for any and all frameworks by keeping itself lean and keeping the Vite Core small, by leveraging its plugin system for anything that is not \u201ccore\u201d, while maintaining the health of said plugins using an amazing CI workflow that constantly tests these and prevents issues before releases: <a href=\"https://github.com/vitejs/vite-ecosystem-ci\">GitHub\u200a\u2014\u200avitejs/vite-ecosystem-ci</a>;</p><ol><li><strong><em>Vite</em> 5</strong>, which major bump was mainly caused by Rollup\u2019s major bump (<a href=\"https://github.com/rollup/rollup/releases/tag/v4.0.0\">rollup/rollup/releases/tag/v4.0.0 \u00b7 rollup/rollup \u00b7 GitHub</a>), is now in beta: <a href=\"https://github.com/vitejs/vite/blob/main/docs/guide/migration.md\">vite/docs/guide/migration.md at main \u00b7 vitejs/vite \u00b7\u00a0GitHub</a>;</li><li><strong><em>Vite</em> is helping with the push for ESM</strong>, as they are deprecating their CommonJS Node API, which means we\u2019re ever so close to no more node polyfills. However, even though native ESM is now widely supported, shipping unbundled ESM in production is still inefficient (even with HTTP/2, careful with the <a href=\"https://cloud.google.com/blog/products/identity-security/how-it-works-the-novel-http2-rapid-reset-ddos-attack\">Rapid Resets</a>) due to the additional network round trips caused by nested imports. Until this changes, bundling your code with tree-shaking, lazy-loading and common chunk splitting (for better caching) will continue to be the best\u00a0option;</li><li>A quick <strong><em>Vite</em>\u2019s HMR</strong> (Hot Module Reload) presentation reminded everyone to stop using barrel files (index.((js|ts)x?) files) as they affect HMR algorithms\u200a\u2014\u200aa few weeks later, the <em>Next.JS</em> site team took their advice and saw the improvements themselves: <a href=\"https://vercel.com/blog/how-we-optimized-package-imports-in-next-js\">How we optimized package imports in Next.js\u200a\u2014\u200aVercel</a>;</li></ol><h4>Remix</h4><p>Remix is considering moving to <em>Vite</em>, once again signalling its growing popularity: <a href=\"https://github.com/remix-run/remix/discussions/7632\">Just use vite! \u00b7 remix-run remix \u00b7 Discussion #7632 \u00b7\u00a0GitHub</a>;</p><h4>Rolldown</h4><p>Rolldown, a <em>Rust</em> port of <em>Rollup</em> (with a slightly larger scope) is being built by contributors of <em>rspack</em>, with a focus on performance with best-effort compatibility with <em>Rollup</em>, to replace <em>esbuild</em> and <em>Rollup</em> in <em>Vite</em>. Clearly, the focus lately has been to \u201crustify\u201d all the\u00a0tools;</p><h4>Rollup</h4><p>Rollup will still be in active development for the time being, however, so <em>Rolldown</em> will need to do some\u00a0catchup:</p><ol><li>They removed the acorn parser for example for a 40% perf improvement (for a Rust alternative).</li><li>They are also replacing more modules for <em>Rust</em> alternatives for extra perf improvements, which questions the whole <em>Rolldown</em> initiative;</li></ol><h4>Volar</h4><p><a href=\"https://github.com/volarjs/volar.js\">Volar</a>, a LSP / Editor Tooling tool with the same maintainability philosophy of Vite, is now the official VSCode plugin for <em>Vue</em> and\u00a0<em>Astro</em>;</p><h4>Storybook</h4><p>Storybook is getting things ready for its 8th release with great perf gains while dropping webpack for <em>Vite</em>\u00a0users;</p><ol><li>They are also starting work towards testing directly in <em>Storybook</em> with a deep integration with\u00a0<em>Vitest</em>;</li><li><a href=\"https://previewjs.com/\"><strong><em>Preview.js</em></strong></a> is a tool to help you preview any UI component or <em>Storybook</em> story directly in your\u00a0editor;</li><li>Storybook now also <strong>supports <em>Svelte</em> and <em>Solidjs</em></strong>, and will now offer a simplified experience called \u201cStorybook lite\u201d;</li></ol><h4>SolidJS</h4><p>Ryan Carniato (creator of SolidJS) gave a wonderful talk about what it means to be a \u201cmeta-framework\u201d, as well as how they are trying to destroy <em>SolidStart</em> as it is, and rebuilding it with platform agnostic tools such as <em>Vinxi</em>, <em>Nitro</em>, <em>Bling</em> and <em>Vite</em>, reducing the LoC from 10.000 to\u00a01.200;</p><h4>RedwoodJS</h4><p><a href=\"https://github.com/redwoodjs/redwood\">RedwoodJS</a> is becoming more and more interesting\u2026 If you want to build something solid, use the right tools and not worry about tool nitpicks, this is for you! They are also switching to Vite, obviously. However, upon opening Redwood\u2019s repo you will find over 400 open issues, which is expected since they are glueing together a lot of tools, whereas an alternative such as <a href=\"https://adonisjs.com/\"><em>Adonis</em></a>, might signal a more resilient and stable\u00a0product.</p><h4>How to write great documentation</h4><p><a href=\"https://www.youtube.com/watch?v=jcpkVJr-rUw\">A great talk by Sarah Rainberger</a> about <strong>how to write great documentation</strong>. She emphasizes the importance of thinking about the reader\u2019s needs and organizing documentation accordingly. She tries to create sections that can be logically grouped and directed accurately for specific reader needs. She also stresses the importance of clear and correct documentation for the success of a project, and encourages the focus to be on helping rather than \u201cfollowing specific writing rules.\u201d In her discussion about writing effective documentation for <em>Astro</em>\u2019s docs, Rainsberger emphasizes the importance of using simple and direct language, providing clear instructions, focusing on the reader\u2019s context, and using words like \u201cshould\u201d and \u201cmust\u201d carefully. She also highlights the importance of contextual help in making documentation easy for readers to discover and navigate.</p><h4>Astro</h4><p>Astro creator, Fred K Schott, talked about ViewTransitions and how cool they are, and from my point of view, they\u2019re here to shake things up on the MPA vs SPA\u00a0debate;</p><h4>React Router</h4><p>Kent C. Dodds talked about how React Router + Vite is a framework and how he prefers the stronger capabilities of a conf-based router vs a file-based one for customizability;</p><h4>Tauri</h4><p>Tauri v2 is about to enter its beta phase, which heralds an exciting opportunity for <em>iOS</em> and Android app development, in addition to all the benefits that v1 has already brought on. Additionally, the team behind it is actively crafting a suite of tools for tasks such as updates, distribution, and app signing\u200a\u2014\u200aalthough it\u2019s worth noting that these services will for sure be offered on a paid basis. Will it be able to compete with what Expo did with React-Native though? Only time will\u00a0tell\u2026;</p><h4>pnpm</h4><p>A new feature for <strong><em>pnpm</em></strong> is <strong>catalogs</strong>, which was created to help with pinning a version to a whole workspace and better ensure that everyone is using the same one with no\u00a0hassle;</p><h4>Analog</h4><p>Brandon Roberts demonstrated the integration of <em>Vite</em>, <em>Nx</em>, and <em>Nitro</em> in <strong><em>Analog</em>, the <em>Angular</em> meta framework</strong>, with features such as a versatile file-system router supporting various layouts, SSR and SSG capabilities, and file-based syntax for defining API\u00a0routes.</p><p>And that wraps it up! While I couldn\u2019t cover every aspect of ViteConf 2023, I trust that I was able to provide an insightful glimpse into the ever-evolving frontend development landscape.</p><p>With discussions spanning from <em>Vite</em>\u2019s future to the rise of ESM and the introduction of promising tools like <em>Rolldown</em> and <em>Volar</em>, the conference showcased the industry\u2019s dynamic nature. And from <em>Tauri</em>, <em>Rolldown</em> and all the way to <em>Rollup</em>, <em>Rust</em>\u2019s presence is being felt as being a cornerstone language to the frontend tool development ecosystem more and\u00a0more.</p><p>Overall, ViteConf did a wonderful job highlighting the continuous innovation and collaboration that drive this dynamic field forward, and I\u2019m very excited to see what the industry will present next\u00a0year.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ef51df230f5a\" width=\"1\" /><hr /><p><a href=\"https://medium.com/yld-blog/all-you-need-to-know-from-my-12-hour-viteconf23-marathon-ef51df230f5a\">All You Need to Know from My 12-Hour ViteConf23 Marathon</a> was originally published in <a href=\"https://medium.com/yld-blog\">YLD Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Brandwatch": {
    "title": "Boolean Cheat Sheet: Unlock the Full Power of Social Media Monitoring",
    "xmlUrl": "https://engineering.brandwatch.com/rss/",
    "htmlUrl": "http://engineering.brandwatch.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.brandwatch.com/feed/",
      "value": "Boolean Cheat Sheet: Unlock the Full Power of Social Media Monitoring"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://s14415.pcdn.co/blog/the-social-media-monitoring-cheat-sheet/"
      }
    ],
    "link": "https://s14415.pcdn.co/blog/the-social-media-monitoring-cheat-sheet/",
    "comments": "https://s14415.pcdn.co/blog/the-social-media-monitoring-cheat-sheet/#comments",
    "authors": [
      {
        "name": "Content Bot"
      }
    ],
    "author": "Content Bot",
    "author_detail": {
      "name": "Content Bot"
    },
    "published": "Wed, 10 Jan 2024 10:39:23 +0000",
    "published_parsed": [
      2024,
      1,
      10,
      10,
      39,
      23,
      2,
      10,
      0
    ],
    "tags": [
      {
        "term": "Brandwatch Updates",
        "scheme": null,
        "label": null
      },
      {
        "term": "Just for Fun",
        "scheme": null,
        "label": null
      },
      {
        "term": "Marketing",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://www.brandwatch.com/?p=11583",
    "guidislink": false,
    "summary": "<img alt=\"Boolean Cheat Sheet: Unlock the Full Power of Social Media Monitoring\" src=\"https://s14415.pcdn.co/wp-content/uploads/2012/07/social-media-monitoring-cheat-sheet-blog-hero-min.jpeg\" style=\"float: right;\" title=\"Boolean Cheat Sheet: Unlock the Full Power of Social Media Monitoring\" />This blog post has it all: bargains, anger, jealousy, love, swearing and even some sexual language. Unfortunately for those of you who found your way here through the Googling of foul words, this post is tailored to both Boolean lovers and Brandwatch users, and is devoid of any explicit scenes. Sorry. One way in which [&#8230;]",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.brandwatch.com/feed/",
      "value": "<img alt=\"Boolean Cheat Sheet: Unlock the Full Power of Social Media Monitoring\" src=\"https://s14415.pcdn.co/wp-content/uploads/2012/07/social-media-monitoring-cheat-sheet-blog-hero-min.jpeg\" style=\"float: right;\" title=\"Boolean Cheat Sheet: Unlock the Full Power of Social Media Monitoring\" />This blog post has it all: bargains, anger, jealousy, love, swearing and even some sexual language. Unfortunately for those of you who found your way here through the Googling of foul words, this post is tailored to both Boolean lovers and Brandwatch users, and is devoid of any explicit scenes. Sorry. One way in which [&#8230;]"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.brandwatch.com/feed/",
        "value": "<img alt=\"Boolean Cheat Sheet: Unlock the Full Power of Social Media Monitoring\" src=\"https://s14415.pcdn.co/wp-content/uploads/2012/07/social-media-monitoring-cheat-sheet-blog-hero-min.jpeg\" style=\"float: right;\" title=\"Boolean Cheat Sheet: Unlock the Full Power of Social Media Monitoring\" /><p>This blog post has it all: bargains, anger, jealousy, love, swearing and even some sexual language. Unfortunately for those of you who found your way here through the Googling of foul words, this post is tailored to both Boolean lovers and <a href=\"https://www.brandwatch.com\">Brandwatch</a> users, and is devoid of any explicit scenes. Sorry.<span id=\"more-11583\"></span></p>\n<p>One way in which Brandwatch is head and shoulders above other <a href=\"https://www.brandwatch.com\">social media monitoring</a> tools is that it allows users to carefully customise their queries using Boolean operators, affording almost unlimited control over what can be searched for.</p>\n<p>However, with great power comes great responsibility. And great patience.</p>\n<p><a href=\"https://s14415.pcdn.co/wp-content/uploads/brandwatch/spiderman.png\"><img alt=\"\" class=\"aligncenter size-full wp-image-11587\" height=\"340\" src=\"https://s14415.pcdn.co/wp-content/uploads/brandwatch/spiderman.png\" title=\"spiderman\" width=\"400\" /></a></p>\n<p>It can mean typing out long passages of key terms to make sure the right words are being included or excluded. If you\u2019re looking to isolate customer-service related tweets from other data you may have collected, it can require a bit of thought as to how best to separate them.</p>\n<p>Our crack team of in-house analysts have put together some commonly-used strings of words that can be copied to find certain criteria, such as the aforementioned customer service. This can be great for categorising and segmenting your data.</p>\n<p>As well as positive and negative lists,\u00a0we&#8217;ve\u00a0included a generic emotive one too, which lets you separate all social media mentions of your brand (or product, competitor et cetera) in which someone has an opinion, from less emotive reporting and neutral statements. It means you can see comments like \u2018I love my new Sony Bravia screen\u2019 and ignore things like \u2018just moving my Sony Bravia into my bedroom\u2019.</p>\n<p>The copypasta is freshly prepared in Brandwatch syntax, so it&#8217;s all ready to be served into your\u00a0existing\u00a0queries.</p>\n<p style=\"text-align: center;\"><a href=\"https://s14415.pcdn.co/wp-content/uploads/brandwatch/copypasta.jpg\"><img alt=\"\" class=\"aligncenter wp-image-11600\" height=\"225\" src=\"https://s14415.pcdn.co/wp-content/uploads/brandwatch/copypasta.jpg\" title=\"copypasta\" width=\"300\" /></a></p>\n<p>To read a quick guide on how to build queries and get to grips with how Booleans work in Brandwatch, you can <a href=\"https://www.brandwatch.com/2012/03/find-what-youre-looking-for-crafting-a-query-in-a-monitoring-tool/\">cast your eyes over this beauty</a>.</p>\n<p>In the meantime, here\u2019s your cheat-sheet for helping you build your queries and searches.</p>\n<p><strong>[Note: you&#8217;ll need to replace :: with your\u00a0</strong><strong>search terms\u00a0</strong><strong>or original\u00a0</strong><strong>query string]</strong></p>\n<p><strong>Voucher/Coupons</strong></p>\n<address style=\"padding-left: 30px;\">(coupon* OR voucher* OR code* OR discount OR deal OR deals OR offer OR offers OR (promo* NEAR/10 (sale OR buy)) OR sale OR (raw:(save OR Save OR SAVE OR off OR Off OR OFF) NEAR/4 raw:(&#8220;\u00a3&#8221; OR &#8220;$&#8221; OR &#8220;\u20ac&#8221; OR &#8220;%&#8221; OR pence OR Pence OR PENCE OR pennies OR Pennies OR PENNIES OR pounds OR Pounds OR POUNDS OR cent OR Cent OR CENT OR cents OR Cents OR CENTS OR dollars OR Dollars OR DOLLARS OR euros OR Euros OR EUROS)))</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">OR</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">title:(coupon* OR voucher* OR code* OR discount OR deal OR deals OR offer OR offers OR (promo* NEAR/10 (sale OR buy)) OR sale OR (raw:(save OR Save OR SAVE OR off OR Off OR OFF) NEAR/4 raw:(&#8220;\u00a3&#8221; OR &#8220;$&#8221; OR &#8220;\u20ac&#8221; OR &#8220;%&#8221; OR pence OR Pence OR PENCE OR pennies OR Pennies OR PENNIES OR pounds OR Pounds OR POUNDS OR cent OR Cent OR CENT OR cents OR Cents OR CENTS OR dollars OR Dollars OR DOLLARS OR euros OR Euros OR EUROS)))</address>\n<p><strong>Price</strong></p>\n<address style=\"padding-left: 30px;\">((pric* OR cost* OR money OR expensive OR cheap* OR value OR charge OR pay* OR paid OR ripoff OR &#8220;rip off&#8221; OR extortion* OR bargain OR tariff*) NEAR/20 ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">OR</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">((worth NEAR/20 ::) -(worth NEAR/3 (hassle OR effort OR risk OR time OR wait OR salt OR candle OR while OR checking OR go* OR taking OR visit* OR look*)))</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">OR</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">(site:twitter AND raw:(&#8220;\u00a3&#8221; OR &#8220;\u20ac&#8221;) AND (::))</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-giveaway -&#8220;give away&#8221; -&#8220;for your chance to&#8221; -&#8220;for ur chance to&#8221; -&#8220;for the chance to&#8221;</address>\n<p><strong>Ticket Price</strong></p>\n<address style=\"padding-left: 30px;\">(((reduc* OR lower OR decreas* OR cheaper OR less OR drop OR increas* OR inflate* OR rise OR cost OR expensive OR price) NEAR/2 ticket) NEAR/10 ::) -&#8220;Cheaper than&#8221; -&#8220;less than&#8221;</address>\n<p><strong>Recommendation</strong></p>\n<address style=\"padding-left: 30px;\">(((((recommend* OR propose* OR suggest* OR should) NEAR/3 (buy OR get OR purchase* OR getting OR bought)) NEAR/1 (I OR im OR you OR u OR your OR ur)) NEAR/10 (::))</address>\n<p><strong>Customer Service</strong></p>\n<p>Customer service is notoriously difficult to create rules for. It can be better to employ an emotive category instead (see below)</p>\n<address style=\"padding-left: 30px;\">((customerservice* OR &#8220;customer service&#8221;~3 OR &#8220;customer services&#8221;~3 &#8220;customer assistance&#8221;~2 OR &#8220;customer support&#8221;~2 OR &#8220;customer relations&#8221;~2 OR &#8220;customer care&#8221;~2 OR &#8220;apology&#8221; OR &#8220;staff&#8221; OR &#8220;helpful&#8221; OR &#8220;polite&#8221; OR &#8220;approachable&#8221; OR &#8220;friendly&#8221; OR &#8220;rude&#8221; OR &#8220;unhelpful&#8221; OR help* OR complain* OR dispute* OR fault OR representative OR issue* OR ring* OR rang OR call* OR &#8220;on hold&#8221; OR &#8220;rude&#8221; OR &#8220;polite&#8221; OR &#8220;inpolite&#8221; OR impatient OR &#8220;interested&#8221; OR Uninterested OR arrogant OR friendly OR unfriendly OR pushy OR persistent OR attentive OR dishonest OR honest OR misleading OR sly OR unattentive OR &#8220;call back&#8221; OR &#8220;ring back&#8221; OR &#8220;ringing back&#8221; OR &#8220;calling back&#8221; OR &#8220;get back to me&#8221; OR &#8220;got back to me&#8221; OR complain* OR moaning OR disput* OR &#8220;hung up&#8221;) NEAR/10 ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-(&#8220;customer tags&#8221;~3 OR &#8220;customer rating&#8221;~3 OR &#8220;customer ratings&#8221;~3 OR &#8220;customer review&#8221;~3 OR &#8220;customer preview&#8221;~3 OR &#8220;customer reviews&#8221;~3 OR &#8220;customer previews&#8221;~3)</address>\n<p><strong>Emotive: Mild</strong></p>\n<address style=\"padding-left: 30px;\">(cool OR enjoy* OR like OR interesting) -(&#8220;looks like&#8221; OR &#8220;look like&#8221; OR &#8220;like there&#8221; OR &#8220;is like&#8221; OR &#8220;are like&#8221; OR &#8220;just like&#8221;)</address>\n<p><strong>Emotive: Intensifiers</strong></p>\n<address style=\"padding-left: 30px;\">((Speechless OR remarkable OR Wow* OR Jesus OR Christ OR Jesuschrist OR fuck* OR fuk* OR holy* OR bloody OR awfully OR deucedly OR emphatic* OR insanely OR madly OR truly OR horrendously OR tremendously OR terribly OR unquestionably OR very OR extremely OR incredibly OR exceedingly OR exceptionally OR extremely OR extraordinarily OR really OR utterly OR absolutely OR perfectly OR sublimely OR dramatically OR sheer OR avid OR flamboyant*) NEAR/10 ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">(site:twitter AND raw:(&#8220;&gt;:o&#8221; OR &#8220;&gt;:O&#8221; OR &#8220;:-O&#8221; OR &#8220;:O&#8221; OR &#8220;\u00c2\u00b0o\u00c2\u00b0&#8221; OR &#8220;\u00c2\u00b0O\u00c2\u00b0&#8221; OR &#8220;o_O&#8221; OR &#8220;o_0&#8221; OR &#8220;o.O&#8221; OR &#8220;8-0&#8221;))</address>\n<p><strong>Emotive: Positive</strong></p>\n<address style=\"padding-left: 30px;\">((&#8220;fuck yes&#8221; OR love* OR brilliant OR amaz* OR excit* OR appealing OR exceptional OR absorbing OR incredible OR matchless OR impressive OR impressed OR ((a OR my OR his OR her OR your OR our OR their) NEAR/0f (favourite OR favorite)) OR outstanding OR superb OR passion OR passionate OR satisfied OR satisfaction OR adore OR exquisite OR genius OR pleasure OR reliable OR reward* OR stunning OR delight* OR excellent OR glorious OR goodness OR stylish OR supreme OR beautiful OR dazzling OR enthusiastic OR marvelous OR marvellous OR wonderful OR &#8220;the shit&#8221; OR &#8220;teh shit&#8221; OR magnificent OR magnanimous OR fantastic OR phenomenal OR wonderful OR extraordinary OR superb OR great* OR excellent OR spectacular OR prodigious OR brilliant OR grand OR glorious OR illustrious OR notable OR impressive OR splendid OR terrific OR tremendous OR wondrous OR wonderful OR sublime) NEAR/5 ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">OR</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">(site:twitter AND raw:(&#8220;:-)&#8221; OR &#8220;:)&#8221; OR &#8220;:-D&#8221; OR &#8220;:^D&#8221; OR &#8220;&lt;3&#8221;) AND ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-(amazon OR amazone OR cunts OR idiots OR troll OR trolling) -&#8220;great deal&#8221; -&#8220;great amount&#8221;</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-((&#8220;don&#8217;t&#8221; OR dont OR not OR &#8220;isn&#8217;t&#8221; OR isnt OR &#8220;doesn&#8217;t&#8221; OR doesnt) NEAR/3f (love* OR brilliant OR amaz* OR excit* OR appealing OR exceptional OR absorbing OR incredible OR matchless OR impressive OR impressed OR ((a OR my OR his OR her OR your OR our OR their) NEAR/0f (favourite OR favorite)) OR outstanding OR superb OR passion OR passionate OR satisfied OR satisfaction OR adore OR exquisite OR genius OR pleasure OR reliable OR reward* OR stunning OR delight* OR excellent OR glorious OR goodness OR stylish OR supreme OR beautiful OR dazzling OR enthusiastic OR marvelous OR marvellous OR wonderful OR &#8220;the shit&#8221; OR &#8220;teh shit&#8221; OR magnificent OR magnanimous OR fantastic OR phenomenal OR wonderful OR extraordinary OR superb OR great* OR excellent OR spectacular OR prodigious OR brilliant OR grand OR glorious OR illustrious OR notable OR impressive OR splendid OR terrific OR tremendous OR wondrous OR wonderful OR sublime))</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address><strong>Emotive: Negative</strong></address>\n<address style=\"padding-left: 30px;\">((&#8220;Fuck no&#8221; OR hate OR hates OR fail* OR horrendous OR frustrated OR frustration OR shit* OR &#8220;is a joke&#8221; OR complicated OR terrible OR disaster OR sceptical OR upset OR disastrous OR dislike* OR disappoint* OR ridiculous OR unrealistic OR &#8220;not satisfied&#8221; OR dissatisfied OR awful OR absurd OR horrible OR unhappy OR sucks OR suck OR lousy OR unclear OR doubtful OR chaotic OR inadequate OR incomplete OR incompetent OR unimpressed OR &#8220;not impressed&#8221; OR confused OR disgusted OR crooked OR crap OR &#8220;fed up&#8221; OR annoy* OR pissedoff OR &#8220;pissed off&#8221; OR &#8220;no hope&#8221;) NEAR/5 ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">OR</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">(site:twitter AND raw:(&#8220;:-(&#8221; OR &#8220;:(&#8221; OR &#8220;:-c&#8221; OR &#8220;:c&#8221; OR &#8220;:&lt;&#8221; OR &#8220;:-&lt;&#8221; OR &#8220;:-||&#8221; OR &#8220;;-(&#8220;) AND ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-(&#8220;holy shit&#8221; OR &#8220;holy shite&#8221; OR &#8220;the shit&#8221; OR &#8220;teh shit&#8221; OR &#8220;that shit&#8221; OR &#8220;and shit&#8221; OR &#8220;buy shit&#8221; OR &#8220;my shit&#8221; OR &#8220;crap at&#8221; OR raw:&#8221;crap @&#8221; OR &#8220;suck on&#8221; OR lol OR &#8220;suck at&#8221; OR &#8220;i&#8217;m crap&#8221; OR &#8220;i suck&#8221; OR &#8220;im crap&#8221; OR shitting)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-((&#8220;don&#8217;t&#8221; OR dont OR not OR &#8220;isn&#8217;t&#8221; OR isnt OR &#8220;doesn&#8217;t&#8221; OR doesnt) NEAR/3f (hate OR hates OR fail* OR horrendous OR frustrated OR frustration OR shit* OR complicated OR terrible OR disaster OR sceptical OR upset OR disastrous OR dislike* OR disappoint* OR ridiculous OR unrealistic OR dissatisfied OR awful OR absurd OR horrible OR unhappy OR sucks OR suck OR lousy OR unclear OR doubtful OR chaotic OR inadequate OR incomplete OR incompetent OR unimpressed OR confused OR disgusted OR crooked OR crap OR &#8220;fed up&#8221; OR annoy* OR pissedoff OR &#8220;pissed off&#8221; OR &#8220;no hope&#8221;))</address>\n<p><strong>Generic Emotive Language</strong></p>\n<address style=\"padding-left: 30px;\">(((&#8220;fuck yes&#8221; OR love* OR brilliant OR amaz* OR excit* OR appealing OR exceptional OR absorbing OR incredible OR matchless OR impressive OR impressed OR ((a OR my OR his OR her OR your OR our OR their) NEAR/0f (favourite OR favorite)) OR outstanding OR superb OR passion OR passionate OR satisfied OR satisfaction OR adore OR exquisite OR genius OR pleasure OR reliable OR reward* OR stunning OR delight* OR excellent OR glorious OR goodness OR stylish OR supreme OR beautiful OR dazzling OR enthusiastic OR marvelous OR marvellous OR wonderful OR &#8220;the shit&#8221; OR &#8220;teh shit&#8221; OR magnificent OR magnanimous OR fantastic OR phenomenal OR wonderful OR extraordinary OR superb OR great* OR excellent OR spectacular OR prodigious OR brilliant OR grand OR glorious OR illustrious OR notable OR impressive OR splendid OR terrific OR tremendous OR wondrous OR wonderful OR sublime) OR (&#8220;Fuck no&#8221; OR hate OR hates OR fail* OR horrendous OR frustrated OR frustration OR shit* OR &#8220;is a joke&#8221; OR complicated OR terrible OR disaster OR sceptical OR upset OR disastrous OR dislike* OR disappoint* OR ridiculous OR unrealistic OR &#8220;not satisfied&#8221; OR dissatisfied OR awful OR absurd OR horrible OR unhappy OR sucks OR suck OR lousy OR unclear OR doubtful OR chaotic OR inadequate OR incomplete OR incompetent OR unimpressed OR &#8220;not impressed&#8221; OR confused OR disgusted OR crooked OR crap OR &#8220;fed up&#8221; OR annoy* OR pissedoff OR &#8220;pissed off&#8221; OR &#8220;no hope&#8221;)) NEAR/5 ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">OR</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">((Speechless OR remarkable OR Wow* OR Jesus OR Christ OR Jesuschrist OR fuck* OR fuk* OR holy* OR bloody OR awfully OR deucedly OR emphatic* OR insanely OR madly OR truly OR horrendously OR tremendously OR terribly OR unquestionably OR very OR extremely OR incredibly OR exceedingly OR exceptionally OR extremely OR extraordinarily OR really OR utterly OR absolutely OR perfectly OR sublimely OR dramatically OR sheer OR avid OR flamboyant*) NEAR/10 ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">OR</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">(site:twitter AND raw:(&#8220;:-)&#8221; OR &#8220;:)&#8221; OR &#8220;:-D&#8221; OR &#8220;:^D&#8221; OR &#8220;&lt;3&#8221; OR &#8220;:-(&#8221; OR &#8220;:(&#8221; OR &#8220;:-c&#8221; OR &#8220;:c&#8221; OR &#8220;:&lt;&#8221; OR &#8220;:-&lt;&#8221; OR &#8220;:-||&#8221; OR &#8220;;-(&#8221; OR &#8220;&gt;:o&#8221; OR &#8220;&gt;:O&#8221; OR &#8220;:-O&#8221; OR &#8220;:O&#8221; OR &#8220;\u00c2\u00b0o\u00c2\u00b0&#8221; OR &#8220;\u00c2\u00b0O\u00c2\u00b0&#8221; OR &#8220;o_O&#8221; OR &#8220;o_0&#8221; OR &#8220;o.O&#8221; OR &#8220;8-0&#8221;) AND ::)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-(&#8220;holy shit&#8221; OR &#8220;holy shite&#8221; OR &#8220;the shit&#8221; OR &#8220;teh shit&#8221; OR &#8220;that shit&#8221; OR &#8220;and shit&#8221; OR &#8220;buy shit&#8221; OR &#8220;my shit&#8221; OR &#8220;crap at&#8221; OR raw:&#8221;crap @&#8221; OR &#8220;suck on&#8221; OR lol OR &#8220;suck at&#8221; OR &#8220;i&#8217;m crap&#8221; OR &#8220;i suck&#8221; OR &#8220;im crap&#8221; OR shitting)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-(amazon OR amazone OR cunts OR idiots OR troll OR trolling)</address>\n<address style=\"padding-left: 30px;\">\u00a0</address>\n<address style=\"padding-left: 30px;\">-&#8220;great deal&#8221; -&#8220;great amount&#8221;</address>\n<p>I hope you agreed that this post made for a jolly good read, and if not, you at least managed to enjoy some delicious copypasta for your social media monitoring queries.</p>\n<div>\n<div style=\"font-family: sans-serif;\"></div>\n</div>\n<div>\n<div style=\"font-family: sans-serif;\"></div>\n</div>\n<div>\n<div style=\"font-family: sans-serif;\"></div>\n</div>\n<div>\n<div style=\"font-family: sans-serif;\"></div>\n</div>"
      }
    ],
    "wfw_commentrss": "https://www.brandwatch.com/blog/the-social-media-monitoring-cheat-sheet/feed/",
    "slash_comments": "6"
  },
  "JobTeaser": {
    "title": "7 tips to survive as a junior developer",
    "xmlUrl": "https://medium.com/feed/jobteaser-dev-team",
    "htmlUrl": "https://medium.com/jobteaser-dev-team/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/jobteaser-dev-team",
      "value": "7 tips to survive as a junior developer"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/jobteaser-dev-team/7-tips-to-survive-as-a-junior-developer-b15b47586fb4?source=rss----bd77d16a0035---4"
      }
    ],
    "link": "https://medium.com/jobteaser-dev-team/7-tips-to-survive-as-a-junior-developer-b15b47586fb4?source=rss----bd77d16a0035---4",
    "id": "https://medium.com/p/b15b47586fb4",
    "guidislink": false,
    "tags": [
      {
        "term": "junior-developer",
        "scheme": null,
        "label": null
      },
      {
        "term": "careers",
        "scheme": null,
        "label": null
      },
      {
        "term": "junior",
        "scheme": null,
        "label": null
      },
      {
        "term": "software-engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "developer",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Cl\u00e9ment Gateaud"
      }
    ],
    "author": "Cl\u00e9ment Gateaud",
    "author_detail": {
      "name": "Cl\u00e9ment Gateaud"
    },
    "published": "Tue, 23 May 2023 14:06:01 GMT",
    "published_parsed": [
      2023,
      5,
      23,
      14,
      6,
      1,
      1,
      143,
      0
    ],
    "updated": "2023-05-23T14:06:01.705Z",
    "updated_parsed": [
      2023,
      5,
      23,
      14,
      6,
      1,
      1,
      143,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/jobteaser-dev-team",
        "value": "<figure><img alt=\"Illustration of a boy entering a maze\" src=\"https://cdn-images-1.medium.com/max/1024/1*tHgmdkN3adeL_rv3MaDAGg.png\" /><figcaption>\u00a9<em> Midjourney</em></figcaption></figure><p>Whether you\u2019re fresh out of school or transitioning from another career, landing a job as a junior developer is a great accomplishment. But it\u2019s only the first step on your path to a successful career.</p><p>Finding your marks in this new position is the next big challenge. In this article I\u2019ll share with you 7 tips I would have loved to receive when I started as a junior developer, one year\u00a0ago.</p><h3><strong>1. Learn to walk before you\u00a0run</strong></h3><p>During your first days as a \u201cprofessional\u201d developer, you will most likely feel overwhelmed by the size and complexity of your company\u2019s codebase. \u201cWhat are all those files? Do we really need millions of lines of code to run our application?\u201d. It will for sure look very different from the small side projects you\u2019ve worked on so\u00a0far.</p><p>Don\u2019t bother trying to understand the whole codebase and how everything is structured. Just focus on what you need for your current task. If your first task involves a minor fix to a specific behavior, focus on the file that\u2019s responsible for that behavior and forget about the rest. It\u2019s already a significant challenge to understand the necessary code for your initial task, especially since you\u2019ll also be learning about the company\u2019s processes, people, and products.</p><a href=\"https://medium.com/media/12a11f60dbd4c74090fdadd0e0f0fded/href\">https://medium.com/media/12a11f60dbd4c74090fdadd0e0f0fded/href</a><p>Don\u2019t get me wrong, getting a bigger picture is important, but take it one step at a time. You will get more comfortable with the rest of the codebase over time. If you try to assimilate everything, you will assimilate nothing. Choose your fights. Time will do the\u00a0rest.</p><h3><strong>2. Getting stuck is great (but not for too\u00a0long)</strong></h3><p>You\u2019ll get stuck on some issues when coding (just like every developer in the history of mankind). It may sound counterintuitive but getting stuck is a chance. Why? Because it is in those situations that you\u2019ll learn the\u00a0most.</p><a href=\"https://medium.com/media/2776dac640fcf556b334de07293fd1e4/href\">https://medium.com/media/2776dac640fcf556b334de07293fd1e4/href</a><p>Do not ask for help right away. Do your best to understand how things work and try different solutions. But if you see that you\u2019ve been going in circles for 30 minutes and you don\u2019t see what next you could try, it\u2019s time to ask for\u00a0help.</p><p>Other developers from your team will probably be happy to help and they might unblock the situation in a snap! The solution they will help you find is important, but the way they will find this solution will be even more valuable for you. Don\u2019t hesitate to ask them to explain their reasoning.</p><h3><strong>3. Master the art of searching</strong></h3><p>The web is full of resources to help you solve your issues, it would be silly not to take advantage of it. After all, what is a developer if not an expert in googling issues and copy-pasting code from Stack Overflow? This is for the joke but honestly, searching online is an essential skill. Nothing to be ashamed\u00a0of.</p><a href=\"https://medium.com/media/d2f77f2c74f5cbc1383578a72f66cc85/href\">https://medium.com/media/d2f77f2c74f5cbc1383578a72f66cc85/href</a><p>As I write this article, there is currently quite a hype around the new AI tools, especially ChatGPT. And I think it can be a game-changer for junior developers. Ask it to explain some code, write functions or even draft some unit tests for you, the outcomes can be stunning! Be as precise as possible to get the best answers and use its conversational capabilities to ask for corrections or precisions.</p><p>But generative AI tools must be used wisely. Most importantly, make sure you don\u2019t share sensitive data in your prompts. Use them sparingly to avoid regressing intellectually, and always keep a critical eye on their answers. These tools should not make you forget the value of asking other developers. Your colleagues will often be the best solution as they know about your specific codebase.</p><h3><strong>4. You\u2019re not just here to\u00a0code</strong></h3><p>Being a developer is not just about writing code. It is a common misconception that a developer\u2019s only responsibility is churning out lines of code, but in reality, there is much more to the\u00a0job.</p><a href=\"https://medium.com/media/a6ddde4268cec451227a99fb1ae37bc1/href\">https://medium.com/media/a6ddde4268cec451227a99fb1ae37bc1/href</a><p>You have the opportunity to contribute to the product discussions and bring a valuable point of view. Don\u2019t hesitate to share your ideas and suggestions, even if you are junior and new to the company. Your fresh perspective and unique insights may provide clever ideas or identify potential opportunities for improvement.</p><p>In addition to that, you need to take ownership of your code and subjects. Make sure to communicate regularly your progress and any potential issues to your team and stakeholders. I\u2019ll also recommend you, if you have the opportunity, to present and demonstrate to your stakeholders the features you\u2019ve been working on. It is an excellent opportunity to showcase your work, receive valuable feedback, and build trust with your colleagues.</p><a href=\"https://medium.com/media/a8807abe4755623ac66dc99c33b3b82d/href\">https://medium.com/media/a8807abe4755623ac66dc99c33b3b82d/href</a><h3><strong>5. Learn to grow, and share to\u00a0learn</strong></h3><p>As a developer, keeping your skills up to date is crucial as the tech industry is constantly evolving. As important as it is, it\u2019s also essential to approach it strategically. During your first months, I advise you to focus on mastering the company\u2019s stack and familiarizing yourself with the codebase.</p><p>Once you\u2019ve established a solid foundation, you can then expand your knowledge and skills to new areas (learning a new language, discovering a library, a new tool, etc.). In some companies like JobTeaser, you\u2019ll be lucky enough to have specific time slots dedicated to learning and\u00a0sharing.</p><p>If you have the opportunity, I highly advise you to share your learnings, even if you are a junior. You can even learn something just for the occasion of this sharing. You can make a presentation about a specific subject you\u2019ve learned, or even write an article on your company\u2019s blog \ud83d\ude09. Sharing is a great way to consolidate your knowledge and gain credibility. Even the most senior developers can get to learn something from\u00a0you.</p><a href=\"https://medium.com/media/66df4e1c27c08e4b4ee1c9bbe13ef43f/href\">https://medium.com/media/66df4e1c27c08e4b4ee1c9bbe13ef43f/href</a><h3><strong>6. Code can go beyond the\u00a0office</strong></h3><p>As with the learning part, I think it\u2019s important to keep having side projects, but only when the first wave of panic is over and you feel at ease with your job\u2019s stack and codebase.</p><p>Coding side projects outside of work will probably differ from the code you are doing at work. Starting a project from scratch is a different feeling than optimizing a big codebase. Keeping these two different facets of coding is to me the best way to keep your passion for coding alive. On top of that, it is a great way to try new technologies and keep learning to become an even greater developer.</p><p>I\u2019m not telling you that you must code every night after work or every week. The best rhythm I found for me is to do a small side-project every 3\u20136 months, but it depends on you. Find the right balance so that you don\u2019t get bored with what you do at work and you don\u2019t do an overdose of code. Coding must remain a pleasure, and if you don\u2019t feel at all like coding outside the office, there is no shame about that, it\u2019s totally\u00a0fine.</p><a href=\"https://medium.com/media/58caa628cb3ed782f3511b034ebe159f/href\">https://medium.com/media/58caa628cb3ed782f3511b034ebe159f/href</a><h3><strong>7. Don\u2019t hold yourself\u00a0back</strong></h3><p>Being a junior developer is not always a long quiet river. You will sometimes feel light-years away from reaching the level of senior developers. This is totally normal. Remember that nobody expects you to be an\u00a0expert.</p><p>It often happens that junior developers get intimidated by years of experience and wonder how they could contribute to a team where all members are way more senior. But good ideas can come from anyone. And so do bad ideas. Junior engineers can propose ingenious solutions that everyone missed. And more experienced engineers sometimes suggest insane ideas that are way too complex and over-engineered.</p><p>So don\u2019t be afraid to speak up, share your ideas, ask questions and challenge the status quo. Your fresh perspective and willingness to learn can be valuable assets to the team. And remember, it\u2019s not about being the best developer in the room, it\u2019s about collaborating with others to create great software.</p><p>Be proud of what you do. Celebrate your accomplishments. Communicate your frustrations. Keep pushing. And everything is gonna be fine\u00a0\ud83d\udcaa</p><a href=\"https://medium.com/media/3036ebf1372b812578b622f81b6c5de0/href\">https://medium.com/media/3036ebf1372b812578b622f81b6c5de0/href</a><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b15b47586fb4\" width=\"1\" /><hr /><p><a href=\"https://medium.com/jobteaser-dev-team/7-tips-to-survive-as-a-junior-developer-b15b47586fb4\">7 tips to survive as a junior developer</a> was originally published in <a href=\"https://medium.com/jobteaser-dev-team\">JobTeaser Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"Illustration of a boy entering a maze\" src=\"https://cdn-images-1.medium.com/max/1024/1*tHgmdkN3adeL_rv3MaDAGg.png\" /><figcaption>\u00a9<em> Midjourney</em></figcaption></figure><p>Whether you\u2019re fresh out of school or transitioning from another career, landing a job as a junior developer is a great accomplishment. But it\u2019s only the first step on your path to a successful career.</p><p>Finding your marks in this new position is the next big challenge. In this article I\u2019ll share with you 7 tips I would have loved to receive when I started as a junior developer, one year\u00a0ago.</p><h3><strong>1. Learn to walk before you\u00a0run</strong></h3><p>During your first days as a \u201cprofessional\u201d developer, you will most likely feel overwhelmed by the size and complexity of your company\u2019s codebase. \u201cWhat are all those files? Do we really need millions of lines of code to run our application?\u201d. It will for sure look very different from the small side projects you\u2019ve worked on so\u00a0far.</p><p>Don\u2019t bother trying to understand the whole codebase and how everything is structured. Just focus on what you need for your current task. If your first task involves a minor fix to a specific behavior, focus on the file that\u2019s responsible for that behavior and forget about the rest. It\u2019s already a significant challenge to understand the necessary code for your initial task, especially since you\u2019ll also be learning about the company\u2019s processes, people, and products.</p><a href=\"https://medium.com/media/12a11f60dbd4c74090fdadd0e0f0fded/href\">https://medium.com/media/12a11f60dbd4c74090fdadd0e0f0fded/href</a><p>Don\u2019t get me wrong, getting a bigger picture is important, but take it one step at a time. You will get more comfortable with the rest of the codebase over time. If you try to assimilate everything, you will assimilate nothing. Choose your fights. Time will do the\u00a0rest.</p><h3><strong>2. Getting stuck is great (but not for too\u00a0long)</strong></h3><p>You\u2019ll get stuck on some issues when coding (just like every developer in the history of mankind). It may sound counterintuitive but getting stuck is a chance. Why? Because it is in those situations that you\u2019ll learn the\u00a0most.</p><a href=\"https://medium.com/media/2776dac640fcf556b334de07293fd1e4/href\">https://medium.com/media/2776dac640fcf556b334de07293fd1e4/href</a><p>Do not ask for help right away. Do your best to understand how things work and try different solutions. But if you see that you\u2019ve been going in circles for 30 minutes and you don\u2019t see what next you could try, it\u2019s time to ask for\u00a0help.</p><p>Other developers from your team will probably be happy to help and they might unblock the situation in a snap! The solution they will help you find is important, but the way they will find this solution will be even more valuable for you. Don\u2019t hesitate to ask them to explain their reasoning.</p><h3><strong>3. Master the art of searching</strong></h3><p>The web is full of resources to help you solve your issues, it would be silly not to take advantage of it. After all, what is a developer if not an expert in googling issues and copy-pasting code from Stack Overflow? This is for the joke but honestly, searching online is an essential skill. Nothing to be ashamed\u00a0of.</p><a href=\"https://medium.com/media/d2f77f2c74f5cbc1383578a72f66cc85/href\">https://medium.com/media/d2f77f2c74f5cbc1383578a72f66cc85/href</a><p>As I write this article, there is currently quite a hype around the new AI tools, especially ChatGPT. And I think it can be a game-changer for junior developers. Ask it to explain some code, write functions or even draft some unit tests for you, the outcomes can be stunning! Be as precise as possible to get the best answers and use its conversational capabilities to ask for corrections or precisions.</p><p>But generative AI tools must be used wisely. Most importantly, make sure you don\u2019t share sensitive data in your prompts. Use them sparingly to avoid regressing intellectually, and always keep a critical eye on their answers. These tools should not make you forget the value of asking other developers. Your colleagues will often be the best solution as they know about your specific codebase.</p><h3><strong>4. You\u2019re not just here to\u00a0code</strong></h3><p>Being a developer is not just about writing code. It is a common misconception that a developer\u2019s only responsibility is churning out lines of code, but in reality, there is much more to the\u00a0job.</p><a href=\"https://medium.com/media/a6ddde4268cec451227a99fb1ae37bc1/href\">https://medium.com/media/a6ddde4268cec451227a99fb1ae37bc1/href</a><p>You have the opportunity to contribute to the product discussions and bring a valuable point of view. Don\u2019t hesitate to share your ideas and suggestions, even if you are junior and new to the company. Your fresh perspective and unique insights may provide clever ideas or identify potential opportunities for improvement.</p><p>In addition to that, you need to take ownership of your code and subjects. Make sure to communicate regularly your progress and any potential issues to your team and stakeholders. I\u2019ll also recommend you, if you have the opportunity, to present and demonstrate to your stakeholders the features you\u2019ve been working on. It is an excellent opportunity to showcase your work, receive valuable feedback, and build trust with your colleagues.</p><a href=\"https://medium.com/media/a8807abe4755623ac66dc99c33b3b82d/href\">https://medium.com/media/a8807abe4755623ac66dc99c33b3b82d/href</a><h3><strong>5. Learn to grow, and share to\u00a0learn</strong></h3><p>As a developer, keeping your skills up to date is crucial as the tech industry is constantly evolving. As important as it is, it\u2019s also essential to approach it strategically. During your first months, I advise you to focus on mastering the company\u2019s stack and familiarizing yourself with the codebase.</p><p>Once you\u2019ve established a solid foundation, you can then expand your knowledge and skills to new areas (learning a new language, discovering a library, a new tool, etc.). In some companies like JobTeaser, you\u2019ll be lucky enough to have specific time slots dedicated to learning and\u00a0sharing.</p><p>If you have the opportunity, I highly advise you to share your learnings, even if you are a junior. You can even learn something just for the occasion of this sharing. You can make a presentation about a specific subject you\u2019ve learned, or even write an article on your company\u2019s blog \ud83d\ude09. Sharing is a great way to consolidate your knowledge and gain credibility. Even the most senior developers can get to learn something from\u00a0you.</p><a href=\"https://medium.com/media/66df4e1c27c08e4b4ee1c9bbe13ef43f/href\">https://medium.com/media/66df4e1c27c08e4b4ee1c9bbe13ef43f/href</a><h3><strong>6. Code can go beyond the\u00a0office</strong></h3><p>As with the learning part, I think it\u2019s important to keep having side projects, but only when the first wave of panic is over and you feel at ease with your job\u2019s stack and codebase.</p><p>Coding side projects outside of work will probably differ from the code you are doing at work. Starting a project from scratch is a different feeling than optimizing a big codebase. Keeping these two different facets of coding is to me the best way to keep your passion for coding alive. On top of that, it is a great way to try new technologies and keep learning to become an even greater developer.</p><p>I\u2019m not telling you that you must code every night after work or every week. The best rhythm I found for me is to do a small side-project every 3\u20136 months, but it depends on you. Find the right balance so that you don\u2019t get bored with what you do at work and you don\u2019t do an overdose of code. Coding must remain a pleasure, and if you don\u2019t feel at all like coding outside the office, there is no shame about that, it\u2019s totally\u00a0fine.</p><a href=\"https://medium.com/media/58caa628cb3ed782f3511b034ebe159f/href\">https://medium.com/media/58caa628cb3ed782f3511b034ebe159f/href</a><h3><strong>7. Don\u2019t hold yourself\u00a0back</strong></h3><p>Being a junior developer is not always a long quiet river. You will sometimes feel light-years away from reaching the level of senior developers. This is totally normal. Remember that nobody expects you to be an\u00a0expert.</p><p>It often happens that junior developers get intimidated by years of experience and wonder how they could contribute to a team where all members are way more senior. But good ideas can come from anyone. And so do bad ideas. Junior engineers can propose ingenious solutions that everyone missed. And more experienced engineers sometimes suggest insane ideas that are way too complex and over-engineered.</p><p>So don\u2019t be afraid to speak up, share your ideas, ask questions and challenge the status quo. Your fresh perspective and willingness to learn can be valuable assets to the team. And remember, it\u2019s not about being the best developer in the room, it\u2019s about collaborating with others to create great software.</p><p>Be proud of what you do. Celebrate your accomplishments. Communicate your frustrations. Keep pushing. And everything is gonna be fine\u00a0\ud83d\udcaa</p><a href=\"https://medium.com/media/3036ebf1372b812578b622f81b6c5de0/href\">https://medium.com/media/3036ebf1372b812578b622f81b6c5de0/href</a><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b15b47586fb4\" width=\"1\" /><hr /><p><a href=\"https://medium.com/jobteaser-dev-team/7-tips-to-survive-as-a-junior-developer-b15b47586fb4\">7 tips to survive as a junior developer</a> was originally published in <a href=\"https://medium.com/jobteaser-dev-team\">JobTeaser Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Teamwork": {
    "title": "The \u201cGo Serverless\u201d Data Engineering Revolution at Teamwork (golang + AWS = \u2764)",
    "xmlUrl": "https://engineroom.teamwork.com/feed",
    "htmlUrl": "https://engineroom.teamwork.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineroom.teamwork.com/feed",
      "value": "The \u201cGo Serverless\u201d Data Engineering Revolution at Teamwork (golang + AWS = \u2764)"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineroom.teamwork.com/the-go-serverless-data-engineering-revolution-at-teamwork-golang-aws-f2fd3cb1f563?source=rss----cea4eecd5960---4"
      }
    ],
    "link": "https://engineroom.teamwork.com/the-go-serverless-data-engineering-revolution-at-teamwork-golang-aws-f2fd3cb1f563?source=rss----cea4eecd5960---4",
    "id": "https://medium.com/p/f2fd3cb1f563",
    "guidislink": false,
    "tags": [
      {
        "term": "golang",
        "scheme": null,
        "label": null
      },
      {
        "term": "aws-lambda",
        "scheme": null,
        "label": null
      },
      {
        "term": "serverless-architecture",
        "scheme": null,
        "label": null
      },
      {
        "term": "data-engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "aws-athena",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Joe Minichino"
      }
    ],
    "author": "Joe Minichino",
    "author_detail": {
      "name": "Joe Minichino"
    },
    "published": "Tue, 19 Oct 2021 13:58:52 GMT",
    "published_parsed": [
      2021,
      10,
      19,
      13,
      58,
      52,
      1,
      292,
      0
    ],
    "updated": "2021-10-19T13:58:52.697Z",
    "updated_parsed": [
      2021,
      10,
      19,
      13,
      58,
      52,
      1,
      292,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineroom.teamwork.com/feed",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kfIA5VlbuKt_gw5v0JO8Pg.jpeg\" /><figcaption>A real data\u00a0lake.</figcaption></figure><p>Traditional Data Engineering relies on products such as Airflow, Hadoop, Spark and Spark-based architectures, or similar technologies.</p><p>These are still viable solutions for a number of reason, not least the fact that Data Engineers are few and far between, and the vast majority of them will be familiar in the above technologies or similar products/frameworks.</p><h3><strong>Go Serverless</strong></h3><p>I wrote an article about our <a href=\"https://engineroom.teamwork.com/prophecy-teamworks-data-lake-1a8ebb6dd3ae\">tech stack</a>, which includes S3, Athena, Glue, Quicksight, Kinesis\u00a0etc.</p><p>What is not immediately apparent is the <strong><em>serverless</em></strong> nature of our stack, which was a deliberate choice taken in the context of a Data Analytics department which was started as an experiment and had to pick its battles very wisely. Sysops, cluster / server management, CI/CD were not top of our list. Creating dashboards was.</p><p>Also before Teamwork I had a nearly 2-year run working with a company that was entirely serverless in their set up AND mentality, and it was a career-changing experience. We worked prevalently with <strong>AWS Lambda</strong> when Lambda was a new toy, and we loved\u00a0it.</p><p>Finally, despite the \u201cbuzz\u201d over <strong>Functional Programming</strong> being seemingly over, I am an arduous fanatic of it and of what it represents philosophically, a way to represent each problem in terms of an input, some transformation, an output and when possible, no side\u00a0effects.</p><p>NOTE: some of the tools I mention are not strictly serverless as much as they are fully managed (eg. Kinesis or Github Actions), but they still involve little or no sysops /\u00a0devops.</p><h3><strong>Serverless Processing: AWS\u00a0Lambda</strong></h3><p>Once upon a time you would have to settle for Node.js or Python to write Lambda code, but nowadays not only you can use a whole lot of runtimes, you can simply use your own docker image et voila\u2019, you\u2019re ready to go. In our case we are ready to <strong>Go</strong>, since at Teamwork Go(lang) is our programming language of choice. It\u2019s fast, easy to use, very safe and reliable, and given that it can complete the same operation faster than most other programming languages it also translates to a <strong>cost save</strong>, given Lambda pricing is a function of the duration of the execution of each Lambda invocation.</p><h3><strong>Serverless Deployment: Github Actions + Terraform</strong></h3><p>Terraform keeps us aligned with the internal practice for infrastructure maintainance and Github Actions allow us to perform a Terraform apply on PR merge, so effectively we have cut out the need for older setups such as Travis or Jenkins. It does not cut out the reliance on a third party (Github) but we\u2019re ok with the eggs being in that basket because if Github goes down then we can\u2019t even push our code so there would not be releases anyway. Note that we build Docker images and store them in ECR (you have to for Lambdas), but we are happier with this than with having our images on Docker Hub since\u200a\u2014\u200aagain\u200a\u2014\u200awithout AWS our system is down so we\u2019d rather reduce the number of service providers we depend\u00a0upon.</p><h3>Serverless Events: AWS EventBridge</h3><p>One particularly elegant aspect of building serverless pipelines in AWS is EventBridge, which allows several triggers to invoke pipelines, making them event driven. Your Lambdas can be invoked by SNS topics, S3 events and so on. A frequent way we use in Teamwork to invoke Lambdas is to set the s3:putObject as a trigger, so any time an object is added to a particular bucket, a Lambda is invoked that will process that particular object.</p><h3>Serverless Analytics: Athena</h3><p>Athena is a great analytics engine whose pricing model is based on the amount of S3 space scanned and\u200a\u2014\u200aif you use <strong>federated queries</strong>\u200a\u2014\u200athe underlying cost of Lambda invocations. Since partitions are of vital importance when querying large datasets, structuring your queries so only subsets of your data are scanned, and making sure you use compressed and optimized columnar formats (such as parquet) means saving cost on\u00a0queries.</p><h3>Fully Managed Components: Kinesis and Quicksight</h3><p>Kinesis covers a vital role in that it holds the streams of data traffic that are meant for processing and storage. Kinesis Firehose in particular does a great job of automatically partitioning your data by time units, down to the hour, into your desired destination. We mostly store in S3 but you can also target Redshift, Elasticsearch and Splunk.<br />Quicksight is a visualization tool that is extremely powerful. It probably lacks a bit behind competitors such as PowerBI or Tableau in terms of UX, but its seamless integration with AWS makes very interesting features such as augmenting your data with ML predictions with Sagemaker an incredibly trivial task. You can also expose your dashboards to the internet if you are on the correct pricing plan, we use this feature to democratize our data internally by granting access to all our dashboard to all our employees.</p><h3>Example Use Case and Architecture</h3><p>The problem at hand was exploring the usage of Teamwork integrations, with a particular focus on the internally maintained ones to prioritize feature development.</p><p>The raw data source is HAProxy logs in common log format, and these logs are funnelled into Cloudwatch, and this was our starting point. We designed the architecture from there, here is the\u00a0diagram:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*tC69D9aVGxq1eeM9HOIc9g.png\" /><figcaption>Integrations Analytics architecture.</figcaption></figure><p><strong>Step 1: Subscription Filter (Production Account)</strong></p><p>The way we extract logs from Cloudwatch is through a little known feature called Subscription Filters. You can have two filters per log group, and all they do is take log entries (you can specify one of several formats available), apply a filter that you can write (regex / parsing kind of thing) and extract the matching\u00a0entries.</p><p><strong>Step 2: Kinesis Firehose (Production)</strong></p><p>Subscription Filters can be configured to publish their data on a Kinesis Stream, or a Firehose stream, which is the option we chose to \u201cpark\u201d the gzipped entries into a S3\u00a0bucket.</p><p><strong>Step 3: S3 replication (Production -&gt;\u00a0DA)</strong></p><p>We are replication data out of our production account into our Data Analytics (DA) account. This is good for a multitude of reasons, but mainly:<br />1. Don\u2019t do Analytics in Production<br />2. Avoid having to set a lot of policies allowing cross-account interaction between components, which is annoying.</p><p><strong>Step 4: Processing (DA)</strong></p><p>Processing happens with a Lambda, which is triggered by the s3:putObject event in EventBridge. Whenever a new object lands in the bucket (in this case by means of replication), the Lambda picks it up and processes it.<br />This step takes the entris that have been transformed into gzipped JSON by Firehose and for each entry, it looks up details of the request so that we can augment the record with account and integration information. We use a Federated Query in Athena to join several data sources, and we store the augmented records in Prophecy, our data\u00a0lake.</p><p><strong>Step 5: Cataloging</strong></p><p>Every hour, an AWS Glue Crawler scans the data lake bucket for new data, and it updates schemas in our AwsDataCatalog which is the catalog of metadata information for Prophecy. There the schemas are updated and new partitions detected.</p><p><strong>Step 6: Analytics (DA)</strong></p><p>At this point the data is ready to be analyzed. Our normal process is to write SQL queries and create an Athena view for them, and so we wrote a single SQL view that retrieves all the data we need to visualize which illustrates integration usage\u00a0records.</p><p><strong>Step 7: Visualization</strong></p><p>Finally we create a dataset in Quicksight based on the aforementioned view and display the integration usage, delegating to Quicksight details such as computing distinct accounts / users / number of requests per integration etc.</p><h3><strong>Conclusion</strong></h3><p>Data Engineering is evolving just as fast as other fields in the Data realm (Data Analytics and Data Science, for example) and while traditional methods won\u2019t go away any time soon, Serverless Data Engineering means data can be collected, transformed, manipulated and made available to data analysts and data scientists cutting costs on overheads and increase elegance and stability of your pipelines.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f2fd3cb1f563\" width=\"1\" /><hr /><p><a href=\"https://engineroom.teamwork.com/the-go-serverless-data-engineering-revolution-at-teamwork-golang-aws-f2fd3cb1f563\">The \u201cGo Serverless\u201d Data Engineering Revolution at Teamwork (golang + AWS = \u2764)</a> was originally published in <a href=\"https://engineroom.teamwork.com\">Teamwork Engine Room</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kfIA5VlbuKt_gw5v0JO8Pg.jpeg\" /><figcaption>A real data\u00a0lake.</figcaption></figure><p>Traditional Data Engineering relies on products such as Airflow, Hadoop, Spark and Spark-based architectures, or similar technologies.</p><p>These are still viable solutions for a number of reason, not least the fact that Data Engineers are few and far between, and the vast majority of them will be familiar in the above technologies or similar products/frameworks.</p><h3><strong>Go Serverless</strong></h3><p>I wrote an article about our <a href=\"https://engineroom.teamwork.com/prophecy-teamworks-data-lake-1a8ebb6dd3ae\">tech stack</a>, which includes S3, Athena, Glue, Quicksight, Kinesis\u00a0etc.</p><p>What is not immediately apparent is the <strong><em>serverless</em></strong> nature of our stack, which was a deliberate choice taken in the context of a Data Analytics department which was started as an experiment and had to pick its battles very wisely. Sysops, cluster / server management, CI/CD were not top of our list. Creating dashboards was.</p><p>Also before Teamwork I had a nearly 2-year run working with a company that was entirely serverless in their set up AND mentality, and it was a career-changing experience. We worked prevalently with <strong>AWS Lambda</strong> when Lambda was a new toy, and we loved\u00a0it.</p><p>Finally, despite the \u201cbuzz\u201d over <strong>Functional Programming</strong> being seemingly over, I am an arduous fanatic of it and of what it represents philosophically, a way to represent each problem in terms of an input, some transformation, an output and when possible, no side\u00a0effects.</p><p>NOTE: some of the tools I mention are not strictly serverless as much as they are fully managed (eg. Kinesis or Github Actions), but they still involve little or no sysops /\u00a0devops.</p><h3><strong>Serverless Processing: AWS\u00a0Lambda</strong></h3><p>Once upon a time you would have to settle for Node.js or Python to write Lambda code, but nowadays not only you can use a whole lot of runtimes, you can simply use your own docker image et voila\u2019, you\u2019re ready to go. In our case we are ready to <strong>Go</strong>, since at Teamwork Go(lang) is our programming language of choice. It\u2019s fast, easy to use, very safe and reliable, and given that it can complete the same operation faster than most other programming languages it also translates to a <strong>cost save</strong>, given Lambda pricing is a function of the duration of the execution of each Lambda invocation.</p><h3><strong>Serverless Deployment: Github Actions + Terraform</strong></h3><p>Terraform keeps us aligned with the internal practice for infrastructure maintainance and Github Actions allow us to perform a Terraform apply on PR merge, so effectively we have cut out the need for older setups such as Travis or Jenkins. It does not cut out the reliance on a third party (Github) but we\u2019re ok with the eggs being in that basket because if Github goes down then we can\u2019t even push our code so there would not be releases anyway. Note that we build Docker images and store them in ECR (you have to for Lambdas), but we are happier with this than with having our images on Docker Hub since\u200a\u2014\u200aagain\u200a\u2014\u200awithout AWS our system is down so we\u2019d rather reduce the number of service providers we depend\u00a0upon.</p><h3>Serverless Events: AWS EventBridge</h3><p>One particularly elegant aspect of building serverless pipelines in AWS is EventBridge, which allows several triggers to invoke pipelines, making them event driven. Your Lambdas can be invoked by SNS topics, S3 events and so on. A frequent way we use in Teamwork to invoke Lambdas is to set the s3:putObject as a trigger, so any time an object is added to a particular bucket, a Lambda is invoked that will process that particular object.</p><h3>Serverless Analytics: Athena</h3><p>Athena is a great analytics engine whose pricing model is based on the amount of S3 space scanned and\u200a\u2014\u200aif you use <strong>federated queries</strong>\u200a\u2014\u200athe underlying cost of Lambda invocations. Since partitions are of vital importance when querying large datasets, structuring your queries so only subsets of your data are scanned, and making sure you use compressed and optimized columnar formats (such as parquet) means saving cost on\u00a0queries.</p><h3>Fully Managed Components: Kinesis and Quicksight</h3><p>Kinesis covers a vital role in that it holds the streams of data traffic that are meant for processing and storage. Kinesis Firehose in particular does a great job of automatically partitioning your data by time units, down to the hour, into your desired destination. We mostly store in S3 but you can also target Redshift, Elasticsearch and Splunk.<br />Quicksight is a visualization tool that is extremely powerful. It probably lacks a bit behind competitors such as PowerBI or Tableau in terms of UX, but its seamless integration with AWS makes very interesting features such as augmenting your data with ML predictions with Sagemaker an incredibly trivial task. You can also expose your dashboards to the internet if you are on the correct pricing plan, we use this feature to democratize our data internally by granting access to all our dashboard to all our employees.</p><h3>Example Use Case and Architecture</h3><p>The problem at hand was exploring the usage of Teamwork integrations, with a particular focus on the internally maintained ones to prioritize feature development.</p><p>The raw data source is HAProxy logs in common log format, and these logs are funnelled into Cloudwatch, and this was our starting point. We designed the architecture from there, here is the\u00a0diagram:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*tC69D9aVGxq1eeM9HOIc9g.png\" /><figcaption>Integrations Analytics architecture.</figcaption></figure><p><strong>Step 1: Subscription Filter (Production Account)</strong></p><p>The way we extract logs from Cloudwatch is through a little known feature called Subscription Filters. You can have two filters per log group, and all they do is take log entries (you can specify one of several formats available), apply a filter that you can write (regex / parsing kind of thing) and extract the matching\u00a0entries.</p><p><strong>Step 2: Kinesis Firehose (Production)</strong></p><p>Subscription Filters can be configured to publish their data on a Kinesis Stream, or a Firehose stream, which is the option we chose to \u201cpark\u201d the gzipped entries into a S3\u00a0bucket.</p><p><strong>Step 3: S3 replication (Production -&gt;\u00a0DA)</strong></p><p>We are replication data out of our production account into our Data Analytics (DA) account. This is good for a multitude of reasons, but mainly:<br />1. Don\u2019t do Analytics in Production<br />2. Avoid having to set a lot of policies allowing cross-account interaction between components, which is annoying.</p><p><strong>Step 4: Processing (DA)</strong></p><p>Processing happens with a Lambda, which is triggered by the s3:putObject event in EventBridge. Whenever a new object lands in the bucket (in this case by means of replication), the Lambda picks it up and processes it.<br />This step takes the entris that have been transformed into gzipped JSON by Firehose and for each entry, it looks up details of the request so that we can augment the record with account and integration information. We use a Federated Query in Athena to join several data sources, and we store the augmented records in Prophecy, our data\u00a0lake.</p><p><strong>Step 5: Cataloging</strong></p><p>Every hour, an AWS Glue Crawler scans the data lake bucket for new data, and it updates schemas in our AwsDataCatalog which is the catalog of metadata information for Prophecy. There the schemas are updated and new partitions detected.</p><p><strong>Step 6: Analytics (DA)</strong></p><p>At this point the data is ready to be analyzed. Our normal process is to write SQL queries and create an Athena view for them, and so we wrote a single SQL view that retrieves all the data we need to visualize which illustrates integration usage\u00a0records.</p><p><strong>Step 7: Visualization</strong></p><p>Finally we create a dataset in Quicksight based on the aforementioned view and display the integration usage, delegating to Quicksight details such as computing distinct accounts / users / number of requests per integration etc.</p><h3><strong>Conclusion</strong></h3><p>Data Engineering is evolving just as fast as other fields in the Data realm (Data Analytics and Data Science, for example) and while traditional methods won\u2019t go away any time soon, Serverless Data Engineering means data can be collected, transformed, manipulated and made available to data analysts and data scientists cutting costs on overheads and increase elegance and stability of your pipelines.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f2fd3cb1f563\" width=\"1\" /><hr /><p><a href=\"https://engineroom.teamwork.com/the-go-serverless-data-engineering-revolution-at-teamwork-golang-aws-f2fd3cb1f563\">The \u201cGo Serverless\u201d Data Engineering Revolution at Teamwork (golang + AWS = \u2764)</a> was originally published in <a href=\"https://engineroom.teamwork.com\">Teamwork Engine Room</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Twilio": {
    "title": "Protect Twilio Voice Input with Encryption and Redaction",
    "xmlUrl": "https://www.twilio.com/blog/feed",
    "htmlUrl": "https://www.twilio.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.twilio.com/blog/feed",
      "value": "Protect Twilio Voice Input with Encryption and Redaction"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.twilio.com/blog/protect-twilio-voice-input-encryption-redaction"
      }
    ],
    "link": "https://www.twilio.com/blog/protect-twilio-voice-input-encryption-redaction",
    "summary": "<div class=\"block-rich_text\">\n\n<p>Are you doing all you can to protect the sensitive information your callers trust you with?</p>\n<p>As organizations leverage more sensitive information, securing that data is more important than ever. Twilio offers numerous ways you can protect your sensitive data\u2014but it\u2019s up to you to implement the resources Twilio provides responsibly.</p>\n<p>In this article, learn how to <strong>encrypt</strong> and <strong>redact </strong>data collected from <a href=\"https://www.twilio.com/docs/voice\">Twilio Programmable Voice</a>, using <a href=\"https://www.twilio.com/docs/voice/twiml/gather\">&lt;Gather&gt; TwiML</a> with <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions\">Twilio Serverless Functions</a> and <a href=\"https://www.twilio.com/en-us/pci-compliance\">Voice PCI Mode.</a></p>\n<h2>Things you'll need</h2>\n<p>In order to follow this tutorial, you will need:</p>\n<ul>\n<li><a href=\"http://twilio.com/try-twilio\">A Twilio account</a> </li>\n<li><a href=\"https://www.twilio.com/console/phone-numbers/search\">A phone number that can receive calls</a></li>\n</ul>\n<h2>What are you building?</h2>\n<p>You will build a simple interactive voice application to handle caller authentication. A Function will be used to prompt the caller for the following sensitive information via &lt;Gather&gt; TwiML.</p>\n<ol>\n<li>\"Please enter your 4 digit PIN\"</li>\n<li>\"Please enter the last 4 digits of your payment card number\"</li>\n</ol>\n<p>As soon as this information is received from the caller, it will be encrypted. From that moment on, the data will remain encrypted until it reaches its destination.</p>\n<p>In a real-world implementation, the destination would likely be your backend service for processing. But here, another Function will act as a \u201cdummy API\u201d to demonstrate how the decryption would be performed.</p>\n<p>You will also <a href=\"https://www.twilio.com/docs/voice/tutorials/how-to-capture-payment-during-a-voice-call-generic-pay-connector#1-enable-pci-mode\">enable Voice PCI Mode</a> to redact gathered information in Voice call logs.</p>\n<h3>The Before</h3>\n<p>Before jumping into the solution, take a look at what your logs would look like without encryption or redaction.</p>\n<p>Twilio Functions will <a href=\"https://www.twilio.com/docs/serverless/api/resource/logs\">log any error</a> generated from a Function to your <a href=\"https://www.twilio.com/console/debugger\">Twilio Debugger</a>. In this example scenario, you will log an error if certain specific digits are not entered. You can see the plain-text request parameters in the error received by the Debugger.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Plain-text request parameters (4 digit PIN and last 4 digits of credit card) from Twilio Function debugger error log\" class=\"richtext-image left\" height=\"446\" src=\"https://assets.cdn.prod.twilio.com/images/fcRT3nFqORoDYYqM0rWAnKDyn8QaJ-jGxA-eyzU91mk7Ot.width-500.png\" width=\"500\" /></p>\n<p>Programmable Voice will also log the digits collected in plain-text in the <a href=\"https://www.twilio.com/docs/voice/troubleshooting#product-specific-logs\">Voice call log</a>:</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Plain-text digits from Gather TwiML in the Twilio Voice Call log\" class=\"richtext-image left\" height=\"288\" src=\"https://assets.cdn.prod.twilio.com/images/iyLeMkQY_5uzYieev6DGSU3eQXOWWirhYe12Q9hLxQ2wqX.width-500.png\" width=\"500\" /></p>\n<p>You can find this information if you have access to Call Logs or the Debugger.</p>\n<h3>The After</h3>\n<p>The data visible after implementing this solution is less vulnerable. By the end, your Function log will show more secure, encrypted values:</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Encrypted request parameters (32-character encrypted PIN and encrypted last 4 digits of card) from Twilio Function debugger error log\" class=\"richtext-image left\" height=\"253\" src=\"https://assets.cdn.prod.twilio.com/images/-WTVfhYqoAD2ZLRzrvRVpqX22uV_e_OZ2xEgDMGS39v1LS.width-500.png\" width=\"500\" /></p>\n<p>And your Call log will show <code>*REDACTED*</code>:</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Redacted digits from Gather TwiML in Voice Call log\" class=\"richtext-image left\" height=\"300\" src=\"https://assets.cdn.prod.twilio.com/images/L3RI7I1nBRFlNgm_bHg7J6_6Kr-v93j1jLn-uJEm-gl92S.width-500.png\" width=\"500\" /></p>\n<h2>Get Started</h2>\n<h3>Twilio Functions</h3>\n<p>To follow along with these instructions, use the <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/migrating-functionsclassic-new-functions-editor\">Twilio Console\u2019s Function Editor</a>.</p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--info\">\n  <span alt=\"info message about a Twilio product\" class=\"docs-note-icon docs-note-icon--info\" title=\"info icon\"></span>\n  <p>Advanced developers should consider using the more robust <a href=\"https://www.twilio.com/docs/labs/serverless-toolkit\">Serverless CLI</a> to create, deploy, and maintain Functions.</p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h4>Create a Service</h4>\n<p>Functions are created and contained within <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/create-service\">Services</a>:</p>\n<ol>\n<li>Log in to the <a href=\"https://www.twilio.com/console/\">Twilio Console</a> and navigate to the <strong><a href=\"https://www.twilio.com/console/functions/overview\">Functions</a> </strong>tab.</li>\n<li>Create a Service by clicking the <strong><a href=\"https://www.twilio.com/console/functions/overview/services\">Create Service</a></strong> button and adding a name such as <code>encrypted-gather-sample</code>.</li>\n</ol>\n<h4>Add Dependency</h4>\n<p>In this solution, the <code><a href=\"https://axios-http.com/docs/intro\">axios</a></code> library is used to make a request to your \u201cpretend\u201d backend service (the <code>decrypt-gather</code> Function) for processing.</p>\n<p>Add <code>axios</code> as a <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/dependencies\">dependency to your Service</a>.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Adding &quot;axios&quot; as a dependency to the Twilio Serverless Service via Twilio Console UI\" class=\"richtext-image full-width\" height=\"243\" src=\"https://assets.cdn.prod.twilio.com/images/kLJfhpN2OQJVv7Vzef3r-LQPD1fneHAtAvx-kbtSfAaLrL.width-800.png\" width=\"800\" /></p>\n<h4>Create an Environment Variable</h4>\n<p>This solution requires a secret key, which will be used to encrypt and decrypt the sensitive data.</p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--info\">\n  <span alt=\"info message about a Twilio product\" class=\"docs-note-icon docs-note-icon--info\" title=\"info icon\"></span>\n  <p>Your secret key string must be at least 32 bytes in length. Keep this secret private.</p>\n<p>To create a random secret, the following command line can be used with Mac/Linux:</p>\n<p><code>xxd -l32 -p /dev/urandom</code></p>\n<p>Alternatively, this secret can be generated through Node.js:</p>\n<p><code>crypto.randomBytes(32).toString('hex')</code></p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>Add an <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/variables\">Environment Variable</a> within your Service that stores your key.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Adding secret key as an Environment Variable in the Twilio Serverless Service via Twilio Console UI\" class=\"richtext-image full-width\" height=\"260\" src=\"https://assets.cdn.prod.twilio.com/images/feG-BIc3DNBoUbbWRv3DOG3P_J1kb10UMb0mx4qleiYsgo.width-800.png\" width=\"800\" /></p>\n<p>For testing purposes, the following 32-byte secret key can be used.</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-text\"><pre class=\"twlo-code language-text\"><code class=\"language-text\">a154eb4c759711bc2538a7cc021e9e9f17dd8aa63151c62ca28a82a4a404203d\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h4>Create <code>AES</code> Encryption Function</h4>\n<p>First, create a Function to handle encryption and decryption of data using <a href=\"https://en.wikipedia.org/wiki/Symmetric-key_algorithm\">symmetric-key</a> cryptography.</p>\n<p><strong>Node.js Crypto</strong></p>\n<p>Node.js offers a built-in cryptography module called <a href=\"https://nodejs.org/api/crypto.html\">Crypto</a>. Crypto provides several useful methods, like <code><a href=\"https://nodejs.org/api/crypto.html#cryptocreatecipherivalgorithm-key-iv-options\">createCipheriv()</a></code> and <code><a href=\"https://nodejs.org/api/crypto.html#cryptocreatedecipherivalgorithm-key-iv-options\">createDecipheriv()</a></code> which allow us to specify what kind of block-cipher algorithm to employ.</p>\n<p><strong>GCM Block Cipher</strong></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Advanced_Encryption_Standard\">Advanced Encryption Standard</a>, known as AES, is a technique for protecting data using encryption algorithms. AES can be achieved through a variety of <a href=\"https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation\">modes of operations</a>.</p>\n<p>In this solution, you\u2019ll be using <a href=\"https://en.wikipedia.org/wiki/Galois/Counter_Mode\">GCM, Galois/Counter Mode</a>, a symmetric-key cryptographic <a href=\"https://en.wikipedia.org/wiki/Block_cipher\">block cipher</a> which is preferred for its speed and strength.</p>\n<p><strong>Code</strong></p>\n<p>Create a new Function called <code>AES</code> with the following code.</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const crypto = require(\"crypto\")\n\nconst ALGORITHM = {\n    BLOCK_CIPHER: \"aes-256-gcm\",\n    AUTH_TAG_BYTE_SIZE: 16, \n    IV_BYTE_SIZE: 12,  \n}\n\nexports.encrypt = (plainText, key) =&gt; {\n    const nonce = crypto.randomBytes(ALGORITHM.IV_BYTE_SIZE)\n    const cipher = crypto.createCipheriv(\n        ALGORITHM.BLOCK_CIPHER, \n        Buffer.from(key, 'hex'), \n        nonce, \n        {\n            authTagLength: ALGORITHM.AUTH_TAG_BYTE_SIZE\n        }\n    )\n\n    const cipherText = Buffer.concat([\n        nonce,\n        cipher.update(plainText),\n        cipher.final(),\n        cipher.getAuthTag()\n    ])\n\n    return cipherText.toString('hex')\n}\n\nexports.decrypt = (cipherText, key) =&gt; {\n    cipherText = Buffer.from(cipherText, 'hex')\n\n    const authTag = cipherText.slice(-16)\n    const nonce = cipherText.slice(0, 12)\n    const encryptedMessage = cipherText.slice(12, -16)\n\n    const decipher = crypto.createDecipheriv(\n        ALGORITHM.BLOCK_CIPHER, \n        Buffer.from(key), \n        nonce, \n        {\n            authTagLength: ALGORITHM.AUTH_TAG_BYTE_SIZE\n        }\n    )\n\n    decipher.setAuthTag(authTag)\n    const decrypted = decipher.update(encryptedMessage, '', 'utf8') + decipher.final('utf8')      \n    return decrypted \n}\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>This Function should be set to a <a href=\"https://www.twilio.com/docs/serverless/functions-assets/visibility\">visibility of \"Private\"</a>, as it will only be used from within another Function in the same Service.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Private Serverless Function visibility setting from the Twilio Console UI\" class=\"richtext-image left\" height=\"528\" src=\"https://assets.cdn.prod.twilio.com/images/gjaufiuXqZIN4bHKoUmluYU6lZ6g-vvcDeFV98t19R54O0.width-500.png\" width=\"500\" /></p>\n<h4>Create <code>encrypted-gather</code> Function</h4>\n<p>Next, create the Function that will perform the sensitive &lt;Gather&gt; operations. This Function will be configured as the <a href=\"https://www.twilio.com/docs/usage/webhooks/voice-webhooks#incoming-voice-call\">incoming Phone Number voice webhook</a> in a later step.</p>\n<p>From this Function, the digits entered by the caller will be encrypted as soon as they are received, and sent in their encrypted state to the final, \u201cdestination\u201d Function.</p>\n<p><strong>Code</strong></p>\n<p>Create a new Function called <code>encrypted-gather</code> with the following code:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const axios = require('axios')\nconst AES = require(Runtime.getFunctions()['AES'].path)\n\nexports.handler = async function (context, event, callback) {\n    const twiml = new Twilio.twiml.VoiceResponse()\n\n    const secret_key = context.AES_SECRET\n\n    const functionUrl = `https://${context.DOMAIN_NAME}/encrypted-gather`\n    const dummyApi = `https://${context.DOMAIN_NAME}/decrypt-gather`\n\n    const step = event.step || \"getLast4CC\"\n\n    switch (step) {\n        case (\"getLast4CC\"):\n            gatherLast4Card(twiml, functionUrl);\n            break\n        case (\"getPin\"):\n            let encryptedCardDigits = AES.encrypt(event.Digits, secret_key)\n            gatherPin(twiml, encryptedCardDigits, functionUrl)\n            break\n        case (\"processData\"):\n            let encryptedPinDigits = AES.encrypt(event.Digits, secret_key)\n            await processGatheredData(twiml, event.encryptedCardDigits, encryptedPinDigits, dummyApi)\n            break\n    }\n\n    return callback(null, twiml)\n}\n\nconst gatherLast4Card = (twiml, functionUrl) =&gt; {\n    const gather = twiml.gather({\n        action: `${functionUrl}?step=getPin`,\n        method: 'POST',\n        input: 'dtmf',\n        timeout: 10,\n        numDigits: 4,\n    });\n    gather.say('Please enter last 4 digits of your payment card number.');\n\n    return gather\n}\n\nconst gatherPin = (twiml, encryptedCardDigits, functionUrl) =&gt; {\n    const gather = twiml.gather({\n        action: `${functionUrl}?step=processData&amp;encryptedCardDigits=${encryptedCardDigits}`,\n        method: 'POST',\n        input: 'dtmf',\n        timeout: 10,\n        numDigits: 4,\n    });\n    gather.say('Please enter your unique 4 digit identification number');\n\n    return gather\n}\n\nconst processGatheredData = async (twiml, encryptedCardDigits, encryptedPinDigits, dummy_url) =&gt; {\n    // make request to \"dummy\" api endpoint - example decrypt function\n    try {\n        const apiResponse = await axios({\n            method: 'post',\n            url: dummy_url,\n            data: {\n                encryptedCardDigits, encryptedPinDigits\n            }\n        })\n\n        twiml.say(`Thank you. Your account number is ${apiResponse.data.account} and your balance is ${apiResponse.data.balance}`)\n    }\n    catch (e) {\n        twiml.say(`We were not able to locate you in our system. Goodbye.`)\n    }\n\n    return twiml\n}\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>This Function should be set to <a href=\"https://www.twilio.com/docs/serverless/functions-assets/visibility\">\"Protected\"</a>, as it will be called from within Twilio and can be secured with the <code>X-Twilio-Signature</code> header.  </p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Protected Serverless Function visibility setting from the Twilio Console UI\" class=\"richtext-image left\" height=\"515\" src=\"https://assets.cdn.prod.twilio.com/images/0NJJ5Rk954VVFMp2qVfZ5JYwGr147qxiazJwpD1NXxzs-c.width-500.png\" width=\"500\" /></p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--info\">\n  <span alt=\"info message about a Twilio product\" class=\"docs-note-icon docs-note-icon--info\" title=\"info icon\"></span>\n  <p>When implementing this solution in production, you\u2019ll need to change the decryption \u201cdummyApi\u201d variable to the URL of your backend service.</p>\n<p><code>const dummyApi = `https://${context.DOMAIN_NAME}/decrypt-gather`</code></p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p><strong>How is it encrypting?</strong></p>\n<p>At the top, you <a href=\"https://www.twilio.com/docs/serverless/functions-assets/client#getfunctions\">import the functions</a> created in the previous step with the following line:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const AES = require(Runtime.getFunctions()['AES'].path)\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>Then, you define your secret by getting it <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/variables#consuming-environment-variables\">from the environment variable</a>:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const secret_key = context.AES_SECRET\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>And, most importantly, any sensitive information is wrapped with the <code>encrypt</code> function. (In this case, &lt;Gather&gt;'d information is passed as the <code>Digit</code> parameter, and can be accessed from the event object.)</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\"> let encryptedCardDigits = AES.encrypt(event.Digits, secret_key)\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>This handles the encryption of the gathered information.</p>\n<h4>Create <code>decrypt-gather</code> Function</h4>\n<p>Finally, let\u2019s create a Function to demonstrate how to <strong>decrypt</strong> the sensitive data.</p>\n<p>In a production environment, this would likely be a request to your backend service that processes the caller information based on your business needs.</p>\n<p>In this solution, a third Function will act as the \u201cbackend service\u201d that processes this data. This Function will receive the encrypted digits and decrypt them for further processing.</p>\n<p><strong>Code</strong></p>\n<p>Create a new Function called <code>decrypt-gather</code> with the following code:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const AES = require(Runtime.getFunctions()['AES'].path)\n\nexports.handler = function(context, event, callback) {\n    const response = new Twilio.Response()\n    const secret_key = context.AES_SECRET\n\n    const last4card = AES.decrypt(event.encryptedCardDigits, secret_key)\n    const pin = AES.decrypt(event.encryptedPinDigits, secret_key)\n\n   //hard-coded values used for testing purposes\n    if (last4card === \"1234\" &amp;&amp; pin === \"4321\") {\n        response.setBody(JSON.stringify({\n            account: \"AC12345678\",\n            balance: \"12.55\"\n        }))\n    } else {\n        response.setStatusCode(404)\n        response.setBody(\"No data found\")\n    }\n\n    return callback(null, response)\n}\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>This Function\u2019s visibility will be <a href=\"https://www.twilio.com/docs/serverless/functions-assets/visibility\">\"Public\"</a>, as it is pretending to be an external service.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Public Serverless Function visibility setting from the Twilio Console UI\" class=\"richtext-image left\" height=\"539\" src=\"https://assets.cdn.prod.twilio.com/images/tC-MMkRDe2YRQ7MgekGi1I4xzG2-3nhWVOcF_h30Leeb5j.width-500.png\" width=\"500\" /></p>\n<p><strong>How is it decrypting?</strong></p>\n<p>At the top, you <a href=\"https://www.twilio.com/docs/serverless/functions-assets/client#getfunctions\">import</a> <code>AES</code> functions again and define the <code>secret_key</code> as a variable.</p>\n<p>Then you call <code>decrypt</code> on the information that was previously encrypted:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const last4card = AES.decrypt(event.encryptedCardDigits, secret_key)\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h2>Additional Configuration</h2>\n<h3>Phone Number Webhook</h3>\n<p>For the sake of simplicity, connect this Function directly to a Phone Number.</p>\n<p>To configure the Phone Number:</p>\n<ol>\n<li>From the Twilio Console, navigate to the <strong><a href=\"https://www.twilio.com/console/phone-numbers/\">Phone Numbers</a></strong><a href=\"https://www.twilio.com/console/phone-numbers/\"> section</a></li>\n<li>Select your phone number, then scroll to the <strong>Voice &amp; Fax</strong> section</li>\n<li>Set the <code>encrypted-gather</code> Function as the <strong>A call comes in</strong> webhook under <strong>Voice Configuration</strong></li>\n<li><strong>Save</strong> changes</li>\n</ol>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Voice Configuration &quot;A call comes in&quot; webhook set to encrypted-gather Function\" class=\"richtext-image full-width\" height=\"162\" src=\"https://assets.cdn.prod.twilio.com/images/Nl3bWTO5bUhq136qP6UbzwSqiB6TwDtjMrSqbUQwD1jAjs.width-800.png\" width=\"800\" /></p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--info\">\n  <span alt=\"info message about a Twilio product\" class=\"docs-note-icon docs-note-icon--info\" title=\"info icon\"></span>\n  <p>If you hope to trigger this from Twilio Studio, check out <a href=\"https://www.twilio.com/blog/hiding-pii-phi-from-studio\">this blog post</a> to learn more about how to incorporate this solution securely with Studio.</p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h3>Enable PCI Mode</h3>\n<p>Almost done! You\u2019ve secured the Functions, but there\u2019s still one more area where Twilio retains gathered digits in plain-text \u2013 <a href=\"https://www.twilio.com/docs/voice/troubleshooting#product-specific-logs\">Voice call logs</a>.</p>\n<p>Below is a screenshot from the Twilio Console for an inbound call with the encrypted &lt;Gather&gt; solution implemented. Even though Functions secured the data, Voice hasn\u2019t.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Plain-text digits from Gather TwiML in the Twilio Voice Call log\" class=\"richtext-image left\" height=\"288\" src=\"https://assets.cdn.prod.twilio.com/images/iyLeMkQY_5uzYieev6DGSU3eQXOWWirhYe12Q9hLxQ2wqX.width-500_zjiMq9p.png\" width=\"500\" /></p>\n<p>There\u2019s only one way to prevent this data from being displayed in the Call log, and that\u2019s with <a href=\"https://www.twilio.com/docs/voice/tutorials/how-to-capture-payment-during-a-voice-call-generic-pay-connector#1-enable-pci-mode\">PCI Mode</a>. Enabling PCI Mode on your account will <strong>redact</strong> all data captured from any &lt;Gather&gt; operation.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Redacted digits from Gather TwiML in Voice Call log\" class=\"richtext-image left\" height=\"300\" src=\"https://assets.cdn.prod.twilio.com/images/L3RI7I1nBRFlNgm_bHg7J6_6Kr-v93j1jLn-uJEm-gl92S.width-500_GMSNjWB.png\" width=\"500\" /></p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--warning\">\n  <span alt=\"warning message about a Twilio product\" class=\"docs-note-icon docs-note-icon--warning\" title=\"warning icon\"></span>\n  <p><strong>Enabling PCI Mode on an account is a one-way street. Once it\u2019s on, you won\u2019t be able to turn it off. Redaction may make troubleshooting Voice issues more challenging.</strong></p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>If you\u2019re serious about capturing sensitive information securely...</p>\n<ol>\n<li>Navigate to the Twilio <a href=\"https://www.twilio.com/console/voice/settings\">Voice Settings</a> in the Twilio Console. (In the left navigation pane, click on <strong>Voice &gt; Settings &gt; General</strong>.)</li>\n<li>Click on the <strong>Enable PCI Mode</strong> button.</li>\n<li><strong>Save</strong> changes.</li>\n</ol>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Programmable Voice Setting for enabling PCI Mode in the Twilio Console UI\" class=\"richtext-image full-width\" height=\"256\" src=\"https://assets.cdn.prod.twilio.com/images/T9JlIt9gaK-uGvsBD_ikYzWSFe0WrYYAsNkkn9X3ZMw8Nu.width-800.png\" width=\"800\" /></p>\n<h2>Make a call</h2>\n<p>Now it\u2019s the moment of truth\u2014it\u2019s time to place a test call to the phone number.</p>\n<p>From here, there are two paths to take.</p>\n<p>If you enter <code>1234</code> as the last 4 digits of your \u201ccredit card\u201d and <code>4321</code> as the unique PIN, you\u2019ll hear some \u201cdummy\u201d account information returned on the call. This is an example of a <strong>successful</strong> API response.</p>\n<p>If you enter any other digits, it will behave as though you aren\u2019t a known user and return a <code>404</code> response. This is an example of an <strong>unsuccessful</strong> request, which will log an error to the Twilio Debugger.</p>\n<h2>How do I know it worked?</h2>\n<p>Follow the unsuccessful path and take a look at your <a href=\"https://www.twilio.com/console/debugger\">Error log in the Twilio Console</a>.</p>\n<p>For the <code>404</code> error response, you\u2019ll find an <a href=\"https://www.twilio.com/docs/api/errors/82005\">82005 Error from Functions</a> with the following details:</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Encrypted request parameters (32-character encrypted PIN and encrypted last 4 digits of card) from Twilio Function debugger error log\" class=\"richtext-image left\" height=\"342\" src=\"https://assets.cdn.prod.twilio.com/images/KSXZilCNkZgfSEpa6SPoVDJWnXuqG6yKHU5oXpTZAhEl6o.width-500.png\" width=\"500\" /></p>\n<p>This is good. Without the encryption, an unsuccessful response would have logged those variables in plain-text. But now the data will log in its safer, encrypted form.</p>\n<p>You can also check <a href=\"https://console.twilio.com/us1/monitor/logs/calls?frameUrl=%2Fconsole%2Fvoice%2Fcalls%2Flogs%3Fx-target-region%3Dus1\">your Call log</a> to confirm the digits show <code>*REDACTED*</code> there as well.</p>\n<h2>Is this secure?</h2>\n<p>Following this tutorial (including the optional PCI Mode steps) would prevent the data from logging in plain-text anywhere within Twilio\u2019s ecosystem, and it would prevent anyone at Twilio from being able to decrypt your sensitive data \u2013 making this an improvement over the default.</p>\n<p>However, the secret key used for encryption and decryption is stored as an Environment Variable on the Service, meaning users to whom you grant Twilio Functions access would be able to extract the key and potentially go through the effort to decrypt the values.</p>\n<h2>Final Recommendation</h2>\n<p>If you are making modifications to the sample code provided, please keep in mind that <a href=\"https://www.twilio.com/docs/serverless/api/resource/logs\">Functions retain console warnings and errors</a> within internal Twilio systems and in the <a href=\"https://www.twilio.com/console/debugger\">Twilio Debugger</a> <a href=\"https://www.twilio.com/docs/serverless/api/resource/logs#debugger-and-webhooks\">for some time</a>.</p>\n<p>Do not use any of the following console logging methods with any sensitive, unencrypted data:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">console.log()\nconsole.warn()\nconsole.error()\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h2>Conclusion</h2>\n<p>In this lesson, you learned how you can protect data collected from &lt;Gather&gt; TwiML with encryption via a Serverless Function and redaction through Voice PCI Mode.</p>\n<p>If you want to collect payments from your callers, consider the fully PCI-compliant <a href=\"https://www.twilio.com/docs/voice/twiml/pay\">Twilio &lt;Pay&gt;</a> feature.</p>\n<p>To learn more about PCI compliance at Twilio, check out <a href=\"https://www.twilio.com/en-us/pci-compliance\">the documentation</a> and responsibility matrix.</p>\n<p>Users trust you to keep their sensitive information private. Make sure you respect and retain that trust by doing all you can to secure the data you process.</p>\n<p><em>Bry Schinina is a developer and educator who deeply appreciates when companies don\u2019t expose private information. She works as Tech Lead and Sr. Technical Account Manager at Twilio, solving complex problems and helping organizations succeed with their digital engagement platform. She can be reached at bschinina [at] twilio.com.</em></p>\n</div>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.twilio.com/blog/feed",
      "value": "<div class=\"block-rich_text\">\n\n<p>Are you doing all you can to protect the sensitive information your callers trust you with?</p>\n<p>As organizations leverage more sensitive information, securing that data is more important than ever. Twilio offers numerous ways you can protect your sensitive data\u2014but it\u2019s up to you to implement the resources Twilio provides responsibly.</p>\n<p>In this article, learn how to <strong>encrypt</strong> and <strong>redact </strong>data collected from <a href=\"https://www.twilio.com/docs/voice\">Twilio Programmable Voice</a>, using <a href=\"https://www.twilio.com/docs/voice/twiml/gather\">&lt;Gather&gt; TwiML</a> with <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions\">Twilio Serverless Functions</a> and <a href=\"https://www.twilio.com/en-us/pci-compliance\">Voice PCI Mode.</a></p>\n<h2>Things you'll need</h2>\n<p>In order to follow this tutorial, you will need:</p>\n<ul>\n<li><a href=\"http://twilio.com/try-twilio\">A Twilio account</a> </li>\n<li><a href=\"https://www.twilio.com/console/phone-numbers/search\">A phone number that can receive calls</a></li>\n</ul>\n<h2>What are you building?</h2>\n<p>You will build a simple interactive voice application to handle caller authentication. A Function will be used to prompt the caller for the following sensitive information via &lt;Gather&gt; TwiML.</p>\n<ol>\n<li>\"Please enter your 4 digit PIN\"</li>\n<li>\"Please enter the last 4 digits of your payment card number\"</li>\n</ol>\n<p>As soon as this information is received from the caller, it will be encrypted. From that moment on, the data will remain encrypted until it reaches its destination.</p>\n<p>In a real-world implementation, the destination would likely be your backend service for processing. But here, another Function will act as a \u201cdummy API\u201d to demonstrate how the decryption would be performed.</p>\n<p>You will also <a href=\"https://www.twilio.com/docs/voice/tutorials/how-to-capture-payment-during-a-voice-call-generic-pay-connector#1-enable-pci-mode\">enable Voice PCI Mode</a> to redact gathered information in Voice call logs.</p>\n<h3>The Before</h3>\n<p>Before jumping into the solution, take a look at what your logs would look like without encryption or redaction.</p>\n<p>Twilio Functions will <a href=\"https://www.twilio.com/docs/serverless/api/resource/logs\">log any error</a> generated from a Function to your <a href=\"https://www.twilio.com/console/debugger\">Twilio Debugger</a>. In this example scenario, you will log an error if certain specific digits are not entered. You can see the plain-text request parameters in the error received by the Debugger.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Plain-text request parameters (4 digit PIN and last 4 digits of credit card) from Twilio Function debugger error log\" class=\"richtext-image left\" height=\"446\" src=\"https://assets.cdn.prod.twilio.com/images/fcRT3nFqORoDYYqM0rWAnKDyn8QaJ-jGxA-eyzU91mk7Ot.width-500.png\" width=\"500\" /></p>\n<p>Programmable Voice will also log the digits collected in plain-text in the <a href=\"https://www.twilio.com/docs/voice/troubleshooting#product-specific-logs\">Voice call log</a>:</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Plain-text digits from Gather TwiML in the Twilio Voice Call log\" class=\"richtext-image left\" height=\"288\" src=\"https://assets.cdn.prod.twilio.com/images/iyLeMkQY_5uzYieev6DGSU3eQXOWWirhYe12Q9hLxQ2wqX.width-500.png\" width=\"500\" /></p>\n<p>You can find this information if you have access to Call Logs or the Debugger.</p>\n<h3>The After</h3>\n<p>The data visible after implementing this solution is less vulnerable. By the end, your Function log will show more secure, encrypted values:</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Encrypted request parameters (32-character encrypted PIN and encrypted last 4 digits of card) from Twilio Function debugger error log\" class=\"richtext-image left\" height=\"253\" src=\"https://assets.cdn.prod.twilio.com/images/-WTVfhYqoAD2ZLRzrvRVpqX22uV_e_OZ2xEgDMGS39v1LS.width-500.png\" width=\"500\" /></p>\n<p>And your Call log will show <code>*REDACTED*</code>:</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Redacted digits from Gather TwiML in Voice Call log\" class=\"richtext-image left\" height=\"300\" src=\"https://assets.cdn.prod.twilio.com/images/L3RI7I1nBRFlNgm_bHg7J6_6Kr-v93j1jLn-uJEm-gl92S.width-500.png\" width=\"500\" /></p>\n<h2>Get Started</h2>\n<h3>Twilio Functions</h3>\n<p>To follow along with these instructions, use the <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/migrating-functionsclassic-new-functions-editor\">Twilio Console\u2019s Function Editor</a>.</p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--info\">\n  <span alt=\"info message about a Twilio product\" class=\"docs-note-icon docs-note-icon--info\" title=\"info icon\"></span>\n  <p>Advanced developers should consider using the more robust <a href=\"https://www.twilio.com/docs/labs/serverless-toolkit\">Serverless CLI</a> to create, deploy, and maintain Functions.</p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h4>Create a Service</h4>\n<p>Functions are created and contained within <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/create-service\">Services</a>:</p>\n<ol>\n<li>Log in to the <a href=\"https://www.twilio.com/console/\">Twilio Console</a> and navigate to the <strong><a href=\"https://www.twilio.com/console/functions/overview\">Functions</a> </strong>tab.</li>\n<li>Create a Service by clicking the <strong><a href=\"https://www.twilio.com/console/functions/overview/services\">Create Service</a></strong> button and adding a name such as <code>encrypted-gather-sample</code>.</li>\n</ol>\n<h4>Add Dependency</h4>\n<p>In this solution, the <code><a href=\"https://axios-http.com/docs/intro\">axios</a></code> library is used to make a request to your \u201cpretend\u201d backend service (the <code>decrypt-gather</code> Function) for processing.</p>\n<p>Add <code>axios</code> as a <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/dependencies\">dependency to your Service</a>.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Adding &quot;axios&quot; as a dependency to the Twilio Serverless Service via Twilio Console UI\" class=\"richtext-image full-width\" height=\"243\" src=\"https://assets.cdn.prod.twilio.com/images/kLJfhpN2OQJVv7Vzef3r-LQPD1fneHAtAvx-kbtSfAaLrL.width-800.png\" width=\"800\" /></p>\n<h4>Create an Environment Variable</h4>\n<p>This solution requires a secret key, which will be used to encrypt and decrypt the sensitive data.</p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--info\">\n  <span alt=\"info message about a Twilio product\" class=\"docs-note-icon docs-note-icon--info\" title=\"info icon\"></span>\n  <p>Your secret key string must be at least 32 bytes in length. Keep this secret private.</p>\n<p>To create a random secret, the following command line can be used with Mac/Linux:</p>\n<p><code>xxd -l32 -p /dev/urandom</code></p>\n<p>Alternatively, this secret can be generated through Node.js:</p>\n<p><code>crypto.randomBytes(32).toString('hex')</code></p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>Add an <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/variables\">Environment Variable</a> within your Service that stores your key.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Adding secret key as an Environment Variable in the Twilio Serverless Service via Twilio Console UI\" class=\"richtext-image full-width\" height=\"260\" src=\"https://assets.cdn.prod.twilio.com/images/feG-BIc3DNBoUbbWRv3DOG3P_J1kb10UMb0mx4qleiYsgo.width-800.png\" width=\"800\" /></p>\n<p>For testing purposes, the following 32-byte secret key can be used.</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-text\"><pre class=\"twlo-code language-text\"><code class=\"language-text\">a154eb4c759711bc2538a7cc021e9e9f17dd8aa63151c62ca28a82a4a404203d\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h4>Create <code>AES</code> Encryption Function</h4>\n<p>First, create a Function to handle encryption and decryption of data using <a href=\"https://en.wikipedia.org/wiki/Symmetric-key_algorithm\">symmetric-key</a> cryptography.</p>\n<p><strong>Node.js Crypto</strong></p>\n<p>Node.js offers a built-in cryptography module called <a href=\"https://nodejs.org/api/crypto.html\">Crypto</a>. Crypto provides several useful methods, like <code><a href=\"https://nodejs.org/api/crypto.html#cryptocreatecipherivalgorithm-key-iv-options\">createCipheriv()</a></code> and <code><a href=\"https://nodejs.org/api/crypto.html#cryptocreatedecipherivalgorithm-key-iv-options\">createDecipheriv()</a></code> which allow us to specify what kind of block-cipher algorithm to employ.</p>\n<p><strong>GCM Block Cipher</strong></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Advanced_Encryption_Standard\">Advanced Encryption Standard</a>, known as AES, is a technique for protecting data using encryption algorithms. AES can be achieved through a variety of <a href=\"https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation\">modes of operations</a>.</p>\n<p>In this solution, you\u2019ll be using <a href=\"https://en.wikipedia.org/wiki/Galois/Counter_Mode\">GCM, Galois/Counter Mode</a>, a symmetric-key cryptographic <a href=\"https://en.wikipedia.org/wiki/Block_cipher\">block cipher</a> which is preferred for its speed and strength.</p>\n<p><strong>Code</strong></p>\n<p>Create a new Function called <code>AES</code> with the following code.</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const crypto = require(\"crypto\")\n\nconst ALGORITHM = {\n    BLOCK_CIPHER: \"aes-256-gcm\",\n    AUTH_TAG_BYTE_SIZE: 16, \n    IV_BYTE_SIZE: 12,  \n}\n\nexports.encrypt = (plainText, key) =&gt; {\n    const nonce = crypto.randomBytes(ALGORITHM.IV_BYTE_SIZE)\n    const cipher = crypto.createCipheriv(\n        ALGORITHM.BLOCK_CIPHER, \n        Buffer.from(key, 'hex'), \n        nonce, \n        {\n            authTagLength: ALGORITHM.AUTH_TAG_BYTE_SIZE\n        }\n    )\n\n    const cipherText = Buffer.concat([\n        nonce,\n        cipher.update(plainText),\n        cipher.final(),\n        cipher.getAuthTag()\n    ])\n\n    return cipherText.toString('hex')\n}\n\nexports.decrypt = (cipherText, key) =&gt; {\n    cipherText = Buffer.from(cipherText, 'hex')\n\n    const authTag = cipherText.slice(-16)\n    const nonce = cipherText.slice(0, 12)\n    const encryptedMessage = cipherText.slice(12, -16)\n\n    const decipher = crypto.createDecipheriv(\n        ALGORITHM.BLOCK_CIPHER, \n        Buffer.from(key), \n        nonce, \n        {\n            authTagLength: ALGORITHM.AUTH_TAG_BYTE_SIZE\n        }\n    )\n\n    decipher.setAuthTag(authTag)\n    const decrypted = decipher.update(encryptedMessage, '', 'utf8') + decipher.final('utf8')      \n    return decrypted \n}\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>This Function should be set to a <a href=\"https://www.twilio.com/docs/serverless/functions-assets/visibility\">visibility of \"Private\"</a>, as it will only be used from within another Function in the same Service.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Private Serverless Function visibility setting from the Twilio Console UI\" class=\"richtext-image left\" height=\"528\" src=\"https://assets.cdn.prod.twilio.com/images/gjaufiuXqZIN4bHKoUmluYU6lZ6g-vvcDeFV98t19R54O0.width-500.png\" width=\"500\" /></p>\n<h4>Create <code>encrypted-gather</code> Function</h4>\n<p>Next, create the Function that will perform the sensitive &lt;Gather&gt; operations. This Function will be configured as the <a href=\"https://www.twilio.com/docs/usage/webhooks/voice-webhooks#incoming-voice-call\">incoming Phone Number voice webhook</a> in a later step.</p>\n<p>From this Function, the digits entered by the caller will be encrypted as soon as they are received, and sent in their encrypted state to the final, \u201cdestination\u201d Function.</p>\n<p><strong>Code</strong></p>\n<p>Create a new Function called <code>encrypted-gather</code> with the following code:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const axios = require('axios')\nconst AES = require(Runtime.getFunctions()['AES'].path)\n\nexports.handler = async function (context, event, callback) {\n    const twiml = new Twilio.twiml.VoiceResponse()\n\n    const secret_key = context.AES_SECRET\n\n    const functionUrl = `https://${context.DOMAIN_NAME}/encrypted-gather`\n    const dummyApi = `https://${context.DOMAIN_NAME}/decrypt-gather`\n\n    const step = event.step || \"getLast4CC\"\n\n    switch (step) {\n        case (\"getLast4CC\"):\n            gatherLast4Card(twiml, functionUrl);\n            break\n        case (\"getPin\"):\n            let encryptedCardDigits = AES.encrypt(event.Digits, secret_key)\n            gatherPin(twiml, encryptedCardDigits, functionUrl)\n            break\n        case (\"processData\"):\n            let encryptedPinDigits = AES.encrypt(event.Digits, secret_key)\n            await processGatheredData(twiml, event.encryptedCardDigits, encryptedPinDigits, dummyApi)\n            break\n    }\n\n    return callback(null, twiml)\n}\n\nconst gatherLast4Card = (twiml, functionUrl) =&gt; {\n    const gather = twiml.gather({\n        action: `${functionUrl}?step=getPin`,\n        method: 'POST',\n        input: 'dtmf',\n        timeout: 10,\n        numDigits: 4,\n    });\n    gather.say('Please enter last 4 digits of your payment card number.');\n\n    return gather\n}\n\nconst gatherPin = (twiml, encryptedCardDigits, functionUrl) =&gt; {\n    const gather = twiml.gather({\n        action: `${functionUrl}?step=processData&amp;encryptedCardDigits=${encryptedCardDigits}`,\n        method: 'POST',\n        input: 'dtmf',\n        timeout: 10,\n        numDigits: 4,\n    });\n    gather.say('Please enter your unique 4 digit identification number');\n\n    return gather\n}\n\nconst processGatheredData = async (twiml, encryptedCardDigits, encryptedPinDigits, dummy_url) =&gt; {\n    // make request to \"dummy\" api endpoint - example decrypt function\n    try {\n        const apiResponse = await axios({\n            method: 'post',\n            url: dummy_url,\n            data: {\n                encryptedCardDigits, encryptedPinDigits\n            }\n        })\n\n        twiml.say(`Thank you. Your account number is ${apiResponse.data.account} and your balance is ${apiResponse.data.balance}`)\n    }\n    catch (e) {\n        twiml.say(`We were not able to locate you in our system. Goodbye.`)\n    }\n\n    return twiml\n}\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>This Function should be set to <a href=\"https://www.twilio.com/docs/serverless/functions-assets/visibility\">\"Protected\"</a>, as it will be called from within Twilio and can be secured with the <code>X-Twilio-Signature</code> header.  </p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Protected Serverless Function visibility setting from the Twilio Console UI\" class=\"richtext-image left\" height=\"515\" src=\"https://assets.cdn.prod.twilio.com/images/0NJJ5Rk954VVFMp2qVfZ5JYwGr147qxiazJwpD1NXxzs-c.width-500.png\" width=\"500\" /></p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--info\">\n  <span alt=\"info message about a Twilio product\" class=\"docs-note-icon docs-note-icon--info\" title=\"info icon\"></span>\n  <p>When implementing this solution in production, you\u2019ll need to change the decryption \u201cdummyApi\u201d variable to the URL of your backend service.</p>\n<p><code>const dummyApi = `https://${context.DOMAIN_NAME}/decrypt-gather`</code></p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p><strong>How is it encrypting?</strong></p>\n<p>At the top, you <a href=\"https://www.twilio.com/docs/serverless/functions-assets/client#getfunctions\">import the functions</a> created in the previous step with the following line:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const AES = require(Runtime.getFunctions()['AES'].path)\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>Then, you define your secret by getting it <a href=\"https://www.twilio.com/docs/serverless/functions-assets/functions/variables#consuming-environment-variables\">from the environment variable</a>:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const secret_key = context.AES_SECRET\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>And, most importantly, any sensitive information is wrapped with the <code>encrypt</code> function. (In this case, &lt;Gather&gt;'d information is passed as the <code>Digit</code> parameter, and can be accessed from the event object.)</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\"> let encryptedCardDigits = AES.encrypt(event.Digits, secret_key)\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>This handles the encryption of the gathered information.</p>\n<h4>Create <code>decrypt-gather</code> Function</h4>\n<p>Finally, let\u2019s create a Function to demonstrate how to <strong>decrypt</strong> the sensitive data.</p>\n<p>In a production environment, this would likely be a request to your backend service that processes the caller information based on your business needs.</p>\n<p>In this solution, a third Function will act as the \u201cbackend service\u201d that processes this data. This Function will receive the encrypted digits and decrypt them for further processing.</p>\n<p><strong>Code</strong></p>\n<p>Create a new Function called <code>decrypt-gather</code> with the following code:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const AES = require(Runtime.getFunctions()['AES'].path)\n\nexports.handler = function(context, event, callback) {\n    const response = new Twilio.Response()\n    const secret_key = context.AES_SECRET\n\n    const last4card = AES.decrypt(event.encryptedCardDigits, secret_key)\n    const pin = AES.decrypt(event.encryptedPinDigits, secret_key)\n\n   //hard-coded values used for testing purposes\n    if (last4card === \"1234\" &amp;&amp; pin === \"4321\") {\n        response.setBody(JSON.stringify({\n            account: \"AC12345678\",\n            balance: \"12.55\"\n        }))\n    } else {\n        response.setStatusCode(404)\n        response.setBody(\"No data found\")\n    }\n\n    return callback(null, response)\n}\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>This Function\u2019s visibility will be <a href=\"https://www.twilio.com/docs/serverless/functions-assets/visibility\">\"Public\"</a>, as it is pretending to be an external service.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Public Serverless Function visibility setting from the Twilio Console UI\" class=\"richtext-image left\" height=\"539\" src=\"https://assets.cdn.prod.twilio.com/images/tC-MMkRDe2YRQ7MgekGi1I4xzG2-3nhWVOcF_h30Leeb5j.width-500.png\" width=\"500\" /></p>\n<p><strong>How is it decrypting?</strong></p>\n<p>At the top, you <a href=\"https://www.twilio.com/docs/serverless/functions-assets/client#getfunctions\">import</a> <code>AES</code> functions again and define the <code>secret_key</code> as a variable.</p>\n<p>Then you call <code>decrypt</code> on the information that was previously encrypted:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">const last4card = AES.decrypt(event.encryptedCardDigits, secret_key)\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h2>Additional Configuration</h2>\n<h3>Phone Number Webhook</h3>\n<p>For the sake of simplicity, connect this Function directly to a Phone Number.</p>\n<p>To configure the Phone Number:</p>\n<ol>\n<li>From the Twilio Console, navigate to the <strong><a href=\"https://www.twilio.com/console/phone-numbers/\">Phone Numbers</a></strong><a href=\"https://www.twilio.com/console/phone-numbers/\"> section</a></li>\n<li>Select your phone number, then scroll to the <strong>Voice &amp; Fax</strong> section</li>\n<li>Set the <code>encrypted-gather</code> Function as the <strong>A call comes in</strong> webhook under <strong>Voice Configuration</strong></li>\n<li><strong>Save</strong> changes</li>\n</ol>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Voice Configuration &quot;A call comes in&quot; webhook set to encrypted-gather Function\" class=\"richtext-image full-width\" height=\"162\" src=\"https://assets.cdn.prod.twilio.com/images/Nl3bWTO5bUhq136qP6UbzwSqiB6TwDtjMrSqbUQwD1jAjs.width-800.png\" width=\"800\" /></p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--info\">\n  <span alt=\"info message about a Twilio product\" class=\"docs-note-icon docs-note-icon--info\" title=\"info icon\"></span>\n  <p>If you hope to trigger this from Twilio Studio, check out <a href=\"https://www.twilio.com/blog/hiding-pii-phi-from-studio\">this blog post</a> to learn more about how to incorporate this solution securely with Studio.</p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h3>Enable PCI Mode</h3>\n<p>Almost done! You\u2019ve secured the Functions, but there\u2019s still one more area where Twilio retains gathered digits in plain-text \u2013 <a href=\"https://www.twilio.com/docs/voice/troubleshooting#product-specific-logs\">Voice call logs</a>.</p>\n<p>Below is a screenshot from the Twilio Console for an inbound call with the encrypted &lt;Gather&gt; solution implemented. Even though Functions secured the data, Voice hasn\u2019t.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Plain-text digits from Gather TwiML in the Twilio Voice Call log\" class=\"richtext-image left\" height=\"288\" src=\"https://assets.cdn.prod.twilio.com/images/iyLeMkQY_5uzYieev6DGSU3eQXOWWirhYe12Q9hLxQ2wqX.width-500_zjiMq9p.png\" width=\"500\" /></p>\n<p>There\u2019s only one way to prevent this data from being displayed in the Call log, and that\u2019s with <a href=\"https://www.twilio.com/docs/voice/tutorials/how-to-capture-payment-during-a-voice-call-generic-pay-connector#1-enable-pci-mode\">PCI Mode</a>. Enabling PCI Mode on your account will <strong>redact</strong> all data captured from any &lt;Gather&gt; operation.</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Redacted digits from Gather TwiML in Voice Call log\" class=\"richtext-image left\" height=\"300\" src=\"https://assets.cdn.prod.twilio.com/images/L3RI7I1nBRFlNgm_bHg7J6_6Kr-v93j1jLn-uJEm-gl92S.width-500_GMSNjWB.png\" width=\"500\" /></p>\n</div>\n<div class=\"block-warning_danger\">\n\n\n<div class=\"docs-note docs-note--warning\">\n  <span alt=\"warning message about a Twilio product\" class=\"docs-note-icon docs-note-icon--warning\" title=\"warning icon\"></span>\n  <p><strong>Enabling PCI Mode on an account is a one-way street. Once it\u2019s on, you won\u2019t be able to turn it off. Redaction may make troubleshooting Voice issues more challenging.</strong></p>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<p>If you\u2019re serious about capturing sensitive information securely...</p>\n<ol>\n<li>Navigate to the Twilio <a href=\"https://www.twilio.com/console/voice/settings\">Voice Settings</a> in the Twilio Console. (In the left navigation pane, click on <strong>Voice &gt; Settings &gt; General</strong>.)</li>\n<li>Click on the <strong>Enable PCI Mode</strong> button.</li>\n<li><strong>Save</strong> changes.</li>\n</ol>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Programmable Voice Setting for enabling PCI Mode in the Twilio Console UI\" class=\"richtext-image full-width\" height=\"256\" src=\"https://assets.cdn.prod.twilio.com/images/T9JlIt9gaK-uGvsBD_ikYzWSFe0WrYYAsNkkn9X3ZMw8Nu.width-800.png\" width=\"800\" /></p>\n<h2>Make a call</h2>\n<p>Now it\u2019s the moment of truth\u2014it\u2019s time to place a test call to the phone number.</p>\n<p>From here, there are two paths to take.</p>\n<p>If you enter <code>1234</code> as the last 4 digits of your \u201ccredit card\u201d and <code>4321</code> as the unique PIN, you\u2019ll hear some \u201cdummy\u201d account information returned on the call. This is an example of a <strong>successful</strong> API response.</p>\n<p>If you enter any other digits, it will behave as though you aren\u2019t a known user and return a <code>404</code> response. This is an example of an <strong>unsuccessful</strong> request, which will log an error to the Twilio Debugger.</p>\n<h2>How do I know it worked?</h2>\n<p>Follow the unsuccessful path and take a look at your <a href=\"https://www.twilio.com/console/debugger\">Error log in the Twilio Console</a>.</p>\n<p>For the <code>404</code> error response, you\u2019ll find an <a href=\"https://www.twilio.com/docs/api/errors/82005\">82005 Error from Functions</a> with the following details:</p>\n<p><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Encrypted request parameters (32-character encrypted PIN and encrypted last 4 digits of card) from Twilio Function debugger error log\" class=\"richtext-image left\" height=\"342\" src=\"https://assets.cdn.prod.twilio.com/images/KSXZilCNkZgfSEpa6SPoVDJWnXuqG6yKHU5oXpTZAhEl6o.width-500.png\" width=\"500\" /></p>\n<p>This is good. Without the encryption, an unsuccessful response would have logged those variables in plain-text. But now the data will log in its safer, encrypted form.</p>\n<p>You can also check <a href=\"https://console.twilio.com/us1/monitor/logs/calls?frameUrl=%2Fconsole%2Fvoice%2Fcalls%2Flogs%3Fx-target-region%3Dus1\">your Call log</a> to confirm the digits show <code>*REDACTED*</code> there as well.</p>\n<h2>Is this secure?</h2>\n<p>Following this tutorial (including the optional PCI Mode steps) would prevent the data from logging in plain-text anywhere within Twilio\u2019s ecosystem, and it would prevent anyone at Twilio from being able to decrypt your sensitive data \u2013 making this an improvement over the default.</p>\n<p>However, the secret key used for encryption and decryption is stored as an Environment Variable on the Service, meaning users to whom you grant Twilio Functions access would be able to extract the key and potentially go through the effort to decrypt the values.</p>\n<h2>Final Recommendation</h2>\n<p>If you are making modifications to the sample code provided, please keep in mind that <a href=\"https://www.twilio.com/docs/serverless/api/resource/logs\">Functions retain console warnings and errors</a> within internal Twilio systems and in the <a href=\"https://www.twilio.com/console/debugger\">Twilio Debugger</a> <a href=\"https://www.twilio.com/docs/serverless/api/resource/logs#debugger-and-webhooks\">for some time</a>.</p>\n<p>Do not use any of the following console logging methods with any sensitive, unencrypted data:</p>\n</div>\n<div class=\"block-markdown\">\n\n<div class=\"markdown\">\n    <div class=\"language-js\"><pre class=\"twlo-code language-js\"><code class=\"language-js\">console.log()\nconsole.warn()\nconsole.error()\n</code></pre></div>\n</div>\n</div>\n<div class=\"block-rich_text\">\n\n<h2>Conclusion</h2>\n<p>In this lesson, you learned how you can protect data collected from &lt;Gather&gt; TwiML with encryption via a Serverless Function and redaction through Voice PCI Mode.</p>\n<p>If you want to collect payments from your callers, consider the fully PCI-compliant <a href=\"https://www.twilio.com/docs/voice/twiml/pay\">Twilio &lt;Pay&gt;</a> feature.</p>\n<p>To learn more about PCI compliance at Twilio, check out <a href=\"https://www.twilio.com/en-us/pci-compliance\">the documentation</a> and responsibility matrix.</p>\n<p>Users trust you to keep their sensitive information private. Make sure you respect and retain that trust by doing all you can to secure the data you process.</p>\n<p><em>Bry Schinina is a developer and educator who deeply appreciates when companies don\u2019t expose private information. She works as Tech Lead and Sr. Technical Account Manager at Twilio, solving complex problems and helping organizations succeed with their digital engagement platform. She can be reached at bschinina [at] twilio.com.</em></p>\n</div>"
    },
    "authors": [
      {
        "name": "Bry Schinina"
      }
    ],
    "author": "Bry Schinina",
    "author_detail": {
      "name": "Bry Schinina"
    },
    "published": "Wed, 10 Jan 2024 20:18:49 +0000",
    "published_parsed": [
      2024,
      1,
      10,
      20,
      18,
      49,
      2,
      10,
      0
    ],
    "id": "https://www.twilio.com/blog/protect-twilio-voice-input-encryption-redaction",
    "guidislink": false,
    "tags": [
      {
        "term": "Developers Drawing The Owl",
        "scheme": null,
        "label": null
      }
    ]
  },
  "XING": {
    "title": "Protecting sensitive data in Elixir GenServers",
    "xmlUrl": "https://tech.xing.com/feed",
    "htmlUrl": "https://tech.xing.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.new-work.se/feed",
      "value": "Protecting sensitive data in Elixir GenServers"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.new-work.se/protecting-sensitive-data-in-elixir-genservers-fac4a8b0ae15?source=rss----35cb8c78d3cf---4"
      }
    ],
    "link": "https://tech.new-work.se/protecting-sensitive-data-in-elixir-genservers-fac4a8b0ae15?source=rss----35cb8c78d3cf---4",
    "id": "https://medium.com/p/fac4a8b0ae15",
    "guidislink": false,
    "authors": [
      {
        "name": "Gabriel Pereira"
      }
    ],
    "author": "Gabriel Pereira",
    "author_detail": {
      "name": "Gabriel Pereira"
    },
    "published": "Tue, 28 Nov 2023 17:07:43 GMT",
    "published_parsed": [
      2023,
      11,
      28,
      17,
      7,
      43,
      1,
      332,
      0
    ],
    "updated": "2023-11-29T09:32:21.598Z",
    "updated_parsed": [
      2023,
      11,
      29,
      9,
      32,
      21,
      2,
      333,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://tech.new-work.se/feed",
        "value": "<p>In Elixir, <a href=\"https://hexdocs.pm/elixir/GenServer.html\">GenServers</a> are a common way to maintain state and handle concurrent processes. However, when these GenServers hold sensitive data, such as credentials or personal information, it\u2019s crucial to ensure this data is protected. Sensitive data, if exposed, can lead to serious security breaches, including data leaks and unauthorized access. These breaches can have far-reaching consequences, such as loss of customer trust, damage to your brand\u2019s reputation, and potential legal liabilities.</p><p>In this blog post, we\u2019ll explore two techniques to protect sensitive data in Elixir GenServers: implementing the Inspect protocol for structs and implementing the format_status/2 callback.</p><p>To illustrate this, let\u2019s take a look at a GenServer that is handling some sensitive data. (I ended up writing a GenServer quite long for a blog post. However, I hope that this example can help to understand the different ways of hiding sensitive data in a GenServer, and the trade-offs involved in each approach)</p><a href=\"https://medium.com/media/47d54a39fa14901582e9be2b477c41cb/href\">https://medium.com/media/47d54a39fa14901582e9be2b477c41cb/href</a><p>Basically this GenServer acts like a diligent security guard managing a special \u201csecurity token\u201d that expires every 15 minutes. It doesn\u2019t wait for the token to expire, but proactively starts a countdown to refresh the token just before expiration. When another process requests the token via the get_security_token function, it ensures the token is valid before handing it over. This creates a seamless cycle of token issuance, countdown, and renewal, ensuring a valid token is always available.</p><pre>\u276f iex security_token_manager.ex<br />Erlang/OTP 26 [erts-14.1] [source] [64-bit] [smp:10:10] [ds:10:10:10] [async-threads:1] [jit]<br /><br />Interactive Elixir (1.15.6) - press Ctrl+C to exit (type h() ENTER for help)<br />iex(1)&gt; {:ok, pid} = SecurityTokenManager.start_link()<br />{:ok, #PID&lt;0.116.0&gt;}<br />iex(2)&gt; SecurityTokenManager.get_security_token()<br />&quot;8QVrN1ohPPdiWHfnmEr+ln4VQ4Y=&quot;</pre><p>While it effectively manages the lifecycle of security tokens, it does have a potential security concern. The GenServer stores sensitive data, such as the access_key, secret_access, and security_token, in its state. This data could potentially be leaked through logging tools when some error is raised for\u00a0example.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BWqtEpR1YYuOL-VrRxc9TA.png\" /><figcaption>Error log output from the SecurityTokenManager GenServer. The server is terminating due to a RuntimeError that occurred while trying to fetch a security token. The error details, including the function calls leading to the error and the state that reveals sensitive data, are displayed.</figcaption></figure><p>Or via the\u00a0:sys.get_status/1 function, which can access the state of a running\u00a0process.</p><pre>iex(3)&gt; :sys.get_status(pid)<br />{:status, #PID&lt;0.116.0&gt;, {:module, :gen_server},<br /> [<br />   [<br />     &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />     &quot;$ancestors&quot;: [#PID&lt;0.115.0&gt;, #PID&lt;0.107.0&gt;]<br />   ],<br />   :running,<br />   #PID&lt;0.115.0&gt;,<br />   [],<br />   [<br />     header: ~c&quot;Status for generic server Elixir.SecurityTokenManager&quot;,<br />     data: [<br />       {~c&quot;Status&quot;, :running},<br />       {~c&quot;Parent&quot;, #PID&lt;0.115.0&gt;},<br />       {~c&quot;Logged events&quot;, []}<br />     ],<br />     data: [<br />       {~c&quot;State&quot;,<br />        %SecurityTokenManager{<br />          access_key: &quot;my-access-key&quot;,<br />          secret_access: &quot;my-secret-access&quot;,<br />          security_token: &quot;ZjhkWWzemgvCMZXwIit+a/00FHw=&quot;,<br />          expires_at: ~U[2023-11-26 15:05:49.494781Z]<br />        }}<br />     ]<br />   ]<br /> ]}</pre><p>This could lead to unauthorized access if the leaked information falls into the wrong hands. Therefore, it\u2019s crucial to ensure that sensitive data stored in a GenServer\u2019s state is adequately protected.</p><h3>Implementing the format_status/2 callback</h3><p>The format_status/2 callback provides a way to protect sensitive data in GenServers. This callback is used to provide a custom representation of the GenServer\u2019s state when debugging or introspecting the\u00a0process.</p><p>By default, the format_status/2 callback returns all the state data. To protect sensitive data, we can implement this callback to filter out or obfuscate the sensitive parts of the\u00a0state.</p><p>Here\u2019s how we can implement the format_status/2 callback in our GenServer:</p><pre>def format_status(_reason, [pdict, state]) do<br />  {:ok,<br />    [<br />      pdict,<br />      %{<br />        state<br />        | access_key: &quot;&lt;sensitive_data&gt;&quot;,<br />          secret_access: &quot;&lt;sensitive_data&gt;&quot;,<br />          security_token: &quot;&lt;sensitive_data&gt;&quot;<br />      }<br />    ]}<br />end</pre><p>So, when the\u00a0:sys.get_status/1 is called we'll have a response that does not display any sensitive data.</p><pre>iex(4)&gt; :sys.get_status(pid)<br />{:status, #PID&lt;0.116.0&gt;, {:module, :gen_server},<br /> [<br />   [<br />     &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />     &quot;$ancestors&quot;: [#PID&lt;0.115.0&gt;, #PID&lt;0.107.0&gt;]<br />   ],<br />   :running,<br />   #PID&lt;0.115.0&gt;,<br />   [],<br />   [<br />     header: ~c&quot;Status for generic server Elixir.SecurityTokenManager&quot;,<br />     data: [<br />       {~c&quot;Status&quot;, :running},<br />       {~c&quot;Parent&quot;, #PID&lt;0.115.0&gt;},<br />       {~c&quot;Logged events&quot;, []}<br />     ],<br />     ok: [<br />       [<br />         &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />         &quot;$ancestors&quot;: [#PID&lt;0.115.0&gt;, #PID&lt;0.107.0&gt;]<br />       ],<br />       %SecurityTokenManager{<br />         access_key: &quot;&lt;sensitive_data&gt;&quot;,<br />         secret_access: &quot;&lt;sensitive_data&gt;&quot;,<br />         security_token: &quot;&lt;sensitive_data&gt;&quot;,<br />         expires_at: ~U[2023-11-26 16:59:47.764327Z]<br />       }<br />     ]<br />   ]<br /> ]}</pre><p>This is certainly an improvement, isn\u2019t it? However, one concern that arises is that sensitive data can still be accessed via the\u00a0:sys.get_state/1 function, even with the implementation of format_status/2.</p><pre>iex(5)&gt; :sys.get_state(pid)<br />%SecurityTokenManager{<br />  access_key: &quot;my-access-key&quot;,<br />  secret_access: &quot;my-secret-access&quot;,<br />  security_token: &quot;fZWO+Dym+bEJ9kw8E1nLNryT5m0=&quot;,<br />  expires_at: ~U[2023-11-26 17:16:47.936304Z]<br />}</pre><p>The next section will delve into how to prevent this\u00a0issue.</p><h3>Implementing or deriving the Inspect protocol for\u00a0structs</h3><p>The Inspect protocol controls how data structures are converted to strings for printing. By default, when a struct is printed, all of its data is exposed. So, again this can lead to sensitive data being accidentally logged or displayed. To prevent this, we can implement the Inspect protocol for our struct to control how it is\u00a0printed.</p><pre>defimpl Inspect, for: SecurityTokenManager do<br />  def inspect(%SecurityTokenManager{} = state, opts) do<br />    Inspect.Map.inspect(<br />      %{<br />        access_key: &quot;&lt;redacted&gt;&quot;,<br />        secret_access: &quot;&lt;redacted&gt;&quot;,<br />        security_token: &quot;&lt;redacted&gt;&quot;,<br />        expires_at: state.expires_at<br />      },<br />      opts<br />    )<br />  end<br />end</pre><p>With the implementation of the Inspect protocol now established, we can achieve the same structured output for both\u00a0:sys.get_state/1 and\u00a0:sys.get_status/1 functions.</p><pre>iex(6)&gt; :sys.get_state(pid)<br />%{<br />  access_key: &quot;&lt;redacted&gt;&quot;,<br />  secret_access: &quot;&lt;redacted&gt;&quot;,<br />  security_token: &quot;&lt;redacted&gt;&quot;,<br />  expires_at: ~U[2023-11-26 21:37:53.396092Z]<br />}</pre><pre>iex(7)&gt; :sys.get_status(pid)<br />{:status, #PID&lt;0.119.0&gt;, {:module, :gen_server},<br /> [<br />   [<br />     &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />     &quot;$ancestors&quot;: [#PID&lt;0.118.0&gt;, #PID&lt;0.110.0&gt;]<br />   ],<br />   :running,<br />   #PID&lt;0.118.0&gt;,<br />   [],<br />   [<br />     header: ~c&quot;Status for generic server Elixir.SecurityTokenManager&quot;,<br />     data: [<br />       {~c&quot;Status&quot;, :running},<br />       {~c&quot;Parent&quot;, #PID&lt;0.118.0&gt;},<br />       {~c&quot;Logged events&quot;, []}<br />     ],<br />     ok: [<br />       [<br />         &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />         &quot;$ancestors&quot;: [#PID&lt;0.118.0&gt;, #PID&lt;0.110.0&gt;]<br />       ],<br />       %{<br />         access_key: &quot;&lt;redacted&gt;&quot;,<br />         secret_access: &quot;&lt;redacted&gt;&quot;,<br />         security_token: &quot;&lt;redacted&gt;&quot;,<br />         expires_at: ~U[2023-11-26 21:37:53.396092Z]<br />       }<br />     ]<br />   ]<br /> ]}</pre><p>As stated in the subtitle, an alternative method involves deriving the Inspect protocol. The\u00a0:only and\u00a0:except options can be utilized with @derive to determine which fields should be displayed and which should not. For simplicity, we\u2019ll use the\u00a0:only option in this instance.</p><pre>@derive {Inspect, only: [:expires_at]}<br />defstruct [:access_key, :secret_access, :security_token, :expires_at]</pre><p>In this method, only the\u00a0:expires_at will be visible. The rest of the fields will not just have their values hidden, but their keys will be completely omitted as\u00a0well.</p><pre>iex(8)&gt; :sys.get_state(pid)<br />#SecurityTokenManager&lt;expires_at: ~U[2023-11-26 22:42:56.998354Z], ...&gt;</pre><pre>iex(9)&gt; :sys.get_status(pid)<br />{:status, #PID&lt;0.119.0&gt;, {:module, :gen_server},<br /> [<br />   [<br />     &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />     &quot;$ancestors&quot;: [#PID&lt;0.118.0&gt;, #PID&lt;0.110.0&gt;]<br />   ],<br />   :running,<br />   #PID&lt;0.118.0&gt;,<br />   [],<br />   [<br />     header: ~c&quot;Status for generic server Elixir.SecurityTokenManager&quot;,<br />     data: [<br />       {~c&quot;Status&quot;, :running},<br />       {~c&quot;Parent&quot;, #PID&lt;0.118.0&gt;},<br />       {~c&quot;Logged events&quot;, []}<br />     ],<br />     data: [<br />       {~c&quot;State&quot;,<br />        #SecurityTokenManager&lt;expires_at: ~U[2023-11-26 22:43:57.000550Z], ...&gt;}<br />     ]<br />   ]<br /> ]}</pre><h3>Conclusion</h3><p>This blog post has explored some techniques to protect sensitive data in Elixir GenServers. It has shown how to implement or derive the Inspect protocol for structs, and how to implement the format_status/2 callback for GenServer,\u00a0:gen_event or\u00a0:gen_statem processes holding sensitive data. These techniques can help prevent or limit the exposure of sensitive data in logs, error reports, or terminal outputs, which can compromise the security and privacy of the application and its\u00a0users.</p><p>I hope you have found this useful and informative, and I encourage you to try these techniques in your own projects. If you have any questions or feedback, please feel free to leave a comment\u00a0below.</p><h3>References</h3><ul><li><a href=\"https://erlef.github.io/security-wg/secure_coding_and_deployment_hardening/sensitive_data.html\">Protecting sensitive data | EEF Security WG (erlef.github.io)</a></li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fac4a8b0ae15\" width=\"1\" /><hr /><p><a href=\"https://tech.new-work.se/protecting-sensitive-data-in-elixir-genservers-fac4a8b0ae15\">Protecting sensitive data in Elixir GenServers</a> was originally published in <a href=\"https://tech.new-work.se\">New Work Development</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>In Elixir, <a href=\"https://hexdocs.pm/elixir/GenServer.html\">GenServers</a> are a common way to maintain state and handle concurrent processes. However, when these GenServers hold sensitive data, such as credentials or personal information, it\u2019s crucial to ensure this data is protected. Sensitive data, if exposed, can lead to serious security breaches, including data leaks and unauthorized access. These breaches can have far-reaching consequences, such as loss of customer trust, damage to your brand\u2019s reputation, and potential legal liabilities.</p><p>In this blog post, we\u2019ll explore two techniques to protect sensitive data in Elixir GenServers: implementing the Inspect protocol for structs and implementing the format_status/2 callback.</p><p>To illustrate this, let\u2019s take a look at a GenServer that is handling some sensitive data. (I ended up writing a GenServer quite long for a blog post. However, I hope that this example can help to understand the different ways of hiding sensitive data in a GenServer, and the trade-offs involved in each approach)</p><a href=\"https://medium.com/media/47d54a39fa14901582e9be2b477c41cb/href\">https://medium.com/media/47d54a39fa14901582e9be2b477c41cb/href</a><p>Basically this GenServer acts like a diligent security guard managing a special \u201csecurity token\u201d that expires every 15 minutes. It doesn\u2019t wait for the token to expire, but proactively starts a countdown to refresh the token just before expiration. When another process requests the token via the get_security_token function, it ensures the token is valid before handing it over. This creates a seamless cycle of token issuance, countdown, and renewal, ensuring a valid token is always available.</p><pre>\u276f iex security_token_manager.ex<br />Erlang/OTP 26 [erts-14.1] [source] [64-bit] [smp:10:10] [ds:10:10:10] [async-threads:1] [jit]<br /><br />Interactive Elixir (1.15.6) - press Ctrl+C to exit (type h() ENTER for help)<br />iex(1)&gt; {:ok, pid} = SecurityTokenManager.start_link()<br />{:ok, #PID&lt;0.116.0&gt;}<br />iex(2)&gt; SecurityTokenManager.get_security_token()<br />&quot;8QVrN1ohPPdiWHfnmEr+ln4VQ4Y=&quot;</pre><p>While it effectively manages the lifecycle of security tokens, it does have a potential security concern. The GenServer stores sensitive data, such as the access_key, secret_access, and security_token, in its state. This data could potentially be leaked through logging tools when some error is raised for\u00a0example.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BWqtEpR1YYuOL-VrRxc9TA.png\" /><figcaption>Error log output from the SecurityTokenManager GenServer. The server is terminating due to a RuntimeError that occurred while trying to fetch a security token. The error details, including the function calls leading to the error and the state that reveals sensitive data, are displayed.</figcaption></figure><p>Or via the\u00a0:sys.get_status/1 function, which can access the state of a running\u00a0process.</p><pre>iex(3)&gt; :sys.get_status(pid)<br />{:status, #PID&lt;0.116.0&gt;, {:module, :gen_server},<br /> [<br />   [<br />     &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />     &quot;$ancestors&quot;: [#PID&lt;0.115.0&gt;, #PID&lt;0.107.0&gt;]<br />   ],<br />   :running,<br />   #PID&lt;0.115.0&gt;,<br />   [],<br />   [<br />     header: ~c&quot;Status for generic server Elixir.SecurityTokenManager&quot;,<br />     data: [<br />       {~c&quot;Status&quot;, :running},<br />       {~c&quot;Parent&quot;, #PID&lt;0.115.0&gt;},<br />       {~c&quot;Logged events&quot;, []}<br />     ],<br />     data: [<br />       {~c&quot;State&quot;,<br />        %SecurityTokenManager{<br />          access_key: &quot;my-access-key&quot;,<br />          secret_access: &quot;my-secret-access&quot;,<br />          security_token: &quot;ZjhkWWzemgvCMZXwIit+a/00FHw=&quot;,<br />          expires_at: ~U[2023-11-26 15:05:49.494781Z]<br />        }}<br />     ]<br />   ]<br /> ]}</pre><p>This could lead to unauthorized access if the leaked information falls into the wrong hands. Therefore, it\u2019s crucial to ensure that sensitive data stored in a GenServer\u2019s state is adequately protected.</p><h3>Implementing the format_status/2 callback</h3><p>The format_status/2 callback provides a way to protect sensitive data in GenServers. This callback is used to provide a custom representation of the GenServer\u2019s state when debugging or introspecting the\u00a0process.</p><p>By default, the format_status/2 callback returns all the state data. To protect sensitive data, we can implement this callback to filter out or obfuscate the sensitive parts of the\u00a0state.</p><p>Here\u2019s how we can implement the format_status/2 callback in our GenServer:</p><pre>def format_status(_reason, [pdict, state]) do<br />  {:ok,<br />    [<br />      pdict,<br />      %{<br />        state<br />        | access_key: &quot;&lt;sensitive_data&gt;&quot;,<br />          secret_access: &quot;&lt;sensitive_data&gt;&quot;,<br />          security_token: &quot;&lt;sensitive_data&gt;&quot;<br />      }<br />    ]}<br />end</pre><p>So, when the\u00a0:sys.get_status/1 is called we'll have a response that does not display any sensitive data.</p><pre>iex(4)&gt; :sys.get_status(pid)<br />{:status, #PID&lt;0.116.0&gt;, {:module, :gen_server},<br /> [<br />   [<br />     &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />     &quot;$ancestors&quot;: [#PID&lt;0.115.0&gt;, #PID&lt;0.107.0&gt;]<br />   ],<br />   :running,<br />   #PID&lt;0.115.0&gt;,<br />   [],<br />   [<br />     header: ~c&quot;Status for generic server Elixir.SecurityTokenManager&quot;,<br />     data: [<br />       {~c&quot;Status&quot;, :running},<br />       {~c&quot;Parent&quot;, #PID&lt;0.115.0&gt;},<br />       {~c&quot;Logged events&quot;, []}<br />     ],<br />     ok: [<br />       [<br />         &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />         &quot;$ancestors&quot;: [#PID&lt;0.115.0&gt;, #PID&lt;0.107.0&gt;]<br />       ],<br />       %SecurityTokenManager{<br />         access_key: &quot;&lt;sensitive_data&gt;&quot;,<br />         secret_access: &quot;&lt;sensitive_data&gt;&quot;,<br />         security_token: &quot;&lt;sensitive_data&gt;&quot;,<br />         expires_at: ~U[2023-11-26 16:59:47.764327Z]<br />       }<br />     ]<br />   ]<br /> ]}</pre><p>This is certainly an improvement, isn\u2019t it? However, one concern that arises is that sensitive data can still be accessed via the\u00a0:sys.get_state/1 function, even with the implementation of format_status/2.</p><pre>iex(5)&gt; :sys.get_state(pid)<br />%SecurityTokenManager{<br />  access_key: &quot;my-access-key&quot;,<br />  secret_access: &quot;my-secret-access&quot;,<br />  security_token: &quot;fZWO+Dym+bEJ9kw8E1nLNryT5m0=&quot;,<br />  expires_at: ~U[2023-11-26 17:16:47.936304Z]<br />}</pre><p>The next section will delve into how to prevent this\u00a0issue.</p><h3>Implementing or deriving the Inspect protocol for\u00a0structs</h3><p>The Inspect protocol controls how data structures are converted to strings for printing. By default, when a struct is printed, all of its data is exposed. So, again this can lead to sensitive data being accidentally logged or displayed. To prevent this, we can implement the Inspect protocol for our struct to control how it is\u00a0printed.</p><pre>defimpl Inspect, for: SecurityTokenManager do<br />  def inspect(%SecurityTokenManager{} = state, opts) do<br />    Inspect.Map.inspect(<br />      %{<br />        access_key: &quot;&lt;redacted&gt;&quot;,<br />        secret_access: &quot;&lt;redacted&gt;&quot;,<br />        security_token: &quot;&lt;redacted&gt;&quot;,<br />        expires_at: state.expires_at<br />      },<br />      opts<br />    )<br />  end<br />end</pre><p>With the implementation of the Inspect protocol now established, we can achieve the same structured output for both\u00a0:sys.get_state/1 and\u00a0:sys.get_status/1 functions.</p><pre>iex(6)&gt; :sys.get_state(pid)<br />%{<br />  access_key: &quot;&lt;redacted&gt;&quot;,<br />  secret_access: &quot;&lt;redacted&gt;&quot;,<br />  security_token: &quot;&lt;redacted&gt;&quot;,<br />  expires_at: ~U[2023-11-26 21:37:53.396092Z]<br />}</pre><pre>iex(7)&gt; :sys.get_status(pid)<br />{:status, #PID&lt;0.119.0&gt;, {:module, :gen_server},<br /> [<br />   [<br />     &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />     &quot;$ancestors&quot;: [#PID&lt;0.118.0&gt;, #PID&lt;0.110.0&gt;]<br />   ],<br />   :running,<br />   #PID&lt;0.118.0&gt;,<br />   [],<br />   [<br />     header: ~c&quot;Status for generic server Elixir.SecurityTokenManager&quot;,<br />     data: [<br />       {~c&quot;Status&quot;, :running},<br />       {~c&quot;Parent&quot;, #PID&lt;0.118.0&gt;},<br />       {~c&quot;Logged events&quot;, []}<br />     ],<br />     ok: [<br />       [<br />         &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />         &quot;$ancestors&quot;: [#PID&lt;0.118.0&gt;, #PID&lt;0.110.0&gt;]<br />       ],<br />       %{<br />         access_key: &quot;&lt;redacted&gt;&quot;,<br />         secret_access: &quot;&lt;redacted&gt;&quot;,<br />         security_token: &quot;&lt;redacted&gt;&quot;,<br />         expires_at: ~U[2023-11-26 21:37:53.396092Z]<br />       }<br />     ]<br />   ]<br /> ]}</pre><p>As stated in the subtitle, an alternative method involves deriving the Inspect protocol. The\u00a0:only and\u00a0:except options can be utilized with @derive to determine which fields should be displayed and which should not. For simplicity, we\u2019ll use the\u00a0:only option in this instance.</p><pre>@derive {Inspect, only: [:expires_at]}<br />defstruct [:access_key, :secret_access, :security_token, :expires_at]</pre><p>In this method, only the\u00a0:expires_at will be visible. The rest of the fields will not just have their values hidden, but their keys will be completely omitted as\u00a0well.</p><pre>iex(8)&gt; :sys.get_state(pid)<br />#SecurityTokenManager&lt;expires_at: ~U[2023-11-26 22:42:56.998354Z], ...&gt;</pre><pre>iex(9)&gt; :sys.get_status(pid)<br />{:status, #PID&lt;0.119.0&gt;, {:module, :gen_server},<br /> [<br />   [<br />     &quot;$initial_call&quot;: {SecurityTokenManager, :init, 1},<br />     &quot;$ancestors&quot;: [#PID&lt;0.118.0&gt;, #PID&lt;0.110.0&gt;]<br />   ],<br />   :running,<br />   #PID&lt;0.118.0&gt;,<br />   [],<br />   [<br />     header: ~c&quot;Status for generic server Elixir.SecurityTokenManager&quot;,<br />     data: [<br />       {~c&quot;Status&quot;, :running},<br />       {~c&quot;Parent&quot;, #PID&lt;0.118.0&gt;},<br />       {~c&quot;Logged events&quot;, []}<br />     ],<br />     data: [<br />       {~c&quot;State&quot;,<br />        #SecurityTokenManager&lt;expires_at: ~U[2023-11-26 22:43:57.000550Z], ...&gt;}<br />     ]<br />   ]<br /> ]}</pre><h3>Conclusion</h3><p>This blog post has explored some techniques to protect sensitive data in Elixir GenServers. It has shown how to implement or derive the Inspect protocol for structs, and how to implement the format_status/2 callback for GenServer,\u00a0:gen_event or\u00a0:gen_statem processes holding sensitive data. These techniques can help prevent or limit the exposure of sensitive data in logs, error reports, or terminal outputs, which can compromise the security and privacy of the application and its\u00a0users.</p><p>I hope you have found this useful and informative, and I encourage you to try these techniques in your own projects. If you have any questions or feedback, please feel free to leave a comment\u00a0below.</p><h3>References</h3><ul><li><a href=\"https://erlef.github.io/security-wg/secure_coding_and_deployment_hardening/sensitive_data.html\">Protecting sensitive data | EEF Security WG (erlef.github.io)</a></li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fac4a8b0ae15\" width=\"1\" /><hr /><p><a href=\"https://tech.new-work.se/protecting-sensitive-data-in-elixir-genservers-fac4a8b0ae15\">Protecting sensitive data in Elixir GenServers</a> was originally published in <a href=\"https://tech.new-work.se\">New Work Development</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Wemake.services": {
    "title": "5 Steps to greater UX",
    "xmlUrl": "https://medium.com/feed/wemake-services",
    "htmlUrl": "https://medium.com/wemake-services",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/wemake-services",
      "value": "5 Steps to greater UX"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/wemake-services/5-steps-to-greater-ux-5e54eb4fcaf0?source=rss----3ac85505f67d---4"
      }
    ],
    "link": "https://medium.com/wemake-services/5-steps-to-greater-ux-5e54eb4fcaf0?source=rss----3ac85505f67d---4",
    "id": "https://medium.com/p/5e54eb4fcaf0",
    "guidislink": false,
    "tags": [
      {
        "term": "user-research",
        "scheme": null,
        "label": null
      },
      {
        "term": "user-experience",
        "scheme": null,
        "label": null
      },
      {
        "term": "ux",
        "scheme": null,
        "label": null
      },
      {
        "term": "user-interface",
        "scheme": null,
        "label": null
      },
      {
        "term": "user-experience-design",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Ellina Morits"
      }
    ],
    "author": "Ellina Morits",
    "author_detail": {
      "name": "Ellina Morits"
    },
    "published": "Sun, 10 Sep 2017 13:16:51 GMT",
    "published_parsed": [
      2017,
      9,
      10,
      13,
      16,
      51,
      6,
      253,
      0
    ],
    "updated": "2017-09-10T13:16:51.276Z",
    "updated_parsed": [
      2017,
      9,
      10,
      13,
      16,
      51,
      6,
      253,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/wemake-services",
        "value": "<p>In this article I will give a quick overview of how to spot UX problems in your product and fix them quickly and effectively.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*K66yGw3xeNw6KjT_YyZo3A.jpeg\" /></figure><h3>UX\u200a\u2014\u200awhat\u2019s it all\u00a0about?</h3><p>Let\u2019s imagine\u200a\u2014\u200ayou have launched your product and are quite happy with it. And then suddenly you hear everyone talk about UX, which gets you wondering: what is UX? Do I need it? How can I get it\u00a0fast?</p><p>In short, UX stands for user experience and if you have a product, then yes, your users certainly have some kind of experience interacting with it. Does it have to be good? Your choice. But if you want to succeed then it\u2019d better\u00a0be.</p><h3>Getting started\u200a\u2014\u200auncovering the\u00a0issues</h3><p>First of all, you need to have a clear understanding of what your product\u2019s or website\u2019s purpose is. Is it a place for people to get information? Is it where they can buy\u00a0stuff?</p><p>Depending on the answer you can establish performance metrics (ideally, you have done that before launching).</p><p>Now ask yourself: is the current performance measuring up to the set KPIs? This is where you turn to analytics. Analytics would give you a lot to work with\u200a\u2014\u200ausually you will see where the users are falling off or not behaving as expected. At this point the most important thing is to pick the right metric to watch, otherwise you may be fixing what isn\u2019t\u00a0broken.</p><p>While analytics can give you an idea of where things are going wrong, you still need to find out \u2018why\u2019 it is happening. The best way is to invite a few users\u200a\u2014\u200a5 would be enough\u200a\u2014\u200aand watch them use your website. There is a proper way to do user testing and I am not going to dwell on this here. But in short you need to come up with the most common tasks people do on your website and without asking leading questions or interrupting let the participants use the\u00a0website.</p><h3>Making sense of your\u00a0findings</h3><p>Observing your users and listening to them \u2018thinking out loud\u2019 will give you a lot of insight. Be careful in picking participants, though. They should be representative of your target customers, while being diverse\u00a0enough.</p><p>Now it\u2019s time to make sense of your findings. Usability testing would give you answers to the questions that emerged from the data analysis.</p><p>The best recipe for creating great UX is setting clear goals in the beginning, communicating with your users throughout the process and making decisions based on solid research.</p><p>Different products call for different level of expertise. Ideally, you should have an Interaction Designer on your team, who is overseeing user experience. If this is not feasible, start with educating yourself and your team about user experience by simply <a href=\"https://medium.com/wemake-services/books-to-get-you-started-in-ux-742e44d4c56d\">reading books and articles</a>.</p><h3>Fixing the\u00a0issues</h3><p>You might have seen your users struggling during usability testing\u200a\u2014\u200athis is usually a powerful incentive for changes. To fix the problem you need to figure out \u2018why\u2019 things are going wrong. Maybe people can\u2019t find what they are looking for- then it is an Information Architecture problem and you need to reconsider your labelling and navigation, or even the whole site structure.</p><p>If people are abandoning your shopping cart, it could be because they get distracted or the process is too complicated. Those things are very individual and require not only common sense but also research.</p><p>At this stage you need to be careful. Listen to your users but always check whether the new solution is actually solving the\u00a0problem.</p><h3>Prioritizing and testing your hypothesis</h3><p>Now that you have a list of issues to fix along with possible solutions, you need to prioritize. The most efficient way is using a 2x2 matrix. There are several variations of the matrix, use whichever you are most comfortable with. Generally, quick wins would be a good place to\u00a0start.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/415/1*j_lfhCo8CaneSqkICsfoiQ.gif\" /><figcaption>Action Priority Matrix courtesy mindtools.com</figcaption></figure><p>Before setting your mind on any changes, though, test your hypothesis. Again, depending on the problems you have uncovered, you may use various techniques. But assuming you have done your research and came up with good ideas, you should go through another round of usability testing. No need to implement everything in real life\u200a\u2014\u200aprototypes will work just fine, especially if the changes are fundamental.</p><h3>And finally, did it\u00a0work?</h3><p>When the changes are done, you need to go back to the goals you have set. It\u2019s time to dig into analytics and check the metrics. Spotting the changes should be easy since you know what you are looking\u00a0for.</p><p>One quick tip about the metrics to watch\u200a\u2014\u200afor any app or product metrics to watch will be changing over time\u200a\u2014\u200atherefore, be careful in setting goals and working with analytics.</p><p>To wrap it up, user experience is crucial for your success. So why not offer your users a great\u00a0one?</p><p>Subscribe to our blog if you love what we are\u00a0doing:</p><p><a href=\"https://medium.com/wemake-services\">wemake.services</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5e54eb4fcaf0\" width=\"1\" /><hr /><p><a href=\"https://medium.com/wemake-services/5-steps-to-greater-ux-5e54eb4fcaf0\">5 Steps to greater UX</a> was originally published in <a href=\"https://medium.com/wemake-services\">wemake.services</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>In this article I will give a quick overview of how to spot UX problems in your product and fix them quickly and effectively.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*K66yGw3xeNw6KjT_YyZo3A.jpeg\" /></figure><h3>UX\u200a\u2014\u200awhat\u2019s it all\u00a0about?</h3><p>Let\u2019s imagine\u200a\u2014\u200ayou have launched your product and are quite happy with it. And then suddenly you hear everyone talk about UX, which gets you wondering: what is UX? Do I need it? How can I get it\u00a0fast?</p><p>In short, UX stands for user experience and if you have a product, then yes, your users certainly have some kind of experience interacting with it. Does it have to be good? Your choice. But if you want to succeed then it\u2019d better\u00a0be.</p><h3>Getting started\u200a\u2014\u200auncovering the\u00a0issues</h3><p>First of all, you need to have a clear understanding of what your product\u2019s or website\u2019s purpose is. Is it a place for people to get information? Is it where they can buy\u00a0stuff?</p><p>Depending on the answer you can establish performance metrics (ideally, you have done that before launching).</p><p>Now ask yourself: is the current performance measuring up to the set KPIs? This is where you turn to analytics. Analytics would give you a lot to work with\u200a\u2014\u200ausually you will see where the users are falling off or not behaving as expected. At this point the most important thing is to pick the right metric to watch, otherwise you may be fixing what isn\u2019t\u00a0broken.</p><p>While analytics can give you an idea of where things are going wrong, you still need to find out \u2018why\u2019 it is happening. The best way is to invite a few users\u200a\u2014\u200a5 would be enough\u200a\u2014\u200aand watch them use your website. There is a proper way to do user testing and I am not going to dwell on this here. But in short you need to come up with the most common tasks people do on your website and without asking leading questions or interrupting let the participants use the\u00a0website.</p><h3>Making sense of your\u00a0findings</h3><p>Observing your users and listening to them \u2018thinking out loud\u2019 will give you a lot of insight. Be careful in picking participants, though. They should be representative of your target customers, while being diverse\u00a0enough.</p><p>Now it\u2019s time to make sense of your findings. Usability testing would give you answers to the questions that emerged from the data analysis.</p><p>The best recipe for creating great UX is setting clear goals in the beginning, communicating with your users throughout the process and making decisions based on solid research.</p><p>Different products call for different level of expertise. Ideally, you should have an Interaction Designer on your team, who is overseeing user experience. If this is not feasible, start with educating yourself and your team about user experience by simply <a href=\"https://medium.com/wemake-services/books-to-get-you-started-in-ux-742e44d4c56d\">reading books and articles</a>.</p><h3>Fixing the\u00a0issues</h3><p>You might have seen your users struggling during usability testing\u200a\u2014\u200athis is usually a powerful incentive for changes. To fix the problem you need to figure out \u2018why\u2019 things are going wrong. Maybe people can\u2019t find what they are looking for- then it is an Information Architecture problem and you need to reconsider your labelling and navigation, or even the whole site structure.</p><p>If people are abandoning your shopping cart, it could be because they get distracted or the process is too complicated. Those things are very individual and require not only common sense but also research.</p><p>At this stage you need to be careful. Listen to your users but always check whether the new solution is actually solving the\u00a0problem.</p><h3>Prioritizing and testing your hypothesis</h3><p>Now that you have a list of issues to fix along with possible solutions, you need to prioritize. The most efficient way is using a 2x2 matrix. There are several variations of the matrix, use whichever you are most comfortable with. Generally, quick wins would be a good place to\u00a0start.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/415/1*j_lfhCo8CaneSqkICsfoiQ.gif\" /><figcaption>Action Priority Matrix courtesy mindtools.com</figcaption></figure><p>Before setting your mind on any changes, though, test your hypothesis. Again, depending on the problems you have uncovered, you may use various techniques. But assuming you have done your research and came up with good ideas, you should go through another round of usability testing. No need to implement everything in real life\u200a\u2014\u200aprototypes will work just fine, especially if the changes are fundamental.</p><h3>And finally, did it\u00a0work?</h3><p>When the changes are done, you need to go back to the goals you have set. It\u2019s time to dig into analytics and check the metrics. Spotting the changes should be easy since you know what you are looking\u00a0for.</p><p>One quick tip about the metrics to watch\u200a\u2014\u200afor any app or product metrics to watch will be changing over time\u200a\u2014\u200atherefore, be careful in setting goals and working with analytics.</p><p>To wrap it up, user experience is crucial for your success. So why not offer your users a great\u00a0one?</p><p>Subscribe to our blog if you love what we are\u00a0doing:</p><p><a href=\"https://medium.com/wemake-services\">wemake.services</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5e54eb4fcaf0\" width=\"1\" /><hr /><p><a href=\"https://medium.com/wemake-services/5-steps-to-greater-ux-5e54eb4fcaf0\">5 Steps to greater UX</a> was originally published in <a href=\"https://medium.com/wemake-services\">wemake.services</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Finn.no": {
    "title": "Haskell at FINN.no",
    "xmlUrl": "http://tech.finn.no/atom.xml",
    "htmlUrl": "http://tech.finn.no/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://tech.finn.no/atom.xml",
      "value": "Haskell at FINN.no"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.finn.no2018/10/18/haskell-at-finn-no/"
      }
    ],
    "link": "https://tech.finn.no2018/10/18/haskell-at-finn-no/",
    "updated": "2018-10-18T09:00:00+00:00",
    "updated_parsed": [
      2018,
      10,
      18,
      9,
      0,
      0,
      3,
      291,
      0
    ],
    "id": "https://tech.finn.no/2018/10/18/haskell-at-finn-no",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "http://tech.finn.no/atom.xml",
        "value": "<h3 id=\"favorites\">Favorites</h3>\n<p>FINN has this feature where users can mark classified ads as a favorite, making it easy to come back to certain ads later. The feature has been around quite a while, and the systems involved, both frontend and backend were becoming quite hard to maintain. So the AdView-team set out to redesign the whole stack. This blog post will focus on the backend API, which is written in Haskell.</p>\n\n<h3 id=\"haskell\">Haskell</h3>\n<p>Haskell is a purely functional programming language, with a powerful type system. The ability to express intent using types brings correctness, and the composition of a large program as small, independent building blocks makes it easy to reason about the code.</p>\n\n<p>A large ecosystem of production grade libraries are available from <a href=\"https://hackage.haskell.org/\">Hackage</a>. We make use of Servant (API), Aeson (JSON), Hasql (postgres) and many more. Servant is a type-level API, meaning the \u201csum\u201d of all our endpoints become a distinct type. This, in turn, means that\nrefactoring our API gives us heavy compiler assistance. More than once during development, we had the need to do major changes in the endpoints (verbs, paths, request body, responses) and found that once every compilation error was resolved, the new API was working correctly.</p>\n\n<p>To manage external packages, build and test code, we use <a href=\"https://haskellstack.org\">Stack</a>, because of its familiarity to maven, gradle and sbt-users. <code class=\"language-plaintext highlighter-rouge\">stack build</code> will compile the project, <code class=\"language-plaintext highlighter-rouge\">stack test</code> run all the tests. Stack pulls down <a href=\"https://www.haskell.org/ghc/\">Glasgow Haskell Compiler (\u201cGHC\u201d)</a> along with required libraries. It also supports building and running of the final program in Docker.</p>\n\n<p>Now Docker is important, because of the cloud infrastructure in FINN; any technology running in Docker can be used as a new Micro Service.</p>\n\n<h3 id=\"experiences\">Experiences</h3>\n<p>So what are the downsides to using Haskell? Well - there is really only one. We have to have a certain amount of developers, at least in our team, know Haskell. We meet this challenge in three ways. Firstly by doing a Haskell course internally at FINN. 21 of our developers have signed up for an <a href=\"https://www.futurelearn.com/courses/functional-programming-haskell/\">Introductory Haskell Course from the University of Glasgow</a>, secondly we cheated a little by simply recruiting another Haskell developer. And lastly, we will put some effort into the <a href=\"https://www.meetup.com/Oslo-Haskell/\">Oslo Haskell Meetup group</a>, hopefully spawning even more Haskellers.</p>\n\n<p>Really? No more downsides? Well, it should be mentioned that our build-times on Travis CI (self-hosted) are not super-awesome-great. We are currently looking at 8-9 minutes for a complete build (including integration tests). The Stack build tool uses Docker for every task, and some times needs to pull a new version of an image. This hurts build times, but we can live with this as it gives us benefits in terms of isolation.</p>\n\n<p>As for performance, the <a href=\"https://hackage.haskell.org/package/warp\">Warp web server</a> is doing an excellent job of spawning lightweight threads and keeping CPU and memory usage low. An indication of memory and CPU usage is given below. Note that the old API still have way more traffic, so a direct comparison is very unfair!</p>\n\n<figure>\n    <img alt=\"haskell performance as seen by kubernetes\" class=\"center-block\" src=\"http://tech.finn.no/images/2018-10-18-haskell-at-finn-no/performance.png\" title=\"haskell performance as seen by kubernetes\" />\n    <figcaption style=\"text-align: right; font-style: italic;\"><strong>favorite-api</strong> is the new API (Haskell).<br /><strong>classified-favorite-management-server</strong> is the old API (Java, hence the long name).<br />You can barely see the <strong>32 MB</strong> memory footprint of the new API in the graphs!</figcaption>\n</figure>\n\n<h3 id=\"check-it-out\">Check it out</h3>\n<p>We are really looking forward to putting more load on our new API, and doing more Haskell in the future.\nYou can check out the redesign of <a href=\"https://www.finn.no/favoritter\">favorites</a> for yourself.\nAnd if you would like to learn some Haskell, a great starting point is <a href=\"http://learnyouahaskell.com/\">Learn You A Haskell For Great Good</a></p>"
      }
    ],
    "summary": "<h3 id=\"favorites\">Favorites</h3>\n<p>FINN has this feature where users can mark classified ads as a favorite, making it easy to come back to certain ads later. The feature has been around quite a while, and the systems involved, both frontend and backend were becoming quite hard to maintain. So the AdView-team set out to redesign the whole stack. This blog post will focus on the backend API, which is written in Haskell.</p>\n\n<h3 id=\"haskell\">Haskell</h3>\n<p>Haskell is a purely functional programming language, with a powerful type system. The ability to express intent using types brings correctness, and the composition of a large program as small, independent building blocks makes it easy to reason about the code.</p>\n\n<p>A large ecosystem of production grade libraries are available from <a href=\"https://hackage.haskell.org/\">Hackage</a>. We make use of Servant (API), Aeson (JSON), Hasql (postgres) and many more. Servant is a type-level API, meaning the \u201csum\u201d of all our endpoints become a distinct type. This, in turn, means that\nrefactoring our API gives us heavy compiler assistance. More than once during development, we had the need to do major changes in the endpoints (verbs, paths, request body, responses) and found that once every compilation error was resolved, the new API was working correctly.</p>\n\n<p>To manage external packages, build and test code, we use <a href=\"https://haskellstack.org\">Stack</a>, because of its familiarity to maven, gradle and sbt-users. <code class=\"language-plaintext highlighter-rouge\">stack build</code> will compile the project, <code class=\"language-plaintext highlighter-rouge\">stack test</code> run all the tests. Stack pulls down <a href=\"https://www.haskell.org/ghc/\">Glasgow Haskell Compiler (\u201cGHC\u201d)</a> along with required libraries. It also supports building and running of the final program in Docker.</p>\n\n<p>Now Docker is important, because of the cloud infrastructure in FINN; any technology running in Docker can be used as a new Micro Service.</p>\n\n<h3 id=\"experiences\">Experiences</h3>\n<p>So what are the downsides to using Haskell? Well - there is really only one. We have to have a certain amount of developers, at least in our team, know Haskell. We meet this challenge in three ways. Firstly by doing a Haskell course internally at FINN. 21 of our developers have signed up for an <a href=\"https://www.futurelearn.com/courses/functional-programming-haskell/\">Introductory Haskell Course from the University of Glasgow</a>, secondly we cheated a little by simply recruiting another Haskell developer. And lastly, we will put some effort into the <a href=\"https://www.meetup.com/Oslo-Haskell/\">Oslo Haskell Meetup group</a>, hopefully spawning even more Haskellers.</p>\n\n<p>Really? No more downsides? Well, it should be mentioned that our build-times on Travis CI (self-hosted) are not super-awesome-great. We are currently looking at 8-9 minutes for a complete build (including integration tests). The Stack build tool uses Docker for every task, and some times needs to pull a new version of an image. This hurts build times, but we can live with this as it gives us benefits in terms of isolation.</p>\n\n<p>As for performance, the <a href=\"https://hackage.haskell.org/package/warp\">Warp web server</a> is doing an excellent job of spawning lightweight threads and keeping CPU and memory usage low. An indication of memory and CPU usage is given below. Note that the old API still have way more traffic, so a direct comparison is very unfair!</p>\n\n<figure>\n    <img alt=\"haskell performance as seen by kubernetes\" class=\"center-block\" src=\"http://tech.finn.no/images/2018-10-18-haskell-at-finn-no/performance.png\" title=\"haskell performance as seen by kubernetes\" />\n    <figcaption style=\"text-align: right; font-style: italic;\"><strong>favorite-api</strong> is the new API (Haskell).<br /><strong>classified-favorite-management-server</strong> is the old API (Java, hence the long name).<br />You can barely see the <strong>32 MB</strong> memory footprint of the new API in the graphs!</figcaption>\n</figure>\n\n<h3 id=\"check-it-out\">Check it out</h3>\n<p>We are really looking forward to putting more load on our new API, and doing more Haskell in the future.\nYou can check out the redesign of <a href=\"https://www.finn.no/favoritter\">favorites</a> for yourself.\nAnd if you would like to learn some Haskell, a great starting point is <a href=\"http://learnyouahaskell.com/\">Learn You A Haskell For Great Good</a></p>",
    "authors": [
      {
        "name": "Sjur Millidahl",
        "email": ""
      }
    ],
    "author_detail": {
      "name": "Sjur Millidahl",
      "email": ""
    },
    "author": "Sjur Millidahl"
  },
  "Codementor": {
    "title": "How Test Driven Development helps you write better code",
    "xmlUrl": "https://www.codementor.io/tutorial/feed",
    "htmlUrl": "https://www.codementor.io/tutorial",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.codementor.io/community/feed",
      "value": "How Test Driven Development helps you write better code"
    },
    "links": [
      {
        "rel": "alternate",
        "href": "https://www.codementor.io/damianpereira/how-test-driven-development-helps-you-write-better-code-2ces1wuwfn",
        "type": "text/html"
      }
    ],
    "link": "https://www.codementor.io/damianpereira/how-test-driven-development-helps-you-write-better-code-2ces1wuwfn",
    "id": "https://www.codementor.io/damianpereira/how-test-driven-development-helps-you-write-better-code-2ces1wuwfn",
    "guidislink": false,
    "summary": "Short introduction to TDD, and some of it's benefits.",
    "summary_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.codementor.io/community/feed",
      "value": "Short introduction to TDD, and some of it's benefits."
    },
    "updated": "2024-01-12T18:59:06+00:00",
    "updated_parsed": [
      2024,
      1,
      12,
      18,
      59,
      6,
      4,
      12,
      0
    ],
    "published": "2024-01-12T18:59:06+00:00",
    "published_parsed": [
      2024,
      1,
      12,
      18,
      59,
      6,
      4,
      12,
      0
    ],
    "authors": [
      {
        "name": "DamianPereira"
      }
    ],
    "author_detail": {
      "name": "DamianPereira"
    },
    "author": "DamianPereira",
    "tags": [
      {
        "term": "Tdd bdd",
        "scheme": null,
        "label": null
      },
      {
        "term": "Test driven development",
        "scheme": null,
        "label": null
      },
      {
        "term": "Test driven design",
        "scheme": null,
        "label": null
      },
      {
        "term": "Testing",
        "scheme": null,
        "label": null
      },
      {
        "term": "Testing techniques",
        "scheme": null,
        "label": null
      }
    ]
  },
  "Wealthfront": {
    "title": "Unifying Wealthfront\u2019s Transfer Flows: An iOS Engineering Journey",
    "xmlUrl": "http://eng.wealthfront.com/feed/",
    "htmlUrl": "http://eng.wealthfront.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://eng.wealthfront.com/feed/",
      "value": "Unifying Wealthfront\u2019s Transfer Flows: An iOS Engineering Journey"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://eng.wealthfront.com/2023/10/10/unifying-wealthfronts-transfer-flows-an-ios-engineering-journey/"
      }
    ],
    "link": "https://eng.wealthfront.com/2023/10/10/unifying-wealthfronts-transfer-flows-an-ios-engineering-journey/",
    "authors": [
      {
        "email": "parkeramundsen@wealthfront.com"
      }
    ],
    "author": "parkeramundsen@wealthfront.com",
    "author_detail": {
      "email": "parkeramundsen@wealthfront.com"
    },
    "published": "Tue, 10 Oct 2023 20:12:45 +0000",
    "published_parsed": [
      2023,
      10,
      10,
      20,
      12,
      45,
      1,
      283,
      0
    ],
    "tags": [
      {
        "term": "wealthfront engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "infrastructure",
        "scheme": null,
        "label": null
      },
      {
        "term": "ios",
        "scheme": null,
        "label": null
      },
      {
        "term": "transfers",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://eng.wealthfront.com/?p=3147",
    "guidislink": false,
    "summary": "Introduction For over a year, the Cash team at Wealthfront has been working towards a consistent transfer experience across the Wealthfront ecosystem. Before beginning this project we had a number of separate transfer flows that each had their distinct user experience. Each transfer flow was built with its own set of UI components, models, and... <a class=\"moretag\" href=\"https://eng.wealthfront.com/2023/10/10/unifying-wealthfronts-transfer-flows-an-ios-engineering-journey/\">Read more</a>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://eng.wealthfront.com/feed/",
      "value": "Introduction For over a year, the Cash team at Wealthfront has been working towards a consistent transfer experience across the Wealthfront ecosystem. Before beginning this project we had a number of separate transfer flows that each had their distinct user experience. Each transfer flow was built with its own set of UI components, models, and... <a class=\"moretag\" href=\"https://eng.wealthfront.com/2023/10/10/unifying-wealthfronts-transfer-flows-an-ios-engineering-journey/\">Read more</a>"
    }
  },
  "Small Improvements": {
    "title": "Interview with Jesper",
    "xmlUrl": "https://tech.small-improvements.com/rss",
    "htmlUrl": "https://tech.small-improvements.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.small-improvements.com/feed/",
      "value": "Interview with Jesper"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.small-improvements.com/interview-with-jesper/"
      }
    ],
    "link": "https://tech.small-improvements.com/interview-with-jesper/",
    "authors": [
      {
        "name": "Jan Heuermann"
      }
    ],
    "author": "Jan Heuermann",
    "author_detail": {
      "name": "Jan Heuermann"
    },
    "published": "Tue, 16 Aug 2022 12:16:22 +0000",
    "published_parsed": [
      2022,
      8,
      16,
      12,
      16,
      22,
      1,
      228,
      0
    ],
    "tags": [
      {
        "term": "Company Culture",
        "scheme": null,
        "label": null
      },
      {
        "term": "How we work",
        "scheme": null,
        "label": null
      },
      {
        "term": "Inside SI",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://tech.small-improvements.com/?p=8614",
    "guidislink": false,
    "summary": "This is an interview with Small Improvement\u2019s software developer Jesper Oskarsson about how the development ... <div><a class=\"more-link\" href=\"https://tech.small-improvements.com/interview-with-jesper/\">Read More <i class=\"x-icon x-icon-long-arrow-right\"></i></a></div>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://tech.small-improvements.com/feed/",
      "value": "This is an interview with Small Improvement\u2019s software developer Jesper Oskarsson about how the development ... <div><a class=\"more-link\" href=\"https://tech.small-improvements.com/interview-with-jesper/\">Read More <i class=\"x-icon x-icon-long-arrow-right\"></i></a></div>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://tech.small-improvements.com/feed/",
        "value": "<p><i>This is an interview with Small Improvement\u2019s software developer Jesper Oskarsson about how the development team works together, what the tech stack looks like, and how big feature releases are tackled. If you want to read on, you find <a href=\"https://tech.small-improvements.com/interview-with-laura/\">another developer interview here</a>.</i></p>\n<p><strong>Hey Jesper! You recently had your 5-year anniversary at Small Improvements, so congratulations again. Could you briefly summarize your professional journey?</strong></p>\n<p><span style=\"font-weight: 400;\">Thanks! Yeah, time flies\u2026 I\u2019ve basically been programming most of my life now. I got interested in game development when I was a teenager, because I used to play a lot of video games and was fascinated by computers. After school, I studied software engineering with focus on game development. Before joining Small Improvements in 2017, I worked as freelance mobile developer for a couple of years.</span></p>\n<p><strong>Do you have a specific technological focus at SI?</strong></p>\n<p><span style=\"font-weight: 400;\">I probably work more in the backend than in the frontend, but like everyone else in the dev team, I write code for the entire stack. Together with one of my teammates, I\u2019m also responsible for overseeing security-related aspects of our application.</span></p>\n<p><strong>Can you tell us more about this security work?</strong></p>\n<p><span style=\"font-weight: 400;\">Security is an important topic for us, because we handle sensitive personal data from our customers. Even though our security setup and mechanisms are pretty solid in general, there are always things to update and improve. For example, we have a HackerOne program, where ethical \u201cwhite-hat hackers\u201d try to uncover potential issues in our application. They report them to us, so that we can fix them, and in return they get a financial reward from us. Another example is a penetration test and security audit, which was conducted by external security researchers last year.</span></p>\n<p><strong>How much time do you spend with security-related tasks every week?</strong></p>\n<p><span style=\"font-weight: 400;\">The workload depends of course, but it\u2019s typically a few hours per week. I also don\u2019t have to fix all bugs myself, by the way </span><i><span style=\"font-weight: 400;\">(laughs)</span></i><span style=\"font-weight: 400;\">: we treat them as regular sprint tickets, which can be picked up by any developer. Our general philosophy is that responsibilities should be divided equally across the team: so certain people drive specific topics they are passionate or knowledgeable about, but at the same time, we want to avoid building up silos. It\u2019s important for us that every developer stays in touch with all technical aspects of the application.</span></p>\n<p><strong>What programming languages and technologies does the app consist of?</strong></p>\n<p><span style=\"font-weight: 400;\">We have a single-page-application in the frontend, which is connected to a monolithic JSON API in the backend. The frontend is mainly ReactJS, but there is also some older AngularJS code from the early days. The backend is implemented in Java using the Spring framework. It runs on Google App Engine in data centers in the US and EU. We are using Google Firestore as our main database, which is a document store, and then also some miscellaneous cloud services, such as task queues, or a secondary storage for our data warehouse.</span></p>\n<p><strong>What do you think about this tech stack?</strong></p>\n<p><span style=\"font-weight: 400;\">Well, the grass on the other side of the fence always looks greener, doesn\u2019t it? </span><i><span style=\"font-weight: 400;\">(laughs)</span></i><span style=\"font-weight: 400;\"> But all jokes aside: I\u2019m actually pretty happy with it. At the end of the day, our customers don\u2019t pay us for what frameworks or programming languages we use. Instead, it\u2019s important for them that the app works reliably and that it solves their business requirements. We have a content and stable customer base, so it seems like we made some good technical decisions.</span></p>\n<p><strong>Can you give an example of what works well and what doesn\u2019t?</strong></p>\n<p><span style=\"font-weight: 400;\">A good example is App Engine, which is Google\u2019s managed cloud infrastructure that we use for hosting. The advantage is that we don\u2019t have to bother with operational duties like scaling or database replication, because this is all taken care of by Google. The time that we save that way, we can invest into developing new features. On the other hand, App Engine has some limitations, so it\u2019s sometimes annoying that we have to deal with or work around certain restrictions. I still think that the positive aspects outweigh the negative ones, though: when I look back at the last years, we only had a handful of minor incidents, even though we deploy multiple times per week. All in all, I would say that our infrastructure \u201cjust works\u201d for the most part.</span></p>\n<p><strong>How does the team go about introducing new technologies?</strong></p>\n<p><span style=\"font-weight: 400;\">Introducing new technologies is always a balancing act. On the one hand, we want to stay modern and take advantage of innovation, but on the other hand we can\u2019t jump onboard of every new hype and refactor the entire code base all at once. I suppose our approach towards innovation can be best described as incremental: when someone sees an opportunity to implement something in a better way, they try it out and bring it up in our weekly developer meeting. It then gets reviewed and discussed in the entire team, and together we decide how we want to move forward. If we feel positive about it, and when it then stands the test of time, we gradually adopt it and make it our new \u201cstandard\u201d. Examples of this from the past are our transition from AngularJS to ReactJS in the frontend, or, more recently, the introduction of a new testing library in the backend.</span></p>\n<p><strong>You recently worked on a new feature called \u201cAutomations\u201c. What is this about?</strong></p>\n<p><span style=\"font-weight: 400;\">The idea of the \u201cAutomations\u201d feature is to make the lives of HR administrators easier. HR admins are the users within a company account who manage the HR-related processes for their companies\u2019 staff, such as performance reviews or 360 feedback. Let\u2019s say that company hires someone: the new employee needs to have access to the companies\u2019\u00a0Small Improvements account, in order to prepare 1:1 meetings with their manager, or to participate in a feedback survey. Some of these administrative tasks can be quite repetitive, though, so with the new \u201cAutomations\u201d feature the HR admin can create recurring workflows and schedule certain events ahead of time.</span></p>\n<p><strong>You implemented large parts of the new \u201cAutomations\u201d feature. How did you approach this, and what did you find most difficult?</strong></p>\n<p><span style=\"font-weight: 400;\">The most tricky challenge regarding the implementation was to carve out the right domain model that reflects the flows and rules in the code in a way that\u2019s both neat and accurate. Although we had a clear vision of what the \u201cAutomations\u201d feature should be capable of, there were many details regarding its usage, which we were uncertain about at the beginning. Our product manager and customer support team did a lot of research, so we started out by building a first prototype. That way, we could play around with the feature ourselves, and we also were able to show it to customers in order to receive external feedback.</span></p>\n<p><strong>How do you make these prototypes available? Do you have a separate testing environment?</strong></p>\n<p><span style=\"font-weight: 400;\">We have a dedicated environment that we can deploy experimental features to. We only use this for internal testing, though. We generally try to integrate work-in-progress features into our main branch early on, to avoid long-running branches and the potential hassle that they can entail. We make use of a mechanism called \u201cfeature flags\u201d. This effectively allows us to hide new functionality from end-users, even though the code is already merged in and deployed to production.</span></p>\n<p><strong>Is this a typical example of the feature development lifecycle?</strong></p>\n<p><span style=\"font-weight: 400;\">For larger features, this is a common practice for us. It first starts on the machine of an individual developer. Once we have something working, we deploy it to our internal testing stage, where we can play around with it ourselves. If a prototype reaches a state that is somewhat stable, we can make it available as beta feature to curious customers. Finally, once we are happy with everything, we roll it out to the entire user base. During that whole process, we keep iterating on the functionality and continuously refine the implementation. For smaller features, we don\u2019t need such a sophisticated procedure, of course: if a tweak or fix is straightforward enough, we usually release it right after merging.</span></p>\n<p><strong>Were you able to build the \u201cAutomations\u201d feature on top of the existing infrastructure, or did you have to make bigger architectural changes?</strong></p>\n<p><span style=\"font-weight: 400;\">Initially, we considered using cloud functions for running the scheduled background tasks, so that we could deploy and scale them separately. But eventually, we realized that it was better to implement the functionality within our existing system setup. This was also a matter of complexity: due to the iterative way we developed the feature itself, we wanted to avoid making bigger infrastructure changes at the same time. Another caveat was the burden of maintenance: while it would have been cool to dabble with new cloud technology, we felt that the benefits wouldn\u2019t have been worth the additional overhead in this case.</span></p>\n<p><strong>Thanks, Jesper, for sharing these insights with us!</strong></p>\n<p><i>If you want to learn more about the development team, you find <a href=\"https://tech.small-improvements.com/interview-with-laura/\">another developer interview here</a>.</i></p>"
      }
    ],
    "media_thumbnail": [
      {
        "url": "https://tech.small-improvements.com/wp-content/uploads/2022/08/Untitled2-1024x767.jpg",
        "width": "880",
        "height": "659"
      }
    ],
    "href": ""
  },
  "Hostinger": {
    "title": "Meeting Our Clients: Trying Their Services and Celebrating Success Stories",
    "xmlUrl": "https://www.hostinger.com/blog/feed/",
    "htmlUrl": "https://www.hostinger.com/blog/engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.hostinger.com/blog/feed",
      "value": "Meeting Our Clients: Trying Their Services and Celebrating Success Stories"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.hostinger.com/blog/meeting-our-clients"
      }
    ],
    "link": "https://www.hostinger.com/blog/meeting-our-clients",
    "comments": "https://www.hostinger.com/blog/meeting-our-clients#respond",
    "authors": [
      {
        "name": "Kotryna D"
      }
    ],
    "author": "Kotryna D",
    "author_detail": {
      "name": "Kotryna D"
    },
    "published": "Wed, 27 Dec 2023 08:35:31 +0000",
    "published_parsed": [
      2023,
      12,
      27,
      8,
      35,
      31,
      2,
      361,
      0
    ],
    "tags": [
      {
        "term": "Daily Life",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://www.hostinger.com/blog/?p=5891",
    "guidislink": false,
    "summary": "<p>This Christmas period, we brought the festive spirit into our offices and teams by meeting our clients. From board games to puppy yoga and wine tasting, these experiences struck t\u2026</p>\n<p>The post <a href=\"https://www.hostinger.com/blog/meeting-our-clients\" rel=\"follow\">Meeting Our Clients: Trying Their Services and Celebrating Success Stories</a> appeared first on <a href=\"https://www.hostinger.com/blog\" rel=\"follow\">Hostinger Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.hostinger.com/blog/feed",
      "value": "<p>This Christmas period, we brought the festive spirit into our offices and teams by meeting our clients. From board games to puppy yoga and wine tasting, these experiences struck t\u2026</p>\n<p>The post <a href=\"https://www.hostinger.com/blog/meeting-our-clients\" rel=\"follow\">Meeting Our Clients: Trying Their Services and Celebrating Success Stories</a> appeared first on <a href=\"https://www.hostinger.com/blog\" rel=\"follow\">Hostinger Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.hostinger.com/blog/feed",
        "value": "<p><strong>This Christmas period, we brought the festive spirit into our offices and teams by meeting our clients. From board games to puppy yoga and wine tasting, these experiences struck the perfect balance between celebrating and getting to know our clients.&nbsp;</strong></p>\n\n\n\n<p><strong>Join us as we share these memorable experiences and our clients&#8217; success stories.&nbsp;</strong></p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"h-from-friends-to-company-parties\">From Friends to Company Parties</h2>\n\n\n\n<p>First, we had a board game party hosted by <a href=\"https://offlinegameclub.lt/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Offline Game Club</a>. Besides having fun, playing board games also strengthens skills like reaction, strategic thinking, communication, and even bluffing.</p>\n\n\n\n<p>The founders of Offline Game Club have been passionate about board games for over two decades. They\u2019ve explored numerous games, attended international exhibitions, and grown their personal game collections. What began as a hobby and casual game nights for friends evolved into an actual job.&nbsp;</p>\n\n\n\n<p>\u201cWe now organize team-building events featuring various board games for both small gatherings and large festivals. Our unique collection of exclusive games ensures there\u2019s something for everyone to enjoy,\u201d shares Andrius Pilypaitis, one of the company&#8217;s founders.\u00a0</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><a href=\"https://www.hostinger.com/blog/wp-content/uploads/sites/4/2023/12/IMG_2289-scaled.jpg\" rel=\"follow\"><img alt=\"Offline Game Club\" class=\"wp-image-5895\" height=\"768\" src=\"https://www.hostinger.com/blog/wp-content/uploads/sites/4/2023/12/IMG_2289-1024x768.jpg\" style=\"width: 619px; height: auto;\" width=\"1024\" /></a></figure></div>\n\n\n<h2 class=\"wp-block-heading\">Website Is a Must for Scaling&nbsp;</h2>\n\n\n\n<p>Starting this business was challenging due to the various misconceptions surrounding it. This is where their website played a crucial role. Through images and videos, they could effectively convey the excitement and diversity of their games. Additionally, customer testimonials on their website have been instrumental in finding new clients.</p>\n\n\n\n<p>\u201cWe chose Hostinger for its reliability and good customer service. We got what we expected &#8211; a very <a href=\"https://www.hostinger.com/website-builder\" rel=\"follow\">easy-to-set-up and manage website</a>. The era of needing a friend-of-a-friend to build your website is over. Nowadays, website creation and editing are so user-friendly that most people can do it themselves,\u201d he highlights.\u00a0</p>\n\n\n\n<h2 class=\"wp-block-heading\">Introducing the New Way of Yoga</h2>\n\n\n\n<p>One of our clients, <a href=\"https://woofyoga.lt/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Woof Yoga</a>, combines relaxation with playful puppies. It is an excellent team-building exercise, allowing colleagues to connect in a fun and adorable setting.&nbsp;</p>\n\n\n\n<p>The creators of Woof Yoga, David Erenburg, Dovydas Da\u0161\u010dioras, and Gabriel\u0117 Zdanavi\u010di\u016bt\u0117, come from different fields \u2013 logistics, construction, and marketing. United by their love for animals and sports, they decided to introduce pet yoga to Lithuania.</p>\n\n\n\n<p>\u201cInitially, it wasn\u2019t about business. We started by making calls and collecting people through social networks. Seeing the joy and repeated attendance of participants, we decided to move further,\u201d David explains.\u00a0</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><a href=\"https://www.hostinger.com/blog/wp-content/uploads/sites/4/2023/12/1-scaled.jpeg\" rel=\"follow\"><img alt=\"Woof Yoga\" class=\"wp-image-5896\" height=\"768\" src=\"https://www.hostinger.com/blog/wp-content/uploads/sites/4/2023/12/1-1024x768.jpeg\" style=\"width: 621px; height: auto;\" width=\"1024\" /></a></figure></div>\n\n\n<h2 class=\"wp-block-heading\">Quality Comes First</h2>\n\n\n\n<p>The Woof Yoga team prioritizes high-quality classes by limiting participant numbers and varying the puppy breeds. They\u2019ve found that their sessions appeal to a diverse range of people, offering various benefits from emotional to physical wellness. Starting with just five sessions per month, the business now hosts multiple sessions per day.</p>\n\n\n\n<p>\u201cAs soon as we came up with the idea, we knew we wanted a website here and now. It&#8217;s been pivotal in simplifying session bookings and management, freeing up our time for other important aspects, like communicating with the kennels, advertising, and improving yoga. The website maintenance is convenient and easy, and the support team&#8217;s work is exceptional!&#8221; \u2013 shares David.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Pursuing the Dream</h2>\n\n\n\n<p>Just before Christmas, our team was inspired by another client who drastically changed her career to pursue her dream. Ieva Elvyra Kazakevi\u010di\u016bt\u0117 and her wine-tasting event business, <a href=\"https://gliugliu.lt/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Gliu Gliu</a>, offered a delightful blend of education and enjoyment, perfect for spending quality time and learning.</p>\n\n\n\n<p>Ieva\u2019s journey is diverse, from children&#8217;s radio hosting to creating internationally renowned albums and magazines, writing for prime-time TV, and working in fintech. She says she finally found her passion &#8211; wine-tasting events, which are getting popular on various occasions, from birthdays to corporate celebrations.&nbsp;</p>\n\n\n\n<p>\u201cI began studying to be a sommelier to learn something new and have fun after work. I always look to simplify things and convey them in a way that&#8217;s relatable to my audience. That\u2019s what I felt was missing in the local wine scene. It felt like many people around me would be able to appreciate wine a lot more if it was presented to them in a simple way,\u201c she says.\u00a0</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><a href=\"https://www.hostinger.com/blog/wp-content/uploads/sites/4/2023/12/Hostinger-020-scaled.jpg\" rel=\"follow\"><img alt=\"Ieva Elvyra Kazakevi\u010di\u016bt\u0117\" class=\"wp-image-5897\" height=\"683\" src=\"https://www.hostinger.com/blog/wp-content/uploads/sites/4/2023/12/Hostinger-020-1024x683.jpg\" style=\"width: 629px; height: auto;\" width=\"1024\" /></a></figure></div>\n\n\n<p>As Ieva Elvyra Kazakevi\u010di\u016bt\u0117 highlights, her goal is to create a safe space for her audience, with no concept of stupid questions. During her events, she tries to teach people a quick checklist about wine &#8211; how do you taste it? What do you look for in it? What questions do you ask to find a wine for the occasion?&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\">Embracing a Website as a Key Business Tool</h2>\n\n\n\n<p>Ieva initially hesitated to create a website, thinking it was a big deal she still had to grow into. However, a friend\u2019s suggested viewing it as an online business card and recommended Hostinger &#8211; she ended up creating a website in a day. To her, it\u2019s a vital platform for promoting natural winemaking and attracting new clients.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><a href=\"https://www.hostinger.com/blog/wp-content/uploads/sites/4/2023/12/Hostinger-054-scaled.jpg\" rel=\"follow\"><img alt=\"Gliu Gliu event\" class=\"wp-image-5898\" height=\"683\" src=\"https://www.hostinger.com/blog/wp-content/uploads/sites/4/2023/12/Hostinger-054-1024x683.jpg\" style=\"width: 650px; height: auto;\" width=\"1024\" /></a></figure></div>\n\n\n<p>\u201cThe user experience on Hostinger Website Builder made me feel like a world-class web creator. It\u2019s all about arranging elements, playing with some colors, and voil\u00e0! Learning to promote my site and increase traffic has been fascinating. While word-of-mouth advertising is crucial in my field, people often research before reaching out. With the website, I show my personality and vibe fairly accurately for people to decide,&#8221; she explains.&nbsp;</p>\n\n\n\n<p>All the clients we&#8217;ve met agree that having a website is a pivotal part of growing a business. These websites serve as platforms for booking and raising your brand awareness to attract more clients. These stories show that a well-crafted website is necessary for connecting with audiences and achieving success.&nbsp;</p>\n<p>The post <a href=\"https://www.hostinger.com/blog/meeting-our-clients\" rel=\"follow\">Meeting Our Clients: Trying Their Services and Celebrating Success Stories</a> appeared first on <a href=\"https://www.hostinger.com/blog\" rel=\"follow\">Hostinger Blog</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://www.hostinger.com/blog/meeting-our-clients/feed",
    "slash_comments": "0"
  },
  "Artsy": {
    "title": "The Checklist for Deploying a Scary Change",
    "xmlUrl": "http://artsy.github.io/feed",
    "htmlUrl": "http://artsy.github.io/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://artsy.github.io/feed",
      "value": "The Checklist for Deploying a Scary Change"
    },
    "summary": "<p>Lately, I\u2019ve been getting involved with some sketchy stuff. You know what I\u2019m\ntalking about\u2013data migrations.</p>\n\n<p>I\u2019ve been rolling out changes that have a significant risk of breaking our\nproduction environment for mission-critical services. It\u2019s been exciting work\n(keep your eyes out for more posts on the exact project, coming soon\u2122\ufe0f), but\nI\u2019ve definitely caused a couple incidents along the way.</p>\n\n<p>After accidentally taking down a key service for a couple hours, I decided I\nneeded to have a better pre-deploy process for these changes. I did some\nthinking and came up with a short checklist to run through before I press the\nshiny green button.</p>\n\n<!-- more -->\n\n<p>Here\u2019s the checklist I came up with:</p>\n\n<ul class=\"task-list\">\n  <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />What is your plan if something goes wrong?\n    <ul class=\"task-list\">\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Run through ramifications of rolling back. If there\u2019s a reason you\u2019re\n    worried about rolling back, then you\u2019re not ready to deploy the change\n    yet!</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Figure out exactly what command(s) you will need to run to roll back. At\n    Artsy, this is usually a\n    <a href=\"https://github.com/artsy/hokusai/blob/main/docs/Command_Reference.md#how-to-do-a-rollback\">one-liner using Hokusai</a>,\n    our command-line Docker/Kubernetes CLI</li>\n    </ul>\n  </li>\n  <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />How will you tell if something is going wrong after you deploy?\n    <ul class=\"task-list\">\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Error rate (DataDog)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Specific error reporting (Sentry)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Latency (DataDog)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Logs (Papertrail)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Functionality (does it still work? Are people using it successfully?\n    Important for things where errors may not be bubbled up correctly or\n    reported immediately)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Sidekiq (are there lots of jobs queued to retry that are failing?)</li>\n    </ul>\n  </li>\n</ul>\n\n<p>With this checklist in hand, I\u2019m deploying more confidently and causing fewer\nincidents along the way.</p>\n\n<p>Do you have something similar? Are there things you think this checklist should\ninclude? Let me know in the comments!</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://artsy.github.io/feed",
      "value": "<p>Lately, I\u2019ve been getting involved with some sketchy stuff. You know what I\u2019m\ntalking about\u2013data migrations.</p>\n\n<p>I\u2019ve been rolling out changes that have a significant risk of breaking our\nproduction environment for mission-critical services. It\u2019s been exciting work\n(keep your eyes out for more posts on the exact project, coming soon\u2122\ufe0f), but\nI\u2019ve definitely caused a couple incidents along the way.</p>\n\n<p>After accidentally taking down a key service for a couple hours, I decided I\nneeded to have a better pre-deploy process for these changes. I did some\nthinking and came up with a short checklist to run through before I press the\nshiny green button.</p>\n\n<!-- more -->\n\n<p>Here\u2019s the checklist I came up with:</p>\n\n<ul class=\"task-list\">\n  <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />What is your plan if something goes wrong?\n    <ul class=\"task-list\">\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Run through ramifications of rolling back. If there\u2019s a reason you\u2019re\n    worried about rolling back, then you\u2019re not ready to deploy the change\n    yet!</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Figure out exactly what command(s) you will need to run to roll back. At\n    Artsy, this is usually a\n    <a href=\"https://github.com/artsy/hokusai/blob/main/docs/Command_Reference.md#how-to-do-a-rollback\">one-liner using Hokusai</a>,\n    our command-line Docker/Kubernetes CLI</li>\n    </ul>\n  </li>\n  <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />How will you tell if something is going wrong after you deploy?\n    <ul class=\"task-list\">\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Error rate (DataDog)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Specific error reporting (Sentry)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Latency (DataDog)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Logs (Papertrail)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Functionality (does it still work? Are people using it successfully?\n    Important for things where errors may not be bubbled up correctly or\n    reported immediately)</li>\n      <li class=\"task-list-item\"><input class=\"task-list-item-checkbox\" disabled=\"disabled\" type=\"checkbox\" />Sidekiq (are there lots of jobs queued to retry that are failing?)</li>\n    </ul>\n  </li>\n</ul>\n\n<p>With this checklist in hand, I\u2019m deploying more confidently and causing fewer\nincidents along the way.</p>\n\n<p>Do you have something similar? Are there things you think this checklist should\ninclude? Let me know in the comments!</p>"
    },
    "published": "Wed, 13 Sep 2023 00:00:00 +0000",
    "published_parsed": [
      2023,
      9,
      13,
      0,
      0,
      0,
      2,
      256,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://artsy.github.io/blog/2023/09/13/deploying-a-scary-change/"
      }
    ],
    "link": "https://artsy.github.io/blog/2023/09/13/deploying-a-scary-change/",
    "id": "https://artsy.github.io/blog/2023/09/13/deploying-a-scary-change/",
    "guidislink": false,
    "tags": [
      {
        "term": "Ruby on Rails",
        "scheme": null,
        "label": null
      },
      {
        "term": "data migrations",
        "scheme": null,
        "label": null
      },
      {
        "term": "deploy process",
        "scheme": null,
        "label": null
      }
    ]
  },
  "theScore": {
    "title": "Repo.transact/2 (The Case Against Ecto.Multi)",
    "xmlUrl": "http://techblog.thescore.com/feed.xml",
    "htmlUrl": "http://techblog.thescore.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://techblog.thescore.com/feed.xml",
      "value": "Repo.transact/2 (The Case Against Ecto.Multi)"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://techblog.thescore.com/2023/05/01/repo-transact/"
      }
    ],
    "link": "https://techblog.thescore.com/2023/05/01/repo-transact/",
    "published": "Mon, 01 May 2023 00:00:00 +0000",
    "published_parsed": [
      2023,
      5,
      1,
      0,
      0,
      0,
      0,
      121,
      0
    ],
    "authors": [
      {}
    ],
    "author": "",
    "id": "https://techblog.thescore.com/2023/05/01/repo-transact",
    "guidislink": false,
    "summary": "<p>After reading <a href=\"https://medium.com/very-big-things/towards-maintainable-elixir-the-core-and-the-interface-c267f0da43\">Towards Maintainable\nElixir</a>\nby Sa\u0161a Juri\u0107 and hearing about his famous <code>Repo.transact</code> in some of his\ntalks, I decided it was time to explore this for myself.</p>\n\n<p>This post takes into account that you (the reader) are aware and know why and\nwhen to use <a href=\"https://hexdocs.pm/ecto/Ecto.Multi.html\">Ecto.Multi</a>. But for\nthose unfamiliar, the TL;DR is you would use an <code>Ecto.Multi</code> when you want to\nperform multiple transaction that you want to be committed to the database in\none shot. Meaning, if one of the transactions fails, you would want to revert\nall other transactions in the run.</p>\n\n<h2>The Problem with Ecto.Multi</h2>\n\n<p>Lets get something straight, <strong>there is nothing wrong with using Ecto.Multi</strong>\nin your codebase. If it works for you, then it works. However after working\nwith it in multiple codebases I have started to see a common theme: it is very\nnoisy and can be sometimes hard to follow and DRY up. You can get around it by\nusing a lot of private functions to support the Ecto.Multi, but then your\nmodule just has a tons of wrapper functions.</p>\n\n<h2>What is Repo.transact/2?</h2>\n\n<blockquote>\n<p>The function Repo.transact is our small wrapper around\n<a href=\"https://hexdocs.pm/ecto/Ecto.Repo.html#c:transaction/2\">Repo.transaction/2</a>.\nThis function commits the transaction if the lambda returns <code>{:ok, result}</code>,\nrolling it back if the lambda returns <code>{:error, reason}</code>. In both cases, the\nfunction returns the result of the lambda. We chose this approach over\nEcto.Multi, because we\u2019ve experimentally established that multi adds a lot of\nnoise with no real benefits for our needs.</p>\n\n<p>-- <cite>Sa\u0161a Juri\u0107</cite></p>\n</blockquote>\n\n<h2>Function definition</h2>\n\n<p>Sa\u0161a never gives out the implementation of the function but I came up with\nthis, and it works great; Exactly as you would expect.</p>\n<div class=\"highlight\"><pre><code class=\"language-elixir\"><span></span><span class=\"kd\">defmodule</span><span class=\"w\"> </span><span class=\"nc\">MyApp.Repo</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">  </span><span class=\"kn\">use</span><span class=\"w\"> </span><span class=\"nc\">Ecto.Repo</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">otp_app</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"ss\">:my_app</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">adapter</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"nc\">Ecto.Adapters.Postgres</span>\n<span class=\"w\">  </span><span class=\"na\">@doc</span><span class=\"w\"> </span><span class=\"sh\">\"\"\"</span>\n<span class=\"w\">  </span><span class=\"sh\">A small wrapper around `Repo.transaction/2'.</span>\n<span class=\"sh\">  Commits the transaction if the lambda returns `{:ok, result}`, rolling it</span>\n<span class=\"sh\">  back if the lambda returns `{:error, reason}`. In both cases, the function</span>\n<span class=\"sh\">  returns the result of the lambda.</span>\n<span class=\"w\">  </span><span class=\"sh\">\"\"\"</span>\n<span class=\"w\">  </span><span class=\"na\">@spec</span><span class=\"w\"> </span><span class=\"n\">transact</span><span class=\"p\">((()</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"n\">any</span><span class=\"p\">()),</span><span class=\"w\"> </span><span class=\"n\">keyword</span><span class=\"p\">())</span><span class=\"w\"> </span><span class=\"o\">::</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">any</span><span class=\"p\">()}</span><span class=\"w\"> </span><span class=\"o\">|</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"ss\">:error</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">any</span><span class=\"p\">()}</span>\n<span class=\"w\">  </span><span class=\"kd\">def</span><span class=\"w\"> </span><span class=\"n\">transact</span><span class=\"p\">(</span><span class=\"n\">fun</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">opts</span><span class=\"w\"> </span><span class=\"p\">\\\\</span><span class=\"w\"> </span><span class=\"p\">[])</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">    </span><span class=\"n\">transaction</span><span class=\"p\">(</span>\n<span class=\"w\">      </span><span class=\"k\">fn</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">        </span><span class=\"k\">case</span><span class=\"w\"> </span><span class=\"n\">fun</span><span class=\"o\">.</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">          </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">value</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"n\">value</span>\n<span class=\"w\">          </span><span class=\"ss\">:ok</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"ss\">:transaction_commited</span>\n<span class=\"w\">          </span><span class=\"p\">{</span><span class=\"ss\">:error</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">reason</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"n\">rollback</span><span class=\"p\">(</span><span class=\"n\">reason</span><span class=\"p\">)</span>\n<span class=\"w\">          </span><span class=\"ss\">:error</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"n\">rollback</span><span class=\"p\">(</span><span class=\"ss\">:transaction_rollback_error</span><span class=\"p\">)</span>\n<span class=\"w\">        </span><span class=\"k\">end</span>\n<span class=\"w\">      </span><span class=\"k\">end</span><span class=\"p\">,</span>\n<span class=\"w\">      </span><span class=\"n\">opts</span>\n<span class=\"w\">    </span><span class=\"p\">)</span>\n<span class=\"w\">  </span><span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<h2>Ecto.Multi vs Repo.transact</h2>\n\n<p>Lets say we want to take the typical user registration flow as an example. If\nwe want to insert a user, log the action to an audit table and also enqueue a job\nto send a confirmation email.</p>\n\n<p>We would have something like this using an Ecto.Multi:</p>\n\n<h4>Ecto.Multi implementation</h4>\n<div class=\"highlight\"><pre><code class=\"language-elixir\"><span></span><span class=\"kd\">def</span><span class=\"w\"> </span><span class=\"n\">register_user</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">  </span><span class=\"nc\">Multi</span><span class=\"o\">.</span><span class=\"n\">new</span><span class=\"p\">()</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"nc\">Multi</span><span class=\"o\">.</span><span class=\"n\">insert</span><span class=\"p\">(</span><span class=\"ss\">:user</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"nc\">Accounts</span><span class=\"o\">.</span><span class=\"n\">new_user_changeset</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">))</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"nc\">Multi</span><span class=\"o\">.</span><span class=\"n\">insert</span><span class=\"p\">(</span><span class=\"ss\">:log</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">fn</span><span class=\"w\"> </span><span class=\"p\">%{</span><span class=\"ss\">user</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">    </span><span class=\"nc\">Logs</span><span class=\"o\">.</span><span class=\"n\">log_action</span><span class=\"p\">(</span><span class=\"ss\">:user_registered</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"p\">%{</span><span class=\"ss\">user</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">})</span>\n<span class=\"w\">  </span><span class=\"k\">end</span><span class=\"p\">)</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"nc\">Multi</span><span class=\"o\">.</span><span class=\"n\">insert</span><span class=\"p\">(</span><span class=\"ss\">:email_job</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">fn</span><span class=\"w\"> </span><span class=\"p\">%{</span><span class=\"ss\">user</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">    </span><span class=\"nc\">Mailer</span><span class=\"o\">.</span><span class=\"n\">enqueue_email_confirmation</span><span class=\"p\">(</span><span class=\"n\">user</span><span class=\"p\">)</span>\n<span class=\"w\">  </span><span class=\"k\">end</span><span class=\"p\">)</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"nc\">Repo</span><span class=\"o\">.</span><span class=\"n\">transaction</span><span class=\"p\">()</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"k\">case</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">    </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"p\">%{</span><span class=\"ss\">user</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">      </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span>\n<span class=\"w\">    </span><span class=\"p\">{</span><span class=\"ss\">:error</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_failed_operation</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">failed_value</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_changes_so_far</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">      </span><span class=\"p\">{</span><span class=\"ss\">:error</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">failed_value</span><span class=\"p\">}</span>\n<span class=\"w\">  </span><span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>As we can see, it is not the worst, but once we see the <code>Repo.transact/2</code> way,\nit will be clear which is better.</p>\n\n<h4>Repo.transact implementation</h4>\n<div class=\"highlight\"><pre><code class=\"language-elixir\"><span></span><span class=\"kd\">def</span><span class=\"w\"> </span><span class=\"n\">register_user</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">  </span><span class=\"nc\">Repo</span><span class=\"o\">.</span><span class=\"n\">transact</span><span class=\"p\">(</span><span class=\"k\">fn</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">    </span><span class=\"n\">with</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nc\">Accounts</span><span class=\"o\">.</span><span class=\"n\">create_user</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">),</span>\n<span class=\"w\">         </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_log</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nc\">Logs</span><span class=\"o\">.</span><span class=\"n\">log_action</span><span class=\"p\">(</span><span class=\"ss\">:user_registered</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">),</span>\n<span class=\"w\">         </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_job</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nc\">Mailer</span><span class=\"o\">.</span><span class=\"n\">enqueue_email_confirmation</span><span class=\"p\">(</span><span class=\"n\">user</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">      </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span>\n<span class=\"w\">    </span><span class=\"k\">end</span>\n<span class=\"w\">  </span><span class=\"k\">end</span><span class=\"p\">)</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>As you can see, it is much shorter and easier to read. Another big benefit is\nthat we do not need to go down to the changeset level for inserting, we could\nuse our functions that perform <code>Repo.insert</code>s in them\n(<code>Accounts.new_user_changeset/1</code> vs <code>Accounts.create_user/1</code>). This lets us\ncompose many functions together from outside the context modules without having\nthe need to expose your changeset functions.</p>\n\n<p>The end result is the same, but it is a lot easier to read what is going on IMHO.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://techblog.thescore.com/feed.xml",
      "value": "<p>After reading <a href=\"https://medium.com/very-big-things/towards-maintainable-elixir-the-core-and-the-interface-c267f0da43\">Towards Maintainable\nElixir</a>\nby Sa\u0161a Juri\u0107 and hearing about his famous <code>Repo.transact</code> in some of his\ntalks, I decided it was time to explore this for myself.</p>\n\n<p>This post takes into account that you (the reader) are aware and know why and\nwhen to use <a href=\"https://hexdocs.pm/ecto/Ecto.Multi.html\">Ecto.Multi</a>. But for\nthose unfamiliar, the TL;DR is you would use an <code>Ecto.Multi</code> when you want to\nperform multiple transaction that you want to be committed to the database in\none shot. Meaning, if one of the transactions fails, you would want to revert\nall other transactions in the run.</p>\n\n<h2>The Problem with Ecto.Multi</h2>\n\n<p>Lets get something straight, <strong>there is nothing wrong with using Ecto.Multi</strong>\nin your codebase. If it works for you, then it works. However after working\nwith it in multiple codebases I have started to see a common theme: it is very\nnoisy and can be sometimes hard to follow and DRY up. You can get around it by\nusing a lot of private functions to support the Ecto.Multi, but then your\nmodule just has a tons of wrapper functions.</p>\n\n<h2>What is Repo.transact/2?</h2>\n\n<blockquote>\n<p>The function Repo.transact is our small wrapper around\n<a href=\"https://hexdocs.pm/ecto/Ecto.Repo.html#c:transaction/2\">Repo.transaction/2</a>.\nThis function commits the transaction if the lambda returns <code>{:ok, result}</code>,\nrolling it back if the lambda returns <code>{:error, reason}</code>. In both cases, the\nfunction returns the result of the lambda. We chose this approach over\nEcto.Multi, because we\u2019ve experimentally established that multi adds a lot of\nnoise with no real benefits for our needs.</p>\n\n<p>-- <cite>Sa\u0161a Juri\u0107</cite></p>\n</blockquote>\n\n<h2>Function definition</h2>\n\n<p>Sa\u0161a never gives out the implementation of the function but I came up with\nthis, and it works great; Exactly as you would expect.</p>\n<div class=\"highlight\"><pre><code class=\"language-elixir\"><span></span><span class=\"kd\">defmodule</span><span class=\"w\"> </span><span class=\"nc\">MyApp.Repo</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">  </span><span class=\"kn\">use</span><span class=\"w\"> </span><span class=\"nc\">Ecto.Repo</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">otp_app</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"ss\">:my_app</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">adapter</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"nc\">Ecto.Adapters.Postgres</span>\n<span class=\"w\">  </span><span class=\"na\">@doc</span><span class=\"w\"> </span><span class=\"sh\">\"\"\"</span>\n<span class=\"w\">  </span><span class=\"sh\">A small wrapper around `Repo.transaction/2'.</span>\n<span class=\"sh\">  Commits the transaction if the lambda returns `{:ok, result}`, rolling it</span>\n<span class=\"sh\">  back if the lambda returns `{:error, reason}`. In both cases, the function</span>\n<span class=\"sh\">  returns the result of the lambda.</span>\n<span class=\"w\">  </span><span class=\"sh\">\"\"\"</span>\n<span class=\"w\">  </span><span class=\"na\">@spec</span><span class=\"w\"> </span><span class=\"n\">transact</span><span class=\"p\">((()</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"n\">any</span><span class=\"p\">()),</span><span class=\"w\"> </span><span class=\"n\">keyword</span><span class=\"p\">())</span><span class=\"w\"> </span><span class=\"o\">::</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">any</span><span class=\"p\">()}</span><span class=\"w\"> </span><span class=\"o\">|</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"ss\">:error</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">any</span><span class=\"p\">()}</span>\n<span class=\"w\">  </span><span class=\"kd\">def</span><span class=\"w\"> </span><span class=\"n\">transact</span><span class=\"p\">(</span><span class=\"n\">fun</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">opts</span><span class=\"w\"> </span><span class=\"p\">\\\\</span><span class=\"w\"> </span><span class=\"p\">[])</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">    </span><span class=\"n\">transaction</span><span class=\"p\">(</span>\n<span class=\"w\">      </span><span class=\"k\">fn</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">        </span><span class=\"k\">case</span><span class=\"w\"> </span><span class=\"n\">fun</span><span class=\"o\">.</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">          </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">value</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"n\">value</span>\n<span class=\"w\">          </span><span class=\"ss\">:ok</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"ss\">:transaction_commited</span>\n<span class=\"w\">          </span><span class=\"p\">{</span><span class=\"ss\">:error</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">reason</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"n\">rollback</span><span class=\"p\">(</span><span class=\"n\">reason</span><span class=\"p\">)</span>\n<span class=\"w\">          </span><span class=\"ss\">:error</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span><span class=\"w\"> </span><span class=\"n\">rollback</span><span class=\"p\">(</span><span class=\"ss\">:transaction_rollback_error</span><span class=\"p\">)</span>\n<span class=\"w\">        </span><span class=\"k\">end</span>\n<span class=\"w\">      </span><span class=\"k\">end</span><span class=\"p\">,</span>\n<span class=\"w\">      </span><span class=\"n\">opts</span>\n<span class=\"w\">    </span><span class=\"p\">)</span>\n<span class=\"w\">  </span><span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<h2>Ecto.Multi vs Repo.transact</h2>\n\n<p>Lets say we want to take the typical user registration flow as an example. If\nwe want to insert a user, log the action to an audit table and also enqueue a job\nto send a confirmation email.</p>\n\n<p>We would have something like this using an Ecto.Multi:</p>\n\n<h4>Ecto.Multi implementation</h4>\n<div class=\"highlight\"><pre><code class=\"language-elixir\"><span></span><span class=\"kd\">def</span><span class=\"w\"> </span><span class=\"n\">register_user</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">  </span><span class=\"nc\">Multi</span><span class=\"o\">.</span><span class=\"n\">new</span><span class=\"p\">()</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"nc\">Multi</span><span class=\"o\">.</span><span class=\"n\">insert</span><span class=\"p\">(</span><span class=\"ss\">:user</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"nc\">Accounts</span><span class=\"o\">.</span><span class=\"n\">new_user_changeset</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">))</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"nc\">Multi</span><span class=\"o\">.</span><span class=\"n\">insert</span><span class=\"p\">(</span><span class=\"ss\">:log</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">fn</span><span class=\"w\"> </span><span class=\"p\">%{</span><span class=\"ss\">user</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">    </span><span class=\"nc\">Logs</span><span class=\"o\">.</span><span class=\"n\">log_action</span><span class=\"p\">(</span><span class=\"ss\">:user_registered</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"p\">%{</span><span class=\"ss\">user</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">})</span>\n<span class=\"w\">  </span><span class=\"k\">end</span><span class=\"p\">)</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"nc\">Multi</span><span class=\"o\">.</span><span class=\"n\">insert</span><span class=\"p\">(</span><span class=\"ss\">:email_job</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">fn</span><span class=\"w\"> </span><span class=\"p\">%{</span><span class=\"ss\">user</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">    </span><span class=\"nc\">Mailer</span><span class=\"o\">.</span><span class=\"n\">enqueue_email_confirmation</span><span class=\"p\">(</span><span class=\"n\">user</span><span class=\"p\">)</span>\n<span class=\"w\">  </span><span class=\"k\">end</span><span class=\"p\">)</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"nc\">Repo</span><span class=\"o\">.</span><span class=\"n\">transaction</span><span class=\"p\">()</span>\n<span class=\"w\">  </span><span class=\"o\">|&gt;</span><span class=\"w\"> </span><span class=\"k\">case</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">    </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"p\">%{</span><span class=\"ss\">user</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">      </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span>\n<span class=\"w\">    </span><span class=\"p\">{</span><span class=\"ss\">:error</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_failed_operation</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">failed_value</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_changes_so_far</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">      </span><span class=\"p\">{</span><span class=\"ss\">:error</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">failed_value</span><span class=\"p\">}</span>\n<span class=\"w\">  </span><span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>As we can see, it is not the worst, but once we see the <code>Repo.transact/2</code> way,\nit will be clear which is better.</p>\n\n<h4>Repo.transact implementation</h4>\n<div class=\"highlight\"><pre><code class=\"language-elixir\"><span></span><span class=\"kd\">def</span><span class=\"w\"> </span><span class=\"n\">register_user</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">  </span><span class=\"nc\">Repo</span><span class=\"o\">.</span><span class=\"n\">transact</span><span class=\"p\">(</span><span class=\"k\">fn</span><span class=\"w\"> </span><span class=\"o\">-&gt;</span>\n<span class=\"w\">    </span><span class=\"n\">with</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nc\">Accounts</span><span class=\"o\">.</span><span class=\"n\">create_user</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">),</span>\n<span class=\"w\">         </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_log</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nc\">Logs</span><span class=\"o\">.</span><span class=\"n\">log_action</span><span class=\"p\">(</span><span class=\"ss\">:user_registered</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">),</span>\n<span class=\"w\">         </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_job</span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nc\">Mailer</span><span class=\"o\">.</span><span class=\"n\">enqueue_email_confirmation</span><span class=\"p\">(</span><span class=\"n\">user</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">      </span><span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"p\">}</span>\n<span class=\"w\">    </span><span class=\"k\">end</span>\n<span class=\"w\">  </span><span class=\"k\">end</span><span class=\"p\">)</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>As you can see, it is much shorter and easier to read. Another big benefit is\nthat we do not need to go down to the changeset level for inserting, we could\nuse our functions that perform <code>Repo.insert</code>s in them\n(<code>Accounts.new_user_changeset/1</code> vs <code>Accounts.create_user/1</code>). This lets us\ncompose many functions together from outside the context modules without having\nthe need to expose your changeset functions.</p>\n\n<p>The end result is the same, but it is a lot easier to read what is going on IMHO.</p>"
    }
  },
  "Twitter": {
    "title": "Twitter's Recommendation Algorithm",
    "xmlUrl": "https://blog.twitter.com/engineering/feed",
    "htmlUrl": "https://blog.twitter.com/engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.twitter.com/content/blog-twitter/engineering/en_us",
      "value": "Twitter's Recommendation Algorithm"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm"
      }
    ],
    "link": "https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm",
    "summary": "Twitter aims to deliver you the best of what\u2019s happening in the world right now. This blog is an introduction to how the algorithm selects Tweets for your timeline.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.twitter.com/content/blog-twitter/engineering/en_us",
      "value": "Twitter aims to deliver you the best of what\u2019s happening in the world right now. This blog is an introduction to how the algorithm selects Tweets for your timeline."
    },
    "published": "",
    "published_parsed": null,
    "id": "https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm",
    "guidislink": false
  },
  "Atlassian": {
    "title": "Ask Me Anything Recap: Understanding Compliance with Vanta",
    "xmlUrl": "https://developer.atlassian.com/blog/feed.xml",
    "htmlUrl": "https://developer.atlassian.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.developer.atlassian.com/feed/",
      "value": "Ask Me Anything Recap: Understanding Compliance with Vanta"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.developer.atlassian.com/ask-me-anything-recap-understanding-compliance-with-vanta/"
      }
    ],
    "link": "https://blog.developer.atlassian.com/ask-me-anything-recap-understanding-compliance-with-vanta/",
    "authors": [
      {
        "name": "Maggie Norby Adams"
      }
    ],
    "author": "Maggie Norby Adams",
    "author_detail": {
      "name": "Maggie Norby Adams"
    },
    "published": "Wed, 20 Dec 2023 15:49:59 +0000",
    "published_parsed": [
      2023,
      12,
      20,
      15,
      49,
      59,
      2,
      354,
      0
    ],
    "tags": [
      {
        "term": "Uncategorized",
        "scheme": null,
        "label": null
      },
      {
        "term": "cloud",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://blog.developer.atlassian.com/?p=4238",
    "guidislink": false,
    "summary": "<p><span class=\"rt-reading-time\" style=\"display: block;\"><span class=\"rt-label rt-prefix\">Reading Time: </span> <span class=\"rt-time\">5</span> <span class=\"rt-label rt-postfix\">minutes</span></span> Navigating compliance is a critical part of running any cloud business, especially if you plan to sell to enterprise customers or&#8230;</p>\n<p>The post <a href=\"https://blog.developer.atlassian.com/ask-me-anything-recap-understanding-compliance-with-vanta/\" rel=\"nofollow\">Ask Me Anything Recap: Understanding Compliance with Vanta</a> appeared first on <a href=\"https://blog.developer.atlassian.com\" rel=\"nofollow\">Atlassian Developer Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.developer.atlassian.com/feed/",
      "value": "<p><span class=\"rt-reading-time\" style=\"display: block;\"><span class=\"rt-label rt-prefix\">Reading Time: </span> <span class=\"rt-time\">5</span> <span class=\"rt-label rt-postfix\">minutes</span></span> Navigating compliance is a critical part of running any cloud business, especially if you plan to sell to enterprise customers or&#8230;</p>\n<p>The post <a href=\"https://blog.developer.atlassian.com/ask-me-anything-recap-understanding-compliance-with-vanta/\" rel=\"nofollow\">Ask Me Anything Recap: Understanding Compliance with Vanta</a> appeared first on <a href=\"https://blog.developer.atlassian.com\" rel=\"nofollow\">Atlassian Developer Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.developer.atlassian.com/feed/",
        "value": "<span class=\"rt-reading-time\" style=\"display: block;\"><span class=\"rt-label rt-prefix\">Reading Time: </span> <span class=\"rt-time\">5</span> <span class=\"rt-label rt-postfix\">minutes</span></span>\n<p>Navigating compliance is a critical part of running any cloud business, especially if you plan to sell to enterprise customers or customers in more regulated markets. But of course, achieving compliance takes time and costs money. </p>\n\n\n\n<p>To help you more easily understand key compliance frameworks and topics, we're regularly sharing resources in the Partner Portal in the <a href=\"https://atlassianpartners.atlassian.net/wiki/spaces/resources/pages/264142905/Grow+customer+trust\" rel=\"noreferrer noopener\" target=\"_blank\">Grow Customer Trust hub</a>. We've also teamed up with the leading compliance automation platform <a href=\"https://www.vanta.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Vanta</a> to streamline your compliance journey.\u00a0Vanta offers Atlassian Partners <a href=\"https://www.vanta.com/landing/25-percent-off?utm_campaign=PartnerReferral&amp;utm_source=atlassian&amp;utm_medium=partner\" rel=\"noreferrer noopener\" target=\"_blank\">25% off of compliance services</a> to help you get through your audit faster.</p>\n\n\n\n<p>On December 12, 2023, we held an Ask Me Anything session with Matt Cooper, Sr. Manager, Privacy, Risk &amp; Compliance at<a href=\"https://www.vanta.com/\" rel=\"noreferrer noopener\" target=\"_blank\"> Vanta</a>. </p>\n\n\n\n<p>Here is a recap of the Q&amp;A:</p>\n\n\n\n<h3 class=\"wp-block-heading\">Q: If you could only pursue one security framework, how would you decide which one to start with?</h3>\n\n\n\n<p>A: Which framework you start with will depend on what your customers are asking for, what your company and apps look like today, and what you'd like to prioritize.</p>\n\n\n\n<p>Of course, it always bears repeating that legal compliance should be on your radar (ex: GDPR, CCPA, etc). If your industry, region, or customer base requires adherence to specific regulations, start your compliance journey there. Regulatory compliance sets the foundation for secure practices.</p>\n\n\n\n<p>Beyond regulatory alignment, adopting compliance with security frameworks can help customers quickly assess your app's security posture. There are two primary framework candidates to get started with: ISO 27001 and SOC 2. </p>\n\n\n\n<p>Carefully weigh the requirements of each against your company's unique needs and objectives before making an informed choice. Both options can significantly enhance your security posture, providing a robust foundation for safeguarding data and building trust with customers. </p>\n\n\n\n<ol>\n<li><strong>SOC 2 considerations</strong></li>\n</ol>\n\n\n\n<p>SOC 2 is a more controls-related audit. Auditors will basically check and ask, \"Are all the security measures in place and operating effectively?\" The requirements for SOC 2 are less prescriptive and it's not a pass or fail certification like ISO 27001.</p>\n\n\n\n<p>That said, a SOC 2 audit is potentially more risky for your business if you're not confident in your trust practices and posture. If there are any undesirable findings or failures in your app or business, they'll be shown on your report and stay on your report for the life of the report. So if you're planning to go through a SOC 2 audit, it's crucial to make sure your controls are really dialed in.&nbsp;</p>\n\n\n\n<p>Also, a SOC 2 framework off the shelf doesn't offer any controls so it can be a bit difficult to apply from scratch for your business.&nbsp;</p>\n\n\n\n<ol start=\"2\">\n<li><strong>ISO 27001 considerations</strong></li>\n</ol>\n\n\n\n<p>ISO 27001 on the other hand does require a lot of business-level governance overhead, monitoring and planning, and risk assessment work up front. This may not always make a lot of sense for a very small business without much to govern. While control effectiveness is the focus for SOC 2, governance gets a deeper examination for ISO 27001. However, an ISO 27001 audit can be more forgiving because \"non-conformities\" are not shown to the customer. The customer only sees if you are compliant (have ticked all the boxes) or not.</p>\n\n\n\n<p>Another thing to consider is this framework's similarities to other frameworks you may want to comply with later. For example, the US healthcare regulation, HIPAA, and the European automotive privacy regulation, TISAX, are derived from ISO. If you'd like to achieve compliance with these later on, you may want to start with ISO 27001 so you have the right policies, laying the groundwork for the future.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Q: Does starting with one framework make others easier?</h3>\n\n\n\n<p>A: There is a heavy overlap between ISO 27001 and SOC 2, so if you do one, the other will be a lot easier. But here's the trick: if you start with SOC 2, you'll have to prove you're managing things well before diving into ISO 27001.\u00a0 On the flip side, beginning with ISO 27001 sets you up for what you need to show in a SOC 2 audit. So, there's a bit of a strategy involved depending on which one you choose first.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Q: What does the commitment look like for an ISO 27001 or SOC 2 audit? How long does this take?</h3>\n\n\n\n<p>A: This will vary depending on your company's headcount, existing controls, and overall trust practices, and it's very dependent on executive buy-in and prioritization. Vanta has seen companies become audit-ready in a matter of weeks if there's internal commitment and the company already has some controls in place.\u00a0</p>\n\n\n\n<p>For a 10-person company, for example,\u00a0 it's doable in 6 months or less if the company is serious about it and have a resource like Vanta supporting the work.</p>\n\n\n\n<p>That said, some companies take 6 months or even longer, or they might not make it all if they don't <em>prioritize</em> compliance. The<strong> key is for everyone on the team to be committed to getting compliant in a timely manner.</strong></p>\n\n\n\n<p>There are some nearer-term efforts you can make that will take less time, like getting a SOC 2 Type 1 audit. You can go through a SOC 2 Type 1 audit at any time. This shows that you're making an effort to pay attention to your security practices, but it's not as intense as a SOC 2 Type 2 audit. Keep in mind, not all customers will accept this.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Q: Are SOC 2 and ISO 27001 equivalent in a customer's eyes?</h3>\n\n\n\n<p>A: Basically yes, most customers will view both of these efforts as evidence of a commitment to security. There are sometimes some regional preferences (ISO in Europe, SOC in the US) but for the most part, these frameworks both hold the same weight for customers.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Q: What are companies actually looking for when they want you to have SOC 2 or ISO 27001 compliance?</h3>\n\n\n\n<p>A: Companies care about these frameworks for several different reasons, varying from one framework to another.\u00a0Some of the main reasons include: </p>\n\n\n\n<p><strong>Showing due diligence in the event of a data leak</strong></p>\n\n\n\n<p>One key reason companies want to buy software that has been audited against these frameworks is to show due diligence. If something bad happens like a data leak, regulators, lawyers, and the customers of that company are going to go back through the chain of events to see what caused the bad thing to happen.&nbsp;</p>\n\n\n\n<p>In this case, the company will want to avoid looking negligent. One way for companies to look like they've covered their bases is to prove they've done due diligence for 3rd parties. But, most customers don't want to or cannot do this in-depth due diligence themselves.</p>\n\n\n\n<p>When the software they purchase (Jira, Confluence, or a Marketplace app) has an ISO 27001 certification or a SOC 2 report, the company can say that another 3rd party came in and validated that the 3rd party software they chose (for example, your cloud app) was secure.</p>\n\n\n\n<p><strong>Validating enterprise readiness</strong></p>\n\n\n\n<p>Some companies feel that if you haven't achieved compliance with these popular frameworks, you aren't serious about selling to enterprise customers. In seeing that you've gone through a SOC 2 or ISO 27001 audit, customers feel more confident in your ability to meet their needs.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" />\n\n\n\n<p>Thank you to Matt Cooper for the answers, and thanks to the Marketplace Partners who joined live to ask questions! </p>\n\n\n\n<p>If you&#8217;re looking for more information about compliance or enterprise trust in general, you can find it in the <a href=\"https://atlassianpartners.atlassian.net/wiki/spaces/resources/pages/264142905/Grow+customer+trust\" rel=\"noreferrer noopener\" target=\"_blank\">Grow Customer Trust hub</a> on the Partner Portal. Or if you&#8217;re ready to get started, Vanta offers Atlassian Partners 25% off of compliance services to help you get through your audit faster.</p>\n\n\n\n<div class=\"wp-block-bitbucket-cta bitbucket-cta text-undefined\"><a class=\"btn btn-primary\" href=\"https://www.vanta.com/landing/25-percent-off?utm_campaign=PartnerReferral&amp;utm_source=atlassian&amp;utm_medium=partner\">Get 25% off Vanta</a></div>\n\n\n\n<p></p>\n<p>The post <a href=\"https://blog.developer.atlassian.com/ask-me-anything-recap-understanding-compliance-with-vanta/\" rel=\"nofollow\">Ask Me Anything Recap: Understanding Compliance with Vanta</a> appeared first on <a href=\"https://blog.developer.atlassian.com\" rel=\"nofollow\">Atlassian Developer Blog</a>.</p>"
      }
    ]
  },
  "Nvidia": {
    "title": "NVIDIA CEO: \u2018This Year, Every Industry Will Become a Technology Industry\u2019",
    "xmlUrl": "https://blogs.nvidia.com/feed/",
    "htmlUrl": "https://blogs.nvidia.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blogs.nvidia.com/feed/",
      "value": "NVIDIA CEO: \u2018This Year, Every Industry Will Become a Technology Industry\u2019"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blogs.nvidia.com/blog/nvidia-ceo-ai-drug-discovery-jp-morgan-healthcare-2024/"
      }
    ],
    "link": "https://blogs.nvidia.com/blog/nvidia-ceo-ai-drug-discovery-jp-morgan-healthcare-2024/",
    "authors": [
      {
        "name": "Rory Kelleher"
      }
    ],
    "author": "Rory Kelleher",
    "author_detail": {
      "name": "Rory Kelleher"
    },
    "published": "Fri, 12 Jan 2024 18:30:17 +0000",
    "published_parsed": [
      2024,
      1,
      12,
      18,
      30,
      17,
      4,
      12,
      0
    ],
    "tags": [
      {
        "term": "Deep Learning",
        "scheme": null,
        "label": null
      },
      {
        "term": "Artificial Intelligence",
        "scheme": null,
        "label": null
      },
      {
        "term": "Events",
        "scheme": null,
        "label": null
      },
      {
        "term": "Generative AI",
        "scheme": null,
        "label": null
      },
      {
        "term": "Genomics",
        "scheme": null,
        "label": null
      },
      {
        "term": "Healthcare and Life Sciences",
        "scheme": null,
        "label": null
      },
      {
        "term": "NVIDIA Clara",
        "scheme": null,
        "label": null
      },
      {
        "term": "NVIDIA DGX",
        "scheme": null,
        "label": null
      },
      {
        "term": "Science",
        "scheme": null,
        "label": null
      },
      {
        "term": "Social Impact",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://blogs.nvidia.com/?p=69339",
    "guidislink": false,
    "summary": "\u201cThis year, every industry will become a technology industry,\u201d NVIDIA founder and CEO Jensen Huang told attendees Wednesday during the annual J.P. Morgan Healthcare Conference. \u201cYou can now recognize and learn the language of almost anything with structure, and you can translate it to anything with structure \u2014 so text-protein, protein-text,\u201d Huang said in a <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/nvidia-ceo-ai-drug-discovery-jp-morgan-healthcare-2024/\">Read article &#62;</a>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blogs.nvidia.com/feed/",
      "value": ""
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "<div id=\"bsf_rt_marker\"><p>\u201cThis year, every industry will become a technology industry,\u201d NVIDIA founder and CEO Jensen Huang told attendees Wednesday during the annual J.P. Morgan Healthcare Conference.</p>\n<p>\u201cYou can now recognize and learn the language of almost anything with structure, and you can translate it to anything with structure \u2014 so text-protein, protein-text,\u201d Huang said in a fireside chat with Martin Chavez, partner and vice chairman of global investment firm Sixth Street Partners and board chair of Recursion, a biopharmaceutical company. \u201cThis is the generative AI revolution.\u201d</p>\n<p>The conversation, which took place at the historic San Francisco Mint, followed a <a href=\"https://investor.nvidia.com/events-and-presentations/events-and-presentations/event-details/2024/JP-Morgan-Healthcare-Conference-2024-KwxXOv7uMk/default.aspx\">presentation at the J.P. Morgan conference</a> Monday by Kimberly Powell, NVIDIA\u2019s VP of healthcare. In her talk, Powell announced that <a href=\"https://www.recursion.com/news/nothing-short-of-phenomenal-new-deep-learning-model-available-on-nvidias-bionemo-platform\" rel=\"noopener\" target=\"_blank\">Recursion is the first hosting partner</a> to offer a foundation model through the <a href=\"https://www.nvidia.com/en-us/clara/bionemo/\">NVIDIA BioNeMo</a> cloud service, which is <a href=\"https://blogs.nvidia.com/blog/drug-discovery-bionemo-generative-ai/\">advancing into beta</a> this month.</p>\n<p>She also said that Amgen, one of the first companies to employ BioNeMo, <a href=\"https://blogs.nvidia.com/blog/genomics-ai-amgen-superpod/\">plans to advance drug discovery with generative AI</a> and <a href=\"https://www.nvidia.com/en-us/data-center/dgx-superpod/\">NVIDIA DGX SuperPOD</a> \u2014 and that BioNeMo is used by a growing number of techbio companies, pharmas, AI software vendors and systems integrators. Among them are <a href=\"https://www.prnewswire.com/news-releases/deloitte-expands-quartz-ai-suite-with-atlas-ai-for-drug-discovery-302028784.html\" rel=\"noopener\" target=\"_blank\">Deloitte</a>, <a href=\"https://innophore.com/innophore-is-folding-the-human-proteome-using-nvidia-bionemo-creating-a-fused-dataset-of-structural-models-for-machine-learning-purposes/\" rel=\"noopener\" target=\"_blank\">Innophore</a>, <a href=\"https://www.linkedin.com/pulse/insilico-medicine-ai-revolution-drug-discovery-in-silico-medicine-zlwfe/\" rel=\"noopener\" target=\"_blank\">Insilico Medicine</a>, <a href=\"https://www.linkedin.com/pulse/transforming-molecular-design-oneangstrom-integrates-nvidia-redon-eukpe%3FtrackingId=GwLwkk17I2oVvvfSB2KuPQ%253D%253D/?trackingId=GwLwkk17I2oVvvfSB2KuPQ%3D%3D\" rel=\"noopener\" target=\"_blank\">OneAngstrom</a>, Recursion and <a href=\"https://resources.nvidia.com/en-us-dgx-cloud/terray-therapeutics-customer-success-story\" rel=\"noopener\" target=\"_blank\">Terray Therapeutics</a>.</p>\n<h2><b>From Computer-Aided Chip Design to Drug Design</b></h2>\n<p>Healthcare customers and partners now consume well over a billion dollars in NVIDIA GPU computing each year \u2014 directly and indirectly through cloud partners.</p>\n<p>Huang traced NVIDIA\u2019s involvement in accelerated healthcare back to two research projects that caught his attention around 15 years ago: one at Mass General tapped <a href=\"https://pubmed.ncbi.nlm.nih.gov/17881799/\" rel=\"noopener\" target=\"_blank\">NVIDIA GPUs to reconstruct CT images</a>, another at the University of Illinois Urbana-Champaign <a href=\"https://www.nvidia.com/es-la/data-center/gpu-accelerated-applications/namd/\">applied GPU acceleration to molecular dynamics</a>.</p>\n<p>\u201cIt opened my mind that we could apply the same methodology that we use in computer-aided chip design to help the world of drug discovery go from computer-aided drug discovery to computer-aided drug design,\u201d he said, realizing that, \u201cif we scale this up by a billion times, we could simulate biology.\u201d</p>\n<p>After 40 years of advancements in computer-aided chip design, engineers can now build complex computing systems entirely in simulation, Huang explained. Over the next decade, the same could be true for AI-accelerated drug design.</p>\n<p>\u201cAlmost everything will largely start in silico, largely end in silico,\u201d he said, using a term that refers to an experiment run on a computer.</p>\n<h2><b>Collaborating on the Future of Drug Discovery and Medical Instruments</b></h2>\n<p>With the progress made to date, computer-aided drug discovery is \u201cgenuinely miraculous,\u201d Huang said.</p>\n<p>NVIDIA is propelling the field forward by building state-of-the-art AI models and powerful computing platforms, and by collaborating with domain experts and investing in techbio companies.</p>\n<p>\u201cWe are determined to work with you to advance this field,\u201d Huang said, inviting healthcare innovators to reach out to NVIDIA. \u201cWe deeply believe that this is going to be the future of the way that drugs will be discovered and designed.\u201d</p>\n<p>The company\u2019s pipelines for accelerated healthcare include algorithms for cryo-electron microscopy, X-ray crystallography, gene sequencing, amino acid structure prediction and virtual drug molecule screening. And as AI advances, these computing tools are becoming much easier to access, Huang said.</p>\n<p>\u201cBecause of artificial intelligence and the groundbreaking work that our industry has done, we have closed the technology divide in a dramatic way,\u201d he said. \u201cEverybody is a programmer, and the programming language of the future is called \u2018human.\u2019\u201d</p>\n<p>Beyond drug development, this transformation to a software-defined, AI-driven industry will also advance medical instruments.</p>\n<p>\u201cA medical instrument is never going to be the same again. Ultrasound systems, CT scan systems, all kinds of instruments \u2014 they\u2019re always going to be a device plus a whole bunch of AIs,\u201d Huang said. \u201cThe value that will create, the opportunities you create, are going to be incredible.\u201d</p>\n<p>For more from NVIDIA at the J.P. Morgan Healthcare Conference, <a href=\"https://jpmorgan.metameetings.net/events/healthcare24/sessions/49355-nvidia-corporation/webcast/general_signin?gpu_only=true&amp;kiosk=true\" rel=\"noopener\" target=\"_blank\">listen to the audio recording</a> and <a href=\"https://nvidianews.nvidia.com/multimedia/corporate#gallery-1\">view the presentation deck</a> of Powell\u2019s session.</p>\n<p><i>Learn about </i><a href=\"https://www.nvidia.com/en-us/clara/\"><i>NVIDIA\u2019s AI platform for healthcare and life sciences</i></a><i> and subscribe to </i><a href=\"https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/\"><i>NVIDIA healthcare news</i></a><i>.</i></p>\n</div>"
      }
    ],
    "media_content": [
      {
        "url": "https://blogs.nvidia.com/wp-content/uploads/2024/01/hc-corp-jpm23-jhh-kp-jpm-3085763-1280x680-r2.png",
        "type": "image/png",
        "width": "1280",
        "height": "680"
      }
    ],
    "media_thumbnail": [
      {
        "url": "https://blogs.nvidia.com/wp-content/uploads/2024/01/hc-corp-jpm23-jhh-kp-jpm-3085763-1280x680-r2-842x450.png",
        "width": "842",
        "height": "450"
      }
    ],
    "href": ""
  },
  "Kinvolk": {
    "title": "Extending Flatcar: Say 'Goodbye' to torcx and 'Hello' to systemd-sysext",
    "xmlUrl": "https://kinvolk.io/blog/index.xml",
    "htmlUrl": "https://kinvolk.io/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://kinvolk.io/blog/index.xml",
      "value": "Extending Flatcar: Say 'Goodbye' to torcx and 'Hello' to systemd-sysext"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://kinvolk.io/blog/2023/12/extending-flatcar-say-goodbye-to-torcx-and-hello-to-systemd-sysext/"
      }
    ],
    "link": "https://kinvolk.io/blog/2023/12/extending-flatcar-say-goodbye-to-torcx-and-hello-to-systemd-sysext/",
    "published": "Mon, 18 Dec 2023 10:22:13 +0200",
    "published_parsed": [
      2023,
      12,
      18,
      8,
      22,
      13,
      0,
      352,
      0
    ],
    "id": "https://kinvolk.io/blog/2023/12/extending-flatcar-say-goodbye-to-torcx-and-hello-to-systemd-sysext/",
    "guidislink": false,
    "summary": "Flatcar is a minimal, immutable, image-based operating system for fully automated, zero-touch container infrastructure. It ships the bare minimum required for running containers at scale - and usually, the answer to questions like &ldquo;how do I install tool XYZ on Flatcar?&rdquo; is: &ldquo;run it in a container&rdquo;. Sometimes though, &ldquo;tool XYZ&rdquo; needs to operate close to the OS itself, and it&rsquo;s not feasible (or even outright impossible) to run it in a container. (<a href=\"https://kinvolk.io/blog/2023/12/extending-flatcar-say-goodbye-to-torcx-and-hello-to-systemd-sysext/\">Continue reading \u00bb</a>)",
    "summary_detail": {
      "type": "application/xhtml+xml",
      "language": null,
      "base": "https://kinvolk.io/blog/index.xml",
      "value": "Flatcar is a minimal, immutable, image-based operating system for fully automated, zero-touch container infrastructure. It ships the bare minimum required for running containers at scale - and usually, the answer to questions like &ldquo;how do I install tool XYZ on Flatcar?&rdquo; is: &ldquo;run it in a container&rdquo;. Sometimes though, &ldquo;tool XYZ&rdquo; needs to operate close to the OS itself, and it&rsquo;s not feasible (or even outright impossible) to run it in a container. (<a href=\"https://kinvolk.io/blog/2023/12/extending-flatcar-say-goodbye-to-torcx-and-hello-to-systemd-sysext/\">Continue reading \u00bb</a>)"
    }
  },
  "Avenue Code": {
    "title": "Data: An Executive Briefing",
    "xmlUrl": "http://blog.avenuecode.com/rss.xml",
    "htmlUrl": "http://blog.avenuecode.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.avenuecode.com/rss.xml",
      "value": "Data: An Executive Briefing"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.avenuecode.com/data-an-executive-briefing"
      }
    ],
    "link": "https://blog.avenuecode.com/data-an-executive-briefing",
    "summary": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://blog.avenuecode.com/data-an-executive-briefing\" title=\"\"> <img alt=\"Data: An Executive Briefing\" class=\"hs-featured-image\" src=\"https://blog.avenuecode.com/hubfs/businessman-holding-of-global-data-network-and-soc-2022-11-09-15-07-04-utc.jpg\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> The term \"data\" has gained significant prominence recently, leading to the emergence of numerous fields of study and job positions. Now, we encounter terms such as Data Strategy, Data Culture, Data Governance, Data Driven, Data Lake, Data Warehouse, and Big Data. But what does each of these terms mean? \n<br />",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.avenuecode.com/rss.xml",
      "value": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://blog.avenuecode.com/data-an-executive-briefing\" title=\"\"> <img alt=\"Data: An Executive Briefing\" class=\"hs-featured-image\" src=\"https://blog.avenuecode.com/hubfs/businessman-holding-of-global-data-network-and-soc-2022-11-09-15-07-04-utc.jpg\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> The term \"data\" has gained significant prominence recently, leading to the emergence of numerous fields of study and job positions. Now, we encounter terms such as Data Strategy, Data Culture, Data Governance, Data Driven, Data Lake, Data Warehouse, and Big Data. But what does each of these terms mean? \n<br />"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.avenuecode.com/rss.xml",
        "value": "<div class=\"hs-featured-image-wrapper\"> \n <a class=\"hs-featured-image-link\" href=\"https://blog.avenuecode.com/data-an-executive-briefing\" title=\"\"> <img alt=\"Data: An Executive Briefing\" class=\"hs-featured-image\" src=\"https://blog.avenuecode.com/hubfs/businessman-holding-of-global-data-network-and-soc-2022-11-09-15-07-04-utc.jpg\" style=\"width: auto !important; float: left; margin: 0 15px 15px 0;\" /> </a> \n</div> The term \"data\" has gained significant prominence recently, leading to the emergence of numerous fields of study and job positions. Now, we encounter terms such as Data Strategy, Data Culture, Data Governance, Data Driven, Data Lake, Data Warehouse, and Big Data. But what does each of these terms mean? \n<br />  \n<img alt=\"\" height=\"1\" src=\"https://track.hubspot.com/__ptq.gif?a=2564010&amp;k=14&amp;r=https%3A%2F%2Fblog.avenuecode.com%2Fdata-an-executive-briefing&amp;bu=https%253A%252F%252Fblog.avenuecode.com&amp;bvt=rss\" style=\"width: 1px!important;\" width=\"1\" />"
      }
    ],
    "tags": [
      {
        "term": "Database",
        "scheme": null,
        "label": null
      },
      {
        "term": "Data Science",
        "scheme": null,
        "label": null
      },
      {
        "term": "Data",
        "scheme": null,
        "label": null
      },
      {
        "term": "Data and Machine Learning",
        "scheme": null,
        "label": null
      }
    ],
    "published": "Fri, 17 Nov 2023 13:45:52 GMT",
    "published_parsed": [
      2023,
      11,
      17,
      13,
      45,
      52,
      4,
      321,
      0
    ],
    "id": "https://blog.avenuecode.com/data-an-executive-briefing",
    "guidislink": false,
    "updated": "2023-11-17T13:45:52Z",
    "updated_parsed": [
      2023,
      11,
      17,
      13,
      45,
      52,
      4,
      321,
      0
    ],
    "authors": [
      {
        "name": "Iury Rosal"
      }
    ],
    "author": "Iury Rosal",
    "author_detail": {
      "name": "Iury Rosal"
    }
  },
  "Swiggy": {
    "title": "How we optimised page load metrics on Minis",
    "xmlUrl": "https://bytes.swiggy.com/feed",
    "htmlUrl": "https://bytes.swiggy.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://bytes.swiggy.com/feed",
      "value": "How we optimised page load metrics on Minis"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://bytes.swiggy.com/how-we-optimised-page-load-metrics-on-minis-7db422dff0db?source=rss----9556560f659---4"
      }
    ],
    "link": "https://bytes.swiggy.com/how-we-optimised-page-load-metrics-on-minis-7db422dff0db?source=rss----9556560f659---4",
    "id": "https://medium.com/p/7db422dff0db",
    "guidislink": false,
    "tags": [
      {
        "term": "react",
        "scheme": null,
        "label": null
      },
      {
        "term": "swiggy-minis",
        "scheme": null,
        "label": null
      },
      {
        "term": "react-native",
        "scheme": null,
        "label": null
      },
      {
        "term": "swiggy-engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "server-side-rendering",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Arpit Goel"
      }
    ],
    "author": "Arpit Goel",
    "author_detail": {
      "name": "Arpit Goel"
    },
    "published": "Mon, 08 Jan 2024 08:40:21 GMT",
    "published_parsed": [
      2024,
      1,
      8,
      8,
      40,
      21,
      0,
      8,
      0
    ],
    "updated": "2024-01-09T08:02:46.281Z",
    "updated_parsed": [
      2024,
      1,
      9,
      8,
      2,
      46,
      1,
      9,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://bytes.swiggy.com/feed",
        "value": "<h3>How we optimised page load metrics for Minis\u00a0web</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WTiBB4tt16bNoa_a8rG6iw.png\" /></figure><h4>Introduction</h4><p>Minis on Swiggy app was built using React Native to cater to growing needs of native experience and at the same time powering m-web and d-web via the react-native-web. We have developed it as a monorepo to be able to leverage the components across native and web\u00a0stacks</p><p>React-native-web fundamentally converts RN components to React DOM elements. This by default renders the page on client side only which requires all assets to be downloaded, parsed and executed. APIs are fetched and subsequently react-native components are rendered before the user can view any meaningful content.</p><p>To optimize the page load time metrics and improve the SEO, we decided to go with implementing SSR for our\u00a0webview.</p><h4>Server Side Rendering with React\u00a018</h4><ol><li>With Concurrent Mode, React 18 allows the server to start streaming the HTML response to the client as soon as it becomes available, without waiting for the entire application to render. As soon as the content before the first <a href=\"https://react.dev/reference/react/Suspense\">Suspense</a> boundary is ready, the <em>onShellReady</em> function is called, and the HTML can be streamed to the\u00a0client.</li></ol><pre>ReactDOMServer.renderToPipeableStream(<br />        &lt;App /&gt;,<br />        {<br />            bootstrapScripts: ['app.js'],<br />            onShellReady: () =&gt; {<br />                res.setHeader('Content-type', 'text/html');<br />                stream.pipe(res);<br />            },<br />            onError: (error) =&gt; {<br />                //log error<br />            } <br />        }<br />  );</pre><p>2. Hydration can start as soon as the JS assets are loaded. Other Suspended components can be streamed later. The waterfall model of SSR of previous React versions is not a bottleneck here.</p><p>3. HTML streaming is split into multiple chunks with React Suspense. The components which are streamed first are hydrated on priority. This is selective hydration. Also the components which are interacted first by the user, are hydrated\u00a0first.</p><h4>Minis SSR Implementation</h4><p>Below is the high level structure of React components for Minis homepage. <em>ShopLoader</em> component is the placeholder which is rendered before the API calls in the suspended components are resolved.</p><pre>&lt;Suspense fallback={&lt;ShopLoader/&gt;}<br />       &lt;StoreInfo/&gt;<br />       &lt;Suspense fallback={&lt;InstagramPreLoader/&gt;}<br />            &lt;InstagramWidget/&gt;<br />       &lt;/Suspense&gt;<br />       &lt;Suspense fallback={&lt;CatalogLoader/&gt;}<br />           &lt;CatalogView/&gt;<br />       &lt;/Suspense&gt;<br />&lt;/Suspense&gt;</pre><p>Node server renders the app using React 18 streaming API\u200a\u2014\u200a<a href=\"https://react.dev/reference/react-dom/server/renderToPipeableStream\"><em>renderToPipeableStream</em></a>. This allows to render Suspense Components which wasn\u2019t possible with <em>renderToNodeStream</em> earlier</p><ul><li><em>Suspense</em> acts as a split in the rendering process. In the above component structure, the first chunk rendered and streamed back to the client will be <em>ShopLoader</em> as the first suspense boundary is\u00a0hit.</li><li>However, this is not what we want. First html response should be meaningful data. So it makes sense to fetch the<em> API </em>data and provide the response as an initialState. So the <em>StoreInfo</em> component will not suspend and <em>storeInfo</em> html can be streamed in the first chunk\u00a0itself.</li><li>When a component is suspended in React 18, a template element is streamed along with a fallback component, which can be later replaced with the actual component that is streamed later. Additionally, a special comment tag: &lt;!\u200a\u2014\u200a$? \u2192 is added to mark the suspense boundary.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*ouy6l99G0DRU9v_x\" /><figcaption>Template element\u00a0streamed</figcaption></figure><p>React 18 also streams the script to replace this template component with meaningful content markup streamed\u00a0later</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/636/0*avhqJHSmHGy_ByYa\" /><figcaption>Script to replace the placeholder B:1 with actual component S:1</figcaption></figure><ul><li>The rest of the components\u200a\u2014\u200a&lt;InstagramWidget/&gt;\u00a0, &lt;CatalogView/&gt; are streamed later when those suspended boundaries are resolved.</li><li>The API response needs to be sent to the client for hydration. The data will be streamed by the component <em>ServerDataComponent</em></li></ul><pre>renderToPipeableStream( <br />  &lt;&gt;<br />    &lt;App/&gt;<br />    &lt;ServerDataComponent /&gt;<br />  &lt;/&gt;<br />)</pre><pre>//ServerDataComponent:<br /><br />//track all the apis fetches status using React 18 useSyncExternalStore<br />const data = getAllAPIPromises();<br /><br />&lt;Suspense&gt;<br />     &lt;ServerData data={data}/&gt;<br />&lt;/Suspense&gt;</pre><p>ServerData will remain suspended till all the API fetches are resolved. Once the promises are settled\u00a0, ServerData will add a script with the data and will be stream to the client for hydration.</p><pre>&lt;script id=&quot;react-data&quot; dangerouslySetInnerHTML={{_html:Json.stringify(data)}}&gt;&lt;/script&gt;</pre><p>React 18 provides a hook for this <a href=\"https://react.dev/reference/react/useSyncExternalStore\"><strong>useSyncExternalStore</strong></a>. It lets the app subscribe to the external store. ServerDataComponent use this hook to get the data from our app redux store once all promises are resolved.</p><h4>Static Assets</h4><p><em>CSS</em></p><p>Extract the css using RN Stylesheet <em>getStyleElement</em> which returns the object of all the styles of the components. And add to the head element as inline\u00a0style</p><p><em>Fonts and\u00a0JS</em></p><p>Using webpack build time manifest file, extract the chunk names of fonts and JS assets. Preload the fonts and add JS assets to the streaming HTML as async\u00a0scripts</p><h4>Client hydration using react-native-web</h4><p>Client side rendered DOM needs to match with the DOM sent from the\u00a0server.</p><ul><li>Browser client can start the hydration as soon as the JS assets are downloaded\u00a0, but in case the server hasn\u2019t send the server data back yet\u00a0, the hydration will fail\u00a0. So add a listener on <em>DomContentLoad</em> event to wait for the streaming to complete\u00a0, get the initial state before starting the hydration process.</li></ul><pre>document.addEventListener('DOMContentLoaded', () =&gt; {<br />     el = document.getElementById(id) as any;<br />     if (el) resolve(getDataFromEl(el, id));<br />     else reject(new Error('failed to find DOM with rest hooks state'));<br />  });</pre><ul><li>Add the argument <em>hydrate:true</em> to runApplication function of <strong><em>React-native-web</em></strong> to hydrate the\u00a0app.</li></ul><pre>    AppRegistry.registerComponent(&quot;App&quot;, () =&gt; WebApp);<br />    AppRegistry.runApplication(&quot;App&quot;, {<br />        rootTag: document.getElementById(ROOT_ELEMENT_ID),<br />        hydrate: true,<br />    });</pre><ul><li>React 18 does progressive hydration with the help of Suspense without blocking the main thread thereby taking care of the responsiveness. Component-1 hydration happens in one task and Component-2 hydration happens in\u00a0another.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/0*TxVcOqpBT9PNFmol\" /><figcaption>Hydration happening as separate async\u00a0tasks.</figcaption></figure><h4>Client only Components?</h4><p>We might want to render some components only on the client side\u00a0.</p><ul><li>One way is to add a state to the component and update it on useEffect. Return null or preloader if the state is false and return the component if state is true after useEffect update.</li></ul><pre>const [isMounted, setMounted] = React.useState(true);<br />React.useEffect(() =&gt; {<br />        setMounted(false);<br />}, []);<br /><br />return isMounted ? &lt;Component/&gt; : &lt;Preloader/&gt;</pre><ul><li>With the Suspense boundary\u00a0, throw an error in a suspended component if the window object is undefined\u00a0, this will prevent node server to proceed with SSR for that component.</li></ul><pre>export const useRenderClientOnly = (errMsg: string): void =&gt; {<br />    if (typeof window === &quot;undefined&quot; &amp;&amp; Platform.OS === &quot;web&quot;) {<br />        throw new Error(errMsg);<br />    }<br />};<br />//In a Suspended Component<br />useRenderClientOnly(&quot;Render this only on client&quot;)</pre><h4>Impact</h4><p>After implementing SSR, the time it takes to make relevant content visible to the user was reduced from <strong>7.5 sec to 5.2 sec (90 percentile)</strong></p><p>Before SSR:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/516/0*-HXF2SZRDOcV65Ct\" /></figure><p>After SSR:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/516/0*6GvYf_UeHAF2cR2I\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7db422dff0db\" width=\"1\" /><hr /><p><a href=\"https://bytes.swiggy.com/how-we-optimised-page-load-metrics-on-minis-7db422dff0db\">How we optimised page load metrics on Minis</a> was originally published in <a href=\"https://bytes.swiggy.com\">Swiggy Bytes\u200a\u2014\u200aTech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h3>How we optimised page load metrics for Minis\u00a0web</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WTiBB4tt16bNoa_a8rG6iw.png\" /></figure><h4>Introduction</h4><p>Minis on Swiggy app was built using React Native to cater to growing needs of native experience and at the same time powering m-web and d-web via the react-native-web. We have developed it as a monorepo to be able to leverage the components across native and web\u00a0stacks</p><p>React-native-web fundamentally converts RN components to React DOM elements. This by default renders the page on client side only which requires all assets to be downloaded, parsed and executed. APIs are fetched and subsequently react-native components are rendered before the user can view any meaningful content.</p><p>To optimize the page load time metrics and improve the SEO, we decided to go with implementing SSR for our\u00a0webview.</p><h4>Server Side Rendering with React\u00a018</h4><ol><li>With Concurrent Mode, React 18 allows the server to start streaming the HTML response to the client as soon as it becomes available, without waiting for the entire application to render. As soon as the content before the first <a href=\"https://react.dev/reference/react/Suspense\">Suspense</a> boundary is ready, the <em>onShellReady</em> function is called, and the HTML can be streamed to the\u00a0client.</li></ol><pre>ReactDOMServer.renderToPipeableStream(<br />        &lt;App /&gt;,<br />        {<br />            bootstrapScripts: ['app.js'],<br />            onShellReady: () =&gt; {<br />                res.setHeader('Content-type', 'text/html');<br />                stream.pipe(res);<br />            },<br />            onError: (error) =&gt; {<br />                //log error<br />            } <br />        }<br />  );</pre><p>2. Hydration can start as soon as the JS assets are loaded. Other Suspended components can be streamed later. The waterfall model of SSR of previous React versions is not a bottleneck here.</p><p>3. HTML streaming is split into multiple chunks with React Suspense. The components which are streamed first are hydrated on priority. This is selective hydration. Also the components which are interacted first by the user, are hydrated\u00a0first.</p><h4>Minis SSR Implementation</h4><p>Below is the high level structure of React components for Minis homepage. <em>ShopLoader</em> component is the placeholder which is rendered before the API calls in the suspended components are resolved.</p><pre>&lt;Suspense fallback={&lt;ShopLoader/&gt;}<br />       &lt;StoreInfo/&gt;<br />       &lt;Suspense fallback={&lt;InstagramPreLoader/&gt;}<br />            &lt;InstagramWidget/&gt;<br />       &lt;/Suspense&gt;<br />       &lt;Suspense fallback={&lt;CatalogLoader/&gt;}<br />           &lt;CatalogView/&gt;<br />       &lt;/Suspense&gt;<br />&lt;/Suspense&gt;</pre><p>Node server renders the app using React 18 streaming API\u200a\u2014\u200a<a href=\"https://react.dev/reference/react-dom/server/renderToPipeableStream\"><em>renderToPipeableStream</em></a>. This allows to render Suspense Components which wasn\u2019t possible with <em>renderToNodeStream</em> earlier</p><ul><li><em>Suspense</em> acts as a split in the rendering process. In the above component structure, the first chunk rendered and streamed back to the client will be <em>ShopLoader</em> as the first suspense boundary is\u00a0hit.</li><li>However, this is not what we want. First html response should be meaningful data. So it makes sense to fetch the<em> API </em>data and provide the response as an initialState. So the <em>StoreInfo</em> component will not suspend and <em>storeInfo</em> html can be streamed in the first chunk\u00a0itself.</li><li>When a component is suspended in React 18, a template element is streamed along with a fallback component, which can be later replaced with the actual component that is streamed later. Additionally, a special comment tag: &lt;!\u200a\u2014\u200a$? \u2192 is added to mark the suspense boundary.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*ouy6l99G0DRU9v_x\" /><figcaption>Template element\u00a0streamed</figcaption></figure><p>React 18 also streams the script to replace this template component with meaningful content markup streamed\u00a0later</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/636/0*avhqJHSmHGy_ByYa\" /><figcaption>Script to replace the placeholder B:1 with actual component S:1</figcaption></figure><ul><li>The rest of the components\u200a\u2014\u200a&lt;InstagramWidget/&gt;\u00a0, &lt;CatalogView/&gt; are streamed later when those suspended boundaries are resolved.</li><li>The API response needs to be sent to the client for hydration. The data will be streamed by the component <em>ServerDataComponent</em></li></ul><pre>renderToPipeableStream( <br />  &lt;&gt;<br />    &lt;App/&gt;<br />    &lt;ServerDataComponent /&gt;<br />  &lt;/&gt;<br />)</pre><pre>//ServerDataComponent:<br /><br />//track all the apis fetches status using React 18 useSyncExternalStore<br />const data = getAllAPIPromises();<br /><br />&lt;Suspense&gt;<br />     &lt;ServerData data={data}/&gt;<br />&lt;/Suspense&gt;</pre><p>ServerData will remain suspended till all the API fetches are resolved. Once the promises are settled\u00a0, ServerData will add a script with the data and will be stream to the client for hydration.</p><pre>&lt;script id=&quot;react-data&quot; dangerouslySetInnerHTML={{_html:Json.stringify(data)}}&gt;&lt;/script&gt;</pre><p>React 18 provides a hook for this <a href=\"https://react.dev/reference/react/useSyncExternalStore\"><strong>useSyncExternalStore</strong></a>. It lets the app subscribe to the external store. ServerDataComponent use this hook to get the data from our app redux store once all promises are resolved.</p><h4>Static Assets</h4><p><em>CSS</em></p><p>Extract the css using RN Stylesheet <em>getStyleElement</em> which returns the object of all the styles of the components. And add to the head element as inline\u00a0style</p><p><em>Fonts and\u00a0JS</em></p><p>Using webpack build time manifest file, extract the chunk names of fonts and JS assets. Preload the fonts and add JS assets to the streaming HTML as async\u00a0scripts</p><h4>Client hydration using react-native-web</h4><p>Client side rendered DOM needs to match with the DOM sent from the\u00a0server.</p><ul><li>Browser client can start the hydration as soon as the JS assets are downloaded\u00a0, but in case the server hasn\u2019t send the server data back yet\u00a0, the hydration will fail\u00a0. So add a listener on <em>DomContentLoad</em> event to wait for the streaming to complete\u00a0, get the initial state before starting the hydration process.</li></ul><pre>document.addEventListener('DOMContentLoaded', () =&gt; {<br />     el = document.getElementById(id) as any;<br />     if (el) resolve(getDataFromEl(el, id));<br />     else reject(new Error('failed to find DOM with rest hooks state'));<br />  });</pre><ul><li>Add the argument <em>hydrate:true</em> to runApplication function of <strong><em>React-native-web</em></strong> to hydrate the\u00a0app.</li></ul><pre>    AppRegistry.registerComponent(&quot;App&quot;, () =&gt; WebApp);<br />    AppRegistry.runApplication(&quot;App&quot;, {<br />        rootTag: document.getElementById(ROOT_ELEMENT_ID),<br />        hydrate: true,<br />    });</pre><ul><li>React 18 does progressive hydration with the help of Suspense without blocking the main thread thereby taking care of the responsiveness. Component-1 hydration happens in one task and Component-2 hydration happens in\u00a0another.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/0*TxVcOqpBT9PNFmol\" /><figcaption>Hydration happening as separate async\u00a0tasks.</figcaption></figure><h4>Client only Components?</h4><p>We might want to render some components only on the client side\u00a0.</p><ul><li>One way is to add a state to the component and update it on useEffect. Return null or preloader if the state is false and return the component if state is true after useEffect update.</li></ul><pre>const [isMounted, setMounted] = React.useState(true);<br />React.useEffect(() =&gt; {<br />        setMounted(false);<br />}, []);<br /><br />return isMounted ? &lt;Component/&gt; : &lt;Preloader/&gt;</pre><ul><li>With the Suspense boundary\u00a0, throw an error in a suspended component if the window object is undefined\u00a0, this will prevent node server to proceed with SSR for that component.</li></ul><pre>export const useRenderClientOnly = (errMsg: string): void =&gt; {<br />    if (typeof window === &quot;undefined&quot; &amp;&amp; Platform.OS === &quot;web&quot;) {<br />        throw new Error(errMsg);<br />    }<br />};<br />//In a Suspended Component<br />useRenderClientOnly(&quot;Render this only on client&quot;)</pre><h4>Impact</h4><p>After implementing SSR, the time it takes to make relevant content visible to the user was reduced from <strong>7.5 sec to 5.2 sec (90 percentile)</strong></p><p>Before SSR:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/516/0*-HXF2SZRDOcV65Ct\" /></figure><p>After SSR:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/516/0*6GvYf_UeHAF2cR2I\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7db422dff0db\" width=\"1\" /><hr /><p><a href=\"https://bytes.swiggy.com/how-we-optimised-page-load-metrics-on-minis-7db422dff0db\">How we optimised page load metrics on Minis</a> was originally published in <a href=\"https://bytes.swiggy.com\">Swiggy Bytes\u200a\u2014\u200aTech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "WePay": {
    "title": "WePay's Logging Infrastructure",
    "xmlUrl": "https://wecode.wepay.com/feed.xml",
    "htmlUrl": "https://wecode.wepay.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://wecode.wepay.com/feed.xml",
      "value": "WePay's Logging Infrastructure"
    },
    "summary": "<h3 id=\"introduction\">Introduction</h3>\n\n<p>Without logs all of us would be stumbling in the dark. We would know that something is wrong, but be unable to figure out exactly what. This article is going to talk about how WePay\u2019s logging infrastructure is set up.</p>\n\n<p>Our centralized logging architecture collects logs from all of our microservices, virtual machines, audit logs from our cloud provider and external vendors, and stores them in a proper format to help search and analyze issues and errors.</p>\n\n<p>WePay uses the <a href=\"https://www.elastic.co/what-is/elk-stack\">ELK stack</a> and <a href=\"https://www.confluent.io/what-is-apache-kafka/\">Kafka</a> components in it\u2019s core logging pipeline.</p>\n\n<p>In this article we are going to talk about:</p>\n\n<ol>\n  <li>\n    <p>Log Aggregation</p>\n  </li>\n  <li>\n    <p>Log Processing and Enrichment</p>\n  </li>\n  <li>\n    <p>Log Buffering and Ingestion</p>\n  </li>\n  <li>\n    <p>Storing Logs</p>\n  </li>\n  <li>\n    <p>Searching Logs</p>\n  </li>\n</ol>\n\n<p><img alt=\"log_pipeline\" class=\"center-image\" id=\"log_pipeline\" src=\"https://wecode.wepay.com/assets/2021-08-10-wepay-logging-infra/image_0.png\" /></p>\n\n<h3 id=\"log-aggregation\">Log Aggregation</h3>\n\n<p>WePay uses filebeat for tailing and shipping logs from VM\u2019s and all our GKE microservices. Filebeat guarantees that events will be delivered to the configured output at least once and with no data loss. Filebeat is able to achieve this behavior because it stores the delivery state of each event in the registry file. In situations where the defined output is blocked and has not confirmed all events, Filebeat will keep trying to send events until the output acknowledges that it has received the events.</p>\n\n<p>Filebeat forwards all logs to logstash for more advanced processing and enrichment.</p>\n\n<h3 id=\"log-processing-and-enrichment\">Log Processing and Enrichment</h3>\n\n<p>Logstash filters parse each log event, identify named fields to build structure, and transform them to converge on a common format for more powerful analysis. Logstash helps us in:</p>\n\n<ul>\n  <li>\n    <p>Deriving structure from unstructured data with powerful grok and mutate filters.</p>\n  </li>\n  <li>\n    <p>Decipher geo coordinates from IP addresses.</p>\n  </li>\n  <li>\n    <p>Anonymize PII data, exclude sensitive fields completely from the logs.</p>\n  </li>\n  <li>\n    <p>Ease overall processing, independent of the data source, format, or schema.</p>\n  </li>\n  <li>\n    <p>Convert json log messages into avro format that match an avro schema so then they can be stored in Kafka.</p>\n  </li>\n</ul>\n\n<p>A raw nginx log message can be parsed into something like:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>10.73.1.39 - test [29/May/2021:23:10:31 +0000] \"GET /v1/sys/health HTTP/1.0\" 200 293 \"-\" \"-\" \"-\"\n\nClient IP : 10.73.1.39\nUser : test \nTimestamp : 29/May/2021:23:10:31\nMethod: GET\nURL: /v1/sys/health\nHTTP_Version : 1.0\nResponse : 200\nRequest Bytes : 293\n</code></pre></div></div>\n\n<p>WePay relies on Avro messages because the structure of logs changes over time. If a \u201cstring\u201d field is converted into an \u201cint\u201d field we would have elasticsearch mapping conflicts, Avro schemas help ensure that we don\u2019t have conflicts in our ElasticSchema\u2019s.</p>\n\n<h3 id=\"log-buffering-and-ingestion\">Log Buffering and Ingestion</h3>\n\n<h4 id=\"buffering\">Buffering</h4>\n\n<p>Sometimes applications log at unprecedented levels, during incidents, incorrect logging format, or when there are bugs in the application. These sudden log surges can overwhelm our logging infrastructure. To protect Elasticsearch from such cases of data surges. WePay uses Apache Kafka to buffer logs. In our logging pipeline, logstash forwards all the logs to Kafka in Avro format.</p>\n\n<h4 id=\"ingestion\">Ingestion</h4>\n\n<p>WePay uses light weight Confluent Kafka Connectors for ingesting logs into Elastic/Google BigQuery/Google Cloud Storage Buckets. We use 3 kind of connectors:</p>\n\n<ul>\n  <li>\n    <p><a href=\"https://github.com/confluentinc/kafka-connect-elasticsearch\">Kafka Connect Elasticsearch</a> to ingest logs into our elastic Cluster</p>\n  </li>\n  <li>\n    <p>Our inhouse developed <a href=\"https://github.com/confluentinc/kafka-connect-bigquery\">Google BigQuery Sink Connector</a> to ingest logs into Google\u2019s BigQuery.</p>\n  </li>\n  <li>\n    <p><a href=\"https://docs.confluent.io/kafka-connect-gcs-sink/current/overview.html\">GCS Sink Connector</a> to ingest logs into Google Cloud Storage Buckets.</p>\n  </li>\n</ul>\n\n<p><img alt=\"kafka_connectors\" class=\"center-image\" id=\"kafka_connectors\" src=\"https://wecode.wepay.com/assets/2021-08-10-wepay-logging-infra/image_1.png\" /></p>\n\n<h3 id=\"storing-logs\">Storing Logs</h3>\n\n<p>WePay, as a payments company, is subject to <a href=\"https://en.wikipedia.org/wiki/Payment_Card_Industry_Data_Security_Standard\">PCI DSS audits</a>. PCI requirements state that logs must be retained for at least one year. Ninety days of logs must also be available for immediate analysis. We store our logs in 3 places:</p>\n\n<ul>\n  <li>\n    <p><a href=\"https://www.elastic.co/elasticsearch/\">Elasticsearch</a> - 90 days of retention policy for immediate analysis.</p>\n  </li>\n  <li>\n    <p><a href=\"https://cloud.google.com/bigquery\">Google Big Query</a><a href=\"https://cloud.google.com/bigquery\"> </a>- Logs are retained for long-term per regulatory and compliance requirements\nFor analysis when we want to look for historic data ( data not in elastic because of retention policies ). With BigQuery\u2019s powerful query interfaces we can structure and search for logs as needed.</p>\n  </li>\n  <li>\n    <p><a href=\"https://cloud.google.com/storage\">Google Cloud Storage</a> - Logs are retained for long-term per regulatory and compliance requirements. We mainly store logs in GCS to backfill Google\u2019s BQ in times when the connector to BigQuery is broken.</p>\n  </li>\n</ul>\n\n<p>At WePay we have 4 environments: dev, testing, staging and production. Each environment generates a lot of logs. We have two elastic clusters to store these logs:</p>\n\n<ul>\n  <li>\n    <p>A Dev Elastic cluster for development, Testing and staging environment logs.</p>\n  </li>\n  <li>\n    <p>A production Elastic cluster for our production environment logs.</p>\n  </li>\n</ul>\n\n<p>Setting up two elastic clusters had the following advantages:</p>\n\n<ul>\n  <li>\n    <p>If an application in dev or testing environments goes rogue and starts logging at unprecedented levels because of a bug or incorrect logging format, this will impact only our dev cluster.</p>\n  </li>\n  <li>\n    <p>When upgrading elastic to a new version, we can first upgrade the dev cluster; if we encounter any backward compatibility issues, only the dev cluster would be impacted. The production cluster remains safe.</p>\n  </li>\n</ul>\n\n<p><img alt=\"elastic_dev_prd\" class=\"center-image\" id=\"elastic_dev_prd\" src=\"https://wecode.wepay.com/assets/2021-08-10-wepay-logging-infra/image_2.png\" /></p>\n\n<h4 id=\"hot-warm-cold-architecture\">Hot Warm Cold Architecture</h4>\n\n<p>With the amount of data that we get, we had to think upstream while designing the data retention and index life cycle management policies.</p>\n\n<p>There are 3 kinds of elastic data nodes setup:</p>\n\n<ul>\n  <li>\n    <p>Hot nodes which will have all new indexes, and will get extensive reads and writes. This is where all new data will be indexed. These are CPU extensive nodes.</p>\n  </li>\n  <li>\n    <p>Warm nodes will host old indexes and will get all reads and no writes.</p>\n  </li>\n  <li>\n    <p>Cold nodes will host old indices and will barely get any reads.</p>\n  </li>\n</ul>\n\n<p><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/index-lifecycle-management.html\">Elastic\u2019s ILM</a> gives us the ability to manage indexes by triggering actions when conditions are met. With ILM policies we have something like:</p>\n\n<ul>\n  <li>\n    <p>For creating a new index and indexing all data use hot nodes. The ILM policy will start by setting the index priority to a high value for the indices so that hot indexes will recover before other indexes in the event of failures.</p>\n  </li>\n  <li>\n    <p>After the index has completed one week of it\u2019s time in a hot node, merge the number of segments to 1 and move it to the warm node.</p>\n  </li>\n  <li>\n    <p>After the index is completed 1 month of its time in the warm node, freeze the index and move it to the cold node.</p>\n  </li>\n  <li>\n    <p>Delete the index after 3 months.</p>\n  </li>\n</ul>\n\n<h3 id=\"searching---kibana\">Searching - Kibana</h3>\n\n<p>In the previous section, we talked about how we have two elastic clusters. We didn\u2019t want two Kibana\u2019s for searching logs in each cluster, so we decided to go with cross cluster search.</p>\n\n<p>We achieved this by creating a third elasticsearch cluster, that sends requests to the dev and production clusters. This architecture has several benefits:</p>\n\n<ul>\n  <li>\n    <p>All security roles and access permissions for end users are defined in this cluster, hence we avoid creating duplicate security mappings in dev and production logging clusters.</p>\n  </li>\n  <li>\n    <p>Licensed Machine learning nodes run only on this proxy cluster to gather insights from the logs stored in Dev and Production Cluster.</p>\n  </li>\n  <li>\n    <p>A Proxy cluster can help set search thread throttling.</p>\n  </li>\n  <li>\n    <p>An end user in Kibana with superuser permissions won\u2019t be able to make changes to Dev and Production clusters, hence increasing the overall security.</p>\n  </li>\n</ul>\n\n<p><img alt=\"proxy_search\" class=\"center-image\" id=\"proxy_search\" src=\"https://wecode.wepay.com/assets/2021-08-10-wepay-logging-infra/image_3.png\" /></p>\n\n<h3 id=\"future-work\">Future Work</h3>\n\n<ul>\n  <li>\n    <p>We aim at getting APM data from our applications into elasticsearch. This will help us to strongly correlate logging events with APM insights.</p>\n  </li>\n  <li>\n    <p>We plan on setting up <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-ccr.html\">Cross Cluster Replication</a> across multiple regions with the active passive model, and switching between each other during region failures for better fault tolerance.</p>\n  </li>\n  <li>\n    <p>We plan on using <a href=\"https://www.elastic.co/blog/introducing-elasticsearch-frozen-tier-searchbox-on-s3\">Frozen Tier</a> for elastic, for searching for longer duration of logs ( 90+ days ) by referencing storage buckets.</p>\n  </li>\n</ul>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>The elastic clusters have been stress tested to handle upto 80k logs per second. Separating the Dev and Production elastic clusters has helped us protect the Production logging pipeline from Dev environment data surges. The log pipeline to BigQuery makes sure we have longer retention of data at low cost. The Proxy cluster along with Cross Cluster Search has helped us protect the elasticsearch data in Dev and Production clusters by having a single point authenticating and surfacing all search requests.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://wecode.wepay.com/feed.xml",
      "value": "<h3 id=\"introduction\">Introduction</h3>\n\n<p>Without logs all of us would be stumbling in the dark. We would know that something is wrong, but be unable to figure out exactly what. This article is going to talk about how WePay\u2019s logging infrastructure is set up.</p>\n\n<p>Our centralized logging architecture collects logs from all of our microservices, virtual machines, audit logs from our cloud provider and external vendors, and stores them in a proper format to help search and analyze issues and errors.</p>\n\n<p>WePay uses the <a href=\"https://www.elastic.co/what-is/elk-stack\">ELK stack</a> and <a href=\"https://www.confluent.io/what-is-apache-kafka/\">Kafka</a> components in it\u2019s core logging pipeline.</p>\n\n<p>In this article we are going to talk about:</p>\n\n<ol>\n  <li>\n    <p>Log Aggregation</p>\n  </li>\n  <li>\n    <p>Log Processing and Enrichment</p>\n  </li>\n  <li>\n    <p>Log Buffering and Ingestion</p>\n  </li>\n  <li>\n    <p>Storing Logs</p>\n  </li>\n  <li>\n    <p>Searching Logs</p>\n  </li>\n</ol>\n\n<p><img alt=\"log_pipeline\" class=\"center-image\" id=\"log_pipeline\" src=\"https://wecode.wepay.com/assets/2021-08-10-wepay-logging-infra/image_0.png\" /></p>\n\n<h3 id=\"log-aggregation\">Log Aggregation</h3>\n\n<p>WePay uses filebeat for tailing and shipping logs from VM\u2019s and all our GKE microservices. Filebeat guarantees that events will be delivered to the configured output at least once and with no data loss. Filebeat is able to achieve this behavior because it stores the delivery state of each event in the registry file. In situations where the defined output is blocked and has not confirmed all events, Filebeat will keep trying to send events until the output acknowledges that it has received the events.</p>\n\n<p>Filebeat forwards all logs to logstash for more advanced processing and enrichment.</p>\n\n<h3 id=\"log-processing-and-enrichment\">Log Processing and Enrichment</h3>\n\n<p>Logstash filters parse each log event, identify named fields to build structure, and transform them to converge on a common format for more powerful analysis. Logstash helps us in:</p>\n\n<ul>\n  <li>\n    <p>Deriving structure from unstructured data with powerful grok and mutate filters.</p>\n  </li>\n  <li>\n    <p>Decipher geo coordinates from IP addresses.</p>\n  </li>\n  <li>\n    <p>Anonymize PII data, exclude sensitive fields completely from the logs.</p>\n  </li>\n  <li>\n    <p>Ease overall processing, independent of the data source, format, or schema.</p>\n  </li>\n  <li>\n    <p>Convert json log messages into avro format that match an avro schema so then they can be stored in Kafka.</p>\n  </li>\n</ul>\n\n<p>A raw nginx log message can be parsed into something like:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>10.73.1.39 - test [29/May/2021:23:10:31 +0000] \"GET /v1/sys/health HTTP/1.0\" 200 293 \"-\" \"-\" \"-\"\n\nClient IP : 10.73.1.39\nUser : test \nTimestamp : 29/May/2021:23:10:31\nMethod: GET\nURL: /v1/sys/health\nHTTP_Version : 1.0\nResponse : 200\nRequest Bytes : 293\n</code></pre></div></div>\n\n<p>WePay relies on Avro messages because the structure of logs changes over time. If a \u201cstring\u201d field is converted into an \u201cint\u201d field we would have elasticsearch mapping conflicts, Avro schemas help ensure that we don\u2019t have conflicts in our ElasticSchema\u2019s.</p>\n\n<h3 id=\"log-buffering-and-ingestion\">Log Buffering and Ingestion</h3>\n\n<h4 id=\"buffering\">Buffering</h4>\n\n<p>Sometimes applications log at unprecedented levels, during incidents, incorrect logging format, or when there are bugs in the application. These sudden log surges can overwhelm our logging infrastructure. To protect Elasticsearch from such cases of data surges. WePay uses Apache Kafka to buffer logs. In our logging pipeline, logstash forwards all the logs to Kafka in Avro format.</p>\n\n<h4 id=\"ingestion\">Ingestion</h4>\n\n<p>WePay uses light weight Confluent Kafka Connectors for ingesting logs into Elastic/Google BigQuery/Google Cloud Storage Buckets. We use 3 kind of connectors:</p>\n\n<ul>\n  <li>\n    <p><a href=\"https://github.com/confluentinc/kafka-connect-elasticsearch\">Kafka Connect Elasticsearch</a> to ingest logs into our elastic Cluster</p>\n  </li>\n  <li>\n    <p>Our inhouse developed <a href=\"https://github.com/confluentinc/kafka-connect-bigquery\">Google BigQuery Sink Connector</a> to ingest logs into Google\u2019s BigQuery.</p>\n  </li>\n  <li>\n    <p><a href=\"https://docs.confluent.io/kafka-connect-gcs-sink/current/overview.html\">GCS Sink Connector</a> to ingest logs into Google Cloud Storage Buckets.</p>\n  </li>\n</ul>\n\n<p><img alt=\"kafka_connectors\" class=\"center-image\" id=\"kafka_connectors\" src=\"https://wecode.wepay.com/assets/2021-08-10-wepay-logging-infra/image_1.png\" /></p>\n\n<h3 id=\"storing-logs\">Storing Logs</h3>\n\n<p>WePay, as a payments company, is subject to <a href=\"https://en.wikipedia.org/wiki/Payment_Card_Industry_Data_Security_Standard\">PCI DSS audits</a>. PCI requirements state that logs must be retained for at least one year. Ninety days of logs must also be available for immediate analysis. We store our logs in 3 places:</p>\n\n<ul>\n  <li>\n    <p><a href=\"https://www.elastic.co/elasticsearch/\">Elasticsearch</a> - 90 days of retention policy for immediate analysis.</p>\n  </li>\n  <li>\n    <p><a href=\"https://cloud.google.com/bigquery\">Google Big Query</a><a href=\"https://cloud.google.com/bigquery\"> </a>- Logs are retained for long-term per regulatory and compliance requirements\nFor analysis when we want to look for historic data ( data not in elastic because of retention policies ). With BigQuery\u2019s powerful query interfaces we can structure and search for logs as needed.</p>\n  </li>\n  <li>\n    <p><a href=\"https://cloud.google.com/storage\">Google Cloud Storage</a> - Logs are retained for long-term per regulatory and compliance requirements. We mainly store logs in GCS to backfill Google\u2019s BQ in times when the connector to BigQuery is broken.</p>\n  </li>\n</ul>\n\n<p>At WePay we have 4 environments: dev, testing, staging and production. Each environment generates a lot of logs. We have two elastic clusters to store these logs:</p>\n\n<ul>\n  <li>\n    <p>A Dev Elastic cluster for development, Testing and staging environment logs.</p>\n  </li>\n  <li>\n    <p>A production Elastic cluster for our production environment logs.</p>\n  </li>\n</ul>\n\n<p>Setting up two elastic clusters had the following advantages:</p>\n\n<ul>\n  <li>\n    <p>If an application in dev or testing environments goes rogue and starts logging at unprecedented levels because of a bug or incorrect logging format, this will impact only our dev cluster.</p>\n  </li>\n  <li>\n    <p>When upgrading elastic to a new version, we can first upgrade the dev cluster; if we encounter any backward compatibility issues, only the dev cluster would be impacted. The production cluster remains safe.</p>\n  </li>\n</ul>\n\n<p><img alt=\"elastic_dev_prd\" class=\"center-image\" id=\"elastic_dev_prd\" src=\"https://wecode.wepay.com/assets/2021-08-10-wepay-logging-infra/image_2.png\" /></p>\n\n<h4 id=\"hot-warm-cold-architecture\">Hot Warm Cold Architecture</h4>\n\n<p>With the amount of data that we get, we had to think upstream while designing the data retention and index life cycle management policies.</p>\n\n<p>There are 3 kinds of elastic data nodes setup:</p>\n\n<ul>\n  <li>\n    <p>Hot nodes which will have all new indexes, and will get extensive reads and writes. This is where all new data will be indexed. These are CPU extensive nodes.</p>\n  </li>\n  <li>\n    <p>Warm nodes will host old indexes and will get all reads and no writes.</p>\n  </li>\n  <li>\n    <p>Cold nodes will host old indices and will barely get any reads.</p>\n  </li>\n</ul>\n\n<p><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/index-lifecycle-management.html\">Elastic\u2019s ILM</a> gives us the ability to manage indexes by triggering actions when conditions are met. With ILM policies we have something like:</p>\n\n<ul>\n  <li>\n    <p>For creating a new index and indexing all data use hot nodes. The ILM policy will start by setting the index priority to a high value for the indices so that hot indexes will recover before other indexes in the event of failures.</p>\n  </li>\n  <li>\n    <p>After the index has completed one week of it\u2019s time in a hot node, merge the number of segments to 1 and move it to the warm node.</p>\n  </li>\n  <li>\n    <p>After the index is completed 1 month of its time in the warm node, freeze the index and move it to the cold node.</p>\n  </li>\n  <li>\n    <p>Delete the index after 3 months.</p>\n  </li>\n</ul>\n\n<h3 id=\"searching---kibana\">Searching - Kibana</h3>\n\n<p>In the previous section, we talked about how we have two elastic clusters. We didn\u2019t want two Kibana\u2019s for searching logs in each cluster, so we decided to go with cross cluster search.</p>\n\n<p>We achieved this by creating a third elasticsearch cluster, that sends requests to the dev and production clusters. This architecture has several benefits:</p>\n\n<ul>\n  <li>\n    <p>All security roles and access permissions for end users are defined in this cluster, hence we avoid creating duplicate security mappings in dev and production logging clusters.</p>\n  </li>\n  <li>\n    <p>Licensed Machine learning nodes run only on this proxy cluster to gather insights from the logs stored in Dev and Production Cluster.</p>\n  </li>\n  <li>\n    <p>A Proxy cluster can help set search thread throttling.</p>\n  </li>\n  <li>\n    <p>An end user in Kibana with superuser permissions won\u2019t be able to make changes to Dev and Production clusters, hence increasing the overall security.</p>\n  </li>\n</ul>\n\n<p><img alt=\"proxy_search\" class=\"center-image\" id=\"proxy_search\" src=\"https://wecode.wepay.com/assets/2021-08-10-wepay-logging-infra/image_3.png\" /></p>\n\n<h3 id=\"future-work\">Future Work</h3>\n\n<ul>\n  <li>\n    <p>We aim at getting APM data from our applications into elasticsearch. This will help us to strongly correlate logging events with APM insights.</p>\n  </li>\n  <li>\n    <p>We plan on setting up <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-ccr.html\">Cross Cluster Replication</a> across multiple regions with the active passive model, and switching between each other during region failures for better fault tolerance.</p>\n  </li>\n  <li>\n    <p>We plan on using <a href=\"https://www.elastic.co/blog/introducing-elasticsearch-frozen-tier-searchbox-on-s3\">Frozen Tier</a> for elastic, for searching for longer duration of logs ( 90+ days ) by referencing storage buckets.</p>\n  </li>\n</ul>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>The elastic clusters have been stress tested to handle upto 80k logs per second. Separating the Dev and Production elastic clusters has helped us protect the Production logging pipeline from Dev environment data surges. The log pipeline to BigQuery makes sure we have longer retention of data at low cost. The Proxy cluster along with Cross Cluster Search has helped us protect the elasticsearch data in Dev and Production clusters by having a single point authenticating and surfacing all search requests.</p>"
    },
    "published": "Tue, 10 Aug 2021 07:00:00 +0000",
    "published_parsed": [
      2021,
      8,
      10,
      7,
      0,
      0,
      1,
      222,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://wecode.wepay.com/posts/wepay-logging-infra"
      }
    ],
    "link": "https://wecode.wepay.com/posts/wepay-logging-infra",
    "id": "https://wecode.wepay.com/posts/wepay-logging-infra",
    "guidislink": false,
    "tags": [
      {
        "term": "Elasticsearch",
        "scheme": null,
        "label": null
      }
    ]
  },
  "Soshace": {
    "title": "Sending Emails in Java Applications: A Comprehensive Guide to JavaMail and SMTP Configuration",
    "xmlUrl": "https://blog.soshace.com/en/feed/",
    "htmlUrl": "https://blog.soshace.com/en/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://soshace.com/feed/",
      "value": "Sending Emails in Java Applications: A Comprehensive Guide to JavaMail and SMTP Configuration"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://soshace.com/sending-emails-in-java-applications-a-comprehensive-guide-to-javamail-and-smtp-configuration/"
      }
    ],
    "link": "https://soshace.com/sending-emails-in-java-applications-a-comprehensive-guide-to-javamail-and-smtp-configuration/",
    "comments": "https://soshace.com/sending-emails-in-java-applications-a-comprehensive-guide-to-javamail-and-smtp-configuration/#respond",
    "published": "Tue, 09 Jan 2024 12:59:41 +0000",
    "published_parsed": [
      2024,
      1,
      9,
      12,
      59,
      41,
      1,
      9,
      0
    ],
    "authors": [
      {
        "name": "Mohan"
      }
    ],
    "author": "Mohan",
    "author_detail": {
      "name": "Mohan"
    },
    "tags": [
      {
        "term": "Java",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://soshace.com/?p=119498",
    "guidislink": false,
    "summary": "<p>The JavaMail API, part of the Java EE (Enterprise Edition) platform, simplifies the process of sending and receiving emails in Java applications. It provides a set of classes and interfaces for working with email protocols, making it a go-to solution for developers looking to implement robust email functionality.</p>\n<p>The post <a href=\"https://soshace.com/sending-emails-in-java-applications-a-comprehensive-guide-to-javamail-and-smtp-configuration/\" rel=\"nofollow\">Sending Emails in Java Applications: A Comprehensive Guide to JavaMail and SMTP Configuration</a> appeared first on <a href=\"https://soshace.com\" rel=\"nofollow\">Soshace</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://soshace.com/feed/",
      "value": "<p>The JavaMail API, part of the Java EE (Enterprise Edition) platform, simplifies the process of sending and receiving emails in Java applications. It provides a set of classes and interfaces for working with email protocols, making it a go-to solution for developers looking to implement robust email functionality.</p>\n<p>The post <a href=\"https://soshace.com/sending-emails-in-java-applications-a-comprehensive-guide-to-javamail-and-smtp-configuration/\" rel=\"nofollow\">Sending Emails in Java Applications: A Comprehensive Guide to JavaMail and SMTP Configuration</a> appeared first on <a href=\"https://soshace.com\" rel=\"nofollow\">Soshace</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://soshace.com/feed/",
        "value": "<div class=\"wp-caption alignnone\" id=\"attachment_120752\" style=\"width: 889px;\"><img alt=\"Sending Emails in Java Applications: A Comprehensive Guide to JavaMail and SMTP Configuration\" class=\"wp-image-120752 size-full\" height=\"461\" src=\"https://soshace.com/wp-content/uploads/2024/01/sending-emails-in-java-applications-a-comprehensive-guide-to-javamail-and-smtp-configuration-cover-image-879.png\" title=\"Sending Emails in Java Applications: A Comprehensive Guide to JavaMail and SMTP Configuration\" width=\"879\" /><p class=\"wp-caption-text\" id=\"caption-attachment-120752\">Sending Emails in Java Applications: A Comprehensive Guide to JavaMail and SMTP Configuration</p></div>\n<h2>Table of Contents</h2>\n<ol>\n<li>Introduction</li>\n<li>Setting Up Your JavaMail Environment</li>\n<li>Understanding JavaMail Components</li>\n<li>Configuring SMTP for JavaMail</li>\n<li>Sending Simple Emails</li>\n<li>Advanced Email Features</li>\n<li>Handling Email Responses</li>\n<li>Best Practices for Email Sending in Java</li>\n<li>Troubleshooting Common Issues</li>\n<li>Conclusion</li>\n</ol>\n<h3>1. Introduction</h3>\n<h4>1.1 Why Email Communication in Java Applications?</h4>\n<p>Email communication is a vital aspect of modern applications, facilitating various functionalities like user notifications, password resets, and transactional emails. Integrating email capabilities into Java applications enhances user experience and ensures effective communication between the application and its users.</p>\n<h3>1.2 JavaMail API Overview</h3>\n<p>The JavaMail API, part of the Java EE (Enterprise Edition) platform, simplifies the process of sending and receiving emails in Java applications. It provides a set of classes and interfaces for working with email protocols, making it a go-to solution for developers looking to implement robust email functionality.</p>\n<h3>2. Setting Up Your JavaMail Environment</h3>\n<h4>2.1 Downloading and Including JavaMail Library</h4>\n<p>Before getting started, download the JavaMail library from the official Oracle website or your preferred repository. Once downloaded, include the JAR files in your Java project. For example, if you&#8217;re using Maven, add the following dependency to your pom.xml:</p><pre class=\"crayon-plain-tag\">&lt;dependencies&gt;\n        &lt;!-- Add JavaMail API dependency --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.sun.mail&lt;/groupId&gt;\n            &lt;artifactId&gt;javax.mail&lt;/artifactId&gt;\n            &lt;version&gt;1.6.2&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.sun.mail&lt;/groupId&gt;\n            &lt;artifactId&gt;jakarta.mail&lt;/artifactId&gt;\n            &lt;version&gt;1.6.7&lt;/version&gt;\n        &lt;/dependency&gt;\n&lt;/dependencies&gt;</pre><p></p>\n<h4>2.2 Configuring Your Java Project</h4>\n<p>Configure your Java project to use the JavaMail API. If you&#8217;re using an Integrated Development Environment (IDE) like Eclipse or IntelliJ, make sure to add the JavaMail library to your project&#8217;s build path.</p>\n<h3>3. Understanding JavaMail Components</h3>\n<h4>3.1 Session</h4>\n<p>The Session class in JavaMail represents a mail session, which encapsulates the properties and settings for connecting to a mail server. To create a Session instance, you need to use the Session.getInstance() method:</p><pre class=\"crayon-plain-tag\">import javax.mail.Session;\nimport java.util.Properties;\n\npublic class EmailSender {\n    public static void main(String[] args) {\n        Properties properties = new Properties();\n        properties.put(\"mail.smtp.host\", \"your-smtp-host.com\");\n        properties.put(\"mail.smtp.port\", \"587\");\n        properties.put(\"mail.smtp.auth\", \"true\");\n\n        Session session = Session.getInstance(properties);\n    }\n}</pre><p></p>\n<h4>3.2 Message</h4>\n<p>The Message class represents an email message. To create a simple text message, use the MimeMessage class:</p><pre class=\"crayon-plain-tag\">import javax.mail.Message;\nimport javax.mail.MessagingException;\nimport javax.mail.internet.InternetAddress;\nimport javax.mail.internet.MimeMessage;\n\npublic class EmailSender {\n    public static void main(String[] args) throws MessagingException {\n        // Assuming 'session' is a configured Session instance\n        Message message = new MimeMessage(session);\n        message.setFrom(new InternetAddress(\"sender@example.com\"));\n        message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"recipient@example.com\"));\n        message.setSubject(\"Hello, JavaMail!\");\n        message.setText(\"This is a test email from JavaMail.\");\n\n        // Now 'message' is ready to be sent\n    }\n}</pre><p></p>\n<h4>3.3 Transport</h4>\n<p>The Transport class handles the actual delivery of email messages. To send a message, use the Transport.send() method:</p><pre class=\"crayon-plain-tag\">import javax.mail.Transport;\n\npublic class EmailSender {\n    public static void main(String[] args) throws Exception {\n        // Assuming 'session' and 'message' are configured instances\n        Transport.send(message);\n    }\n}</pre><p></p>\n<h4>3.4 Store</h4>\n<p>The Store class in JavaMail is a fundamental component that facilitates the retrieval of email messages from a mail server. While our focus in this guide has primarily been on sending emails, understanding how to retrieve and manage incoming messages is equally important for comprehensive email functionality in Java applications.</p>\n<p><strong>IMAP</strong>: IMAP is a widely used protocol for retrieving emails from a server. It allows users to view and manipulate messages without downloading them to the local machine. IMAP maintains the messages on the server, providing a synchronized view across multiple devices.<br />\n<strong>POP3</strong>: POP3, on the other hand, is another protocol for email retrieval. Unlike IMAP, POP3 downloads emails to the local machine, removing them from the server. This makes it suitable for scenarios where emails are primarily accessed from a single device.</p>\n<h4>3.4.1 Connecting to a Mail Server</h4>\n<p>To use the Store class, you first need to obtain a Session object (similar to what we discussed in previous sections). The Session object encapsulates the properties required for establishing a connection to the mail server.</p>\n<p>Here&#8217;s a basic example of connecting to an IMAP server:</p><pre class=\"crayon-plain-tag\">import javax.mail.*;\n\n// Assuming 'session' is a valid Session object\nStore store = session.getStore(\"imaps\");  // Use \"imap\" for non-secure connections\nstore.connect(\"imap.example.com\", \"your-username\", \"your-password\");</pre><p></p>\n<h4>3.4.2 Accessing the Mailbox</h4>\n<p>Once the connection is established, you can access the user&#8217;s mailbox and retrieve email messages. The Folder class represents a mailbox, and you can use it in conjunction with the Store class to manage messages.</p><pre class=\"crayon-plain-tag\">Folder inbox = store.getFolder(\"INBOX\");\ninbox.open(Folder.READ_ONLY);  // Open the folder in read-only mode\n\n// Retrieve messages from the inbox\nMessage[] messages = inbox.getMessages();</pre><p></p>\n<h4>3.4.3 Message Retrieval and Handling</h4>\n<p>Once you have retrieved the messages, you can iterate through them and perform various actions, such as reading the content, extracting attachments, and managing flags.</p><pre class=\"crayon-plain-tag\">for (Message message : messages) {\n    // Retrieve and display message details\n    String subject = message.getSubject();\n    Address[] from = message.getFrom();\n    // Additional details can be retrieved as needed\n\n    // Perform actions based on message content\n    // ...\n\n    // Mark the message as read, if necessary\n    message.setFlag(Flags.Flag.SEEN, true);\n}</pre><p></p>\n<h4>3.4.4 Choosing between IMAP and POP3</h4>\n<p>The choice between IMAP and POP3 depends on the specific requirements of your application:</p>\n<p>Use <strong>IMAP</strong> if you need to access emails from multiple devices, keep emails synchronized, and perform actions on the server without downloading the entire message.<br />\nUse <strong>POP3</strong> if your application is designed for a single device, and you prefer downloading emails to the local machine, removing them from the server.</p>\n<p>Let us understand this concept with a code example in the later part of this article.</p>\n<h3>4. Configuring SMTP for JavaMail</h3>\n<h4>4.1 SMTP Servers and Providers</h4>\n<p>Selecting the right SMTP server is crucial for reliable email delivery. Popular providers include Gmail, Outlook, and your organization&#8217;s SMTP server. Ensure that you have the correct server address, port, and authentication details. In this article, we will be using the <strong>Gmail SMTP</strong> server.</p><pre class=\"crayon-plain-tag\">properties.put(\"mail.smtp.host\", \"smtp.gmail.com\");\nproperties.put(\"mail.smtp.port\", \"587\");</pre><p></p>\n<h4>4.2 Authentication</h4>\n<p>SMTP servers often require authentication to ensure that only authorized users can send emails. Provide your email address and password for authentication:</p><pre class=\"crayon-plain-tag\">properties.put(\"mail.smtp.auth\", \"true\");\nproperties.put(\"mail.smtp.user\", \"your-email@gmail.com\");\nproperties.put(\"mail.smtp.password\", \"your-email-password\");</pre><p><strong>Note:</strong></p>\n<p>When using Gmail SMTP, you cannot authenticate with your regular Gmail password. Instead, you need to generate a 16-digit app password. Detailed information about this process is available at <a href=\"https://support.google.com/mail/answer/185833?sjid=1520987343100173206-AP\" rel=\"nofollow noopener\" target=\"_blank\">https://support.google.com/mail/answer/185833?sjid=1520987343100173206-AP</a>.</p>\n<h4>4.3 Secure Connections (SSL/TLS)</h4>\n<p>When you&#8217;re sending emails, especially over the internet, it&#8217;s essential to encrypt the communication to safeguard the content of the messages and sensitive information such as login credentials. SSL and TLS are cryptographic protocols that provide secure communication channels, and JavaMail makes it straightforward to enable these protocols.</p><pre class=\"crayon-plain-tag\">// Enable TLS\nproperties.put(\"mail.smtp.starttls.enable\", \"true\");\n\n// Enable SSL\nproperties.put(\"mail.smtp.ssl.enable\", \"true\");</pre><p>But in this article, we will use TLS.</p>\n<h3>5. Sending Simple Emails</h3>\n<p>Creating a message involves specifying the sender, recipient, subject, and content. Additionally, you can customize headers and other properties.</p>\n<p>Sending the message using the Transport class remains the same as shown in the previous section.</p><pre class=\"crayon-plain-tag\">package org.example;\n\nimport javax.mail.*;\nimport javax.mail.internet.InternetAddress;\nimport javax.mail.internet.MimeBodyPart;\nimport javax.mail.internet.MimeMessage;\nimport javax.mail.internet.MimeMultipart;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.Arrays;\nimport java.util.Properties;\n\npublic class Main {\n    public static void main(String[] args) throws MessagingException, IOException {\n        \n        // Creating session\n        Session session = createSession();\n\n        // Create and configure a simple text message\n        Message message = new MimeMessage(session);\n        message.setFrom(new InternetAddress(\"fromAddress@gmail.com\"));\n        message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"toAddress@gmail.com\"));\n\t\t\n\t\tmessage.setSubject(\"Hello, JavaMail!\");\n        message.setText(\"This is a test email from JavaMail.\");\n\t\t\n        // Now 'message' is ready to be sent\n        Transport.send(message);\n        System.out.println(\"Email sent successfully!\");\n    }\n\t\n\tprivate static Session createSession() {\n        Properties properties = new Properties();\n        properties.put(\"mail.smtp.host\", \"smtp.gmail.com\");\n        properties.put(\"mail.smtp.port\", \"587\");\n        properties.put(\"mail.smtp.auth\", \"true\");\n        properties.put(\"mail.smtp.starttls.enable\", \"true\");\n\n        return Session.getInstance(properties, new javax.mail.Authenticator() {\n            protected javax.mail.PasswordAuthentication getPasswordAuthentication() {\n                return new javax.mail.PasswordAuthentication(\"fromAddress@gmail@gmail.com\", \"password\");\n            }\n        });\n    }\n    \n}</pre><p><strong>Output:</strong></p>\n<div class=\"wp-caption alignnone\" id=\"attachment_120755\" style=\"width: 993px;\"><img alt=\"Simple Mail from Java\" class=\"wp-image-120755 size-full\" height=\"317\" src=\"https://soshace.com/wp-content/uploads/2024/01/simple-mail-from-java.png\" title=\"Simple Mail from Java\" width=\"983\" /><p class=\"wp-caption-text\" id=\"caption-attachment-120755\">Simple Mail from Java</p></div>\n<h3>6. Advanced Email Features</h3>\n<p>6.1 Adding Attachments<br />\nIncluding attachments in your emails is a common requirement. The following code snippet demonstrates how to attach a file to your email:</p>\n<ol>\n<li>Create a Session object to encapsulate email configuration settings. The createSession() method is presumed to provide a configured session.</li>\n<li>Instantiate a MimeMessage object to represent the email message.</li>\n<li>Set sender, recipient, and subject attributes of the email message.</li>\n<li>Create a MimeBodyPart object to represent the text body of the email. Set the text content of the body part using setText().</li>\n<li>Create another MimeBodyPart to represent the attachment.Use attachFile() to attach the specified file to the body part.</li>\n<li>Create a MimeMultipart object to hold both the text body and the attachment.Add the created MimeBodyPart instances to the multipart container.</li>\n<li>Set the Multipart object as the content of the email message. This indicates that the email contains both text and an attachment.</li>\n<li>Use Transport.send() to send the email with the configured message.</li>\n</ol>\n<p></p><pre class=\"crayon-plain-tag\">package org.example;\n\nimport javax.mail.*;\nimport javax.mail.internet.InternetAddress;\nimport javax.mail.internet.MimeBodyPart;\nimport javax.mail.internet.MimeMessage;\nimport javax.mail.internet.MimeMultipart;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.Arrays;\nimport java.util.Properties;\n\npublic class Main {\n    public static void main(String[] args) throws MessagingException, IOException {\n\n        // Creating session\n        Session session = createSession();\n\n        // Create and configure a simple text message\n        Message message = new MimeMessage(session);\n        message.setFrom(new InternetAddress(\"From-Address@gmail.com\"));\n        message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"To-Address@gmail.com\"));\n\n        mailWithAttachments(session, message);\n\n        // Now 'message' is ready to be sent\n        Transport.send(message);\n        System.out.println(\"Email sent successfully!\");\n    }\n\t\n\tprivate static Session createSession() {\n        Properties properties = new Properties();\n        properties.put(\"mail.smtp.host\", \"smtp.gmail.com\");\n        properties.put(\"mail.smtp.port\", \"587\");\n        properties.put(\"mail.smtp.auth\", \"true\");\n        properties.put(\"mail.smtp.starttls.enable\", \"true\");\n\n        return Session.getInstance(properties, new javax.mail.Authenticator() {\n            protected javax.mail.PasswordAuthentication getPasswordAuthentication() {\n                return new javax.mail.PasswordAuthentication(\"fromAddress@gmail@gmail.com\", \"password\");\n            }\n        });\n    }\n\t\n\tpublic static void mailWithAttachments(Session session, Message message) throws MessagingException, IOException {\n        BodyPart messageBodyPart = new MimeBodyPart();\n        messageBodyPart.setText(\"This email contains an attachment.\");\n\n        // Attach the file\n        MimeBodyPart attachmentBodyPart = new MimeBodyPart();\n        attachmentBodyPart.attachFile(\"C:/Users/sai.p/Downloads/test.csv\");\n\n        // Create a multipart message\n        Multipart multipart = new MimeMultipart();\n        multipart.addBodyPart(messageBodyPart);\n        multipart.addBodyPart(attachmentBodyPart);\n\n        // Set the multipart as the message's content\n        message.setContent(multipart);\n    }\n    \n}</pre><p><strong>Output:</strong></p>\n<div class=\"wp-caption alignnone\" id=\"attachment_120747\" style=\"width: 737px;\"><img alt=\"Mail with attachment (CSV file in this case)\" class=\"wp-image-120747 size-full\" height=\"673\" src=\"https://soshace.com/wp-content/uploads/2024/01/mail-with-attachment-csv-file-in-this-case.png\" title=\"Mail with attachment (CSV file in this case)\" width=\"727\" /><p class=\"wp-caption-text\" id=\"caption-attachment-120747\">Mail with attachment (CSV file in this case)</p></div>\n<h4>6.2 HTML Emails</h4>\n<p>Send HTML-formatted emails for more visually appealing content.</p>\n<p><strong>6.2.1 Setting HTML content from a string.</strong></p><pre class=\"crayon-plain-tag\">package org.example;\n\nimport javax.mail.*;\nimport javax.mail.internet.InternetAddress;\nimport javax.mail.internet.MimeBodyPart;\nimport javax.mail.internet.MimeMessage;\nimport javax.mail.internet.MimeMultipart;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.Arrays;\nimport java.util.Properties;\n\npublic class Main {\n    public static void main(String[] args) throws MessagingException, IOException {\n\n        // Creating session\n        Session session = createSession();\n\n        // Create and configure a simple text message\n        Message message = new MimeMessage(session);\n        message.setFrom(new InternetAddress(\"From-Address@gmail.com\"));\n        message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"To-Address@gmail.com\"));\n\n        simpleHtmlMail(message);\n\n        // Now 'message' is ready to be sent\n        Transport.send(message);\n        System.out.println(\"Email sent successfully!\");\n    }\n\t\n\tprivate static Session createSession() {\n        Properties properties = new Properties();\n        properties.put(\"mail.smtp.host\", \"smtp.gmail.com\");\n        properties.put(\"mail.smtp.port\", \"587\");\n        properties.put(\"mail.smtp.auth\", \"true\");\n        properties.put(\"mail.smtp.starttls.enable\", \"true\");\n\n        return Session.getInstance(properties, new javax.mail.Authenticator() {\n            protected javax.mail.PasswordAuthentication getPasswordAuthentication() {\n                return new javax.mail.PasswordAuthentication(\"fromAddress@gmail.com\", \"password\");\n            }\n        });\n    }\n\t\n\tpublic static void simpleHtmlMail(Message message) throws MessagingException, IOException {\n        String htmlContent = \"This is a simple html &lt;b&gt;content&lt;/b&gt; &lt;div style='color:red;padding:8px'&gt;Hello Everyone!&lt;/div&gt; \";\n        message.setContent(htmlContent,\"text/html\");\n    }\n    \n}</pre><p><strong>Output:</strong></p>\n<div class=\"wp-caption alignnone\" id=\"attachment_120748\" style=\"width: 454px;\"><img alt=\"Mail with HTML Content\" class=\"wp-image-120748 size-full\" height=\"266\" src=\"https://soshace.com/wp-content/uploads/2024/01/mail-with-html-content.png\" title=\"Mail with HTML Content\" width=\"444\" /><p class=\"wp-caption-text\" id=\"caption-attachment-120748\">Mail with HTML Content</p></div>\n<h4>6.2.1 Setting HTML content from an HTML file.</h4>\n<ul>\n<li>Read the contents of an HTML.</li>\n<li>file convert it into a string and pass it to the setContent() method.</li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">package org.example;\n\nimport javax.mail.*;\nimport javax.mail.internet.InternetAddress;\nimport javax.mail.internet.MimeBodyPart;\nimport javax.mail.internet.MimeMessage;\nimport javax.mail.internet.MimeMultipart;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.Arrays;\nimport java.util.Properties;\n\npublic class Main {\n    public static void main(String[] args) throws MessagingException, IOException {\n\n        // Creating session\n        Session session = createSession();\n\n        // Create and configure a simple text message\n        Message message = new MimeMessage(session);\n        message.setFrom(new InternetAddress(\"From-Address@gmail.com\"));\n        message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"To-Address@gmail.com\"));\n\n        htmlMail(message);\n\n        // Now 'message' is ready to be sent\n        Transport.send(message);\n        System.out.println(\"Email sent successfully!\");\n    }\n\t\n\tprivate static Session createSession() {\n        Properties properties = new Properties();\n        properties.put(\"mail.smtp.host\", \"smtp.gmail.com\");\n        properties.put(\"mail.smtp.port\", \"587\");\n        properties.put(\"mail.smtp.auth\", \"true\");\n        properties.put(\"mail.smtp.starttls.enable\", \"true\");\n\n        return Session.getInstance(properties, new javax.mail.Authenticator() {\n            protected javax.mail.PasswordAuthentication getPasswordAuthentication() {\n                return new javax.mail.PasswordAuthentication(\"fromAddress@gmail.com\", \"password\");\n            }\n        });\n    }\n\t\n\tpublic static void htmlMail(Message message) throws MessagingException, IOException {\n        String htmlContent = new String(Files.readAllBytes(Paths.get(\"C:/Users/sai.p/Downloads/greetings.html\")));\n        message.setContent(htmlContent,\"text/html\");\n    }\n    \n}</pre><p><strong>Output:</strong></p>\n<div class=\"wp-caption alignnone\" id=\"attachment_120749\" style=\"width: 647px;\"><img alt=\"Mails sent by rendering HTML file\" class=\"wp-image-120749 size-full\" height=\"475\" src=\"https://soshace.com/wp-content/uploads/2024/01/mails-sent-by-rendering-html-file.png\" title=\"Mails sent by rendering HTML file\" width=\"637\" /><p class=\"wp-caption-text\" id=\"caption-attachment-120749\">Mails sent by rendering HTML file</p></div>\n<h4>6.3 Retrieving mail from Mail Inbox.</h4>\n<ol>\n<li>The readMails method connects to a Gmail account using IMAP and retrieves the last 10 emails from the INBOX folder.</li>\n<li>It connects to the Gmail IMAP server using the provided credentials.</li>\n<li>Accesses the INBOX folder and opens it in read-only mode.</li>\n<li>Retrieves the last 10 messages (or fewer if there are fewer than 10) using inbox.getMessages(inbox.getMessageCount()-10, inbox.getMessageCount()-1).</li>\n<li>Iterates through the retrieved messages and prints their subjects and senders.</li>\n</ol>\n<p></p><pre class=\"crayon-plain-tag\">package org.example;\n\nimport javax.mail.*;\nimport javax.mail.internet.InternetAddress;\nimport javax.mail.internet.MimeBodyPart;\nimport javax.mail.internet.MimeMessage;\nimport javax.mail.internet.MimeMultipart;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.Arrays;\nimport java.util.Properties;\n\npublic class Main {\n        public static void main(String[] args) throws MessagingException, IOException {\n\n        // Creating session\n        Session session = createSession();\n\n        readMails(session);\n\n        System.out.println(\"Email sent successfully!\");\n    }\n\n    public static void readMails(Session session) throws MessagingException {\n        Store store = session.getStore(\"imaps\");\n        store.connect(\"imap.gmail.com\", \"username@gmail.com\", \"password\");\n\n        // Access the INBOX folder\n        Folder inbox = store.getFolder(\"INBOX\");\n        inbox.open(Folder.READ_ONLY);\n\n        // Retrieve and display messages\n        Message[] messages = inbox.getMessages(inbox.getMessageCount()-10, inbox.getMessageCount()-1);\n        for (Message message : messages) {\n            System.out.print(\"Subject: \" + message.getSubject());\n            System.out.println(\", From: \" + Arrays.toString(message.getFrom()));\n            // Additional details can be displayed\n        }\n\n        // Close the connection\n        inbox.close(false);\n        store.close();\n    }\n\t\n\tprivate static Session createSession() {\n        Properties properties = new Properties();\n        properties.put(\"mail.smtp.host\", \"smtp.gmail.com\");\n        properties.put(\"mail.smtp.port\", \"587\");\n        properties.put(\"mail.smtp.auth\", \"true\");\n        properties.put(\"mail.smtp.starttls.enable\", \"true\");\n\n        return Session.getInstance(properties, new javax.mail.Authenticator() {\n            protected javax.mail.PasswordAuthentication getPasswordAuthentication() {\n                return new javax.mail.PasswordAuthentication(\"username@gmail\", \"password\");\n            }\n        });\n    }\n\t\n    \n}</pre><p></p>\n<h3>7. Handling Email Responses</h3>\n<h4>7.1 Setting Reply-To Address</h4>\n<p>Setting a &#8220;Reply-To&#8221; address in an email message is a useful feature that allows the sender to specify an alternative email address to which recipients should direct their replies. This is particularly beneficial in scenarios where the person initiating the email communication may not be the primary point of contact or where specific departments or individuals handle responses.</p>\n<p>The <strong>setReplyTo</strong> method is used to configure the &#8220;Reply-To&#8221; address in the email message.</p><pre class=\"crayon-plain-tag\">message.setReplyTo(new Address[]{new InternetAddress(\"reply-to@example.com\")});</pre><p></p>\n<h4>7.2 Handling Bounced Emails</h4>\n<p>Handling bounced emails involves monitoring and processing delivery status notifications. While this often requires additional configuration on the server side, you can set the Return-Receipt-To header to request a notification.</p><pre class=\"crayon-plain-tag\">message.setHeader(\"Return-Receipt-To\", \"your-email@example.com\");</pre><p>By configuring the return receipt, the configured mail will receive the return receipt notification.</p>\n<h3>8. Best Practices for Email Sending in Java</h3>\n<h4>8.1 Error Handling and Logging</h4>\n<p>Implementing error handling ensures that your application gracefully manages exceptions. Logging mechanisms, such as Java&#8217;s built-in logging or third-party libraries like Log4j, can help track issues.</p><pre class=\"crayon-plain-tag\">try {\n    // Sending email code here\n} catch (MessagingException e) {\n    // Handle messaging exception\n    e.printStackTrace(); // Log the exception\n}</pre><p></p>\n<h4>8.2 Performance Optimization</h4>\n<p>Optimizing email-sending performance involves minimizing network latency and resource consumption. Consider using asynchronous methods or threading for parallel email sending.</p>\n<ul>\n<li>A loop is used to send five emails concurrently, each in a separate thread.</li>\n<li>Inside the loop, a lambda expression creates a MimeMessage for each email, sets content, and sends it using a thread from the fixed-size thread pool.</li>\n<li>An ExecutorService with a fixed thread pool is employed for the concurrent execution of email-sending tasks.</li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">package org.example;\n\nimport javax.mail.*;\nimport javax.mail.internet.InternetAddress;\nimport javax.mail.internet.MimeBodyPart;\nimport javax.mail.internet.MimeMessage;\nimport javax.mail.internet.MimeMultipart;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.Arrays;\nimport java.util.Properties;\n\npublic class Main {\n    public static void main(String[] args) throws MessagingException, IOException {\n        // Creating session\n        Session session = createSession();\n\n        ExecutorService executorService = Executors.newFixedThreadPool(5);\n\n        for (int i = 0; i &lt; 5; i++) {\n            int finalI = i;\n            executorService.submit(() -&gt; {\n                try {\n                    // Create and configure a new message for each iteration\n                    Message message = new MimeMessage(session);\n                    message.setFrom(new InternetAddress(\"from-address@gmail.com\"));\n                    message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"To-address@gmail.com\"));\n\n                    // Set the content for this specific message\n                    message.setText(\"Mail number = \" + finalI);\n\n                    // Send the message\n                    Transport.send(message);\n                    System.out.println(\"Email sent successfully for mail number = \" + finalI);\n                } catch (MessagingException e) {\n                    e.printStackTrace();\n                }\n            });\n        }\n\n        executorService.shutdown();\n    }\n\n\tprivate static Session createSession() {\n        Properties properties = new Properties();\n        properties.put(\"mail.smtp.host\", \"smtp.gmail.com\");\n        properties.put(\"mail.smtp.port\", \"587\");\n        properties.put(\"mail.smtp.auth\", \"true\");\n        properties.put(\"mail.smtp.starttls.enable\", \"true\");\n\n        return Session.getInstance(properties, new javax.mail.Authenticator() {\n            protected javax.mail.PasswordAuthentication getPasswordAuthentication() {\n                return new javax.mail.PasswordAuthentication(\"username@gmail.com\", \"password\");\n            }\n        });\n    }\n\t\n    \n}</pre><p><strong>Output:</strong></p>\n<div class=\"wp-caption alignnone\" id=\"attachment_120750\" style=\"width: 683px;\"><img alt=\"Mails sent using Multi-Threading\" class=\"wp-image-120750 size-full\" height=\"236\" src=\"https://soshace.com/wp-content/uploads/2024/01/mails-sent-using-multi-threading.png\" title=\"Mails sent using Multi-Threading\" width=\"673\" /><p class=\"wp-caption-text\" id=\"caption-attachment-120750\">Mails sent using Multi-Threading</p></div>\n<h3>9. Troubleshooting Common Issues</h3>\n<h4>9.1 Connection Problems</h4>\n<p>Issue: Unable to connect to the SMTP server.</p>\n<p>Ensure that the SMTP server address, port, and connection properties are correctly configured. Additionally, check your network settings and firewall rules.</p>\n<h4>9.2 Authentication Failures</h4>\n<p>Issue: Authentication credentials are not accepted by the SMTP server.</p>\n<p>Double-check the correctness of your email address and password. Some SMTP providers might require an application-specific password, so verify the authentication requirements.</p>\n<h3>10. Conclusion</h3>\n<p>In this comprehensive guide, we&#8217;ve covered the fundamentals of sending emails in Java applications using the JavaMail API. From setting up your environment, understanding JavaMail components, and configuring SMTP for email delivery, to implementing advanced features and handling common issues, you now have a solid foundation for incorporating robust email functionality into your Java projects.</p>\n<p>By following best practices, testing thoroughly, and leveraging real-world examples, you can enhance user experience and streamline communication in your applications. Remember to troubleshoot any issues effectively, ensuring that your email-sending functionality is reliable and error-tolerant.</p>\n<h3>References:</h3>\n<ol>\n<li>https://javaee.github.io/javamail/</li>\n<li>https://source.unsplash.com/ (For Images)</li>\n<li>https://openai.com/dall-e-2 (Thumbnail Image)</li>\n<li>https://deepai.org/ (Cover Image)</li>\n</ol>\n<p>The post <a href=\"https://soshace.com/sending-emails-in-java-applications-a-comprehensive-guide-to-javamail-and-smtp-configuration/\" rel=\"nofollow\">Sending Emails in Java Applications: A Comprehensive Guide to JavaMail and SMTP Configuration</a> appeared first on <a href=\"https://soshace.com\" rel=\"nofollow\">Soshace</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://soshace.com/sending-emails-in-java-applications-a-comprehensive-guide-to-javamail-and-smtp-configuration/feed/",
    "slash_comments": "0"
  },
  "SurveyMonkey": {
    "title": "Top survey trends for 2024",
    "xmlUrl": "https://www.surveymonkey.com/feed/",
    "htmlUrl": "https://engineering.surveymonkey.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.surveymonkey.com/feed/",
      "value": "Top survey trends for 2024"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.surveymonkey.com/curiosity/top-survey-trends-for-2024/?ut_source=rss"
      }
    ],
    "link": "https://www.surveymonkey.com/curiosity/top-survey-trends-for-2024/?ut_source=rss",
    "id": "https://www.surveymonkey.com/curiosity/top-survey-trends-for-2024/",
    "guidislink": false,
    "summary": "What\u2019s asked\u2014and answered\u2014on our platform highlights important trends for the upcoming year",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.surveymonkey.com/feed/",
      "value": "What\u2019s asked\u2014and answered\u2014on our platform highlights important trends for the upcoming year"
    },
    "published": "Mon, 08 Jan 2024 10:15:26 GMT",
    "published_parsed": [
      2024,
      1,
      8,
      10,
      15,
      26,
      0,
      8,
      0
    ]
  },
  "OpenDNS": {
    "title": "Retail Wins with Umbrella",
    "xmlUrl": "https://umbrella.cisco.com/blog/feed/",
    "htmlUrl": "https://engineering.opendns.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://umbrella.cisco.com/blog/feed",
      "value": "Retail Wins with Umbrella"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://umbrella.cisco.com/blog/retail-wins-with-umbrella"
      }
    ],
    "link": "https://umbrella.cisco.com/blog/retail-wins-with-umbrella",
    "authors": [
      {
        "name": "Negisa Taymourian"
      }
    ],
    "author": "Negisa Taymourian",
    "author_detail": {
      "name": "Negisa Taymourian"
    },
    "published": "Thu, 06 Jul 2023 08:00:00 +0000",
    "published_parsed": [
      2023,
      7,
      6,
      8,
      0,
      0,
      3,
      187,
      0
    ],
    "tags": [
      {
        "term": "Customer Focus",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://umbrella-staging.marketops.umbrella.com/?p=68143",
    "guidislink": false,
    "summary": "<p>Retailers face new cybersecurity challenges as the industry becomes more digitized. Vendors are processing increasing amounts of customer data and attracting unwanted attention from bad actors that steal consumers\u2019 personally identifiable information (PII). Additional challenges include social engineering (phishing), ransomware, automation and bots, fake accounts, and web scraping. These all can have major consequences for [&#8230;]</p>\n<p>The post <a href=\"https://umbrella.cisco.com/blog/retail-wins-with-umbrella\">Retail Wins with Umbrella</a> appeared first on <a href=\"https://umbrella.cisco.com\">Cisco Umbrella</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://umbrella.cisco.com/blog/feed",
      "value": "<p>Retailers face new cybersecurity challenges as the industry becomes more digitized. Vendors are processing increasing amounts of customer data and attracting unwanted attention from bad actors that steal consumers\u2019 personally identifiable information (PII). Additional challenges include social engineering (phishing), ransomware, automation and bots, fake accounts, and web scraping. These all can have major consequences for [&#8230;]</p>\n<p>The post <a href=\"https://umbrella.cisco.com/blog/retail-wins-with-umbrella\">Retail Wins with Umbrella</a> appeared first on <a href=\"https://umbrella.cisco.com\">Cisco Umbrella</a>.</p>"
    }
  },
  "Jolly Good Code": {
    "title": "Test gem with multiple dependencies on Travis CI",
    "xmlUrl": "https://jollygoodcode.github.io/atom.xml",
    "htmlUrl": "https://jollygoodcode.github.io/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://jollygoodcode.github.io/atom.xml",
      "value": "Test gem with multiple dependencies on Travis CI"
    },
    "links": [
      {
        "href": "http://jollygoodcode.com/blog/2016/07/03/test-gem-with-multiple-dependencies-on-travis-ci.html",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "link": "http://jollygoodcode.com/blog/2016/07/03/test-gem-with-multiple-dependencies-on-travis-ci.html",
    "updated": "2016-07-03T05:27:56+00:00",
    "updated_parsed": [
      2016,
      7,
      3,
      5,
      27,
      56,
      6,
      185,
      0
    ],
    "id": "https://github.com/jollygoodcode/jollygoodcode.github.io/issues/21",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://jollygoodcode.github.io/atom.xml",
        "value": "Learn how to test your Gem with multiple dependencies on Travis CI with thoughtbot's appraisal tool."
      }
    ],
    "summary": "Learn how to test your Gem with multiple dependencies on Travis CI with thoughtbot's appraisal tool."
  },
  "Chartbeat": {
    "title": "All The Cool Kids Are Doing It",
    "xmlUrl": "http://engineering.chartbeat.com/feed/",
    "htmlUrl": "http://engineering.chartbeat.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://engineering.chartbeat.com/feed/",
      "value": "All The Cool Kids Are Doing It"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "http://engineering.chartbeat.com/2017/08/01/all-the-cool-kids-are-doing-it/"
      }
    ],
    "link": "http://engineering.chartbeat.com/2017/08/01/all-the-cool-kids-are-doing-it/",
    "comments": "http://engineering.chartbeat.com/2017/08/01/all-the-cool-kids-are-doing-it/#respond",
    "published": "Tue, 01 Aug 2017 20:48:29 +0000",
    "published_parsed": [
      2017,
      8,
      1,
      20,
      48,
      29,
      1,
      213,
      0
    ],
    "authors": [
      {
        "name": "Wes"
      }
    ],
    "author": "Wes",
    "author_detail": {
      "name": "Wes"
    },
    "tags": [
      {
        "term": "Uncategorized",
        "scheme": null,
        "label": null
      }
    ],
    "id": "http://engineering.chartbeat.com/?p=187",
    "guidislink": false,
    "summary": "We&#8217;re moving our Engineering Blog to Medium! Some of the old content has been migrated, but all the tasty freshness will be appearing there going forward. And do expect tastiness &#8212; we&#8217;ve been working hard at building up a nice queue of thought provoking and illustrative content that I guarantee you will write your mother [&#8230;]",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "http://engineering.chartbeat.com/feed/",
      "value": "We&#8217;re moving our Engineering Blog to Medium! Some of the old content has been migrated, but all the tasty freshness will be appearing there going forward. And do expect tastiness &#8212; we&#8217;ve been working hard at building up a nice queue of thought provoking and illustrative content that I guarantee you will write your mother [&#8230;]"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "http://engineering.chartbeat.com/feed/",
        "value": "<p>We&#8217;re moving our <a href=\"https://medium.com/chartbeat-engineering\">Engineering Blog</a> to Medium! Some of the old content has been migrated, but all the tasty freshness will be appearing there going forward. And do expect tastiness &#8212; we&#8217;ve been working hard at building up a nice queue of thought provoking and illustrative content that I guarantee you will write your mother about.</p>"
      }
    ],
    "wfw_commentrss": "http://engineering.chartbeat.com/2017/08/01/all-the-cool-kids-are-doing-it/feed/",
    "slash_comments": "0"
  },
  "GIPHY": {
    "title": "From GIFs To Git: Learning to Code & Debugging Self Doubt",
    "xmlUrl": "https://engineering.giphy.com/rss",
    "htmlUrl": "https://engineering.giphy.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.giphy.com/feed/",
      "value": "From GIFs To Git: Learning to Code & Debugging Self Doubt"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.giphy.com/from-gifs-to-git-learning-to-code-debugging-self-doubt/"
      }
    ],
    "link": "https://engineering.giphy.com/from-gifs-to-git-learning-to-code-debugging-self-doubt/",
    "authors": [
      {
        "name": "Jake Martella"
      }
    ],
    "author": "Jake Martella",
    "author_detail": {
      "name": "Jake Martella"
    },
    "published": "Wed, 01 Nov 2023 19:36:34 +0000",
    "published_parsed": [
      2023,
      11,
      1,
      19,
      36,
      34,
      2,
      305,
      0
    ],
    "tags": [
      {
        "term": "Blog",
        "scheme": null,
        "label": null
      },
      {
        "term": "Featured",
        "scheme": null,
        "label": null
      },
      {
        "term": "GIPHY",
        "scheme": null,
        "label": null
      },
      {
        "term": "learning",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.giphy.com/?p=927",
    "guidislink": false,
    "summary": "Jake Martella tells us how he, as a non-engineer, created an internal tool now used by Staff at GIPHY, including himself.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.giphy.com/feed/",
      "value": "Jake Martella tells us how he, as a non-engineer, created an internal tool now used by Staff at GIPHY, including himself."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.giphy.com/feed/",
        "value": "<p><strong>Welcome readers!</strong><br /><br />I\u2019m Jake Martella and I\u2019d like to share a recent journey of mine that I think may shine a light on the struggles of learning new career skills, taking on new challenges, and conquering self doubt.&nbsp;</p>\n\n\n\n<p><strong>Firstly, who am I?</strong></p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img alt=\"\" class=\"wp-image-929\" height=\"286\" src=\"https://engineering.giphy.com/wp-content/uploads/2023/11/giphy.webp\" width=\"480\" /></figure>\n\n\n\n<p>I started at GIPHY in 2018 as NFL Editor, and have donned multiple roles over the years from Sports Editor to now finding my stride as Editorial Director for Sports. The GIPHY Sports department is vibrant and constant. Our work requires meticulous tagging, curation and editorialization. With hundreds of official sports partners, thousands of GIFs, and billions of views, managing such content must be thorough. Recently, my passion for sports collided with the dynamic realm of tech. In perhaps the best example of problem solving I can offer, I decided to one day devote time to developing some skills that would allow me to build a solution to a tedious problem. With the endless ingestion of sports GIF content, it was cumbersome to host my relevant hashtags in a messy google doc or notepad. Something had to be done, so\u2026&nbsp;</p>\n\n\n\n<p><strong>Rough Beginnings</strong></p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img alt=\"\" class=\"wp-image-930\" height=\"180\" src=\"https://engineering.giphy.com/wp-content/uploads/2023/11/giphy-1.gif\" width=\"320\" /></figure>\n\n\n\n<p>It all began with a three-month coding boot camp hosted by <a href=\"https://brainstation.io\">Brainstation</a>, a crucible where my determination was forged in the fires of frustration and doubt. I often felt like the slowest ship in a regatta, constantly trailing behind my peers, grappling for understanding where others seemed to effortlessly sail. The shadows of self-doubt loomed large, and I frequently thought I didn\u2019t belong. Although I completed the course, I didn\u2019t feel I deserved to. Self loathing\u2026exhibit A.</p>\n\n\n\n<p><strong>Progress</strong></p>\n\n\n\n<p>Seven months later, while working full-time and coding in my spare time, I started to make serious progress in my understanding. I saw the first rays of &#8220;Eureka!&#8221; pierce through the clouds of confusion. So much so that I eventually developed a web-app as a side project that helped me in my everyday work at GIPHY as Sports Editor. I was thrilled with the result. The ability to organize tags into categories and cards with a simple copy button saved me a great amount of time curating content, a task I do dozens of times per day, hundreds per week, and thousands per month!<img height=\"850\" src=\"https://lh7-us.googleusercontent.com/xKM7wKGNqt0wdQOSmlAO0HA1aSKaKMyiMyuFGHlKPcAEptsSTTFlAk_VDLEysze7cn8pJcF03k7yCxipmJGsZQO7JD79cY9YIVKBYQuZ885GwL0uKfjayk6C4tI7L6eA6xrSZh1wnjc82rfeF5Fnb0A\" width=\"1181\" /></p>\n\n\n\n<p>After showing the application to friends and colleagues, a colleague suggested that there may be a possibility to build this feature directly into the GIPHY infrastructure, and that I may be able to gain valuable experience coding in a real world dev environment. While this suggestion made my blood pressure spike, it also presented an unimaginable opportunity\u2026</p>\n\n\n\n<p>The possibility of integrating my feature into GIPHY&#8217;s infrastructure was both thrilling and terrifying. &#8216;Coding for GIPHY? Am I in over my head?&#8217; I wondered. But I refused to let doubt anchor me. In the words of Gretzky: \u201cYou miss 100% of the shots you don\u2019t take.\u201d</p>\n\n\n\n<p>My journey was a rollercoaster of emotions, marked by trial and error, and a generous dose of humility. I leaned on mentors and late-night debugging sessions, savoring the small victories along the way. While collaborating with more experienced developers at GIPHY, I learned invaluable lessons. I discovered that each company has its own unique approach to product development.&nbsp; Google searches didn\u2019t always offer the right solution because many errors required a deeper understanding of the specific systems, authentications and methodologies being used. Also, note to self: always remember to make sure you\u2019re connected to the VPN <img alt=\"\ud83d\ude05\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/1f605.png\" style=\"height: 1em;\" />.</p>\n\n\n\n<p>I successfully navigated the native dev environment, ultimately creating the GIPHY Tag Tamer\u2014an invaluable hashtag organizer now used internally company-wide, simplifying content curation.</p>\n\n\n\n<p><strong>What is the Tag Tamer?</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" class=\"wp-image-934\" height=\"822\" src=\"https://engineering.giphy.com/wp-content/uploads/2023/11/image-1.png\" width=\"1041\" /></figure>\n\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" class=\"wp-image-933\" height=\"819\" src=\"https://engineering.giphy.com/wp-content/uploads/2023/11/image.png\" width=\"1050\" /></figure>\n\n\n\n<p>The Tag Tamer empowers staff users to generate categorized hashtag lists, neatly arranged within distinct cards. Each card features a title and a dedicated space for storing an array of frequently used hashtags. There&#8217;s a convenient &#8220;COPY&#8221; button on each card so staff users can quickly attach relevant tags to their clipboard and paste them on desired content. This feature streamlines the handling of GIPHY\u2019s extensive GIF library, enabling efficient organization and archiving of the data. Consider the NBA All-Star game scenario, where the influx of NBA-related content necessitates the strategic use of hyper-specific hashtags for effective content management and access. Multiplying this process across various sports leagues, teams, and tournaments underscores the potential challenges in handling such an extensive content repertoire. That, in a nutshell, is the Tag Tamer.&nbsp;</p>\n\n\n\n<p><strong>How does it work?</strong></p>\n\n\n\n<p>The tag tamer tool leverages a powerful combination of React for the frontend, TypeScript for enhanced code quality, and Styled Components for UI design. On the backend, it harnesses the robust capabilities of Django, providing a reliable and scalable foundation for data management and processing. This stack ensures a seamless and intuitive user experience.&nbsp;</p>\n\n\n\n<p><strong>Final Thoughts&nbsp;</strong></p>\n\n\n\n<p>This tool, born from struggle and self-questioning, is now a vital part of my daily workflow, streamlining content management for myself and my colleagues. And I&#8217;m proud of it.</p>\n\n\n\n<p>While I once thought I might never get the hang of this coding thing, I am a true believer that embracing challenges and continuing to learn for the sake of learning is always worth it. Also, never, ever be ashamed or scared to ask for help.</p>\n\n\n\n<p>Trust yourself. Bet on yourself. This is the way.</p>\n\n\n\n<p></p>\n\n\n\n<p>-Jake Martella, Editorial Director, Sports</p>"
      }
    ]
  },
  "Shyp": {
    "title": "A Unique Journey in Search of Keys",
    "xmlUrl": "https://medium.com/feed/shyp-engineering",
    "htmlUrl": "https://medium.com/shyp-engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/shyp-engineering",
      "value": "A Unique Journey in Search of Keys"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/shyp-engineering/a-unique-journey-in-search-of-keys-3bb250471104?source=rss----6513e7cf74b---4"
      }
    ],
    "link": "https://medium.com/shyp-engineering/a-unique-journey-in-search-of-keys-3bb250471104?source=rss----6513e7cf74b---4",
    "id": "https://medium.com/p/3bb250471104",
    "guidislink": false,
    "tags": [
      {
        "term": "postgresql",
        "scheme": null,
        "label": null
      },
      {
        "term": "sql",
        "scheme": null,
        "label": null
      },
      {
        "term": "programming",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Derek Barnes"
      }
    ],
    "author": "Derek Barnes",
    "author_detail": {
      "name": "Derek Barnes"
    },
    "published": "Wed, 24 Aug 2016 18:17:45 GMT",
    "published_parsed": [
      2016,
      8,
      24,
      18,
      17,
      45,
      2,
      237,
      0
    ],
    "updated": "2016-08-24T18:17:45.031Z",
    "updated_parsed": [
      2016,
      8,
      24,
      18,
      17,
      45,
      2,
      237,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/shyp-engineering",
        "value": "<h3>Introduction</h3><p>At Shyp we\u2019ve begun undertaking an extensive maintenance project on our primary API\u2019s database, changing its tables\u2019 primary keys from a prefixed uuid stored as text, to utilizing the database\u2019s native uuid type, and adding the prefix in the application layer. This blog post will give some general background on primary keys, outline why we made this change, the process of preparing our application for this change, and how we\u2019ve gone about migrating the existing\u00a0data.</p><h3>Primary Keys and\u00a0UUIDs</h3><p>Relational databases store records as rows in tables. Each table has a strict definition of the columns that each row entry will be made up of, along with their type. For example, you might have a contacts table defined\u00a0as:</p><pre>first: text<br />last: text<br />birthday: date</pre><p>Then, you might have a table that looks\u00a0like:</p><pre>| first   | last     | birthday   |<br />|---------|----------|------------|<br />| Lindsey | Homer    | 1984-06-24 |<br />| Melvin  | Anderson | 1987-01-23 |<br />| Jessie  | Bell     | 1957-09-16 |</pre><p>In this case, the table does not have a primary key\u200a\u2014\u200athe only way to query it is based on the information it contains. Sometimes this is appropriate, but often this becomes difficult when other information needs to be associated with a record. For example, we might want to have a notes table where we could add a note for each contact, but there\u2019s no way to clearly associate a particular contact with a note, as it\u2019s possible that two contacts can share the same name and birthday. So we need a way of uniquely identifying the record with what\u2019s called a \u201ckey\u201d. Some database designs use another attribute about a record, such as a person\u2019s Social Security Number, in order to provide a way of looking up the record; this is called a \u201cnatural key\u201d. However, this can be problematic when we can\u2019t guarantee that the value of the natural key is truly unique, and so we need to utilize something else in order to identify\u00a0records.</p><p>Since relying on intrinsic properties of a dataset is problematic for establishing the identity of records in the set, databases are often designed using synthetic primary keys. These keys are guaranteed to be unique by the database system, and are used for the sole purpose of looking up a record. The most common approach is to use a sequential integer. In our contacts example, this might look something like:</p><pre>| id | first   | last     | birthday   |<br />|----|---------|----------|------------|<br />| 1  | Lindsey | Homer    | 1984-06-24 |<br />| 2  | Melvin  | Anderson | 1987-01-23 |<br />| 3  | Jessie  | Bell     | 1957-09-16 |</pre><p>When the responsibility of generating the primary keys is entirely in the domain of the database system (as is often the case), this works well. In a distributed system, however, you might want to have an identifier for an entity without relying on the database to generate that for you. In this case, you can take a randomized value and format it in a consistent way; one category of these identifiers are known as UUIDs, which are 128-bit values, usually formatted as a hyphen-separated hexadecimal string. For example, \u201c5c3ad9ab-a0fe-474c-87a2\u201338fc818d2b03\u201d is a UUID. There are several variants of UUIDs, but they all have the same format, and the variants have to do with how the values are generated. V4 UUIDs are truly random, and are what Shyp uses for primary\u00a0keys.</p><p>In addition, we prefix a short identifier to the id at Shyp. Although this is a less common practice, it\u2019s not a quirk that\u2019s unique to us (Stripe does this too). For example, a pickup is prefixed with \u201cpik_\u201d, and a shipment is prefixed with \u201cshp_\u201d. This is useful from an application and API perspective: Our operations apps can scan a QR code containing the id of a number of things (a shipment, a container, a warehouse worker\u2019s badge) and route the UI appropriately. It\u2019s also useful for debugging, as we can readily know the kind of data we\u2019re dealing with just from its identifier.</p><p>These ids have historically been stored as text in our PostgreSQL database. While this works and has no impact on lookup speed, it\u2019s an inefficient use of space. This is especially important with primary keys, whose indexes should fit in memory. And while disk space is cheap these days, RAM is comparatively expensive, and as we scale we\u2019d like to keep these costs under control. There is also no real reason to have the database store these values as text, since PostgreSQL supports UUIDs as a first class data type, and at the database level, you always know <em>what</em> you\u2019re querying for. The different representations are quite different size-wise. A text representation of a uuid (with hyphens) is 36 bytes (or 288 bits)\u200a\u2014\u200aa little more than double the actual byte size of a UUID. An index for these values reflects this difference as well, as we will later\u00a0see.</p><p>If there\u2019s such a big difference, why did these get stored as text in the first place? Shyp\u2019s API was first built on Sails, and Sails\u2019s ORM, Waterline does not have built in support for handling UUIDs\u200a\u2014\u200ait simply treats them as text. We\u2019ve maintained our own fork of Waterline, which we\u2019ve stripped a lot of features from, as well as removed all other parts of Sails from our API. In any case, the first step in this endeavor was to prepare our API and Waterline to handle\u00a0UUIDs.</p><h3>Planning</h3><p>Changing the type in the database, is fairly easy in some sense\u200a\u2014\u200asimply change the\u00a0type:</p><pre>ALTER TABLE users CHANGE COLUMN id SET TYPE uuid;</pre><p>This sort of schema change could cause problems in a production environment, particularly when the table is so large that running the query will take more than a second or two, but it\u2019s a good start in terms of getting the application code prepared for using the prefix-less ids.</p><p>In integrating with the existing codebase, we need to make sure the assumptions around prefixes are being challenged. For example, in my initial exploration I added a migration for one of our tables, ran the unit tests, and everything passed (great, ship it!). Since I knew that the prefixes weren\u2019t being added I had to explicitly define the assumptions around our prefixing behavior.</p><p>First, I wrote an integration test that attempted to create a record, asserted that the newly created record was serialized by the application with a prefix, and finally, could be searched with that record. This ensures that the boundary around having prefixes or not is flexible; Ideally we\u2019d go with one or the other, but we have a living codebase with many teams, and it\u2019s impossible to change everything overnight while continuing to deliver new features.</p><p>In other words, not only did we want to handle UUIDs, but also we thought it would be nice if we could have our models handle prefixed UUIDs, and simply ignore the prefix when running\u00a0queries.</p><p>In order to handle this, we <a href=\"https://github.com/Shyp/waterline/pull/32\">added some UUID type coercion functionality</a> to our fork of Waterline. This was pretty straightforward, as Waterline already has built in type coercion functionality; that is, if you give a model a string for an integer primary key, it will attempt to coerce it to an actual\u00a0integer.</p><p>This results with the following Waterline query</p><pre>User.findOne('usr_abc123') // ...</pre><p>only using the UUID in issuing the\u00a0query</p><pre>SELECT * FROM users WHERE id = 'abc123';</pre><p>instead of using the\u00a0prefix</p><pre>SELECT * FROM users WHERE id = 'usr_abc123';</pre><p>(The latter query would throw an error in Postgres, because the value is not a valid\u00a0uuid).</p><p>Next, we needed to add the prefix in the models. This is relatively straightforward; All models in our system have \u201ctoJSON()\u201d invoked when being serialized, so we simply override the id serialization here, essentially adding the prefix if it\u2019s not present on the\u00a0id.</p><p>As a result of all this, we\u2019ve got our models covered on both ends, compatible with our prefixed UUIDs internally, and our integration test passes. One nice quality of this approach in the model layer is that our code will be compatible with the schema as we\u00a0migrate.</p><h3>Data Migration</h3><p>Now that our codebase will work with the prefix-less UUIDs, we need to migrate the existing data. This is a little tricky, because while it affects an entire table, it needs to happen without interrupting service. It also needs to be easily reversed in case something goes\u00a0wrong.</p><p>To do this, we can break the migration into 5\u00a0steps:</p><ol><li>Create a new column that will be the eventual new id\u00a0column.</li><li>Fill any new records with the prefix-less id via a trigger on the\u00a0table.</li><li>Backfill this column with the prefix-less data.</li><li>Create an index (concurrently) on that\u00a0column.</li><li>Swap the new column in, and keep the old one (in a transaction).</li></ol><p>Our migration was on the \u201ctrackingevents\u201d table, which records a shipment\u2019s various updates from the\u00a0carrier.</p><p>This is what the migration looks like in\u00a0SQL:</p><pre>ALTER TABLE trackingevents ADD COLUMN newid uuid;</pre><pre>CREATE FUNCTION shyp_copy_newid() RETURNS TRIGGER AS $$<br />  BEGIN<br />    IF NEW.id IS NOT NULL THEN<br />      NEW.newid := regexp_replace(NEW.id, '\\w+_', '')::uuid;<br />    END IF;<br />    RETURN NEW;<br />  END<br />$$ LANGUAGE plpgsql;</pre><pre>CREATE TRIGGER shyp_copy_newid BEFORE INSERT OR UPDATE ON trackingevents<br />  FOR EACH ROW EXECUTE PROCEDURE shyp_copy_newid();</pre><pre>UPDATE trackingevents SET id = id;</pre><pre>CREATE UNIQUE INDEX CONCURRENTLY trackingevents_newid_idx ON trackingevents(newid);<br />CREATE UNIQUE INDEX CONCURRENTLY trackingevents_oldid_idx ON trackingevents(id);</pre><pre>BEGIN;<br />  DROP TRIGGER shyp_copy_newid ON trackingevents;<br />  DROP FUNCTION shyp_copy_newid();</pre><pre>  ALTER TABLE trackingevents DROP CONSTRAINT trackingevents_pkey;<br />  ALTER TABLE trackingevents RENAME COLUMN id TO oldid;<br />  ALTER TABLE trackingevents ALTER COLUMN oldid DROP DEFAULT;<br />  ALTER TABLE trackingevents ALTER COLUMN oldid DROP NOT NULL;</pre><pre>  ALTER TABLE trackingevents RENAME COLUMN newid TO id;<br />  ALTER TABLE trackingevents ADD PRIMARY KEY USING INDEX trackingevents_newid_idx;<br />  ALTER INDEX trackingevents_newid_idx RENAME TO trackingevents_pkey;<br />  ALTER TABLE trackingevents ALTER COLUMN id SET DEFAULT gen_random_uuid();<br />COMMIT;</pre><p>Then if everything goes well, drop the old id\u00a0column:</p><pre>ALTER TABLE trackingevents DROP COLUMN oldid;</pre><p>And if something goes wrong, the old column can be swapped back\u00a0in:</p><pre>BEGIN;<br />  UPDATE trackingevents SET oldid = 'trk_' || id WHERE oldid IS NULL;<br />  ALTER TABLE trackingevents DROP COLUMN id;<br />  ALTER TABLE trackingevents RENAME COLUMN oldid TO id;<br />  ALTER TABLE trackingevents ALTER COLUMN id SET DEFAULT 'trk_' || gen_random_uuid();<br />  ALTER TABLE trackingevents ADD PRIMARY KEY USING INDEX trackingevents_oldid_idx;<br />  ALTER INDEX trackingevents_oldid_idx RENAME TO trackingevents_pkey;<br />COMMIT;</pre><p>Following those steps, we migrated the table. The resulting index size was a little less than half the existing one. Not\u00a0bad!</p><h3>Next Steps</h3><p>There\u2019s been a lot of work going into this. We\u2019ve migrated two of our largest tables, and any new tables use uuids for their primary\u00a0keys.</p><p>As of writing our database has 67 tables, ten of which have uuid primary\u00a0keys.</p><p>Some of these have foreign keys, so the foreign key needs to be changed as well. The setup, such as backfilling to a temporary column, will be the same, but the transaction of swapping the columns out would be slightly different. Let\u2019s pretend a table called \u201ctrackingeventdetails\u201d existed and had a foreign key pointed at the \u201ctrackingevents\u201d table\u2019s id. We\u2019d have to write something like:</p><pre>BEGIN;</pre><pre>-- New! Drop the foreign key reference to the table<br />ALTER TABLE trackingeventsdetails DROP CONSTRAINT &quot;trackingeventdetails_trackingEventId_fkey&quot;;</pre><pre>-- Same as above<br />ALTER TABLE trackingevents DROP CONSTRAINT trackingevents_pkey;<br />ALTER TABLE trackingevents RENAME COLUMN id TO oldid;<br />ALTER TABLE trackingevents ALTER COLUMN oldid DROP DEFAULT;<br />ALTER TABLE trackingevents ALTER COLUMN oldid DROP NOT NULL;</pre><pre>ALTER TABLE trackingevents RENAME COLUMN newid TO id;<br />ALTER TABLE trackingevents ADD PRIMARY KEY USING INDEX trackingevents_newid_idx;<br />ALTER INDEX trackingevents_newid_idx RENAME TO trackingevents_pkey;<br />ALTER TABLE trackingevents ALTER COLUMN id SET DEFAULT gen_random_uuid();</pre><pre>-- Now we have to migrate the table pointing here as well<br />-- (pretend we have a backfilled column)<br />ALTER TABLE trackingeventdetails RENAME COLUMN &quot;trackingEventId&quot; TO oldTrackingEventId;<br />ALTER TABLE trackingeventdetails RENAME COLUMN &quot;newTrackingEventId&quot; TO id;<br />ALTER TABLE trackingeventdetails<br />  ADD CONSTRAINT &quot;trackingeventdetails_trackingEventId_fkey&quot;<br />  FOREIGN KEY REFERENCES trackingevents(id);</pre><pre>COMMIT;</pre><p>Overall, it\u2019s pretty similar\u200a\u2014\u200awe just add the modifications to the foreign keys, and since it\u2019s in a transaction, to the outside it appears as if nothing happened.</p><p>There are more complicated situations we can get into with regard to our foreign keys, but thankfully these are on our smaller tables. If you have any questions or improvements, please let us know! Also, a shout out to Braintree for posting their <a href=\"https://www.braintreepayments.com/blog/safe-operations-for-high-volume-postgresql/\">summary of high volume operations in Postgres</a>. It\u2019s been a great resource for this project as well as some of our ongoing feature\u00a0work.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3bb250471104\" width=\"1\" /><hr /><p><a href=\"https://medium.com/shyp-engineering/a-unique-journey-in-search-of-keys-3bb250471104\">A Unique Journey in Search of Keys</a> was originally published in <a href=\"https://medium.com/shyp-engineering\">Shyp Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h3>Introduction</h3><p>At Shyp we\u2019ve begun undertaking an extensive maintenance project on our primary API\u2019s database, changing its tables\u2019 primary keys from a prefixed uuid stored as text, to utilizing the database\u2019s native uuid type, and adding the prefix in the application layer. This blog post will give some general background on primary keys, outline why we made this change, the process of preparing our application for this change, and how we\u2019ve gone about migrating the existing\u00a0data.</p><h3>Primary Keys and\u00a0UUIDs</h3><p>Relational databases store records as rows in tables. Each table has a strict definition of the columns that each row entry will be made up of, along with their type. For example, you might have a contacts table defined\u00a0as:</p><pre>first: text<br />last: text<br />birthday: date</pre><p>Then, you might have a table that looks\u00a0like:</p><pre>| first   | last     | birthday   |<br />|---------|----------|------------|<br />| Lindsey | Homer    | 1984-06-24 |<br />| Melvin  | Anderson | 1987-01-23 |<br />| Jessie  | Bell     | 1957-09-16 |</pre><p>In this case, the table does not have a primary key\u200a\u2014\u200athe only way to query it is based on the information it contains. Sometimes this is appropriate, but often this becomes difficult when other information needs to be associated with a record. For example, we might want to have a notes table where we could add a note for each contact, but there\u2019s no way to clearly associate a particular contact with a note, as it\u2019s possible that two contacts can share the same name and birthday. So we need a way of uniquely identifying the record with what\u2019s called a \u201ckey\u201d. Some database designs use another attribute about a record, such as a person\u2019s Social Security Number, in order to provide a way of looking up the record; this is called a \u201cnatural key\u201d. However, this can be problematic when we can\u2019t guarantee that the value of the natural key is truly unique, and so we need to utilize something else in order to identify\u00a0records.</p><p>Since relying on intrinsic properties of a dataset is problematic for establishing the identity of records in the set, databases are often designed using synthetic primary keys. These keys are guaranteed to be unique by the database system, and are used for the sole purpose of looking up a record. The most common approach is to use a sequential integer. In our contacts example, this might look something like:</p><pre>| id | first   | last     | birthday   |<br />|----|---------|----------|------------|<br />| 1  | Lindsey | Homer    | 1984-06-24 |<br />| 2  | Melvin  | Anderson | 1987-01-23 |<br />| 3  | Jessie  | Bell     | 1957-09-16 |</pre><p>When the responsibility of generating the primary keys is entirely in the domain of the database system (as is often the case), this works well. In a distributed system, however, you might want to have an identifier for an entity without relying on the database to generate that for you. In this case, you can take a randomized value and format it in a consistent way; one category of these identifiers are known as UUIDs, which are 128-bit values, usually formatted as a hyphen-separated hexadecimal string. For example, \u201c5c3ad9ab-a0fe-474c-87a2\u201338fc818d2b03\u201d is a UUID. There are several variants of UUIDs, but they all have the same format, and the variants have to do with how the values are generated. V4 UUIDs are truly random, and are what Shyp uses for primary\u00a0keys.</p><p>In addition, we prefix a short identifier to the id at Shyp. Although this is a less common practice, it\u2019s not a quirk that\u2019s unique to us (Stripe does this too). For example, a pickup is prefixed with \u201cpik_\u201d, and a shipment is prefixed with \u201cshp_\u201d. This is useful from an application and API perspective: Our operations apps can scan a QR code containing the id of a number of things (a shipment, a container, a warehouse worker\u2019s badge) and route the UI appropriately. It\u2019s also useful for debugging, as we can readily know the kind of data we\u2019re dealing with just from its identifier.</p><p>These ids have historically been stored as text in our PostgreSQL database. While this works and has no impact on lookup speed, it\u2019s an inefficient use of space. This is especially important with primary keys, whose indexes should fit in memory. And while disk space is cheap these days, RAM is comparatively expensive, and as we scale we\u2019d like to keep these costs under control. There is also no real reason to have the database store these values as text, since PostgreSQL supports UUIDs as a first class data type, and at the database level, you always know <em>what</em> you\u2019re querying for. The different representations are quite different size-wise. A text representation of a uuid (with hyphens) is 36 bytes (or 288 bits)\u200a\u2014\u200aa little more than double the actual byte size of a UUID. An index for these values reflects this difference as well, as we will later\u00a0see.</p><p>If there\u2019s such a big difference, why did these get stored as text in the first place? Shyp\u2019s API was first built on Sails, and Sails\u2019s ORM, Waterline does not have built in support for handling UUIDs\u200a\u2014\u200ait simply treats them as text. We\u2019ve maintained our own fork of Waterline, which we\u2019ve stripped a lot of features from, as well as removed all other parts of Sails from our API. In any case, the first step in this endeavor was to prepare our API and Waterline to handle\u00a0UUIDs.</p><h3>Planning</h3><p>Changing the type in the database, is fairly easy in some sense\u200a\u2014\u200asimply change the\u00a0type:</p><pre>ALTER TABLE users CHANGE COLUMN id SET TYPE uuid;</pre><p>This sort of schema change could cause problems in a production environment, particularly when the table is so large that running the query will take more than a second or two, but it\u2019s a good start in terms of getting the application code prepared for using the prefix-less ids.</p><p>In integrating with the existing codebase, we need to make sure the assumptions around prefixes are being challenged. For example, in my initial exploration I added a migration for one of our tables, ran the unit tests, and everything passed (great, ship it!). Since I knew that the prefixes weren\u2019t being added I had to explicitly define the assumptions around our prefixing behavior.</p><p>First, I wrote an integration test that attempted to create a record, asserted that the newly created record was serialized by the application with a prefix, and finally, could be searched with that record. This ensures that the boundary around having prefixes or not is flexible; Ideally we\u2019d go with one or the other, but we have a living codebase with many teams, and it\u2019s impossible to change everything overnight while continuing to deliver new features.</p><p>In other words, not only did we want to handle UUIDs, but also we thought it would be nice if we could have our models handle prefixed UUIDs, and simply ignore the prefix when running\u00a0queries.</p><p>In order to handle this, we <a href=\"https://github.com/Shyp/waterline/pull/32\">added some UUID type coercion functionality</a> to our fork of Waterline. This was pretty straightforward, as Waterline already has built in type coercion functionality; that is, if you give a model a string for an integer primary key, it will attempt to coerce it to an actual\u00a0integer.</p><p>This results with the following Waterline query</p><pre>User.findOne('usr_abc123') // ...</pre><p>only using the UUID in issuing the\u00a0query</p><pre>SELECT * FROM users WHERE id = 'abc123';</pre><p>instead of using the\u00a0prefix</p><pre>SELECT * FROM users WHERE id = 'usr_abc123';</pre><p>(The latter query would throw an error in Postgres, because the value is not a valid\u00a0uuid).</p><p>Next, we needed to add the prefix in the models. This is relatively straightforward; All models in our system have \u201ctoJSON()\u201d invoked when being serialized, so we simply override the id serialization here, essentially adding the prefix if it\u2019s not present on the\u00a0id.</p><p>As a result of all this, we\u2019ve got our models covered on both ends, compatible with our prefixed UUIDs internally, and our integration test passes. One nice quality of this approach in the model layer is that our code will be compatible with the schema as we\u00a0migrate.</p><h3>Data Migration</h3><p>Now that our codebase will work with the prefix-less UUIDs, we need to migrate the existing data. This is a little tricky, because while it affects an entire table, it needs to happen without interrupting service. It also needs to be easily reversed in case something goes\u00a0wrong.</p><p>To do this, we can break the migration into 5\u00a0steps:</p><ol><li>Create a new column that will be the eventual new id\u00a0column.</li><li>Fill any new records with the prefix-less id via a trigger on the\u00a0table.</li><li>Backfill this column with the prefix-less data.</li><li>Create an index (concurrently) on that\u00a0column.</li><li>Swap the new column in, and keep the old one (in a transaction).</li></ol><p>Our migration was on the \u201ctrackingevents\u201d table, which records a shipment\u2019s various updates from the\u00a0carrier.</p><p>This is what the migration looks like in\u00a0SQL:</p><pre>ALTER TABLE trackingevents ADD COLUMN newid uuid;</pre><pre>CREATE FUNCTION shyp_copy_newid() RETURNS TRIGGER AS $$<br />  BEGIN<br />    IF NEW.id IS NOT NULL THEN<br />      NEW.newid := regexp_replace(NEW.id, '\\w+_', '')::uuid;<br />    END IF;<br />    RETURN NEW;<br />  END<br />$$ LANGUAGE plpgsql;</pre><pre>CREATE TRIGGER shyp_copy_newid BEFORE INSERT OR UPDATE ON trackingevents<br />  FOR EACH ROW EXECUTE PROCEDURE shyp_copy_newid();</pre><pre>UPDATE trackingevents SET id = id;</pre><pre>CREATE UNIQUE INDEX CONCURRENTLY trackingevents_newid_idx ON trackingevents(newid);<br />CREATE UNIQUE INDEX CONCURRENTLY trackingevents_oldid_idx ON trackingevents(id);</pre><pre>BEGIN;<br />  DROP TRIGGER shyp_copy_newid ON trackingevents;<br />  DROP FUNCTION shyp_copy_newid();</pre><pre>  ALTER TABLE trackingevents DROP CONSTRAINT trackingevents_pkey;<br />  ALTER TABLE trackingevents RENAME COLUMN id TO oldid;<br />  ALTER TABLE trackingevents ALTER COLUMN oldid DROP DEFAULT;<br />  ALTER TABLE trackingevents ALTER COLUMN oldid DROP NOT NULL;</pre><pre>  ALTER TABLE trackingevents RENAME COLUMN newid TO id;<br />  ALTER TABLE trackingevents ADD PRIMARY KEY USING INDEX trackingevents_newid_idx;<br />  ALTER INDEX trackingevents_newid_idx RENAME TO trackingevents_pkey;<br />  ALTER TABLE trackingevents ALTER COLUMN id SET DEFAULT gen_random_uuid();<br />COMMIT;</pre><p>Then if everything goes well, drop the old id\u00a0column:</p><pre>ALTER TABLE trackingevents DROP COLUMN oldid;</pre><p>And if something goes wrong, the old column can be swapped back\u00a0in:</p><pre>BEGIN;<br />  UPDATE trackingevents SET oldid = 'trk_' || id WHERE oldid IS NULL;<br />  ALTER TABLE trackingevents DROP COLUMN id;<br />  ALTER TABLE trackingevents RENAME COLUMN oldid TO id;<br />  ALTER TABLE trackingevents ALTER COLUMN id SET DEFAULT 'trk_' || gen_random_uuid();<br />  ALTER TABLE trackingevents ADD PRIMARY KEY USING INDEX trackingevents_oldid_idx;<br />  ALTER INDEX trackingevents_oldid_idx RENAME TO trackingevents_pkey;<br />COMMIT;</pre><p>Following those steps, we migrated the table. The resulting index size was a little less than half the existing one. Not\u00a0bad!</p><h3>Next Steps</h3><p>There\u2019s been a lot of work going into this. We\u2019ve migrated two of our largest tables, and any new tables use uuids for their primary\u00a0keys.</p><p>As of writing our database has 67 tables, ten of which have uuid primary\u00a0keys.</p><p>Some of these have foreign keys, so the foreign key needs to be changed as well. The setup, such as backfilling to a temporary column, will be the same, but the transaction of swapping the columns out would be slightly different. Let\u2019s pretend a table called \u201ctrackingeventdetails\u201d existed and had a foreign key pointed at the \u201ctrackingevents\u201d table\u2019s id. We\u2019d have to write something like:</p><pre>BEGIN;</pre><pre>-- New! Drop the foreign key reference to the table<br />ALTER TABLE trackingeventsdetails DROP CONSTRAINT &quot;trackingeventdetails_trackingEventId_fkey&quot;;</pre><pre>-- Same as above<br />ALTER TABLE trackingevents DROP CONSTRAINT trackingevents_pkey;<br />ALTER TABLE trackingevents RENAME COLUMN id TO oldid;<br />ALTER TABLE trackingevents ALTER COLUMN oldid DROP DEFAULT;<br />ALTER TABLE trackingevents ALTER COLUMN oldid DROP NOT NULL;</pre><pre>ALTER TABLE trackingevents RENAME COLUMN newid TO id;<br />ALTER TABLE trackingevents ADD PRIMARY KEY USING INDEX trackingevents_newid_idx;<br />ALTER INDEX trackingevents_newid_idx RENAME TO trackingevents_pkey;<br />ALTER TABLE trackingevents ALTER COLUMN id SET DEFAULT gen_random_uuid();</pre><pre>-- Now we have to migrate the table pointing here as well<br />-- (pretend we have a backfilled column)<br />ALTER TABLE trackingeventdetails RENAME COLUMN &quot;trackingEventId&quot; TO oldTrackingEventId;<br />ALTER TABLE trackingeventdetails RENAME COLUMN &quot;newTrackingEventId&quot; TO id;<br />ALTER TABLE trackingeventdetails<br />  ADD CONSTRAINT &quot;trackingeventdetails_trackingEventId_fkey&quot;<br />  FOREIGN KEY REFERENCES trackingevents(id);</pre><pre>COMMIT;</pre><p>Overall, it\u2019s pretty similar\u200a\u2014\u200awe just add the modifications to the foreign keys, and since it\u2019s in a transaction, to the outside it appears as if nothing happened.</p><p>There are more complicated situations we can get into with regard to our foreign keys, but thankfully these are on our smaller tables. If you have any questions or improvements, please let us know! Also, a shout out to Braintree for posting their <a href=\"https://www.braintreepayments.com/blog/safe-operations-for-high-volume-postgresql/\">summary of high volume operations in Postgres</a>. It\u2019s been a great resource for this project as well as some of our ongoing feature\u00a0work.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3bb250471104\" width=\"1\" /><hr /><p><a href=\"https://medium.com/shyp-engineering/a-unique-journey-in-search-of-keys-3bb250471104\">A Unique Journey in Search of Keys</a> was originally published in <a href=\"https://medium.com/shyp-engineering\">Shyp Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Remind": {
    "title": "Transitive Closure in PostgreSQL",
    "xmlUrl": "http://engineering.remind.com/feed.xml",
    "htmlUrl": "http://engineering.remind.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.remind.com/feed.xml",
      "value": "Transitive Closure in PostgreSQL"
    },
    "summary": "<p>At Remind we operate one of the largest communication tools for education in the United States and Canada. We have millions of parents, students, teachers and administrators use our application each day to improve learning outcomes by sending 10s of millions of messages per day. With this large scale usage we\u2019ve had many opportunities to innovate and some of our most recent work has been around using PostgreSQL to capture graph-based structure and efficiently query them.</p>\n\n<h3 id=\"graphs-in-a-relational-database\">Graphs in a relational database</h3>\n<p>Our particular dataset consists of multiple organization trees. In education, most classes belong to a school and most schools belong to a district. But some classes may belong to a department, which may belong to a school, which may belong to a college, which may belong to a campus, which may belong to a university. We wanted to build a system that could not only represent these hierarchies but do so in an efficient manner.</p>\n\n<p>As a concrete example, here\u2019s how a middle school mach class might be represented:</p>\n\n<p><img alt=\"Simple Example\" src=\"https://s3.amazonaws.com/engineering.remind.com/transitive_closure/transitive_closure_example_simple.png\" /></p>\n\n<p>In our database, we store these entities as an adjacency list. Note: We store these with UUIDs, but here we\u2019ll use the names to make it easier to follow.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra I</td>\n      <td>Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>Springfield District</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>NULL</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Common query patterns we have require finding all classes in a district, or finding the district a class belongs to.</p>\n\n<p>Naively, we need to traverse through <code class=\"language-plaintext highlighter-rouge\">Maple Middle School</code> to determine that <code class=\"language-plaintext highlighter-rouge\">Algebra 1</code> is a descendent of <code class=\"language-plaintext highlighter-rouge\">Springfield District</code>.</p>\n\n<p>Our goal was to make such queries fast and performant while maintaining accuracy.</p>\n\n<p>There are a few techniques for doing this inside a PostgreSQL database:</p>\n<ol>\n  <li>We can traverse through the adjacency list using <a href=\"https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-RECURSIVE\">Recursive Queries</a>.</li>\n  <li>We can use <a href=\"https://en.wikipedia.org/wiki/Nested_set_model\">Nested Sets</a></li>\n  <li>We can materialize the <a href=\"https://en.wikipedia.org/wiki/Transitive_closure#In_graph_theory\">Transitive Closure</a>.</li>\n</ol>\n\n<p>We started with option 1 but performance wasn\u2019t quite where we wanted it to be. Option 2 was a viable path, but concerns around maintenance and our update pattern (where leaf nodes are frequently added and removed) didn\u2019t seem like the right fit. So we went with Option 3.</p>\n\n<h3 id=\"transitive-closure\">Transitive Closure</h3>\n<p>The transitive closure of a graph tells if one node is reachable from another node. In our <code class=\"language-plaintext highlighter-rouge\">Algebra 1</code> example above, we have 6 edges in the transitive closure:</p>\n\n<p><img alt=\"Example with Closure\" src=\"https://s3.amazonaws.com/engineering.remind.com/transitive_closure/transitive_closure_example_with_closure.png\" /></p>\n\n<p>Note: We include self references here for reasons we\u2019ll explain in a bit.</p>\n\n<h3 id=\"the-edge-organization-ancestor-and-distance\">The Edge: <code class=\"language-plaintext highlighter-rouge\">organization</code>, <code class=\"language-plaintext highlighter-rouge\">ancestor</code>, and <code class=\"language-plaintext highlighter-rouge\">distance</code></h3>\n<p>These are the columns that describe the edges in our graph. Given a class <code class=\"language-plaintext highlighter-rouge\">Algebra 1</code> in a school <code class=\"language-plaintext highlighter-rouge\">Maple Middle School</code> in a district <code class=\"language-plaintext highlighter-rouge\">Springfield District</code>, the edges look like:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>1</td>\n      <td>Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>2</td>\n      <td>Springfield District</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>1</td>\n      <td>Springfield District</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n    </tr>\n  </tbody>\n</table>\n\n<p><code class=\"language-plaintext highlighter-rouge\">organization</code> is the start node, <code class=\"language-plaintext highlighter-rouge\">ancestor</code> is the end node and <code class=\"language-plaintext highlighter-rouge\">distance</code> captures how many other nodes we had to go through to get there.</p>\n\n<p>This is a really great schema for querying. We have organization tables like <code class=\"language-plaintext highlighter-rouge\">organization_memberships</code> and we can perform simple queries like:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>select\n  count(distinct \"user\")\nfrom organizations_closure\njoin organization_memberships using (organization)\nwhere ancestor = 'Springfield District'\n</code></pre></div></div>\n<p>This query will count the number of users enrolled in any class in the <code class=\"language-plaintext highlighter-rouge\">Springfield District</code>. We didn\u2019t have to traverse through the schools, we could just enumerate the user enrollment directly by following the connection from <code class=\"language-plaintext highlighter-rouge\">district -&gt; class</code>.</p>\n\n<h3 id=\"the-proof-through_org-distance_to_through_org\">The Proof: <code class=\"language-plaintext highlighter-rouge\">through_org</code>, <code class=\"language-plaintext highlighter-rouge\">distance_to_through_org</code></h3>\n<p>Something missing from the above data is <em>why</em> an organization is considered an ancestor. Let\u2019s capture those reasons:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>ancestor</th>\n      <th>reason</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra I</td>\n      <td>Algebra I</td>\n      <td>Self</td>\n    </tr>\n    <tr>\n      <td>Algebra I</td>\n      <td>Maple Middle School</td>\n      <td>Parent of Algebra I</td>\n    </tr>\n    <tr>\n      <td>Algebra I</td>\n      <td>Springfield District</td>\n      <td>Parent of Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>Maple Middle School</td>\n      <td>Self</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>Springfield District</td>\n      <td>Parent of Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>Springfield District</td>\n      <td>Self</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Each <code class=\"language-plaintext highlighter-rouge\">reason</code> is either <code class=\"language-plaintext highlighter-rouge\">Self</code> or <code class=\"language-plaintext highlighter-rouge\">Parent of X</code> where <code class=\"language-plaintext highlighter-rouge\">X</code> is an established ancestor of the organization. In our schema we capture this by recording the <code class=\"language-plaintext highlighter-rouge\">through_org</code> for each edge as well as the distance to the <code class=\"language-plaintext highlighter-rouge\">through_org</code>. For self references these will be <code class=\"language-plaintext highlighter-rouge\">NULL</code>. For any other references they will describe the node that must be travelled through to reach the <code class=\"language-plaintext highlighter-rouge\">ancestor</code>. The resulting data looks like this:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n      <th>through_org</th>\n      <th>distance_to_through_org</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>1</td>\n      <td>Maple Middle School</td>\n      <td>Algebra 1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>1</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>2</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n\n<h4 id=\"constraints\">Constraints</h4>\n\n<p>With our columns in place, we want to ensure this data is correct and that we will not drift from our adjacency list.</p>\n\n<p>Our constraints:</p>\n<ol>\n  <li>A row must either be a self reference or it must have a <code class=\"language-plaintext highlighter-rouge\">through_org</code> .</li>\n  <li>A self reference has a <code class=\"language-plaintext highlighter-rouge\">distance</code> of 0. All other rows must have <code class=\"language-plaintext highlighter-rouge\">distance</code> of <code class=\"language-plaintext highlighter-rouge\">distance_to_through_org + 1</code>.</li>\n  <li>A <code class=\"language-plaintext highlighter-rouge\">through_org</code> must be an ancestor of <code class=\"language-plaintext highlighter-rouge\">organization</code> (which can mean itself) and <code class=\"language-plaintext highlighter-rouge\">distance_to_through_org</code> must match the distance from <code class=\"language-plaintext highlighter-rouge\">organization</code> to <code class=\"language-plaintext highlighter-rouge\">through_org</code>.</li>\n  <li>If there is a <code class=\"language-plaintext highlighter-rouge\">through_org</code>, <code class=\"language-plaintext highlighter-rouge\">ancestor</code> must be a direct parent of the <code class=\"language-plaintext highlighter-rouge\">through_org</code>.</li>\n</ol>\n\n<p>We can enforce these constraints in PostgreSQL:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"nv\">\"organizations_closure_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">through_org</span> <span class=\"k\">IS</span> <span class=\"k\">NOT</span> <span class=\"k\">NULL</span> <span class=\"k\">OR</span> <span class=\"n\">organization</span> <span class=\"o\">=</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n\n    <span class=\"nv\">\"organizations_closure_distance_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">distance</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"k\">OR</span> <span class=\"n\">organization</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_distance_to_through_org_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">distance_to_through_org</span> <span class=\"k\">IS</span> <span class=\"k\">NULL</span> <span class=\"k\">AND</span> <span class=\"n\">distance</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"k\">OR</span> <span class=\"n\">distance_to_through_org</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">distance</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n\n    <span class=\"nv\">\"organizations_closure_through_org_distance_fk\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">distance_to_through_org</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span> <span class=\"n\">distance</span><span class=\"p\">)</span>\n\n    <span class=\"nv\">\"organizations_closure_through_org_fkey\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">parent</span><span class=\"p\">)</span> <span class=\"k\">ON</span> <span class=\"k\">DELETE</span> <span class=\"k\">CASCADE</span>\n</code></pre></div></div>\n\n<p>Finally, we want to ensure referential integrity, so we ensure that <code class=\"language-plaintext highlighter-rouge\">ancestor</code> is an organization that exists:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"nv\">\"organizations_closure_ancestor_fkey\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">)</span> <span class=\"k\">ON</span> <span class=\"k\">DELETE</span> <span class=\"k\">CASCADE</span>\n</code></pre></div></div>\n<p>(It\u2019s not necessary to have a foreign key on <code class=\"language-plaintext highlighter-rouge\">organization</code> as every row has an eventual dependency on a self reference. For self references, <code class=\"language-plaintext highlighter-rouge\">organization = ancestor</code> and so the foreign key on <code class=\"language-plaintext highlighter-rouge\">ancestor</code> gives us what we need. Having the additional key wouldn\u2019t hurt, but it\u2019s not necessary.)</p>\n\n<p>With these constraints in place, we are protected against stale data from intermediate nodes being improperly removed.</p>\n\n<h3 id=\"populating\">Populating</h3>\n\n<p>To populate this table, we can follow a recursive approach:</p>\n<ol>\n  <li>Establish self nodes as ancestors</li>\n  <li>For each ancestor, add its parent as a new ancestor</li>\n  <li>If an ancestor has no parent, do nothing</li>\n</ol>\n\n<p>Returning to our <code class=\"language-plaintext highlighter-rouge\">Algebra 1</code> example, from the above rules we can first establish the self references:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n      <th>through_org</th>\n      <th>distance_to_through_org</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>We can then add immediate parents. Because <code class=\"language-plaintext highlighter-rouge\">organization</code> is its own <code class=\"language-plaintext highlighter-rouge\">ancestor</code> (from the self references), we can use those as <code class=\"language-plaintext highlighter-rouge\">through_org</code> and use their parent as <code class=\"language-plaintext highlighter-rouge\">ancestor</code></p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n      <th>through_org</th>\n      <th>distance_to_through_org</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>1</td>\n      <td>Maple Middle School</td>\n      <td>Algebra 1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>1</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Now that we have parents in our table, we can use those parents to add grandparents</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n      <th>through_org</th>\n      <th>distance_to_through_org</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>1</td>\n      <td>Maple Middle School</td>\n      <td>Algebra 1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>1</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>2</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>And in this case, because <code class=\"language-plaintext highlighter-rouge\">Springfield District</code> has no parent, we\u2019re done.</p>\n\n<h3 id=\"full-schema\">Full Schema</h3>\n<p>Whenever data is denormalized, the greatest risk is inconsistency. As we traverse more of the graph, a given relation depends on more and more rows. If a great-grandparent moves under another node, all of its children will need to be updated.</p>\n\n<p>Our goal was to find a way to leverage database constraints to ensure correctness.</p>\n\n<p>This is the schema and constraints we landed on:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>                <span class=\"k\">Table</span> <span class=\"nv\">\"remind.organizations_closure\"</span>\n         <span class=\"k\">Column</span>          <span class=\"o\">|</span>  <span class=\"k\">Type</span>   <span class=\"o\">|</span> <span class=\"k\">Collation</span> <span class=\"o\">|</span> <span class=\"k\">Nullable</span> <span class=\"o\">|</span> <span class=\"k\">Default</span>\n<span class=\"c1\">-------------------------+---------+-----------+----------+---------</span>\n <span class=\"n\">organization</span>            <span class=\"o\">|</span> <span class=\"n\">uuid</span>    <span class=\"o\">|</span>           <span class=\"o\">|</span> <span class=\"k\">not</span> <span class=\"k\">null</span> <span class=\"o\">|</span>\n <span class=\"n\">through_org</span>             <span class=\"o\">|</span> <span class=\"n\">uuid</span>    <span class=\"o\">|</span>           <span class=\"o\">|</span>          <span class=\"o\">|</span>\n <span class=\"n\">ancestor</span>                <span class=\"o\">|</span> <span class=\"n\">uuid</span>    <span class=\"o\">|</span>           <span class=\"o\">|</span> <span class=\"k\">not</span> <span class=\"k\">null</span> <span class=\"o\">|</span>\n <span class=\"n\">distance</span>                <span class=\"o\">|</span> <span class=\"nb\">integer</span> <span class=\"o\">|</span>           <span class=\"o\">|</span> <span class=\"k\">not</span> <span class=\"k\">null</span> <span class=\"o\">|</span>\n <span class=\"n\">distance_to_through_org</span> <span class=\"o\">|</span> <span class=\"nb\">integer</span> <span class=\"o\">|</span>           <span class=\"o\">|</span>          <span class=\"o\">|</span>\n\n<span class=\"n\">Indexes</span><span class=\"p\">:</span>\n    <span class=\"nv\">\"organizations_closure_pkey\"</span> <span class=\"k\">PRIMARY</span> <span class=\"k\">KEY</span><span class=\"p\">,</span> <span class=\"n\">btree</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_ancestor_idx\"</span> <span class=\"n\">btree</span> <span class=\"p\">(</span><span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_organization_ancestor_distance_idx\"</span> <span class=\"k\">UNIQUE</span><span class=\"p\">,</span> <span class=\"n\">btree</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span> <span class=\"n\">distance</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_through_org_idx\"</span> <span class=\"n\">btree</span> <span class=\"p\">(</span><span class=\"n\">through_org</span><span class=\"p\">)</span>\n\n<span class=\"k\">Check</span> <span class=\"k\">constraints</span><span class=\"p\">:</span>\n    <span class=\"nv\">\"organizations_closure_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">through_org</span> <span class=\"k\">IS</span> <span class=\"k\">NOT</span> <span class=\"k\">NULL</span> <span class=\"k\">OR</span> <span class=\"n\">organization</span> <span class=\"o\">=</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_distance_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">distance</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"k\">OR</span> <span class=\"n\">organization</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_distance_to_through_org_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">distance_to_through_org</span> <span class=\"k\">IS</span> <span class=\"k\">NULL</span> <span class=\"k\">AND</span> <span class=\"n\">distance</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"k\">OR</span> <span class=\"n\">distance_to_through_org</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">distance</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n\n<span class=\"k\">Foreign</span><span class=\"o\">-</span><span class=\"k\">key</span> <span class=\"k\">constraints</span><span class=\"p\">:</span>\n    <span class=\"nv\">\"organizations_closure_ancestor_fkey\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">)</span> <span class=\"k\">ON</span> <span class=\"k\">DELETE</span> <span class=\"k\">CASCADE</span>\n    <span class=\"nv\">\"organizations_closure_through_org_distance_fk\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">distance_to_through_org</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span> <span class=\"n\">distance</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_through_org_fkey\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">parent</span><span class=\"p\">)</span> <span class=\"k\">ON</span> <span class=\"k\">DELETE</span> <span class=\"k\">CASCADE</span>\n</code></pre></div></div>\n\n<h3 id=\"additional-invalid-states\">Additional Invalid States</h3>\n<p>We also want to prevent any invalid states that we couldn\u2019t fully capture in our schema. The primary case we need to prevent is a cycle.</p>\n\n<p>To prevent a cycle, we use the following function as a <code class=\"language-plaintext highlighter-rouge\">before insert</code> trigger:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">CREATE</span> <span class=\"k\">FUNCTION</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_block_cycle</span><span class=\"p\">()</span> <span class=\"k\">RETURNS</span> <span class=\"k\">trigger</span>\n    <span class=\"k\">LANGUAGE</span> <span class=\"n\">plpgsql</span>\n    <span class=\"k\">AS</span> <span class=\"err\">$$</span>\n      <span class=\"k\">begin</span>\n        <span class=\"n\">if</span> <span class=\"k\">exists</span> <span class=\"p\">(</span><span class=\"k\">select</span> <span class=\"k\">from</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span> <span class=\"k\">where</span> <span class=\"n\">ancestor</span> <span class=\"o\">=</span> <span class=\"k\">NEW</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"k\">and</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"o\">=</span> <span class=\"k\">NEW</span><span class=\"p\">.</span><span class=\"n\">parent</span><span class=\"p\">)</span> <span class=\"k\">then</span>\n          <span class=\"n\">raise</span> <span class=\"n\">exception</span> <span class=\"s1\">'Cannot add descendant as parent, would create cycle'</span><span class=\"p\">;</span>\n        <span class=\"k\">else</span>\n          <span class=\"k\">return</span> <span class=\"k\">NEW</span><span class=\"p\">;</span>\n        <span class=\"k\">end</span> <span class=\"n\">if</span><span class=\"p\">;</span>\n      <span class=\"k\">end</span>\n    <span class=\"err\">$$</span><span class=\"p\">;</span>\n</code></pre></div></div>\n\n<h3 id=\"maintenance\">Maintenance</h3>\n<p>Now that we have a schema and constraints that ensure correctness, we need a way to update it easily. While the schema will prevent invalid states, we don\u2019t want to hit these errors. We want the normal range of CRUD operations to propagate changes to these tables and keep them in sync.</p>\n\n<p>We used the following functions in an <code class=\"language-plaintext highlighter-rouge\">after insert</code> trigger:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">CREATE</span> <span class=\"k\">FUNCTION</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_rematerialize_closure</span><span class=\"p\">(</span><span class=\"n\">uuid</span><span class=\"p\">)</span> <span class=\"k\">RETURNS</span> <span class=\"n\">void</span>\n    <span class=\"k\">LANGUAGE</span> <span class=\"n\">plpgsql</span>\n    <span class=\"k\">AS</span> <span class=\"err\">$</span><span class=\"n\">_</span><span class=\"err\">$</span>\n      <span class=\"k\">begin</span>\n        <span class=\"c1\">-- This could maybe be reworked to recursively build the list of orgs that need to be</span>\n        <span class=\"c1\">-- rematerialized and then materialize them all in one fell swoop.</span>\n        <span class=\"n\">perform</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">materialize_org_ancestors</span><span class=\"p\">(</span><span class=\"err\">$</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n\n        <span class=\"c1\">-- When we update the ancestors of the parent, we need to update all the children</span>\n        <span class=\"c1\">-- so that they reflect the new grandparent, great-grandparent, etc.</span>\n        <span class=\"n\">perform</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_rematerialize_closure</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">)</span> <span class=\"k\">from</span> <span class=\"p\">(</span>\n          <span class=\"k\">select</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span>\n          <span class=\"k\">from</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span>\n          <span class=\"k\">where</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">parent</span> <span class=\"o\">=</span> <span class=\"err\">$</span><span class=\"mi\">1</span>\n        <span class=\"p\">)</span> <span class=\"n\">child_orgs</span><span class=\"p\">;</span>\n      <span class=\"k\">end</span><span class=\"p\">;</span>\n    <span class=\"err\">$</span><span class=\"n\">_</span><span class=\"err\">$</span><span class=\"p\">;</span>\n\n<span class=\"k\">CREATE</span> <span class=\"k\">FUNCTION</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">materialize_org_ancestors</span><span class=\"p\">(</span><span class=\"n\">VARIADIC</span> <span class=\"n\">uuid</span><span class=\"p\">[])</span> <span class=\"k\">RETURNS</span> <span class=\"n\">void</span>\n    <span class=\"k\">LANGUAGE</span> <span class=\"n\">plpgsql</span>\n    <span class=\"k\">AS</span> <span class=\"err\">$</span><span class=\"n\">_</span><span class=\"err\">$</span>\n      <span class=\"k\">begin</span>\n        <span class=\"k\">with</span> <span class=\"k\">recursive</span> <span class=\"n\">closure</span> <span class=\"k\">as</span> <span class=\"p\">(</span>\n          <span class=\"k\">select</span>\n            <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span><span class=\"p\">,</span>\n            <span class=\"k\">null</span><span class=\"p\">::</span><span class=\"n\">uuid</span> <span class=\"k\">as</span> <span class=\"n\">through_org</span><span class=\"p\">,</span>\n            <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"k\">as</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span>\n            <span class=\"mi\">0</span> <span class=\"k\">as</span> <span class=\"n\">distance</span><span class=\"p\">,</span>\n            <span class=\"k\">null</span><span class=\"p\">::</span><span class=\"nb\">integer</span> <span class=\"k\">as</span> <span class=\"n\">distance_to_through_org</span>\n          <span class=\"k\">from</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span>\n          <span class=\"k\">where</span> <span class=\"n\">organization</span> <span class=\"o\">=</span> <span class=\"k\">any</span> <span class=\"p\">(</span><span class=\"err\">$</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n          <span class=\"k\">union</span>\n          <span class=\"k\">select</span>\n            <span class=\"n\">closure</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"k\">as</span> <span class=\"n\">organization</span><span class=\"p\">,</span>\n            <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"k\">as</span> <span class=\"n\">through_org</span><span class=\"p\">,</span>\n            <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">parent</span> <span class=\"k\">as</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span>\n            <span class=\"n\">closure</span><span class=\"p\">.</span><span class=\"n\">distance</span> <span class=\"o\">+</span> <span class=\"mi\">1</span> <span class=\"k\">as</span> <span class=\"n\">distance</span><span class=\"p\">,</span>\n            <span class=\"n\">closure</span><span class=\"p\">.</span><span class=\"n\">distance</span> <span class=\"k\">as</span> <span class=\"n\">distance_to_through_org</span>\n          <span class=\"k\">from</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span>\n          <span class=\"k\">join</span> <span class=\"n\">closure</span> <span class=\"k\">on</span> <span class=\"p\">(</span><span class=\"n\">closure</span><span class=\"p\">.</span><span class=\"n\">ancestor</span> <span class=\"o\">=</span> <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span><span class=\"p\">)</span>\n          <span class=\"k\">where</span> <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">parent</span> <span class=\"k\">is</span> <span class=\"k\">not</span> <span class=\"k\">null</span>\n        <span class=\"p\">)</span>\n        <span class=\"k\">insert</span> <span class=\"k\">into</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span> <span class=\"n\">distance</span><span class=\"p\">,</span> <span class=\"n\">distance_to_through_org</span><span class=\"p\">)</span>\n        <span class=\"k\">select</span> <span class=\"o\">*</span> <span class=\"k\">from</span> <span class=\"n\">closure</span>\n        <span class=\"k\">on</span> <span class=\"n\">conflict</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">do</span> <span class=\"k\">nothing</span><span class=\"p\">;</span>\n      <span class=\"k\">end</span>\n      <span class=\"err\">$</span><span class=\"n\">_</span><span class=\"err\">$</span><span class=\"p\">;</span>\n</code></pre></div></div>\n<p>Essentially, we rematerialize all ancestors for a given org and then iterate through its children and rematerialize their ancestors (and continue until we\u2019ve reached all leaf nodes). This is a recursive process and it is why preventing cycles is essential.</p>\n\n<p>When rematerializing ancestors, we use a recursive CTE. On each iteration we track <code class=\"language-plaintext highlighter-rouge\">through_org</code> and <code class=\"language-plaintext highlighter-rouge\">distance_to_through_org</code>.</p>\n\n<p>For deletes and updates we rely on our foreign keys <code class=\"language-plaintext highlighter-rouge\">on delete casade</code> as well as a before update trigger to clean up rows that are no longer relevant.</p>\n\n<h3 id=\"testing-strategy\">Testing Strategy</h3>\n<p>This is a lot of complexity. While we are confident the data in the table will be accurate, we were (rightfully) very concerned about application errors when a constraint blocks us from making a change. We decided that robust testing was essential to having confidence operationally.</p>\n\n<p>When we started this, we had been separately exploring a style of testing called <a href=\"https://proptest-rs.github.io/proptest/intro.html\">property testing</a> in a couple of different contexts. The core idea is that if you can create a simple model that captures your behavior, you can generate broad and nearly exhaustive test cases for a more complex implementation. In our case, the model is fairly straightforward (it\u2019s just a tree structure) and the materialization is fairly complex. It has worked very well for us.</p>\n\n<p>Our property tests (using the <code class=\"language-plaintext highlighter-rouge\">proptest</code> crate) build an organization forest (or a collection of organization trees) in memory. We then sync this structure into the database and assert the following for each organization:</p>\n<ol>\n  <li>An <code class=\"language-plaintext highlighter-rouge\">organizations_closure</code> row exists for the organization and each of its ancestors with the correct distance values. No other ancestors should exist.</li>\n  <li>An <code class=\"language-plaintext highlighter-rouge\">organizations_closure</code> row exists for each of its descendants with the correct ancestor and with the correct distance values. No other descendants should exist.</li>\n</ol>\n\n<p>Then we mutate the tree with arbitrary actions. For each action we perform the mutation on our simple model as well as in the database.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Action</th>\n      <th>Simple Model</th>\n      <th>Complex Model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Nothing</td>\n      <td>Nothing</td>\n      <td>Nothing</td>\n    </tr>\n    <tr>\n      <td>Detach</td>\n      <td>Remove from children, add to tree list</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = null where organization = ?</code></td>\n    </tr>\n    <tr>\n      <td>Update (1 step)</td>\n      <td>Remove from old parent, add to new parent</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = ? where organization = ?</code></td>\n    </tr>\n    <tr>\n      <td>Update (2 step)</td>\n      <td>Remove from old parent, add to new parent</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = null where organization = ?</code> followed by <code class=\"language-plaintext highlighter-rouge\">update organizations set parent = ? where organization = ?</code></td>\n    </tr>\n    <tr>\n      <td>Delete (roll up children)</td>\n      <td>Move children to grand parent, remove organization</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = ? where parent = ?</code> followed by <code class=\"language-plaintext highlighter-rouge\">delete from organizations where organization = ?</code></td>\n    </tr>\n    <tr>\n      <td>Delete (detach children)</td>\n      <td>Add children to tree list, remove organization</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = null where parent = ?</code> followed by <code class=\"language-plaintext highlighter-rouge\">delete from organizations where organization = ?</code></td>\n    </tr>\n  </tbody>\n</table>\n\n<p>In addition to these, we have a handful of other cases more specific to our product.</p>\n\n<p>We then assert the same properties as before.</p>\n\n<p>This testing strategy has been great. The <code class=\"language-plaintext highlighter-rouge\">proptest</code> crate captures the generated tests that fail and includes them in all future runs as a regression suite. While developing we ran with 10k cases, but in our CI suite we now run with \u201cjust\u201d the default of 256 cases. The thoroughness of the testing approach has made adding additional actions (for example, \u201cArchiving\u201d an organization) easy to implement and has given us very high confidence as we roll new features out.</p>\n\n<h3 id=\"rolling-it-out\">Rolling it out</h3>\n<p>We rely heavily on AWS Aurora with PostgreSQL. One of the great features available with Aurora are clones. In about 15 minutes, a Copy-on-Write clone can be spun up and be used for testing. With our full production dataset in a clone, we created the table and constraints and started populating it. It was no surprise that we had some cycles in our data set (a decade of organic data at scale means nothing is a surprise), but otherwise everything went smoothly.  We worked with our support team to clean up the cycles, added the tables to prod, and backfilled the data. Everything ran smoothly and we\u2019ve been using this table ever since.</p>\n\n<h2 id=\"closing\">Closing</h2>\n<p>We use this to power a product that serves millions and millions of parents, students, teachers and administrators every day. It\u2019s improved performance, reduced load, and accelerated our team\u2019s ability to deliver value to our customers. A special thanks to all the team members at Remind who worked on this from conceptualization to running it in prod. Especially Phil Frost, who held the vision and set us on this path.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.remind.com/feed.xml",
      "value": "<p>At Remind we operate one of the largest communication tools for education in the United States and Canada. We have millions of parents, students, teachers and administrators use our application each day to improve learning outcomes by sending 10s of millions of messages per day. With this large scale usage we\u2019ve had many opportunities to innovate and some of our most recent work has been around using PostgreSQL to capture graph-based structure and efficiently query them.</p>\n\n<h3 id=\"graphs-in-a-relational-database\">Graphs in a relational database</h3>\n<p>Our particular dataset consists of multiple organization trees. In education, most classes belong to a school and most schools belong to a district. But some classes may belong to a department, which may belong to a school, which may belong to a college, which may belong to a campus, which may belong to a university. We wanted to build a system that could not only represent these hierarchies but do so in an efficient manner.</p>\n\n<p>As a concrete example, here\u2019s how a middle school mach class might be represented:</p>\n\n<p><img alt=\"Simple Example\" src=\"https://s3.amazonaws.com/engineering.remind.com/transitive_closure/transitive_closure_example_simple.png\" /></p>\n\n<p>In our database, we store these entities as an adjacency list. Note: We store these with UUIDs, but here we\u2019ll use the names to make it easier to follow.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra I</td>\n      <td>Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>Springfield District</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>NULL</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Common query patterns we have require finding all classes in a district, or finding the district a class belongs to.</p>\n\n<p>Naively, we need to traverse through <code class=\"language-plaintext highlighter-rouge\">Maple Middle School</code> to determine that <code class=\"language-plaintext highlighter-rouge\">Algebra 1</code> is a descendent of <code class=\"language-plaintext highlighter-rouge\">Springfield District</code>.</p>\n\n<p>Our goal was to make such queries fast and performant while maintaining accuracy.</p>\n\n<p>There are a few techniques for doing this inside a PostgreSQL database:</p>\n<ol>\n  <li>We can traverse through the adjacency list using <a href=\"https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-RECURSIVE\">Recursive Queries</a>.</li>\n  <li>We can use <a href=\"https://en.wikipedia.org/wiki/Nested_set_model\">Nested Sets</a></li>\n  <li>We can materialize the <a href=\"https://en.wikipedia.org/wiki/Transitive_closure#In_graph_theory\">Transitive Closure</a>.</li>\n</ol>\n\n<p>We started with option 1 but performance wasn\u2019t quite where we wanted it to be. Option 2 was a viable path, but concerns around maintenance and our update pattern (where leaf nodes are frequently added and removed) didn\u2019t seem like the right fit. So we went with Option 3.</p>\n\n<h3 id=\"transitive-closure\">Transitive Closure</h3>\n<p>The transitive closure of a graph tells if one node is reachable from another node. In our <code class=\"language-plaintext highlighter-rouge\">Algebra 1</code> example above, we have 6 edges in the transitive closure:</p>\n\n<p><img alt=\"Example with Closure\" src=\"https://s3.amazonaws.com/engineering.remind.com/transitive_closure/transitive_closure_example_with_closure.png\" /></p>\n\n<p>Note: We include self references here for reasons we\u2019ll explain in a bit.</p>\n\n<h3 id=\"the-edge-organization-ancestor-and-distance\">The Edge: <code class=\"language-plaintext highlighter-rouge\">organization</code>, <code class=\"language-plaintext highlighter-rouge\">ancestor</code>, and <code class=\"language-plaintext highlighter-rouge\">distance</code></h3>\n<p>These are the columns that describe the edges in our graph. Given a class <code class=\"language-plaintext highlighter-rouge\">Algebra 1</code> in a school <code class=\"language-plaintext highlighter-rouge\">Maple Middle School</code> in a district <code class=\"language-plaintext highlighter-rouge\">Springfield District</code>, the edges look like:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>1</td>\n      <td>Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>2</td>\n      <td>Springfield District</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>1</td>\n      <td>Springfield District</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n    </tr>\n  </tbody>\n</table>\n\n<p><code class=\"language-plaintext highlighter-rouge\">organization</code> is the start node, <code class=\"language-plaintext highlighter-rouge\">ancestor</code> is the end node and <code class=\"language-plaintext highlighter-rouge\">distance</code> captures how many other nodes we had to go through to get there.</p>\n\n<p>This is a really great schema for querying. We have organization tables like <code class=\"language-plaintext highlighter-rouge\">organization_memberships</code> and we can perform simple queries like:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>select\n  count(distinct \"user\")\nfrom organizations_closure\njoin organization_memberships using (organization)\nwhere ancestor = 'Springfield District'\n</code></pre></div></div>\n<p>This query will count the number of users enrolled in any class in the <code class=\"language-plaintext highlighter-rouge\">Springfield District</code>. We didn\u2019t have to traverse through the schools, we could just enumerate the user enrollment directly by following the connection from <code class=\"language-plaintext highlighter-rouge\">district -&gt; class</code>.</p>\n\n<h3 id=\"the-proof-through_org-distance_to_through_org\">The Proof: <code class=\"language-plaintext highlighter-rouge\">through_org</code>, <code class=\"language-plaintext highlighter-rouge\">distance_to_through_org</code></h3>\n<p>Something missing from the above data is <em>why</em> an organization is considered an ancestor. Let\u2019s capture those reasons:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>ancestor</th>\n      <th>reason</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra I</td>\n      <td>Algebra I</td>\n      <td>Self</td>\n    </tr>\n    <tr>\n      <td>Algebra I</td>\n      <td>Maple Middle School</td>\n      <td>Parent of Algebra I</td>\n    </tr>\n    <tr>\n      <td>Algebra I</td>\n      <td>Springfield District</td>\n      <td>Parent of Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>Maple Middle School</td>\n      <td>Self</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>Springfield District</td>\n      <td>Parent of Maple Middle School</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>Springfield District</td>\n      <td>Self</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Each <code class=\"language-plaintext highlighter-rouge\">reason</code> is either <code class=\"language-plaintext highlighter-rouge\">Self</code> or <code class=\"language-plaintext highlighter-rouge\">Parent of X</code> where <code class=\"language-plaintext highlighter-rouge\">X</code> is an established ancestor of the organization. In our schema we capture this by recording the <code class=\"language-plaintext highlighter-rouge\">through_org</code> for each edge as well as the distance to the <code class=\"language-plaintext highlighter-rouge\">through_org</code>. For self references these will be <code class=\"language-plaintext highlighter-rouge\">NULL</code>. For any other references they will describe the node that must be travelled through to reach the <code class=\"language-plaintext highlighter-rouge\">ancestor</code>. The resulting data looks like this:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n      <th>through_org</th>\n      <th>distance_to_through_org</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>1</td>\n      <td>Maple Middle School</td>\n      <td>Algebra 1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>1</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>2</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n\n<h4 id=\"constraints\">Constraints</h4>\n\n<p>With our columns in place, we want to ensure this data is correct and that we will not drift from our adjacency list.</p>\n\n<p>Our constraints:</p>\n<ol>\n  <li>A row must either be a self reference or it must have a <code class=\"language-plaintext highlighter-rouge\">through_org</code> .</li>\n  <li>A self reference has a <code class=\"language-plaintext highlighter-rouge\">distance</code> of 0. All other rows must have <code class=\"language-plaintext highlighter-rouge\">distance</code> of <code class=\"language-plaintext highlighter-rouge\">distance_to_through_org + 1</code>.</li>\n  <li>A <code class=\"language-plaintext highlighter-rouge\">through_org</code> must be an ancestor of <code class=\"language-plaintext highlighter-rouge\">organization</code> (which can mean itself) and <code class=\"language-plaintext highlighter-rouge\">distance_to_through_org</code> must match the distance from <code class=\"language-plaintext highlighter-rouge\">organization</code> to <code class=\"language-plaintext highlighter-rouge\">through_org</code>.</li>\n  <li>If there is a <code class=\"language-plaintext highlighter-rouge\">through_org</code>, <code class=\"language-plaintext highlighter-rouge\">ancestor</code> must be a direct parent of the <code class=\"language-plaintext highlighter-rouge\">through_org</code>.</li>\n</ol>\n\n<p>We can enforce these constraints in PostgreSQL:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"nv\">\"organizations_closure_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">through_org</span> <span class=\"k\">IS</span> <span class=\"k\">NOT</span> <span class=\"k\">NULL</span> <span class=\"k\">OR</span> <span class=\"n\">organization</span> <span class=\"o\">=</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n\n    <span class=\"nv\">\"organizations_closure_distance_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">distance</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"k\">OR</span> <span class=\"n\">organization</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_distance_to_through_org_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">distance_to_through_org</span> <span class=\"k\">IS</span> <span class=\"k\">NULL</span> <span class=\"k\">AND</span> <span class=\"n\">distance</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"k\">OR</span> <span class=\"n\">distance_to_through_org</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">distance</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n\n    <span class=\"nv\">\"organizations_closure_through_org_distance_fk\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">distance_to_through_org</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span> <span class=\"n\">distance</span><span class=\"p\">)</span>\n\n    <span class=\"nv\">\"organizations_closure_through_org_fkey\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">parent</span><span class=\"p\">)</span> <span class=\"k\">ON</span> <span class=\"k\">DELETE</span> <span class=\"k\">CASCADE</span>\n</code></pre></div></div>\n\n<p>Finally, we want to ensure referential integrity, so we ensure that <code class=\"language-plaintext highlighter-rouge\">ancestor</code> is an organization that exists:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"nv\">\"organizations_closure_ancestor_fkey\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">)</span> <span class=\"k\">ON</span> <span class=\"k\">DELETE</span> <span class=\"k\">CASCADE</span>\n</code></pre></div></div>\n<p>(It\u2019s not necessary to have a foreign key on <code class=\"language-plaintext highlighter-rouge\">organization</code> as every row has an eventual dependency on a self reference. For self references, <code class=\"language-plaintext highlighter-rouge\">organization = ancestor</code> and so the foreign key on <code class=\"language-plaintext highlighter-rouge\">ancestor</code> gives us what we need. Having the additional key wouldn\u2019t hurt, but it\u2019s not necessary.)</p>\n\n<p>With these constraints in place, we are protected against stale data from intermediate nodes being improperly removed.</p>\n\n<h3 id=\"populating\">Populating</h3>\n\n<p>To populate this table, we can follow a recursive approach:</p>\n<ol>\n  <li>Establish self nodes as ancestors</li>\n  <li>For each ancestor, add its parent as a new ancestor</li>\n  <li>If an ancestor has no parent, do nothing</li>\n</ol>\n\n<p>Returning to our <code class=\"language-plaintext highlighter-rouge\">Algebra 1</code> example, from the above rules we can first establish the self references:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n      <th>through_org</th>\n      <th>distance_to_through_org</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>We can then add immediate parents. Because <code class=\"language-plaintext highlighter-rouge\">organization</code> is its own <code class=\"language-plaintext highlighter-rouge\">ancestor</code> (from the self references), we can use those as <code class=\"language-plaintext highlighter-rouge\">through_org</code> and use their parent as <code class=\"language-plaintext highlighter-rouge\">ancestor</code></p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n      <th>through_org</th>\n      <th>distance_to_through_org</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>1</td>\n      <td>Maple Middle School</td>\n      <td>Algebra 1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>1</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Now that we have parents in our table, we can use those parents to add grandparents</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>organization</th>\n      <th>distance</th>\n      <th>ancestor</th>\n      <th>through_org</th>\n      <th>distance_to_through_org</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Algebra 1</td>\n      <td>0</td>\n      <td>Algebra 1</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>0</td>\n      <td>Maple Middle School</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Springfield District</td>\n      <td>0</td>\n      <td>Springfield District</td>\n      <td>NULL</td>\n      <td>NULL</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>1</td>\n      <td>Maple Middle School</td>\n      <td>Algebra 1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Maple Middle School</td>\n      <td>1</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>Algebra 1</td>\n      <td>2</td>\n      <td>Springfield District</td>\n      <td>Maple Middle School</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>And in this case, because <code class=\"language-plaintext highlighter-rouge\">Springfield District</code> has no parent, we\u2019re done.</p>\n\n<h3 id=\"full-schema\">Full Schema</h3>\n<p>Whenever data is denormalized, the greatest risk is inconsistency. As we traverse more of the graph, a given relation depends on more and more rows. If a great-grandparent moves under another node, all of its children will need to be updated.</p>\n\n<p>Our goal was to find a way to leverage database constraints to ensure correctness.</p>\n\n<p>This is the schema and constraints we landed on:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>                <span class=\"k\">Table</span> <span class=\"nv\">\"remind.organizations_closure\"</span>\n         <span class=\"k\">Column</span>          <span class=\"o\">|</span>  <span class=\"k\">Type</span>   <span class=\"o\">|</span> <span class=\"k\">Collation</span> <span class=\"o\">|</span> <span class=\"k\">Nullable</span> <span class=\"o\">|</span> <span class=\"k\">Default</span>\n<span class=\"c1\">-------------------------+---------+-----------+----------+---------</span>\n <span class=\"n\">organization</span>            <span class=\"o\">|</span> <span class=\"n\">uuid</span>    <span class=\"o\">|</span>           <span class=\"o\">|</span> <span class=\"k\">not</span> <span class=\"k\">null</span> <span class=\"o\">|</span>\n <span class=\"n\">through_org</span>             <span class=\"o\">|</span> <span class=\"n\">uuid</span>    <span class=\"o\">|</span>           <span class=\"o\">|</span>          <span class=\"o\">|</span>\n <span class=\"n\">ancestor</span>                <span class=\"o\">|</span> <span class=\"n\">uuid</span>    <span class=\"o\">|</span>           <span class=\"o\">|</span> <span class=\"k\">not</span> <span class=\"k\">null</span> <span class=\"o\">|</span>\n <span class=\"n\">distance</span>                <span class=\"o\">|</span> <span class=\"nb\">integer</span> <span class=\"o\">|</span>           <span class=\"o\">|</span> <span class=\"k\">not</span> <span class=\"k\">null</span> <span class=\"o\">|</span>\n <span class=\"n\">distance_to_through_org</span> <span class=\"o\">|</span> <span class=\"nb\">integer</span> <span class=\"o\">|</span>           <span class=\"o\">|</span>          <span class=\"o\">|</span>\n\n<span class=\"n\">Indexes</span><span class=\"p\">:</span>\n    <span class=\"nv\">\"organizations_closure_pkey\"</span> <span class=\"k\">PRIMARY</span> <span class=\"k\">KEY</span><span class=\"p\">,</span> <span class=\"n\">btree</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_ancestor_idx\"</span> <span class=\"n\">btree</span> <span class=\"p\">(</span><span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_organization_ancestor_distance_idx\"</span> <span class=\"k\">UNIQUE</span><span class=\"p\">,</span> <span class=\"n\">btree</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span> <span class=\"n\">distance</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_through_org_idx\"</span> <span class=\"n\">btree</span> <span class=\"p\">(</span><span class=\"n\">through_org</span><span class=\"p\">)</span>\n\n<span class=\"k\">Check</span> <span class=\"k\">constraints</span><span class=\"p\">:</span>\n    <span class=\"nv\">\"organizations_closure_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">through_org</span> <span class=\"k\">IS</span> <span class=\"k\">NOT</span> <span class=\"k\">NULL</span> <span class=\"k\">OR</span> <span class=\"n\">organization</span> <span class=\"o\">=</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_distance_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">distance</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"k\">OR</span> <span class=\"n\">organization</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_distance_to_through_org_check\"</span> <span class=\"k\">CHECK</span> <span class=\"p\">(</span><span class=\"n\">distance_to_through_org</span> <span class=\"k\">IS</span> <span class=\"k\">NULL</span> <span class=\"k\">AND</span> <span class=\"n\">distance</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"k\">OR</span> <span class=\"n\">distance_to_through_org</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">distance</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n\n<span class=\"k\">Foreign</span><span class=\"o\">-</span><span class=\"k\">key</span> <span class=\"k\">constraints</span><span class=\"p\">:</span>\n    <span class=\"nv\">\"organizations_closure_ancestor_fkey\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">)</span> <span class=\"k\">ON</span> <span class=\"k\">DELETE</span> <span class=\"k\">CASCADE</span>\n    <span class=\"nv\">\"organizations_closure_through_org_distance_fk\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">distance_to_through_org</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span> <span class=\"n\">distance</span><span class=\"p\">)</span>\n    <span class=\"nv\">\"organizations_closure_through_org_fkey\"</span> <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">parent</span><span class=\"p\">)</span> <span class=\"k\">ON</span> <span class=\"k\">DELETE</span> <span class=\"k\">CASCADE</span>\n</code></pre></div></div>\n\n<h3 id=\"additional-invalid-states\">Additional Invalid States</h3>\n<p>We also want to prevent any invalid states that we couldn\u2019t fully capture in our schema. The primary case we need to prevent is a cycle.</p>\n\n<p>To prevent a cycle, we use the following function as a <code class=\"language-plaintext highlighter-rouge\">before insert</code> trigger:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">CREATE</span> <span class=\"k\">FUNCTION</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_block_cycle</span><span class=\"p\">()</span> <span class=\"k\">RETURNS</span> <span class=\"k\">trigger</span>\n    <span class=\"k\">LANGUAGE</span> <span class=\"n\">plpgsql</span>\n    <span class=\"k\">AS</span> <span class=\"err\">$$</span>\n      <span class=\"k\">begin</span>\n        <span class=\"n\">if</span> <span class=\"k\">exists</span> <span class=\"p\">(</span><span class=\"k\">select</span> <span class=\"k\">from</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span> <span class=\"k\">where</span> <span class=\"n\">ancestor</span> <span class=\"o\">=</span> <span class=\"k\">NEW</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"k\">and</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"o\">=</span> <span class=\"k\">NEW</span><span class=\"p\">.</span><span class=\"n\">parent</span><span class=\"p\">)</span> <span class=\"k\">then</span>\n          <span class=\"n\">raise</span> <span class=\"n\">exception</span> <span class=\"s1\">'Cannot add descendant as parent, would create cycle'</span><span class=\"p\">;</span>\n        <span class=\"k\">else</span>\n          <span class=\"k\">return</span> <span class=\"k\">NEW</span><span class=\"p\">;</span>\n        <span class=\"k\">end</span> <span class=\"n\">if</span><span class=\"p\">;</span>\n      <span class=\"k\">end</span>\n    <span class=\"err\">$$</span><span class=\"p\">;</span>\n</code></pre></div></div>\n\n<h3 id=\"maintenance\">Maintenance</h3>\n<p>Now that we have a schema and constraints that ensure correctness, we need a way to update it easily. While the schema will prevent invalid states, we don\u2019t want to hit these errors. We want the normal range of CRUD operations to propagate changes to these tables and keep them in sync.</p>\n\n<p>We used the following functions in an <code class=\"language-plaintext highlighter-rouge\">after insert</code> trigger:</p>\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">CREATE</span> <span class=\"k\">FUNCTION</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_rematerialize_closure</span><span class=\"p\">(</span><span class=\"n\">uuid</span><span class=\"p\">)</span> <span class=\"k\">RETURNS</span> <span class=\"n\">void</span>\n    <span class=\"k\">LANGUAGE</span> <span class=\"n\">plpgsql</span>\n    <span class=\"k\">AS</span> <span class=\"err\">$</span><span class=\"n\">_</span><span class=\"err\">$</span>\n      <span class=\"k\">begin</span>\n        <span class=\"c1\">-- This could maybe be reworked to recursively build the list of orgs that need to be</span>\n        <span class=\"c1\">-- rematerialized and then materialize them all in one fell swoop.</span>\n        <span class=\"n\">perform</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">materialize_org_ancestors</span><span class=\"p\">(</span><span class=\"err\">$</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n\n        <span class=\"c1\">-- When we update the ancestors of the parent, we need to update all the children</span>\n        <span class=\"c1\">-- so that they reflect the new grandparent, great-grandparent, etc.</span>\n        <span class=\"n\">perform</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_rematerialize_closure</span><span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">)</span> <span class=\"k\">from</span> <span class=\"p\">(</span>\n          <span class=\"k\">select</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span>\n          <span class=\"k\">from</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span>\n          <span class=\"k\">where</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">parent</span> <span class=\"o\">=</span> <span class=\"err\">$</span><span class=\"mi\">1</span>\n        <span class=\"p\">)</span> <span class=\"n\">child_orgs</span><span class=\"p\">;</span>\n      <span class=\"k\">end</span><span class=\"p\">;</span>\n    <span class=\"err\">$</span><span class=\"n\">_</span><span class=\"err\">$</span><span class=\"p\">;</span>\n\n<span class=\"k\">CREATE</span> <span class=\"k\">FUNCTION</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">materialize_org_ancestors</span><span class=\"p\">(</span><span class=\"n\">VARIADIC</span> <span class=\"n\">uuid</span><span class=\"p\">[])</span> <span class=\"k\">RETURNS</span> <span class=\"n\">void</span>\n    <span class=\"k\">LANGUAGE</span> <span class=\"n\">plpgsql</span>\n    <span class=\"k\">AS</span> <span class=\"err\">$</span><span class=\"n\">_</span><span class=\"err\">$</span>\n      <span class=\"k\">begin</span>\n        <span class=\"k\">with</span> <span class=\"k\">recursive</span> <span class=\"n\">closure</span> <span class=\"k\">as</span> <span class=\"p\">(</span>\n          <span class=\"k\">select</span>\n            <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span><span class=\"p\">,</span>\n            <span class=\"k\">null</span><span class=\"p\">::</span><span class=\"n\">uuid</span> <span class=\"k\">as</span> <span class=\"n\">through_org</span><span class=\"p\">,</span>\n            <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"k\">as</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span>\n            <span class=\"mi\">0</span> <span class=\"k\">as</span> <span class=\"n\">distance</span><span class=\"p\">,</span>\n            <span class=\"k\">null</span><span class=\"p\">::</span><span class=\"nb\">integer</span> <span class=\"k\">as</span> <span class=\"n\">distance_to_through_org</span>\n          <span class=\"k\">from</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span>\n          <span class=\"k\">where</span> <span class=\"n\">organization</span> <span class=\"o\">=</span> <span class=\"k\">any</span> <span class=\"p\">(</span><span class=\"err\">$</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n          <span class=\"k\">union</span>\n          <span class=\"k\">select</span>\n            <span class=\"n\">closure</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"k\">as</span> <span class=\"n\">organization</span><span class=\"p\">,</span>\n            <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span> <span class=\"k\">as</span> <span class=\"n\">through_org</span><span class=\"p\">,</span>\n            <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">parent</span> <span class=\"k\">as</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span>\n            <span class=\"n\">closure</span><span class=\"p\">.</span><span class=\"n\">distance</span> <span class=\"o\">+</span> <span class=\"mi\">1</span> <span class=\"k\">as</span> <span class=\"n\">distance</span><span class=\"p\">,</span>\n            <span class=\"n\">closure</span><span class=\"p\">.</span><span class=\"n\">distance</span> <span class=\"k\">as</span> <span class=\"n\">distance_to_through_org</span>\n          <span class=\"k\">from</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations</span>\n          <span class=\"k\">join</span> <span class=\"n\">closure</span> <span class=\"k\">on</span> <span class=\"p\">(</span><span class=\"n\">closure</span><span class=\"p\">.</span><span class=\"n\">ancestor</span> <span class=\"o\">=</span> <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">organization</span><span class=\"p\">)</span>\n          <span class=\"k\">where</span> <span class=\"n\">organizations</span><span class=\"p\">.</span><span class=\"n\">parent</span> <span class=\"k\">is</span> <span class=\"k\">not</span> <span class=\"k\">null</span>\n        <span class=\"p\">)</span>\n        <span class=\"k\">insert</span> <span class=\"k\">into</span> <span class=\"n\">remind</span><span class=\"p\">.</span><span class=\"n\">organizations_closure</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">through_org</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">,</span> <span class=\"n\">distance</span><span class=\"p\">,</span> <span class=\"n\">distance_to_through_org</span><span class=\"p\">)</span>\n        <span class=\"k\">select</span> <span class=\"o\">*</span> <span class=\"k\">from</span> <span class=\"n\">closure</span>\n        <span class=\"k\">on</span> <span class=\"n\">conflict</span> <span class=\"p\">(</span><span class=\"n\">organization</span><span class=\"p\">,</span> <span class=\"n\">ancestor</span><span class=\"p\">)</span> <span class=\"k\">do</span> <span class=\"k\">nothing</span><span class=\"p\">;</span>\n      <span class=\"k\">end</span>\n      <span class=\"err\">$</span><span class=\"n\">_</span><span class=\"err\">$</span><span class=\"p\">;</span>\n</code></pre></div></div>\n<p>Essentially, we rematerialize all ancestors for a given org and then iterate through its children and rematerialize their ancestors (and continue until we\u2019ve reached all leaf nodes). This is a recursive process and it is why preventing cycles is essential.</p>\n\n<p>When rematerializing ancestors, we use a recursive CTE. On each iteration we track <code class=\"language-plaintext highlighter-rouge\">through_org</code> and <code class=\"language-plaintext highlighter-rouge\">distance_to_through_org</code>.</p>\n\n<p>For deletes and updates we rely on our foreign keys <code class=\"language-plaintext highlighter-rouge\">on delete casade</code> as well as a before update trigger to clean up rows that are no longer relevant.</p>\n\n<h3 id=\"testing-strategy\">Testing Strategy</h3>\n<p>This is a lot of complexity. While we are confident the data in the table will be accurate, we were (rightfully) very concerned about application errors when a constraint blocks us from making a change. We decided that robust testing was essential to having confidence operationally.</p>\n\n<p>When we started this, we had been separately exploring a style of testing called <a href=\"https://proptest-rs.github.io/proptest/intro.html\">property testing</a> in a couple of different contexts. The core idea is that if you can create a simple model that captures your behavior, you can generate broad and nearly exhaustive test cases for a more complex implementation. In our case, the model is fairly straightforward (it\u2019s just a tree structure) and the materialization is fairly complex. It has worked very well for us.</p>\n\n<p>Our property tests (using the <code class=\"language-plaintext highlighter-rouge\">proptest</code> crate) build an organization forest (or a collection of organization trees) in memory. We then sync this structure into the database and assert the following for each organization:</p>\n<ol>\n  <li>An <code class=\"language-plaintext highlighter-rouge\">organizations_closure</code> row exists for the organization and each of its ancestors with the correct distance values. No other ancestors should exist.</li>\n  <li>An <code class=\"language-plaintext highlighter-rouge\">organizations_closure</code> row exists for each of its descendants with the correct ancestor and with the correct distance values. No other descendants should exist.</li>\n</ol>\n\n<p>Then we mutate the tree with arbitrary actions. For each action we perform the mutation on our simple model as well as in the database.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Action</th>\n      <th>Simple Model</th>\n      <th>Complex Model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Nothing</td>\n      <td>Nothing</td>\n      <td>Nothing</td>\n    </tr>\n    <tr>\n      <td>Detach</td>\n      <td>Remove from children, add to tree list</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = null where organization = ?</code></td>\n    </tr>\n    <tr>\n      <td>Update (1 step)</td>\n      <td>Remove from old parent, add to new parent</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = ? where organization = ?</code></td>\n    </tr>\n    <tr>\n      <td>Update (2 step)</td>\n      <td>Remove from old parent, add to new parent</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = null where organization = ?</code> followed by <code class=\"language-plaintext highlighter-rouge\">update organizations set parent = ? where organization = ?</code></td>\n    </tr>\n    <tr>\n      <td>Delete (roll up children)</td>\n      <td>Move children to grand parent, remove organization</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = ? where parent = ?</code> followed by <code class=\"language-plaintext highlighter-rouge\">delete from organizations where organization = ?</code></td>\n    </tr>\n    <tr>\n      <td>Delete (detach children)</td>\n      <td>Add children to tree list, remove organization</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">update organizations set parent = null where parent = ?</code> followed by <code class=\"language-plaintext highlighter-rouge\">delete from organizations where organization = ?</code></td>\n    </tr>\n  </tbody>\n</table>\n\n<p>In addition to these, we have a handful of other cases more specific to our product.</p>\n\n<p>We then assert the same properties as before.</p>\n\n<p>This testing strategy has been great. The <code class=\"language-plaintext highlighter-rouge\">proptest</code> crate captures the generated tests that fail and includes them in all future runs as a regression suite. While developing we ran with 10k cases, but in our CI suite we now run with \u201cjust\u201d the default of 256 cases. The thoroughness of the testing approach has made adding additional actions (for example, \u201cArchiving\u201d an organization) easy to implement and has given us very high confidence as we roll new features out.</p>\n\n<h3 id=\"rolling-it-out\">Rolling it out</h3>\n<p>We rely heavily on AWS Aurora with PostgreSQL. One of the great features available with Aurora are clones. In about 15 minutes, a Copy-on-Write clone can be spun up and be used for testing. With our full production dataset in a clone, we created the table and constraints and started populating it. It was no surprise that we had some cycles in our data set (a decade of organic data at scale means nothing is a surprise), but otherwise everything went smoothly.  We worked with our support team to clean up the cycles, added the tables to prod, and backfilled the data. Everything ran smoothly and we\u2019ve been using this table ever since.</p>\n\n<h2 id=\"closing\">Closing</h2>\n<p>We use this to power a product that serves millions and millions of parents, students, teachers and administrators every day. It\u2019s improved performance, reduced load, and accelerated our team\u2019s ability to deliver value to our customers. A special thanks to all the team members at Remind who worked on this from conceptualization to running it in prod. Especially Phil Frost, who held the vision and set us on this path.</p>"
    },
    "published": "Fri, 29 Sep 2023 00:00:00 +0000",
    "published_parsed": [
      2023,
      9,
      29,
      0,
      0,
      0,
      4,
      272,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "http://engineering.remind.com/Transitive-Closure-In-PostgreSQL/"
      }
    ],
    "link": "http://engineering.remind.com/Transitive-Closure-In-PostgreSQL/",
    "id": "http://engineering.remind.com/Transitive-Closure-In-PostgreSQL/",
    "guidislink": false
  },
  "REA Group": {
    "title": "One year at REA: Lessons, Growth, and Gratitude",
    "xmlUrl": "https://www.rea-group.com/category/tech/feed/",
    "htmlUrl": "https://www.rea-group.com/category/tech/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.rea-group.com/category/tech/feed/",
      "value": "One year at REA: Lessons, Growth, and Gratitude"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.rea-group.com/about-us/news-and-insights/blog/1-year-at-my-first-adult-job-lessons-growth-and-gratitude-at-rea/"
      }
    ],
    "link": "https://www.rea-group.com/about-us/news-and-insights/blog/1-year-at-my-first-adult-job-lessons-growth-and-gratitude-at-rea/",
    "authors": [
      {
        "name": "Anmol Kaur"
      }
    ],
    "author": "Anmol Kaur",
    "author_detail": {
      "name": "Anmol Kaur"
    },
    "published": "Mon, 11 Sep 2023 02:08:08 +0000",
    "published_parsed": [
      2023,
      9,
      11,
      2,
      8,
      8,
      0,
      254,
      0
    ],
    "tags": [
      {
        "term": "Life at REA",
        "scheme": null,
        "label": null
      },
      {
        "term": "Tech",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://www.rea-group.com/?post_type=blog&p=56729",
    "guidislink": false,
    "summary": "",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.rea-group.com/category/tech/feed/",
      "value": ""
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.rea-group.com/category/tech/feed/",
        "value": ""
      }
    ]
  },
  "Upday": {
    "title": "We've moved",
    "xmlUrl": "https://upday.github.io/feed.xml",
    "htmlUrl": "https://upday.github.io/",
    "title_detail": {
      "type": "text/html",
      "language": "en",
      "base": "https://upday.github.io/feed.xml",
      "value": "We've moved"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://upday.github.io/blog/we_are_moved/"
      }
    ],
    "link": "https://upday.github.io/blog/we_are_moved/",
    "id": "https://upday.github.io/blog/we_are_moved",
    "guidislink": false,
    "published": "2017-09-20T08:00:00+00:00",
    "published_parsed": [
      2017,
      9,
      20,
      8,
      0,
      0,
      2,
      263,
      0
    ],
    "updated": "2017-09-20T08:00:00+00:00",
    "updated_parsed": [
      2017,
      9,
      20,
      8,
      0,
      0,
      2,
      263,
      0
    ],
    "authors": [
      {
        "name": "Peter Krau\u00df",
        "href": "https://upday.github.io",
        "email": "peter.krauss@upday.com"
      }
    ],
    "author_detail": {
      "name": "Peter Krau\u00df",
      "href": "https://upday.github.io",
      "email": "peter.krauss@upday.com"
    },
    "href": "https://upday.github.io",
    "author": "Peter Krau\u00df (peter.krauss@upday.com)",
    "content": [
      {
        "type": "text/html",
        "language": "en",
        "base": "https://upday.github.io/feed.xml",
        "value": "<h3 id=\"weve-moved-to-medium\">We\u2019ve moved to medium!!!!</h3>\n\n<p>Basically the headline says it - we decided to move our blog over to <a href=\"https://medium.com/upday-devs\">medium.com</a>.\nFollow us there!!!</p>\n\n    <p><a href=\"https://upday.github.io/blog/we_are_moved/\">We've moved</a> was originally published by upday dev at <a href=\"https://upday.github.io\">upday tech blog - now at medium</a> on September 20, 2017.</p>"
      }
    ],
    "summary": "<h3 id=\"weve-moved-to-medium\">We\u2019ve moved to medium!!!!</h3>\n\n<p>Basically the headline says it - we decided to move our blog over to <a href=\"https://medium.com/upday-devs\">medium.com</a>.\nFollow us there!!!</p>\n\n    <p><a href=\"https://upday.github.io/blog/we_are_moved/\">We've moved</a> was originally published by upday dev at <a href=\"https://upday.github.io\">upday tech blog - now at medium</a> on September 20, 2017.</p>"
  },
  "OLX": {
    "title": "Live Coding Interviews in the Era of LLMs",
    "xmlUrl": "https://tech.olx.com/feed",
    "htmlUrl": "https://tech.olx.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://tech.olx.com/feed",
      "value": "Live Coding Interviews in the Era of LLMs"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://tech.olx.com/live-coding-interviews-in-the-era-of-llms-4e09553bb117?source=rss----761b019b483f---4"
      }
    ],
    "link": "https://tech.olx.com/live-coding-interviews-in-the-era-of-llms-4e09553bb117?source=rss----761b019b483f---4",
    "id": "https://medium.com/p/4e09553bb117",
    "guidislink": false,
    "tags": [
      {
        "term": "interview",
        "scheme": null,
        "label": null
      },
      {
        "term": "llm",
        "scheme": null,
        "label": null
      },
      {
        "term": "ai",
        "scheme": null,
        "label": null
      },
      {
        "term": "software-engineering",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "JB Lorenzo"
      }
    ],
    "author": "JB Lorenzo",
    "author_detail": {
      "name": "JB Lorenzo"
    },
    "published": "Wed, 18 Oct 2023 11:22:54 GMT",
    "published_parsed": [
      2023,
      10,
      18,
      11,
      22,
      54,
      2,
      291,
      0
    ],
    "updated": "2023-10-26T14:38:43.490Z",
    "updated_parsed": [
      2023,
      10,
      26,
      14,
      38,
      43,
      3,
      299,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://tech.olx.com/feed",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FcHc33-5Mg3PjxFoxtOtsw.png\" /><figcaption>Image generated by using the title of this\u00a0article</figcaption></figure><p>The introduction of ChatGPT, Copilot, Codex, and other tools makes it easier to code but also makes it easier to answer live coding interviews unless we do something about\u00a0it.</p><p><em>Disclaimer:</em> In this article, we will be exploring what happens if we don\u2019t act on this, what can be done to adjust to the new normal, and what is the view of the future in tech interviews. <strong>Currently, we are not trying to suggest any changes to the interview process because we have not proven anything meaningful yet.</strong> This article is about <strong>reflecting</strong> <strong>on the</strong> <strong>implications of action and inaction </strong>towards the live coding interview process with regards to allowing using LLMs during\u00a0it.</p><h4>Context</h4><p>In OLX, we promote the use of a tool called <a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7110901049833439234?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7110901049833439234%29\">PlusOne</a>, which is an internal LLM tool made to help us code, coach ourselves, and more. This reveals an interesting gap, which\u00a0is</p><blockquote>If OLX promotes the use of a tool once you are hired, why when hiring are we not evaluating people based on using these tools effectively?</blockquote><p>The impact of not addressing this is that people who can\u2019t adapt to the use of these tools will surely lag behind other engineers, and their performance will suffer. We will only be able to notice this after a few months, and it is better to notice that as early as possible.</p><p><em>For those who are not aware: ChatGPT is a Large Language Model able to generate code if you give it a problem statement and the platform+language it should use. Copilot is a tool from Github that can autocomplete large amounts of code, e.g. writing unit tests. Codex is a similar LLM tool from Microsoft.</em></p><p>A few weeks ago, we saw two interview candidates using Copilot/Codex during a live coding interview. While we talked about the possibility of that happening during our interviewer's sync, we were not really prepared to evaluate candidates if they use those, compared to candidates who don\u2019t use them. Because of this, I was interested to know the latest on\u00a0the:</p><ul><li>Allowing the usage of Copilot/LLMs during live coding interviews</li><li>In case of allowing it, evaluating candidates that use them during the interview</li><li>In the case of not allowing it, evaluating if they know how to use these\u00a0tools</li></ul><p>In this article, we will be exploring what happens if we don\u2019t act on this, what can be done to adjust to the new normal, and what is the view of the future in tech interviews.</p><h4>Related Work</h4><p>Several other articles discussed this topic. This <a href=\"https://blog.expertlead.com/how-ai-driven-chatbots-like-chatgpt-are-affecting-the-way-of-doing-tech-assessments\">article</a> talks about the critical thinking and creativity skills that cannot be taken away by the AI tools that are provided.</p><p>In <a href=\"https://www.linkedin.com/pulse/dawn-ai-coding-rethinking-engineering-interview-vidal-graupera/\">another</a> article, Vidal talks about how soft skills become more important in the light of these tools that help with generating code.</p><p>A <a href=\"https://www.google.com/search?q=pair+programming+with+llm&amp;rlz=1CDGOYI_enDE996DE996&amp;oq=pair+programming+with+llm&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg8MgcIAhAAGKIE0gEIMzU0OWowajSoAgCwAgA&amp;hl=en-GB&amp;sourceid=chrome-mobile&amp;ie=UTF-8\">course</a> on how to pair program with a LLM was published in collaboration with Google. This shows some basics of how to use a LLM while writing\u00a0code.</p><p>A <a href=\"https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai\">McKinsey study</a> shows that developers are more productive using generative AI, but it depends on the complexity of the\u00a0task.</p><h4><strong>Problem</strong></h4><p>Not addressing what to do on this topic will lead to a couple of scenarios</p><ol><li>Candidates will not be able to show their full potential during interviews when we don\u2019t allow them to use the Copilot that they are used\u00a0to.</li><li>We will get candidates who we are not sure if they can\u2019t learn to work with these\u00a0tools.</li><li>We get less time evaluating their critical thinking skills due to setting up code, downloading dependencies, or a slow machine, and so\u00a0on.</li><li>We will not be able to find candidates who work very well with these\u00a0tools.</li></ol><p>These all impact the quality of hires by decreasing success rates for people who cannot use LLM\u00a0tools.</p><p>In the case of not allowing these tools. We are going to be falling back into the age of interviews before these tools existed. People rely on their own problem-solving skills, and the amount of output they generate during live coding interviews is limited by their machine\u2019s speed in compilation and their ability to debug\u00a0quickly.</p><p>In case we allow the copilot tools, there would be less effort in generating the initial code to allow developers to start quickly. There are multiple cases that could happen based on how good the Copilot/LLM tools they use are, in decreasing order of help from the Copilot/LLM:</p><ol><li>They don\u2019t have access to these tools. In this case, we fall back to classical interviewing.</li><li>The Copilot generates the whole solution for them, with no need to edit/debug, and it already covers the edge cases we would be throwing at them. We would only be able to evaluate their prompt engineering skills.</li><li>The Copilot generates code that works for the normal cases and is missing edge cases. We would be able to evaluate their prompt engineering skills, their code review skills, their ability to identify edge cases, and their ability to adapt the\u00a0code.</li><li>The Copilot generates a barely working code that doesn\u2019t meet the requirements. They would have to correct the LLM to guide it to a working solution like the case above. Or they would have to break down the problem so that the tool can help them with some parts of\u00a0it.</li></ol><p>These cases reveal some of the (new) key concepts that we need to pay attention to when evaluating candidates.</p><h4><strong>Key concepts</strong></h4><p>Please take the following with the grain of salt, since this is just based on self-reflection:</p><p>While trying to shifting technical coding interview from pure code generation to prompt engineering plus code review plus refactoring (of course, also debugging and testing). Some of the following key concepts might\u00a0appear:</p><ul><li><strong>Prompt Engineering</strong>\u200a\u2014\u200ae.g. they would write the problem in a form that LLM understands.</li><li><strong>Code Review</strong>\u200a\u2014\u200ae.g. to find edge cases and see if the code works as intended.</li><li><strong>Refactoring</strong>\u200a\u2014\u200ae.g. changing the architecture of the generated code</li><li><strong>Debugging</strong>\u200a\u2014\u200ae.g. if the generated code doesn\u2019t\u00a0work</li><li><strong>Testing</strong>\u200a\u2014\u200ae.g. to confirm that the generated code works in various\u00a0cases</li></ul><p>In order to assess the seniority of the person using these key concepts, we also have to benchmark what a junior vs mid vs senior interviewee would look like. For example, a Senior Engineer would be able to identify more edge cases or would be able to explain the engineering choices that the tool made and maybe explain what happens to these decisions if the assumptions change.</p><h4><strong>View of the\u00a0Future</strong></h4><p>Live Coding interviews are a way to test how someone would perform in a real-life situation in a short amount of time using a controlled environment. Some tradeoffs in this process are the amount of time and the accuracy and granularity of evaluation that we are able to make during this\u00a0process.</p><p>I was inspired by a <a href=\"https://www.offerzen.com/events/offerzen-events/untold-stories-in-tech-hiring/do-more-with-less-futureproof-technical-assessments-with-ai\">talk</a> I heard before that mentions that, ideally, we would also include working together with the team to evaluate a real-life situation where people are working together.</p><p>Ideally, the interview process would involve people from the team and a Copilot-like tool, which mirrors how a normal working day looks like. The problem with this approach is that it uses a lot of time from the interviewers. In the current view of things, we already have this problem of Engineers spending a lot of time on interviews, which is mitigated by limiting the time per week that is allocated to this. We also treat interviewing as part of Senior Engineer responsibilities.</p><h4><strong>Conclusion</strong></h4><p>While using LLMs won\u2019t replace our technical skills, it will definitely add to our suite of second-brain tools like Google Search, StackOverflow, or our own\u00a0notes.</p><p>In my opinion, there will still be some time until companies adapt to allowing these tools or being able to evaluate people who use these AI tools during live coding interviews. The call to action is for us to start talking about how to evaluate them. Otherwise, we wont know if the people we are hiring can adapt with working with these tools and they will be <a href=\"https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai\">left\u00a0behind</a>.</p><p>We will be diving deeper into this topic in another article, e.g. what we have tried, what the results are, and our recommendations.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4e09553bb117\" width=\"1\" /><hr /><p><a href=\"https://tech.olx.com/live-coding-interviews-in-the-era-of-llms-4e09553bb117\">Live Coding Interviews in the Era of LLMs</a> was originally published in <a href=\"https://tech.olx.com\">OLX Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FcHc33-5Mg3PjxFoxtOtsw.png\" /><figcaption>Image generated by using the title of this\u00a0article</figcaption></figure><p>The introduction of ChatGPT, Copilot, Codex, and other tools makes it easier to code but also makes it easier to answer live coding interviews unless we do something about\u00a0it.</p><p><em>Disclaimer:</em> In this article, we will be exploring what happens if we don\u2019t act on this, what can be done to adjust to the new normal, and what is the view of the future in tech interviews. <strong>Currently, we are not trying to suggest any changes to the interview process because we have not proven anything meaningful yet.</strong> This article is about <strong>reflecting</strong> <strong>on the</strong> <strong>implications of action and inaction </strong>towards the live coding interview process with regards to allowing using LLMs during\u00a0it.</p><h4>Context</h4><p>In OLX, we promote the use of a tool called <a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7110901049833439234?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7110901049833439234%29\">PlusOne</a>, which is an internal LLM tool made to help us code, coach ourselves, and more. This reveals an interesting gap, which\u00a0is</p><blockquote>If OLX promotes the use of a tool once you are hired, why when hiring are we not evaluating people based on using these tools effectively?</blockquote><p>The impact of not addressing this is that people who can\u2019t adapt to the use of these tools will surely lag behind other engineers, and their performance will suffer. We will only be able to notice this after a few months, and it is better to notice that as early as possible.</p><p><em>For those who are not aware: ChatGPT is a Large Language Model able to generate code if you give it a problem statement and the platform+language it should use. Copilot is a tool from Github that can autocomplete large amounts of code, e.g. writing unit tests. Codex is a similar LLM tool from Microsoft.</em></p><p>A few weeks ago, we saw two interview candidates using Copilot/Codex during a live coding interview. While we talked about the possibility of that happening during our interviewer's sync, we were not really prepared to evaluate candidates if they use those, compared to candidates who don\u2019t use them. Because of this, I was interested to know the latest on\u00a0the:</p><ul><li>Allowing the usage of Copilot/LLMs during live coding interviews</li><li>In case of allowing it, evaluating candidates that use them during the interview</li><li>In the case of not allowing it, evaluating if they know how to use these\u00a0tools</li></ul><p>In this article, we will be exploring what happens if we don\u2019t act on this, what can be done to adjust to the new normal, and what is the view of the future in tech interviews.</p><h4>Related Work</h4><p>Several other articles discussed this topic. This <a href=\"https://blog.expertlead.com/how-ai-driven-chatbots-like-chatgpt-are-affecting-the-way-of-doing-tech-assessments\">article</a> talks about the critical thinking and creativity skills that cannot be taken away by the AI tools that are provided.</p><p>In <a href=\"https://www.linkedin.com/pulse/dawn-ai-coding-rethinking-engineering-interview-vidal-graupera/\">another</a> article, Vidal talks about how soft skills become more important in the light of these tools that help with generating code.</p><p>A <a href=\"https://www.google.com/search?q=pair+programming+with+llm&amp;rlz=1CDGOYI_enDE996DE996&amp;oq=pair+programming+with+llm&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg8MgcIAhAAGKIE0gEIMzU0OWowajSoAgCwAgA&amp;hl=en-GB&amp;sourceid=chrome-mobile&amp;ie=UTF-8\">course</a> on how to pair program with a LLM was published in collaboration with Google. This shows some basics of how to use a LLM while writing\u00a0code.</p><p>A <a href=\"https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai\">McKinsey study</a> shows that developers are more productive using generative AI, but it depends on the complexity of the\u00a0task.</p><h4><strong>Problem</strong></h4><p>Not addressing what to do on this topic will lead to a couple of scenarios</p><ol><li>Candidates will not be able to show their full potential during interviews when we don\u2019t allow them to use the Copilot that they are used\u00a0to.</li><li>We will get candidates who we are not sure if they can\u2019t learn to work with these\u00a0tools.</li><li>We get less time evaluating their critical thinking skills due to setting up code, downloading dependencies, or a slow machine, and so\u00a0on.</li><li>We will not be able to find candidates who work very well with these\u00a0tools.</li></ol><p>These all impact the quality of hires by decreasing success rates for people who cannot use LLM\u00a0tools.</p><p>In the case of not allowing these tools. We are going to be falling back into the age of interviews before these tools existed. People rely on their own problem-solving skills, and the amount of output they generate during live coding interviews is limited by their machine\u2019s speed in compilation and their ability to debug\u00a0quickly.</p><p>In case we allow the copilot tools, there would be less effort in generating the initial code to allow developers to start quickly. There are multiple cases that could happen based on how good the Copilot/LLM tools they use are, in decreasing order of help from the Copilot/LLM:</p><ol><li>They don\u2019t have access to these tools. In this case, we fall back to classical interviewing.</li><li>The Copilot generates the whole solution for them, with no need to edit/debug, and it already covers the edge cases we would be throwing at them. We would only be able to evaluate their prompt engineering skills.</li><li>The Copilot generates code that works for the normal cases and is missing edge cases. We would be able to evaluate their prompt engineering skills, their code review skills, their ability to identify edge cases, and their ability to adapt the\u00a0code.</li><li>The Copilot generates a barely working code that doesn\u2019t meet the requirements. They would have to correct the LLM to guide it to a working solution like the case above. Or they would have to break down the problem so that the tool can help them with some parts of\u00a0it.</li></ol><p>These cases reveal some of the (new) key concepts that we need to pay attention to when evaluating candidates.</p><h4><strong>Key concepts</strong></h4><p>Please take the following with the grain of salt, since this is just based on self-reflection:</p><p>While trying to shifting technical coding interview from pure code generation to prompt engineering plus code review plus refactoring (of course, also debugging and testing). Some of the following key concepts might\u00a0appear:</p><ul><li><strong>Prompt Engineering</strong>\u200a\u2014\u200ae.g. they would write the problem in a form that LLM understands.</li><li><strong>Code Review</strong>\u200a\u2014\u200ae.g. to find edge cases and see if the code works as intended.</li><li><strong>Refactoring</strong>\u200a\u2014\u200ae.g. changing the architecture of the generated code</li><li><strong>Debugging</strong>\u200a\u2014\u200ae.g. if the generated code doesn\u2019t\u00a0work</li><li><strong>Testing</strong>\u200a\u2014\u200ae.g. to confirm that the generated code works in various\u00a0cases</li></ul><p>In order to assess the seniority of the person using these key concepts, we also have to benchmark what a junior vs mid vs senior interviewee would look like. For example, a Senior Engineer would be able to identify more edge cases or would be able to explain the engineering choices that the tool made and maybe explain what happens to these decisions if the assumptions change.</p><h4><strong>View of the\u00a0Future</strong></h4><p>Live Coding interviews are a way to test how someone would perform in a real-life situation in a short amount of time using a controlled environment. Some tradeoffs in this process are the amount of time and the accuracy and granularity of evaluation that we are able to make during this\u00a0process.</p><p>I was inspired by a <a href=\"https://www.offerzen.com/events/offerzen-events/untold-stories-in-tech-hiring/do-more-with-less-futureproof-technical-assessments-with-ai\">talk</a> I heard before that mentions that, ideally, we would also include working together with the team to evaluate a real-life situation where people are working together.</p><p>Ideally, the interview process would involve people from the team and a Copilot-like tool, which mirrors how a normal working day looks like. The problem with this approach is that it uses a lot of time from the interviewers. In the current view of things, we already have this problem of Engineers spending a lot of time on interviews, which is mitigated by limiting the time per week that is allocated to this. We also treat interviewing as part of Senior Engineer responsibilities.</p><h4><strong>Conclusion</strong></h4><p>While using LLMs won\u2019t replace our technical skills, it will definitely add to our suite of second-brain tools like Google Search, StackOverflow, or our own\u00a0notes.</p><p>In my opinion, there will still be some time until companies adapt to allowing these tools or being able to evaluate people who use these AI tools during live coding interviews. The call to action is for us to start talking about how to evaluate them. Otherwise, we wont know if the people we are hiring can adapt with working with these tools and they will be <a href=\"https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai\">left\u00a0behind</a>.</p><p>We will be diving deeper into this topic in another article, e.g. what we have tried, what the results are, and our recommendations.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4e09553bb117\" width=\"1\" /><hr /><p><a href=\"https://tech.olx.com/live-coding-interviews-in-the-era-of-llms-4e09553bb117\">Live Coding Interviews in the Era of LLMs</a> was originally published in <a href=\"https://tech.olx.com\">OLX Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "RapidAPI": {
    "title": "Enhanced Functionality and Improved User Experience with the Rapid API Enterprise Hub November 2023 Release",
    "xmlUrl": "https://blog.rapidapi.com/feed/",
    "htmlUrl": "http://blog.rapidapi.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://rapidapi.com/blog/feed/",
      "value": "Enhanced Functionality and Improved User Experience with the Rapid API Enterprise Hub November 2023 Release"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://rapidapi.com/blog/enhanced-functionality-and-improved-user-experience-with-the-rapid-api-enterprise-hub-november-2023-release/"
      }
    ],
    "link": "https://rapidapi.com/blog/enhanced-functionality-and-improved-user-experience-with-the-rapid-api-enterprise-hub-november-2023-release/",
    "comments": "https://rapidapi.com/blog/enhanced-functionality-and-improved-user-experience-with-the-rapid-api-enterprise-hub-november-2023-release/#respond",
    "authors": [
      {
        "name": "James De Luca"
      }
    ],
    "author": "James De Luca",
    "author_detail": {
      "name": "James De Luca"
    },
    "published": "Fri, 01 Dec 2023 20:25:58 +0000",
    "published_parsed": [
      2023,
      12,
      1,
      20,
      25,
      58,
      4,
      335,
      0
    ],
    "tags": [
      {
        "term": "API Management",
        "scheme": null,
        "label": null
      },
      {
        "term": "APIs",
        "scheme": null,
        "label": null
      },
      {
        "term": "Enterprise",
        "scheme": null,
        "label": null
      },
      {
        "term": "api governance",
        "scheme": null,
        "label": null
      },
      {
        "term": "api management",
        "scheme": null,
        "label": null
      },
      {
        "term": "dashboard",
        "scheme": null,
        "label": null
      },
      {
        "term": "RapidAPI",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://rapidapi.com/blog/?p=8680",
    "guidislink": false,
    "summary": "<p><img alt=\"Enhanced Functionality and Improved User Experience with the Rapid API Enterprise Hub November 2023 Release\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"687\" src=\"https://rapidapi.com/blog/wp-content/uploads/2023/12/Screenshot-2023-12-01-at-3.09.19\u202fPM.png\" width=\"1236\" /></p>\n<p>Rapid API is committed to providing its users with the best possible experience, and the November 2023 release of the Enterprise Hub is a testament to this commitment. This release introduces new and improved features to enhance functionality, streamline user workflows, and provide deeper insights into API usage and performance. For more information, go to [&#8230;]</p>\n<p>The post <a href=\"https://rapidapi.com/blog/enhanced-functionality-and-improved-user-experience-with-the-rapid-api-enterprise-hub-november-2023-release/\" rel=\"nofollow\">Enhanced Functionality and Improved User Experience with the Rapid API Enterprise Hub November 2023 Release</a> appeared first on <a href=\"https://rapidapi.com/blog\" rel=\"nofollow\">Rapid Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://rapidapi.com/blog/feed/",
      "value": "<p><img alt=\"Enhanced Functionality and Improved User Experience with the Rapid API Enterprise Hub November 2023 Release\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"687\" src=\"https://rapidapi.com/blog/wp-content/uploads/2023/12/Screenshot-2023-12-01-at-3.09.19\u202fPM.png\" width=\"1236\" /></p>\n<p>Rapid API is committed to providing its users with the best possible experience, and the November 2023 release of the Enterprise Hub is a testament to this commitment. This release introduces new and improved features to enhance functionality, streamline user workflows, and provide deeper insights into API usage and performance. For more information, go to [&#8230;]</p>\n<p>The post <a href=\"https://rapidapi.com/blog/enhanced-functionality-and-improved-user-experience-with-the-rapid-api-enterprise-hub-november-2023-release/\" rel=\"nofollow\">Enhanced Functionality and Improved User Experience with the Rapid API Enterprise Hub November 2023 Release</a> appeared first on <a href=\"https://rapidapi.com/blog\" rel=\"nofollow\">Rapid Blog</a>.</p>"
    },
    "wfw_commentrss": "https://rapidapi.com/blog/enhanced-functionality-and-improved-user-experience-with-the-rapid-api-enterprise-hub-november-2023-release/feed/",
    "slash_comments": "0"
  },
  "Heroku": {
    "title": "How to Use pgvector for Similarity Search on Heroku Postgres",
    "xmlUrl": "https://blog.heroku.com/engineering/feed",
    "htmlUrl": "https://blog.heroku.com/engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.heroku.com/engineering/feed",
      "value": "How to Use pgvector for Similarity Search on Heroku Postgres"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.heroku.com/pgvector-for-similarity-search-on-heroku-postgres"
      }
    ],
    "link": "https://blog.heroku.com/pgvector-for-similarity-search-on-heroku-postgres",
    "published": "Wed, 15 Nov 2023 18:42:51 GMT",
    "published_parsed": [
      2023,
      11,
      15,
      18,
      42,
      51,
      2,
      319,
      0
    ],
    "id": "https://blog.heroku.com/pgvector-for-similarity-search-on-heroku-postgres",
    "guidislink": false,
    "summary": "<h2 class=\"anchored\">\n  <a href=\"https://blog.heroku.com/engineering/feed#introducing-pgvector-for-heroku-postgres\" name=\"introducing-pgvector-for-heroku-postgres\">Introducing pgvector for Heroku Postgres</a>\n</h2>\n\n<p>Over the past few weeks, we worked on adding <a href=\"https://github.com/pgvector/pgvector\">pgvector</a> as an extension on Heroku Postgres. We're excited to release this feature, and based on the feedback on <a href=\"https://github.com/heroku/roadmap/issues/156\">our public roadmap</a>, many of you are too. We want to share a bit more about how you can use it and how it may be helpful to you. </p>\n\n<p>All <a href=\"https://devcenter.heroku.com/articles/heroku-postgres-plans#plan-tiers\">Standard-tier or higher</a> databases running Postgres 15 now support the <a href=\"https://devcenter.heroku.com/articles/heroku-postgres-extensions-postgis-full-text-search#pgvector\"><code>pgvector</code> extension</a>. You can get started by running <code>CREATE EXTENSION vector;</code> in a client session. Postgres 15 has been the default version on Heroku Postgres since March 2023.  If you're on an older version and want to use pgvector, <a href=\"https://devcenter.heroku.com/articles/upgrading-heroku-postgres-databases\">upgrade</a> to Postgres 15.</p>\n\n<p>The extension adds the vector data type to Heroku Postgres along with additional functions to work with it. Vectors are important for working with large language models and other machine learning applications, as the <a href=\"https://huggingface.co/blog/getting-started-with-embeddings#understanding-embeddings\">embeddings</a> generated by these models are often output in vector format. Working with vectors lets you implement things like similarity search across these embeddings. See our <a href=\"https://blog.heroku.com/pgvector-launch#understanding-pgvector-and-its-significance\">launch blog</a> for more background into what pgvector is, its significance, and ideas for how to use this new data type.</p>\n<h2 class=\"anchored\">\n  <a href=\"https://blog.heroku.com/engineering/feed#an-example-word-vector-similarity-search\" name=\"an-example-word-vector-similarity-search\">An Example: Word Vector Similarity Search</a>\n</h2>\n\n<p>To show a simple example of how to generate and save vector data to your Heroku database, I'm using the <a href=\"https://wikipedia2vec.github.io/wikipedia2vec/\">Wikipedia2Vec</a> pretrained embeddings. However, you can train your own embeddings or use other models providing embeddings via API, like <a href=\"https://huggingface.co/blog/getting-started-with-embeddings\">HuggingFace</a> or <a href=\"https://openai.com/\">OpenAI</a>. The model you want to use depends on the type of data you're working with. There are models for tasks like computing sentence similarities, searching large texts, or performing image classification. Wikipedia2Vec uses a <a href=\"https://en.wikipedia.org/wiki/Word2vec\">Word2vec</a> algorithm to generate vectors for individual words, which maps similar words close to each other in a continuous vector space. </p>\n\n<p>I like animals, so I want to use Wikipedia2Vec to group similar animals. I\u2019m using the vector embeddings of each animal and the distance between them to find animals that are alike.</p>\n\n<p>If I want to get the embedding for a word from Wikipedia2Vec, I need to use a model. I downloaded one from the <a href=\"https://wikipedia2vec.github.io/wikipedia2vec/pretrained/\">pretrained embeddings</a> on their website. Then I can use their Python module and the function <code>get_word_vector</code> as follows:</p>\n\n<pre><code>from wikipedia2vec import Wikipedia2Vec\nwiki2vec = Wikipedia2Vec.load('enwiki_20180420_100d.pkl')\nwiki2vec.get_word_vector('llama')\n</code></pre>\n\n<p>The output of the vector looks like this:</p>\n\n<pre><code>memmap([-0.15647224,  0.04055957,  0.48439676, -0.22689971, -0.04544162,\n        -0.06538601,  0.22609918, -0.26075622, -0.7195759 , -0.24022003,\n         0.1050799 , -0.5550985 ,  0.4054564 ,  0.14180332,  0.19856507,\n         0.09962048,  0.38372937, -1.1912689 , -0.93939453, -0.28067762,\n         0.04410955,  0.43394643, -0.3429818 ,  0.22209083, -0.46317756,\n        -0.18109794,  0.2775289 , -0.21939017, -0.27015808,  0.72002393,\n        -0.01586861, -0.23480305,  0.365697  ,  0.61743397, -0.07460125,\n        -0.10441436, -0.6537417 ,  0.01339269,  0.06189647, -0.17747395,\n         0.2669941 , -0.03428648, -0.8533792 , -0.09588563, -0.7616592 ,\n        -0.11528812, -0.07127796,  0.28456485, -0.12986512, -0.8063386 ,\n        -0.04875885, -0.27353695, -0.32921   , -0.03807172,  0.10544889,\n         0.49989182, -0.03783042, -0.37752548, -0.19257008,  0.06255971,\n         0.25994852, -0.81092316, -0.15077794,  0.00658835,  0.02033841,\n        -0.32411653, -0.03033727, -0.64633304, -0.43443972, -0.30764043,\n        -0.11036412,  0.04134453, -0.26934972, -0.0289086 , -0.50319433,\n        -0.0204528 , -0.00278326,  0.36589545,  0.5446438 , -0.10852882,\n         0.09699931, -0.01168614,  0.08618425, -0.28925297, -0.25445923,\n         0.63120073,  0.52186656,  0.3439454 ,  0.6686451 ,  0.1076297 ,\n        -0.34688494,  0.05976971, -0.3720558 ,  0.20328045, -0.485623  ,\n        -0.2222396 , -0.22480975,  0.4386788 , -0.7506131 ,  0.14270408],\n       dtype=float32)\n</code></pre>\n\n<p>To get your vector data into your database:</p>\n\n<ol>\n<li>Generate the embeddings.</li>\n<li>Add a column to your database to store your embeddings.</li>\n<li>Save the embeddings to the database.</li>\n</ol>\n\n<p>I already have the embeddings from Wikipedia2Vec, so let\u2019s walk through preparing my database and saving them. When creating a vector column, it's necessary to declare a length for it, so check and see the length of the embedding the model outputs. In my case, the embeddings are 100 numbers long, so I add that column to my table.</p>\n\n<pre><code>CREATE TABLE animals(id serial PRIMARY KEY, name VARCHAR(100), embedding VECTOR(100));\n</code></pre>\n\n<p>From there, save the items you're interested in to your database. You can do it directly in SQL:</p>\n\n<pre><code>INSERT INTO animals(name, embedding) VALUES ('llama', '[-0.15647223591804504, \n\u2026\n-0.7506130933761597, 0.1427040845155716]');\n</code></pre>\n\n<p>But you can also use your <a href=\"https://devcenter.heroku.com/articles/connecting-heroku-postgres\">favorite programming language</a> along with a Postgres client and a <a href=\"https://github.com/pgvector/pgvector#languages\">pgvector library</a>. For this example, I used Python, <a href=\"https://github.com/psycopg/psycopg\">psycopg</a>, and <a href=\"https://github.com/pgvector/pgvector-python\">pgvector-python</a>. Here I'm using the pretrained embedding file to generate embeddings for a list of animals I made, <code>valeries-animals.txt</code>,  and save them to my database.</p>\n\n<pre><code>import psycopg\nfrom pathlib import Path\nfrom pgvector.psycopg import register_vector\nfrom wikipedia2vec import Wikipedia2Vec\n\nwiki2vec = Wikipedia2Vec.load('enwiki_20180420_100d.pkl')\nanimals = Path('valeries-animals.txt').read_text().split('\\n')\n\nwith psycopg.connect(DATABASE_URL, sslmode='require', autocommit=True) as conn:\n    register_vector(conn)\n    cur = conn.cursor()\n    for animal in animals:\n        cur.execute(\"INSERT INTO animals(name, embedding) VALUES (%s, %s)\", (animal, wiki2vec.get_word_vector(animal)))\n</code></pre>\n\n<p>Now that I have the embeddings in my database, I can use pgvector's functions to query them. The extension includes functions to calculate Euclidean distance (<code>&lt;-&gt;</code>), cosine distance (<code>&lt;=&gt;</code>), and inner product (<code>&lt;#&gt;</code>). You can use all three for <a href=\"https://developers.google.com/machine-learning/clustering/similarity/measuring-similarity\">calculating similarity</a> between vectors. Which one you use depends on <a href=\"https://cmry.github.io/notes/euclidean-v-cosine\">your data as well as your use case</a>.</p>\n\n<p>Here I'm using Euclidean distance to find the five animals closest to a shark:</p>\n\n<pre><code>=&gt; SELECT name FROM animals WHERE name != 'shark' ORDER BY embedding &lt;-&gt; (SELECT embedding FROM animals WHERE name = 'shark') LIMIT 5;\n name \n-----------\n crocodile\n dolphin\n whale\n turtle\n alligator\n(5 rows)\n</code></pre>\n\n<p>It works! It's worth noting that the model that we used is based on words appearing together in Wikipedia articles, and different models or source corpuses likely yield different results. The results here are also limited to the hundred or so animals that I added to my database.</p>\n<h2 class=\"anchored\">\n  <a href=\"https://blog.heroku.com/engineering/feed#pgvector-optimization-and-performance-considerations\" name=\"pgvector-optimization-and-performance-considerations\">pgvector Optimization and Performance Considerations</a>\n</h2>\n\n<p>As you add more vector data to your database, you may notice performance issues or slowness in performing queries. You can index vector data like other columns in Postgres, and pgvector provides a few ways to do so, but there are some important considerations to keep in mind:</p>\n\n<ul>\n<li>Adding an index causes pgvector to switch to using approximate nearest neighbor search instead of exact nearest neighbor search, possibly causing a difference in query results.</li>\n<li>Indexing functions are based on distance calculations, so create one based on the calculation you plan to rely on the most in your application.</li>\n<li>There are two index types supported, IVFFlat and HNSW. Before you add an IVFFlat index, make sure you have some data in your table for better recall.</li>\n</ul>\n\n<p>Check out the <a href=\"https://github.com/pgvector/pgvector#indexing\">pgvector documentation</a> for more information on indexing and other performance considerations.</p>\n<h2 class=\"anchored\">\n  <a href=\"https://blog.heroku.com/engineering/feed#collaborate-and-share-your-pgvector-projects\" name=\"collaborate-and-share-your-pgvector-projects\">Collaborate and Share Your pgvector Projects</a>\n</h2>\n\n<p>Now that pgvector for Heroku Postgres is out in the world, we're really excited to hear what you do with it! One of pgvector's great advantages is that it lets vector data live alongside all the other data you might already have in Postgres. You can add an embedding column to your existing tables and start experimenting. Our <a href=\"https://blog.heroku.com/pgvector-launch\">launch blog</a> for this feature includes a lot of ideas and possible use cases for how to use this new tool, and I'm sure you can come up with many more. If you have questions, our <a href=\"https://help.heroku.com/\">Support team</a> is available to assist. Don't forget you can share your solutions using the <a href=\"https://devcenter.heroku.com/articles/heroku-button\">Heroku Button</a> on your repo. If you feel like blogging on your success, tag us on social media and we would love to read about it!</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.heroku.com/engineering/feed",
      "value": "<h2 class=\"anchored\">\n  <a href=\"https://blog.heroku.com/engineering/feed#introducing-pgvector-for-heroku-postgres\" name=\"introducing-pgvector-for-heroku-postgres\">Introducing pgvector for Heroku Postgres</a>\n</h2>\n\n<p>Over the past few weeks, we worked on adding <a href=\"https://github.com/pgvector/pgvector\">pgvector</a> as an extension on Heroku Postgres. We're excited to release this feature, and based on the feedback on <a href=\"https://github.com/heroku/roadmap/issues/156\">our public roadmap</a>, many of you are too. We want to share a bit more about how you can use it and how it may be helpful to you. </p>\n\n<p>All <a href=\"https://devcenter.heroku.com/articles/heroku-postgres-plans#plan-tiers\">Standard-tier or higher</a> databases running Postgres 15 now support the <a href=\"https://devcenter.heroku.com/articles/heroku-postgres-extensions-postgis-full-text-search#pgvector\"><code>pgvector</code> extension</a>. You can get started by running <code>CREATE EXTENSION vector;</code> in a client session. Postgres 15 has been the default version on Heroku Postgres since March 2023.  If you're on an older version and want to use pgvector, <a href=\"https://devcenter.heroku.com/articles/upgrading-heroku-postgres-databases\">upgrade</a> to Postgres 15.</p>\n\n<p>The extension adds the vector data type to Heroku Postgres along with additional functions to work with it. Vectors are important for working with large language models and other machine learning applications, as the <a href=\"https://huggingface.co/blog/getting-started-with-embeddings#understanding-embeddings\">embeddings</a> generated by these models are often output in vector format. Working with vectors lets you implement things like similarity search across these embeddings. See our <a href=\"https://blog.heroku.com/pgvector-launch#understanding-pgvector-and-its-significance\">launch blog</a> for more background into what pgvector is, its significance, and ideas for how to use this new data type.</p>\n<h2 class=\"anchored\">\n  <a href=\"https://blog.heroku.com/engineering/feed#an-example-word-vector-similarity-search\" name=\"an-example-word-vector-similarity-search\">An Example: Word Vector Similarity Search</a>\n</h2>\n\n<p>To show a simple example of how to generate and save vector data to your Heroku database, I'm using the <a href=\"https://wikipedia2vec.github.io/wikipedia2vec/\">Wikipedia2Vec</a> pretrained embeddings. However, you can train your own embeddings or use other models providing embeddings via API, like <a href=\"https://huggingface.co/blog/getting-started-with-embeddings\">HuggingFace</a> or <a href=\"https://openai.com/\">OpenAI</a>. The model you want to use depends on the type of data you're working with. There are models for tasks like computing sentence similarities, searching large texts, or performing image classification. Wikipedia2Vec uses a <a href=\"https://en.wikipedia.org/wiki/Word2vec\">Word2vec</a> algorithm to generate vectors for individual words, which maps similar words close to each other in a continuous vector space. </p>\n\n<p>I like animals, so I want to use Wikipedia2Vec to group similar animals. I\u2019m using the vector embeddings of each animal and the distance between them to find animals that are alike.</p>\n\n<p>If I want to get the embedding for a word from Wikipedia2Vec, I need to use a model. I downloaded one from the <a href=\"https://wikipedia2vec.github.io/wikipedia2vec/pretrained/\">pretrained embeddings</a> on their website. Then I can use their Python module and the function <code>get_word_vector</code> as follows:</p>\n\n<pre><code>from wikipedia2vec import Wikipedia2Vec\nwiki2vec = Wikipedia2Vec.load('enwiki_20180420_100d.pkl')\nwiki2vec.get_word_vector('llama')\n</code></pre>\n\n<p>The output of the vector looks like this:</p>\n\n<pre><code>memmap([-0.15647224,  0.04055957,  0.48439676, -0.22689971, -0.04544162,\n        -0.06538601,  0.22609918, -0.26075622, -0.7195759 , -0.24022003,\n         0.1050799 , -0.5550985 ,  0.4054564 ,  0.14180332,  0.19856507,\n         0.09962048,  0.38372937, -1.1912689 , -0.93939453, -0.28067762,\n         0.04410955,  0.43394643, -0.3429818 ,  0.22209083, -0.46317756,\n        -0.18109794,  0.2775289 , -0.21939017, -0.27015808,  0.72002393,\n        -0.01586861, -0.23480305,  0.365697  ,  0.61743397, -0.07460125,\n        -0.10441436, -0.6537417 ,  0.01339269,  0.06189647, -0.17747395,\n         0.2669941 , -0.03428648, -0.8533792 , -0.09588563, -0.7616592 ,\n        -0.11528812, -0.07127796,  0.28456485, -0.12986512, -0.8063386 ,\n        -0.04875885, -0.27353695, -0.32921   , -0.03807172,  0.10544889,\n         0.49989182, -0.03783042, -0.37752548, -0.19257008,  0.06255971,\n         0.25994852, -0.81092316, -0.15077794,  0.00658835,  0.02033841,\n        -0.32411653, -0.03033727, -0.64633304, -0.43443972, -0.30764043,\n        -0.11036412,  0.04134453, -0.26934972, -0.0289086 , -0.50319433,\n        -0.0204528 , -0.00278326,  0.36589545,  0.5446438 , -0.10852882,\n         0.09699931, -0.01168614,  0.08618425, -0.28925297, -0.25445923,\n         0.63120073,  0.52186656,  0.3439454 ,  0.6686451 ,  0.1076297 ,\n        -0.34688494,  0.05976971, -0.3720558 ,  0.20328045, -0.485623  ,\n        -0.2222396 , -0.22480975,  0.4386788 , -0.7506131 ,  0.14270408],\n       dtype=float32)\n</code></pre>\n\n<p>To get your vector data into your database:</p>\n\n<ol>\n<li>Generate the embeddings.</li>\n<li>Add a column to your database to store your embeddings.</li>\n<li>Save the embeddings to the database.</li>\n</ol>\n\n<p>I already have the embeddings from Wikipedia2Vec, so let\u2019s walk through preparing my database and saving them. When creating a vector column, it's necessary to declare a length for it, so check and see the length of the embedding the model outputs. In my case, the embeddings are 100 numbers long, so I add that column to my table.</p>\n\n<pre><code>CREATE TABLE animals(id serial PRIMARY KEY, name VARCHAR(100), embedding VECTOR(100));\n</code></pre>\n\n<p>From there, save the items you're interested in to your database. You can do it directly in SQL:</p>\n\n<pre><code>INSERT INTO animals(name, embedding) VALUES ('llama', '[-0.15647223591804504, \n\u2026\n-0.7506130933761597, 0.1427040845155716]');\n</code></pre>\n\n<p>But you can also use your <a href=\"https://devcenter.heroku.com/articles/connecting-heroku-postgres\">favorite programming language</a> along with a Postgres client and a <a href=\"https://github.com/pgvector/pgvector#languages\">pgvector library</a>. For this example, I used Python, <a href=\"https://github.com/psycopg/psycopg\">psycopg</a>, and <a href=\"https://github.com/pgvector/pgvector-python\">pgvector-python</a>. Here I'm using the pretrained embedding file to generate embeddings for a list of animals I made, <code>valeries-animals.txt</code>,  and save them to my database.</p>\n\n<pre><code>import psycopg\nfrom pathlib import Path\nfrom pgvector.psycopg import register_vector\nfrom wikipedia2vec import Wikipedia2Vec\n\nwiki2vec = Wikipedia2Vec.load('enwiki_20180420_100d.pkl')\nanimals = Path('valeries-animals.txt').read_text().split('\\n')\n\nwith psycopg.connect(DATABASE_URL, sslmode='require', autocommit=True) as conn:\n    register_vector(conn)\n    cur = conn.cursor()\n    for animal in animals:\n        cur.execute(\"INSERT INTO animals(name, embedding) VALUES (%s, %s)\", (animal, wiki2vec.get_word_vector(animal)))\n</code></pre>\n\n<p>Now that I have the embeddings in my database, I can use pgvector's functions to query them. The extension includes functions to calculate Euclidean distance (<code>&lt;-&gt;</code>), cosine distance (<code>&lt;=&gt;</code>), and inner product (<code>&lt;#&gt;</code>). You can use all three for <a href=\"https://developers.google.com/machine-learning/clustering/similarity/measuring-similarity\">calculating similarity</a> between vectors. Which one you use depends on <a href=\"https://cmry.github.io/notes/euclidean-v-cosine\">your data as well as your use case</a>.</p>\n\n<p>Here I'm using Euclidean distance to find the five animals closest to a shark:</p>\n\n<pre><code>=&gt; SELECT name FROM animals WHERE name != 'shark' ORDER BY embedding &lt;-&gt; (SELECT embedding FROM animals WHERE name = 'shark') LIMIT 5;\n name \n-----------\n crocodile\n dolphin\n whale\n turtle\n alligator\n(5 rows)\n</code></pre>\n\n<p>It works! It's worth noting that the model that we used is based on words appearing together in Wikipedia articles, and different models or source corpuses likely yield different results. The results here are also limited to the hundred or so animals that I added to my database.</p>\n<h2 class=\"anchored\">\n  <a href=\"https://blog.heroku.com/engineering/feed#pgvector-optimization-and-performance-considerations\" name=\"pgvector-optimization-and-performance-considerations\">pgvector Optimization and Performance Considerations</a>\n</h2>\n\n<p>As you add more vector data to your database, you may notice performance issues or slowness in performing queries. You can index vector data like other columns in Postgres, and pgvector provides a few ways to do so, but there are some important considerations to keep in mind:</p>\n\n<ul>\n<li>Adding an index causes pgvector to switch to using approximate nearest neighbor search instead of exact nearest neighbor search, possibly causing a difference in query results.</li>\n<li>Indexing functions are based on distance calculations, so create one based on the calculation you plan to rely on the most in your application.</li>\n<li>There are two index types supported, IVFFlat and HNSW. Before you add an IVFFlat index, make sure you have some data in your table for better recall.</li>\n</ul>\n\n<p>Check out the <a href=\"https://github.com/pgvector/pgvector#indexing\">pgvector documentation</a> for more information on indexing and other performance considerations.</p>\n<h2 class=\"anchored\">\n  <a href=\"https://blog.heroku.com/engineering/feed#collaborate-and-share-your-pgvector-projects\" name=\"collaborate-and-share-your-pgvector-projects\">Collaborate and Share Your pgvector Projects</a>\n</h2>\n\n<p>Now that pgvector for Heroku Postgres is out in the world, we're really excited to hear what you do with it! One of pgvector's great advantages is that it lets vector data live alongside all the other data you might already have in Postgres. You can add an embedding column to your existing tables and start experimenting. Our <a href=\"https://blog.heroku.com/pgvector-launch\">launch blog</a> for this feature includes a lot of ideas and possible use cases for how to use this new tool, and I'm sure you can come up with many more. If you have questions, our <a href=\"https://help.heroku.com/\">Support team</a> is available to assist. Don't forget you can share your solutions using the <a href=\"https://devcenter.heroku.com/articles/heroku-button\">Heroku Button</a> on your repo. If you feel like blogging on your success, tag us on social media and we would love to read about it!</p>"
    },
    "authors": [
      {
        "name": "Valerie Woolard"
      }
    ],
    "author": "Valerie Woolard",
    "author_detail": {
      "name": "Valerie Woolard"
    }
  },
  "RoseHosting": {
    "title": "What is Uptime? Overview, Importance, Tips and Best Practices",
    "xmlUrl": "https://www.rosehosting.com/blog/feed/",
    "htmlUrl": "https://www.rosehosting.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.rosehosting.com/blog/feed/",
      "value": "What is Uptime? Overview, Importance, Tips and Best Practices"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.rosehosting.com/blog/what-is-uptime-overview-importance-tips-and-best-practices/"
      }
    ],
    "link": "https://www.rosehosting.com/blog/what-is-uptime-overview-importance-tips-and-best-practices/",
    "comments": "https://www.rosehosting.com/blog/what-is-uptime-overview-importance-tips-and-best-practices/#respond",
    "authors": [
      {
        "name": "Jeff Wilson"
      }
    ],
    "author": "Jeff Wilson",
    "author_detail": {
      "name": "Jeff Wilson"
    },
    "published": "Mon, 01 Jan 2024 18:30:00 +0000",
    "published_parsed": [
      2024,
      1,
      1,
      18,
      30,
      0,
      0,
      1,
      0
    ],
    "tags": [
      {
        "term": "Managed Hosting",
        "scheme": null,
        "label": null
      },
      {
        "term": "Tips and Tricks",
        "scheme": null,
        "label": null
      },
      {
        "term": "Fully Managed Hosting",
        "scheme": null,
        "label": null
      },
      {
        "term": "uptime",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://www.rosehosting.com/blog/?p=47527",
    "guidislink": false,
    "summary": "<p>Many hosting providers claim to provide optimal uptime for their customers. What is uptime, though?&#160; Uptime is simply the length ... </p>\n<p class=\"read-more-container\"><a class=\"read-more button\" href=\"https://www.rosehosting.com/blog/what-is-uptime-overview-importance-tips-and-best-practices/#more-47527\" title=\"What is Uptime? Overview, Importance, Tips and Best Practices\">Read More</a></p>\n<p>The post <a href=\"https://www.rosehosting.com/blog/what-is-uptime-overview-importance-tips-and-best-practices/\">What is Uptime? Overview, Importance, Tips and Best Practices</a> appeared first on <a href=\"https://www.rosehosting.com/blog\">RoseHosting</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.rosehosting.com/blog/feed/",
      "value": "<p>Many hosting providers claim to provide optimal uptime for their customers. What is uptime, though?&#160; Uptime is simply the length ... </p>\n<p class=\"read-more-container\"><a class=\"read-more button\" href=\"https://www.rosehosting.com/blog/what-is-uptime-overview-importance-tips-and-best-practices/#more-47527\" title=\"What is Uptime? Overview, Importance, Tips and Best Practices\">Read More</a></p>\n<p>The post <a href=\"https://www.rosehosting.com/blog/what-is-uptime-overview-importance-tips-and-best-practices/\">What is Uptime? Overview, Importance, Tips and Best Practices</a> appeared first on <a href=\"https://www.rosehosting.com/blog\">RoseHosting</a>.</p>"
    },
    "wfw_commentrss": "https://www.rosehosting.com/blog/what-is-uptime-overview-importance-tips-and-best-practices/feed/",
    "slash_comments": "0"
  },
  "Moove-it": {
    "title": "What\u2019s new in Kotlin for Android?",
    "xmlUrl": "https://blog.moove-it.com/rss",
    "htmlUrl": "https://blog.moove-it.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.moove-it.com/feed/",
      "value": "What\u2019s new in Kotlin for Android?"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.moove-it.com/whats-new-in-kotlin-for-android/"
      }
    ],
    "link": "https://blog.moove-it.com/whats-new-in-kotlin-for-android/",
    "authors": [
      {
        "name": "Andres De La Grana"
      }
    ],
    "author": "Andres De La Grana",
    "author_detail": {
      "name": "Andres De La Grana"
    },
    "published": "Wed, 21 Jun 2023 15:07:14 +0000",
    "published_parsed": [
      2023,
      6,
      21,
      15,
      7,
      14,
      2,
      172,
      0
    ],
    "tags": [
      {
        "term": "All",
        "scheme": null,
        "label": null
      },
      {
        "term": "Mobile Studio",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://blog.moove-it.com/?p=6856",
    "guidislink": false,
    "summary": "<p>Kotlin has become one of the most popular programming languages for Android development in recent years. It is now widely used by developers across the globe to create high-quality Android apps. Kotlin offers several advantages, such as better...</p>\n<p>The post <a href=\"https://blog.moove-it.com/whats-new-in-kotlin-for-android/\" rel=\"nofollow\">What&#8217;s new in Kotlin for Android?</a> appeared first on <a href=\"https://blog.moove-it.com\" rel=\"nofollow\">Moove It</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.moove-it.com/feed/",
      "value": "<p>Kotlin has become one of the most popular programming languages for Android development in recent years. It is now widely used by developers across the globe to create high-quality Android apps. Kotlin offers several advantages, such as better...</p>\n<p>The post <a href=\"https://blog.moove-it.com/whats-new-in-kotlin-for-android/\" rel=\"nofollow\">What&#8217;s new in Kotlin for Android?</a> appeared first on <a href=\"https://blog.moove-it.com\" rel=\"nofollow\">Moove It</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.moove-it.com/feed/",
        "value": "<p><span style=\"font-weight: 400;\">Kotlin has become one of the most popular programming languages for Android development in recent years. It is now widely used by developers across the globe to create high-quality Android apps. Kotlin offers several advantages, such as better code quality, enhanced performance, and improved developer productivity. Today, we will explore the latest features and updates in Kotlin for Android development, which is utilized by our Mobile Studio.</span></p>\n<h4><b>The Kotlin 2.0 compiler</b></h4>\n<p><span style=\"font-weight: 400;\">Also known as the codename \u201cK2\u201d, the Kotlin 2.0 compiler is a drop-in replacement for most code, so the developer using it doesn&#8217;t have to change their Kotlin source. The new architecture will be faster and have better build performance, and it is said to be twice as fast as the current Kotlin compiler.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">The Kotlin 2.0 compiler is expected to have a stable release in 2024, but it\u2019s currently able to be tried out as soon as possible to verify it works correctly.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">You can test it out by the setting the language version to 2.0, as shown below:</span></p>\n<p><img alt=\"\" class=\"alignnone wp-image-6857\" height=\"336\" src=\"https://blog.moove-it.com/wp-content/uploads/2023/06/image1-300x164.png\" width=\"615\" /></p>\n<h4><b>Kotlin DSL for Gradle builds</b></h4>\n<p><span style=\"font-weight: 400;\">Android has primarily used Kotlin for years, due to higher productivity and more stable apps for developers. Even with a Kotlin preference, the default language to define builds has been Groovy, even with a Kotlin Gradle option.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">Android has recently announced that they will be switching to Kotlin for the default languages for build scripts. This is a beneficial change for Android developers, since there are a lot of benefits to having Kotlin as the default language. Kotlin builds scripts by using statically typed values, so code hinting is more precise and helpful. Syntax errors are also more accurate and displayed while editing Kotlin build scripts instead of when the developer is trying to sync the project. Kotlin DSL also includes type and method documentation. There is also the option to migrate your build to version catalogs, if you&#8217;re looking to add and maintain your dependencies and plugins in a scalable way. If you\u2019re looking for resources on how to make the changes, here are some guides from Android Studio:</span></p>\n<ul>\n<li style=\"font-weight: 400;\"><a href=\"https://developer.android.com/build/migrate-to-kotlin-dsl\"><span style=\"font-weight: 400;\">Migrate your build configuration from Groovy to Kotlin\u00a0</span></a></li>\n<li style=\"font-weight: 400;\"><a href=\"https://developer.android.com/build/migrate-to-catalogs\"><span style=\"font-weight: 400;\">Migrate your build to version catalogs</span></a></li>\n</ul>\n<p>&nbsp;</p>\n<h4><b>Kotlin symbol processing</b><span style=\"font-weight: 400;\">\u00a0</span></h4>\n<p><span style=\"font-weight: 400;\">Code generation initially began with the Kotlin Annotation Processing Tool (KAPT), which generates Java stubs for Kotlin code and allows annotation processors written for Java to work with Kotlin. This stub generation has been a time consuming process, and over has had a significant impact on the build speed of projects that use annotation processing.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">However, KSP is a Kotlin-first alternative to KAPT, which analyzes Kotlin code and has shown to have several advantages such as:\u00a0</span></p>\n<ul>\n<li style=\"font-weight: 400;\"><b>Up to two times the speed</b><span style=\"font-weight: 400;\">. KSP requires no stub generation.</span></li>\n<li style=\"font-weight: 400;\"><b>Better typing.</b><span style=\"font-weight: 400;\"> KSP understands Kotlin specific languages such as nullability.\u00a0</span></li>\n<li style=\"font-weight: 400;\"><b>Multiplatform-ready</b><span style=\"font-weight: 400;\">. Doesn\u2019t depend on Java source code.\u00a0</span></li>\n</ul>\n<p>&nbsp;</p>\n<p><span style=\"font-weight: 400;\">Migration is recommended to be done as soon as possible. Here is how to set it up:</span></p>\n<ul>\n<li><span style=\"font-weight: 400;\">Add the plugin </span></li>\n</ul>\n<p><img alt=\"\" class=\"alignnone wp-image-6859\" height=\"104\" src=\"https://blog.moove-it.com/wp-content/uploads/2023/06/image2-1-300x48.png\" width=\"650\" /></p>\n<ul>\n<li><span style=\"font-weight: 400;\">Change KAPT for KSP whenever possible. (note: some libraries might not support KSP yet.)</span></li>\n</ul>\n<p><img alt=\"\" class=\"alignnone wp-image-6860\" height=\"299\" src=\"https://blog.moove-it.com/wp-content/uploads/2023/06/image3-300x138.png\" width=\"650\" /></p>\n<p><span style=\"font-weight: 400;\">For more information, check out the official libraries for KSP support:</span></p>\n<p><a href=\"https://kotlinlang.org/docs/ksp-overview.html#supported-libraries\"><span style=\"font-weight: 400;\">Kotlin Symbol Processing API\u00a0</span></a></p>\n<p>&nbsp;</p>\n<h4><b>Kotlin Multiplatform (Beta)\u00a0</b></h4>\n<p><span style=\"font-weight: 400;\">Kotlin Multiplatform is made to simplify the development of cross-platform projects by sharing Kotlin code across different platforms. It reduces the overall time spent writing and maintaining the code for different platforms, while maintaining the benefits of native programming.</span></p>\n<p><img alt=\"\" class=\"alignnone wp-image-6864\" height=\"310\" src=\"https://blog.moove-it.com/wp-content/uploads/2023/06/graph-300x143.png\" width=\"650\" /></p>\n<p><span style=\"font-weight: 400;\">Kotlin Multiplatform is currently in Beta, and Google is currently experimenting with code sharing in Kotlin across Android, iOS and web while utilizing Google Suite applications. </span></p>\n<p><img alt=\"\" class=\"alignnone wp-image-6861\" height=\"82\" src=\"https://blog.moove-it.com/wp-content/uploads/2023/06/image5-300x37.png\" width=\"665\" /></p>\n<p><span style=\"font-weight: 400;\">With the benefits of native programming while working on different platforms, Kotlin provides the following code sharing mechanics:\u00a0</span></p>\n<ul>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Share common code among all the platforms that are being used in your project</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Share code among only some of the platforms included in your project in order to reuse the code in similar platforms\u00a0</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">If platform specific APIS need to be accessed from the shared code, you can use the Kotlin mechanism of expected and actual declarations.\u00a0</span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Some Jetpack libraries are bringing support for\u00a0 Kotlin Multiplatform, to learn more about the Jetpack libraries, </span><a href=\"https://github.com/android/kotlin-multiplatform-samples\"><span style=\"font-weight: 400;\">click here</span></a><span style=\"font-weight: 400;\">.\u00a0</span></p>\n<h4><b>Conclusion</b></h4>\n<p><span style=\"font-weight: 400;\">Kotlin has introduced several new features that will continue to make it a great language for Android development. Kotlin is continuing to make it easier for developers to write clean and efficient code, and making it more efficient to migrate their existing code to Kotlin.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">Overall, Kotlin is a powerful language, and as Google continues to support Kotlin and add new features to the language, we can expect even more exciting features in the future.</span><span style=\"font-weight: 400;\">To learn more about what our Mobile Studio is doing in Android development, check out our Mobile Studio site at: </span><a href=\"https://moove-it.com/studios/mobile-studio\"><span style=\"font-weight: 400;\">https://moove-it.com/studios/mobile-studio</span></a></p>\n<p>The post <a href=\"https://blog.moove-it.com/whats-new-in-kotlin-for-android/\" rel=\"nofollow\">What&#8217;s new in Kotlin for Android?</a> appeared first on <a href=\"https://blog.moove-it.com\" rel=\"nofollow\">Moove It</a>.</p>"
      }
    ]
  },
  "Azavea": {
    "title": "Our next era: Azavea joins Element 84",
    "xmlUrl": "https://www.azavea.com/blog/category/software-development/rss",
    "htmlUrl": "https://www.azavea.com/blog/category/software-development/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.azavea.com/blog/feed/",
      "value": "Our next era: Azavea joins Element 84"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.azavea.com/blog/2023/02/15/our-next-era-azavea-joins-element-84/"
      }
    ],
    "link": "https://www.azavea.com/blog/2023/02/15/our-next-era-azavea-joins-element-84/",
    "authors": [
      {
        "name": "Robert Cheetham"
      }
    ],
    "author": "Robert Cheetham",
    "author_detail": {
      "name": "Robert Cheetham"
    },
    "published": "Wed, 15 Feb 2023 19:47:18 +0000",
    "published_parsed": [
      2023,
      2,
      15,
      19,
      47,
      18,
      2,
      46,
      0
    ],
    "tags": [
      {
        "term": "Company",
        "scheme": null,
        "label": null
      },
      {
        "term": "Community",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://www.azavea.com/?p=14805",
    "guidislink": false,
    "summary": "<p>As of February 16, '23, Element 84 has acquired Azavea. Together, we look forward to creating solutions for pressing global challenges.</p>\n<p>The post <a href=\"https://www.azavea.com/blog/2023/02/15/our-next-era-azavea-joins-element-84/\">Our next era: Azavea joins Element 84</a> appeared first on <a href=\"https://www.azavea.com\">Azavea</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.azavea.com/blog/feed/",
      "value": "<p>As of February 16, '23, Element 84 has acquired Azavea. Together, we look forward to creating solutions for pressing global challenges.</p>\n<p>The post <a href=\"https://www.azavea.com/blog/2023/02/15/our-next-era-azavea-joins-element-84/\">Our next era: Azavea joins Element 84</a> appeared first on <a href=\"https://www.azavea.com\">Azavea</a>.</p>"
    }
  },
  "Postmates": {
    "title": "Density\u200a\u2014\u200aMerchant Density",
    "xmlUrl": "https://medium.com/feed/postmates-blog/tagged/engineering",
    "htmlUrl": "https://blog.postmates.com/tagged/engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/postmates-blog/tagged/engineering",
      "value": "Density\u200a\u2014\u200aMerchant Density"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/postmates-blog/density-merchant-density-933c6b048d3e?source=rss----2664e1d3cff9--engineering"
      }
    ],
    "link": "https://medium.com/postmates-blog/density-merchant-density-933c6b048d3e?source=rss----2664e1d3cff9--engineering",
    "id": "https://medium.com/p/933c6b048d3e",
    "guidislink": false,
    "tags": [
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Postmates"
      }
    ],
    "author": "Postmates",
    "author_detail": {
      "name": "Postmates"
    },
    "published": "Mon, 03 Feb 2020 11:16:01 GMT",
    "published_parsed": [
      2020,
      2,
      3,
      11,
      16,
      1,
      0,
      34,
      0
    ],
    "updated": "2020-02-03T18:13:59.843Z",
    "updated_parsed": [
      2020,
      2,
      3,
      18,
      13,
      59,
      0,
      34,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/postmates-blog/tagged/engineering",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*nWCVGtB7-cySAXG0\" /></figure><h3>Density\u200a\u2014\u200aMerchant\u00a0Density</h3><a href=\"https://medium.com/media/0b06e7a9068b4672a8e0a766a45bba7c/href\">https://medium.com/media/0b06e7a9068b4672a8e0a766a45bba7c/href</a><p><a href=\"https://blog.postmates.com/the-sonification-of-postmates-data-e68294243362\"><em>Click here for more info on this\u00a0project.</em></a></p><h3>The Closest\u00a0Burrito</h3><p>We\u2019ve already compared the <a href=\"https://blog.postmates.com/density-postmate-density-25ff2ae210f8\">density of our Postmates</a> as they are completing deliveries throughout a day in two different markets. In this case, we want to look at how far does food need to travel to get to our customers. In other words, how densely distributed are our merchants.</p><p>Postmates doesn\u2019t have hours. Any time you open the app, we\u2019ll show you what you can order from and a Postmate will always be available to get anything you need. As you can imagine, what is available throughout the day will change, what shops are open will change, and so maybe the thing you want will need to travel farther than normal depending on the\u00a0time.</p><p>Let\u2019s look at how far orders need to travel to get to customers in two different markets, Los Angeles and New\u00a0York.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*VI4rjOqoj2ZLtIfW\" /></figure><p>This is super interesting to me. It\u2019s very clear that each market has a natural distance that things tend to travel to get to the person that requested them. There\u2019s only a brief window of time every day when that distance moves away from that center. It makes sense that things in NYC don\u2019t travel as far as they do in\u00a0LA.</p><p>You can also see that during the late night hours (right around midnight), we see the distances get very erratic. In LA we generally see late night deliveries increase in distance, which makes sense, since fewer places will be open, so the odds of the thing a given customer wants being close to them go down. In NYC that seems true as well for the most part, but it fluctuates in both directions. I don\u2019t think that\u2019s anything special about NYC, it just shows that when we aren\u2019t in the normal waking hours things become less predictable.</p><h3>Active Postmates</h3><p>While we\u2019re looking at how far things are travelling to customers, let\u2019s also look at the Postmates that are moving these things. Here\u2019s how many active Postmates we see in these markets in this same period of\u00a0time:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*k_lpnXxb81qHnzLg\" /></figure><p>Values have been normalized so that each market\u2019s max value is the same, we\u2019re really just trying to capture the shape of each market, not the size. Also both series are in local\u00a0time.</p><p>A few things stick out to me. First, it\u2019s pretty wild how extremely different this chart is compared to the previous one. Both of these are sampled hourly, and we really only see anywhere between 1\u20133 hours in a day really deviating from the average. Looking at the number of Postmates on the other hand, there\u2019s a massive range in the shape of when Postmates are completing deliveries. That strengthens the idea that each market has kind of a \u201cnatural\u201d expected distance between merchants and customers.</p><p>Another thing that I see here is that we see more active Postmates during the week at lunch in LA than in NYC. It\u2019s interesting how similar the shapes are, and how they move together. There are distinct lunch and dinner peaks in both markets during the week, on Saturday we see less of a dip between lunch and dinner, and even less of a dip on Sundays in both markets. This means that Postmates are staying online more consistently on Sundays compared to any other\u00a0day.</p><h3>What You\u2019re\u00a0Hearing</h3><p>We\u2019ve got two tracks here, both with the same synth sound. You\u2019re hearing a note for each hour in a\u00a0week.</p><ul><li>The pitch is determined by the average distance traveled between merchant and customer in each hour, arranged so it\u2019s only hitting notes in C Major (to my ear it sounds more like D Dorian since the note in the bass, NYC, stays on D for so much of the\u00a0piece).</li><li>The volume is determined by the number of active Postmates in each hour, normalized so that each market\u2019s max is the peak volume of the instrument (again, I\u2019m using this for the shape, not the\u00a0scale).</li></ul><p>NYC gravitates towards D in the bass, and LA dances around F and G an octave above. It makes some very pleasant sounding harmonies. I didn\u2019t tweak the scale between them to make that happen either, it arose out of just normalizing everything to fit within the four-octave range that I\u00a0chose.</p><h3>How it\u00a0Works</h3><p>I made a simplified tutorial on how to create these from start to finish. Check out the <a href=\"https://colab.research.google.com/drive/17_L5slKIB2fvbcMyt-y9tO1zZ1UChAf-#scrollTo=kLAW5VHw-yLl\">Colab notebook</a> if you want to make one yourself.</p><p>This piece required two MIDI files, one per market, and the data populated the pitch and velocity values of each note. No Control Change values to worry about here. I put in a bit of a buffer between the note_off of one note and the note_on of the next note, and since this data was sampled hourly everything is a constant number of ticks between notes, so it\u2019s not hard to insert a small rest between\u00a0notes.</p><p>Once the MIDI files are made, I brought them into <a href=\"https://www.reaper.fm/\">REAPER</a>, and set up each one with an instance of <a href=\"https://output.com/products/analog-strings\">Analog Strings by Output</a> with an identical patch I created. That\u2019s it. No mapping of anything required since we\u2019re only dealing with pitches and velocities.</p><h3>Conclusion</h3><p>It always sounds great in PR blasts when a company can say \u201cwe\u2019ve got X million places on our platform!\u201d But in reality that number can\u2019t possibly be static. As we can see here, what\u2019s available to customers at any given moment changes, and sometimes our Postmates are going to have to travel a bit further to get the thing you\u00a0want.</p><p>I knew that deliveries in NYC weren\u2019t going to travel as far as they do in LA, but I wasn\u2019t expecting it to be so consistent. And I wasn\u2019t expecting it to sound so nice, that was a pleasant surprise.</p><p>Postmates really is a network of living 24/7 marketplaces more than it\u2019s a menu of stuff to get. Each market will have its own normal conditions, but things shift constantly.</p><p><em>Postmates is always looking for creative data-focused people to join our team. If you want to make things like this, check out </em><a href=\"https://careers.postmates.com/\"><em>https://careers.postmates.com/</em></a><em> and say that Alex sent\u00a0you.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=933c6b048d3e\" width=\"1\" /><hr /><p><a href=\"https://medium.com/postmates-blog/density-merchant-density-933c6b048d3e\">Density\u200a\u2014\u200aMerchant Density</a> was originally published in <a href=\"https://medium.com/postmates-blog\">Postmates</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*nWCVGtB7-cySAXG0\" /></figure><h3>Density\u200a\u2014\u200aMerchant\u00a0Density</h3><a href=\"https://medium.com/media/0b06e7a9068b4672a8e0a766a45bba7c/href\">https://medium.com/media/0b06e7a9068b4672a8e0a766a45bba7c/href</a><p><a href=\"https://blog.postmates.com/the-sonification-of-postmates-data-e68294243362\"><em>Click here for more info on this\u00a0project.</em></a></p><h3>The Closest\u00a0Burrito</h3><p>We\u2019ve already compared the <a href=\"https://blog.postmates.com/density-postmate-density-25ff2ae210f8\">density of our Postmates</a> as they are completing deliveries throughout a day in two different markets. In this case, we want to look at how far does food need to travel to get to our customers. In other words, how densely distributed are our merchants.</p><p>Postmates doesn\u2019t have hours. Any time you open the app, we\u2019ll show you what you can order from and a Postmate will always be available to get anything you need. As you can imagine, what is available throughout the day will change, what shops are open will change, and so maybe the thing you want will need to travel farther than normal depending on the\u00a0time.</p><p>Let\u2019s look at how far orders need to travel to get to customers in two different markets, Los Angeles and New\u00a0York.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*VI4rjOqoj2ZLtIfW\" /></figure><p>This is super interesting to me. It\u2019s very clear that each market has a natural distance that things tend to travel to get to the person that requested them. There\u2019s only a brief window of time every day when that distance moves away from that center. It makes sense that things in NYC don\u2019t travel as far as they do in\u00a0LA.</p><p>You can also see that during the late night hours (right around midnight), we see the distances get very erratic. In LA we generally see late night deliveries increase in distance, which makes sense, since fewer places will be open, so the odds of the thing a given customer wants being close to them go down. In NYC that seems true as well for the most part, but it fluctuates in both directions. I don\u2019t think that\u2019s anything special about NYC, it just shows that when we aren\u2019t in the normal waking hours things become less predictable.</p><h3>Active Postmates</h3><p>While we\u2019re looking at how far things are travelling to customers, let\u2019s also look at the Postmates that are moving these things. Here\u2019s how many active Postmates we see in these markets in this same period of\u00a0time:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*k_lpnXxb81qHnzLg\" /></figure><p>Values have been normalized so that each market\u2019s max value is the same, we\u2019re really just trying to capture the shape of each market, not the size. Also both series are in local\u00a0time.</p><p>A few things stick out to me. First, it\u2019s pretty wild how extremely different this chart is compared to the previous one. Both of these are sampled hourly, and we really only see anywhere between 1\u20133 hours in a day really deviating from the average. Looking at the number of Postmates on the other hand, there\u2019s a massive range in the shape of when Postmates are completing deliveries. That strengthens the idea that each market has kind of a \u201cnatural\u201d expected distance between merchants and customers.</p><p>Another thing that I see here is that we see more active Postmates during the week at lunch in LA than in NYC. It\u2019s interesting how similar the shapes are, and how they move together. There are distinct lunch and dinner peaks in both markets during the week, on Saturday we see less of a dip between lunch and dinner, and even less of a dip on Sundays in both markets. This means that Postmates are staying online more consistently on Sundays compared to any other\u00a0day.</p><h3>What You\u2019re\u00a0Hearing</h3><p>We\u2019ve got two tracks here, both with the same synth sound. You\u2019re hearing a note for each hour in a\u00a0week.</p><ul><li>The pitch is determined by the average distance traveled between merchant and customer in each hour, arranged so it\u2019s only hitting notes in C Major (to my ear it sounds more like D Dorian since the note in the bass, NYC, stays on D for so much of the\u00a0piece).</li><li>The volume is determined by the number of active Postmates in each hour, normalized so that each market\u2019s max is the peak volume of the instrument (again, I\u2019m using this for the shape, not the\u00a0scale).</li></ul><p>NYC gravitates towards D in the bass, and LA dances around F and G an octave above. It makes some very pleasant sounding harmonies. I didn\u2019t tweak the scale between them to make that happen either, it arose out of just normalizing everything to fit within the four-octave range that I\u00a0chose.</p><h3>How it\u00a0Works</h3><p>I made a simplified tutorial on how to create these from start to finish. Check out the <a href=\"https://colab.research.google.com/drive/17_L5slKIB2fvbcMyt-y9tO1zZ1UChAf-#scrollTo=kLAW5VHw-yLl\">Colab notebook</a> if you want to make one yourself.</p><p>This piece required two MIDI files, one per market, and the data populated the pitch and velocity values of each note. No Control Change values to worry about here. I put in a bit of a buffer between the note_off of one note and the note_on of the next note, and since this data was sampled hourly everything is a constant number of ticks between notes, so it\u2019s not hard to insert a small rest between\u00a0notes.</p><p>Once the MIDI files are made, I brought them into <a href=\"https://www.reaper.fm/\">REAPER</a>, and set up each one with an instance of <a href=\"https://output.com/products/analog-strings\">Analog Strings by Output</a> with an identical patch I created. That\u2019s it. No mapping of anything required since we\u2019re only dealing with pitches and velocities.</p><h3>Conclusion</h3><p>It always sounds great in PR blasts when a company can say \u201cwe\u2019ve got X million places on our platform!\u201d But in reality that number can\u2019t possibly be static. As we can see here, what\u2019s available to customers at any given moment changes, and sometimes our Postmates are going to have to travel a bit further to get the thing you\u00a0want.</p><p>I knew that deliveries in NYC weren\u2019t going to travel as far as they do in LA, but I wasn\u2019t expecting it to be so consistent. And I wasn\u2019t expecting it to sound so nice, that was a pleasant surprise.</p><p>Postmates really is a network of living 24/7 marketplaces more than it\u2019s a menu of stuff to get. Each market will have its own normal conditions, but things shift constantly.</p><p><em>Postmates is always looking for creative data-focused people to join our team. If you want to make things like this, check out </em><a href=\"https://careers.postmates.com/\"><em>https://careers.postmates.com/</em></a><em> and say that Alex sent\u00a0you.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=933c6b048d3e\" width=\"1\" /><hr /><p><a href=\"https://medium.com/postmates-blog/density-merchant-density-933c6b048d3e\">Density\u200a\u2014\u200aMerchant Density</a> was originally published in <a href=\"https://medium.com/postmates-blog\">Postmates</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Prezi": {
    "title": "How Prezi Serves Customer Traffic",
    "xmlUrl": "https://engineering.prezi.com/feed",
    "htmlUrl": "https://medium.com/prezi-engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.prezi.com/feed",
      "value": "How Prezi Serves Customer Traffic"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.prezi.com/how-prezi-serves-customer-traffic-60fc9711702b?source=rss----911e72786e31---4"
      }
    ],
    "link": "https://engineering.prezi.com/how-prezi-serves-customer-traffic-60fc9711702b?source=rss----911e72786e31---4",
    "id": "https://medium.com/p/60fc9711702b",
    "guidislink": false,
    "authors": [
      {
        "name": "Alex"
      }
    ],
    "author": "Alex",
    "author_detail": {
      "name": "Alex"
    },
    "published": "Tue, 09 Jan 2024 09:56:32 GMT",
    "published_parsed": [
      2024,
      1,
      9,
      9,
      56,
      32,
      1,
      9,
      0
    ],
    "updated": "2024-01-09T09:56:32.688Z",
    "updated_parsed": [
      2024,
      1,
      9,
      9,
      56,
      32,
      1,
      9,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.prezi.com/feed",
        "value": "<p>Prezi has a global audience that depends on the fast and reliable accessibility of its content. In this article, we look into the way Prezi serves content from a network perspective.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*wAbH9ve3pibIrm0F\" /><figcaption>Photo by <a href=\"https://unsplash.com/@dead____artist?utm_source=medium&amp;utm_medium=referral\">Z</a> on\u00a0<a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>See this article as a general overview of how content can be served on a global scale. This is not the only and probably not the ultimate solution but one way to do\u00a0it.</p><p>The overall flow of this is depicted in the following image. Prezi runs on AWS and uses AWS services to offer customer-facing internet endpoints.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/778/1*eddbE2b-YnTWyh9oNkoIeg.png\" /><figcaption>Network diagram</figcaption></figure><p>The DNS zones and records are managed in Route53. Customer traffic goes through AWS Global Accelerator to decrease latency before it is filtered by AWS Web Application Firewall (WAF). The traffic is then terminated at the Application Load Balancer (ALB) and forwarded into the cloud environment where most of the workload runs inside Elastic Kubernetes Services\u00a0(EKS).</p><p>Some of the customer traffic is going to AWS Cloudfront which is used to deliver media assets that benefit from being cached closer to the customer.</p><p>The following article will go over these components, see what they do, and discuss the benefits those components offer.</p><h3>Find the best path (AWS Route53 and Global Accelerator)</h3><p>Having customers worldwide and offering services over the Internet poses multiple challenges. One of them is to reduce latency. Cloudflare defines latency as the \u201camount of time it takes for a data packet to go from one place to another. Lowering latency is an important part of building a good user experience.\u201d (source <a href=\"https://www.cloudflare.com/en-gb/learning/performance/glossary/what-is-latency/\">https://www.cloudflare.com/en-gb/learning/performance/glossary/what-is-latency/</a>)</p><p>That said, the challenge in having customers worldwide is the heterogeneity of the network normal people call \u201cthe internet\u201d.</p><p>When we look at the lower network layer at the internet topology, we can see many different networks peered together.</p><p>The following image shows parts of the peering connections in Latin America that form the internet\u2019s backbone. For a data packet, going from South America to Miami means traversing through multiple networks and every network adds a little bit to the complete travel\u00a0time.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*5spQvhNu27Ddsual\" /><figcaption>taken from <a href=\"https://global-internet-map-2022.telegeography.com/\">https://global-internet-map-2022.telegeography.com/</a></figcaption></figure><p>Going back to the challenge of controlling latency for customers there are generally speaking 2\u00a0options:</p><ul><li>Offering services close to the customer to avoid far network\u00a0travels</li><li>Offer a fast path from the customer to the place where services are\u00a0offered.</li></ul><h4>The best path for most of the\u00a0world</h4><p>Prezi uses the second option by offering a fast path to services via AWS GlobalAccelerator. This service enables customer traffic to be routed most of the time via the global AWS network instead of the public internet.</p><p>This routing reduces latency. In experiments from my local machine, optimized requests traveled 200ms faster than the not-optimized ones. The total time until I got an answer went down from 800ms to 600ms. <br />Loading the Prezi dashboard when logged in needs at the moment roughly 150 individual requests which all benefit from the decrease of 25% in latency. <br />Please keep in mind that the real percentage of acceleration depends on multiple factors like location and current routing situation.</p><p>Whenever a customer sends requests to prezi.com, those requests are routed to the closest AWS network endpoint and then transferred inside this global\u00a0network.</p><h4>And the best path for inhabitants of\u00a0Virginia</h4><p>As stated in the headline of the previous chapter, most Prezi customers go to Global Accelerator except those who reside in Virginia. Those customers are already close enough to the service endpoint and are routed directly to the following components.</p><p><em>Note</em>: the network diagram above does not show this route to avoid being too\u00a0complex.</p><h3>Implementation</h3><p>To achieve this, Prezi leverages geo-balanced DNS queries in Route53 so that different IP addresses are returned depending on the location.</p><p>The following screenshot for a practical example. The first lookup is executed from a local machine in Europe, and the second one with an activated VPN from Virginia.</p><p>The first DNS query returns the endpoints for the Global Accelerator, and the second query from Virgina returns the endpoints of some AWS load balancer (see the following chapter).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*er-snPt_ZVhdB3Xf\" /><figcaption>Terminal showing different DNS lookup results depending on location.</figcaption></figure><h4>Alternatives</h4><p>The alternative to this network-based approach is to move offered services closer to the customer. This can be achieved for example by deploying instances into selected cloud regions. To achieve this, the whole application stack needs to be deployed and some backend synchronization is needed\u200a\u2014\u200aas part of the Prezi, suite enables collaboration in-between multiple\u00a0users.</p><p>Serving from a single region reduces the complexity and streamlines deployment.</p><h3>Protection (AWS WAF and\u00a0Shield)</h3><p>While the internet is a wonderful place to connect, collaborate, be creative, and a lot more, it is at the same time also a place that attracts bad actors. It is widespread that public and well-known endpoints are the target of distributed denial of service (DDoS) attacks. Prezi leverages the combination of AWS Web Application Firewall (WAF) and Shield to protect the downstream infrastructure from these threat\u00a0vectors.</p><p>Every request that needs to reach Prezi infrastructure is evaluated through these components. Certain endpoints are protected via a specific rate limit to make sure they are not hammered.</p><p>For example, it does not make sense to send multiple requests for the login endpoint within a small amount of time. To protect sensible endpoints, the AWS WAF can respond with HTTP/429 (<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\">https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429</a>). <br />See the following screenshot of how a triggered rate limit looks in the browser\u00a0console:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*wRfL6hOiUq5NUAKw\" /><figcaption>Chrome Developer tools show one HTTP\u00a0response</figcaption></figure><p>On a bigger scale, the traffic flow is monitored by AWS Shield and blocked when a DDoS attack is detected. When Shield detects a DDoS from multiple traffic sources, those sources get\u00a0blocked.</p><h4>Alternatives</h4><p>Offering services over the Internet without any protection is a bad idea. Any public-facing IP is attracting traffic and if a company has reached a certain scale it attracts bad actors. There are alternative solutions and vendors like Cloudflare or Akamai that can offer the same protection service. As we run our workload on AWS the natural choice is AWS WAF as the integration is\u00a0easy.</p><h3>Access (ALB, EKS, API\u00a0Gateway)</h3><p>Requests allowed to enter reach the AWS-managed load balancer fleet that keeps track of routing those requests into the VPC environment that hosts the actual workload. The load balancer uses our public TLS certificate to offload HTTPS connections from customers.</p><p>The application load balancer (ALB) is used for routing based on the HTTP Host header. This means that based on the domain used, ALB can forward traffic into the isolated workload environment.</p><p>Running inside the Kubernetes fleet is a self-written API gateway. The purpose of this component is to build more detailed routes based on request paths or other identifiers. Most of the backends are based on Python and Scala. Those pods run inside the Kubernetes offering of AWS: Elastic Kubernetes Service. <br />Traffic is routed into these pods either by a WSGI conform application server in Python land or directly by the JVM for Scala services.</p><p>As the mentioned API gateway runs also inside Kubernetes, it can forward traffic to the target backend services based on different routing guidelines within the cluster network. The API gateway offers the flexibility to do advanced routing to the microservices based on configuration by the developers.</p><p>When you think back about the scope of AWS WAF usage, there was no check for malicious content and requests. We use a different web application firewall to check for bad requests and protection against cross-site scripting, injections, and other things that might harm Prezi\u200a\u2014\u200aor our customer.</p><h3>Content delivery (CloudFront)</h3><p>Prezi\u2019s main purpose is to deliver amazing presentations that most of the time contain visuals like images and gifs. They can be served via a content delivery network (CDN) that can reproach content closer to the customer.</p><p>Loading resources from a CDN does decrease the time in which the user waits for the resources to\u00a0appear.</p><p>Also on the cost focus, it is cheaper to serve content from CloudFront instead of serving it every time from the backend. This applies especially to assets like images that don\u2019t change\u00a0often.</p><p>Due to the deep integration into the ecosystem, in our setup, there is no other choice than CloudFront. Technically, it should also be doable with CloudFlare or any other CDN\u00a0vendor.</p><h3>Wrap up</h3><p>The article above describes the architecture Prezi uses to serve content to a global audience.</p><p>There are multiple different ways to serve traffic\u200a\u2014\u200aeven if running on\u00a0AWS.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=60fc9711702b\" width=\"1\" /><hr /><p><a href=\"https://engineering.prezi.com/how-prezi-serves-customer-traffic-60fc9711702b\">How Prezi Serves Customer Traffic</a> was originally published in <a href=\"https://engineering.prezi.com\">Prezi Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>Prezi has a global audience that depends on the fast and reliable accessibility of its content. In this article, we look into the way Prezi serves content from a network perspective.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*wAbH9ve3pibIrm0F\" /><figcaption>Photo by <a href=\"https://unsplash.com/@dead____artist?utm_source=medium&amp;utm_medium=referral\">Z</a> on\u00a0<a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>See this article as a general overview of how content can be served on a global scale. This is not the only and probably not the ultimate solution but one way to do\u00a0it.</p><p>The overall flow of this is depicted in the following image. Prezi runs on AWS and uses AWS services to offer customer-facing internet endpoints.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/778/1*eddbE2b-YnTWyh9oNkoIeg.png\" /><figcaption>Network diagram</figcaption></figure><p>The DNS zones and records are managed in Route53. Customer traffic goes through AWS Global Accelerator to decrease latency before it is filtered by AWS Web Application Firewall (WAF). The traffic is then terminated at the Application Load Balancer (ALB) and forwarded into the cloud environment where most of the workload runs inside Elastic Kubernetes Services\u00a0(EKS).</p><p>Some of the customer traffic is going to AWS Cloudfront which is used to deliver media assets that benefit from being cached closer to the customer.</p><p>The following article will go over these components, see what they do, and discuss the benefits those components offer.</p><h3>Find the best path (AWS Route53 and Global Accelerator)</h3><p>Having customers worldwide and offering services over the Internet poses multiple challenges. One of them is to reduce latency. Cloudflare defines latency as the \u201camount of time it takes for a data packet to go from one place to another. Lowering latency is an important part of building a good user experience.\u201d (source <a href=\"https://www.cloudflare.com/en-gb/learning/performance/glossary/what-is-latency/\">https://www.cloudflare.com/en-gb/learning/performance/glossary/what-is-latency/</a>)</p><p>That said, the challenge in having customers worldwide is the heterogeneity of the network normal people call \u201cthe internet\u201d.</p><p>When we look at the lower network layer at the internet topology, we can see many different networks peered together.</p><p>The following image shows parts of the peering connections in Latin America that form the internet\u2019s backbone. For a data packet, going from South America to Miami means traversing through multiple networks and every network adds a little bit to the complete travel\u00a0time.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*5spQvhNu27Ddsual\" /><figcaption>taken from <a href=\"https://global-internet-map-2022.telegeography.com/\">https://global-internet-map-2022.telegeography.com/</a></figcaption></figure><p>Going back to the challenge of controlling latency for customers there are generally speaking 2\u00a0options:</p><ul><li>Offering services close to the customer to avoid far network\u00a0travels</li><li>Offer a fast path from the customer to the place where services are\u00a0offered.</li></ul><h4>The best path for most of the\u00a0world</h4><p>Prezi uses the second option by offering a fast path to services via AWS GlobalAccelerator. This service enables customer traffic to be routed most of the time via the global AWS network instead of the public internet.</p><p>This routing reduces latency. In experiments from my local machine, optimized requests traveled 200ms faster than the not-optimized ones. The total time until I got an answer went down from 800ms to 600ms. <br />Loading the Prezi dashboard when logged in needs at the moment roughly 150 individual requests which all benefit from the decrease of 25% in latency. <br />Please keep in mind that the real percentage of acceleration depends on multiple factors like location and current routing situation.</p><p>Whenever a customer sends requests to prezi.com, those requests are routed to the closest AWS network endpoint and then transferred inside this global\u00a0network.</p><h4>And the best path for inhabitants of\u00a0Virginia</h4><p>As stated in the headline of the previous chapter, most Prezi customers go to Global Accelerator except those who reside in Virginia. Those customers are already close enough to the service endpoint and are routed directly to the following components.</p><p><em>Note</em>: the network diagram above does not show this route to avoid being too\u00a0complex.</p><h3>Implementation</h3><p>To achieve this, Prezi leverages geo-balanced DNS queries in Route53 so that different IP addresses are returned depending on the location.</p><p>The following screenshot for a practical example. The first lookup is executed from a local machine in Europe, and the second one with an activated VPN from Virginia.</p><p>The first DNS query returns the endpoints for the Global Accelerator, and the second query from Virgina returns the endpoints of some AWS load balancer (see the following chapter).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*er-snPt_ZVhdB3Xf\" /><figcaption>Terminal showing different DNS lookup results depending on location.</figcaption></figure><h4>Alternatives</h4><p>The alternative to this network-based approach is to move offered services closer to the customer. This can be achieved for example by deploying instances into selected cloud regions. To achieve this, the whole application stack needs to be deployed and some backend synchronization is needed\u200a\u2014\u200aas part of the Prezi, suite enables collaboration in-between multiple\u00a0users.</p><p>Serving from a single region reduces the complexity and streamlines deployment.</p><h3>Protection (AWS WAF and\u00a0Shield)</h3><p>While the internet is a wonderful place to connect, collaborate, be creative, and a lot more, it is at the same time also a place that attracts bad actors. It is widespread that public and well-known endpoints are the target of distributed denial of service (DDoS) attacks. Prezi leverages the combination of AWS Web Application Firewall (WAF) and Shield to protect the downstream infrastructure from these threat\u00a0vectors.</p><p>Every request that needs to reach Prezi infrastructure is evaluated through these components. Certain endpoints are protected via a specific rate limit to make sure they are not hammered.</p><p>For example, it does not make sense to send multiple requests for the login endpoint within a small amount of time. To protect sensible endpoints, the AWS WAF can respond with HTTP/429 (<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\">https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429</a>). <br />See the following screenshot of how a triggered rate limit looks in the browser\u00a0console:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*wRfL6hOiUq5NUAKw\" /><figcaption>Chrome Developer tools show one HTTP\u00a0response</figcaption></figure><p>On a bigger scale, the traffic flow is monitored by AWS Shield and blocked when a DDoS attack is detected. When Shield detects a DDoS from multiple traffic sources, those sources get\u00a0blocked.</p><h4>Alternatives</h4><p>Offering services over the Internet without any protection is a bad idea. Any public-facing IP is attracting traffic and if a company has reached a certain scale it attracts bad actors. There are alternative solutions and vendors like Cloudflare or Akamai that can offer the same protection service. As we run our workload on AWS the natural choice is AWS WAF as the integration is\u00a0easy.</p><h3>Access (ALB, EKS, API\u00a0Gateway)</h3><p>Requests allowed to enter reach the AWS-managed load balancer fleet that keeps track of routing those requests into the VPC environment that hosts the actual workload. The load balancer uses our public TLS certificate to offload HTTPS connections from customers.</p><p>The application load balancer (ALB) is used for routing based on the HTTP Host header. This means that based on the domain used, ALB can forward traffic into the isolated workload environment.</p><p>Running inside the Kubernetes fleet is a self-written API gateway. The purpose of this component is to build more detailed routes based on request paths or other identifiers. Most of the backends are based on Python and Scala. Those pods run inside the Kubernetes offering of AWS: Elastic Kubernetes Service. <br />Traffic is routed into these pods either by a WSGI conform application server in Python land or directly by the JVM for Scala services.</p><p>As the mentioned API gateway runs also inside Kubernetes, it can forward traffic to the target backend services based on different routing guidelines within the cluster network. The API gateway offers the flexibility to do advanced routing to the microservices based on configuration by the developers.</p><p>When you think back about the scope of AWS WAF usage, there was no check for malicious content and requests. We use a different web application firewall to check for bad requests and protection against cross-site scripting, injections, and other things that might harm Prezi\u200a\u2014\u200aor our customer.</p><h3>Content delivery (CloudFront)</h3><p>Prezi\u2019s main purpose is to deliver amazing presentations that most of the time contain visuals like images and gifs. They can be served via a content delivery network (CDN) that can reproach content closer to the customer.</p><p>Loading resources from a CDN does decrease the time in which the user waits for the resources to\u00a0appear.</p><p>Also on the cost focus, it is cheaper to serve content from CloudFront instead of serving it every time from the backend. This applies especially to assets like images that don\u2019t change\u00a0often.</p><p>Due to the deep integration into the ecosystem, in our setup, there is no other choice than CloudFront. Technically, it should also be doable with CloudFlare or any other CDN\u00a0vendor.</p><h3>Wrap up</h3><p>The article above describes the architecture Prezi uses to serve content to a global audience.</p><p>There are multiple different ways to serve traffic\u200a\u2014\u200aeven if running on\u00a0AWS.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=60fc9711702b\" width=\"1\" /><hr /><p><a href=\"https://engineering.prezi.com/how-prezi-serves-customer-traffic-60fc9711702b\">How Prezi Serves Customer Traffic</a> was originally published in <a href=\"https://engineering.prezi.com\">Prezi Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Postmark": {
    "title": "Your 2024 guide to Google & Yahoo\u2019s new requirements for email senders",
    "xmlUrl": "https://postmarkapp.com/blog/feed.atom",
    "htmlUrl": "https://postmarkapp.com/blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://postmarkapp.com/blog/feed.atom",
      "value": "Your 2024 guide to Google & Yahoo\u2019s new requirements for email senders"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://postmarkapp.com/blog/2024-gmail-yahoo-email-requirements"
      }
    ],
    "link": "https://postmarkapp.com/blog/2024-gmail-yahoo-email-requirements",
    "id": "https://postmarkapp.com/blog/2024-gmail-yahoo-email-requirements",
    "guidislink": false,
    "published": "2023-12-06T15:40:00-05:00",
    "published_parsed": [
      2023,
      12,
      6,
      20,
      40,
      0,
      2,
      340,
      0
    ],
    "updated": "2024-01-10T14:17:02-05:00",
    "updated_parsed": [
      2024,
      1,
      10,
      19,
      17,
      2,
      2,
      10,
      0
    ],
    "authors": [
      {
        "name": "Anna Ward",
        "email": "award@activecampaign.com"
      }
    ],
    "author_detail": {
      "name": "Anna Ward",
      "email": "award@activecampaign.com"
    },
    "author": "Anna Ward (award@activecampaign.com)",
    "tags": [
      {
        "term": "Email delivery",
        "scheme": null,
        "label": "Email delivery"
      }
    ],
    "content": [
      {
        "type": "text/html",
        "language": "en",
        "base": "https://postmarkapp.com/",
        "value": "<p>Google and Yahoo are turning what was once considered best practices for email authentication into mandatory requirements\u2014and senders who don\u2019t comply with the new requirements will start to see issues getting their emails delivered in 2024. If you want to make sure your emails keep making it to the inbox, follow these 5 steps.</p>\n\n      \n    \n      \n    \n      \n        <p>Since the announcement in October, 2023, the email industry has been buzzing about these collaborative announcements from <a href=\"https://blog.google/products/gmail/gmail-security-authentication-spam-protection/\">Google</a> and <a href=\"https://blog.postmaster.yahooinc.com/post/730172167494483968/more-secure-less-spam\">Yahoo</a>. These two receivers have agreed it's time to start enforcing new rules&nbsp;to help protect recipients from unwanted emails.</p>\n<h2 dir=\"ltr\">Why Google and Yahoo are changing the rules for email senders</h2>\n<p dir=\"ltr\">Properly authenticating your emails has always been a best practice, but not all senders are using the tools available to protect their emails. And that\u2019s a major problem: If senders don\u2019t properly authenticate their emails, they\u2019re making it incredibly easy for bad actors to impersonate domains and to send phishing\u2014and that will damage your sending reputation. </p>\n<p dir=\"ltr\">Gmail and Yahoo are on a mission to protect their users from spam and unwanted emails, but if senders fail to properly secure their systems and leave the door for exploitation wide open, that job is a whole lot harder. That\u2019s why Gmail and Yahoo decided that proper email authentication and following deliverability best practices are no longer a nice-to-have. If you want to ensure your emails continue to make it to the inbox, you\u2019ll have to comply with key best practices for email authentication and spam prevention. According to the inbox providers, that means:  <br /></p>\n<ol><li dir=\"ltr\"><p dir=\"ltr\"><strong>Authenticating your emails using DKIM, SPF, and DMARC.</strong><em><a href=\"https://postmarkapp.com/#get-ready-for-the-gmail-and-yahoo-changes-in-5-steps\"><br />We'll&nbsp;show you how to do that.</a></em>&nbsp;</p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>Reducing spam and maintaining a spam complaint rate under 0.3%.</strong><em><a href=\"https://postmarkapp.com/blog/2024-gmail-yahoo-email-requirements#5-register-your-domain-for-google-postmaster-tools-and-keep-your-spam-complaint-rates-under-0-3\"><br />Here's how you can keep an eye on that.</a></em></p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>Allowing people to unsubscribe by clicking just one link</strong>, and honor unsubscribes within two days.<em><br />Postmark handles <a href=\"https://postmarkapp.com/support/article/1217-why-broadcasts-require-an-unsubscribe-link\">unsubscribes for Broadcast messages</a> for you so you don't have to worry about that.</em><strong><br /></strong></p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>RFC 5322 compliance, PTR records, rDNS</strong><br /><em>Postmark has you covered here.</em></p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>Making sure your sending server IP addresses have&nbsp;valid reverse DNS records.</strong><em><br />Postmark has you covered here.</em></p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>Use a TLS connection for transmitting email.</strong><em></em><br /><em></em><em>Out of the box, Postmark supports opportunistic TLS for all outbound email, ensuring messages are encrypted in transit.</em></p></li></ol>\n<div><h2 dir=\"ltr\">Our take: These changes matter for every email sender</h2>\n<p dir=\"ltr\">Gmail and Yahoo\u2019s new requirements primarily target large <em>bulk</em> senders, and if you\u2019re diving into their requirements in detail, you\u2019ll see that some of them will only apply to high-volume senders who send more than 5,000 emails a day. If you\u2019re a smaller sender or only send <a href=\"https://postmarkapp.com/transactional-email\">transactional email</a>, you\u2019re less likely to be impacted by the changes\u2014but that doesn\u2019t mean you can <em>ignore</em> them. </p>\n<p dir=\"ltr\">What\u2019s required for large senders today will likely become a requirement for all senders in the future. Plus, operating in the \u201cbarely compliant\u201d zone, hoping the authorities don\u2019t look at you too closely because you\u2019re a small fish is rarely a good strategy. We believe this isn\u2019t just true when you do your taxes, but for sending email, too. </p>\n<p dir=\"ltr\">So whether you send one email or a few million, protecting your domains, avoiding spam, and following deliverability best practices is the key to keeping your subscribers safe and your email program healthy. </p><h2 dir=\"ltr\">Get ready for the Gmail and Yahoo changes in 5 steps</h2>\n<p dir=\"ltr\">If you\u2019re a Postmark customer, here are the top 5 steps we recommend you take now to make sure your emails keep making it to Google and Yahoo inboxes in 2024: </p><h3 dir=\"ltr\">1. Understand what domains you use for email sending today (and whether they\u2019re already authenticated)</h3>\n<p dir=\"ltr\">Before you can start sending email with Postmark, we ensure you own the mailboxes you want to send from. You can either validate a single email address (i.e. we just send you a confirmation link via email that you need to click on), or you can validate an entire domain by making some tweaks to your DNS records. </p>\n<p dir=\"ltr\">The first option is simpler, but as Gmail and Yahoo tighten their requirements, we encourage you to fully authenticate your sending domains. </p>\n<p dir=\"ltr\">Head over to the <a href=\"https://account.postmarkapp.com/signature_domains\">Sender Signatures</a> tab in your Postmark account to see what email addresses and domains are set up in your Postmark account\u2014and to see the status of each domain. </p>\n<p dir=\"ltr\">If you\u2019ve only verified individual email addresses, you\u2019ll see that you still need to take action to properly authenticate your domain: </p></div>\n\n      \n    \n      \n        \n                                                \n                    \n                        \n                    \n\n          \n          <figure>\n            <img alt=\"\" height=\"205\" src=\"https://craft-assets.postmarkapp.com/blog/outstanding-postmark-domain-authentication-tasks.png\" title=\"\" width=\"999\" />\n\n                          <figcaption>Seeing bright red in your Sender Signatures overview means open authentication tasks for you! \ud83d\udd34</figcaption>\n            \n          </figure>\n        \n      \n    \n      \n        <p dir=\"ltr\">Click on the DNS settings for a more detailed overview of your domain\u2019s status. If you see a row of green check marks here, your domain is properly authenticated (and you can jump ahead to <a href=\"https://postmarkapp.com/blog/2024-gmail-yahoo-email-requirements#4-set-up-dmarc\">task #4</a>). If your domain details look like this though, you\u2019ll want to take action to properly authenticate your sending domain:   <br /></p>\n\n      \n    \n      \n        \n                                                \n                    \n            \n                                            \n              \n            \n                        \n          \n\n          \n          <figure>\n            <img alt=\"\" height=\"493\" src=\"https://craft-assets.postmarkapp.com/blog/image2.png\" title=\"\" width=\"609\" />\n\n            \n          </figure>\n        \n      \n    \n      \n        <h3 dir=\"ltr\">2. Authenticate your mail with custom DKIM</h3>\n<p dir=\"ltr\">DKIM (<a href=\"https://postmarkapp.com/guides/dkim\">DomainKeys Identified Mail</a>) is an email authentication method that confirms your legitimacy and trustworthiness as a sender and verifies that the messages were not altered in transit. <strong>Going forward, Yahoo! and Gmail will require all email to be DKIM signed, </strong>so if you haven\u2019t already, now is the time to implement your custom DKIM signature.</p>\n<p dir=\"ltr\">This custom DKIM setup will require you (or whoever manages your domain) to add a TXT record to your domain\u2019s DNS. We show you what values you should include when you visit your domain\u2019s DNS setting in Postmark: <br /></p>\n\n      \n    \n      \n        \n                                                \n                    \n            \n                                            \n                                            \n            \n                        \n          \n\n          \n          <figure>\n            <img alt=\"\" height=\"329\" src=\"https://craft-assets.postmarkapp.com/blog/_normal2x/postmark-dkim-setup.png\" title=\"\" width=\"610\" />\n\n            \n          </figure>\n        \n      \n    \n      \n        <p dir=\"ltr\">For step-by-step instructions on how to validate your domain using DKIM, check out our <a href=\"https://postmarkapp.com/support/article/1091-how-do-i-set-up-dkim-for-postmark\">support article here</a>.</p>\n<h3 dir=\"ltr\">3. Authenticate your mail with custom SPF</h3>\n<p dir=\"ltr\">The Return-Path (also known as the \"envelope-from\") is the address where bounces and other email feedback are sent, and it's also the domain used for SPF authentication. It is specified by the Return-Path header in an email, and by default, the Return-Path for emails sent through Postmark is:</p>\n\n      \n    \n      \n        <pre><code class=\"language-markup\">Return-Path: &lt;pm_bounces@pm.mtasv.net&gt;</code></pre>\n\n      \n    \n      \n        <p dir=\"ltr\">Replacing Postmark\u2019s default Return-Path domain with your own sending domain means your messages are now SPF authenticated with your sending domain. This helps build your domain's reputation while also providing SPF domain alignment for your domain's DMARC policy.</p>\n\n\n<p dir=\"ltr\">You can <a href=\"https://postmarkapp.com/support/article/910-how-do-i-add-a-custom-return-path\">set up a custom Return-Path</a> by adding a CNAME record to your DNS that points to pm.mtasv.net. This is so that Postmark is still able to collect bounces and other feedback sent to that address.<br /></p>\n<h3 dir=\"ltr\">4. Set up DMARC</h3>\n<p dir=\"ltr\"><br /><a href=\"https://postmarkapp.com/guides/dmarc\">DMARC</a> is an email security standard that allows domain owners to monitor who\u2019s sending email using their domain and instructs email receivers (like Gmail) to approve, quarantine, or reject emails that aren\u2019t sent from an authenticated source. </p>\n<p dir=\"ltr\"><strong>Gmail and Yahoo will start requiring DMARC</strong> for all bulk senders who send more than 5,000 messages a day, but even if you aren\u2019t sending at that volume, we encourage you to set up DMARC anyway. Here\u2019s a step-by-step walkthrough of <a href=\"https://postmarkapp.com/guides/dmarc#how-do-i-setup-and-implement-dmarc-on-my-domain\">how you can set up DMARC for your domain</a>. Gmail and Yahoo don't require&nbsp;strict DMARC policies, so you can get started with a <a href=\"https://postmarkapp.com/guides/dmarc#how-do-i-setup-and-implement-dmarc-on-my-domain\">\u201cp=none\u201d policy</a>. With that policy in place, you can start monitoring who\u2019s sending email using your domain without receivers taking any action just yet.  <br /></p>\n\n      \n    \n      \n    \n      \n        <p><br /></p>\n<p>If you visit your domain details in Postmark at this point, you should be able to see what we call the magic trifecta of email authentication &#x1f510;&#x1f510;&#x1f510;.</p>\n\n      \n    \n      \n        \n                                                \n                    \n                        \n                    \n\n          \n          <figure>\n            <img alt=\"\" height=\"135\" src=\"https://craft-assets.postmarkapp.com/blog/successfully-authenticated.png\" title=\"\" width=\"479\" />\n\n            \n          </figure>\n        \n      \n    \n      \n        <h3 dir=\"ltr\">5. Register your domain for Google Postmaster Tools and keep your spam complaint rates under 0.3%</h3>\n<p dir=\"ltr\"><strong>Gmail will require senders to keep the spam complaint rate below 0.3%</strong>. If a larger share of your recipients mark your emails as spam, your sender reputation will decrease\u2014and you\u2019ll have a harder time reaching the inbox. </p>\n<p dir=\"ltr\">If you\u2019re a Postmark customer, you can see spam reports from most inbox providers in your Postmark account, but Gmail is a bit of a special case. Since Gmail doesn\u2019t provide a feedback loop\u2014that\u2019s the process for sharing spam report data with email providers\u2014you can\u2019t see spam reports from Gmail users in your Postmark account.</p>\n<p dir=\"ltr\">To keep an eye on your spam report data from Gmail users, you\u2019ll have to register your domain with a dedicated service, <a href=\"https://support.google.com/mail/answer/9981691?hl=en&amp;ref_topic=6259779&amp;sjid=11226422159337736043-EU\">Google\u2019s Postmaster Tools</a>. Registering your domain is free, only takes a minute, and once you\u2019re set up and Google has collected some email data, you can see aggregated spam report information in your Postmaster account.</p>\n\n      \n    \n      \n        \n                                                \n                    \n            \n                                            \n                                            \n            \n                        \n          \n\n          \n          <figure>\n            <img alt=\"\" height=\"224\" src=\"https://craft-assets.postmarkapp.com/blog/_normal2x/spam-rate-google-postmaster.png\" title=\"\" width=\"610\" />\n\n            \n          </figure>\n        \n      \n    \n      \n        <p dir=\"ltr\">If you see your user-reported spam rate grow beyond 0.1%, that shows that there\u2019s room for improvement. If you see your spam rate approach 0.3%, that\u2019s a sign you should urgently take action.  </p>\n<p dir=\"ltr\">Follow these <a href=\"https://postmarkapp.com/blog/why-are-my-emails-going-to-spam\">best practices to reduce your spam rate</a></p>\n<p dir=\"ltr\">If you have any additional questions about these changes, check out our FAQ below\u2014and if you don\u2019t find the answer to your question there, please reach out! We\u2019re here to help. <br /></p>\n<h2>FAQs</h2>\n<h3>Q. What happens if I send mail that doesn't meet these requirements?</h3>\n<p dir=\"ltr\">A. \u201cIf senders don\u2019t meet these requirements, messages might be rejected or delivered to recipients\u2019 spam folders,\u201d <a href=\"https://support.google.com/a/answer/14229414#zippy=%2Cwhat-happens-if-senders-dont-meet-the-requirements-in-the-sender-guidelines\">say</a> the folks at Gmail. <br /></p>\n<h3><strong>Q. When will these changes take place?</strong></h3>\n<p dir=\"ltr\">A. Changes are set to roll out gradually from February 2024, allowing for optimization and adjustments based on industry feedback.</p>\n<h3><strong>Q. Yahoo and Gmail mention additional requirements in their documents that you don\u2019t mention in the blog post above. Why do you not include them in your tips for senders?</strong></h3>\n<p dir=\"ltr\">A. If you\u2019re sending email with Postmark, we automatically take care of some of the crucial requirements that the inbox providers will be enforcing. For example, we automatically include a list-unsubscribe header to all Broadcast emails you might send with Postmark and handle FCrDNS (Forward-Confirmed Reverse DNS) for all our sending IPs. </p>\n<h3><strong>Q. How will this affect </strong><a href=\"https://postmarkapp.com/transactional-email\"><strong>transactional</strong></a><strong> senders?</strong></h3>\n<p dir=\"ltr\">A. While the changes primarily target bulk mail, transactional senders\u2014and especially those that are sending over 5000 messages a day\u2014should comply with requirements for enhanced deliverability and engagement. Distinguishing transactional and bulk mail is crucial, and Postmark makes that easy through <a href=\"https://postmarkapp.com/message-streams\">Message Streams</a>.</p>\n<h3><strong>Q. \u200b\u200bWhat is the bulk threshold for anti-spam policy?</strong><br /></h3>\n<p>A. Google will be requiring <a href=\"https://support.google.com/mail/answer/81126?hl=en#requirements-5k&amp;zippy=%2Crequirements-for-all-senders%2Crequirements-for-sending-or-more-messages-per-day\">specific rules for users who send over 5,000 messages a day</a>. However, users who send less than 5,000 messages will still need to authenticate their messages with SPF and DKIM. </p>\n<p dir=\"ltr\">Yahoo doesn't yet specify any particular volume for these categories of senders, nor do they specify a spam complaint rate threshold.</p>\n<h3><strong>Q. Could these requirements and our understanding of them change?</strong></h3>\n<p dir=\"ltr\">A. Absolutely - in fact, let's expect them to!</p>\n<p><br /></p>"
      }
    ],
    "summary": "<p>Google and Yahoo are turning what was once considered best practices for email authentication into mandatory requirements\u2014and senders who don\u2019t comply with the new requirements will start to see issues getting their emails delivered in 2024. If you want to make sure your emails keep making it to the inbox, follow these 5 steps.</p>\n\n      \n    \n      \n    \n      \n        <p>Since the announcement in October, 2023, the email industry has been buzzing about these collaborative announcements from <a href=\"https://blog.google/products/gmail/gmail-security-authentication-spam-protection/\">Google</a> and <a href=\"https://blog.postmaster.yahooinc.com/post/730172167494483968/more-secure-less-spam\">Yahoo</a>. These two receivers have agreed it's time to start enforcing new rules&nbsp;to help protect recipients from unwanted emails.</p>\n<h2 dir=\"ltr\">Why Google and Yahoo are changing the rules for email senders</h2>\n<p dir=\"ltr\">Properly authenticating your emails has always been a best practice, but not all senders are using the tools available to protect their emails. And that\u2019s a major problem: If senders don\u2019t properly authenticate their emails, they\u2019re making it incredibly easy for bad actors to impersonate domains and to send phishing\u2014and that will damage your sending reputation. </p>\n<p dir=\"ltr\">Gmail and Yahoo are on a mission to protect their users from spam and unwanted emails, but if senders fail to properly secure their systems and leave the door for exploitation wide open, that job is a whole lot harder. That\u2019s why Gmail and Yahoo decided that proper email authentication and following deliverability best practices are no longer a nice-to-have. If you want to ensure your emails continue to make it to the inbox, you\u2019ll have to comply with key best practices for email authentication and spam prevention. According to the inbox providers, that means:  <br /></p>\n<ol><li dir=\"ltr\"><p dir=\"ltr\"><strong>Authenticating your emails using DKIM, SPF, and DMARC.</strong><em><a href=\"https://postmarkapp.com/#get-ready-for-the-gmail-and-yahoo-changes-in-5-steps\"><br />We'll&nbsp;show you how to do that.</a></em>&nbsp;</p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>Reducing spam and maintaining a spam complaint rate under 0.3%.</strong><em><a href=\"https://postmarkapp.com/blog/2024-gmail-yahoo-email-requirements#5-register-your-domain-for-google-postmaster-tools-and-keep-your-spam-complaint-rates-under-0-3\"><br />Here's how you can keep an eye on that.</a></em></p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>Allowing people to unsubscribe by clicking just one link</strong>, and honor unsubscribes within two days.<em><br />Postmark handles <a href=\"https://postmarkapp.com/support/article/1217-why-broadcasts-require-an-unsubscribe-link\">unsubscribes for Broadcast messages</a> for you so you don't have to worry about that.</em><strong><br /></strong></p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>RFC 5322 compliance, PTR records, rDNS</strong><br /><em>Postmark has you covered here.</em></p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>Making sure your sending server IP addresses have&nbsp;valid reverse DNS records.</strong><em><br />Postmark has you covered here.</em></p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>Use a TLS connection for transmitting email.</strong><em></em><br /><em></em><em>Out of the box, Postmark supports opportunistic TLS for all outbound email, ensuring messages are encrypted in transit.</em></p></li></ol>\n<div><h2 dir=\"ltr\">Our take: These changes matter for every email sender</h2>\n<p dir=\"ltr\">Gmail and Yahoo\u2019s new requirements primarily target large <em>bulk</em> senders, and if you\u2019re diving into their requirements in detail, you\u2019ll see that some of them will only apply to high-volume senders who send more than 5,000 emails a day. If you\u2019re a smaller sender or only send <a href=\"https://postmarkapp.com/transactional-email\">transactional email</a>, you\u2019re less likely to be impacted by the changes\u2014but that doesn\u2019t mean you can <em>ignore</em> them. </p>\n<p dir=\"ltr\">What\u2019s required for large senders today will likely become a requirement for all senders in the future. Plus, operating in the \u201cbarely compliant\u201d zone, hoping the authorities don\u2019t look at you too closely because you\u2019re a small fish is rarely a good strategy. We believe this isn\u2019t just true when you do your taxes, but for sending email, too. </p>\n<p dir=\"ltr\">So whether you send one email or a few million, protecting your domains, avoiding spam, and following deliverability best practices is the key to keeping your subscribers safe and your email program healthy. </p><h2 dir=\"ltr\">Get ready for the Gmail and Yahoo changes in 5 steps</h2>\n<p dir=\"ltr\">If you\u2019re a Postmark customer, here are the top 5 steps we recommend you take now to make sure your emails keep making it to Google and Yahoo inboxes in 2024: </p><h3 dir=\"ltr\">1. Understand what domains you use for email sending today (and whether they\u2019re already authenticated)</h3>\n<p dir=\"ltr\">Before you can start sending email with Postmark, we ensure you own the mailboxes you want to send from. You can either validate a single email address (i.e. we just send you a confirmation link via email that you need to click on), or you can validate an entire domain by making some tweaks to your DNS records. </p>\n<p dir=\"ltr\">The first option is simpler, but as Gmail and Yahoo tighten their requirements, we encourage you to fully authenticate your sending domains. </p>\n<p dir=\"ltr\">Head over to the <a href=\"https://account.postmarkapp.com/signature_domains\">Sender Signatures</a> tab in your Postmark account to see what email addresses and domains are set up in your Postmark account\u2014and to see the status of each domain. </p>\n<p dir=\"ltr\">If you\u2019ve only verified individual email addresses, you\u2019ll see that you still need to take action to properly authenticate your domain: </p></div>\n\n      \n    \n      \n        \n                                                \n                    \n                        \n                    \n\n          \n          <figure>\n            <img alt=\"\" height=\"205\" src=\"https://craft-assets.postmarkapp.com/blog/outstanding-postmark-domain-authentication-tasks.png\" title=\"\" width=\"999\" />\n\n                          <figcaption>Seeing bright red in your Sender Signatures overview means open authentication tasks for you! \ud83d\udd34</figcaption>\n            \n          </figure>\n        \n      \n    \n      \n        <p dir=\"ltr\">Click on the DNS settings for a more detailed overview of your domain\u2019s status. If you see a row of green check marks here, your domain is properly authenticated (and you can jump ahead to <a href=\"https://postmarkapp.com/blog/2024-gmail-yahoo-email-requirements#4-set-up-dmarc\">task #4</a>). If your domain details look like this though, you\u2019ll want to take action to properly authenticate your sending domain:   <br /></p>\n\n      \n    \n      \n        \n                                                \n                    \n            \n                                            \n              \n            \n                        \n          \n\n          \n          <figure>\n            <img alt=\"\" height=\"493\" src=\"https://craft-assets.postmarkapp.com/blog/image2.png\" title=\"\" width=\"609\" />\n\n            \n          </figure>\n        \n      \n    \n      \n        <h3 dir=\"ltr\">2. Authenticate your mail with custom DKIM</h3>\n<p dir=\"ltr\">DKIM (<a href=\"https://postmarkapp.com/guides/dkim\">DomainKeys Identified Mail</a>) is an email authentication method that confirms your legitimacy and trustworthiness as a sender and verifies that the messages were not altered in transit. <strong>Going forward, Yahoo! and Gmail will require all email to be DKIM signed, </strong>so if you haven\u2019t already, now is the time to implement your custom DKIM signature.</p>\n<p dir=\"ltr\">This custom DKIM setup will require you (or whoever manages your domain) to add a TXT record to your domain\u2019s DNS. We show you what values you should include when you visit your domain\u2019s DNS setting in Postmark: <br /></p>\n\n      \n    \n      \n        \n                                                \n                    \n            \n                                            \n                                            \n            \n                        \n          \n\n          \n          <figure>\n            <img alt=\"\" height=\"329\" src=\"https://craft-assets.postmarkapp.com/blog/_normal2x/postmark-dkim-setup.png\" title=\"\" width=\"610\" />\n\n            \n          </figure>\n        \n      \n    \n      \n        <p dir=\"ltr\">For step-by-step instructions on how to validate your domain using DKIM, check out our <a href=\"https://postmarkapp.com/support/article/1091-how-do-i-set-up-dkim-for-postmark\">support article here</a>.</p>\n<h3 dir=\"ltr\">3. Authenticate your mail with custom SPF</h3>\n<p dir=\"ltr\">The Return-Path (also known as the \"envelope-from\") is the address where bounces and other email feedback are sent, and it's also the domain used for SPF authentication. It is specified by the Return-Path header in an email, and by default, the Return-Path for emails sent through Postmark is:</p>\n\n      \n    \n      \n        <pre><code class=\"language-markup\">Return-Path: &lt;pm_bounces@pm.mtasv.net&gt;</code></pre>\n\n      \n    \n      \n        <p dir=\"ltr\">Replacing Postmark\u2019s default Return-Path domain with your own sending domain means your messages are now SPF authenticated with your sending domain. This helps build your domain's reputation while also providing SPF domain alignment for your domain's DMARC policy.</p>\n\n\n<p dir=\"ltr\">You can <a href=\"https://postmarkapp.com/support/article/910-how-do-i-add-a-custom-return-path\">set up a custom Return-Path</a> by adding a CNAME record to your DNS that points to pm.mtasv.net. This is so that Postmark is still able to collect bounces and other feedback sent to that address.<br /></p>\n<h3 dir=\"ltr\">4. Set up DMARC</h3>\n<p dir=\"ltr\"><br /><a href=\"https://postmarkapp.com/guides/dmarc\">DMARC</a> is an email security standard that allows domain owners to monitor who\u2019s sending email using their domain and instructs email receivers (like Gmail) to approve, quarantine, or reject emails that aren\u2019t sent from an authenticated source. </p>\n<p dir=\"ltr\"><strong>Gmail and Yahoo will start requiring DMARC</strong> for all bulk senders who send more than 5,000 messages a day, but even if you aren\u2019t sending at that volume, we encourage you to set up DMARC anyway. Here\u2019s a step-by-step walkthrough of <a href=\"https://postmarkapp.com/guides/dmarc#how-do-i-setup-and-implement-dmarc-on-my-domain\">how you can set up DMARC for your domain</a>. Gmail and Yahoo don't require&nbsp;strict DMARC policies, so you can get started with a <a href=\"https://postmarkapp.com/guides/dmarc#how-do-i-setup-and-implement-dmarc-on-my-domain\">\u201cp=none\u201d policy</a>. With that policy in place, you can start monitoring who\u2019s sending email using your domain without receivers taking any action just yet.  <br /></p>\n\n      \n    \n      \n    \n      \n        <p><br /></p>\n<p>If you visit your domain details in Postmark at this point, you should be able to see what we call the magic trifecta of email authentication &#x1f510;&#x1f510;&#x1f510;.</p>\n\n      \n    \n      \n        \n                                                \n                    \n                        \n                    \n\n          \n          <figure>\n            <img alt=\"\" height=\"135\" src=\"https://craft-assets.postmarkapp.com/blog/successfully-authenticated.png\" title=\"\" width=\"479\" />\n\n            \n          </figure>\n        \n      \n    \n      \n        <h3 dir=\"ltr\">5. Register your domain for Google Postmaster Tools and keep your spam complaint rates under 0.3%</h3>\n<p dir=\"ltr\"><strong>Gmail will require senders to keep the spam complaint rate below 0.3%</strong>. If a larger share of your recipients mark your emails as spam, your sender reputation will decrease\u2014and you\u2019ll have a harder time reaching the inbox. </p>\n<p dir=\"ltr\">If you\u2019re a Postmark customer, you can see spam reports from most inbox providers in your Postmark account, but Gmail is a bit of a special case. Since Gmail doesn\u2019t provide a feedback loop\u2014that\u2019s the process for sharing spam report data with email providers\u2014you can\u2019t see spam reports from Gmail users in your Postmark account.</p>\n<p dir=\"ltr\">To keep an eye on your spam report data from Gmail users, you\u2019ll have to register your domain with a dedicated service, <a href=\"https://support.google.com/mail/answer/9981691?hl=en&amp;ref_topic=6259779&amp;sjid=11226422159337736043-EU\">Google\u2019s Postmaster Tools</a>. Registering your domain is free, only takes a minute, and once you\u2019re set up and Google has collected some email data, you can see aggregated spam report information in your Postmaster account.</p>\n\n      \n    \n      \n        \n                                                \n                    \n            \n                                            \n                                            \n            \n                        \n          \n\n          \n          <figure>\n            <img alt=\"\" height=\"224\" src=\"https://craft-assets.postmarkapp.com/blog/_normal2x/spam-rate-google-postmaster.png\" title=\"\" width=\"610\" />\n\n            \n          </figure>\n        \n      \n    \n      \n        <p dir=\"ltr\">If you see your user-reported spam rate grow beyond 0.1%, that shows that there\u2019s room for improvement. If you see your spam rate approach 0.3%, that\u2019s a sign you should urgently take action.  </p>\n<p dir=\"ltr\">Follow these <a href=\"https://postmarkapp.com/blog/why-are-my-emails-going-to-spam\">best practices to reduce your spam rate</a></p>\n<p dir=\"ltr\">If you have any additional questions about these changes, check out our FAQ below\u2014and if you don\u2019t find the answer to your question there, please reach out! We\u2019re here to help. <br /></p>\n<h2>FAQs</h2>\n<h3>Q. What happens if I send mail that doesn't meet these requirements?</h3>\n<p dir=\"ltr\">A. \u201cIf senders don\u2019t meet these requirements, messages might be rejected or delivered to recipients\u2019 spam folders,\u201d <a href=\"https://support.google.com/a/answer/14229414#zippy=%2Cwhat-happens-if-senders-dont-meet-the-requirements-in-the-sender-guidelines\">say</a> the folks at Gmail. <br /></p>\n<h3><strong>Q. When will these changes take place?</strong></h3>\n<p dir=\"ltr\">A. Changes are set to roll out gradually from February 2024, allowing for optimization and adjustments based on industry feedback.</p>\n<h3><strong>Q. Yahoo and Gmail mention additional requirements in their documents that you don\u2019t mention in the blog post above. Why do you not include them in your tips for senders?</strong></h3>\n<p dir=\"ltr\">A. If you\u2019re sending email with Postmark, we automatically take care of some of the crucial requirements that the inbox providers will be enforcing. For example, we automatically include a list-unsubscribe header to all Broadcast emails you might send with Postmark and handle FCrDNS (Forward-Confirmed Reverse DNS) for all our sending IPs. </p>\n<h3><strong>Q. How will this affect </strong><a href=\"https://postmarkapp.com/transactional-email\"><strong>transactional</strong></a><strong> senders?</strong></h3>\n<p dir=\"ltr\">A. While the changes primarily target bulk mail, transactional senders\u2014and especially those that are sending over 5000 messages a day\u2014should comply with requirements for enhanced deliverability and engagement. Distinguishing transactional and bulk mail is crucial, and Postmark makes that easy through <a href=\"https://postmarkapp.com/message-streams\">Message Streams</a>.</p>\n<h3><strong>Q. \u200b\u200bWhat is the bulk threshold for anti-spam policy?</strong><br /></h3>\n<p>A. Google will be requiring <a href=\"https://support.google.com/mail/answer/81126?hl=en#requirements-5k&amp;zippy=%2Crequirements-for-all-senders%2Crequirements-for-sending-or-more-messages-per-day\">specific rules for users who send over 5,000 messages a day</a>. However, users who send less than 5,000 messages will still need to authenticate their messages with SPF and DKIM. </p>\n<p dir=\"ltr\">Yahoo doesn't yet specify any particular volume for these categories of senders, nor do they specify a spam complaint rate threshold.</p>\n<h3><strong>Q. Could these requirements and our understanding of them change?</strong></h3>\n<p dir=\"ltr\">A. Absolutely - in fact, let's expect them to!</p>\n<p><br /></p>"
  },
  "SitePoint": {
    "title": "Accelerating the Cloud: The Final Steps",
    "xmlUrl": "https://www.sitepoint.com/feed/",
    "htmlUrl": "https://sitepoint.com",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.sitepoint.com/sitepoint.rss",
      "value": "Accelerating the Cloud: The Final Steps"
    },
    "summary": "<a href=\"https://www.sitepoint.com/accelerating-the-cloud-the-final-steps/?utm_source=rss\" rel=\"nofollow\" title=\"Accelerating the Cloud: The Final Steps\">\n              <img alt=\"\" class=\"webfeedsFeaturedVisual\" src=\"https://uploads.sitepoint.com/wp-content/uploads/2024/01/1704993254d71df428-b87d-4c87-bfbf-e9a41c5006fc.webp\" style=\"display: block; margin: auto; margin-bottom: 5px;\" />\n            </a>\n            We explore how to approach cloud native application development and where to start the process within your organization.\n            <p>\n              Continue reading\n              <a href=\"https://www.sitepoint.com/accelerating-the-cloud-the-final-steps/?utm_source=rss\" rel=\"nofollow\">Accelerating the Cloud: The Final Steps</a>\n              on <a href=\"https://www.sitepoint.com\" rel=\"nofollow\">SitePoint</a>.\n            </p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.sitepoint.com/sitepoint.rss",
      "value": "<a href=\"https://www.sitepoint.com/accelerating-the-cloud-the-final-steps/?utm_source=rss\" rel=\"nofollow\" title=\"Accelerating the Cloud: The Final Steps\">\n              <img alt=\"\" class=\"webfeedsFeaturedVisual\" src=\"https://uploads.sitepoint.com/wp-content/uploads/2024/01/1704993254d71df428-b87d-4c87-bfbf-e9a41c5006fc.webp\" style=\"display: block; margin: auto; margin-bottom: 5px;\" />\n            </a>\n            We explore how to approach cloud native application development and where to start the process within your organization.\n            <p>\n              Continue reading\n              <a href=\"https://www.sitepoint.com/accelerating-the-cloud-the-final-steps/?utm_source=rss\" rel=\"nofollow\">Accelerating the Cloud: The Final Steps</a>\n              on <a href=\"https://www.sitepoint.com\" rel=\"nofollow\">SitePoint</a>.\n            </p>"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.sitepoint.com/accelerating-the-cloud-the-final-steps/?utm_source=rss"
      }
    ],
    "link": "https://www.sitepoint.com/accelerating-the-cloud-the-final-steps/?utm_source=rss",
    "id": "/?p=440113",
    "guidislink": false,
    "tags": [
      {
        "term": "Web",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Dave Neary"
      }
    ],
    "author": "Dave Neary",
    "author_detail": {
      "name": "Dave Neary"
    },
    "published": "Wed, 10 Jan 2024 22:15:13 GMT",
    "published_parsed": [
      2024,
      1,
      10,
      22,
      15,
      13,
      2,
      10,
      0
    ]
  },
  "Oursky": {
    "title": "How to Build a Name and Address Parser: Regex vs Named Entity Recognition (NER)",
    "xmlUrl": "https://code.oursky.com/feed/",
    "htmlUrl": "https://code.oursky.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://code.oursky.com/feed/",
      "value": "How to Build a Name and Address Parser: Regex vs Named Entity Recognition (NER)"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://code.oursky.com/how-to-build-a-name-and-address-parser-regex-vs-named-entity-recognition-ner/"
      }
    ],
    "link": "https://code.oursky.com/how-to-build-a-name-and-address-parser-regex-vs-named-entity-recognition-ner/",
    "comments": "https://code.oursky.com/how-to-build-a-name-and-address-parser-regex-vs-named-entity-recognition-ner/#respond",
    "authors": [
      {
        "name": "Elliot Wong"
      }
    ],
    "author": "Elliot Wong",
    "author_detail": {
      "name": "Elliot Wong"
    },
    "published": "Fri, 05 Mar 2021 09:08:41 +0000",
    "published_parsed": [
      2021,
      3,
      5,
      9,
      8,
      41,
      4,
      64,
      0
    ],
    "tags": [
      {
        "term": "Artificial Intelligence",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://code.oursky.com/?p=796",
    "guidislink": false,
    "summary": "<p>The post <a href=\"https://code.oursky.com/how-to-build-a-name-and-address-parser-regex-vs-named-entity-recognition-ner/\" rel=\"nofollow\">How to Build a Name and Address Parser: Regex vs Named Entity Recognition (NER)</a> appeared first on <a href=\"https://code.oursky.com\" rel=\"nofollow\">Oursky Code Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://code.oursky.com/feed/",
      "value": "<p>The post <a href=\"https://code.oursky.com/how-to-build-a-name-and-address-parser-regex-vs-named-entity-recognition-ner/\" rel=\"nofollow\">How to Build a Name and Address Parser: Regex vs Named Entity Recognition (NER)</a> appeared first on <a href=\"https://code.oursky.com\" rel=\"nofollow\">Oursky Code Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://code.oursky.com/feed/",
        "value": "<p>In this article, we&#8217;ll look into how addresses and names can be parsed from physical documents, like a letter or bank statement. We&#8217;ll assume that the text/content is already pulled from document images through optical character recognition (OCR) services. <strong>Our focus here is how to obtain the address and name from these unstructured strings</strong>,<strong> </strong>in scanned forms/document.</p>\n\n\n\n<p>Address and name are in fact closely related.  Often, parts of a name are seen in a street address. Here\u2019s a\u00a0<a href=\"https://en.wikipedia.org/wiki/Category:Lists_of_roads_named_after_people\">wiki list of roads named after people</a> to visualize the statement a bit better.</p>\n\n\n\n<p>Regular expressions (regex) naturally come to mind when searching in strings. So, let\u2019s kick-start with some of them that match address and names! Below we have some code snippets parsing text in Python as examples.</p>\n\n\n\n<p>Disclaimer: Only instances represented by English alphabets are considered here.</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"name-regex\">Name Regex</h2>\n\n\n\n<p>We&#8217;re first discussing name regex intentionally, just because the it often includes a human name. It\u2019d be clearer for you if we talk about names first. </p>\n\n\n\n<p>The regex here can be applied to a first or last name text field. We&#8217;ll focus on a data field for human name and ignore details differentiating first names and surnames.</p>\n\n\n\n<p>The pattern in more common names like \u201cJames,\u201d \u201cWilliam,\u201d \u201cElizabeth,\u201d \u201cMary,\u201d are trivial. They can be easily matched with . How about those with more variations? There are plenty of languages with different naming conventions. We\u2019ll try to group different types of names into basic groups:</p>\n\n\n\n<ul><li>Hyphenated names, e.g., Lloyd-Atkinson, Smith-Jones</li><li>Names with apostrophes, e.g., D&#8217;Angelo, D&#8217;Esposito</li><li>Names with spaces in-between, e.g., Van der Humpton, De Jong, Di Lorenzo</li></ul>\n\n\n\n<p>Carry on reading to see how text extraction can be done with a regex.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"regex\">Regex</h3>\n\n\n\n<p>This regex should do the trick for <strong>most</strong> names:</p>\n\n\n\n<pre class=\"wp-block-preformatted\">r'^+$'</pre>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"code-snippet\">Code Snippet</h3>\n\n\n\n<p>You can sub in other values in the <code>test</code> list to see if they can be matched against this regex:</p>\n\n\n\n\n\n\n\n<h2 class=\"wp-block-heading\" id=\"address-regex\">Address Regex</h2>\n\n\n\n<p>For geographical or language reasons, the format of an address varies all over the world. Here&#8217;s a <a href=\"https://en.wikipedia.org/wiki/Address\">long list</a> describing these formats per country. </p>\n\n\n\n<p>Since address format is too varied, it&#8217;s impossible for a regex to cover all these patterns. Even if there is one that manages to do so, it&#8217;d be very challenging to test, as the testing data set has to be more than enormous.</p>\n\n\n\n<p>Our regex for address will only cover some of the common ones in English-speaking countries. It should do the trick for addresses that start with a number, like &#8220;123 Sesame Street.&#8221; It&#8217;s from this <a href=\"https://community.alteryx.com/t5/Alteryx-Designer-Discussions/RegEx-Addresses-different-formats-and-headaches/m-p/360176/highlight/true#M66106\">discussion thread</a> where it received positive feedback.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"regex-2\">Regex</h3>\n\n\n\n<pre class=\"wp-block-preformatted\">^(\\d+) ?((?= ))? (.*?) ([^ ]+?) ?((?&lt;= )APT)? ?((?&lt;= )\\d*)?$</pre>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"code-snippet-2\">Code Snippet</h3>\n\n\n\n\n\n\n\n<h2 class=\"wp-block-heading\" id=\"limitations-of-using-regex-to-extract-names-and-addresses\">Limitations of Using Regex to Extract Names and Addresses</h2>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"dealing-with-uncommon-values\">Dealing with Uncommon Values</h3>\n\n\n\n<p>While these regexes may be able to validate a large portion of names and addresses, they will likely miss out on some, especially those that are non-English or newly introduced. For example, Spanish or German names weren&#8217;t considered thoroughly here, probably because the developer wasn&#8217;t familiar with these languages.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"no-pattern-to-follow\">No Pattern to Follow</h3>\n\n\n\n<p>Regex works well against data that has a strict pattern to follow, where neither name nor address belongs to a category. They&#8217;re ever-changing, with new instances created every day, along with a massive variation. Regex isn&#8217;t really going to do a good job on extracting them. In short, they are not &#8220;regular&#8221; enough with no intuitive patterns to follow.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"unable-to-find-the-likeliest-name\">Unable to Find the Likeliest Name</h3>\n\n\n\n<p>Regex also lacks the ability to differentiate to find the &#8220;most likely&#8221; name. Let&#8217;s take a step back and assume there&#8217;s a regex R that can extract names flawlessly from documents that scanned via an OCR data extraction service. We want to get the recipient&#8217;s name (from a letter from Ann to Mary):</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: plain; title: ; notranslate\">\nDear Mary,\n\nHow have you been these days? Lately, Tom and I have been planning to travel around the World.\n...\n...\n...\n\nLove,\nAnn\n</pre></div>\n\n\n<p>There are three names in the letter \u2014 Mary, Tom, and Ann. If you use R to find names, you&#8217;ll end up with a list of the three names,  but you won&#8217;t be receiving just Mary, the recipient.</p>\n\n\n\n<p>So, how can this be achieved? We can give each name a score based on:</p>\n\n\n\n<ul><li>Its position on the document</li><li>How &#8220;naive&#8221; it is (i.e., how often it appeared in a training data set)</li><li>Likelihood of a name to be the single target from a training data set</li></ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"unable-to-differentiate-name-and-address\">Unable to Differentiate Name and Address</h3>\n\n\n\n<p>On paper, names and address can be the same thing. &#8220;John&#8221; can be a name, or it can also be a part of an address, like &#8220;John Street&#8221;. Regexes don&#8217;t have the capability to see this difference and react accordingly. We surely don&#8217;t want to have results &#8220;Sesame Street&#8221; as a name and &#8220;Mr. Sherlock Holmes&#8221; as a street address!</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"a-quick-sum-up\">A Quick Sum up</h3>\n\n\n\n<p>Do bear in mind that using regex for name validation isn&#8217;t really a good idea, as new names are generated at a rate that a regex won&#8217;t be able to keep up to. Regexes won&#8217;t be able to extract address from text accurately as well, due to the same reason.</p>\n\n\n\n<p>No need to worry though! Carry on reading, we got you covered!</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"classify-named-entity-with-bert\">Classify Named-Entity with BERT</h2>\n\n\n\n<p>What we have here is a <a href=\"https://en.wikipedia.org/wiki/Named-entity_recognition\">named entity recognition (NER)</a> problem, where we&#8217;ll have to locate then obtain names and addresses from a bunch of unstructured string (from documents that use OCR).</p>\n\n\n\n<p>We assume you have the technical know-how behind some core machine learning and neural network concepts. We&#8217;ll focus on our flow to recognize target named entities {name}, {address}, and {telephone number}. Yep, apart from name and address, telephone number is also our target. We didn&#8217;t provide a regex for that because its format varies in length and geographical code. </p>\n\n\n\n<p>If you find the definitions or technical details confusing, we&#8217;ll provide in-place links for your convenience to get to speed with background knowledge.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"example-acceptance-letter-for-harry-potter\">Example: Acceptance Letter for Harry Potter</h3>\n\n\n\n<p>We&#8217;ll use an acceptance letter from Hogwarts to Harry Potter as an example throughout this part. Our target is to get all names and the receipt address from this letter.</p>\n\n\n\n<pre class=\"wp-block-preformatted\">Mr. H Potter\nThe Cupboard under the Stairs,\n4 Privet Drive,\nLittle Whinging,\nSurrey\n\nDear Mr Potter,\n\nWe are pleased to inform you that you have been accepted at&nbsp;Hogwarts School of Witchcraft and Wizardry. Please find enclosed a&nbsp;list&nbsp;of all necessary books and equipment.\n\nTerm begins on&nbsp;1 September. We await your owl by no later than&nbsp;31 July.\n\nYours sincerely,\nMinerva McGonagall\nDeputy Headmistress</pre>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.oursky.com/wp-content/uploads/2021/03/photo-1515816052601-210d5501d471.jpeg\"><img alt=\"Name and Address Parser Implemented with NER on a Harry Potter Acceptance Letter\" class=\"wp-image-806\" height=\"870\" src=\"https://code.oursky.com/wp-content/uploads/2021/03/photo-1515816052601-210d5501d471-1160x870.jpeg\" width=\"1160\" /></a></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"output-tagged-tokens-with-iob\">Output: Tagged Tokens with IOB</h3>\n\n\n\n<p>Our output will be a list of tagged tokens using the <a href=\"https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\">inside-outside-beginning (IOB)</a> format. Our targets are {name}, {address}, and {telephone number}, so here we have seven tags \u2014 beginning (B) and inside (I) for each target, and outside (O), meaning a token isn&#8217;t what we&#8217;re looking for. LOC, which stands for location, is just the address in this case.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.oursky.com/wp-content/uploads/2021/03/Screenshot-2021-03-03-at-6.28.29-PM.png\"><img alt=\"\" class=\"wp-image-804\" height=\"224\" src=\"https://code.oursky.com/wp-content/uploads/2021/03/Screenshot-2021-03-03-at-6.28.29-PM-1160x224.png\" width=\"1160\" /></a><figcaption>IOB tags for { name, address, telephone number }</figcaption></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"token-classifier-on-top-of-bert\">Token Classifier on Top of Bert</h3>\n\n\n\n<p><a href=\"https://arxiv.org/pdf/1810.04805.pdf\">Bidirectional Encoder Representations from Transformers (BERT)</a> is quite popular these days due to its <a href=\"https://en.wikipedia.org/wiki/State_of_the_art\">state-of-the-art</a>&nbsp;performance in handling Natural Language Processing (NLP) tasks. BERT is a sequence-to-sequence, transformer-based feature extractor, whose output of embeddings can be passed to a downstream classifier for further processing. If you&#8217;re not familiar with what BERT is and how it works, check out this <a href=\"http://jalammar.github.io/illustrated-bert/\">amazing article</a>.</p>\n\n\n\n<p>The recommended approach to an NER issue is to add a token classifier on top of BERT (which is pre-trained when you download it). We can architect our solution following that, as shown below:</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://code.oursky.com/wp-content/uploads/2021/03/Screenshot-2021-03-03-at-6.37.42-PM.png\"><img alt=\"BERT NER is usually the go-to option nowadays\" class=\"wp-image-803\" height=\"776\" src=\"https://code.oursky.com/wp-content/uploads/2021/03/Screenshot-2021-03-03-at-6.37.42-PM-1160x776.png\" width=\"1160\" /></a><figcaption>Inputs of &#8220;accepted at hogwarts school&#8221; fed through bert + token classifier to become outputs of token tags</figcaption></figure>\n\n\n\n<p>Our code was implemented with classes provided by <a href=\"https://huggingface.co/transformers/index.html\">Huggingface</a>. Text sequences are first fed to a <a href=\"https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer\">PreTrainedTokenizer</a> before the tokens are passed through <a href=\"https://huggingface.co/transformers/model_doc/bert.html#transformers.TFBertForTokenClassification\">TFBertForTokenClassification</a>. Our transformers were developed with <a href=\"https://www.tensorflow.org/\">TensorFlow</a>.</p>\n\n\n\n<p>TFBertForTokenClassification includes an underlying pre-trained BERT model, and a top token classifier processing the embeddings incoming from below. As suggested in Huggingface&#8217;s documentation, TFBertForTokenClassification is created <em>for Named-Entity-Recognition (NER) tasks.</em></p>\n\n\n\n<p>The output of each input token, say that of &#8220;Hogwarts,&#8221; is a logit of our seven tags {B-PER, I-PER, B-LOC, I-LOC, B-TEL, I-TEL, O}. The logit represents how likely the token belongs to a tag. Post-processing functions are applied to the logit, before the final tagging result of a token is obtained via an ARGMAX function.</p>\n\n\n\n<p>So the sequence, [&#8220;accepted&#8221;, &#8220;at&#8221;, &#8220;hogwarts&#8221;, &#8220;school&#8221;] will result in a corresponding tag list [&#8220;O&#8221;, &#8220;O&#8221;, &#8220;B-LOC&#8221;, &#8220;I-LOC&#8221;]. We should end up with the address words, &#8220;The Cupboard under the Stairs&#8230;&#8221;, all tagged as &#8220;I-LOC&#8221;, except the first being a &#8220;B-LOC&#8221;.</p>\n\n\n\n<p>For name tokens like [&#8220;Mr&#8221;, &#8220;Potter&#8221;], they should end up with these tags \u2014 [&#8220;B-PER&#8221;, &#8220;I-PER&#8221;].</p>\n\n\n\n<p>Our main effort for developing this solution was heavily invested in two parts. First, fine-tuning with synthetic data sets. Second, differentiating tags with post-processing functions. For configurations and training on the Huggingface, we mostly followed their <a href=\"https://huggingface.co/transformers/training.html\">guide</a>.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"pseudo-code\">Pseudo Code</h3>\n\n\n\n<pre class=\"wp-block-preformatted\">for text_chunks in input:\n  regroup words in text_chunks so that they don\u2019t get separated during the tokenization stage\n  for word in regrouped_text_chunks:\n    tokenize the word\n    classify a token to obtain a logit</pre>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"fine-tuning-with-synthetic-data-sets\">Fine-Tuning with Synthetic Data Sets</h3>\n\n\n\n<p>The TFBertForTokenClassification was developed from more general data. To boost its classification accuracy on parsing address, name, and telephone number from our data set, we fine-tuned it with our own data sets.</p>\n\n\n\n<p>Since we&#8217;re looking to get the targets from letters such as bank statements, bills, and invoices, we collected a large of amount of them and fed it to the model for fine-tuning. If you&#8217;re looking to construct a BERT model for some NER task on some specific text formats, prepare fine-tuning data sets accordingly!</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"differentiate-tags-with-post-processing-functions\">Differentiate Tags with Post-Processing Functions</h3>\n\n\n\n<p>As we covered earlier, addresses and human names are so similar that, at times, it&#8217;s hard to tell which is which. The issue we faced was that often, a token has a high likelihood of being both a location (i.e., address) and a person&#8217;s name. </p>\n\n\n\n<p>To separate them in these cases, we implemented several measures.</p>\n\n\n\n<h4 class=\"wp-block-heading\" id=\"look-by-keywords\">Look by Keywords</h4>\n\n\n\n<p>An address usually contains location or street keywords like &#8220;road&#8221;, &#8220;block&#8221;, &#8220;shop&#8221;, or &#8220;level. That&#8217;s a big indicator on a token being an address.</p>\n\n\n\n<p>A name often comes with a title like &#8220;Mr&#8221; or &#8220;Ms&#8221;. So when we find them near the token, it&#8217;s likely that the token is a name. Let&#8217;s take the signature in the acceptance letter as an example:</p>\n\n\n\n<pre class=\"wp-block-preformatted\" id=\"block-5ba201db-f552-4e8d-a387-6f24756ee813\">Minerva McGonagall\nDeputy Headmistress</pre>\n\n\n\n<p>&#8220;Minerva McGonagall&#8221; has to be a name, as indicated by her position, &#8220;Deputy Headmistress,&#8221; at Hogwarts. Without her position, it&#8217;d be hard to tell. &#8220;Minerva McGonagall Street&#8221; sounds quite natural to me!</p>\n\n\n\n<p>These keywords can be used to mark down a token as well. Let&#8217;s say the current token has the highest probability of being a name, but there&#8217;s a word &#8220;street&#8221; right next to it. In this case, the score of this token being a name gets marked down.</p>\n\n\n\n<h4 class=\"wp-block-heading\" id=\"word-length\">Word Length</h4>\n\n\n\n<p>We also review the logits by the word&#8217;s length. If a word has a length of 12, it&#8217;s quite likely to be an address instead of a human name. Long names aren&#8217;t really that rare though. After all, we&#8217;re looking at likelihood here.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"model-trained-for-you-out-of-the-box\">Model Trained for You, Out of the Box</h3>\n\n\n\n<p>Even if you are familiar with machine learning concepts, enormous amount of effort will be required to collect enough and good-enough data for fine-tuning/training purposes. You&#8217;d also need to learn the patterns (not obvious at times) between input tokens in order to write correct and effective post-processing logics.</p>\n\n\n\n<p>Some good news. The classifier we have just covered is actually available to everyone, since its a feature of our very own data extraction service <a href=\"https://www.formx.ai/\">FormX</a>.  Name and address parsers can be applied to:</p>\n\n\n\n<ol><li>document-level under <em>Auto Extraction Item</em>, </li><li>only a selected region on documents, under <em>Detection Region</em></li></ol>\n\n\n\n<p>Sign up a free account and try it out, along with a vast range of other functions!</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"address-and-name-regexes-are-not-good-enough-for-data-extraction\">Address and Name Regexes Are Not Good Enough for Data Extraction</h2>\n\n\n\n<p>So, we&#8217;ve covered regular expressions here as a shorthand way for getting names and addresses. You&#8217;d think they&#8217;d allow you to parse all possible strings, but, <em>Houston, we have a problem</em>. Regexes have inherent inabilities to deal with edge values, rank candidates by likelihood, and distinguish between values.</p>\n\n\n\n<p>Consequently we adopted a BERT based AI model as a way to overcome regex&#8217;s limitations. You&#8217;ll need to leverage machine learning- and NLP-based capabilities, as well as prepare a bunch of data if you choose that path. The research and development (R&amp;D) stage takes serious amount of time, therefore do think thoroughly before you make the decision. Always consider their trade-offs when you come across these options \u2014 their complexity, accuracy, and maintainability.</p>\n\n\n\n<p>That&#8217;s the end of this article, do you have other solutions towards this problem in mind? Feel free to let us know your thoughts by commenting below! Cheers and see you next time. <img alt=\"\ud83d\ude42\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/1f642.png\" style=\"height: 1em;\" /></p>\n<p>The post <a href=\"https://code.oursky.com/how-to-build-a-name-and-address-parser-regex-vs-named-entity-recognition-ner/\" rel=\"nofollow\">How to Build a Name and Address Parser: Regex vs Named Entity Recognition (NER)</a> appeared first on <a href=\"https://code.oursky.com\" rel=\"nofollow\">Oursky Code Blog</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://code.oursky.com/how-to-build-a-name-and-address-parser-regex-vs-named-entity-recognition-ner/feed/",
    "slash_comments": "0",
    "post-id": "796"
  },
  "Mixpanel": {
    "title": "How Mixpanel Built a \u201cFast Lane\u201d for Our Modern Data Stack",
    "xmlUrl": "https://engineering.mixpanel.com/feed/",
    "htmlUrl": "https://code.mixpanel.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.mixpanel.com/feed",
      "value": "How Mixpanel Built a \u201cFast Lane\u201d for Our Modern Data Stack"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.mixpanel.com/how-mixpanel-built-a-fast-lane-for-our-modern-data-stack-680701736f8c?source=rss----b5de3443ad1f---4"
      }
    ],
    "link": "https://engineering.mixpanel.com/how-mixpanel-built-a-fast-lane-for-our-modern-data-stack-680701736f8c?source=rss----b5de3443ad1f---4",
    "id": "https://medium.com/p/680701736f8c",
    "guidislink": false,
    "tags": [
      {
        "term": "data-engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "etl",
        "scheme": null,
        "label": null
      },
      {
        "term": "modern-data-stack",
        "scheme": null,
        "label": null
      },
      {
        "term": "gcp",
        "scheme": null,
        "label": null
      },
      {
        "term": "data-pipeline",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Illirik Smirnov"
      }
    ],
    "author": "Illirik Smirnov",
    "author_detail": {
      "name": "Illirik Smirnov"
    },
    "published": "Wed, 13 Dec 2023 16:42:27 GMT",
    "published_parsed": [
      2023,
      12,
      13,
      16,
      42,
      27,
      2,
      347,
      0
    ],
    "updated": "2024-01-04T00:33:36.585Z",
    "updated_parsed": [
      2024,
      1,
      4,
      0,
      33,
      36,
      3,
      4,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.mixpanel.com/feed",
        "value": "<p><strong>Introducing YCat: A Simple, Near-Real-Time Architecture for Event-Driven Orchestration</strong></p><h3>Intro</h3><p>I work on internal data infrastructure at Mixpanel, and our team has experienced the benefits of the <a href=\"https://funnel.io/blog/what-is-a-modern-data-stack\">modern data stack</a> firsthand. Building and maintaining a source of truth using ETL and in-warehouse transformations, which is then synced to our internal tools and other destinations using Reverse ETL, is head and shoulders above the Wild West of point-to-point integrations with ad-hoc transformations. However,<a href=\"https://www.lri.fr/~mbl/Stanford/CS477/papers/Kuhn-SSR-2ndEd.pdf\"> just like any other paradigm, there are gaps</a>\u200a\u2014\u200apuzzles that need to be solved within the paradigm. Previously, I <a href=\"https://engineering.mixpanel.com/how-we-cut-bigquery-costs-by-80-by-identifying-and-optimizing-costly-query-patterns-1a297b46bd33\">wrote about the gaps in monitoring the costs of pay-as-you-go data warehouses like BigQuery</a>. Today, <strong>I\u2019ll write about the issues we ran into while decommissioning an email marketing tool, and how we solved them by building a simple event-driven orchestration system.</strong></p><figure><img alt=\"A photograph taken at a London Underground station, showing the edge of the train platform where a train\u2019s door is open. Behind the tactile platform-edge surface, the tiles read \u201cMind The Gap\u201d, referring to the gap between the platform edge and the train.\" src=\"https://cdn-images-1.medium.com/max/1024/1*lKWqsD9KVK_ippgLmF97tQ.png\" /><figcaption>Data stacks and underground trains aren\u2019t that different!</figcaption></figure><h3>Context: Email Marketing Automation</h3><p>For our email marketing platform, we\u2019ve long used Adobe Marketo; not because we\u2019re fans, but because we chose Marketo long ago and it just stuck around. <strong>The purpose of an email marketing automation platform is to enable targeted emails to your customers or prospects using the data you have about them.</strong> For example, when we plan an in-person event, we want to invite our users and customers who live nearby; we don\u2019t want to invite users who live in e.g. Pittsburgh to an event in London (it\u2019s a long\u00a0flight)!</p><p><strong>To enable this kind of targeting, the tool needs to have access to information about the users and customers.</strong> This can go well beyond simple demographic information. For example, if we want to send an email <a href=\"https://mixpanel.com/m/data-warehouse-connectors\">announcing our new Redshift connector</a>, it likely doesn\u2019t make sense to send that email to users who have already connected Mixpanel to a different data warehouse. To target that email, we would need product usage information\u200a\u2014\u200aspecifically, which users have integrated which connectors.</p><p><strong>Marketo, like most other email marketing automation tools, maintains this information in a database within the system; like most Marketo users, we had configured Marketo to access this data through a Salesforce sync.</strong> At the time, we weren\u2019t on the modern data stack and didn\u2019t have a data warehouse, so our CRM was our best source for the targeting information Marketo needed. As I like to say, \u201cIf you don\u2019t have a data warehouse, your CRM is your data warehouse.\u201d</p><p>Like most legacy enterprise software, Marketo is endlessly configurable, with workflows and smart lists that allow you to build any sort of automation you can imagine. Since it syncs state both to and from Salesforce, you can use these automations to do much more than target emails. <strong>Users can build automations within Marketo that validate and transform the targeting information; it can essentially become a no-code automation tool.</strong></p><p>Over time, these automations accumulate. Attributes are added for each new targeting factor. Old attributes are not deleted\u200a\u2014\u200anobody owns the system holistically, and the employees who configured the old automations have left, so it\u2019s seen as safer to just add more and more <em>stuff</em> to Marketo, which leads to <strong>more and more state in Salesforce via the bi-directional sync.</strong> Eventually, you have over 600 fields on your Salesforce lead object, and it becomes very difficult to make any additional changes, barring a comprehensive project to migrate away from\u00a0Marketo.</p><figure><img alt=\"A seal depicting an octopus sitting on the Earth, perched atop the North Pole. Its tentacles are spread across the earth. The text of the seal reads \u201cNothing Is Beyond Our Reach\u201d. This image is an edit of a mission patch produced by an American intelligence service, with the name of the mission replaced by the Marketo logo.\" src=\"https://cdn-images-1.medium.com/max/1024/1*UaOOO42Dp3q4kQg_KE1qvg.png\" /></figure><h3>Reverse ETL latency and time-sensitive workflows</h3><p>When we kicked off our comprehensive project to migrate away from Marketo, the first step was to interview our marketing team and deeply understand their use cases. They were stoked to get a clean source of truth from our data warehouse\u200a\u2014\u200aour new system would contain only the folks that actually expressed interest in receiving these emails, with the same trustworthy demographic and product usage information that we\u2019re using throughout the rest of our stack. Sending out invitations for events and product updates would be a\u00a0breeze!</p><p><strong>However, there were some use cases where the latencies of ETL, </strong><a href=\"https://www.getdbt.com/\"><strong>dbt</strong></a><strong> (our in-warehouse transformation tool), and reverse ETL added up to a real stumbling block.</strong> Suppose a user fills out our <a href=\"https://mixpanel.com/contact-us/sales\">contact sales form</a> on our website. If we processed this form fill like any other interaction with our website, the data flow looks something like\u00a0this:</p><ul><li>The contents of the form fill are stored in our application database when the API call to submit the form is\u00a0made.</li><li>The table containing the form fill is ETLed into our data warehouse in a sync that runs every fifteen\u00a0minutes.</li><li>The source table is transformed using dbt models into a destination table. We have two \u201ctiers\u201d of tables; some are built only once per day, while tables we want to build more frequently are built every two\u00a0hours.</li><li>The transformed records are synced to Salesforce (so the lead can be routed to a rep), as well as <a href=\"http://customer.io/\">customer.io</a> and other necessary destinations.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*X0zqjyHcOYvwbV1iAkWeDg.png\" /><figcaption>Flow required to process an event using a standard MDS stack\u200a\u2014\u200athose latencies add\u00a0up!</figcaption></figure><p>The biggest delay here is the in-warehouse transformation, which does have some room for optimization. We could build the tables more frequently, but that can get pricey. We could ensure that the entire lineage of our destination table consists of views, but many models are expensive to compute. Running a query against a deep lineage of views comes with its own performance problems, especially when you\u2019re paying for queries as you go (the pricing model that better fits the spiky load of a regularly scheduled dbt\u00a0run).</p><p><strong>This latency becomes more problematic for multi-step workflows.</strong> Suppose our field marketing team is running an event. First, an invite list is put together and an invitation email is sent to the users that might be interested. When users register for the event, we need to send them a timely confirmation email. The event could fill up, so we might move the event to a space-available waitlist. Users might register just before an event happens; perhaps a conflicting meeting was cancelled at the last minute. <strong>All of these state changes need to be visible in near-real-time</strong> to the attendees (via email confirmations and waitlist notifications), the field marketing team, and sales reps (they need to know if one of their customers is attending the event). <strong>Even if in-warehouse transformation was instant (e.g. the \u201cviews all the way down\u201d approach), the ETL and reverse ETL delays are simply too long\u200a</strong>\u2014\u200aif someone registers just a few minutes before an event, they still expect their name on the list at the\u00a0door.</p><figure><img alt=\"An illustration of six turtles standing on each others\u2019 backs. Each turtle is smaller than the turtle it is standing on. The illustration has been edited to label each turtle with dbt configuration code to materialize a model as a view.\" src=\"https://cdn-images-1.medium.com/max/799/1*14joNhg-E1Er0CEegeRB2g.png\" /><figcaption>Views all the way down can help ameliorate the latency of in-warehouse transformations, but ETL and reverse ETL delays can\u2019t be\u00a0helped.</figcaption></figure><h3>Near-real-time problems and solutions</h3><p><strong>The consequences were clear\u200a\u2014\u200awe needed a \u201cfast lane\u201d for processing time-sensitive events, the nearer to real-time the better.</strong> There are a whole host of ways to get data from one system to another, each with pros and cons to consider. Generally, there are three main approaches you can take\u00a0here:</p><ol><li><strong>Build a classic real-time data pipeline on a streaming architecture</strong>\u200a\u2014\u200aspin up a Kafka broker, dust off the Spark book on your shelf, and do some good old-fashioned OLTP (online transaction processing). This is all well and good, but it introduces a lot of complexity and infrastructure to manage. Since we are a modern data stack team, we don\u2019t have any pipelines like this\u200a\u2014\u200ait\u2019s a lot of complexity to build out, within an already massive project, just to process a relatively small number of\u00a0events.</li><li><strong>Connect all of these internal systems (Salesforce, email marketing automation, event registration) directly using point-to-point integrations.</strong> Between native integrations, webhooks, and the host of rETL-like features popping up in so many internal tools, it can be surprisingly easy to implement all of these data flows by configuring syncs in the right way. However, not all of the tools in our stack integrate with each other. The only common denominator is Salesforce, and having our CRM manage more state is the exact opposite of our vision for our overall data architecture. Of course, sending all data through a bloated CRM was one of the factors that got us in this mess in the first\u00a0place!</li><li><strong>Use a no-code or low-code automation tool,</strong> like Zapier, Parabola, Boom, Tray, Integrately, Workato, IFTTT, or one of the other thousands of alternatives. They\u2019re so plentiful and omnipresent because they can be fantastic tools for solving this class of problems, especially for non-technical teams\u2026 when used properly and responsibly. Things can get quickly out of hand, and no-code means no version control (although there are <a href=\"https://www.ncscale.com/\">startups out there</a> tackling that problem). Given that we\u2019re an engineering team, with backgrounds in data, full-stack, and backend engineering, the benefits of code (version control, unit tests, robust change management, etc.) were too much for us to pass\u00a0up.</li></ol><p><strong>We needed a healthy middle ground</strong>\u200a\u2014\u200aan architecture that allows us to own and manage these integrations using code, without the heft of a classic real-time data pipeline or the limitations of direct integrations. So, after we mapped out all of our workflows and use cases, <strong>we took the best parts of a classic real-time data pipeline and combined them with the best parts of direct integrations and no-code automation</strong>. We call this system YCat, for \u201cyes-code automation tool\u201d\u200a\u2014\u200aa play on \u201cno-code automation tool\u201d\u200a\u2014\u200aand I\u2019ll go over the high-level architecture in this\u00a0article.</p><p>Before I go into our architecture, I want to be clear that you can\u200a\u2014\u200aand should!\u200a\u2014\u200atweak this approach to meet your needs, as well as your team\u2019s unique context. Maybe your stack looks different, or you use more direct integrations, or you ingest data from an existing store rather than webhooks. Before I go into our architecture, I want to be clear that you can\u200a\u2014\u200aand should!\u200a\u2014\u200atweak this approach to meet your needs, as well as your team\u2019s unique context. Maybe your stack looks different, or you use more direct integrations, or you ingest data from an existing store rather than webhooks. <strong>Feel free to experiment and improvise!</strong></p><h3>Architecture Overview</h3><figure><img alt=\"An architectural diagram representing the YCat system, in the form of a flow chart. The alt-text character limit on Medium does not have enough space for a full description of the flow-chart, but the accompanying plaintext describess everything in the diagram in detail.\" src=\"https://cdn-images-1.medium.com/max/1024/1*zmZDcIDQXoH0h-vgblnKSA.png\" /><figcaption>High-level architectural diagram of our YCat\u00a0system</figcaption></figure><p>At a high level, the architecture is very similar to a traditional data pipeline, but <strong>simplified to the bare minimum necessary for processing events</strong>. We want to sync as much of the state as possible through our modern data stack, so user profiles, enrichment information, and the like don\u2019t need to be processed or synced through this system\u200a\u2014\u200athey can continue to be reverse ETLed in. This system will only process the latency-sensitive events that our modern data stack implementation struggles with.</p><p>By restricting our system to only process events, it can <strong>process those events as idempotent transactions</strong>; we map each event type (e.g. event registration, email sent, form filled out) to a callback handler that makes the appropriate API calls to the appropriate services in the appropriate order. This approach means we don\u2019t need a datastore to maintain state within the system, which reduces complexity and eliminates state mismatches between YCat\u2019s datastore and our data warehouse.</p><p><strong>Events are ingested by a lightweight API service;</strong> we used <a href=\"https://fastapi.tiangolo.com/\">FastAPI</a>, which made this a breeze. The API service ingests events via webhook from the service each event originates from. The ingestion service should be kept as lightweight as possible and be hosted in some way that allows it to autoscale (so traffic spikes can be handled). It\u2019s probably best to piggyback on whatever infrastructure you already have; otherwise, use a serverless solution like Google Cloud Functions or a lightweight service runner like Cloud Run. We chose the former and built it out as a Kubernetes workload on a <a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview\">GCP Autopilot cluster</a>, which made it super easy to spin up and gave us a ton of monitoring and metrics out of the\u00a0box.</p><p><strong>The ingestion service validates the messages against the appropriate schemas, serializes them, and pushes the events as messages into a message broker</strong>, just like most classic data pipelines. We used <a href=\"https://cloud.google.com/pubsub?hl=en\">Pub/Sub here</a>, with one topic for each type of message. This allows us to easily monitor how many messages are in each topic, track latencies and SLAs with per-event granularity, and gracefully handle massive traffic spikes (like sending a product newsletter to hundreds of thousands of\u00a0users).</p><p><strong>The worker pool reads messages from the broker using a streaming pull subscription.</strong> Here, pub/sub\u2019s support for <a href=\"https://cloud.google.com/pubsub/docs/exactly-once-delivery\">exactly-once delivery</a> is super valuable\u200a\u2014\u200awe need to process our events idempotently (because we don\u2019t have a memory store), and ensuring that two workers won\u2019t be processing the same message at the same time reduces the surface area where race conditions could bubble up. <strong>We write a callback for each message type, which makes the appropriate API calls and implements other business logic</strong>, and package it in a specification that includes the schema for the message and the topic the worker should subscribe to. <strong>These callbacks can be unit tested like any other code, with ample logging and </strong><a href=\"https://prometheus.io/\"><strong>Prometheus metrics</strong></a><strong> for performance and reliability monitoring.</strong> We also configured pages on these metrics, alerting us when the shape of our webhooks change upstream, or our API calls downstream time out or\u00a0fail.</p><p>When a callback processes a message properly, it acknowledges the message, and the event is fully processed. <strong>If an error is encountered, the message is nacked</strong> (negative acknowledgement) so it can be redelivered later. <strong>If the message fails to process repeatedly, the message is redirected to a dead letter queue and we get paged</strong>; we do this after five delivery attempts all fail. That way, after we fix the issue, we can easily replay the message so that it\u2019s processed properly.</p><p>It might sound like a lot up front, but it\u2019s dead simple to work with and has been super reliable for us. Gone are the days of debugging point-to-point integrations and regexing page names out of failure notification emails\u200a\u2014\u200aour ops lead rotations are much more efficient and issues are easily caught before bad state causes further downstream problems. <strong>Often, issues with direct integrations and no-code automations are brought to the attention of their owners only once they\u2019ve had a significant downstream impact</strong>, such as an event attendee arriving to the venue only to find they\u2019re not on the list, or a support ticket from a prospective customer asking why he hasn\u2019t heard from the sales team after requesting a demo. <strong>Building out event handlers as unit-tested and monitored callbacks, which can be configured to retry individual api calls or fall back on simpler behavior, is fundamentally more reliable than a no-code automation tool or point-to-point integration\u200a\u2014\u200ayou\u2019re not constrained by how the tool handles errors or service degradations.</strong></p><h4>Example: Processing a Form\u00a0Fill</h4><p>Let\u2019s walk through this architecture through the lens of an example: processing a form fill. <strong>The event enters YCat through an API call.</strong> In this case, the form\u2019s Submit button calls our app\u2019s API, which records the form fill in its database and calls the ingestion service (via an <a href=\"https://docs.celeryq.dev/en/stable/getting-started/introduction.html\">asynchronous Celery task</a> to enable retries). <strong>The ingestion service serializes the form data and publishes it as a pub/sub message</strong> to the topic for form fills. (It will also validate form data against the expected schema, but this is less relevant in this example; the form data will have been validated by the form already.)</p><p>The message is pulled from the topic by one of our workers. The worker then deserializes the message and calls the appropriate callback for the message. The callback makes the appropriate API calls for a form fill; in this case, it\u00a0will:</p><ul><li><strong>Check to see if there is a Lead or Contact in Salesforce with the email address used to submit the form.</strong> If there isn\u2019t one, we create one, using the information (like name and company name) provided in the\u00a0form.</li><li><strong>Check to see if the Lead or Contact in Salesforce (whether it already exists or we just created it) is a member of the appropriate Salesforce campaign.</strong> If they aren\u2019t, add them to the campaign.</li><li><strong>Check to see if there is a person in our marketing email system with this email address.</strong> If there isn\u2019t, create\u00a0one.</li><li><strong>Send an event to the marketing email system representing the form fill.</strong> This event includes a deduplication key that is deterministically generated using the form, so if the event is sent twice, it will be deduplicated by the destination system.</li></ul><p>Notably, <strong>this callback is idempotent, because each state change in the destination systems is only performed if the system doesn\u2019t have the desired end state already.</strong> This is especially important for Salesforce, as there are many ways we can create Leads and Contacts there, and we want to avoid race conditions. (We avoid race conditions within YCat by using exactly-once delivery in pub/sub, which prevents a message from being processed by two workers at the same\u00a0time.)</p><p><strong>Suppose one of these API calls fail\u200a\u2014\u200athe worker NACKs the message</strong>, putting it back on the queue to be retried later; if enough retries fail, the message is sent to a dead-letter queue and we are paged. <strong>On the other hand, if all the API calls succeed, the message is acknowledged</strong> and the form fill is officially complete.</p><h3>Four things we learned while building the\u00a0system</h3><p>Your system, of course, might look a little different than ours, and you\u2019re almost certainly going to be integrating with different services than ours. We did learn some things while building and implementing this system that I\u2019d like to share, which should also shed some light on some of the problems and solutions you might run into during your\u00a0journey.</p><h4>If throughput is a problem, consider using bulk APIs, especially for Salesforce.</h4><p>Often, you\u2019ll be able to horizontally scale your workers to get more throughput. <strong>However, if the API you\u2019re interacting with doesn\u2019t let you horizontally scale enough, pulling batches of messages and passing them to a single callback can really help with throughput.</strong> This can happen when your API has strict rate limits or locks resources during a transaction.</p><p>For example, when you add members to a campaign in Salesforce, that API call locks not only the CampaignMember object you\u2019re creating or updating, but also the Campaign itself. This means that we can\u2019t horizontally scale to handle bursty \u201csent email\u201d traffic. By pulling and processing batches of hundreds of messages in one callback, we can use bulk API calls to set up the proper Salesforce state with much higher throughput.</p><p><strong>If you build out bulk support, your callback will need to keep track of which messages were successfully processed</strong> and ack or nack the messages as appropriate, usually at the end of the callback. You\u2019ll also need to tweak your flow control settings, to ensure that your worker is able to pull messages efficiently. Unit testing this behavior is super important\u200a\u2014\u200aa single-message callback failing in an unexpected manner will cause one message to get retried, while a bulk callback can cause hundreds or thousands of messages to be unnecessarily retried.</p><h4>Retries, acknowledgement deadlines, and dead-lettering in\u00a0Pub/Sub</h4><p>You\u2019ll need to <a href=\"https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwiwqcyJqICDAxUmKlkFHaDMBA8QFnoECAwQAw&amp;url=https%3A%2F%2Fcloud.google.com%2Fpubsub%2Fdocs%2Flease-management%23%3A~%3Atext%3D%252F%252F%2520Pub%252FSub%2520may%2520return%2520fewer%2520than%2520the%2520number%2520specified.%26text%3D%252F%252F%2520take%2520longer%2520than%2520the%2520default%252010%252Dsec%2520acknowledge%2520deadline.&amp;usg=AOvVaw04AqcZdfSGpLQqLiL2UfxQ&amp;opi=89978449\">tweak your acknowledgement deadlines</a> so that your callbacks have enough time to process their messages. The default is 10 seconds for pub/sub, which can quickly be eaten up by slow API calls. The Salesforce Bulk API is especially slow\u200a\u2014\u200aour bulk \u201cemail sent\u201d handler has a deadline of <strong>ten minutes</strong> because it needs to make up to four Salesforce Bulk API\u00a0calls.</p><p>If your \u201cmessages in dead letter\u201d page is too noisy, and re-processing the messages clears up your issue every time, consider increasing the number of retries. The default and minimum number of delivery attempts is 5, but <a href=\"https://cloud.google.com/pubsub/docs/handling-failures#how_dead_letter_topics_work\">it can be configured up to 100</a>. <a href=\"https://cloud.google.com/pubsub/docs/handling-failures#exponential_backoff\">Exponential backoff</a> can also be configured to wait a bit between retries, which is very helpful when integrating with flaky\u00a0APIs.</p><h4>Unit and integration testing for reliability</h4><p><strong>One of the most critical benefits of this architecture is that it\u2019s easy to write unit and integration tests\u200a\u2014\u200aso do!</strong> Each topic should have tests, not only for the happy path, but for the many types of edge cases you can run into. For example, if a specific API call fails, does the state left over make sense? Does retrying the message with a working API result in the same state as a message processed properly the first time? Be sure to test what happens when a message is processed twice (e.g. it got retried because it hit the acknowledgement deadline)\u200a\u2014\u200ais idempotence maintained?</p><p><strong>Rather than mocking individual API call signatures and their responses, build a fake (or mock\u200a\u2014\u200atesting nomenclature can be messy!) client for the services you integrate with</strong>, which maintains the state of the system it\u2019s impersonating. For example, when you create a Lead in your mock Salesforce client, actually store the lead data in the mock client class, and write your mock GET and PATCH endpoints to work on this state as well. This helps make your tests easier to write and less brittle; it also makes it easy to mock the state in the external systems that your callbacks are interfacing with.</p><h4>Security and ingestion-time validation</h4><p>You definitely need some sort of load balancer that\u2019s able to ensure the requests to your ingestion API service are legit. <strong>Typically, the webhooks your upstream systems send will be signed, or come from a specific IP address; check the documentation of your upstream systems to see how they validate their webhooks.</strong> We use Cloud Armor to block requests from the general Internet, which prevents bad state from entering our\u00a0systems.</p><p><strong>Carefully consider what your ingestion layer should do when it gets malformed data.</strong> Usually, a webhook that gets a response outside the 2xx success rate will retry; this can spam your ingestion layer if you\u2019re not careful. Our approach when we get a webhook we don\u2019t want to process\u200a\u2014\u200afor whatever reason\u200a\u2014\u200ais to 201 the request, but not put the message on the topic. If your ingestion service is getting requests that can\u2019t be retried for whatever reason, consider logging bad messages and paging on high error rates, which will help avoid potentially unrecoverable data\u00a0loss.</p><h3>Wrap-up</h3><p><strong>A lightweight, event-driven orchestration system was just the ticket for us to bridge the inherent gap caused by the latency of the ETL/dbt/rETL stack we use for everything that doesn\u2019t need to be processed in near real-time.</strong> Classic data pipelines, no-code automation tools, and direct integrations can be helpful patterns to solve these problems, but by combining the best parts of all three, we were able to build a lightweight and reliable system and nail the timeline on our Marketo deprecation project. Consider building a similar system if you\u2019re running into similar problems!</p><p><strong>By the way, if you love building reliable and performant systems for processing data\u200a\u2014\u200aMixpanel engineering is\u00a0</strong><a href=\"https://mixpanel.com/jobs\"><strong>hiring</strong></a><strong>!</strong></p><p><em>This article was not written by, or with the assistance of, AI tools, and contains no text generated by large language\u00a0models.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=680701736f8c\" width=\"1\" /><hr /><p><a href=\"https://engineering.mixpanel.com/how-mixpanel-built-a-fast-lane-for-our-modern-data-stack-680701736f8c\">How Mixpanel Built a \u201cFast Lane\u201d for Our Modern Data Stack</a> was originally published in <a href=\"https://engineering.mixpanel.com\">Mixpanel Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p><strong>Introducing YCat: A Simple, Near-Real-Time Architecture for Event-Driven Orchestration</strong></p><h3>Intro</h3><p>I work on internal data infrastructure at Mixpanel, and our team has experienced the benefits of the <a href=\"https://funnel.io/blog/what-is-a-modern-data-stack\">modern data stack</a> firsthand. Building and maintaining a source of truth using ETL and in-warehouse transformations, which is then synced to our internal tools and other destinations using Reverse ETL, is head and shoulders above the Wild West of point-to-point integrations with ad-hoc transformations. However,<a href=\"https://www.lri.fr/~mbl/Stanford/CS477/papers/Kuhn-SSR-2ndEd.pdf\"> just like any other paradigm, there are gaps</a>\u200a\u2014\u200apuzzles that need to be solved within the paradigm. Previously, I <a href=\"https://engineering.mixpanel.com/how-we-cut-bigquery-costs-by-80-by-identifying-and-optimizing-costly-query-patterns-1a297b46bd33\">wrote about the gaps in monitoring the costs of pay-as-you-go data warehouses like BigQuery</a>. Today, <strong>I\u2019ll write about the issues we ran into while decommissioning an email marketing tool, and how we solved them by building a simple event-driven orchestration system.</strong></p><figure><img alt=\"A photograph taken at a London Underground station, showing the edge of the train platform where a train\u2019s door is open. Behind the tactile platform-edge surface, the tiles read \u201cMind The Gap\u201d, referring to the gap between the platform edge and the train.\" src=\"https://cdn-images-1.medium.com/max/1024/1*lKWqsD9KVK_ippgLmF97tQ.png\" /><figcaption>Data stacks and underground trains aren\u2019t that different!</figcaption></figure><h3>Context: Email Marketing Automation</h3><p>For our email marketing platform, we\u2019ve long used Adobe Marketo; not because we\u2019re fans, but because we chose Marketo long ago and it just stuck around. <strong>The purpose of an email marketing automation platform is to enable targeted emails to your customers or prospects using the data you have about them.</strong> For example, when we plan an in-person event, we want to invite our users and customers who live nearby; we don\u2019t want to invite users who live in e.g. Pittsburgh to an event in London (it\u2019s a long\u00a0flight)!</p><p><strong>To enable this kind of targeting, the tool needs to have access to information about the users and customers.</strong> This can go well beyond simple demographic information. For example, if we want to send an email <a href=\"https://mixpanel.com/m/data-warehouse-connectors\">announcing our new Redshift connector</a>, it likely doesn\u2019t make sense to send that email to users who have already connected Mixpanel to a different data warehouse. To target that email, we would need product usage information\u200a\u2014\u200aspecifically, which users have integrated which connectors.</p><p><strong>Marketo, like most other email marketing automation tools, maintains this information in a database within the system; like most Marketo users, we had configured Marketo to access this data through a Salesforce sync.</strong> At the time, we weren\u2019t on the modern data stack and didn\u2019t have a data warehouse, so our CRM was our best source for the targeting information Marketo needed. As I like to say, \u201cIf you don\u2019t have a data warehouse, your CRM is your data warehouse.\u201d</p><p>Like most legacy enterprise software, Marketo is endlessly configurable, with workflows and smart lists that allow you to build any sort of automation you can imagine. Since it syncs state both to and from Salesforce, you can use these automations to do much more than target emails. <strong>Users can build automations within Marketo that validate and transform the targeting information; it can essentially become a no-code automation tool.</strong></p><p>Over time, these automations accumulate. Attributes are added for each new targeting factor. Old attributes are not deleted\u200a\u2014\u200anobody owns the system holistically, and the employees who configured the old automations have left, so it\u2019s seen as safer to just add more and more <em>stuff</em> to Marketo, which leads to <strong>more and more state in Salesforce via the bi-directional sync.</strong> Eventually, you have over 600 fields on your Salesforce lead object, and it becomes very difficult to make any additional changes, barring a comprehensive project to migrate away from\u00a0Marketo.</p><figure><img alt=\"A seal depicting an octopus sitting on the Earth, perched atop the North Pole. Its tentacles are spread across the earth. The text of the seal reads \u201cNothing Is Beyond Our Reach\u201d. This image is an edit of a mission patch produced by an American intelligence service, with the name of the mission replaced by the Marketo logo.\" src=\"https://cdn-images-1.medium.com/max/1024/1*UaOOO42Dp3q4kQg_KE1qvg.png\" /></figure><h3>Reverse ETL latency and time-sensitive workflows</h3><p>When we kicked off our comprehensive project to migrate away from Marketo, the first step was to interview our marketing team and deeply understand their use cases. They were stoked to get a clean source of truth from our data warehouse\u200a\u2014\u200aour new system would contain only the folks that actually expressed interest in receiving these emails, with the same trustworthy demographic and product usage information that we\u2019re using throughout the rest of our stack. Sending out invitations for events and product updates would be a\u00a0breeze!</p><p><strong>However, there were some use cases where the latencies of ETL, </strong><a href=\"https://www.getdbt.com/\"><strong>dbt</strong></a><strong> (our in-warehouse transformation tool), and reverse ETL added up to a real stumbling block.</strong> Suppose a user fills out our <a href=\"https://mixpanel.com/contact-us/sales\">contact sales form</a> on our website. If we processed this form fill like any other interaction with our website, the data flow looks something like\u00a0this:</p><ul><li>The contents of the form fill are stored in our application database when the API call to submit the form is\u00a0made.</li><li>The table containing the form fill is ETLed into our data warehouse in a sync that runs every fifteen\u00a0minutes.</li><li>The source table is transformed using dbt models into a destination table. We have two \u201ctiers\u201d of tables; some are built only once per day, while tables we want to build more frequently are built every two\u00a0hours.</li><li>The transformed records are synced to Salesforce (so the lead can be routed to a rep), as well as <a href=\"http://customer.io/\">customer.io</a> and other necessary destinations.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*X0zqjyHcOYvwbV1iAkWeDg.png\" /><figcaption>Flow required to process an event using a standard MDS stack\u200a\u2014\u200athose latencies add\u00a0up!</figcaption></figure><p>The biggest delay here is the in-warehouse transformation, which does have some room for optimization. We could build the tables more frequently, but that can get pricey. We could ensure that the entire lineage of our destination table consists of views, but many models are expensive to compute. Running a query against a deep lineage of views comes with its own performance problems, especially when you\u2019re paying for queries as you go (the pricing model that better fits the spiky load of a regularly scheduled dbt\u00a0run).</p><p><strong>This latency becomes more problematic for multi-step workflows.</strong> Suppose our field marketing team is running an event. First, an invite list is put together and an invitation email is sent to the users that might be interested. When users register for the event, we need to send them a timely confirmation email. The event could fill up, so we might move the event to a space-available waitlist. Users might register just before an event happens; perhaps a conflicting meeting was cancelled at the last minute. <strong>All of these state changes need to be visible in near-real-time</strong> to the attendees (via email confirmations and waitlist notifications), the field marketing team, and sales reps (they need to know if one of their customers is attending the event). <strong>Even if in-warehouse transformation was instant (e.g. the \u201cviews all the way down\u201d approach), the ETL and reverse ETL delays are simply too long\u200a</strong>\u2014\u200aif someone registers just a few minutes before an event, they still expect their name on the list at the\u00a0door.</p><figure><img alt=\"An illustration of six turtles standing on each others\u2019 backs. Each turtle is smaller than the turtle it is standing on. The illustration has been edited to label each turtle with dbt configuration code to materialize a model as a view.\" src=\"https://cdn-images-1.medium.com/max/799/1*14joNhg-E1Er0CEegeRB2g.png\" /><figcaption>Views all the way down can help ameliorate the latency of in-warehouse transformations, but ETL and reverse ETL delays can\u2019t be\u00a0helped.</figcaption></figure><h3>Near-real-time problems and solutions</h3><p><strong>The consequences were clear\u200a\u2014\u200awe needed a \u201cfast lane\u201d for processing time-sensitive events, the nearer to real-time the better.</strong> There are a whole host of ways to get data from one system to another, each with pros and cons to consider. Generally, there are three main approaches you can take\u00a0here:</p><ol><li><strong>Build a classic real-time data pipeline on a streaming architecture</strong>\u200a\u2014\u200aspin up a Kafka broker, dust off the Spark book on your shelf, and do some good old-fashioned OLTP (online transaction processing). This is all well and good, but it introduces a lot of complexity and infrastructure to manage. Since we are a modern data stack team, we don\u2019t have any pipelines like this\u200a\u2014\u200ait\u2019s a lot of complexity to build out, within an already massive project, just to process a relatively small number of\u00a0events.</li><li><strong>Connect all of these internal systems (Salesforce, email marketing automation, event registration) directly using point-to-point integrations.</strong> Between native integrations, webhooks, and the host of rETL-like features popping up in so many internal tools, it can be surprisingly easy to implement all of these data flows by configuring syncs in the right way. However, not all of the tools in our stack integrate with each other. The only common denominator is Salesforce, and having our CRM manage more state is the exact opposite of our vision for our overall data architecture. Of course, sending all data through a bloated CRM was one of the factors that got us in this mess in the first\u00a0place!</li><li><strong>Use a no-code or low-code automation tool,</strong> like Zapier, Parabola, Boom, Tray, Integrately, Workato, IFTTT, or one of the other thousands of alternatives. They\u2019re so plentiful and omnipresent because they can be fantastic tools for solving this class of problems, especially for non-technical teams\u2026 when used properly and responsibly. Things can get quickly out of hand, and no-code means no version control (although there are <a href=\"https://www.ncscale.com/\">startups out there</a> tackling that problem). Given that we\u2019re an engineering team, with backgrounds in data, full-stack, and backend engineering, the benefits of code (version control, unit tests, robust change management, etc.) were too much for us to pass\u00a0up.</li></ol><p><strong>We needed a healthy middle ground</strong>\u200a\u2014\u200aan architecture that allows us to own and manage these integrations using code, without the heft of a classic real-time data pipeline or the limitations of direct integrations. So, after we mapped out all of our workflows and use cases, <strong>we took the best parts of a classic real-time data pipeline and combined them with the best parts of direct integrations and no-code automation</strong>. We call this system YCat, for \u201cyes-code automation tool\u201d\u200a\u2014\u200aa play on \u201cno-code automation tool\u201d\u200a\u2014\u200aand I\u2019ll go over the high-level architecture in this\u00a0article.</p><p>Before I go into our architecture, I want to be clear that you can\u200a\u2014\u200aand should!\u200a\u2014\u200atweak this approach to meet your needs, as well as your team\u2019s unique context. Maybe your stack looks different, or you use more direct integrations, or you ingest data from an existing store rather than webhooks. Before I go into our architecture, I want to be clear that you can\u200a\u2014\u200aand should!\u200a\u2014\u200atweak this approach to meet your needs, as well as your team\u2019s unique context. Maybe your stack looks different, or you use more direct integrations, or you ingest data from an existing store rather than webhooks. <strong>Feel free to experiment and improvise!</strong></p><h3>Architecture Overview</h3><figure><img alt=\"An architectural diagram representing the YCat system, in the form of a flow chart. The alt-text character limit on Medium does not have enough space for a full description of the flow-chart, but the accompanying plaintext describess everything in the diagram in detail.\" src=\"https://cdn-images-1.medium.com/max/1024/1*zmZDcIDQXoH0h-vgblnKSA.png\" /><figcaption>High-level architectural diagram of our YCat\u00a0system</figcaption></figure><p>At a high level, the architecture is very similar to a traditional data pipeline, but <strong>simplified to the bare minimum necessary for processing events</strong>. We want to sync as much of the state as possible through our modern data stack, so user profiles, enrichment information, and the like don\u2019t need to be processed or synced through this system\u200a\u2014\u200athey can continue to be reverse ETLed in. This system will only process the latency-sensitive events that our modern data stack implementation struggles with.</p><p>By restricting our system to only process events, it can <strong>process those events as idempotent transactions</strong>; we map each event type (e.g. event registration, email sent, form filled out) to a callback handler that makes the appropriate API calls to the appropriate services in the appropriate order. This approach means we don\u2019t need a datastore to maintain state within the system, which reduces complexity and eliminates state mismatches between YCat\u2019s datastore and our data warehouse.</p><p><strong>Events are ingested by a lightweight API service;</strong> we used <a href=\"https://fastapi.tiangolo.com/\">FastAPI</a>, which made this a breeze. The API service ingests events via webhook from the service each event originates from. The ingestion service should be kept as lightweight as possible and be hosted in some way that allows it to autoscale (so traffic spikes can be handled). It\u2019s probably best to piggyback on whatever infrastructure you already have; otherwise, use a serverless solution like Google Cloud Functions or a lightweight service runner like Cloud Run. We chose the former and built it out as a Kubernetes workload on a <a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview\">GCP Autopilot cluster</a>, which made it super easy to spin up and gave us a ton of monitoring and metrics out of the\u00a0box.</p><p><strong>The ingestion service validates the messages against the appropriate schemas, serializes them, and pushes the events as messages into a message broker</strong>, just like most classic data pipelines. We used <a href=\"https://cloud.google.com/pubsub?hl=en\">Pub/Sub here</a>, with one topic for each type of message. This allows us to easily monitor how many messages are in each topic, track latencies and SLAs with per-event granularity, and gracefully handle massive traffic spikes (like sending a product newsletter to hundreds of thousands of\u00a0users).</p><p><strong>The worker pool reads messages from the broker using a streaming pull subscription.</strong> Here, pub/sub\u2019s support for <a href=\"https://cloud.google.com/pubsub/docs/exactly-once-delivery\">exactly-once delivery</a> is super valuable\u200a\u2014\u200awe need to process our events idempotently (because we don\u2019t have a memory store), and ensuring that two workers won\u2019t be processing the same message at the same time reduces the surface area where race conditions could bubble up. <strong>We write a callback for each message type, which makes the appropriate API calls and implements other business logic</strong>, and package it in a specification that includes the schema for the message and the topic the worker should subscribe to. <strong>These callbacks can be unit tested like any other code, with ample logging and </strong><a href=\"https://prometheus.io/\"><strong>Prometheus metrics</strong></a><strong> for performance and reliability monitoring.</strong> We also configured pages on these metrics, alerting us when the shape of our webhooks change upstream, or our API calls downstream time out or\u00a0fail.</p><p>When a callback processes a message properly, it acknowledges the message, and the event is fully processed. <strong>If an error is encountered, the message is nacked</strong> (negative acknowledgement) so it can be redelivered later. <strong>If the message fails to process repeatedly, the message is redirected to a dead letter queue and we get paged</strong>; we do this after five delivery attempts all fail. That way, after we fix the issue, we can easily replay the message so that it\u2019s processed properly.</p><p>It might sound like a lot up front, but it\u2019s dead simple to work with and has been super reliable for us. Gone are the days of debugging point-to-point integrations and regexing page names out of failure notification emails\u200a\u2014\u200aour ops lead rotations are much more efficient and issues are easily caught before bad state causes further downstream problems. <strong>Often, issues with direct integrations and no-code automations are brought to the attention of their owners only once they\u2019ve had a significant downstream impact</strong>, such as an event attendee arriving to the venue only to find they\u2019re not on the list, or a support ticket from a prospective customer asking why he hasn\u2019t heard from the sales team after requesting a demo. <strong>Building out event handlers as unit-tested and monitored callbacks, which can be configured to retry individual api calls or fall back on simpler behavior, is fundamentally more reliable than a no-code automation tool or point-to-point integration\u200a\u2014\u200ayou\u2019re not constrained by how the tool handles errors or service degradations.</strong></p><h4>Example: Processing a Form\u00a0Fill</h4><p>Let\u2019s walk through this architecture through the lens of an example: processing a form fill. <strong>The event enters YCat through an API call.</strong> In this case, the form\u2019s Submit button calls our app\u2019s API, which records the form fill in its database and calls the ingestion service (via an <a href=\"https://docs.celeryq.dev/en/stable/getting-started/introduction.html\">asynchronous Celery task</a> to enable retries). <strong>The ingestion service serializes the form data and publishes it as a pub/sub message</strong> to the topic for form fills. (It will also validate form data against the expected schema, but this is less relevant in this example; the form data will have been validated by the form already.)</p><p>The message is pulled from the topic by one of our workers. The worker then deserializes the message and calls the appropriate callback for the message. The callback makes the appropriate API calls for a form fill; in this case, it\u00a0will:</p><ul><li><strong>Check to see if there is a Lead or Contact in Salesforce with the email address used to submit the form.</strong> If there isn\u2019t one, we create one, using the information (like name and company name) provided in the\u00a0form.</li><li><strong>Check to see if the Lead or Contact in Salesforce (whether it already exists or we just created it) is a member of the appropriate Salesforce campaign.</strong> If they aren\u2019t, add them to the campaign.</li><li><strong>Check to see if there is a person in our marketing email system with this email address.</strong> If there isn\u2019t, create\u00a0one.</li><li><strong>Send an event to the marketing email system representing the form fill.</strong> This event includes a deduplication key that is deterministically generated using the form, so if the event is sent twice, it will be deduplicated by the destination system.</li></ul><p>Notably, <strong>this callback is idempotent, because each state change in the destination systems is only performed if the system doesn\u2019t have the desired end state already.</strong> This is especially important for Salesforce, as there are many ways we can create Leads and Contacts there, and we want to avoid race conditions. (We avoid race conditions within YCat by using exactly-once delivery in pub/sub, which prevents a message from being processed by two workers at the same\u00a0time.)</p><p><strong>Suppose one of these API calls fail\u200a\u2014\u200athe worker NACKs the message</strong>, putting it back on the queue to be retried later; if enough retries fail, the message is sent to a dead-letter queue and we are paged. <strong>On the other hand, if all the API calls succeed, the message is acknowledged</strong> and the form fill is officially complete.</p><h3>Four things we learned while building the\u00a0system</h3><p>Your system, of course, might look a little different than ours, and you\u2019re almost certainly going to be integrating with different services than ours. We did learn some things while building and implementing this system that I\u2019d like to share, which should also shed some light on some of the problems and solutions you might run into during your\u00a0journey.</p><h4>If throughput is a problem, consider using bulk APIs, especially for Salesforce.</h4><p>Often, you\u2019ll be able to horizontally scale your workers to get more throughput. <strong>However, if the API you\u2019re interacting with doesn\u2019t let you horizontally scale enough, pulling batches of messages and passing them to a single callback can really help with throughput.</strong> This can happen when your API has strict rate limits or locks resources during a transaction.</p><p>For example, when you add members to a campaign in Salesforce, that API call locks not only the CampaignMember object you\u2019re creating or updating, but also the Campaign itself. This means that we can\u2019t horizontally scale to handle bursty \u201csent email\u201d traffic. By pulling and processing batches of hundreds of messages in one callback, we can use bulk API calls to set up the proper Salesforce state with much higher throughput.</p><p><strong>If you build out bulk support, your callback will need to keep track of which messages were successfully processed</strong> and ack or nack the messages as appropriate, usually at the end of the callback. You\u2019ll also need to tweak your flow control settings, to ensure that your worker is able to pull messages efficiently. Unit testing this behavior is super important\u200a\u2014\u200aa single-message callback failing in an unexpected manner will cause one message to get retried, while a bulk callback can cause hundreds or thousands of messages to be unnecessarily retried.</p><h4>Retries, acknowledgement deadlines, and dead-lettering in\u00a0Pub/Sub</h4><p>You\u2019ll need to <a href=\"https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwiwqcyJqICDAxUmKlkFHaDMBA8QFnoECAwQAw&amp;url=https%3A%2F%2Fcloud.google.com%2Fpubsub%2Fdocs%2Flease-management%23%3A~%3Atext%3D%252F%252F%2520Pub%252FSub%2520may%2520return%2520fewer%2520than%2520the%2520number%2520specified.%26text%3D%252F%252F%2520take%2520longer%2520than%2520the%2520default%252010%252Dsec%2520acknowledge%2520deadline.&amp;usg=AOvVaw04AqcZdfSGpLQqLiL2UfxQ&amp;opi=89978449\">tweak your acknowledgement deadlines</a> so that your callbacks have enough time to process their messages. The default is 10 seconds for pub/sub, which can quickly be eaten up by slow API calls. The Salesforce Bulk API is especially slow\u200a\u2014\u200aour bulk \u201cemail sent\u201d handler has a deadline of <strong>ten minutes</strong> because it needs to make up to four Salesforce Bulk API\u00a0calls.</p><p>If your \u201cmessages in dead letter\u201d page is too noisy, and re-processing the messages clears up your issue every time, consider increasing the number of retries. The default and minimum number of delivery attempts is 5, but <a href=\"https://cloud.google.com/pubsub/docs/handling-failures#how_dead_letter_topics_work\">it can be configured up to 100</a>. <a href=\"https://cloud.google.com/pubsub/docs/handling-failures#exponential_backoff\">Exponential backoff</a> can also be configured to wait a bit between retries, which is very helpful when integrating with flaky\u00a0APIs.</p><h4>Unit and integration testing for reliability</h4><p><strong>One of the most critical benefits of this architecture is that it\u2019s easy to write unit and integration tests\u200a\u2014\u200aso do!</strong> Each topic should have tests, not only for the happy path, but for the many types of edge cases you can run into. For example, if a specific API call fails, does the state left over make sense? Does retrying the message with a working API result in the same state as a message processed properly the first time? Be sure to test what happens when a message is processed twice (e.g. it got retried because it hit the acknowledgement deadline)\u200a\u2014\u200ais idempotence maintained?</p><p><strong>Rather than mocking individual API call signatures and their responses, build a fake (or mock\u200a\u2014\u200atesting nomenclature can be messy!) client for the services you integrate with</strong>, which maintains the state of the system it\u2019s impersonating. For example, when you create a Lead in your mock Salesforce client, actually store the lead data in the mock client class, and write your mock GET and PATCH endpoints to work on this state as well. This helps make your tests easier to write and less brittle; it also makes it easy to mock the state in the external systems that your callbacks are interfacing with.</p><h4>Security and ingestion-time validation</h4><p>You definitely need some sort of load balancer that\u2019s able to ensure the requests to your ingestion API service are legit. <strong>Typically, the webhooks your upstream systems send will be signed, or come from a specific IP address; check the documentation of your upstream systems to see how they validate their webhooks.</strong> We use Cloud Armor to block requests from the general Internet, which prevents bad state from entering our\u00a0systems.</p><p><strong>Carefully consider what your ingestion layer should do when it gets malformed data.</strong> Usually, a webhook that gets a response outside the 2xx success rate will retry; this can spam your ingestion layer if you\u2019re not careful. Our approach when we get a webhook we don\u2019t want to process\u200a\u2014\u200afor whatever reason\u200a\u2014\u200ais to 201 the request, but not put the message on the topic. If your ingestion service is getting requests that can\u2019t be retried for whatever reason, consider logging bad messages and paging on high error rates, which will help avoid potentially unrecoverable data\u00a0loss.</p><h3>Wrap-up</h3><p><strong>A lightweight, event-driven orchestration system was just the ticket for us to bridge the inherent gap caused by the latency of the ETL/dbt/rETL stack we use for everything that doesn\u2019t need to be processed in near real-time.</strong> Classic data pipelines, no-code automation tools, and direct integrations can be helpful patterns to solve these problems, but by combining the best parts of all three, we were able to build a lightweight and reliable system and nail the timeline on our Marketo deprecation project. Consider building a similar system if you\u2019re running into similar problems!</p><p><strong>By the way, if you love building reliable and performant systems for processing data\u200a\u2014\u200aMixpanel engineering is\u00a0</strong><a href=\"https://mixpanel.com/jobs\"><strong>hiring</strong></a><strong>!</strong></p><p><em>This article was not written by, or with the assistance of, AI tools, and contains no text generated by large language\u00a0models.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=680701736f8c\" width=\"1\" /><hr /><p><a href=\"https://engineering.mixpanel.com/how-mixpanel-built-a-fast-lane-for-our-modern-data-stack-680701736f8c\">How Mixpanel Built a \u201cFast Lane\u201d for Our Modern Data Stack</a> was originally published in <a href=\"https://engineering.mixpanel.com\">Mixpanel Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "8th Light": {
    "title": "Fostering Product-Thinking Within Your Team",
    "xmlUrl": "https://8thlight.com/blog/feed/atom.xml",
    "htmlUrl": "https://8thlight.com/blog/",
    "id": "https://8thlight.com/insights/fostering-product-thinking-within-your-team",
    "guidislink": true,
    "link": "https://8thlight.com/insights/fostering-product-thinking-within-your-team",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://8thlight.com/insights/feed/atom.xml",
      "value": "Fostering Product-Thinking Within Your Team"
    },
    "published": "2024-01-03T08:33:00-06:00",
    "published_parsed": [
      2024,
      1,
      3,
      14,
      33,
      0,
      2,
      3,
      0
    ],
    "updated": "2024-01-04T09:56:00-06:00",
    "updated_parsed": [
      2024,
      1,
      4,
      15,
      56,
      0,
      3,
      4,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://8thlight.com/insights/fostering-product-thinking-within-your-team"
      }
    ],
    "authors": [
      {
        "name": "Pia Opulencia"
      }
    ],
    "author_detail": {
      "name": "Pia Opulencia"
    },
    "author": "Pia Opulencia",
    "media_thumbnail": [
      {
        "height": "150",
        "url": "https://assets.8thlight.com/images/leadership/_150x150_crop_center-center_none/94238/PiaOpulencia.webp",
        "width": "150",
        "xmlns:media": "http://search.yahoo.com/mrss/"
      }
    ],
    "href": "",
    "summary": "",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://8thlight.com/insights/feed/atom.xml",
      "value": ""
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://8thlight.com/insights/feed/atom.xml",
        "value": "<h2 dir=\"ltr\">A Frequent Misdiagnosis</h2>\n<p dir=\"ltr\">We\u2019ve seen it before and what usually follows: Leadership wonders why <a href=\"https://8thlight.com/services/software-development\">software development</a> velocity is slow (\u201cJust ship it faster!\u201d), customers are not adopting the product (\u201cMake it cooler!\u201d), and teams frequently miscommunicate or misunderstand requirements (\u201cProvide more documentation!\u201d). And yet, simply changing the mechanics of how the <a href=\"https://8thlight.com/services/product-strategy\">product</a> is built may not achieve the desired result, making development slower or features less delightful. <br /><br /></p>\n<h3>The Certainty Effect</h3>\n<p dir=\"ltr\">What levers can we pull to solve \u201cslow delivery\u201d? Is it the number of people on the team? The requirements process or lack thereof? Is it tooling and infrastructure? There is a wealth of information surrounding product development, delivery frameworks, and an industry of SaaS products that bake in their own development workflows as best practice. So, when faced with uncertainty about how to solve a problem like \u201cslow delivery,\u201d we often default to what is most known to us and thus perceived as less risky. We pull on the levers that we know and are tractable.<br /><br />Organizations employ a myriad of software development practices and team structures with no two companies following the exact same form. The most successful software product companies master connecting their customers with the value their product offers. What do these companies have in common? <strong>Product mindset</strong>.<br /><br /></p>\n<h3>Mindset Mastery</h3>\n<p dir=\"ltr\">Instead of focusing on processes and tools, organizations have shifted toward focusing on the mentality of approaching a problem to solve. The organizations able to hone this skill across their teams are more likely to achieve their desired outcomes.</p>\n<p dir=\"ltr\">A product mindset places the customer at the center of every decision, values continuous improvement, and emphasizes the long-term success and sustainability of a product. Before diagnosing your organization\u2019s particular issues, observe how your teams work together, make decisions, and frame problems within four pillars of product mindset:</p>\n<ol><li dir=\"ltr\"><p dir=\"ltr\"><strong>The necessity of prioritizing features based on customer feedback and market demand. </strong>Evaluate how priorities are defined within each workstream. Do the parameters being considered, such as level of effort and addressable market, fit the target customer? </p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>The importance of delivering value to the customer.</strong> Has your team attended a user research call? Does your team see customer support tickets? Building empathy for the customer can improve how we decide what to build.</p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>The need for a long-term vision for the product.</strong> Does your team make near-term technical decisions that balance the long-term vision? Does the long-term vision provide the team with tractable problems to solve?</p></li><li dir=\"ltr\"><p dir=\"ltr\"><strong>The significance of cross-functional collaboration and teamwork. </strong>How are the teams communicating with each other? Is there transparency or siloes?<br /><br /></p></li></ol>\n<h2 dir=\"ltr\">Value-driven Prioritization</h2>\n<p dir=\"ltr\">Customer feedback is the lifeblood of a product-driven mindset. To develop this mindset, your teams should actively seek, analyze, and act upon customer feedback. This requires a shift from a \"build it and they will come\" mentality to a \"listen, iterate, and improve\" approach.</p>\n<p dir=\"ltr\"></p>\n<p dir=\"ltr\"></p>\n<h3 dir=\"ltr\">To prioritize customer feedback:</h3>\n<ul><li dir=\"ltr\"><p dir=\"ltr\">Collect feedback through surveys, user interviews, and data analytics.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Create a feedback loop that channels insights back to the development teams.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Use feedback to prioritize feature development and product improvements.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Continuously iterate based on customer input<br /></p></li></ul>\n<div><br /></div>\n                              \n\n  \n  \n  <figure>\n    \n\n<img alt=\"Prioritization\" height=\"512\" src=\"https://assets.8thlight.com/images/_840xAUTO_crop_center-center_none/Prioritization_2024-01-04-155156_tspi.webp\" width=\"840\" />\n\n          <figcaption>Two bulleted lists showcasing the customer value outputs of backlog prioritization versus value-driven prioritization.</figcaption>\n      </figure>\n                              <p><br /><br /></p>\n<h3 dir=\"ltr\">Driving Toward a Vision</h3>\n<p dir=\"ltr\">A product mindset requires a clear understanding of what success looks like. Establish key performance indicators (KPIs) and metrics that align with your product's objectives. This enables your teams to measure progress and make data-driven decisions incrementally. The continuous measurement and milestones towards the long-term vision allow for course corrections along the way.<br /></p>\n<h3 dir=\"ltr\">To set clear goals and metrics:</h3>\n<ul><li dir=\"ltr\"><p dir=\"ltr\">Define measurable objectives for your product.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Establish realistic timelines and milestones.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Monitor KPIs and adjust strategies accordingly.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Celebrate achievements and learn from setbacks<br /></p></li></ul>\n<div><br /></div>\n<h2 dir=\"ltr\">Cultivating an Empowered Team</h2>\n<p dir=\"ltr\">Fostering a product mindset starts with breaking down silos within your organization. Encourage cross-functional collaboration among product, design, development, and quality assurance teams. This multidisciplinary approach ensures that all stakeholders are aligned with the product vision and share responsibility for its success.</p>\n<h3 dir=\"ltr\">To promote collaboration:</h3>\n<ul><li dir=\"ltr\"><p dir=\"ltr\">Create cross-functional teams where members work together on the same product.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Establish clear communication channels to facilitate information sharing.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Encourage regular meetings and brainstorming sessions.</p></li><li dir=\"ltr\"><p dir=\"ltr\">Celebrate team achievements rather than individual accomplishments.</p></li></ul>\n<p dir=\"ltr\">By focusing our improvements around mindset and less on promoting \u201cfoolproof processes\u201d we promote the agility of the team. This agility allows for organizations to react quickly to changing market conditions, leveraging the empowered team to extract and deliver continuous value to customers.</p>\n<p dir=\"ltr\">Interested in learning more about how your organization can adopt a product mindset? <a href=\"https://8thlight.com/contact-form\">Give us a shout</a>! </p>"
      }
    ]
  },
  "VTS": {
    "title": "Day in the Life @ VTS: Sorren Isler, Lead Product Manager",
    "xmlUrl": "https://buildingvts.com/feed",
    "htmlUrl": "https://buildingvts.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://buildingvts.com/feed",
      "value": "Day in the Life @ VTS: Sorren Isler, Lead Product Manager"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://buildingvts.com/day-in-the-life-vts-sorren-isler-lead-product-manager-6128bb5325e4?source=rss----f76c28ec6a84---4"
      }
    ],
    "link": "https://buildingvts.com/day-in-the-life-vts-sorren-isler-lead-product-manager-6128bb5325e4?source=rss----f76c28ec6a84---4",
    "id": "https://medium.com/p/6128bb5325e4",
    "guidislink": false,
    "authors": [
      {
        "name": "Louisa Petkov"
      }
    ],
    "author": "Louisa Petkov",
    "author_detail": {
      "name": "Louisa Petkov"
    },
    "published": "Mon, 09 Oct 2023 14:14:55 GMT",
    "published_parsed": [
      2023,
      10,
      9,
      14,
      14,
      55,
      0,
      282,
      0
    ],
    "updated": "2023-10-09T14:14:55.612Z",
    "updated_parsed": [
      2023,
      10,
      9,
      14,
      14,
      55,
      0,
      282,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://buildingvts.com/feed",
        "value": "<p><strong><em>VTS is composed of individuals with a wide array of characteristics, skills, experiences and outlooks\u200a\u2014\u200aand we\u2019re eager for you to get to know them! We\u2019ve crafted this series to give you a closer look at the vibrant lives they have and the environment they help foster, so that each VTSer can be their authentic self.</em></strong></p><p><strong><em>Next in our series is Sorren Isler, Lead Product Manager, who has been with VTS since December\u00a02020.</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/656/1*uHfemEFvqqfp2m0Oqsm_qg.png\" /></figure><p><strong><em>In a sentence or two\u200a\u2014\u200awhat do you do here at\u00a0VTS?</em></strong></p><p>I am a Lead Product Manager on VTS Activate\u200a\u2014\u200aour tenant experience business unit (also known as\u00a0TenEx).</p><p><strong><em>Tell us more about your\u00a0team.</em></strong></p><p>I have a couple of areas of ownership and accountability. The first is my squad, where I\u2019m the Product IC (Individual Contributor). Within my squad, we\u2019re focused on building hardware interfaces and experiences. For example, our hardware work up-levels our visitor management software product because it allows building visitors to sign in without hassle. Once they arrive, the hosts automatically receive a notification. This helps take the weight off the folks working at the front desk, who usually only have a device or two to get everyone in the building.</p><p>My squad includes an Engineering Manager, a Designer, a number of Software Engineers, and our QA. We have a very collaborative team and even though we work across different time zones, we talk asynchronously. It\u2019s important to us that everyone feels comfortable bringing up issues and concerns, so when someone raises their hand, the team jumps in whether they need help or an opinion on a topic. One way we build ownership in the team is by rotating who takes on the role of sprint lead for each sprint. This gives everyone the chance to take ownership, support the team, and mix things up! If there are different ways one may choose to run the rituals, this is a great time to experiment with different formats and approaches.</p><p>As a mission lead, I need to zoom out to an even more holistic view as I think about our overarching mission, its overlap with other missions, and how our strategies and work can best deliver impact for VTS Activate. This part of my role is focused on considering how multiple pieces connect across multiple squads (beyond those just with hardware dependencies) and missions, the overarching UX team, and our stakeholders to create a vision for how everything works together.</p><p><strong><em>What is the problem your team is\u00a0solving?</em></strong></p><p>My squad\u2019s ultimate goal is to create a hardware strategy and roadmap that supports key software across TenEx so that our users have a comprehensive and easy experience doing what they need to\u00a0do.</p><p>My mission\u2019s goal is to support our users as they move through buildings and every area they should have access\u00a0to.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Mnn9HEdKzbMrA2OLfMGbdA.jpeg\" /></figure><p><strong><em>What is a typical day like for\u00a0you?</em></strong></p><p>I often jump between different areas of focus throughout my day. My priorities will often shift, but I\u2019m likely touching both squad and mission lead work each day of the\u00a0week.</p><p>As a Lead Product Manager, my day-to-day involves our squad rituals, squad syncs, and cross-squad dependency syncs. Our squad syncs could be anything from 1:1s, to full squad meetings to discuss processes, upcoming features, design run-throughs, refinement, or roadmap planning.</p><p>Oftentimes I\u2019m also meeting with people outside of hardware squads to understand how different potential hardware may support their product. This often is to help plan out our next focus area and how we might work in parallel with any teams we have dependencies with.</p><p>As a mission lead, I\u2019m working with stakeholders outside of PED <em>[Product, Engineering and Design</em>] to understand access to our product from different perspectives. This could involve conversations with Client teams to better understand gaps and opportunities or the Solutions team to understand capabilities at a market level. At this stage, my mission focus is bringing me a lot of discovery, analysis, and data\u00a0work.</p><p><strong><em>What is your favorite project you\u2019ve had at VTS so\u00a0far?</em></strong></p><p>For my first 2 years at VTS, I worked on VTS Lease on the mobile team, as well as some additional projects, including a strategy for a holistic global experience.</p><p>Being a Mobile PM, I\u2019m often in a unique position where I have oversight across multiple features and multiple teams. So, as I became familiar with the website, I started to notice a gap in the holistic ownership of the website; the website had so many different teams but no one accountable for the overarching information architecture that created the larger\u00a0vision.</p><p>After identifying that gap, I got to work with the VP of Design and Staff Engineer for a quarter, pulling together a business case and pitch to address this need. Through this, we did an audit of the sitemap and all pages, workshops with client stakeholders to uncover more gaps and validate some of the things we were seeing, and then pulled together some initial high-level concepts for how we might approach it all. We pulled this into our business case and created a pitch alongside a number of others pitching different ideas.</p><p>I love complex, interconnected, foundational problems, so having the opportunity to tackle this was a really fun\u00a0project.</p><p><strong><em>What brought you to this career? What is your favorite thing about the work that you\u2019re doing\u00a0now?</em></strong></p><p>I started my career in marketing. I had always loved big, out-of-home advertising, but the marketing world shifted, and I found my role to be more focused on click-throughs than creative output. I finally ended up in a role where I was a stakeholder for a product team. Through this role, I attended the demos and saw how the product teams worked together, and it really resonated with me\u200a\u2014\u200aeveryone was really transparent and open in their communication!</p><p>I switched over to product management and never looked back! One of my favorite things about PED<em> [Product, Engineering, and Design]</em> is that it\u2019s very collaborative. I love how everyone in the team brings different expertise, skills, and experience, which is what makes a great\u00a0product.</p><p><strong><em>For anyone who might join VTS, what can they expect? What pleasantly surprised you?</em></strong></p><p>VTS is a company that lives its values more than other companies I\u2019ve been a part of. We have 6 values that are important to us, and we don\u2019t just act on them in isolated moments; we look to incorporate them throughout the\u00a0year.</p><p>One way I\u2019ve seen this happen is when things happen in the world; we call on our values to re-center everyone and talk about what is acceptable behavior and what is not. I think that shows the human side of VTS\u200a\u2014\u200athat we are willing to acknowledge what is going on in the world and how it might impact our people internally.</p><p><strong><em>What advice would you give to someone who is considering product management as a\u00a0career?</em></strong></p><p>Product management is great, but it\u2019s not always what it seems like on the outside. There\u2019s this idea that PMs are the CEOs of their product; the reality of this statement really depends on what you understand a CEO\u2019s role and responsibility to\u00a0be.</p><p>Some people have the perspective that a CEO makes decisions in an isolated fashion, and what they say goes. The way I see it is that a CEO facilitates conversations with the people around them to understand what\u2019s important, which helps the CEO make better decisions. They are not making decisions in a single-minded way based on what they think to be best\u200a\u2014\u200athey are leveraging all of the knowledge and experiences of the team around them to make the best decisions.</p><p>Product is similar as you rely on the people around you who have different expertise to help you understand the full scenario. You have to know how to facilitate the right conversations with stakeholders, and you have to ask the right questions within your squad. You have to be very good at listening and hearing what people are trying to tell you to get a pulse on everything to make the right tradeoffs. You have to put your ego aside and advocate for what you believe is the right decision. This role can be a balancing act but can be so rewarding when the product comes together, and you see it out in the\u00a0world.</p><p><strong><em>What interested you in VTS &amp; how did you know it was the right fit for\u00a0you?</em></strong></p><p>I knew someone who worked here, and they told me how VTS had a good work-life balance. I\u2019ve been working long enough that I know what my deal breakers are, and being a part of a company that understands humans need time away to recharge our batteries and come back stronger, is key. Where I\u2019ve seen this in action at VTS is through perks like summer Fridays, VTS summer vacation, or the unlimited vacation policy, and managers who check in to make sure you are taking that\u00a0time!</p><p>This is so important to me that at the time when I joined VTS, I even took a step back with respect to my role and title, going from a Lead Product Manager role to a Senior Product Manager role at VTS. Ultimately, my career has grown and will continue to grow with\u00a0VTS.</p><p><strong><em>What is a fun fact about\u00a0you?</em></strong></p><p>My husband and I got a grant to make a short film a few years ago in 2016! We co-wrote it, and my husband directed it while I produced and managed a crew of 20 people. Since then, I\u2019ve dabbled in a follow-up project but haven\u2019t settled on anything to see through just yet. I\u2019m also renovating our house with my husband. We\u2019ve brought in electricians and plumbers, but otherwise, we\u2019re doing it ourselves! We\u2019ve broken down walls to the studs, tiled the floor (wouldn\u2019t do that again), put up drywall, door frames, and all that jazz. We\u2019ve taken on a couple of pretty big projects together! When I\u2019m not doing manual labor or creative projects in my spare time, I like cycling, surfing, and traveling.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6128bb5325e4\" width=\"1\" /><hr /><p><a href=\"https://buildingvts.com/day-in-the-life-vts-sorren-isler-lead-product-manager-6128bb5325e4\">Day in the Life @ VTS: Sorren Isler, Lead Product Manager</a> was originally published in <a href=\"https://buildingvts.com\">Building VTS</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p><strong><em>VTS is composed of individuals with a wide array of characteristics, skills, experiences and outlooks\u200a\u2014\u200aand we\u2019re eager for you to get to know them! We\u2019ve crafted this series to give you a closer look at the vibrant lives they have and the environment they help foster, so that each VTSer can be their authentic self.</em></strong></p><p><strong><em>Next in our series is Sorren Isler, Lead Product Manager, who has been with VTS since December\u00a02020.</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/656/1*uHfemEFvqqfp2m0Oqsm_qg.png\" /></figure><p><strong><em>In a sentence or two\u200a\u2014\u200awhat do you do here at\u00a0VTS?</em></strong></p><p>I am a Lead Product Manager on VTS Activate\u200a\u2014\u200aour tenant experience business unit (also known as\u00a0TenEx).</p><p><strong><em>Tell us more about your\u00a0team.</em></strong></p><p>I have a couple of areas of ownership and accountability. The first is my squad, where I\u2019m the Product IC (Individual Contributor). Within my squad, we\u2019re focused on building hardware interfaces and experiences. For example, our hardware work up-levels our visitor management software product because it allows building visitors to sign in without hassle. Once they arrive, the hosts automatically receive a notification. This helps take the weight off the folks working at the front desk, who usually only have a device or two to get everyone in the building.</p><p>My squad includes an Engineering Manager, a Designer, a number of Software Engineers, and our QA. We have a very collaborative team and even though we work across different time zones, we talk asynchronously. It\u2019s important to us that everyone feels comfortable bringing up issues and concerns, so when someone raises their hand, the team jumps in whether they need help or an opinion on a topic. One way we build ownership in the team is by rotating who takes on the role of sprint lead for each sprint. This gives everyone the chance to take ownership, support the team, and mix things up! If there are different ways one may choose to run the rituals, this is a great time to experiment with different formats and approaches.</p><p>As a mission lead, I need to zoom out to an even more holistic view as I think about our overarching mission, its overlap with other missions, and how our strategies and work can best deliver impact for VTS Activate. This part of my role is focused on considering how multiple pieces connect across multiple squads (beyond those just with hardware dependencies) and missions, the overarching UX team, and our stakeholders to create a vision for how everything works together.</p><p><strong><em>What is the problem your team is\u00a0solving?</em></strong></p><p>My squad\u2019s ultimate goal is to create a hardware strategy and roadmap that supports key software across TenEx so that our users have a comprehensive and easy experience doing what they need to\u00a0do.</p><p>My mission\u2019s goal is to support our users as they move through buildings and every area they should have access\u00a0to.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Mnn9HEdKzbMrA2OLfMGbdA.jpeg\" /></figure><p><strong><em>What is a typical day like for\u00a0you?</em></strong></p><p>I often jump between different areas of focus throughout my day. My priorities will often shift, but I\u2019m likely touching both squad and mission lead work each day of the\u00a0week.</p><p>As a Lead Product Manager, my day-to-day involves our squad rituals, squad syncs, and cross-squad dependency syncs. Our squad syncs could be anything from 1:1s, to full squad meetings to discuss processes, upcoming features, design run-throughs, refinement, or roadmap planning.</p><p>Oftentimes I\u2019m also meeting with people outside of hardware squads to understand how different potential hardware may support their product. This often is to help plan out our next focus area and how we might work in parallel with any teams we have dependencies with.</p><p>As a mission lead, I\u2019m working with stakeholders outside of PED <em>[Product, Engineering and Design</em>] to understand access to our product from different perspectives. This could involve conversations with Client teams to better understand gaps and opportunities or the Solutions team to understand capabilities at a market level. At this stage, my mission focus is bringing me a lot of discovery, analysis, and data\u00a0work.</p><p><strong><em>What is your favorite project you\u2019ve had at VTS so\u00a0far?</em></strong></p><p>For my first 2 years at VTS, I worked on VTS Lease on the mobile team, as well as some additional projects, including a strategy for a holistic global experience.</p><p>Being a Mobile PM, I\u2019m often in a unique position where I have oversight across multiple features and multiple teams. So, as I became familiar with the website, I started to notice a gap in the holistic ownership of the website; the website had so many different teams but no one accountable for the overarching information architecture that created the larger\u00a0vision.</p><p>After identifying that gap, I got to work with the VP of Design and Staff Engineer for a quarter, pulling together a business case and pitch to address this need. Through this, we did an audit of the sitemap and all pages, workshops with client stakeholders to uncover more gaps and validate some of the things we were seeing, and then pulled together some initial high-level concepts for how we might approach it all. We pulled this into our business case and created a pitch alongside a number of others pitching different ideas.</p><p>I love complex, interconnected, foundational problems, so having the opportunity to tackle this was a really fun\u00a0project.</p><p><strong><em>What brought you to this career? What is your favorite thing about the work that you\u2019re doing\u00a0now?</em></strong></p><p>I started my career in marketing. I had always loved big, out-of-home advertising, but the marketing world shifted, and I found my role to be more focused on click-throughs than creative output. I finally ended up in a role where I was a stakeholder for a product team. Through this role, I attended the demos and saw how the product teams worked together, and it really resonated with me\u200a\u2014\u200aeveryone was really transparent and open in their communication!</p><p>I switched over to product management and never looked back! One of my favorite things about PED<em> [Product, Engineering, and Design]</em> is that it\u2019s very collaborative. I love how everyone in the team brings different expertise, skills, and experience, which is what makes a great\u00a0product.</p><p><strong><em>For anyone who might join VTS, what can they expect? What pleasantly surprised you?</em></strong></p><p>VTS is a company that lives its values more than other companies I\u2019ve been a part of. We have 6 values that are important to us, and we don\u2019t just act on them in isolated moments; we look to incorporate them throughout the\u00a0year.</p><p>One way I\u2019ve seen this happen is when things happen in the world; we call on our values to re-center everyone and talk about what is acceptable behavior and what is not. I think that shows the human side of VTS\u200a\u2014\u200athat we are willing to acknowledge what is going on in the world and how it might impact our people internally.</p><p><strong><em>What advice would you give to someone who is considering product management as a\u00a0career?</em></strong></p><p>Product management is great, but it\u2019s not always what it seems like on the outside. There\u2019s this idea that PMs are the CEOs of their product; the reality of this statement really depends on what you understand a CEO\u2019s role and responsibility to\u00a0be.</p><p>Some people have the perspective that a CEO makes decisions in an isolated fashion, and what they say goes. The way I see it is that a CEO facilitates conversations with the people around them to understand what\u2019s important, which helps the CEO make better decisions. They are not making decisions in a single-minded way based on what they think to be best\u200a\u2014\u200athey are leveraging all of the knowledge and experiences of the team around them to make the best decisions.</p><p>Product is similar as you rely on the people around you who have different expertise to help you understand the full scenario. You have to know how to facilitate the right conversations with stakeholders, and you have to ask the right questions within your squad. You have to be very good at listening and hearing what people are trying to tell you to get a pulse on everything to make the right tradeoffs. You have to put your ego aside and advocate for what you believe is the right decision. This role can be a balancing act but can be so rewarding when the product comes together, and you see it out in the\u00a0world.</p><p><strong><em>What interested you in VTS &amp; how did you know it was the right fit for\u00a0you?</em></strong></p><p>I knew someone who worked here, and they told me how VTS had a good work-life balance. I\u2019ve been working long enough that I know what my deal breakers are, and being a part of a company that understands humans need time away to recharge our batteries and come back stronger, is key. Where I\u2019ve seen this in action at VTS is through perks like summer Fridays, VTS summer vacation, or the unlimited vacation policy, and managers who check in to make sure you are taking that\u00a0time!</p><p>This is so important to me that at the time when I joined VTS, I even took a step back with respect to my role and title, going from a Lead Product Manager role to a Senior Product Manager role at VTS. Ultimately, my career has grown and will continue to grow with\u00a0VTS.</p><p><strong><em>What is a fun fact about\u00a0you?</em></strong></p><p>My husband and I got a grant to make a short film a few years ago in 2016! We co-wrote it, and my husband directed it while I produced and managed a crew of 20 people. Since then, I\u2019ve dabbled in a follow-up project but haven\u2019t settled on anything to see through just yet. I\u2019m also renovating our house with my husband. We\u2019ve brought in electricians and plumbers, but otherwise, we\u2019re doing it ourselves! We\u2019ve broken down walls to the studs, tiled the floor (wouldn\u2019t do that again), put up drywall, door frames, and all that jazz. We\u2019ve taken on a couple of pretty big projects together! When I\u2019m not doing manual labor or creative projects in my spare time, I like cycling, surfing, and traveling.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6128bb5325e4\" width=\"1\" /><hr /><p><a href=\"https://buildingvts.com/day-in-the-life-vts-sorren-isler-lead-product-manager-6128bb5325e4\">Day in the Life @ VTS: Sorren Isler, Lead Product Manager</a> was originally published in <a href=\"https://buildingvts.com\">Building VTS</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Hashnode": {
    "title": "Hashnode's Feed Architecture",
    "xmlUrl": "https://engineering.hashnode.com/rss.xml",
    "htmlUrl": "https://engineering.hashnode.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.hashnode.com/rss.xml",
      "value": "Hashnode's Feed Architecture"
    },
    "summary": "<p>We <a href=\"https://engineering.hashnode.com/the-art-of-feed-curating-our-approach-to-generating-personalized-feeds-that-match-users-interests\" target=\"_blank\">previously explained</a> how we calculate the Hashnode Feed and select content and metadata for each user. We found that the feed now displays improved and personalized content. However, we did find two issues in the implementation:</p><ul><li><p><strong>Performance</strong>: The Feed calculation is not trivial; thus, it slows down the access to our main page.</p></li><li><p><strong>Security</strong>: Many expensive queries and aggregations are needed to gather all the data required for the calculation. Safeguarding our database from excessive usage is a must.</p></li></ul><p>Speeding up the page, keeping our databased safe, and showing the freshest content for you on the Hompage was the inspiration for building Feeds on steroids: a scalable and serverless architecture to pre-calculate feeds for recurring users \ud83d\udc8a</p><p><img alt=\"High level overview of Hashnode's scalable feed architecture\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701676684074/b5095a33-6ce7-4119-8a9b-78acc6afe43a.png\" /></p><p>To optimize page speed, we found that pre-calculating feeds for users is the best option. This means we don't have to calculate the feed every time a user visits our feed page. Instead, we can return the feed from the cache and make page loading times faster. A crucial enabler for this is using a cache. With the fast access a cache offers, we can directly load the feed from there to be presented for our users. The above image shows this in a very high abstraction. We are calculating feeds using data from our internal database and a cache for relevant metadata. The calculated data is then stored in a cache for quick access.</p><p>Let's take a look at how everything comes together in detail </p><h2 id=\"heading-pre-calculating-feeds-for-thousands-of-users-with-aws-step-functions\">Pre-calculating feeds for thousands of users with AWS Step Functions \ud83d\ude0e</h2><p><img alt=\"Detailed overview of Hashnode's scalable feed architecture\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701675809464/e1fe24b7-4c14-4fd3-8499-7dad71d9abbb.png\" /></p><p>We calculate the feed for each user based on internal Hashnode events. These events require a re-calculation of the feeds. An example here is publishing a new post on Hashnode.</p><ul><li><p><strong>Prepare the cache</strong>: Before we start calculating each feed, we must ensure that all data required is in the cache. The final calculation step is wholly based on the cache. This includes user metadata, relevant data for posts, and active users for whom we are pre-calculating. If data is unavailable in the cache or too old for usage, we pull fresh data from our internal database.</p></li><li><p><strong>Calculate the feed</strong>: We start the actual calculation when all data is prepared and ready in the cache. We use an AWS Step Function feature called distributed map execution to do this in parallel. We can calculate multiple feeds simultaneously and reduce execution time. Each calculation has its own AWS Lambda function.</p></li></ul><p>If each user's feed would be calculated on the fly, we would see longer loading times on Hashnode's main page. To do the calculation, we need a lot of data. We must get all the data from the database. This will affect other queries. Lastly, a simple approach like that seems wasteful. We are pulling in the same data again and again for the calculation without reusing it.</p><p>The above architecture reference shows the feed pre-calculation process. We utilize a couple of services to achieve a performant recalculation on various triggers:</p><ul><li><p>AWS Lambda</p></li><li><p>AWS Step Functions</p></li><li><p>Redis Cache</p></li><li><p>Distributed Maps in Step Functions</p></li><li><p>Amazon EventBridge</p></li></ul><p>Once an event that requires feed re-calculation reaches the AWS Step Function, we will run different checks and collect the necessary data. A new feed for each active user on our platform is then generated. We minimize database access and store necessary data in a cache for fast access. Utilizing our event-driven architecture allows us to react to different events within the system and keep the cache up-to-date.</p><p>Let's look at the core parts and what's happening there.</p><h3 id=\"heading-preparing-data-in-the-cache\">Preparing data in the cache</h3><p><img alt=\"Preparing user relevant data for the calculation\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701270335460/57af6b77-a4d0-454b-809b-f083e581d2ed.png\" /></p><p>When an event triggers an AWS Step Function, we must have all the required data for the calculation step. The first step is to check if the cache has valid data. If not, fill it. The main data for feed calculation are posts. The first AWS Lambda in the AWS Step Function execution will check if we have valid data in the cache for the posts we base our calculation on. Valid in this context refers to data that is not outdated and available in the cache.</p><p>Once this is resolved, we can go to the next ingredient for calculation: getting the active users. When no active user is found, we skip the further execution altogether.</p><p>Based on the active users, we can now check if the personalization component, the user's metadata, is available in the cache. If metadata is found, we can directly calculate the feed. Otherwise, we have to collect the metadata beforehand from the database and save it to the cache.</p><p>These last two steps are done by utilizing <a href=\"https://docs.aws.amazon.com/step-functions/latest/dg/use-dist-map-orchestrate-large-scale-parallel-workloads.html\" target=\"_blank\">distributed maps</a>. One map for users whom we have found valid metadata in our cache. One for users where no metadata data was found, and we need to collect it before starting the actual calculation</p><h3 id=\"heading-distributed-map-for-users-where-metadata-is-available\">Distributed map for users where metadata is available</h3><p><img alt=\"Calculating the feed for users where metadata was found in the cache\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701270466651/8c1223e0-ee2e-4a02-8679-39b606dd10ba.png\" /></p><p>We find valid metadata for a user. The previous steps of our AWS Step Function provided all the required data. We can now start calculating the user's feed directly. Notice how no database is involved in this step anymore.</p><h3 id=\"heading-distributed-map-for-users-where-metadata-is-not-available\">Distributed map for users where metadata is not available</h3><p><img alt=\"Calculating the feed for users where no metadata was found in the cache\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701270435343/37161cbd-b9f6-49d6-9ad8-ca9d5e870ca2.png\" /></p><p>No metadata found for the user requires us to prepare it before starting the calculation. A preceding AWS Lambda function handles this before the actual calculation is done. The database is queried to collect the user's metadata, and the result is stored in our cache. Again, the calculation step does not require any database connection to do its job.</p><hr /><p>The two distributed maps share the same final step of the feed calculation. Once succeeded, we save the result, the user's feed, in the cache for fast access via our APIs. To make the process faster and use less bandwidth, we use item batching in the AWS Step Function. This allows us to share post data with the items in the same batch. We would have to get the post data and metadata information for each user otherwise.</p><p><img alt=\"Feed calculation execution duration\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1699864467563/5db1457e-34da-484f-acf3-36c71ef0753c.png\" /></p><p>A typical AWS Step Function run has a duration of ~26 seconds - while calculating the feed for thousands of users \ud83d\ude80</p><h2 id=\"heading-getting-rid-of-stale-data-purging-and-re-calculating-feeds-on-a-period\">Getting rid of stale data - Purging and re-calculating feeds on a period</h2><p>We decided to purge the whole cache regularly, even though we have implemented householding for our cache. We also have various steps in the AWS Step Function that validate cache data before the calculation is done.</p><p>A cron job runs the AWS Step Function every couple of hours to delete all data in the cache. This is a safety measure and reassurance that we only store essential data briefly. We can ignore events that may affect the feed for a longer time. The updates from these events will be included after the next purge. This is a nice bonus. This saves some implementation effort for low-priority events regarding feed re-calculation. The AWS Step Function will refill the cache when the feed is empty.</p><h2 id=\"heading-final-words\">Final words</h2><p>This post should give you a rough idea of calculating feeds on the scale and which services we apply. Are you interested in more feed-related content? If so, let us know in the comments - we have a couple more crips implementation details ready to be published \ud83d\ude4c</p><p>Cheers \ud83d\ude4c</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.hashnode.com/rss.xml",
      "value": "<p>We <a href=\"https://engineering.hashnode.com/the-art-of-feed-curating-our-approach-to-generating-personalized-feeds-that-match-users-interests\" target=\"_blank\">previously explained</a> how we calculate the Hashnode Feed and select content and metadata for each user. We found that the feed now displays improved and personalized content. However, we did find two issues in the implementation:</p><ul><li><p><strong>Performance</strong>: The Feed calculation is not trivial; thus, it slows down the access to our main page.</p></li><li><p><strong>Security</strong>: Many expensive queries and aggregations are needed to gather all the data required for the calculation. Safeguarding our database from excessive usage is a must.</p></li></ul><p>Speeding up the page, keeping our databased safe, and showing the freshest content for you on the Hompage was the inspiration for building Feeds on steroids: a scalable and serverless architecture to pre-calculate feeds for recurring users \ud83d\udc8a</p><p><img alt=\"High level overview of Hashnode's scalable feed architecture\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701676684074/b5095a33-6ce7-4119-8a9b-78acc6afe43a.png\" /></p><p>To optimize page speed, we found that pre-calculating feeds for users is the best option. This means we don't have to calculate the feed every time a user visits our feed page. Instead, we can return the feed from the cache and make page loading times faster. A crucial enabler for this is using a cache. With the fast access a cache offers, we can directly load the feed from there to be presented for our users. The above image shows this in a very high abstraction. We are calculating feeds using data from our internal database and a cache for relevant metadata. The calculated data is then stored in a cache for quick access.</p><p>Let's take a look at how everything comes together in detail </p><h2 id=\"heading-pre-calculating-feeds-for-thousands-of-users-with-aws-step-functions\">Pre-calculating feeds for thousands of users with AWS Step Functions \ud83d\ude0e</h2><p><img alt=\"Detailed overview of Hashnode's scalable feed architecture\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701675809464/e1fe24b7-4c14-4fd3-8499-7dad71d9abbb.png\" /></p><p>We calculate the feed for each user based on internal Hashnode events. These events require a re-calculation of the feeds. An example here is publishing a new post on Hashnode.</p><ul><li><p><strong>Prepare the cache</strong>: Before we start calculating each feed, we must ensure that all data required is in the cache. The final calculation step is wholly based on the cache. This includes user metadata, relevant data for posts, and active users for whom we are pre-calculating. If data is unavailable in the cache or too old for usage, we pull fresh data from our internal database.</p></li><li><p><strong>Calculate the feed</strong>: We start the actual calculation when all data is prepared and ready in the cache. We use an AWS Step Function feature called distributed map execution to do this in parallel. We can calculate multiple feeds simultaneously and reduce execution time. Each calculation has its own AWS Lambda function.</p></li></ul><p>If each user's feed would be calculated on the fly, we would see longer loading times on Hashnode's main page. To do the calculation, we need a lot of data. We must get all the data from the database. This will affect other queries. Lastly, a simple approach like that seems wasteful. We are pulling in the same data again and again for the calculation without reusing it.</p><p>The above architecture reference shows the feed pre-calculation process. We utilize a couple of services to achieve a performant recalculation on various triggers:</p><ul><li><p>AWS Lambda</p></li><li><p>AWS Step Functions</p></li><li><p>Redis Cache</p></li><li><p>Distributed Maps in Step Functions</p></li><li><p>Amazon EventBridge</p></li></ul><p>Once an event that requires feed re-calculation reaches the AWS Step Function, we will run different checks and collect the necessary data. A new feed for each active user on our platform is then generated. We minimize database access and store necessary data in a cache for fast access. Utilizing our event-driven architecture allows us to react to different events within the system and keep the cache up-to-date.</p><p>Let's look at the core parts and what's happening there.</p><h3 id=\"heading-preparing-data-in-the-cache\">Preparing data in the cache</h3><p><img alt=\"Preparing user relevant data for the calculation\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701270335460/57af6b77-a4d0-454b-809b-f083e581d2ed.png\" /></p><p>When an event triggers an AWS Step Function, we must have all the required data for the calculation step. The first step is to check if the cache has valid data. If not, fill it. The main data for feed calculation are posts. The first AWS Lambda in the AWS Step Function execution will check if we have valid data in the cache for the posts we base our calculation on. Valid in this context refers to data that is not outdated and available in the cache.</p><p>Once this is resolved, we can go to the next ingredient for calculation: getting the active users. When no active user is found, we skip the further execution altogether.</p><p>Based on the active users, we can now check if the personalization component, the user's metadata, is available in the cache. If metadata is found, we can directly calculate the feed. Otherwise, we have to collect the metadata beforehand from the database and save it to the cache.</p><p>These last two steps are done by utilizing <a href=\"https://docs.aws.amazon.com/step-functions/latest/dg/use-dist-map-orchestrate-large-scale-parallel-workloads.html\" target=\"_blank\">distributed maps</a>. One map for users whom we have found valid metadata in our cache. One for users where no metadata data was found, and we need to collect it before starting the actual calculation</p><h3 id=\"heading-distributed-map-for-users-where-metadata-is-available\">Distributed map for users where metadata is available</h3><p><img alt=\"Calculating the feed for users where metadata was found in the cache\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701270466651/8c1223e0-ee2e-4a02-8679-39b606dd10ba.png\" /></p><p>We find valid metadata for a user. The previous steps of our AWS Step Function provided all the required data. We can now start calculating the user's feed directly. Notice how no database is involved in this step anymore.</p><h3 id=\"heading-distributed-map-for-users-where-metadata-is-not-available\">Distributed map for users where metadata is not available</h3><p><img alt=\"Calculating the feed for users where no metadata was found in the cache\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701270435343/37161cbd-b9f6-49d6-9ad8-ca9d5e870ca2.png\" /></p><p>No metadata found for the user requires us to prepare it before starting the calculation. A preceding AWS Lambda function handles this before the actual calculation is done. The database is queried to collect the user's metadata, and the result is stored in our cache. Again, the calculation step does not require any database connection to do its job.</p><hr /><p>The two distributed maps share the same final step of the feed calculation. Once succeeded, we save the result, the user's feed, in the cache for fast access via our APIs. To make the process faster and use less bandwidth, we use item batching in the AWS Step Function. This allows us to share post data with the items in the same batch. We would have to get the post data and metadata information for each user otherwise.</p><p><img alt=\"Feed calculation execution duration\" class=\"image--center mx-auto\" src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1699864467563/5db1457e-34da-484f-acf3-36c71ef0753c.png\" /></p><p>A typical AWS Step Function run has a duration of ~26 seconds - while calculating the feed for thousands of users \ud83d\ude80</p><h2 id=\"heading-getting-rid-of-stale-data-purging-and-re-calculating-feeds-on-a-period\">Getting rid of stale data - Purging and re-calculating feeds on a period</h2><p>We decided to purge the whole cache regularly, even though we have implemented householding for our cache. We also have various steps in the AWS Step Function that validate cache data before the calculation is done.</p><p>A cron job runs the AWS Step Function every couple of hours to delete all data in the cache. This is a safety measure and reassurance that we only store essential data briefly. We can ignore events that may affect the feed for a longer time. The updates from these events will be included after the next purge. This is a nice bonus. This saves some implementation effort for low-priority events regarding feed re-calculation. The AWS Step Function will refill the cache when the feed is empty.</p><h2 id=\"heading-final-words\">Final words</h2><p>This post should give you a rough idea of calculating feeds on the scale and which services we apply. Are you interested in more feed-related content? If so, let us know in the comments - we have a couple more crips implementation details ready to be published \ud83d\ude4c</p><p>Cheers \ud83d\ude4c</p>"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.hashnode.com/hashnodes-feed-architecture"
      }
    ],
    "link": "https://engineering.hashnode.com/hashnodes-feed-architecture",
    "id": "https://engineering.hashnode.com/hashnodes-feed-architecture",
    "guidislink": false,
    "authors": [
      {
        "name": "Florian Fuchs"
      }
    ],
    "author": "Florian Fuchs",
    "author_detail": {
      "name": "Florian Fuchs"
    },
    "published": "Thu, 07 Dec 2023 11:00:17 GMT",
    "published_parsed": [
      2023,
      12,
      7,
      11,
      0,
      17,
      3,
      341,
      0
    ],
    "cover_image": "https://cdn.hashnode.com/res/hashnode/image/upload/v1699961744035/51aa7ebc-e811-44bd-97e1-ed00e3506fbc.png"
  },
  "Novoda": {
    "title": "We\u2019re a B Corp! Here\u2019s what it means for our clients and impact.",
    "xmlUrl": "https://blog.novoda.com/rss/",
    "htmlUrl": "https://www.novoda.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://novoda.com/blog/feed/",
      "value": "We\u2019re a B Corp! Here\u2019s what it means for our clients and impact."
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://novoda.com/blog/2023/11/16/novoda-is-a-b-corp/"
      }
    ],
    "link": "https://novoda.com/blog/2023/11/16/novoda-is-a-b-corp/",
    "authors": [
      {
        "name": "tally"
      }
    ],
    "author": "tally",
    "author_detail": {
      "name": "tally"
    },
    "published": "Thu, 16 Nov 2023 14:59:45 +0000",
    "published_parsed": [
      2023,
      11,
      16,
      14,
      59,
      45,
      3,
      320,
      0
    ],
    "tags": [
      {
        "term": "Good Business",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://novoda.com/?p=10414",
    "guidislink": false,
    "summary": "<p>We\u2019re now part of a group of purpose-led, forward-thinking, conscious businesses. Let\u2019s break it down and get a bit more personal about what B Corp status means for us and our clients. </p>\n<p>The post <a href=\"https://novoda.com/blog/2023/11/16/novoda-is-a-b-corp/\" rel=\"nofollow\">We\u2019re a B Corp! Here\u2019s what it means for our clients and impact.</a> appeared first on <a href=\"https://novoda.com\" rel=\"nofollow\">Novoda</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://novoda.com/blog/feed/",
      "value": "<p>We\u2019re now part of a group of purpose-led, forward-thinking, conscious businesses. Let\u2019s break it down and get a bit more personal about what B Corp status means for us and our clients. </p>\n<p>The post <a href=\"https://novoda.com/blog/2023/11/16/novoda-is-a-b-corp/\" rel=\"nofollow\">We\u2019re a B Corp! Here\u2019s what it means for our clients and impact.</a> appeared first on <a href=\"https://novoda.com\" rel=\"nofollow\">Novoda</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://novoda.com/blog/feed/",
        "value": "<p><strong><em>By Carl-Gustaf Harroch and Julia Zaman</em></strong></p>\n\n\n\n<p>It&rsquo;s official, Novoda has joined the ranks of more than 7,000 businesses in 92 countries that have achieved B Corp certification. We couldn&rsquo;t be prouder of our team who have worked so hard to get us here, or more excited for what B Corp accreditation represents for the future of Novoda.</p>\n\n\n\n<p>Becoming part of the <a href=\"https://www.bcorporation.net/en-us/\">B Lab</a> global network means that we&rsquo;re now part of a group of purpose-led, forward-thinking, conscious businesses whose mission is to transform the global economy to the benefit of people, communities and the planet.&nbsp;</p>\n\n\n\n<p>Now, that&rsquo;s a big mission! So, let&rsquo;s break it down and get a bit more personal about what B Corp status means for us and our clients.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-10416\" height=\"576\" src=\"https://novoda.com/wp-content/uploads/2023/11/b-corp-1024x576.jpg\" width=\"1024\" /></figure>\n\n\n\n<h2 class=\"wp-block-heading\">What B Corp means to us</h2>\n\n\n\n<p>When we embarked on the <a href=\"https://novoda.com/blog/2023/03/21/novoda-relaunch/\">Novoda rebrand</a>, we knew we wanted to put doing good at the core of our business. We wanted to have a purpose that every single person in the company could unite behind. We had ambitious goals, and we were looking for a framework to help us achieve them &ndash; and that&rsquo;s exactly what B Corp has been for us.</p>\n\n\n\n<p>Joining the B Corp community has also opened the doors to an incredible network of like-minded business owners who share our philosophy when it comes to business for good, and who continually inspire us to keep learning and improving.</p>\n\n\n\n<p>What&rsquo;s more, having official recognition from B Lab gives us the confidence that we&rsquo;re doing all we can to be a sustainable, ethical, person-centred business. Of course, there&rsquo;s always room for improvement, and being part of the B Corp community helps us to keep thinking about the positive changes we can make now and in the future.</p>\n\n\n\n<blockquote class=\"wp-block-quote\">\n<p>&ldquo;The B Corp accreditation is the main reason I joined Novoda. I was drawn to work here because I have an innate desire to create a positive impact in the world, and I saw an opportunity for that.&rdquo;&nbsp;</p>\n<cite><strong>S<strong>arah Gruneisen</strong></strong>, Director of Engineering</cite></blockquote>\n\n\n\n<h2 class=\"wp-block-heading\">What B Corp has taught us</h2>\n\n\n\n<p>One of our biggest learnings from the B Corp process is that it&rsquo;s within the power of ANY business &ndash; no matter your sector &ndash; to do good. We&rsquo;re certainly not the same company that started this process, we&rsquo;ve learned and reframed so much of what we believe and how we operate along the way.</p>\n\n\n\n<p>We&rsquo;ve always known that the people who work at Novoda are what makes us so special &ndash; and it&rsquo;s been incredible to see how everyone has banded together during the B Corp process, wholeheartedly embracing all the changes we&rsquo;ve made along the way. Knowing we&rsquo;ve made this happen together has hugely strengthened our team.&nbsp;</p>\n\n\n\n<p>There is something incredibly empowering about coming to work and knowing you&rsquo;re doing good in the world &ndash; that&rsquo;s not an opportunity everyone gets. Going through the process has strengthened our foundational principles and positively impacted how we work together, the work we do and the decisions we make.</p>\n\n\n\n<p>But the process has also taught us that there is still work to be done. We want to go above and beyond the B Corp requirements. For us, this process was much more than a tick-box exercise, and we&rsquo;ll continue to focus on making more impact in our strongest areas of community, learning, wellbeing and reward.&nbsp;&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"Illustration of a pair of hands holding a brain and a heart\" class=\"wp-image-9374\" height=\"348\" src=\"https://novoda.com/wp-content/uploads/2022/10/Head-and-heart.svg\" width=\"648\" /></figure>\n\n\n\n<h2 class=\"wp-block-heading\">How B Corp has changed our approach to business</h2>\n\n\n\n<p>Our identity as a B Corp has become a fundamental part of how we operate &ndash; it&rsquo;s not just a tag on to business as usual. We take pride in the fact that, together with thousands of other businesses around the world, we are working together to create something better.</p>\n\n\n\n<p>It&rsquo;s important to us that the clients we work with share our values and intentions, and we&rsquo;re looking forward to our B Corp journey becoming a key part of our sales and marketing conversations. Having the accreditation means we can step confidently into these discussions and demonstrate our commitment to the B Corp vision for an inclusive, equitable and regenerative global economy in everything we do.</p>\n\n\n\n<p>Interestingly, we&rsquo;ve met very few fellow tech companies that have achieved B Corp status &ndash; but we want to see more of them. We believe that when you combine innovation in technology with a vision for a better world, incredible things can happen.&nbsp;</p>\n\n\n\n<p>For example, we would love to dig deeper into how technology can be used as a force for good in the areas of privacy, democracy and equality. Big tech has a bad reputation in these areas, but they need to be tackled &ndash; and we hope to see more funding and investment become available for this kind of work in the future.</p>\n\n\n\n<blockquote class=\"wp-block-quote\">\n<p>&ldquo;As part of the B Corp process, we had to sign a declaration of interdependence, showing that we are committed to working together with other businesses to make something better. I love this idea.&rdquo;</p>\n<cite><strong>Carl-Gustaf Harroch,</strong> Founder &amp; MD</cite></blockquote>\n\n\n\n<h2 class=\"wp-block-heading\">How becoming a B Corp benefits our clients</h2>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"A group of people talking and laughing in a circle\" class=\"wp-image-9402\" height=\"683\" src=\"https://novoda.com/wp-content/uploads/2022/10/NOVODA_HEADSHOTS_1440L-1-1024x683.jpg\" width=\"1024\" /></figure>\n\n\n\n<p>First and foremost, we are humans &ndash; it&rsquo;s always been the case at Novoda, but now it&rsquo;s written into the fabric of how we do business.&nbsp;</p>\n\n\n\n<p>We bring the human touch into everything we do &ndash; we aren&rsquo;t robots with a rate card, we bring genuinely creative thinking that adds huge value to our clients. B Corp has given us a framework to align our products with our purpose, which isn&rsquo;t the case for most agencies.&nbsp;</p>\n\n\n\n<p>As a team, we&rsquo;re feeling motivated and inspired to apply our values to every single project we work on in the future and make great things happen as a result.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Considering becoming a B Corp? </h2>\n\n\n\n<h3 class=\"wp-block-heading\">Here&rsquo;s our advice&hellip;</h3>\n\n\n\n<ul>\n<li>Start now! It&rsquo;s a long process and there&rsquo;s no time like the present to get started on the journey. It will have a huge impact on your business and will prompt deep reflections that can be transformative.&nbsp;</li>\n\n\n\n<li>Don&rsquo;t think you&rsquo;re ready? Look at your business carefully and be open to the possibility that you can have more of an impact than you think.</li>\n\n\n\n<li>Lean on and engage with the incredible B Corp community throughout your accreditation and beyond &ndash; the fellow businesses we&rsquo;ve met have been amazing, leading us to excellent conversations and ideas on how to implement our ideas and aspirations.</li>\n\n\n\n<li>If you&rsquo;re a service-based company, it&rsquo;s easy to think you don&rsquo;t have that many emissions &ndash; but you still do! We did a carbon footprinting workshop and it was eye-opening, one of our biggest impacts (and easiest to reduce) was from banking, which many businesses don&rsquo;t think about.</li>\n\n\n\n<li>B-Corp is just the first step, together as businesses we have the potential to do so much more good in the world!</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\">Want to find out more about working with us?</h2>\n\n\n\n<p>Book a discovery call and let&rsquo;s talk about making good things happen for your business and in the world.</p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><img alt=\"The Novoda Team\" class=\"wp-image-9100\" height=\"73\" src=\"https://novoda.com/wp-content/uploads/2022/10/The-Novoda-Team-1.png\" style=\"width: 452px; height: 73px;\" width=\"452\" /></figure>\n<p>The post <a href=\"https://novoda.com/blog/2023/11/16/novoda-is-a-b-corp/\" rel=\"nofollow\">We\u2019re a B Corp! Here\u2019s what it means for our clients and impact.</a> appeared first on <a href=\"https://novoda.com\" rel=\"nofollow\">Novoda</a>.</p>"
      }
    ]
  },
  "Commercetools": {
    "title": "How we evaluated the impact of GitHub Copilot for 3 months",
    "xmlUrl": "https://techblog.commercetools.com/feed",
    "htmlUrl": "https://techblog.commercetools.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://techblog.commercetools.com/feed",
      "value": "How we evaluated the impact of GitHub Copilot for 3 months"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://techblog.commercetools.com/how-we-evaluated-the-impact-of-github-copilot-for-3-months-b36f8c10c4f8?source=rss----d3d69d818e3d---4"
      }
    ],
    "link": "https://techblog.commercetools.com/how-we-evaluated-the-impact-of-github-copilot-for-3-months-b36f8c10c4f8?source=rss----d3d69d818e3d---4",
    "id": "https://medium.com/p/b36f8c10c4f8",
    "guidislink": false,
    "tags": [
      {
        "term": "github-copilot",
        "scheme": null,
        "label": null
      },
      {
        "term": "generative-ai-tools",
        "scheme": null,
        "label": null
      },
      {
        "term": "ai",
        "scheme": null,
        "label": null
      },
      {
        "term": "llm",
        "scheme": null,
        "label": null
      },
      {
        "term": "github",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Tobias Deekens"
      }
    ],
    "author": "Tobias Deekens",
    "author_detail": {
      "name": "Tobias Deekens"
    },
    "published": "Wed, 13 Sep 2023 15:25:38 GMT",
    "published_parsed": [
      2023,
      9,
      13,
      15,
      25,
      38,
      2,
      256,
      0
    ],
    "updated": "2023-09-13T15:25:38.815Z",
    "updated_parsed": [
      2023,
      9,
      13,
      15,
      25,
      38,
      2,
      256,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://techblog.commercetools.com/feed",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/779/1*u_rS9hD-IXZsJaL0pUmfXA@2x.png\" /><figcaption>We evaluated GitHub Copilot for three\u00a0months</figcaption></figure><p>GitHub announced its launch of <a href=\"https://docs.github.com/en/enterprise-cloud@latest/copilot/overview-of-github-copilot/about-github-copilot-for-business\"><strong>GitHub Copilot for Business</strong></a> in February of this year. This announcement <strong>immediately caught our attention</strong> and interest, and engineers across the organization shared their desire to use this product. After aligning internally on an adoption strategy, we decided to <strong>evaluate GitHub Copilot for three months to learn how it can help</strong> us be more productive.</p><p><a href=\"https://commercetools.com/blog/how-we-evaluated-the-impact-of-github-copilot-for-3-months\"><strong>This blog post</strong></a> describes our path to evaluating and adopting GitHub\u00a0Copilot.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b36f8c10c4f8\" width=\"1\" /><hr /><p><a href=\"https://techblog.commercetools.com/how-we-evaluated-the-impact-of-github-copilot-for-3-months-b36f8c10c4f8\">How we evaluated the impact of GitHub Copilot for 3 months</a> was originally published in <a href=\"https://techblog.commercetools.com\">commercetools tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/779/1*u_rS9hD-IXZsJaL0pUmfXA@2x.png\" /><figcaption>We evaluated GitHub Copilot for three\u00a0months</figcaption></figure><p>GitHub announced its launch of <a href=\"https://docs.github.com/en/enterprise-cloud@latest/copilot/overview-of-github-copilot/about-github-copilot-for-business\"><strong>GitHub Copilot for Business</strong></a> in February of this year. This announcement <strong>immediately caught our attention</strong> and interest, and engineers across the organization shared their desire to use this product. After aligning internally on an adoption strategy, we decided to <strong>evaluate GitHub Copilot for three months to learn how it can help</strong> us be more productive.</p><p><a href=\"https://commercetools.com/blog/how-we-evaluated-the-impact-of-github-copilot-for-3-months\"><strong>This blog post</strong></a> describes our path to evaluating and adopting GitHub\u00a0Copilot.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b36f8c10c4f8\" width=\"1\" /><hr /><p><a href=\"https://techblog.commercetools.com/how-we-evaluated-the-impact-of-github-copilot-for-3-months-b36f8c10c4f8\">How we evaluated the impact of GitHub Copilot for 3 months</a> was originally published in <a href=\"https://techblog.commercetools.com\">commercetools tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "HomeAway": {
    "title": "We\u2019ve Moved\u2026",
    "xmlUrl": "https://medium.com/feed/homeaway-tech-blog",
    "htmlUrl": "https://tech.homeaway.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/homeaway-tech-blog",
      "value": "We\u2019ve Moved\u2026"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/homeaway-tech-blog/weve-moved-6748186fb6cf?source=rss----c8142f33b9ec---4"
      }
    ],
    "link": "https://medium.com/homeaway-tech-blog/weve-moved-6748186fb6cf?source=rss----c8142f33b9ec---4",
    "id": "https://medium.com/p/6748186fb6cf",
    "guidislink": false,
    "tags": [
      {
        "term": "expedia-group",
        "scheme": null,
        "label": null
      },
      {
        "term": "homeaway",
        "scheme": null,
        "label": null
      },
      {
        "term": "tech",
        "scheme": null,
        "label": null
      },
      {
        "term": "technology",
        "scheme": null,
        "label": null
      },
      {
        "term": "vrbo",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "HomeAway"
      }
    ],
    "author": "HomeAway",
    "author_detail": {
      "name": "HomeAway"
    },
    "published": "Wed, 03 Jul 2019 16:10:26 GMT",
    "published_parsed": [
      2019,
      7,
      3,
      16,
      10,
      26,
      2,
      184,
      0
    ],
    "updated": "2019-07-08T16:58:13.060Z",
    "updated_parsed": [
      2019,
      7,
      8,
      16,
      58,
      13,
      0,
      189,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/homeaway-tech-blog",
        "value": "<h4>Check us out on the <a href=\"https://medium.com/expedia-group-tech\">Expedia Group Tech\u00a0Blog</a>!</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WHdqOBjHJDcDfpnLV6uQNQ.jpeg\" /></figure><p>HomeAway is now <a href=\"https://www.vrbo.com/\">Vrbo</a>, part of <a href=\"https://www.expediagroup.com/\">Expedia Group</a>, and we are excited to add our tech stories to the <a href=\"https://medium.com/expedia-group-tech\">Expedia Group Technology blog</a> on\u00a0Medium!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/424/1*r6A0SrGMnC14SsPfi7pwtw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*R-d3BExs_O4SsM21got0RA.png\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6748186fb6cf\" width=\"1\" /><hr /><p><a href=\"https://medium.com/homeaway-tech-blog/weve-moved-6748186fb6cf\">We\u2019ve Moved\u2026</a> was originally published in <a href=\"https://medium.com/homeaway-tech-blog\">HomeAway Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h4>Check us out on the <a href=\"https://medium.com/expedia-group-tech\">Expedia Group Tech\u00a0Blog</a>!</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WHdqOBjHJDcDfpnLV6uQNQ.jpeg\" /></figure><p>HomeAway is now <a href=\"https://www.vrbo.com/\">Vrbo</a>, part of <a href=\"https://www.expediagroup.com/\">Expedia Group</a>, and we are excited to add our tech stories to the <a href=\"https://medium.com/expedia-group-tech\">Expedia Group Technology blog</a> on\u00a0Medium!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/424/1*r6A0SrGMnC14SsPfi7pwtw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*R-d3BExs_O4SsM21got0RA.png\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6748186fb6cf\" width=\"1\" /><hr /><p><a href=\"https://medium.com/homeaway-tech-blog/weve-moved-6748186fb6cf\">We\u2019ve Moved\u2026</a> was originally published in <a href=\"https://medium.com/homeaway-tech-blog\">HomeAway Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Okta": {
    "title": "How I Built an Okta Documentation Chatbot in Python",
    "xmlUrl": "https://developer.okta.com/feed.xml",
    "htmlUrl": "https://developer.okta.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://developer.okta.com/feed.xml",
      "value": "How I Built an Okta Documentation Chatbot in Python"
    },
    "summary": "<p>In today\u2019s fast-paced world of technology, developers must navigate through detailed API documentation to integrate with software solutions. As a Developer Support Intern at Okta, I noticed developers underutilizing <a href=\"https://developer.okta.com/\">Okta\u2019s Developer Documentation</a>. To help them benefit from the wealth of information in these docs, I was inspired to build a tool using OpenAI. Leveraging ChatGPT, I built \u2728Oktanaut\u2728, a versatile Python chatbot running on Jupyter Notebook that makes access to information on Okta\u2019s Developer Documentation simple and straightforward.</p>\n\n<p><img alt=\"OktaDev Forum and SDK logo\" class=\"center-image\" height=\"400\" src=\"https://developer.okta.com/assets-jekyll/blog/okta-documentation-chatbot/oktadevforumsdk-c888c276f3cc4d9a230aa1f0800a6bd7504977c57282dee890eb58ea402f6004.jpg\" /> \n\u2013 Image source: <cite><a href=\"https://raw.githubusercontent.com/oktadev/.github/main/images/okta-dev-header.png\">Okta Developer GitHub</a></cite></p>\n\n<h2 id=\"evolution-of-oktanaut-a-python-chatbot\">Evolution of Oktanaut, a Python Chatbot</h2>\n<p>I developed two versions of Oktanaut. The first version was a specific approach, offering greater precision rather than general knowledge. I built the prototype chatbot using LlamaIndex and trained it on the Okta Developer Documentation. While this version generated accurate responses due to its focused training, it could not handle diverse questions.</p>\n\n<p>The second version, a versatile approach, utilized the capabilities of the <a href=\"https://chat.openai.com/auth/login\">OpenAI GPT-3.5 API</a>; it generated responses based on a broader sample of user inquiries. This version handled various questions, providing a dynamic, self-learning, and interactive experience.</p>\n\n<p>The trade-off between precision and versatility was obvious when comparing the two versions. The LLamaIndex-based Oktanaut version excelled in accuracy, while the GPT-3.5-powered version generated better responses to a broader set of questions. The final chatbot I chose to demo in this blog uses OpenAI API as it has bigger models to run inquiries and is more user-friendly.</p>\n\n<h2 id=\"meticulous-training-on-oktas-developer-documentation-for-enhanced-performance\">Meticulous Training on Okta\u2019s Developer Documentation for Enhanced Performance</h2>\n<p>For both versions, meticulous training was a necessary building block. Carefully refining the training data helped the bot produce more accurate responses to edge cases and custom-specific questions. I collected training data, including curated sample questions, answers, and information provided by Okta\u2019s Developer Support Engineers. I stored this data in Google Drive to run on <a href=\"https://colab.google/\">Colab</a>. Additionally, I transformed the chatbot into a self-learning entity by storing historical interactions, allowing it to learn from its mistakes. This self-improvement mechanism allowed the chatbot to utilize context information from past responses within the session to provide more informed responses.</p>\n\n<h2 id=\"personalizing-the-conversational-experience-with-the-python-chatbot-ai\">Personalizing the Conversational Experience with the Python Chatbot AI</h2>\n<p>I programmed the chatbot to greet users with its name, functionality, and purpose. Doing so added a personal touch that will help minimize potential confusion users may have when interacting with the chatbot.</p>\n\n<p>I utilized a Python library called <a href=\"https://panel.holoviz.org/getting_started/installation.html\">Panel</a> on the frontend to achieve a user-friendly interface. Building the interface was not as simple as I first expected. The Panel library has several bugs and glitches, and considering a frontend built-in Python is uncommon. When I considered deployment options, I decided to run Oktanaut on Jupyter Notebook to ensure a simple setup process for everyone.</p>\n\n<h2 id=\"demonstrating-oktanauts-ai-chat-potential\">Demonstrating Oktanaut\u2019s AI Chat Potential</h2>\n<p>The completed code for the OpenAI version of the chatbot can be found <a href=\"https://github.com/oktadev/okta-python-chatbot-example\">here</a>.</p>\n\n<p>Key terms to note before diving into the Python code:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">model:\"gpt-3.5-turbo\"</code>: Specifies the GPT-3.5 Turbo model used for conversation.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">messages</code>: The list of messages that make up the conversation.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">temperature</code>: A parameter that controls the randomness of the model\u2019s responses.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">continue_conversation</code>: This function takes a list of messages as input and continues the conversation with the GPT-3.5 Turbo model. It sends the messages to the model and receives a response.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">add_prompts_conversation</code>: This function adds prompts to the conversation and retrieves responses from the chatbot.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">client_prompt</code>: The user asks a question about Okta in this input field.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">role</code>: The user\u2019s input adds to the conversation with the role \u201cuser.\u201d</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">continue_conversation</code>: This function retrieves the chatbot\u2019s response in string format.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">assistant</code>: This role adds The chatbot\u2019s response to the conversation.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">context list</code>: This initializes the conversation with a system message that introduces Oktanaut, the chatbot. It provides information about the bot\u2019s purpose and capabilities.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">pn.extension()</code>: This line initializes the Panel library.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">panels list</code>: This list stores the components displayed in the web interface.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">client_prompt input field</code>: This widget allows users to input their questions or prompts for Oktanaut.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">button_conversation</code>: This submits the user\u2019s question, calls the function and queries the API, leading to the conversation with the chatbot.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">interactive_conversation function binding</code>: This binds the add_prompts_conversation function to the button_conversation button, so the function is called when the user clicks the button.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">dashboard layout</code>: This section assembles the dashboard for the chatbot, including the input field, the conversation button, and the chatbot\u2019s responses.</li>\n</ul>\n\n<div class=\"language-py highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">continue_conversation</span><span class=\"p\">(</span><span class=\"n\">messages</span><span class=\"p\">,</span> <span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span>\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">openai</span><span class=\"p\">.</span><span class=\"n\">ChatCompletion</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span>\n        <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"s\">\"gpt-3.5-turbo\"</span><span class=\"p\">,</span>\n        <span class=\"n\">messages</span><span class=\"o\">=</span><span class=\"n\">messages</span><span class=\"p\">,</span>\n        <span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"n\">temperature</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n    <span class=\"c1\">#print(str(response.choices[0].message[\"content\"]))\n</span>    <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">choices</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">].</span><span class=\"n\">message</span><span class=\"p\">[</span><span class=\"s\">\"content\"</span><span class=\"p\">]</span>\n</code></pre></div></div>\n\n<div class=\"language-py highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">add_prompts_conversation</span><span class=\"p\">(</span><span class=\"n\">_</span><span class=\"p\">):</span>\n    <span class=\"n\">prompt</span> <span class=\"o\">=</span> <span class=\"n\">client_prompt</span><span class=\"p\">.</span><span class=\"n\">value_input</span>\n    <span class=\"n\">client_prompt</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"o\">=</span> <span class=\"s\">''</span>\n\n    <span class=\"n\">context</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">({</span><span class=\"s\">'role'</span><span class=\"p\">:</span><span class=\"s\">'user'</span><span class=\"p\">,</span> <span class=\"s\">'content'</span><span class=\"p\">:</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"n\">prompt</span><span class=\"si\">}</span><span class=\"s\">\"</span><span class=\"p\">})</span>\n\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">continue_conversation</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">)</span>\n\n    <span class=\"n\">context</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">({</span><span class=\"s\">'role'</span><span class=\"p\">:</span><span class=\"s\">'assistant'</span><span class=\"p\">,</span> <span class=\"s\">'content'</span><span class=\"p\">:</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"n\">response</span><span class=\"si\">}</span><span class=\"s\">\"</span><span class=\"p\">})</span>\n\n    <span class=\"n\">panels</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span>\n        <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Row</span><span class=\"p\">(</span><span class=\"s\">'Developer:'</span><span class=\"p\">,</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">pane</span><span class=\"p\">.</span><span class=\"n\">Markdown</span><span class=\"p\">(</span><span class=\"n\">prompt</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">600</span><span class=\"p\">)))</span>\n    <span class=\"n\">panels</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span>\n        <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Row</span><span class=\"p\">(</span><span class=\"s\">'Oktanaut:'</span><span class=\"p\">,</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">pane</span><span class=\"p\">.</span><span class=\"n\">Markdown</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">600</span><span class=\"p\">)))</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Column</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">panels</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-py highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">context</span> <span class=\"o\">=</span> <span class=\"p\">[</span> <span class=\"p\">{</span><span class=\"s\">'role'</span><span class=\"p\">:</span><span class=\"s\">'system'</span><span class=\"p\">,</span> <span class=\"s\">'content'</span><span class=\"p\">:</span><span class=\"s\">\"\"\"'I am Oktanaut, a helpful chatbot meant to answer your questions about Okta and OAuth Developer Documentation. I answer questions from Okta Developer Documentation. How may I help you? (Say \"thank you\" to end the session) </span><span class=\"se\">\\n</span><span class=\"s\">'\"\"\"</span><span class=\"p\">}</span> <span class=\"p\">]</span>\n\n<span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">extension</span><span class=\"p\">()</span>\n\n<span class=\"n\">panels</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n<span class=\"n\">client_prompt</span> <span class=\"o\">=</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">widgets</span><span class=\"p\">.</span><span class=\"n\">TextInput</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"o\">=</span><span class=\"s\">\"Hi\"</span><span class=\"p\">,</span> <span class=\"n\">placeholder</span><span class=\"o\">=</span><span class=\"s\">'Enter your questions here...'</span><span class=\"p\">)</span>\n<span class=\"n\">button_conversation</span> <span class=\"o\">=</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">widgets</span><span class=\"p\">.</span><span class=\"n\">Button</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s\">\"Chat with Oktanaut!\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">interactive_conversation</span> <span class=\"o\">=</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">bind</span><span class=\"p\">(</span><span class=\"n\">add_prompts_conversation</span><span class=\"p\">,</span> <span class=\"n\">button_conversation</span><span class=\"p\">)</span>\n\n<span class=\"n\">dashboard</span> <span class=\"o\">=</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Column</span><span class=\"p\">(</span>\n    <span class=\"n\">client_prompt</span><span class=\"p\">,</span>\n    <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Row</span><span class=\"p\">(</span><span class=\"n\">button_conversation</span><span class=\"p\">),</span>\n    <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">panel</span><span class=\"p\">(</span><span class=\"n\">interactive_conversation</span><span class=\"p\">,</span> <span class=\"n\">loading_indicator</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">),</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">dashboard</span>\n</code></pre></div></div>\n\n<p>The code for the Jupiter Python Notebook above, <a href=\"https://github.com/oktadev/okta-python-chatbot-example/blob/main/GPTChatbot.ipynb\">okta-python-chatbot-example\n/GPTChatbot.ipynb</a>, is for summoning Oktanaut.</p>\n\n<p>Here\u2019s a step-by-step walkthrough of how to run the code:</p>\n\n<ol>\n  <li>\n    <p>With a Google account, ensure you have access to <a href=\"https://colab.google/\">Colab</a>; this will be the environment we will use to run the Python scripts.</p>\n  </li>\n  <li>\n    <p>Library installation: The script begins with installing the required Python packages:</p>\n    <ul>\n      <li><a href=\"https://pypi.org/project/openai/\">OpenAI</a></li>\n      <li><a href=\"https://panel.holoviz.org/getting_started/installation.html\">Panel</a></li>\n      <li><a href=\"https://pypi.org/project/llama-index/\">LlamaIndex</a></li>\n    </ul>\n  </li>\n</ol>\n\n<p>These packages work with the GPT-3.5 model, create the web interface, and manage the chatbot\u2019s conversation. The LlamaIndex package is only used to read data in the OpenAI implementation of the bot.</p>\n\n<ol>\n  <li>Create an OpenAI account and follow these <a href=\"https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key\">instructions</a> to obtain an API Key. On line 161 of <code class=\"language-plaintext highlighter-rouge\">GPTChatbot.ipynb</code>, replace the API Key code snippet with your API Key. ChatGPT used to offer free credits to use, but it now costs five or more dollars to purchase API usage.</li>\n</ol>\n\n<p><img alt=\"Image with an arrow pointing to where the OpenAI API key should be added in the code.\" class=\"center-image\" height=\"400\" src=\"https://developer.okta.com/assets-jekyll/blog/okta-documentation-chatbot/openai-api-key-e8d78ac3a43c75963f066dcfa99f4afeb1aa4f02bdbd52a1ffb21045f394d969.jpg\" /></p>\n\n<ol>\n  <li>\n    <p>Download the Okta Developer Documentation files from <a href=\"https://github.com/oktadev/okta-python-chatbot-example/tree/tar-file\">here</a>, and extract the archive. Upload the archive contents to a folder named \u2018oktanaut\u2019 in your Google Drive.<br />\n Make sure the training files are in the <code class=\"language-plaintext highlighter-rouge\">oktanaut</code> folder, not in an additional folder within it. If you change the name of the folder where you keep the files in your Google Drive, update line 167 of <code class=\"language-plaintext highlighter-rouge\">GPTChatbot.ipynb</code> to the correct path.  Alternatively, you can download the files directly from the Okta Developer Documentation Repository, or supply your own custom training data.</p>\n  </li>\n  <li>\n    <p>Run the <code class=\"language-plaintext highlighter-rouge\">GPTChatbot.ipynb</code> notebook in your Colab development environment.</p>\n  </li>\n  <li>\n    <p>After running the script, a web interface displays an input field and a \u201cChat with Oktanaut!\u201d button.</p>\n  </li>\n  <li>\n    <p>Enter your questions about the Okta Developer Documentation in the input field.</p>\n  </li>\n  <li>\n    <p>To submit your question, click the \u201cChat with Oktanaut!\u201d button to begin a conversation with the Python chatbot.</p>\n  </li>\n  <li>\n    <p>Oktanaut will answer your question with an AI-generated response using its knowledge from the developer documentation, training data from internal support engineers, and the OpenAI API. The responses will appear on the web interface in real-time.</p>\n  </li>\n  <li>\n    <p>Continue the conversation by entering additional questions or prompts and clicking the button. The bot will use your questions from earlier in the conversation to improve its understanding of your needs, and provide contextually appropriate answers as you converse with it.</p>\n  </li>\n  <li>\n    <p>To end the session, say \u201cThank you\u201d or leave the web page.</p>\n  </li>\n</ol>\n\n<p><img alt=\"Image of Oktanaut's answer to, 'What is OIDC?'\" class=\"center-image\" height=\"400\" src=\"https://developer.okta.com/assets-jekyll/blog/okta-documentation-chatbot/openai-oidc-1addb48f146ee8edee1d214084a186e452c1aa910212c3f4e73f0bbc605c8e62.jpg\" /></p>\n\n<h2 id=\"further-python-chatbot-improvements\">Further Python Chatbot Improvements</h2>\n<p>I am enthusiastic about enhancing Oktanaut\u2019s training by incorporating information from the Okta Dev Forum and Okta\u2019s Software Developer Kits (SDKs). In the future, I hope to collaborate with the Okta Developer Documentation team to improve information gaps in the documentation. I also want to add a feature to automatically update to the latest version of the Okta Developer Documentation so that the data Oktanaut references is up-to-date and reliable.</p>\n\n<p>Have you thought about building your own chatbot with AI? Would you like to know more about how I built Oktanaut? Let me know in the comments below! Want to stay in touch? Follow our social channels @oktadev on <a href=\"https://twitter.com/oktadev\">Twitter</a> and subscribe to our <a href=\"https://www.youtube.com/c/oktadev\">YouTube</a> channel.</p>\n\n<h2 id=\"python-chatbot-resources\">Python Chatbot Resources</h2>\n<ul>\n  <li><a href=\"https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api-a-few-tips-and-tricks-on-controlling-the-creativity-deterministic-output-of-prompt-responses/172683/10\">Cheat Sheet: Mastering Temperature and Top_p in ChatGPT API (a few tips and tricks on controlling the creativity/deterministic output of prompt responses.)</a></li>\n  <li><a href=\"https://www.coltsteele.com/tips/understanding-openai-s-temperature-parameter\">Understanding OpenAI\u2019s Temperature Parameter</a></li>\n</ul>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://developer.okta.com/feed.xml",
      "value": "<p>In today\u2019s fast-paced world of technology, developers must navigate through detailed API documentation to integrate with software solutions. As a Developer Support Intern at Okta, I noticed developers underutilizing <a href=\"https://developer.okta.com/\">Okta\u2019s Developer Documentation</a>. To help them benefit from the wealth of information in these docs, I was inspired to build a tool using OpenAI. Leveraging ChatGPT, I built \u2728Oktanaut\u2728, a versatile Python chatbot running on Jupyter Notebook that makes access to information on Okta\u2019s Developer Documentation simple and straightforward.</p>\n\n<p><img alt=\"OktaDev Forum and SDK logo\" class=\"center-image\" height=\"400\" src=\"https://developer.okta.com/assets-jekyll/blog/okta-documentation-chatbot/oktadevforumsdk-c888c276f3cc4d9a230aa1f0800a6bd7504977c57282dee890eb58ea402f6004.jpg\" /> \n\u2013 Image source: <cite><a href=\"https://raw.githubusercontent.com/oktadev/.github/main/images/okta-dev-header.png\">Okta Developer GitHub</a></cite></p>\n\n<h2 id=\"evolution-of-oktanaut-a-python-chatbot\">Evolution of Oktanaut, a Python Chatbot</h2>\n<p>I developed two versions of Oktanaut. The first version was a specific approach, offering greater precision rather than general knowledge. I built the prototype chatbot using LlamaIndex and trained it on the Okta Developer Documentation. While this version generated accurate responses due to its focused training, it could not handle diverse questions.</p>\n\n<p>The second version, a versatile approach, utilized the capabilities of the <a href=\"https://chat.openai.com/auth/login\">OpenAI GPT-3.5 API</a>; it generated responses based on a broader sample of user inquiries. This version handled various questions, providing a dynamic, self-learning, and interactive experience.</p>\n\n<p>The trade-off between precision and versatility was obvious when comparing the two versions. The LLamaIndex-based Oktanaut version excelled in accuracy, while the GPT-3.5-powered version generated better responses to a broader set of questions. The final chatbot I chose to demo in this blog uses OpenAI API as it has bigger models to run inquiries and is more user-friendly.</p>\n\n<h2 id=\"meticulous-training-on-oktas-developer-documentation-for-enhanced-performance\">Meticulous Training on Okta\u2019s Developer Documentation for Enhanced Performance</h2>\n<p>For both versions, meticulous training was a necessary building block. Carefully refining the training data helped the bot produce more accurate responses to edge cases and custom-specific questions. I collected training data, including curated sample questions, answers, and information provided by Okta\u2019s Developer Support Engineers. I stored this data in Google Drive to run on <a href=\"https://colab.google/\">Colab</a>. Additionally, I transformed the chatbot into a self-learning entity by storing historical interactions, allowing it to learn from its mistakes. This self-improvement mechanism allowed the chatbot to utilize context information from past responses within the session to provide more informed responses.</p>\n\n<h2 id=\"personalizing-the-conversational-experience-with-the-python-chatbot-ai\">Personalizing the Conversational Experience with the Python Chatbot AI</h2>\n<p>I programmed the chatbot to greet users with its name, functionality, and purpose. Doing so added a personal touch that will help minimize potential confusion users may have when interacting with the chatbot.</p>\n\n<p>I utilized a Python library called <a href=\"https://panel.holoviz.org/getting_started/installation.html\">Panel</a> on the frontend to achieve a user-friendly interface. Building the interface was not as simple as I first expected. The Panel library has several bugs and glitches, and considering a frontend built-in Python is uncommon. When I considered deployment options, I decided to run Oktanaut on Jupyter Notebook to ensure a simple setup process for everyone.</p>\n\n<h2 id=\"demonstrating-oktanauts-ai-chat-potential\">Demonstrating Oktanaut\u2019s AI Chat Potential</h2>\n<p>The completed code for the OpenAI version of the chatbot can be found <a href=\"https://github.com/oktadev/okta-python-chatbot-example\">here</a>.</p>\n\n<p>Key terms to note before diving into the Python code:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">model:\"gpt-3.5-turbo\"</code>: Specifies the GPT-3.5 Turbo model used for conversation.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">messages</code>: The list of messages that make up the conversation.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">temperature</code>: A parameter that controls the randomness of the model\u2019s responses.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">continue_conversation</code>: This function takes a list of messages as input and continues the conversation with the GPT-3.5 Turbo model. It sends the messages to the model and receives a response.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">add_prompts_conversation</code>: This function adds prompts to the conversation and retrieves responses from the chatbot.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">client_prompt</code>: The user asks a question about Okta in this input field.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">role</code>: The user\u2019s input adds to the conversation with the role \u201cuser.\u201d</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">continue_conversation</code>: This function retrieves the chatbot\u2019s response in string format.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">assistant</code>: This role adds The chatbot\u2019s response to the conversation.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">context list</code>: This initializes the conversation with a system message that introduces Oktanaut, the chatbot. It provides information about the bot\u2019s purpose and capabilities.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">pn.extension()</code>: This line initializes the Panel library.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">panels list</code>: This list stores the components displayed in the web interface.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">client_prompt input field</code>: This widget allows users to input their questions or prompts for Oktanaut.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">button_conversation</code>: This submits the user\u2019s question, calls the function and queries the API, leading to the conversation with the chatbot.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">interactive_conversation function binding</code>: This binds the add_prompts_conversation function to the button_conversation button, so the function is called when the user clicks the button.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">dashboard layout</code>: This section assembles the dashboard for the chatbot, including the input field, the conversation button, and the chatbot\u2019s responses.</li>\n</ul>\n\n<div class=\"language-py highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">continue_conversation</span><span class=\"p\">(</span><span class=\"n\">messages</span><span class=\"p\">,</span> <span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span>\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">openai</span><span class=\"p\">.</span><span class=\"n\">ChatCompletion</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span>\n        <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"s\">\"gpt-3.5-turbo\"</span><span class=\"p\">,</span>\n        <span class=\"n\">messages</span><span class=\"o\">=</span><span class=\"n\">messages</span><span class=\"p\">,</span>\n        <span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"n\">temperature</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n    <span class=\"c1\">#print(str(response.choices[0].message[\"content\"]))\n</span>    <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">choices</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">].</span><span class=\"n\">message</span><span class=\"p\">[</span><span class=\"s\">\"content\"</span><span class=\"p\">]</span>\n</code></pre></div></div>\n\n<div class=\"language-py highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">add_prompts_conversation</span><span class=\"p\">(</span><span class=\"n\">_</span><span class=\"p\">):</span>\n    <span class=\"n\">prompt</span> <span class=\"o\">=</span> <span class=\"n\">client_prompt</span><span class=\"p\">.</span><span class=\"n\">value_input</span>\n    <span class=\"n\">client_prompt</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"o\">=</span> <span class=\"s\">''</span>\n\n    <span class=\"n\">context</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">({</span><span class=\"s\">'role'</span><span class=\"p\">:</span><span class=\"s\">'user'</span><span class=\"p\">,</span> <span class=\"s\">'content'</span><span class=\"p\">:</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"n\">prompt</span><span class=\"si\">}</span><span class=\"s\">\"</span><span class=\"p\">})</span>\n\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">continue_conversation</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">)</span>\n\n    <span class=\"n\">context</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">({</span><span class=\"s\">'role'</span><span class=\"p\">:</span><span class=\"s\">'assistant'</span><span class=\"p\">,</span> <span class=\"s\">'content'</span><span class=\"p\">:</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"n\">response</span><span class=\"si\">}</span><span class=\"s\">\"</span><span class=\"p\">})</span>\n\n    <span class=\"n\">panels</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span>\n        <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Row</span><span class=\"p\">(</span><span class=\"s\">'Developer:'</span><span class=\"p\">,</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">pane</span><span class=\"p\">.</span><span class=\"n\">Markdown</span><span class=\"p\">(</span><span class=\"n\">prompt</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">600</span><span class=\"p\">)))</span>\n    <span class=\"n\">panels</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span>\n        <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Row</span><span class=\"p\">(</span><span class=\"s\">'Oktanaut:'</span><span class=\"p\">,</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">pane</span><span class=\"p\">.</span><span class=\"n\">Markdown</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">600</span><span class=\"p\">)))</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Column</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">panels</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-py highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">context</span> <span class=\"o\">=</span> <span class=\"p\">[</span> <span class=\"p\">{</span><span class=\"s\">'role'</span><span class=\"p\">:</span><span class=\"s\">'system'</span><span class=\"p\">,</span> <span class=\"s\">'content'</span><span class=\"p\">:</span><span class=\"s\">\"\"\"'I am Oktanaut, a helpful chatbot meant to answer your questions about Okta and OAuth Developer Documentation. I answer questions from Okta Developer Documentation. How may I help you? (Say \"thank you\" to end the session) </span><span class=\"se\">\\n</span><span class=\"s\">'\"\"\"</span><span class=\"p\">}</span> <span class=\"p\">]</span>\n\n<span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">extension</span><span class=\"p\">()</span>\n\n<span class=\"n\">panels</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n<span class=\"n\">client_prompt</span> <span class=\"o\">=</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">widgets</span><span class=\"p\">.</span><span class=\"n\">TextInput</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"o\">=</span><span class=\"s\">\"Hi\"</span><span class=\"p\">,</span> <span class=\"n\">placeholder</span><span class=\"o\">=</span><span class=\"s\">'Enter your questions here...'</span><span class=\"p\">)</span>\n<span class=\"n\">button_conversation</span> <span class=\"o\">=</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">widgets</span><span class=\"p\">.</span><span class=\"n\">Button</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s\">\"Chat with Oktanaut!\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">interactive_conversation</span> <span class=\"o\">=</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">bind</span><span class=\"p\">(</span><span class=\"n\">add_prompts_conversation</span><span class=\"p\">,</span> <span class=\"n\">button_conversation</span><span class=\"p\">)</span>\n\n<span class=\"n\">dashboard</span> <span class=\"o\">=</span> <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Column</span><span class=\"p\">(</span>\n    <span class=\"n\">client_prompt</span><span class=\"p\">,</span>\n    <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">Row</span><span class=\"p\">(</span><span class=\"n\">button_conversation</span><span class=\"p\">),</span>\n    <span class=\"n\">pn</span><span class=\"p\">.</span><span class=\"n\">panel</span><span class=\"p\">(</span><span class=\"n\">interactive_conversation</span><span class=\"p\">,</span> <span class=\"n\">loading_indicator</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">),</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">dashboard</span>\n</code></pre></div></div>\n\n<p>The code for the Jupiter Python Notebook above, <a href=\"https://github.com/oktadev/okta-python-chatbot-example/blob/main/GPTChatbot.ipynb\">okta-python-chatbot-example\n/GPTChatbot.ipynb</a>, is for summoning Oktanaut.</p>\n\n<p>Here\u2019s a step-by-step walkthrough of how to run the code:</p>\n\n<ol>\n  <li>\n    <p>With a Google account, ensure you have access to <a href=\"https://colab.google/\">Colab</a>; this will be the environment we will use to run the Python scripts.</p>\n  </li>\n  <li>\n    <p>Library installation: The script begins with installing the required Python packages:</p>\n    <ul>\n      <li><a href=\"https://pypi.org/project/openai/\">OpenAI</a></li>\n      <li><a href=\"https://panel.holoviz.org/getting_started/installation.html\">Panel</a></li>\n      <li><a href=\"https://pypi.org/project/llama-index/\">LlamaIndex</a></li>\n    </ul>\n  </li>\n</ol>\n\n<p>These packages work with the GPT-3.5 model, create the web interface, and manage the chatbot\u2019s conversation. The LlamaIndex package is only used to read data in the OpenAI implementation of the bot.</p>\n\n<ol>\n  <li>Create an OpenAI account and follow these <a href=\"https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key\">instructions</a> to obtain an API Key. On line 161 of <code class=\"language-plaintext highlighter-rouge\">GPTChatbot.ipynb</code>, replace the API Key code snippet with your API Key. ChatGPT used to offer free credits to use, but it now costs five or more dollars to purchase API usage.</li>\n</ol>\n\n<p><img alt=\"Image with an arrow pointing to where the OpenAI API key should be added in the code.\" class=\"center-image\" height=\"400\" src=\"https://developer.okta.com/assets-jekyll/blog/okta-documentation-chatbot/openai-api-key-e8d78ac3a43c75963f066dcfa99f4afeb1aa4f02bdbd52a1ffb21045f394d969.jpg\" /></p>\n\n<ol>\n  <li>\n    <p>Download the Okta Developer Documentation files from <a href=\"https://github.com/oktadev/okta-python-chatbot-example/tree/tar-file\">here</a>, and extract the archive. Upload the archive contents to a folder named \u2018oktanaut\u2019 in your Google Drive.<br />\n Make sure the training files are in the <code class=\"language-plaintext highlighter-rouge\">oktanaut</code> folder, not in an additional folder within it. If you change the name of the folder where you keep the files in your Google Drive, update line 167 of <code class=\"language-plaintext highlighter-rouge\">GPTChatbot.ipynb</code> to the correct path.  Alternatively, you can download the files directly from the Okta Developer Documentation Repository, or supply your own custom training data.</p>\n  </li>\n  <li>\n    <p>Run the <code class=\"language-plaintext highlighter-rouge\">GPTChatbot.ipynb</code> notebook in your Colab development environment.</p>\n  </li>\n  <li>\n    <p>After running the script, a web interface displays an input field and a \u201cChat with Oktanaut!\u201d button.</p>\n  </li>\n  <li>\n    <p>Enter your questions about the Okta Developer Documentation in the input field.</p>\n  </li>\n  <li>\n    <p>To submit your question, click the \u201cChat with Oktanaut!\u201d button to begin a conversation with the Python chatbot.</p>\n  </li>\n  <li>\n    <p>Oktanaut will answer your question with an AI-generated response using its knowledge from the developer documentation, training data from internal support engineers, and the OpenAI API. The responses will appear on the web interface in real-time.</p>\n  </li>\n  <li>\n    <p>Continue the conversation by entering additional questions or prompts and clicking the button. The bot will use your questions from earlier in the conversation to improve its understanding of your needs, and provide contextually appropriate answers as you converse with it.</p>\n  </li>\n  <li>\n    <p>To end the session, say \u201cThank you\u201d or leave the web page.</p>\n  </li>\n</ol>\n\n<p><img alt=\"Image of Oktanaut's answer to, 'What is OIDC?'\" class=\"center-image\" height=\"400\" src=\"https://developer.okta.com/assets-jekyll/blog/okta-documentation-chatbot/openai-oidc-1addb48f146ee8edee1d214084a186e452c1aa910212c3f4e73f0bbc605c8e62.jpg\" /></p>\n\n<h2 id=\"further-python-chatbot-improvements\">Further Python Chatbot Improvements</h2>\n<p>I am enthusiastic about enhancing Oktanaut\u2019s training by incorporating information from the Okta Dev Forum and Okta\u2019s Software Developer Kits (SDKs). In the future, I hope to collaborate with the Okta Developer Documentation team to improve information gaps in the documentation. I also want to add a feature to automatically update to the latest version of the Okta Developer Documentation so that the data Oktanaut references is up-to-date and reliable.</p>\n\n<p>Have you thought about building your own chatbot with AI? Would you like to know more about how I built Oktanaut? Let me know in the comments below! Want to stay in touch? Follow our social channels @oktadev on <a href=\"https://twitter.com/oktadev\">Twitter</a> and subscribe to our <a href=\"https://www.youtube.com/c/oktadev\">YouTube</a> channel.</p>\n\n<h2 id=\"python-chatbot-resources\">Python Chatbot Resources</h2>\n<ul>\n  <li><a href=\"https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api-a-few-tips-and-tricks-on-controlling-the-creativity-deterministic-output-of-prompt-responses/172683/10\">Cheat Sheet: Mastering Temperature and Top_p in ChatGPT API (a few tips and tricks on controlling the creativity/deterministic output of prompt responses.)</a></li>\n  <li><a href=\"https://www.coltsteele.com/tips/understanding-openai-s-temperature-parameter\">Understanding OpenAI\u2019s Temperature Parameter</a></li>\n</ul>"
    },
    "published": "Wed, 20 Dec 2023 00:00:00 -0500",
    "published_parsed": [
      2023,
      12,
      20,
      5,
      0,
      0,
      2,
      354,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://developer.okta.com/blog/2023/12/20/okta-documentation-chatbot"
      }
    ],
    "link": "https://developer.okta.com/blog/2023/12/20/okta-documentation-chatbot",
    "id": "https://developer.okta.com/blog/2023/12/20/okta-documentation-chatbot",
    "guidislink": false
  },
  "Expedia": {
    "title": "Search Speed: Making Expedia Flights Faster",
    "xmlUrl": "https://medium.com/feed/expedia-group-tech",
    "htmlUrl": "https://medium.com/expedia-group-tech",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/expedia-group-tech",
      "value": "Search Speed: Making Expedia Flights Faster"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/expedia-group-tech/search-speed-making-expedia-flights-faster-5c3f7fec4c10?source=rss----38998a53046f---4"
      }
    ],
    "link": "https://medium.com/expedia-group-tech/search-speed-making-expedia-flights-faster-5c3f7fec4c10?source=rss----38998a53046f---4",
    "id": "https://medium.com/p/5c3f7fec4c10",
    "guidislink": false,
    "tags": [
      {
        "term": "data",
        "scheme": null,
        "label": null
      },
      {
        "term": "travel",
        "scheme": null,
        "label": null
      },
      {
        "term": "ux",
        "scheme": null,
        "label": null
      },
      {
        "term": "search",
        "scheme": null,
        "label": null
      },
      {
        "term": "performance",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Heena Gupta"
      }
    ],
    "author": "Heena Gupta",
    "author_detail": {
      "name": "Heena Gupta"
    },
    "published": "Wed, 03 Jan 2024 12:01:29 GMT",
    "published_parsed": [
      2024,
      1,
      3,
      12,
      1,
      29,
      2,
      3,
      0
    ],
    "updated": "2024-01-03T20:41:28.996Z",
    "updated_parsed": [
      2024,
      1,
      3,
      20,
      41,
      28,
      2,
      3,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/expedia-group-tech",
        "value": "<h4><a href=\"https://medium.com/expedia-group-tech/engineering/home\">Expedia Group\u200a\u2014\u200aEngineering</a></h4><h4>How we dramatically improved the performance of customer flight searches on\u00a0Expedia</h4><figure><img alt=\"People walk around a city in Norway\" src=\"https://cdn-images-1.medium.com/max/1024/0*9-rAUeZ48GcdnsfM\" /><figcaption>Photo by Oliver Cole on\u00a0Unsplash</figcaption></figure><figure><img alt=\"A line graph showing a sharp downward trend, plateauing at about half the height of the original line.\" src=\"https://cdn-images-1.medium.com/max/1024/1*mdlZqiCWTzy6Vua_xqtx6w.png\" /><figcaption>Trend showing improving in performance metric</figcaption></figure><p>Performance plays a crucial role in ensuring the responsiveness and functionalities of an application which leads to better end user experience and user engagements. It is vital for making the application scalable and maintainable in an efficient manner. Studies have shown the negative impact mediocre performance can have on business goals. High performing applications engage and retain users better than low performing ones. When we migrated Expedia Flights to Progressive web application, it enhanced the user experience and resulted in an increase in the demands at Expedia. However, the latency of Expedia Flights was too high, a standard monitoring of performance metrics was missing and there was a strong need to automate performance monitoring especially during releases which affected user retention and a seamless user experience.</p><h3>Motivation</h3><p><a href=\"https://www.expediagroup.com/\">Expedia Group</a>\u2122 is a leading global travel platform. Flight searches are a large chunk of user traffic on our platform. Flights search is traditionally a heavy system with peak search traffic going regularly in the large range of transactions per second. There is a latency overhead associated with each request which goes all the way down to the supplier. It was noticed that the airline information obtained from third parties further added to the latency. While optimising the third-party APIs was not controllable, the goal was to optimise the network call and progressive web application for a seamless user experience. From the product analysis we found that a bad user experience leads to a drop in conversion and a higher page load time leads to a higher bounce rate as well. <strong><em>Better performance leads to higher user engagement and a reduction in overhead on both client &amp; server\u00a0side.</em></strong></p><h3>Performance metrics</h3><p>To measure the performance in top 90th percentile, we produced the following derived performance metrics:</p><ul><li><strong>Page Usable Time</strong>: Page usable time measures the loading of a React component and is useful especially for Query components. This metric helped to determine the latency happening due to huge payload, multiple re-rendering and synchronous GraphQL\u00a0calls.</li><li><strong>Non-Supply Overhead</strong>: Non-supply overhead measures the journey of the GraphQL call from the beginning till the browser receives it, excluding the time spent getting the data which includes a lot of dependencies which is external to Expedia\u00a0Group.</li></ul><p>Other than the derived metrics, we also monitored the first contentful paint, first input delay, cumulative layout shift, and time to interactive.</p><p><strong>Size limit: </strong>With the micro frontend architecture, we wanted to ensure the bundles for each of the packages are not exceeding the upper limit as this would affect performance especially on a slow network. To ensure this, we integrated Git commit hooks along with GitHub actions integrated for size limit when a pull request is\u00a0raised.</p><h3>How did we improve the performance?</h3><p>We carried out some experimental performance initiatives among which the following are worth mentioning:</p><ul><li><strong>Prefetching of JS and CSS static resources</strong>: Fetching static resources could be made faster by prefetching a common set of resources needed for the next page that a user is likely to visit ahead of time. For the Flights Search Page, we prefetched the static JS and CSS bundles on the homepage for loading the bundles faster, which meant it did not need to wait for the respective resources. The prefetching of bundles improved page usable time marginally on the Flights Search\u00a0page.</li><li><strong>Faster caching:</strong> For any route, there can be lots of flight combinations. For instance, it is common to see a huge number of unique flight combinations for return travel between source and destination on any given date. To create a unique yet coherent experience for the users, we slice and dice these combinations and show a best-differentiated subset to the users based on the user\u2019s current position in the shopping funnel. The combinations are also affected by individual preferences and interactions in their current session. Our caching solution was powered by <a href=\"https://cassandra.apache.org/_/index.html\">Apache Cassandra</a> and it has been serving our requirements for many years. Even though the Cassandra fetch times are swift, the 90th percentile of the overall response time of the flight search service was more than 3 seconds to display results from the cache to the user. The goal of this project is to build a search offer cache for Flights to add the capability to assess if the search for identical parameters is still in progress and accordingly make the subsequent identical searches \u201cwait\u201d for the results from down level or serve from cache if already available. It improved in non-supply overhead by\u00a0~10%.</li><li><strong>Preemptive Search</strong>: The payload size is huge for Flights at Expedia, so to save the computation and fetch time from third party APIs the search criteria was predicted even before the user lands on Flights Search page. This is done by passing the search criteria beforehand from homepage which is then passed downstream to process further. When the user lands on Flights search page, the cached search response is shown to the user and thereby reduces the latency significantly. To reduce the number of networks calls on Homepage for preemptive search, the network call is triggered on the last field updated by majority of the end users. With the preemptive search experiment, a visible improvement of ~50% was observed on page usable time on Web and Native apps (iOS/Android).</li><li><strong>Horizontal and Vertical Slicing</strong>: The GraphQL query on Flights Search page was very expensive as the payload size was huge for search result combinations obtained from the third party. To optimise the payload size, it was broken down into smaller GraphQL queries to obtain the list of search offers in chunks rather than all at once within Expedia. This helped improve the user experience as the users no longer need to wait to have a quick glance on the results and could check the loaded search offers while the remaining search offers are getting resolved on client side. In addition to horizontal slicing, when a user clicks on search offers, the detailed information for the search offers is shown which usually takes some time to resolve due to downstream call. To let the user be able to view the search offers summary faster, the detailed information was separated out to another GraphQL query which only resolves upsell information. This helped speed up the user experience as now the user can view the summary information faster and the downstream call will be made only for the offer which is clicked. Horizontal Slicing experiment improved the non-supply overhead by 20% on Web and Native apps (iOS/Android)</li><li><strong>Async GraphQL loading and loaded states</strong>: Based on the code inspection, it was noticed that the loading and loaded GraphQL queries were not async. The loading call being a server-side call, is quicker to resolve and happens first followed by the client-side loaded call. This implies that the loaded call will wait for the loading call to resolve first and then will get resolved which will increase the page load time further. To optimise the network calls here, we did an experiment in which we prepared the request params for the loaded GraphQL call at an initial stage by injecting the fetch (XHR) into the HTML beforehand and resolved the promise of fetch at a later stage. As a result of this we noticed an improvement of ~8% on non-supply overhead and slight improvement in page usable\u00a0time.</li><li><strong>Micro frontend architecture</strong>: We have broken down the Expedia Flights PWA codebase into shareable packages which are reused across other lines of business as well. These shareable independent packages are then owned by their respective service owners, allowing flexibility, reusability, and better optimizations at the package level. With micro-frontend architecture in place, the build size has improved significantly as only the packages that are needed by the Flights progressive web application are being utilised.</li></ul><h3>Conclusion and\u00a0impact</h3><p>As a result of these performance initiatives, we observed a visible impact on the top 90th percentile on Page usable time by 52% overall and top 90th percentile on non-supply overhead by 40%. This is a great result and has improved search speed for all of our customers looking for flights on\u00a0Expedia.</p><p><a href=\"https://careers.expediagroup.com/life/\">Learn about life at Expedia\u00a0Group</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5c3f7fec4c10\" width=\"1\" /><hr /><p><a href=\"https://medium.com/expedia-group-tech/search-speed-making-expedia-flights-faster-5c3f7fec4c10\">Search Speed: Making Expedia Flights Faster</a> was originally published in <a href=\"https://medium.com/expedia-group-tech\">Expedia Group Technology</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<h4><a href=\"https://medium.com/expedia-group-tech/engineering/home\">Expedia Group\u200a\u2014\u200aEngineering</a></h4><h4>How we dramatically improved the performance of customer flight searches on\u00a0Expedia</h4><figure><img alt=\"People walk around a city in Norway\" src=\"https://cdn-images-1.medium.com/max/1024/0*9-rAUeZ48GcdnsfM\" /><figcaption>Photo by Oliver Cole on\u00a0Unsplash</figcaption></figure><figure><img alt=\"A line graph showing a sharp downward trend, plateauing at about half the height of the original line.\" src=\"https://cdn-images-1.medium.com/max/1024/1*mdlZqiCWTzy6Vua_xqtx6w.png\" /><figcaption>Trend showing improving in performance metric</figcaption></figure><p>Performance plays a crucial role in ensuring the responsiveness and functionalities of an application which leads to better end user experience and user engagements. It is vital for making the application scalable and maintainable in an efficient manner. Studies have shown the negative impact mediocre performance can have on business goals. High performing applications engage and retain users better than low performing ones. When we migrated Expedia Flights to Progressive web application, it enhanced the user experience and resulted in an increase in the demands at Expedia. However, the latency of Expedia Flights was too high, a standard monitoring of performance metrics was missing and there was a strong need to automate performance monitoring especially during releases which affected user retention and a seamless user experience.</p><h3>Motivation</h3><p><a href=\"https://www.expediagroup.com/\">Expedia Group</a>\u2122 is a leading global travel platform. Flight searches are a large chunk of user traffic on our platform. Flights search is traditionally a heavy system with peak search traffic going regularly in the large range of transactions per second. There is a latency overhead associated with each request which goes all the way down to the supplier. It was noticed that the airline information obtained from third parties further added to the latency. While optimising the third-party APIs was not controllable, the goal was to optimise the network call and progressive web application for a seamless user experience. From the product analysis we found that a bad user experience leads to a drop in conversion and a higher page load time leads to a higher bounce rate as well. <strong><em>Better performance leads to higher user engagement and a reduction in overhead on both client &amp; server\u00a0side.</em></strong></p><h3>Performance metrics</h3><p>To measure the performance in top 90th percentile, we produced the following derived performance metrics:</p><ul><li><strong>Page Usable Time</strong>: Page usable time measures the loading of a React component and is useful especially for Query components. This metric helped to determine the latency happening due to huge payload, multiple re-rendering and synchronous GraphQL\u00a0calls.</li><li><strong>Non-Supply Overhead</strong>: Non-supply overhead measures the journey of the GraphQL call from the beginning till the browser receives it, excluding the time spent getting the data which includes a lot of dependencies which is external to Expedia\u00a0Group.</li></ul><p>Other than the derived metrics, we also monitored the first contentful paint, first input delay, cumulative layout shift, and time to interactive.</p><p><strong>Size limit: </strong>With the micro frontend architecture, we wanted to ensure the bundles for each of the packages are not exceeding the upper limit as this would affect performance especially on a slow network. To ensure this, we integrated Git commit hooks along with GitHub actions integrated for size limit when a pull request is\u00a0raised.</p><h3>How did we improve the performance?</h3><p>We carried out some experimental performance initiatives among which the following are worth mentioning:</p><ul><li><strong>Prefetching of JS and CSS static resources</strong>: Fetching static resources could be made faster by prefetching a common set of resources needed for the next page that a user is likely to visit ahead of time. For the Flights Search Page, we prefetched the static JS and CSS bundles on the homepage for loading the bundles faster, which meant it did not need to wait for the respective resources. The prefetching of bundles improved page usable time marginally on the Flights Search\u00a0page.</li><li><strong>Faster caching:</strong> For any route, there can be lots of flight combinations. For instance, it is common to see a huge number of unique flight combinations for return travel between source and destination on any given date. To create a unique yet coherent experience for the users, we slice and dice these combinations and show a best-differentiated subset to the users based on the user\u2019s current position in the shopping funnel. The combinations are also affected by individual preferences and interactions in their current session. Our caching solution was powered by <a href=\"https://cassandra.apache.org/_/index.html\">Apache Cassandra</a> and it has been serving our requirements for many years. Even though the Cassandra fetch times are swift, the 90th percentile of the overall response time of the flight search service was more than 3 seconds to display results from the cache to the user. The goal of this project is to build a search offer cache for Flights to add the capability to assess if the search for identical parameters is still in progress and accordingly make the subsequent identical searches \u201cwait\u201d for the results from down level or serve from cache if already available. It improved in non-supply overhead by\u00a0~10%.</li><li><strong>Preemptive Search</strong>: The payload size is huge for Flights at Expedia, so to save the computation and fetch time from third party APIs the search criteria was predicted even before the user lands on Flights Search page. This is done by passing the search criteria beforehand from homepage which is then passed downstream to process further. When the user lands on Flights search page, the cached search response is shown to the user and thereby reduces the latency significantly. To reduce the number of networks calls on Homepage for preemptive search, the network call is triggered on the last field updated by majority of the end users. With the preemptive search experiment, a visible improvement of ~50% was observed on page usable time on Web and Native apps (iOS/Android).</li><li><strong>Horizontal and Vertical Slicing</strong>: The GraphQL query on Flights Search page was very expensive as the payload size was huge for search result combinations obtained from the third party. To optimise the payload size, it was broken down into smaller GraphQL queries to obtain the list of search offers in chunks rather than all at once within Expedia. This helped improve the user experience as the users no longer need to wait to have a quick glance on the results and could check the loaded search offers while the remaining search offers are getting resolved on client side. In addition to horizontal slicing, when a user clicks on search offers, the detailed information for the search offers is shown which usually takes some time to resolve due to downstream call. To let the user be able to view the search offers summary faster, the detailed information was separated out to another GraphQL query which only resolves upsell information. This helped speed up the user experience as now the user can view the summary information faster and the downstream call will be made only for the offer which is clicked. Horizontal Slicing experiment improved the non-supply overhead by 20% on Web and Native apps (iOS/Android)</li><li><strong>Async GraphQL loading and loaded states</strong>: Based on the code inspection, it was noticed that the loading and loaded GraphQL queries were not async. The loading call being a server-side call, is quicker to resolve and happens first followed by the client-side loaded call. This implies that the loaded call will wait for the loading call to resolve first and then will get resolved which will increase the page load time further. To optimise the network calls here, we did an experiment in which we prepared the request params for the loaded GraphQL call at an initial stage by injecting the fetch (XHR) into the HTML beforehand and resolved the promise of fetch at a later stage. As a result of this we noticed an improvement of ~8% on non-supply overhead and slight improvement in page usable\u00a0time.</li><li><strong>Micro frontend architecture</strong>: We have broken down the Expedia Flights PWA codebase into shareable packages which are reused across other lines of business as well. These shareable independent packages are then owned by their respective service owners, allowing flexibility, reusability, and better optimizations at the package level. With micro-frontend architecture in place, the build size has improved significantly as only the packages that are needed by the Flights progressive web application are being utilised.</li></ul><h3>Conclusion and\u00a0impact</h3><p>As a result of these performance initiatives, we observed a visible impact on the top 90th percentile on Page usable time by 52% overall and top 90th percentile on non-supply overhead by 40%. This is a great result and has improved search speed for all of our customers looking for flights on\u00a0Expedia.</p><p><a href=\"https://careers.expediagroup.com/life/\">Learn about life at Expedia\u00a0Group</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5c3f7fec4c10\" width=\"1\" /><hr /><p><a href=\"https://medium.com/expedia-group-tech/search-speed-making-expedia-flights-faster-5c3f7fec4c10\">Search Speed: Making Expedia Flights Faster</a> was originally published in <a href=\"https://medium.com/expedia-group-tech\">Expedia Group Technology</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Auth0": {
    "title": "Auth0 Community AMA: Rules & Hooks and Why Actions Matter",
    "xmlUrl": "https://auth0.com/blog/rss.xml",
    "htmlUrl": "https://auth0.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://auth0.com/blog/rss.xml",
      "value": "Auth0 Community AMA: Rules & Hooks and Why Actions Matter"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://auth0.com/blog/community-ama-rules-hooks-actions/"
      },
      {
        "type": "image/png",
        "href": "https://images.ctfassets.net/23aumh6u8s0i/6dzUooaW9RxlsvJiTR1Zze/1050212aa88e4fe21a6a8322504933f1/01_Announcement.png",
        "rel": "enclosure"
      }
    ],
    "link": "https://auth0.com/blog/community-ama-rules-hooks-actions/",
    "id": "https://auth0.com/blog/community-ama-rules-hooks-actions/",
    "guidislink": false,
    "published": "Thu, 11 Jan 2024 15:23:00 GMT",
    "published_parsed": [
      2024,
      1,
      11,
      15,
      23,
      0,
      3,
      11,
      0
    ],
    "authors": [
      {},
      {
        "name": "Konrad Sopala"
      }
    ],
    "author": "Konrad Sopala",
    "author_detail": {
      "name": "Konrad Sopala"
    },
    "summary": "Join the Auth0 Community and learn directly from the experts with the online AMA series.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://auth0.com/blog/rss.xml",
      "value": "Join the Auth0 Community and learn directly from the experts with the online AMA series."
    }
  },
  "Curalate": {
    "title": "Safely Modifying Your Hosts File with Gas Mask",
    "xmlUrl": "http://engineering.curalate.com/feed.xml",
    "htmlUrl": "http://engineering.curalate.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://engineering.curalate.com/feed.xml",
      "value": "Safely Modifying Your Hosts File with Gas Mask"
    },
    "summary": "<p>Sometimes the DNS for a specific domain on your machine needs to point somewhere else \u2013 at Curalate, we test changes microservices locally before shipping them, which could require redirecting requests to look at that local instance. One way to do this is by adding an entry like <code class=\"highlighter-rouge\">127.0.0.1 some.service.curalate.com</code> to <code class=\"highlighter-rouge\">/etc/hosts</code>.</p>\n\n<h3 id=\"why-use-a-hosts-file-manager\">Why use a hosts file manager?</h3>\n<p>In most cases, it\u2019s not advised to directly modify <code class=\"highlighter-rouge\">/etc/hosts</code>. Because it\u2019s buried deep into the filesystem, it\u2019s easy to forget you\u2019ve modified it, which can lead to numerous problems ranging from annoying to dangerous.\nAlso, danger aside, it can begin to get messy and complex if you have a lot of entries to manage. Think of even just fifteen lines you\u2019re constantly commenting/uncommenting to represent the configuration you need at a given moment. This would be insanity.\nGas Mask, a simple UI-based hosts file manager, allows you to set up different hosts files, while making it plainly obvious which hosts file is currently activated on your system via the OS Menu bar.</p>\n\n<h3 id=\"installation-instructions\">Installation instructions</h3>\n<ul>\n  <li>Go to <a href=\"https://github.com/2ndalpha/gasmask\">https://github.com/2ndalpha/gasmask</a> and download the latest version.</li>\n  <li>Unpack and install.</li>\n  <li>On first-run, the only hosts file listed will be <code class=\"highlighter-rouge\">Original File</code> which is the <code class=\"highlighter-rouge\">/etc/hosts</code> file you\u2019ll no longer be modifying.</li>\n</ul>\n\n<h3 id=\"creating-your-first-host-file\">Creating your first host file</h3>\n<ul>\n  <li>Create a new hosts file and name it something that makes sense.</li>\n  <li>Add the test entry <code class=\"highlighter-rouge\">127.0.0.1 google.com</code> and save. The format of these entries is <code class=\"highlighter-rouge\">&lt;target IP address&gt; &lt;URL or IP to redirect&gt;</code>.</li>\n  <li>Activate that hosts file. Gasmask substitutes in this file at <code class=\"highlighter-rouge\">/etc/hosts</code>.</li>\n  <li>You may either need to flush your DNS cache or just restart the browser.</li>\n  <li>To test it out, go to google.com in the browser.</li>\n  <li>What happens now is, when the browser goes to get the IP for google.com, the OS sees the matching entry in your hosts file, then refers to <code class=\"highlighter-rouge\">127.0.0.1</code> (your local computer) to make the request \u2013 which will fail.</li>\n  <li>Go ahead and reactivate your Original File, restart the browser, and you should be able to access google.com as expected.</li>\n</ul>\n\n<h3 id=\"use-the-menubar-icon\">Use the Menubar icon</h3>\n<p>It\u2019s easy to forget to flip your hosts file back. You\u2019ll end up spending 45 minutes on what you think is a bug, that doesn\u2019t reproduce for anyone else, only to realize your hosts file is sending requests someplace else.</p>\n\n<p>Next time you reach to modify that hosts file, consider integrating Gas Mask into your development workflow to keep it maintained and safe from unintended state.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "http://engineering.curalate.com/feed.xml",
      "value": "<p>Sometimes the DNS for a specific domain on your machine needs to point somewhere else \u2013 at Curalate, we test changes microservices locally before shipping them, which could require redirecting requests to look at that local instance. One way to do this is by adding an entry like <code class=\"highlighter-rouge\">127.0.0.1 some.service.curalate.com</code> to <code class=\"highlighter-rouge\">/etc/hosts</code>.</p>\n\n<h3 id=\"why-use-a-hosts-file-manager\">Why use a hosts file manager?</h3>\n<p>In most cases, it\u2019s not advised to directly modify <code class=\"highlighter-rouge\">/etc/hosts</code>. Because it\u2019s buried deep into the filesystem, it\u2019s easy to forget you\u2019ve modified it, which can lead to numerous problems ranging from annoying to dangerous.\nAlso, danger aside, it can begin to get messy and complex if you have a lot of entries to manage. Think of even just fifteen lines you\u2019re constantly commenting/uncommenting to represent the configuration you need at a given moment. This would be insanity.\nGas Mask, a simple UI-based hosts file manager, allows you to set up different hosts files, while making it plainly obvious which hosts file is currently activated on your system via the OS Menu bar.</p>\n\n<h3 id=\"installation-instructions\">Installation instructions</h3>\n<ul>\n  <li>Go to <a href=\"https://github.com/2ndalpha/gasmask\">https://github.com/2ndalpha/gasmask</a> and download the latest version.</li>\n  <li>Unpack and install.</li>\n  <li>On first-run, the only hosts file listed will be <code class=\"highlighter-rouge\">Original File</code> which is the <code class=\"highlighter-rouge\">/etc/hosts</code> file you\u2019ll no longer be modifying.</li>\n</ul>\n\n<h3 id=\"creating-your-first-host-file\">Creating your first host file</h3>\n<ul>\n  <li>Create a new hosts file and name it something that makes sense.</li>\n  <li>Add the test entry <code class=\"highlighter-rouge\">127.0.0.1 google.com</code> and save. The format of these entries is <code class=\"highlighter-rouge\">&lt;target IP address&gt; &lt;URL or IP to redirect&gt;</code>.</li>\n  <li>Activate that hosts file. Gasmask substitutes in this file at <code class=\"highlighter-rouge\">/etc/hosts</code>.</li>\n  <li>You may either need to flush your DNS cache or just restart the browser.</li>\n  <li>To test it out, go to google.com in the browser.</li>\n  <li>What happens now is, when the browser goes to get the IP for google.com, the OS sees the matching entry in your hosts file, then refers to <code class=\"highlighter-rouge\">127.0.0.1</code> (your local computer) to make the request \u2013 which will fail.</li>\n  <li>Go ahead and reactivate your Original File, restart the browser, and you should be able to access google.com as expected.</li>\n</ul>\n\n<h3 id=\"use-the-menubar-icon\">Use the Menubar icon</h3>\n<p>It\u2019s easy to forget to flip your hosts file back. You\u2019ll end up spending 45 minutes on what you think is a bug, that doesn\u2019t reproduce for anyone else, only to realize your hosts file is sending requests someplace else.</p>\n\n<p>Next time you reach to modify that hosts file, consider integrating Gas Mask into your development workflow to keep it maintained and safe from unintended state.</p>"
    },
    "published": "Thu, 30 May 2019 00:00:00 +0000",
    "published_parsed": [
      2019,
      5,
      30,
      0,
      0,
      0,
      3,
      150,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "http://engineering.curalate.com/2019/05/30/gas-mask.html"
      }
    ],
    "link": "http://engineering.curalate.com/2019/05/30/gas-mask.html",
    "id": "http://engineering.curalate.com/2019/05/30/gas-mask.html",
    "guidislink": false
  },
  "Flickr": {
    "title": "Safer Internet Day and Open Source Codes of Conduct",
    "xmlUrl": "http://code.flickr.net/feed/",
    "htmlUrl": "http://code.flickr.net/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://code.flickr.net/feed/",
      "value": "Safer Internet Day and Open Source Codes of Conduct"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://code.flickr.net/2022/02/14/safer-internet-day-and-open-source-codes-of-conduct/"
      }
    ],
    "link": "https://code.flickr.net/2022/02/14/safer-internet-day-and-open-source-codes-of-conduct/",
    "authors": [
      {
        "name": "Sarah Graywood"
      }
    ],
    "author": "Sarah Graywood",
    "author_detail": {
      "name": "Sarah Graywood"
    },
    "published": "Mon, 14 Feb 2022 17:23:51 +0000",
    "published_parsed": [
      2022,
      2,
      14,
      17,
      23,
      51,
      0,
      45,
      0
    ],
    "tags": [
      {
        "term": "open source",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://code.flickr.net/?p=3642",
    "guidislink": false,
    "summary": "To continue the work of making our spaces safer and more accessible to all, we have added a code of conduct to our most trafficked open source repositories on GitHub in celebration of Safer Internet Day! <a href=\"https://code.flickr.net/2022/02/14/safer-internet-day-and-open-source-codes-of-conduct/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://code.flickr.net/feed/",
      "value": "To continue the work of making our spaces safer and more accessible to all, we have added a code of conduct to our most trafficked open source repositories on GitHub in celebration of Safer Internet Day! <a href=\"https://code.flickr.net/2022/02/14/safer-internet-day-and-open-source-codes-of-conduct/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://code.flickr.net/feed/",
        "value": "<p><span style=\"font-weight: 400;\"><img alt=\"\" class=\"alignnone size-medium wp-image-3640\" height=\"450\" src=\"https://code.flickr.net/wp-content/uploads/sites/3/2022/02/7-Standard-SID-logo.png?w=800\" width=\"800\" /></span></p>\n<p><span style=\"font-weight: 400;\">Last week the world celebrated </span><a href=\"https://www.saferinternetday.org/en-US/\"><span style=\"font-weight: 400;\">Safer Internet Day</span></a><span style=\"font-weight: 400;\">, a day used to call upon stakeholders to join together to make the internet a safer and better place for all, and especially for children and young people. Here at Flickr, we believe in creating spaces on the internet that take into account the safety of all of our contributors, especially our youngest and most underrepresented. So, to celebrate that and to continue the work of making our spaces safer and more accessible to all, we have added a code of conduct to our most trafficked open source repositories on GitHub.</span></p>\n<h1><b>What\u2019s/Why Open Source?</b></h1>\n<div class=\"wp-caption alignnone\" style=\"width: 810px;\"><a href=\"https://www.flickr.com/photos/qrush/2960047774\" title=\"100_0509\"><img alt=\"100_0509\" height=\"600\" src=\"https://live.staticflickr.com/3050/2960047774_6e39a980dc_c.jpg\" width=\"800\" /></a><p class=\"wp-caption-text\">&#8220;100_0509&#8221; by Nick Quaranto is licensed under CC BY-SA 2.0</p></div>\n<p><br />\n<span style=\"font-weight: 400;\">Open source is a method of development that allows software to be available publicly so that contributors can modify, add, and remove code as they see fit in order to create a more robust codebase colored with the ideas and innovations of many developers rather than just a few. At Flickr we believe that innovation happens when we have a diverse and widespread set of voices coming together to suggest changes. Open source allows us to harness the power of these voices to create the very best software we can.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">Flickr has 15 open source repositories, 4 of which are actively contributed to. Of those four, none had a formal code of conduct to govern contributions to the code base or interpersonal interactions between developers actively working on the code\u2026 until now!</span></p>\n<h1><b>Why a code of conduct?</b></h1>\n<p><span style=\"font-weight: 400;\">Codes of conduct are extremely common and important in the open source community. Groups like Linux, Homebrew, Bootstrap, and Kubernetes all have codes of conduct governing the use of and contributions to their open source projects. Because open source allows such a diverse set of voices to express themselves, conflicts can arise and unfortunately not all come with the best of intent.\u00a0</span></p>\n<div class=\"wp-caption alignnone\" style=\"width: 810px;\"><a href=\"https://www.flickr.com/photos/agenciasenado/42102914074/in/photolist-2kKUH2o-279urvC-r6iTn9-5Swue-8KFrVd-EJMhYR-4Q911C-EJMho2-58xh7o-q5seCB-akPoZH-EuQrDE-9FgmUa-E7NHng-a4sk8m-DHUWwc-Ex5pP6-cj3oZ-Ex4Zon-Ex5x4M-nkrYVf-Ex5bqx-E7PfV6-gSFzVa-EkhJ3-8qhRSN-cY3qF3-E7NUie-dAbKpC-EFi7sn-b2KwD-mbX3PG-E7P5yV-EFhNkR-Ex56xM-DHUPnx-Eeavz1-ECYv21-DHUqvk-EFhHjD-cGmtWQ-ECYM8E-E7NYoP-MssRm-DHULui-Ex5u4P-DHUME4-4uET46-6mBGvY-8TpQdY\" title=\"Bullying\"><img alt=\"Bullying\" height=\"533\" src=\"https://live.staticflickr.com/896/42102914074_5f389e6e14_c.jpg\" width=\"800\" /></a><p class=\"wp-caption-text\">&#8220;Bullying&#8221; by Senado Federal is licensed under CC by 2.0</p></div>\n<p></p>\n<p><span style=\"font-weight: 400;\">Codes of conduct allow us to have a preconceived understanding of what interactions in our community are meant to look like and why we hold these expectations of members. Codes of conduct can range from what is expected of interpersonal interactions (e.g. Demonstrate kindness and empathy toward other developers in pull request reviews) to more generalized expectations (e.g. Focus on what is best for the community as a whole rather than individual desires or needs). Codes of conduct not only benefit the community in its entirety, but also allow us to focus on protecting the psychological safety of members of our community who are most at risk. We care about all of our members while also recognizing the need for specific and directed language to protect members of underrepresented groups. The best way to do this is to have a written code of conduct with specific, actionable steps used to govern the safety of the community.\u00a0</span></p>\n<h1><b>Why Contributor Covenant?</b></h1>\n<p><span style=\"font-weight: 400;\">In order to protect underrepresented groups and to foster a strong and healthy open source community here at Flickr, we thought about whether it would be best to write our own code of conduct specifically tailored to what we value at Flickr or whether it would be better to find a code of conduct already in use that we could use to guide our own open source communities. We ended up finding a code of conduct already in use by quite a few well respected organizations that directly spoke to </span><a href=\"https://code.flickr.net/2021/11/22/flickr-engineering-team-vision-guiding-principles/\"><span style=\"font-weight: 400;\">our most important operating principles</span></a><span style=\"font-weight: 400;\">.</span></p>\n<p><a href=\"https://www.contributor-covenant.org/\"><span style=\"font-weight: 400;\">Contributor Covenant</span></a><span style=\"font-weight: 400;\"> is a code of conduct for participating in open source communities which explicitly outlines expectations in order to create a healthy open source culture. Contributor Covenant has been adopted by over a hundred thousand open source communities and projects since 2014 and is used by Linux, Babel, Bootstrap, Kubernetes, code.gov, Twilio, Homebrew-Cask, and Target to name a few. With such well-respected organizations turning to Contributor Covenant, it was something we thought we would be foolish not to consider.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">As we considered, we realized that Contributor Covenant had all of our values specified in </span><a href=\"https://www.contributor-covenant.org/version/2/1/code_of_conduct/\"><span style=\"font-weight: 400;\">a wonderful document that was only a little over a page long</span></a><span style=\"font-weight: 400;\">. Both accessible in its readability and shortness and robust enough to do the job of protecting underrepresented contributors on our open source repositories, we had found a perfect marriage of all of the things that we wanted in a code of conduct, while also allowing us to become part of a large scale community adopting a singular vision for a healthy, safe, and innovational open source community. </span></p>"
      }
    ],
    "post-id": "3642",
    "media_content": [
      {
        "url": "https://code.flickr.net/wp-content/uploads/sites/3/2022/02/7-Standard-SID-logo.png?w=800",
        "medium": "image"
      },
      {
        "url": "https://live.staticflickr.com/3050/2960047774_6e39a980dc_c.jpg",
        "medium": "image"
      },
      {
        "url": "https://live.staticflickr.com/896/42102914074_5f389e6e14_c.jpg",
        "medium": "image"
      }
    ]
  },
  "Benchling": {
    "title": "10x faster python test iteration via fork(2)",
    "xmlUrl": "https://benchling.engineering/feed",
    "htmlUrl": "https://benchling.engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://benchling.engineering/feed",
      "value": "10x faster python test iteration via fork(2)"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://benchling.engineering/10x-faster-python-test-iteration-via-fork-2-3aae52d2f6?source=rss----3d4aa8fb07ea---4"
      }
    ],
    "link": "https://benchling.engineering/10x-faster-python-test-iteration-via-fork-2-3aae52d2f6?source=rss----3d4aa8fb07ea---4",
    "id": "https://medium.com/p/3aae52d2f6",
    "guidislink": false,
    "tags": [
      {
        "term": "developer-productivity",
        "scheme": null,
        "label": null
      },
      {
        "term": "python",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "fork",
        "scheme": null,
        "label": null
      },
      {
        "term": "benchling",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "raylu"
      }
    ],
    "author": "raylu",
    "author_detail": {
      "name": "raylu"
    },
    "published": "Thu, 20 Jul 2023 16:01:45 GMT",
    "published_parsed": [
      2023,
      7,
      20,
      16,
      1,
      45,
      3,
      201,
      0
    ],
    "updated": "2023-07-20T23:02:38.923Z",
    "updated_parsed": [
      2023,
      7,
      20,
      23,
      2,
      38,
      3,
      201,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://benchling.engineering/feed",
        "value": "<p>It\u2019s ideal to get feedback on your code faster\u200a\u2014\u200ato make a code change and see the result instantly. But, as projects get larger, reload times get longer. Each incremental dependency or bootstrap code block that adds 200ms feels worth it, but 50 of them later and it takes 10 seconds to see the result of a code\u00a0change.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kXnodzozvuBFupVH2kYfmA.png\" /></figure><p>On the Build team at Benchling, that\u2019s where we found ourselves one day. We used 146 packages which pull in 128 transitive dependencies for a total of 274 packages. We also spent a lot of time waiting for SQLAlchemy models to initialize. The result is our test harness took 10 seconds to set up. After making a code change, you\u2019d start the test runner, wait a few seconds, alt+tab to your browser, get distracted for a few minutes, and then find out you had a typo in your\u00a0code.</p><p>This is a common challenge for a growing codebase, but it\u2019s something we knew we needed to fix. Here\u2019s the process we arrived at which allowed the second run of tests to start 10x faster\u200a\u2014\u200a90% less waiting. While it\u2019ll work a little differently for your codebase depending on the language, dependencies, etc. you\u2019re using, hopefully this can inspire you on your journey to faster feedback and\u00a0testing.</p><h3>importlib.reload()</h3><p>Since the problem is that we spend so long setting up a bunch of modules just right and then want to see the change in a single file we\u2019re editing, the most obvious solution is to use <a href=\"https://docs.python.org/3/library/importlib.html#importlib.reload\">importlib.reload</a> from the standard\u00a0library.</p><pre>import importlib<br />import sys<br />import test_harness_stuff  # takes 10 seconds<br />import tests<br />def rerun_tests(changed_path):<br />    for mod in sys.modules.values():<br />        if mod.__file__ == changed_path:<br />            importlib.reload(mod)<br />            tests.run_tests()<br />            break<br />if __name__ == '__main__':<br />  setup_file_watcher(rerun_tests)<br />  tests.run_tests()</pre><p>This (with some special handling for built-in modules, relative path resolution, and batching to handle editors that perform multiple filesystem operations per save) works alright when the file being changed is a test file (or any other leaf node in the dependency tree).</p><p>However, as you\u2019ve probably guessed from the very long documentation for reload(), this doesn\u2019t work in many other cases. A very common one is if you have animal.py:</p><pre>cow = &quot;woof&quot;</pre><p>and then cow_say.py:</p><pre>from animal import cow</pre><p>If you change cow = &quot;moo&quot;, reloading animal.pyis not enough because cow_say.py has its own global bound to the old str. After reloading animal.py, you must then reload all reverse dependencies in topological order. You must also ensure that if a class definition is changed, all instantiations of that are reinitialized. For projects of almost any complexity, this is not feasible.</p><h3>Not importing</h3><p>Despite reload() not solving our problems, thinking about its issues is helpful in building a more useful solution. The giant list of caveats with reload() means you need to do surgery on the already-loaded modules.</p><p>What if we just didn\u2019t load the code you were going to change until after you changed it? Then we wouldn\u2019t need to do surgery! It\u2019s not too hard to guess what code might be changed. Roughly speaking, our codebase has 3 kinds of modules: 3rd-party dependencies, SQLAlchemy models, and actual app code/tests. More than 90% of the time, we\u2019re working in that last category, so we can just import the 3rd-party dependencies and SQLAlchemy models and not load the app/tests until we\u2019re ready to run a\u00a0test.</p><h3>zeus, fork()</h3><p>That leaves one problem: after we run a test, the test is loaded. How do we reset back to the state where dependencies and models were loaded but not app/tests? <a href=\"https://github.com/burke/zeus\">zeus</a> actually solved this for Rails: load Rails, fork(), then load app\u00a0code.</p><blockquote>fork() creates a new process by duplicating the calling process. [\u2026] The child process and the parent process run in separate memory spaces. At the time of <em>fork()</em> both memory spaces have the same content. Memory writes [\u2026] performed by one of the processes do not affect the\u00a0other.</blockquote><p>So we can use fork()to snapshot the parent, import some code that is going to change (app/tests), and then rewind back to the snapshot later. Rather than doing surgery on in-memory modules, we can just let the child process exit, re-fork, and re-import any changed\u00a0code.</p><pre>import os<br />import sys<br />import test_harness_stuff  # takes 10 seconds<br />def run_tests():<br />    pid = os.fork()<br />    if pid == 0:  # child<br />        import tests<br />        tests.run_tests()<br />        sys.exit()<br />    else:  # parent<br />        os.waitpid(pid, 0)<br />if __name__ == '__main__':<br />    setup_file_watcher(run_tests)<br />    run_tests()</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/493/1*gw3y9mouurXRIBgsxyGoig.png\" /></figure><p>Something like this sped up our test iteration time from 10 seconds to 1 second, which is a workflow-altering speed improvement (someone told me \u201cI wouldn\u2019t have bothered writing this tricky test if it weren\u2019t for the fast reloader\u201d).</p><p>zeus actually has a multi-level process tree and, when a file changes, it identifies which level imported it and terminates that process and all its ancestors. We do this too at Benchling: we divide up our modules into tiers based on how often developers work on them and where they fall in our dependency tree and then import each tier after forking. This allows us to discard as little import work as possible when a file closer to the root of our dependency tree\u00a0changes.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/444/1*hN4X4y6xyNsPZ_fTRTXxJA.png\" /><figcaption>Our process\u00a0tree</figcaption></figure><p>We actually ended up with some other components for ergonomics (a terminal forwarder that uses libreadline) and performance (file watcher that can\u2019t fork because it\u2019s threaded).</p><h3>Bonus: memory savings by not garbage collecting</h3><p>Once you start running python code after os.fork(), you start running into the same <a href=\"https://instagram-engineering.com/dismissing-python-garbage-collection-at-instagram-4dca40b29172\">memory usage problems Instagram faced</a>. They run a Django web server and load up all their dependencies before forking the web workers. At first, they tried to solve their runaway memory usage by disabling garbage collection entirely. Later, they came up with a <a href=\"https://instagram-engineering.com/copy-on-write-friendly-python-garbage-collection-ad6ed5233ddf\">more elegant solution</a> and upstreamed it into CPython\u00a03.7.</p><p>But what caused the memory usage? In short, copy-on-write pages and reference counting.</p><h4>Copy-on-write</h4><p>The fork() docs say \u201cAt the time of fork() both memory spaces have the same content. Memory writes [\u2026] performed by one of the processes do not affect the other\u201d. The simplest way to implement this is to copy all the memory from the parent into the\u00a0child.</p><p>The Linux kernel doesn\u2019t do that. Instead, it makes new <a href=\"https://wiki.osdev.org/Memory_management#Paging\">page tables</a> for the child process that point back at the parent\u2019s memory and marks them both as read-only. When the child tries to write to any memory, it triggers a page fault. The kernel\u2019s page fault handler looks at the page, sees that it was a copy-on-write page, makes an actual copy of the page, and lets the child retry the write operation.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/397/1*pTr64TonnUJkIA6tzjM6nQ.png\" /><figcaption>Parent and child processes sharing the same physical\u00a0memory</figcaption></figure><p>As you can imagine, this saves a lot of memory (and makes fork quite a bit faster). So what\u2019s the problem? The child rarely writes to any modules imported by the parent (the app/tests code rarely makes any changes to SQLAlchemy models or 3rd-party dependencies); it only reads them and calls functions defined in\u00a0them.</p><h4>gc_refs</h4><p>Python\u2019s garbage collector needs to know which objects are safe to free. To do this, every object has a <a href=\"https://github.com/python/cpython/blob/8d999cbf4adea053be6dbb612b9844635c4dfb8e/Include/objimpl.h#L256\">gc_refs field</a> stored in its header that is incremented whenever it is referred to (for example, added to a\u00a0list).</p><p>This means that if a module imported by our parent process defines a str and we later <em>read</em> that str in the child (which we do all the time), we will modify its object header to increment the ref count and trigger the kernel\u2019s copy-on-write behavior.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/563/1*3fm2cmM-3WogymwrZDLAVQ.png\" /><figcaption>Child process with its own memory after incrementing gc_refs</figcaption></figure><h4>gc.freeze()</h4><p>Instagram\u2019s solution to this problem is to (rewrite all the CPython code that looks at gc_refs, introduce, and then) call <a href=\"https://docs.python.org/3/library/gc.html#gc.freeze\">gc.freeze()</a>. This tells the interpreter that all existing objects should be considered ineligible for garbage collection and future accesses shouldn\u2019t increment the ref counter. (The new object header layout, after Instagram\u2019s changes in 3.7 and after another change in 3.12, is documented <a href=\"https://github.com/python/cpython/blob/main/Objects/object_layout.md\">here</a>.)</p><p>Implementing this is very easy: just call gc.freeze() right before you fork()! Running a typical test, we saw a 160 MiB reduction in <a href=\"https://en.wikipedia.org/wiki/Unique_set_size\">unique set\u00a0size</a>.</p><h4>Don\u2019t gc.collect()!</h4><p>Now that you\u2019re thinking about the garbage collector, you might be tempted to call gc.collect() right before freezing and forking. It sounds like it would save memory\u200a\u2014\u200aotherwise, objects with no refs in the parent will stick around forever in both the parent and the child. Unfortunately, that\u2019s a bad\u00a0idea.</p><p>When the garbage collector actually \u201ccollects\u201d something, the <a href=\"https://github.com/python/cpython/blob/main/Objects/obmalloc.c\">object allocator</a> \u201cfrees\u201d that object\u2019s memory. This doesn\u2019t return any memory back to the system; it simply marks that memory as unused. It also creates a \u201chole\u201d in the memory. A later allocation can fill that hole by using that freed\u00a0memory.</p><p>If we think about what happens in the child after GC has created \u201choles\u201d in the memory, we realize that the child will fill those holes in copy-on-write pages. In your development environment, your pages are likely <a href=\"https://dengking.github.io/Linux-OS/Kernel/%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD/Memory-management/Virtual-memory/Paging/Unix-system-page-size/\">4 KiB</a>. If you free a 1 KiB object, in the absolute best case it resides entirely within a page boundary and you replace it with another 1 KiB worth of objects. When the child tries to allocate 1 KiB, the kernel copies the entire 4 KiB page: you spent 3 KiB to save 1\u00a0KiB.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*40CzyrfGXQa1A8AAcSjNZg.png\" /><figcaption>3 KiB used to save 1\u00a0KiB</figcaption></figure><p>This is why Instagram actually <a href=\"https://bugs.python.org/issue31558#msg302780\">disables GC entirely in the parent</a>. In their words, \u201cwe\u2019re wasting a bit of memory in the shared pages to save a lot of memory later (that would otherwise be wasted on copying entire pages after forking).\u201d</p><h3>General applicability</h3><p>The approach we\u2019ve described here solves a problem that we think a lot of others face\u200a\u2014\u200aif you rack up enough dependencies, you probably have slow startup/reload times. It works on any system with fork (everything but Windows sans WSL). There are a few caveats,\u00a0though:</p><ul><li>You need to be able to fork and then continue executing your code. Some languages\u2019 standard libraries, such as nodejs, don\u2019t offer this out of the box, so you may need platform-specific C extensions.</li><li>Your language needs to be able to dynamically load modules at runtime. This is pretty tricky for most compiled languages.</li><li>If you want this to work for your webserver (like zeus), it\u2019s a bit more work. You need to integrate with your <a href=\"https://peps.python.org/pep-3333/\">WSGI</a>/<a href=\"https://github.com/rack/rack/blob/main/SPEC.rdoc\">rack</a>/etc. server to handle requests in a properly setup child process. Each server is different, so we don\u2019t have any general advice for how to do\u00a0this.</li></ul><p>Also, the benefits are only realized after you separate out modules based on their position in the dependency tree and frequency of edit. Because this is going to be different for everyone, we don\u2019t have much code to share. We undertook this project because we noticed that SQLAlchemy models were close to the root of our dependency tree and took up the majority of startup time, but your mileage may\u00a0vary.</p><h3>We\u2019re hiring!</h3><p>If you\u2019re interested in working with us to solve complex engineering problems, check out our <a href=\"https://www.benchling.com/careers/\">careers page</a> or <a href=\"mailto:jobs@benchling.com\">contact\u00a0us</a>!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UneW9cQzCOETv6sgn-JqHw.png\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3aae52d2f6\" width=\"1\" /><hr /><p><a href=\"https://benchling.engineering/10x-faster-python-test-iteration-via-fork-2-3aae52d2f6\">10x faster python test iteration via fork(2)</a> was originally published in <a href=\"https://benchling.engineering\">Benchling Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>It\u2019s ideal to get feedback on your code faster\u200a\u2014\u200ato make a code change and see the result instantly. But, as projects get larger, reload times get longer. Each incremental dependency or bootstrap code block that adds 200ms feels worth it, but 50 of them later and it takes 10 seconds to see the result of a code\u00a0change.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kXnodzozvuBFupVH2kYfmA.png\" /></figure><p>On the Build team at Benchling, that\u2019s where we found ourselves one day. We used 146 packages which pull in 128 transitive dependencies for a total of 274 packages. We also spent a lot of time waiting for SQLAlchemy models to initialize. The result is our test harness took 10 seconds to set up. After making a code change, you\u2019d start the test runner, wait a few seconds, alt+tab to your browser, get distracted for a few minutes, and then find out you had a typo in your\u00a0code.</p><p>This is a common challenge for a growing codebase, but it\u2019s something we knew we needed to fix. Here\u2019s the process we arrived at which allowed the second run of tests to start 10x faster\u200a\u2014\u200a90% less waiting. While it\u2019ll work a little differently for your codebase depending on the language, dependencies, etc. you\u2019re using, hopefully this can inspire you on your journey to faster feedback and\u00a0testing.</p><h3>importlib.reload()</h3><p>Since the problem is that we spend so long setting up a bunch of modules just right and then want to see the change in a single file we\u2019re editing, the most obvious solution is to use <a href=\"https://docs.python.org/3/library/importlib.html#importlib.reload\">importlib.reload</a> from the standard\u00a0library.</p><pre>import importlib<br />import sys<br />import test_harness_stuff  # takes 10 seconds<br />import tests<br />def rerun_tests(changed_path):<br />    for mod in sys.modules.values():<br />        if mod.__file__ == changed_path:<br />            importlib.reload(mod)<br />            tests.run_tests()<br />            break<br />if __name__ == '__main__':<br />  setup_file_watcher(rerun_tests)<br />  tests.run_tests()</pre><p>This (with some special handling for built-in modules, relative path resolution, and batching to handle editors that perform multiple filesystem operations per save) works alright when the file being changed is a test file (or any other leaf node in the dependency tree).</p><p>However, as you\u2019ve probably guessed from the very long documentation for reload(), this doesn\u2019t work in many other cases. A very common one is if you have animal.py:</p><pre>cow = &quot;woof&quot;</pre><p>and then cow_say.py:</p><pre>from animal import cow</pre><p>If you change cow = &quot;moo&quot;, reloading animal.pyis not enough because cow_say.py has its own global bound to the old str. After reloading animal.py, you must then reload all reverse dependencies in topological order. You must also ensure that if a class definition is changed, all instantiations of that are reinitialized. For projects of almost any complexity, this is not feasible.</p><h3>Not importing</h3><p>Despite reload() not solving our problems, thinking about its issues is helpful in building a more useful solution. The giant list of caveats with reload() means you need to do surgery on the already-loaded modules.</p><p>What if we just didn\u2019t load the code you were going to change until after you changed it? Then we wouldn\u2019t need to do surgery! It\u2019s not too hard to guess what code might be changed. Roughly speaking, our codebase has 3 kinds of modules: 3rd-party dependencies, SQLAlchemy models, and actual app code/tests. More than 90% of the time, we\u2019re working in that last category, so we can just import the 3rd-party dependencies and SQLAlchemy models and not load the app/tests until we\u2019re ready to run a\u00a0test.</p><h3>zeus, fork()</h3><p>That leaves one problem: after we run a test, the test is loaded. How do we reset back to the state where dependencies and models were loaded but not app/tests? <a href=\"https://github.com/burke/zeus\">zeus</a> actually solved this for Rails: load Rails, fork(), then load app\u00a0code.</p><blockquote>fork() creates a new process by duplicating the calling process. [\u2026] The child process and the parent process run in separate memory spaces. At the time of <em>fork()</em> both memory spaces have the same content. Memory writes [\u2026] performed by one of the processes do not affect the\u00a0other.</blockquote><p>So we can use fork()to snapshot the parent, import some code that is going to change (app/tests), and then rewind back to the snapshot later. Rather than doing surgery on in-memory modules, we can just let the child process exit, re-fork, and re-import any changed\u00a0code.</p><pre>import os<br />import sys<br />import test_harness_stuff  # takes 10 seconds<br />def run_tests():<br />    pid = os.fork()<br />    if pid == 0:  # child<br />        import tests<br />        tests.run_tests()<br />        sys.exit()<br />    else:  # parent<br />        os.waitpid(pid, 0)<br />if __name__ == '__main__':<br />    setup_file_watcher(run_tests)<br />    run_tests()</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/493/1*gw3y9mouurXRIBgsxyGoig.png\" /></figure><p>Something like this sped up our test iteration time from 10 seconds to 1 second, which is a workflow-altering speed improvement (someone told me \u201cI wouldn\u2019t have bothered writing this tricky test if it weren\u2019t for the fast reloader\u201d).</p><p>zeus actually has a multi-level process tree and, when a file changes, it identifies which level imported it and terminates that process and all its ancestors. We do this too at Benchling: we divide up our modules into tiers based on how often developers work on them and where they fall in our dependency tree and then import each tier after forking. This allows us to discard as little import work as possible when a file closer to the root of our dependency tree\u00a0changes.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/444/1*hN4X4y6xyNsPZ_fTRTXxJA.png\" /><figcaption>Our process\u00a0tree</figcaption></figure><p>We actually ended up with some other components for ergonomics (a terminal forwarder that uses libreadline) and performance (file watcher that can\u2019t fork because it\u2019s threaded).</p><h3>Bonus: memory savings by not garbage collecting</h3><p>Once you start running python code after os.fork(), you start running into the same <a href=\"https://instagram-engineering.com/dismissing-python-garbage-collection-at-instagram-4dca40b29172\">memory usage problems Instagram faced</a>. They run a Django web server and load up all their dependencies before forking the web workers. At first, they tried to solve their runaway memory usage by disabling garbage collection entirely. Later, they came up with a <a href=\"https://instagram-engineering.com/copy-on-write-friendly-python-garbage-collection-ad6ed5233ddf\">more elegant solution</a> and upstreamed it into CPython\u00a03.7.</p><p>But what caused the memory usage? In short, copy-on-write pages and reference counting.</p><h4>Copy-on-write</h4><p>The fork() docs say \u201cAt the time of fork() both memory spaces have the same content. Memory writes [\u2026] performed by one of the processes do not affect the other\u201d. The simplest way to implement this is to copy all the memory from the parent into the\u00a0child.</p><p>The Linux kernel doesn\u2019t do that. Instead, it makes new <a href=\"https://wiki.osdev.org/Memory_management#Paging\">page tables</a> for the child process that point back at the parent\u2019s memory and marks them both as read-only. When the child tries to write to any memory, it triggers a page fault. The kernel\u2019s page fault handler looks at the page, sees that it was a copy-on-write page, makes an actual copy of the page, and lets the child retry the write operation.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/397/1*pTr64TonnUJkIA6tzjM6nQ.png\" /><figcaption>Parent and child processes sharing the same physical\u00a0memory</figcaption></figure><p>As you can imagine, this saves a lot of memory (and makes fork quite a bit faster). So what\u2019s the problem? The child rarely writes to any modules imported by the parent (the app/tests code rarely makes any changes to SQLAlchemy models or 3rd-party dependencies); it only reads them and calls functions defined in\u00a0them.</p><h4>gc_refs</h4><p>Python\u2019s garbage collector needs to know which objects are safe to free. To do this, every object has a <a href=\"https://github.com/python/cpython/blob/8d999cbf4adea053be6dbb612b9844635c4dfb8e/Include/objimpl.h#L256\">gc_refs field</a> stored in its header that is incremented whenever it is referred to (for example, added to a\u00a0list).</p><p>This means that if a module imported by our parent process defines a str and we later <em>read</em> that str in the child (which we do all the time), we will modify its object header to increment the ref count and trigger the kernel\u2019s copy-on-write behavior.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/563/1*3fm2cmM-3WogymwrZDLAVQ.png\" /><figcaption>Child process with its own memory after incrementing gc_refs</figcaption></figure><h4>gc.freeze()</h4><p>Instagram\u2019s solution to this problem is to (rewrite all the CPython code that looks at gc_refs, introduce, and then) call <a href=\"https://docs.python.org/3/library/gc.html#gc.freeze\">gc.freeze()</a>. This tells the interpreter that all existing objects should be considered ineligible for garbage collection and future accesses shouldn\u2019t increment the ref counter. (The new object header layout, after Instagram\u2019s changes in 3.7 and after another change in 3.12, is documented <a href=\"https://github.com/python/cpython/blob/main/Objects/object_layout.md\">here</a>.)</p><p>Implementing this is very easy: just call gc.freeze() right before you fork()! Running a typical test, we saw a 160 MiB reduction in <a href=\"https://en.wikipedia.org/wiki/Unique_set_size\">unique set\u00a0size</a>.</p><h4>Don\u2019t gc.collect()!</h4><p>Now that you\u2019re thinking about the garbage collector, you might be tempted to call gc.collect() right before freezing and forking. It sounds like it would save memory\u200a\u2014\u200aotherwise, objects with no refs in the parent will stick around forever in both the parent and the child. Unfortunately, that\u2019s a bad\u00a0idea.</p><p>When the garbage collector actually \u201ccollects\u201d something, the <a href=\"https://github.com/python/cpython/blob/main/Objects/obmalloc.c\">object allocator</a> \u201cfrees\u201d that object\u2019s memory. This doesn\u2019t return any memory back to the system; it simply marks that memory as unused. It also creates a \u201chole\u201d in the memory. A later allocation can fill that hole by using that freed\u00a0memory.</p><p>If we think about what happens in the child after GC has created \u201choles\u201d in the memory, we realize that the child will fill those holes in copy-on-write pages. In your development environment, your pages are likely <a href=\"https://dengking.github.io/Linux-OS/Kernel/%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD/Memory-management/Virtual-memory/Paging/Unix-system-page-size/\">4 KiB</a>. If you free a 1 KiB object, in the absolute best case it resides entirely within a page boundary and you replace it with another 1 KiB worth of objects. When the child tries to allocate 1 KiB, the kernel copies the entire 4 KiB page: you spent 3 KiB to save 1\u00a0KiB.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*40CzyrfGXQa1A8AAcSjNZg.png\" /><figcaption>3 KiB used to save 1\u00a0KiB</figcaption></figure><p>This is why Instagram actually <a href=\"https://bugs.python.org/issue31558#msg302780\">disables GC entirely in the parent</a>. In their words, \u201cwe\u2019re wasting a bit of memory in the shared pages to save a lot of memory later (that would otherwise be wasted on copying entire pages after forking).\u201d</p><h3>General applicability</h3><p>The approach we\u2019ve described here solves a problem that we think a lot of others face\u200a\u2014\u200aif you rack up enough dependencies, you probably have slow startup/reload times. It works on any system with fork (everything but Windows sans WSL). There are a few caveats,\u00a0though:</p><ul><li>You need to be able to fork and then continue executing your code. Some languages\u2019 standard libraries, such as nodejs, don\u2019t offer this out of the box, so you may need platform-specific C extensions.</li><li>Your language needs to be able to dynamically load modules at runtime. This is pretty tricky for most compiled languages.</li><li>If you want this to work for your webserver (like zeus), it\u2019s a bit more work. You need to integrate with your <a href=\"https://peps.python.org/pep-3333/\">WSGI</a>/<a href=\"https://github.com/rack/rack/blob/main/SPEC.rdoc\">rack</a>/etc. server to handle requests in a properly setup child process. Each server is different, so we don\u2019t have any general advice for how to do\u00a0this.</li></ul><p>Also, the benefits are only realized after you separate out modules based on their position in the dependency tree and frequency of edit. Because this is going to be different for everyone, we don\u2019t have much code to share. We undertook this project because we noticed that SQLAlchemy models were close to the root of our dependency tree and took up the majority of startup time, but your mileage may\u00a0vary.</p><h3>We\u2019re hiring!</h3><p>If you\u2019re interested in working with us to solve complex engineering problems, check out our <a href=\"https://www.benchling.com/careers/\">careers page</a> or <a href=\"mailto:jobs@benchling.com\">contact\u00a0us</a>!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UneW9cQzCOETv6sgn-JqHw.png\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3aae52d2f6\" width=\"1\" /><hr /><p><a href=\"https://benchling.engineering/10x-faster-python-test-iteration-via-fork-2-3aae52d2f6\">10x faster python test iteration via fork(2)</a> was originally published in <a href=\"https://benchling.engineering\">Benchling Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Crowdfire": {
    "title": "Dealing With Errors in Go Projects",
    "xmlUrl": "https://crowdfire.engineering/feed",
    "htmlUrl": "https://crowdfire.engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://crowdfire.engineering/feed",
      "value": "Dealing With Errors in Go Projects"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://crowdfire.engineering/dealing-with-errors-in-go-projects-36aa09fc1496?source=rss----212c5945ed6c---4"
      }
    ],
    "link": "https://crowdfire.engineering/dealing-with-errors-in-go-projects-36aa09fc1496?source=rss----212c5945ed6c---4",
    "id": "https://medium.com/p/36aa09fc1496",
    "guidislink": false,
    "tags": [
      {
        "term": "tech",
        "scheme": null,
        "label": null
      },
      {
        "term": "coding",
        "scheme": null,
        "label": null
      },
      {
        "term": "golang",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering",
        "scheme": null,
        "label": null
      },
      {
        "term": "nodejs",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Crowdfire Engineering"
      }
    ],
    "author": "Crowdfire Engineering",
    "author_detail": {
      "name": "Crowdfire Engineering"
    },
    "published": "Fri, 15 Sep 2017 16:01:01 GMT",
    "published_parsed": [
      2017,
      9,
      15,
      16,
      1,
      1,
      4,
      258,
      0
    ],
    "updated": "2017-09-15T16:01:01.617Z",
    "updated_parsed": [
      2017,
      9,
      15,
      16,
      1,
      1,
      4,
      258,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://crowdfire.engineering/feed",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Zf-PAHOjW70eF-wWOjNpUg.png\" /><figcaption><a href=\"http://reneefrench.blogspot.in/\">Gopher Design by Renee\u00a0French</a></figcaption></figure><p>I come from a NodeJS background and my coding habits have been heavily influenced by the paradigms most used in Node. I started coding in Go quite recently and I immediately fell in love with the language. I love a lot of things about Go, but let\u2019s not get into that right now or we\u2019ll never get to the\u00a0point.</p><p>Let\u2019s talk, instead, of what caused me a lot of headache and frustration: <strong>errors</strong>.</p><p>I didn\u2019t know what to do with the darned things. The idiomatic way in Go is to return errors as a second value and that\u2019s what pretty much all libraries do. There is a panic-recover mechanism but I\u2019ve found it being used to recover from things like illegal memory access or nil pointer dereference (which shouldn\u2019t happen if you code properly).</p><p>My only viable choices were either handling and logging errors on the spot, or returning them up the chain of function calls. Neither sounded like a good idea. Here\u2019s\u00a0why:</p><p><strong>If you handle errors on the spot and log them</strong> you lose context of the steps that led to this error. You can log variables local to the function where the error occured, but you have no idea what path your program took to finally call this function and face this\u00a0error.</p><p><strong>If you return errors up the chain</strong> and then handle them at the top-most level, you end up with almost the same thing. You have the error and you know which entry point of your function eventually led to that error, but now you\u2019ve lost context of the function where the error originated.</p><p>Neither is a good idea, especially not at 4 in the morning when your boss calls you up to debug some obscure bug made all the more obscure by insufficient information. You need to know where the error originated, which entry point led to it and what path it followed. And of course, the details of the error\u00a0itself.</p><p>To work around these issues, I had this idea of annotating the error message at each stage. So say I have the following extremely contrived code:</p><a href=\"https://medium.com/media/a9dc1b3fde4224de63b1e202522a2de9/href\">https://medium.com/media/a9dc1b3fde4224de63b1e202522a2de9/href</a><p>By concatenating the errors at each step I retain context. At the top level, when I log, I can see the calls that led to the error. This is better than not having much context but is extremely tedious in practice.</p><p>Then I came across <a href=\"https://dave.cheney.net/2016/06/12/stack-traces-and-the-errors-package\">this excellent blog post</a> by Dave Cheney. And once you\u2019ve read through it (seriously, read through it before continuing), you\u2019ll see that he\u2019s implemented the same idea I had but done it a gazillion times better. So I started perusing more things he\u2019d written. The presentation link includes most of the content of the preceding articles.</p><ul><li><a href=\"https://dave.cheney.net/2016/04/07/constant-errors\">Constant Errors</a></li><li><a href=\"https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully\">Don\u2019t just check errors, handle them gracefully</a></li><li><a href=\"https://dave.cheney.net/2014/12/24/inspecting-errors\">Inspecting Errors</a></li><li><a href=\"https://godoc.org/github.com/pkg/errors\">pkg/errors</a></li><li>Dave Cheney\u2019s presentation on Error Handling <a href=\"https://www.youtube.com/watch?v=lsBF58Q-DnY\">youtube</a>\u00a0<a href=\"https://dave.cheney.net/paste/gocon-spring-2016.pdf\">pdf</a></li></ul><p>After reading through all that and tinkering around for a while, I came up with a set of sensible guidelines for handling errors. Some of them are taken directly from Dave Cheney\u2019s blog, some I added based on my own experiences.</p><h3>Let\u2019s Begin</h3><ul><li><strong>Always</strong> check for errors if the function returns one. I know that sounds obvious but you\u2019d be surprised at how much code I\u2019ve seen that doesn\u2019t do\u00a0this.</li><li>Create custom error types for the errors you <em>know</em> you are gonna face (bad input, duplicate request, etc.). Return these, wrapped by the errors package, when you face\u00a0them.</li><li>When dealing with errors returned from a library, wrap it with errors.Wrap or errors.Wrapfand return.</li><li>When dealing with errors returned from your own code, if:<br />\u200a\u2014\u200ait requires no further context, just return it.<br />\u200a\u2014\u200aif it requires some extra context (perhaps data points captured within that function), use Wrap or\u00a0Wrapf.</li><li>Handle errors without further propagation at the entry point of your program (commands in a cli or handlers in a web server). Unwrap it with errors.Cause and test it:<br />\u200a\u2014\u200aIf it is of the custom type you have defined for your project, handle accordingly (you might wanna log these at level Error or Warning since these were expected). If it\u2019s an endpoint facing your users, you might wanna have a contract with the client on what codes to return and act accordingly (you might even end up returning a generic error message). If it is an internal endpoint (think microservices), you could return an appropriate status code and message while logging the same.<br />\u2014 If it is of an unknown type, you might wanna log a fatal. This is an error that should never have happened. After that it\u2019s up to\u00a0you.</li></ul><p>I use these guidelines to make sure I have enough information during debugging to figure what\u2019s going wrong. I still have to do error\u00a0!= nil everywhere but I think that\u2019s not as bad a thing as I first thought. Unlike exception propagation, this way of doing things makes me stop and think at each step if I wanna let the error propagate on its own or add more\u00a0context.</p><h3>Lastly</h3><p>This approach works for me, for now. Is there a better way to do this? I don\u2019t know. There\u2019s still a lot for me to learn and I\u2019m hoping that as I keep coding, I\u2019ll face enough new challenges to keep me reaching for better ways to code. I\u2019d love to hear about your own experiences and challenges with Go. Hit me up on Twitter at <a href=\"http://twitter.com/@scionofbytes\">@scionofbytes</a> or leave a comment below\u00a0\ud83d\udc47</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/100/1*LAYhxZHlYzrF3lE4iejXxA.png\" /><figcaption><a href=\"https://medium.com/u/39f2954e09bc\">Shaun</a> is a Backend Developer at Crowdfire. He likes automating everything, including coffee\u00a0breaks.</figcaption></figure><p><em>*</em><a href=\"http://scionofbytes.me/coding-practices/error-handling-in-go/\"><em>This article was first published on Shaun\u2019s\u00a0Blog.</em></a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=36aa09fc1496\" width=\"1\" /><hr /><p><a href=\"https://crowdfire.engineering/dealing-with-errors-in-go-projects-36aa09fc1496\">Dealing With Errors in Go Projects</a> was originally published in <a href=\"https://crowdfire.engineering\">Coding Big\u200a\u2014\u200aThe Crowdfire Engineering Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Zf-PAHOjW70eF-wWOjNpUg.png\" /><figcaption><a href=\"http://reneefrench.blogspot.in/\">Gopher Design by Renee\u00a0French</a></figcaption></figure><p>I come from a NodeJS background and my coding habits have been heavily influenced by the paradigms most used in Node. I started coding in Go quite recently and I immediately fell in love with the language. I love a lot of things about Go, but let\u2019s not get into that right now or we\u2019ll never get to the\u00a0point.</p><p>Let\u2019s talk, instead, of what caused me a lot of headache and frustration: <strong>errors</strong>.</p><p>I didn\u2019t know what to do with the darned things. The idiomatic way in Go is to return errors as a second value and that\u2019s what pretty much all libraries do. There is a panic-recover mechanism but I\u2019ve found it being used to recover from things like illegal memory access or nil pointer dereference (which shouldn\u2019t happen if you code properly).</p><p>My only viable choices were either handling and logging errors on the spot, or returning them up the chain of function calls. Neither sounded like a good idea. Here\u2019s\u00a0why:</p><p><strong>If you handle errors on the spot and log them</strong> you lose context of the steps that led to this error. You can log variables local to the function where the error occured, but you have no idea what path your program took to finally call this function and face this\u00a0error.</p><p><strong>If you return errors up the chain</strong> and then handle them at the top-most level, you end up with almost the same thing. You have the error and you know which entry point of your function eventually led to that error, but now you\u2019ve lost context of the function where the error originated.</p><p>Neither is a good idea, especially not at 4 in the morning when your boss calls you up to debug some obscure bug made all the more obscure by insufficient information. You need to know where the error originated, which entry point led to it and what path it followed. And of course, the details of the error\u00a0itself.</p><p>To work around these issues, I had this idea of annotating the error message at each stage. So say I have the following extremely contrived code:</p><a href=\"https://medium.com/media/a9dc1b3fde4224de63b1e202522a2de9/href\">https://medium.com/media/a9dc1b3fde4224de63b1e202522a2de9/href</a><p>By concatenating the errors at each step I retain context. At the top level, when I log, I can see the calls that led to the error. This is better than not having much context but is extremely tedious in practice.</p><p>Then I came across <a href=\"https://dave.cheney.net/2016/06/12/stack-traces-and-the-errors-package\">this excellent blog post</a> by Dave Cheney. And once you\u2019ve read through it (seriously, read through it before continuing), you\u2019ll see that he\u2019s implemented the same idea I had but done it a gazillion times better. So I started perusing more things he\u2019d written. The presentation link includes most of the content of the preceding articles.</p><ul><li><a href=\"https://dave.cheney.net/2016/04/07/constant-errors\">Constant Errors</a></li><li><a href=\"https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully\">Don\u2019t just check errors, handle them gracefully</a></li><li><a href=\"https://dave.cheney.net/2014/12/24/inspecting-errors\">Inspecting Errors</a></li><li><a href=\"https://godoc.org/github.com/pkg/errors\">pkg/errors</a></li><li>Dave Cheney\u2019s presentation on Error Handling <a href=\"https://www.youtube.com/watch?v=lsBF58Q-DnY\">youtube</a>\u00a0<a href=\"https://dave.cheney.net/paste/gocon-spring-2016.pdf\">pdf</a></li></ul><p>After reading through all that and tinkering around for a while, I came up with a set of sensible guidelines for handling errors. Some of them are taken directly from Dave Cheney\u2019s blog, some I added based on my own experiences.</p><h3>Let\u2019s Begin</h3><ul><li><strong>Always</strong> check for errors if the function returns one. I know that sounds obvious but you\u2019d be surprised at how much code I\u2019ve seen that doesn\u2019t do\u00a0this.</li><li>Create custom error types for the errors you <em>know</em> you are gonna face (bad input, duplicate request, etc.). Return these, wrapped by the errors package, when you face\u00a0them.</li><li>When dealing with errors returned from a library, wrap it with errors.Wrap or errors.Wrapfand return.</li><li>When dealing with errors returned from your own code, if:<br />\u200a\u2014\u200ait requires no further context, just return it.<br />\u200a\u2014\u200aif it requires some extra context (perhaps data points captured within that function), use Wrap or\u00a0Wrapf.</li><li>Handle errors without further propagation at the entry point of your program (commands in a cli or handlers in a web server). Unwrap it with errors.Cause and test it:<br />\u200a\u2014\u200aIf it is of the custom type you have defined for your project, handle accordingly (you might wanna log these at level Error or Warning since these were expected). If it\u2019s an endpoint facing your users, you might wanna have a contract with the client on what codes to return and act accordingly (you might even end up returning a generic error message). If it is an internal endpoint (think microservices), you could return an appropriate status code and message while logging the same.<br />\u2014 If it is of an unknown type, you might wanna log a fatal. This is an error that should never have happened. After that it\u2019s up to\u00a0you.</li></ul><p>I use these guidelines to make sure I have enough information during debugging to figure what\u2019s going wrong. I still have to do error\u00a0!= nil everywhere but I think that\u2019s not as bad a thing as I first thought. Unlike exception propagation, this way of doing things makes me stop and think at each step if I wanna let the error propagate on its own or add more\u00a0context.</p><h3>Lastly</h3><p>This approach works for me, for now. Is there a better way to do this? I don\u2019t know. There\u2019s still a lot for me to learn and I\u2019m hoping that as I keep coding, I\u2019ll face enough new challenges to keep me reaching for better ways to code. I\u2019d love to hear about your own experiences and challenges with Go. Hit me up on Twitter at <a href=\"http://twitter.com/@scionofbytes\">@scionofbytes</a> or leave a comment below\u00a0\ud83d\udc47</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/100/1*LAYhxZHlYzrF3lE4iejXxA.png\" /><figcaption><a href=\"https://medium.com/u/39f2954e09bc\">Shaun</a> is a Backend Developer at Crowdfire. He likes automating everything, including coffee\u00a0breaks.</figcaption></figure><p><em>*</em><a href=\"http://scionofbytes.me/coding-practices/error-handling-in-go/\"><em>This article was first published on Shaun\u2019s\u00a0Blog.</em></a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=36aa09fc1496\" width=\"1\" /><hr /><p><a href=\"https://crowdfire.engineering/dealing-with-errors-in-go-projects-36aa09fc1496\">Dealing With Errors in Go Projects</a> was originally published in <a href=\"https://crowdfire.engineering\">Coding Big\u200a\u2014\u200aThe Crowdfire Engineering Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Codemancers": {
    "title": "How Asynchronous JavaScript Works",
    "xmlUrl": "https://crypt.codemancers.com/index.xml",
    "htmlUrl": "https://crypt.codemancers.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://crypt.codemancers.com/index.xml",
      "value": "How Asynchronous JavaScript Works"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://crypt.codemancers.com/posts/2022-10-26-how-asynchronous-js-works/"
      }
    ],
    "link": "https://crypt.codemancers.com/posts/2022-10-26-how-asynchronous-js-works/",
    "published": "Wed, 26 Oct 2022 20:53:17 +0530",
    "published_parsed": [
      2022,
      10,
      26,
      15,
      23,
      17,
      2,
      299,
      0
    ],
    "id": "https://crypt.codemancers.com/posts/2022-10-26-how-asynchronous-js-works/",
    "guidislink": false,
    "summary": "A thread is a sequential flow of control within a program, and multi-threading is the execution of multiple flows of control within a program.\nOn the contrary, single-threaded processes contain the instructions to be executed in a single sequence. This means that a line of code will be executed only after the lines before it have finished execution.\nThat being said, a language may support multi-threaded processes like Java or may not support it like JavaScript.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://crypt.codemancers.com/index.xml",
      "value": "A thread is a sequential flow of control within a program, and multi-threading is the execution of multiple flows of control within a program.\nOn the contrary, single-threaded processes contain the instructions to be executed in a single sequence. This means that a line of code will be executed only after the lines before it have finished execution.\nThat being said, a language may support multi-threaded processes like Java or may not support it like JavaScript."
    }
  },
  "Kickstarter": {
    "title": "Supporting Open Source: Our Donations for 2018",
    "xmlUrl": "https://kickstarter.engineering/feed",
    "htmlUrl": "https://www.kickstarter.com/backing-and-hacking",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://kickstarter.engineering/feed",
      "value": "Supporting Open Source: Our Donations for 2018"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://kickstarter.engineering/supporting-open-source-our-donations-for-2018-d69a6114bf89?source=rss----c5ef8826f270---4"
      }
    ],
    "link": "https://kickstarter.engineering/supporting-open-source-our-donations-for-2018-d69a6114bf89?source=rss----c5ef8826f270---4",
    "id": "https://medium.com/p/d69a6114bf89",
    "guidislink": false,
    "tags": [
      {
        "term": "kickstarter-campaign",
        "scheme": null,
        "label": null
      },
      {
        "term": "open-source",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering-job-openings",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering-leadership",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering-solutions",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Natacha Springer"
      }
    ],
    "author": "Natacha Springer",
    "author_detail": {
      "name": "Natacha Springer"
    },
    "published": "Fri, 11 Jan 2019 15:25:10 GMT",
    "published_parsed": [
      2019,
      1,
      11,
      15,
      25,
      10,
      4,
      11,
      0
    ],
    "updated": "2019-01-11T15:25:10.700Z",
    "updated_parsed": [
      2019,
      1,
      11,
      15,
      25,
      10,
      4,
      11,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://kickstarter.engineering/feed",
        "value": "<p>At Kickstarter, we use a lot of open-source software. We pledge in <a href=\"https://www.kickstarter.com/charter\">our PBC charter</a> to support a more creative and equitable world, and that our operations will reflect our values. As part of that ethos, we try to do our share to support the open-source ecosystem by making a financial contribution to select projects.</p><p>To choose these organizations, we surveyed all of our engineers asking for nominations. They were more than eager to help, and as a result we split our yearly donation budget between two open-source projects and four organizations that foster learning or the improvement of coding skills within the open-source community.</p><p><a href=\"https://babeljs.io/\"><strong>Babel</strong></a><strong>:</strong></p><p>Babel is a toolchain that is mainly used to convert ECMAScript 2015+ code into a backwards-compatible version of JavaScript in current and older browsers or environments.</p><p>Babel allows us to use the latest Javascript technologies while making Kickstarter accessible to creators and backers all over the world. Henry and the rest of the Babel team have done an amazing job growing and improving the Babel toolchain.</p><h3>Henry Zhu on Twitter</h3><p>Awesome to see a donation from @kickstarter just now to @babeljs \ud83c\udf89! Thanks for the support and would be happy to chat more! https://t.co/u1VRcvDtz8</p><p><a href=\"https://webpack.js.org/\"><strong>Webpack</strong></a><strong>:</strong></p><p>Webpack is the tool we use to bundle our Javascript here at Kickstarter, and we\u2019re grateful for the community that builds and maintains this\u00a0tool!</p><p><a href=\"https://adventofcode.com/\"><strong>Advent of\u00a0Code</strong></a><strong>:</strong></p><p>For the last two years our engineers have enjoyed sharpening their problem-solving skills by working together on Advent of Code puzzles during the holiday season. Eric Wastl has done an amazing job turning complex computing problems into whimsical holiday\u00a0stories!</p><p><a href=\"https://railsgirlssummerofcode.org\"><strong>Rails Girls Summer of\u00a0Code</strong></a><strong>:</strong></p><p>Rails Girls Summer of Code is a program that helps women and non-binary individuals get involved in open-source projects. More diverse teams build better software. We value diversity on our team and chose to support Rails Girls Summer of Code to encourage diversity in the wider tech community.</p><p><a href=\"https://codenation.org/\"><strong>Code Nation</strong></a><strong>:</strong></p><p>Code Nation equips students in under-resourced high schools with skills, experiences and connections to create access to careers in technology. One of our senior engineers spends time each week mentoring students through Code Nation, so it made sense for us to support them a bit\u00a0more.</p><p><a href=\"https://codecooperative.org/\"><strong>Code Cooperative</strong></a><strong>:</strong></p><p>Code Cooperative teaches formerly incarcerated individuals the skills needed to be users and creators of technology. The work of addressing the systemic inequity of the prison system is vast, and we\u2019re excited to support an organization equipping this community to address issues important to them using technology.</p><p>Huge thanks to all of the many people who put time and effort into these projects!</p><p>Want to help select the projects and organizations we support next year? <a href=\"https://www.kickstarter.com/jobs\"><strong>Join our team</strong>!</a> We\u2019re always hiring passionate, creative, and collaborative engineers to help bring creative projects to\u00a0life.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d69a6114bf89\" width=\"1\" /><hr /><p><a href=\"https://kickstarter.engineering/supporting-open-source-our-donations-for-2018-d69a6114bf89\">Supporting Open Source: Our Donations for 2018</a> was originally published in <a href=\"https://kickstarter.engineering\">Kickstarter Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>At Kickstarter, we use a lot of open-source software. We pledge in <a href=\"https://www.kickstarter.com/charter\">our PBC charter</a> to support a more creative and equitable world, and that our operations will reflect our values. As part of that ethos, we try to do our share to support the open-source ecosystem by making a financial contribution to select projects.</p><p>To choose these organizations, we surveyed all of our engineers asking for nominations. They were more than eager to help, and as a result we split our yearly donation budget between two open-source projects and four organizations that foster learning or the improvement of coding skills within the open-source community.</p><p><a href=\"https://babeljs.io/\"><strong>Babel</strong></a><strong>:</strong></p><p>Babel is a toolchain that is mainly used to convert ECMAScript 2015+ code into a backwards-compatible version of JavaScript in current and older browsers or environments.</p><p>Babel allows us to use the latest Javascript technologies while making Kickstarter accessible to creators and backers all over the world. Henry and the rest of the Babel team have done an amazing job growing and improving the Babel toolchain.</p><h3>Henry Zhu on Twitter</h3><p>Awesome to see a donation from @kickstarter just now to @babeljs \ud83c\udf89! Thanks for the support and would be happy to chat more! https://t.co/u1VRcvDtz8</p><p><a href=\"https://webpack.js.org/\"><strong>Webpack</strong></a><strong>:</strong></p><p>Webpack is the tool we use to bundle our Javascript here at Kickstarter, and we\u2019re grateful for the community that builds and maintains this\u00a0tool!</p><p><a href=\"https://adventofcode.com/\"><strong>Advent of\u00a0Code</strong></a><strong>:</strong></p><p>For the last two years our engineers have enjoyed sharpening their problem-solving skills by working together on Advent of Code puzzles during the holiday season. Eric Wastl has done an amazing job turning complex computing problems into whimsical holiday\u00a0stories!</p><p><a href=\"https://railsgirlssummerofcode.org\"><strong>Rails Girls Summer of\u00a0Code</strong></a><strong>:</strong></p><p>Rails Girls Summer of Code is a program that helps women and non-binary individuals get involved in open-source projects. More diverse teams build better software. We value diversity on our team and chose to support Rails Girls Summer of Code to encourage diversity in the wider tech community.</p><p><a href=\"https://codenation.org/\"><strong>Code Nation</strong></a><strong>:</strong></p><p>Code Nation equips students in under-resourced high schools with skills, experiences and connections to create access to careers in technology. One of our senior engineers spends time each week mentoring students through Code Nation, so it made sense for us to support them a bit\u00a0more.</p><p><a href=\"https://codecooperative.org/\"><strong>Code Cooperative</strong></a><strong>:</strong></p><p>Code Cooperative teaches formerly incarcerated individuals the skills needed to be users and creators of technology. The work of addressing the systemic inequity of the prison system is vast, and we\u2019re excited to support an organization equipping this community to address issues important to them using technology.</p><p>Huge thanks to all of the many people who put time and effort into these projects!</p><p>Want to help select the projects and organizations we support next year? <a href=\"https://www.kickstarter.com/jobs\"><strong>Join our team</strong>!</a> We\u2019re always hiring passionate, creative, and collaborative engineers to help bring creative projects to\u00a0life.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d69a6114bf89\" width=\"1\" /><hr /><p><a href=\"https://kickstarter.engineering/supporting-open-source-our-donations-for-2018-d69a6114bf89\">Supporting Open Source: Our Donations for 2018</a> was originally published in <a href=\"https://kickstarter.engineering\">Kickstarter Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "New York Times": {
    "title": "Experimenting with Handwriting Recognition for The New York Times Crossword",
    "xmlUrl": "https://open.nytimes.com/feed",
    "htmlUrl": "https://open.blogs.nytimes.com",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://open.nytimes.com/feed",
      "value": "Experimenting with Handwriting Recognition for The New York Times Crossword"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://open.nytimes.com/experimenting-with-handwriting-recognition-for-new-york-times-crossword-a78e08fec08f?source=rss----51e1d1745b32---4"
      }
    ],
    "link": "https://open.nytimes.com/experimenting-with-handwriting-recognition-for-new-york-times-crossword-a78e08fec08f?source=rss----51e1d1745b32---4",
    "id": "https://medium.com/p/a78e08fec08f",
    "guidislink": false,
    "tags": [
      {
        "term": "machine-learning",
        "scheme": null,
        "label": null
      },
      {
        "term": "android",
        "scheme": null,
        "label": null
      },
      {
        "term": "crossword-puzzles",
        "scheme": null,
        "label": null
      },
      {
        "term": "ios",
        "scheme": null,
        "label": null
      },
      {
        "term": "algorithms",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "The NYT Open Team"
      }
    ],
    "author": "The NYT Open Team",
    "author_detail": {
      "name": "The NYT Open Team"
    },
    "published": "Mon, 08 Jan 2024 16:26:58 GMT",
    "published_parsed": [
      2024,
      1,
      8,
      16,
      26,
      58,
      0,
      8,
      0
    ],
    "updated": "2024-01-08T16:53:05.854Z",
    "updated_parsed": [
      2024,
      1,
      8,
      16,
      53,
      5,
      0,
      8,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://open.nytimes.com/feed",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fnRTJpam-cGan7LWE2SXgA.jpeg\" /><figcaption>Illustration by <a href=\"https://www.eddieperrote.com/\">Eddie\u00a0Perrote</a></figcaption></figure><p><strong>By Shafik Quoraishee</strong></p><h4><strong>Introduction</strong></h4><p>As part of MakerWeek 2023, The New York Times annual hackathon, iOS and Android Mobile engineers explored the ability to write in The New York Times Crosswords app on each respective platform.</p><p>As an Android engineer who participated in the experiment, I\u2019m excited to share my platform specific experience implementing <a href=\"https://arxiv.org/abs/1911.00623\">On Device ML</a> onto the Android Crosswords.</p><p><strong>Note: </strong>This exploration is for a future feature, which hasn\u2019t been released\u00a0yet.</p><h4><strong>Initial Setup and Requirements</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/374/0*iEYnoVS6-CxzktlN\" /></figure><p>The New York Times Crossword has a custom software keyboard built into the app. When a user types their letter on the keyboard, it appears on that\u00a0square.</p><p>To allow for handwriting, the first thing we needed to do was to ensure that the user could actually enter text manually, via a stylus or their finger. We took each crossword square on both the Mini and the Daily, and we transformed it into a custom component we called \u2018SketchBox\u2019. This component captures each stroke made by the user\u2019s finger or stylus as they write on the screen, and is specially designed to listen for touch and drag events to display drawn letter\u00a0strokes.</p><p>After our Sketchbox captured the resultant letter pixels from the canvas, we could then send the data to the machine learning algorithm of our\u00a0choice.</p><h4>Pencil Timing</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/146/0*3CR6gkTwOlMdR7n6\" /></figure><p>Before we get to the actual handwriting detection, we need to address a subtle but important point.</p><p>As a user writes on the Sketchbox, they typically lift their finger or the stylus off the canvas, especially to complete letters like K, A, H, etc. This means we needed to determine when exactly a user was done writing, between each stroke. For example, if they enter the stem of the \u201cK,\u201d if we try to detect what letter this may be as soon as they lift their writing utensil off the canvas, it might be interpreted as an\u00a0\u201cI\u201d.</p><p>So how long do we wait between\u00a0strokes?</p><p>For our initial implementation, we introduced the concept of a <a href=\"https://developer.android.com/reference/java/util/concurrent/CountDownLatch\">mutex-like</a> input locking system. Between each stroke we experimented with values around 500 to 1000 milliseconds depending on certain conditions. We didn\u2019t want to wait too long before unlocking the stylus, otherwise the user input experience would seem degraded and\u00a0choppy.</p><p>This is one of the many complexities we had to consider as we were designing the writing mechanic; and something that will be open for refinement in the\u00a0future.</p><h4><strong>Data Preparation, Conditioning and Normalization</strong></h4><p>Before exploring conversion of images into text, we had to consider our input: letters from various devices with different screen sizes and resolutions.</p><p>An essential pre-processing step included getting the simplest form of the data that the algorithm needs for accurate learning. In the case of image data, this means getting rid of non-essential noise, and \u201cfrivolous geometry\u201d. We downscaled and <a href=\"https://reference.wolfram.com/language/ref/Binarize.html\">binarized</a> the letter data, and then converted 128x128 raw input letters to much smaller, efficient and simplified 28x28\u00a0images.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*oWPlRhmFt8nZjLWT\" /><figcaption>An image next to a black/white binarized version to reduce unnecessary detail for easier character detection.</figcaption></figure><p>Once we did that, we could finally begin to discuss how we translate the <a href=\"https://en.wikipedia.org/wiki/Rasterisation\">rasterized</a> canvas image data to an actual character that our crossword app understands.</p><p>Handwriting recognition is a classic machine learning challenge within <a href=\"https://en.wikipedia.org/wiki/Optical_character_recognition\">Optical Character Recognition (OCR)</a>. It has seen substantial advancements over the years, notably with Dr. Yann LeCun\u2019s <a href=\"https://en.wikipedia.org/wiki/LeNet\">LeNet-5</a> architecture in 1998, which significantly improved digit recognition on the <a href=\"https://en.wikipedia.org/wiki/MNIST_database\">Modified National Institute of Standards and Technology (MNIST) dataset</a>. The MNIST dataset contains thousands of variations of the digits 1\u20139, and is the de facto standard database for digit recognition.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*1ikaPILBGn26AEK_\" /><figcaption>Snapshot of several digits from the MNIST data\u00a0set</figcaption></figure><p>The system we were trying to build looks like this high-level architecture diagram:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*uJQn8fJFcUCeb3Yz\" /></figure><p>The machine learning algorithm we chose was intended to provide the best separation of character data into recognition clusters as idealized below. This way it would be easy for our system to determine if the user wanted, for example, to enter an \u2018A\u2019 vs a \u2018C\u2019. We explored several other options that I won\u2019t go into detail about here, before settling on the use of a Deep Convolutional Neural Network architecture, which proved up to the\u00a0task.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*I5__3gyaTMD8RKBz\" /></figure><h4><strong>Building A Deep Convolutional Network</strong></h4><p>The Deep-CNN ((<a href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network\">Convolutional Neural Network</a>) is the cornerstone of any legitimate modern day image based machine learning system. It is a special kind of neural network that examines sections of image data, and using its learning mechanic, intelligently finds important features that help identify and classify\u00a0images.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*UacII8sF994dsaww\" /></figure><p>In the example presented above, the neural network takes in an input image of a bird, and detects structures that correspond to different qualitative elements of the bird. It can detect portions of the image that correspond to feathers, eyes, edges of the beak, internal beak geometry, and a whole host of traits that a person would have difficulty designing an algorithm from scratch to\u00a0do.</p><p>Using the most important features, it can determine if it\u2019s looking at a bird, and what kind of bird it is. We can even determine things like what direction the bird is flying in or looking at\u2013provided the network is trained properly. We apply the same principle to letters that a user inputs into our crossword app.</p><p>The basic CNN is a combination of the following elemental layers. By intelligently mixing and matching these structures with the proper parameters, there\u2019s very little imagewise that we can\u2019t\u00a0detect:</p><ul><li><a href=\"https://www.databricks.com/glossary/convolutional-layer\">Convolutional </a>layers allow the model to extract features automatically</li><li><a href=\"https://computersciencewiki.org/index.php/Max-pooling_/_Pooling\">Max pooling</a> layers narrow down the features obtained from the Conv\u00a0Layers</li><li><a href=\"https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\">ReLU</a> layers introduce non-linearity and allow for complex pattern discrimination</li><li><a href=\"https://en.wikipedia.org/wiki/Dilution_(neural_networks)\">Dropout</a> layers mitigate overfitting of the network to the training\u00a0data</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Kr4p9UCztPDTz0l6\" /></figure><h4><strong>TensorFlow Lite and Ingesting our\u00a0Model</strong></h4><p>In addition to building the model, we also had to find a way to deliver it to our device. We chose to use <a href=\"https://www.tensorflow.org/lite\">Tensorflow Lite</a>, a mobile framework used to install Python compiled ML models into an Android or iOS\u00a0device.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/970/0*_5tgJLlluZc71nQM\" /><figcaption>The TensorFlow Lite framework for on-device model ingestion.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Ly6YfZf-lyfNSS0i\" /></figure><p>Once we were satisfied with our model, we compiled it to a\u00a0.tflite file and baked it into our application, then built a shunt for listening to letter writing events coming from the crossword squares. We iterated several times through different models and different configurations until we were satisfied with the final result, which turned into a trained file of only 100K or so\u2013perfect for a mobile application, where space considerations are important.</p><h4><strong>Digit Recognition</strong></h4><p>Before approaching the problem of full-blown letter recognition, we decided to start simple and tackle the well studied and foundational problem of numerical digit recognition. The core section of code below provides the basic CNN setup we implemented:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*oW6A-x01ZI7Bgmhu\" /></figure><h4><strong>First Digit Based CNN Model Failure: What Went\u00a0wrong?</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/146/0*CVyYY1vIS4xKzxVe\" /></figure><p>Despite abundant training data obtained from the MNIST, our recognition results were\u00a0poor.</p><p>We ascertained the training data was \u201ctoo perfect\u201d. All the digits were only minor variations of each other, and all of them were mostly in the center of the\u00a0box.</p><p>This is not the way people enter data into a crossword square. People have different handwriting styles and ways of tilting and placing the characters in the squares off\u00a0center.</p><p>To solve this, we needed to employ a well known machine learning technique called <a href=\"https://en.wikipedia.org/wiki/Data_augmentation\">Data Augmentation</a>.</p><p>Data augmentation automatically generates off-center and distorted versions of our training data, bypassing the need for manual adjustments and skewing. This allows for many variations of our initial data set, including significantly off-centered versions of our characters.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Nn4UqcjQz8BJP4J7\" /><figcaption>The image to the left is the original digits without much variation, and to the right are the skewed, stretched and off center digits created by data augmentation.</figcaption></figure><p>By applying data augmentation techniques, we expanded our dataset from thousands to over 1 million samples with off-center minor shifts, rotations, and scaling\u200a\u2014\u200aalso called <a href=\"https://en.wikipedia.org/wiki/Affine_transformation\">affine transformations</a>.</p><h4><strong>Data Augmented Digit Model Success against\u00a0Digits</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/148/0*4Taq3RO_cG7KP69V\" /></figure><p>As you can see, the digit recognition has improved significantly on the real crossword\u200a\u2014\u200aa milestone in our\u00a0work!</p><h4><strong>Moving to Full Blown Letter Recognition</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/772/0*TcSRuBm6V-NudDFP\" /></figure><p>Now that we solved digits, the next step was to solve letters. This includes lowercase and capital letters and all of their variations. Instead of just ten digits, we are now dealing with 26 lowercase, 26 capital letters and ten digits, which equates to 62 characters.</p><p>We can use the <a href=\"https://www.nist.gov/itl/products-and-services/emnist-dataset\">EMNIST</a> dataset (Dataset source: <a href=\"http://arxiv.org/abs/1702.05373\">http://arxiv.org/abs/1702.05373</a>), an expanded version of the MNIST set, that includes both letters and digits and even punctuation, to help train the model\u00a0better.</p><p>However, even with the enhanced dataset, the digit specific model isn\u2019t sufficient for our needs. This is intuitively not surprising, because while the digit recognition model was powerful, it is surely not \u201cintelligent\u201d enough for the greatly expanded variation in character structure that is introduced by looking at\u00a0letters.</p><h4><strong>Hyper Powering The Model through Parameter Optimization</strong></h4><p>To increase the power of our model, we added much more depth to our network in the form of several additional layers. We also employed Stratified K<a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\">-Fold cross-validation</a> to diversify our training by using randomized subsets of our augmented training/validation data.</p><p>To ensure that our layers were optimally designed, we employed a <a href=\"https://en.wikipedia.org/wiki/Hyperparameter_optimization\">randomized parametric search</a> along with enhanced statistical testing, which allowed us to find the optimal hyperparameters for our model. This proved to be an enhancement from our previous strategy of guessing the right parameters.</p><p>In our testing phase, we attained an average validation accuracy of ~91% on the Augmented EMNIST dataset. This gave us faith that our model would\u00a0work.</p><p>FINALLY: SUCCESS!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/146/0*nuyWn_cKwvbG-Agt\" /></figure><p>After a long journey of exploring the landscape of ML model building, we finally arrived at a working crossword model\u2013which was exciting. Even though we attained stellar results, there is still much work to do for the complete crossword experience, including dealing with partial letters, and letters that are spaced at irregular intervals.</p><h4><strong>Conclusion</strong></h4><p>Implementing handwriting recognition on the Android crossword app was an exciting adventure, even in an experimental context. Aside from handwriting, there\u2019s also the potential for interactive features like \u201cScribble-to-Erase\u201d detection and the possibility of in-app self-training mechanisms, and a whole host of other doors that On-Device ML in the Games App can\u00a0open.</p><p>Having the opportunity to experiment with new techniques and amplifications to our existing products is a core part of why working at the Times as an engineer is so unique and so worth it. We hope one day to turn this into a feature that amplifies the Games experience for our current users and attracts new subscribers.</p><p><em>Shafik Quoraishee is a Senior Android Engineer on the Games Team at The New York Times. He is an avid machine learning/A.I. Enthusiast. Outside of work, he enjoys playing guitar, writing, and running quirky experiments.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a78e08fec08f\" width=\"1\" /><hr /><p><a href=\"https://open.nytimes.com/experimenting-with-handwriting-recognition-for-new-york-times-crossword-a78e08fec08f\">Experimenting with Handwriting Recognition for The New York Times Crossword</a> was originally published in <a href=\"https://open.nytimes.com\">NYT Open</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fnRTJpam-cGan7LWE2SXgA.jpeg\" /><figcaption>Illustration by <a href=\"https://www.eddieperrote.com/\">Eddie\u00a0Perrote</a></figcaption></figure><p><strong>By Shafik Quoraishee</strong></p><h4><strong>Introduction</strong></h4><p>As part of MakerWeek 2023, The New York Times annual hackathon, iOS and Android Mobile engineers explored the ability to write in The New York Times Crosswords app on each respective platform.</p><p>As an Android engineer who participated in the experiment, I\u2019m excited to share my platform specific experience implementing <a href=\"https://arxiv.org/abs/1911.00623\">On Device ML</a> onto the Android Crosswords.</p><p><strong>Note: </strong>This exploration is for a future feature, which hasn\u2019t been released\u00a0yet.</p><h4><strong>Initial Setup and Requirements</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/374/0*iEYnoVS6-CxzktlN\" /></figure><p>The New York Times Crossword has a custom software keyboard built into the app. When a user types their letter on the keyboard, it appears on that\u00a0square.</p><p>To allow for handwriting, the first thing we needed to do was to ensure that the user could actually enter text manually, via a stylus or their finger. We took each crossword square on both the Mini and the Daily, and we transformed it into a custom component we called \u2018SketchBox\u2019. This component captures each stroke made by the user\u2019s finger or stylus as they write on the screen, and is specially designed to listen for touch and drag events to display drawn letter\u00a0strokes.</p><p>After our Sketchbox captured the resultant letter pixels from the canvas, we could then send the data to the machine learning algorithm of our\u00a0choice.</p><h4>Pencil Timing</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/146/0*3CR6gkTwOlMdR7n6\" /></figure><p>Before we get to the actual handwriting detection, we need to address a subtle but important point.</p><p>As a user writes on the Sketchbox, they typically lift their finger or the stylus off the canvas, especially to complete letters like K, A, H, etc. This means we needed to determine when exactly a user was done writing, between each stroke. For example, if they enter the stem of the \u201cK,\u201d if we try to detect what letter this may be as soon as they lift their writing utensil off the canvas, it might be interpreted as an\u00a0\u201cI\u201d.</p><p>So how long do we wait between\u00a0strokes?</p><p>For our initial implementation, we introduced the concept of a <a href=\"https://developer.android.com/reference/java/util/concurrent/CountDownLatch\">mutex-like</a> input locking system. Between each stroke we experimented with values around 500 to 1000 milliseconds depending on certain conditions. We didn\u2019t want to wait too long before unlocking the stylus, otherwise the user input experience would seem degraded and\u00a0choppy.</p><p>This is one of the many complexities we had to consider as we were designing the writing mechanic; and something that will be open for refinement in the\u00a0future.</p><h4><strong>Data Preparation, Conditioning and Normalization</strong></h4><p>Before exploring conversion of images into text, we had to consider our input: letters from various devices with different screen sizes and resolutions.</p><p>An essential pre-processing step included getting the simplest form of the data that the algorithm needs for accurate learning. In the case of image data, this means getting rid of non-essential noise, and \u201cfrivolous geometry\u201d. We downscaled and <a href=\"https://reference.wolfram.com/language/ref/Binarize.html\">binarized</a> the letter data, and then converted 128x128 raw input letters to much smaller, efficient and simplified 28x28\u00a0images.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*oWPlRhmFt8nZjLWT\" /><figcaption>An image next to a black/white binarized version to reduce unnecessary detail for easier character detection.</figcaption></figure><p>Once we did that, we could finally begin to discuss how we translate the <a href=\"https://en.wikipedia.org/wiki/Rasterisation\">rasterized</a> canvas image data to an actual character that our crossword app understands.</p><p>Handwriting recognition is a classic machine learning challenge within <a href=\"https://en.wikipedia.org/wiki/Optical_character_recognition\">Optical Character Recognition (OCR)</a>. It has seen substantial advancements over the years, notably with Dr. Yann LeCun\u2019s <a href=\"https://en.wikipedia.org/wiki/LeNet\">LeNet-5</a> architecture in 1998, which significantly improved digit recognition on the <a href=\"https://en.wikipedia.org/wiki/MNIST_database\">Modified National Institute of Standards and Technology (MNIST) dataset</a>. The MNIST dataset contains thousands of variations of the digits 1\u20139, and is the de facto standard database for digit recognition.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*1ikaPILBGn26AEK_\" /><figcaption>Snapshot of several digits from the MNIST data\u00a0set</figcaption></figure><p>The system we were trying to build looks like this high-level architecture diagram:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*uJQn8fJFcUCeb3Yz\" /></figure><p>The machine learning algorithm we chose was intended to provide the best separation of character data into recognition clusters as idealized below. This way it would be easy for our system to determine if the user wanted, for example, to enter an \u2018A\u2019 vs a \u2018C\u2019. We explored several other options that I won\u2019t go into detail about here, before settling on the use of a Deep Convolutional Neural Network architecture, which proved up to the\u00a0task.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*I5__3gyaTMD8RKBz\" /></figure><h4><strong>Building A Deep Convolutional Network</strong></h4><p>The Deep-CNN ((<a href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network\">Convolutional Neural Network</a>) is the cornerstone of any legitimate modern day image based machine learning system. It is a special kind of neural network that examines sections of image data, and using its learning mechanic, intelligently finds important features that help identify and classify\u00a0images.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*UacII8sF994dsaww\" /></figure><p>In the example presented above, the neural network takes in an input image of a bird, and detects structures that correspond to different qualitative elements of the bird. It can detect portions of the image that correspond to feathers, eyes, edges of the beak, internal beak geometry, and a whole host of traits that a person would have difficulty designing an algorithm from scratch to\u00a0do.</p><p>Using the most important features, it can determine if it\u2019s looking at a bird, and what kind of bird it is. We can even determine things like what direction the bird is flying in or looking at\u2013provided the network is trained properly. We apply the same principle to letters that a user inputs into our crossword app.</p><p>The basic CNN is a combination of the following elemental layers. By intelligently mixing and matching these structures with the proper parameters, there\u2019s very little imagewise that we can\u2019t\u00a0detect:</p><ul><li><a href=\"https://www.databricks.com/glossary/convolutional-layer\">Convolutional </a>layers allow the model to extract features automatically</li><li><a href=\"https://computersciencewiki.org/index.php/Max-pooling_/_Pooling\">Max pooling</a> layers narrow down the features obtained from the Conv\u00a0Layers</li><li><a href=\"https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\">ReLU</a> layers introduce non-linearity and allow for complex pattern discrimination</li><li><a href=\"https://en.wikipedia.org/wiki/Dilution_(neural_networks)\">Dropout</a> layers mitigate overfitting of the network to the training\u00a0data</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Kr4p9UCztPDTz0l6\" /></figure><h4><strong>TensorFlow Lite and Ingesting our\u00a0Model</strong></h4><p>In addition to building the model, we also had to find a way to deliver it to our device. We chose to use <a href=\"https://www.tensorflow.org/lite\">Tensorflow Lite</a>, a mobile framework used to install Python compiled ML models into an Android or iOS\u00a0device.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/970/0*_5tgJLlluZc71nQM\" /><figcaption>The TensorFlow Lite framework for on-device model ingestion.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Ly6YfZf-lyfNSS0i\" /></figure><p>Once we were satisfied with our model, we compiled it to a\u00a0.tflite file and baked it into our application, then built a shunt for listening to letter writing events coming from the crossword squares. We iterated several times through different models and different configurations until we were satisfied with the final result, which turned into a trained file of only 100K or so\u2013perfect for a mobile application, where space considerations are important.</p><h4><strong>Digit Recognition</strong></h4><p>Before approaching the problem of full-blown letter recognition, we decided to start simple and tackle the well studied and foundational problem of numerical digit recognition. The core section of code below provides the basic CNN setup we implemented:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*oW6A-x01ZI7Bgmhu\" /></figure><h4><strong>First Digit Based CNN Model Failure: What Went\u00a0wrong?</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/146/0*CVyYY1vIS4xKzxVe\" /></figure><p>Despite abundant training data obtained from the MNIST, our recognition results were\u00a0poor.</p><p>We ascertained the training data was \u201ctoo perfect\u201d. All the digits were only minor variations of each other, and all of them were mostly in the center of the\u00a0box.</p><p>This is not the way people enter data into a crossword square. People have different handwriting styles and ways of tilting and placing the characters in the squares off\u00a0center.</p><p>To solve this, we needed to employ a well known machine learning technique called <a href=\"https://en.wikipedia.org/wiki/Data_augmentation\">Data Augmentation</a>.</p><p>Data augmentation automatically generates off-center and distorted versions of our training data, bypassing the need for manual adjustments and skewing. This allows for many variations of our initial data set, including significantly off-centered versions of our characters.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Nn4UqcjQz8BJP4J7\" /><figcaption>The image to the left is the original digits without much variation, and to the right are the skewed, stretched and off center digits created by data augmentation.</figcaption></figure><p>By applying data augmentation techniques, we expanded our dataset from thousands to over 1 million samples with off-center minor shifts, rotations, and scaling\u200a\u2014\u200aalso called <a href=\"https://en.wikipedia.org/wiki/Affine_transformation\">affine transformations</a>.</p><h4><strong>Data Augmented Digit Model Success against\u00a0Digits</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/148/0*4Taq3RO_cG7KP69V\" /></figure><p>As you can see, the digit recognition has improved significantly on the real crossword\u200a\u2014\u200aa milestone in our\u00a0work!</p><h4><strong>Moving to Full Blown Letter Recognition</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/772/0*TcSRuBm6V-NudDFP\" /></figure><p>Now that we solved digits, the next step was to solve letters. This includes lowercase and capital letters and all of their variations. Instead of just ten digits, we are now dealing with 26 lowercase, 26 capital letters and ten digits, which equates to 62 characters.</p><p>We can use the <a href=\"https://www.nist.gov/itl/products-and-services/emnist-dataset\">EMNIST</a> dataset (Dataset source: <a href=\"http://arxiv.org/abs/1702.05373\">http://arxiv.org/abs/1702.05373</a>), an expanded version of the MNIST set, that includes both letters and digits and even punctuation, to help train the model\u00a0better.</p><p>However, even with the enhanced dataset, the digit specific model isn\u2019t sufficient for our needs. This is intuitively not surprising, because while the digit recognition model was powerful, it is surely not \u201cintelligent\u201d enough for the greatly expanded variation in character structure that is introduced by looking at\u00a0letters.</p><h4><strong>Hyper Powering The Model through Parameter Optimization</strong></h4><p>To increase the power of our model, we added much more depth to our network in the form of several additional layers. We also employed Stratified K<a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\">-Fold cross-validation</a> to diversify our training by using randomized subsets of our augmented training/validation data.</p><p>To ensure that our layers were optimally designed, we employed a <a href=\"https://en.wikipedia.org/wiki/Hyperparameter_optimization\">randomized parametric search</a> along with enhanced statistical testing, which allowed us to find the optimal hyperparameters for our model. This proved to be an enhancement from our previous strategy of guessing the right parameters.</p><p>In our testing phase, we attained an average validation accuracy of ~91% on the Augmented EMNIST dataset. This gave us faith that our model would\u00a0work.</p><p>FINALLY: SUCCESS!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/146/0*nuyWn_cKwvbG-Agt\" /></figure><p>After a long journey of exploring the landscape of ML model building, we finally arrived at a working crossword model\u2013which was exciting. Even though we attained stellar results, there is still much work to do for the complete crossword experience, including dealing with partial letters, and letters that are spaced at irregular intervals.</p><h4><strong>Conclusion</strong></h4><p>Implementing handwriting recognition on the Android crossword app was an exciting adventure, even in an experimental context. Aside from handwriting, there\u2019s also the potential for interactive features like \u201cScribble-to-Erase\u201d detection and the possibility of in-app self-training mechanisms, and a whole host of other doors that On-Device ML in the Games App can\u00a0open.</p><p>Having the opportunity to experiment with new techniques and amplifications to our existing products is a core part of why working at the Times as an engineer is so unique and so worth it. We hope one day to turn this into a feature that amplifies the Games experience for our current users and attracts new subscribers.</p><p><em>Shafik Quoraishee is a Senior Android Engineer on the Games Team at The New York Times. He is an avid machine learning/A.I. Enthusiast. Outside of work, he enjoys playing guitar, writing, and running quirky experiments.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a78e08fec08f\" width=\"1\" /><hr /><p><a href=\"https://open.nytimes.com/experimenting-with-handwriting-recognition-for-new-york-times-crossword-a78e08fec08f\">Experimenting with Handwriting Recognition for The New York Times Crossword</a> was originally published in <a href=\"https://open.nytimes.com\">NYT Open</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "NPR Apps": {
    "title": "Join us for the 2024 election",
    "xmlUrl": "http://blog.apps.npr.org/atom.xml",
    "htmlUrl": "http://blog.apps.npr.org/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://blog.apps.npr.org/atom.xml",
      "value": "Join us for the 2024 election"
    },
    "links": [
      {
        "href": "http://blog.apps.npr.org/2023/09/08/election-jobs.html",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "link": "http://blog.apps.npr.org/2023/09/08/election-jobs.html",
    "updated": "2023-09-08T00:00:00+00:00",
    "updated_parsed": [
      2023,
      9,
      8,
      0,
      0,
      0,
      4,
      251,
      0
    ],
    "id": "http://blog.apps.npr.org/2023/09/08/election-jobs",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "http://blog.apps.npr.org/atom.xml",
        "value": "<p>NPR is staffing up for the 2024 elections, and we have a few contract code / graphics / visual positions open:</p>\n\n<p><strong>News Apps / graphics:</strong> Work on election results and analysis, as well as other stories and projects that come up. Both of these roles can be based at our DC headquarters or remote (U.S.-based, at a location NPR approves)</p>\n\n<ul>\n  <li><a href=\"https://grnh.se/d55dda975us\">Elections graphics reporter</a></li>\n  <li><a href=\"https://grnh.se/5623b8475us\">Elections news apps developer</a></li>\n</ul>\n\n<p><strong>Visuals:</strong> Photo and video-related roles. These are hybrid roles, requiring some onsite work.</p>\n\n<ul>\n  <li><a href=\"https://boards.greenhouse.io/nationalpublicradioinc/jobs/4310679005\">Visuals editor, elections</a> (DC)</li>\n  <li><a href=\"https://boards.greenhouse.io/nationalpublicradioinc/jobs/4310671005\">Associate producer, elections</a> (NYC)</li>\n</ul>"
      }
    ],
    "summary": "<p>NPR is staffing up for the 2024 elections, and we have a few contract code / graphics / visual positions open:</p>\n\n<p><strong>News Apps / graphics:</strong> Work on election results and analysis, as well as other stories and projects that come up. Both of these roles can be based at our DC headquarters or remote (U.S.-based, at a location NPR approves)</p>\n\n<ul>\n  <li><a href=\"https://grnh.se/d55dda975us\">Elections graphics reporter</a></li>\n  <li><a href=\"https://grnh.se/5623b8475us\">Elections news apps developer</a></li>\n</ul>\n\n<p><strong>Visuals:</strong> Photo and video-related roles. These are hybrid roles, requiring some onsite work.</p>\n\n<ul>\n  <li><a href=\"https://boards.greenhouse.io/nationalpublicradioinc/jobs/4310679005\">Visuals editor, elections</a> (DC)</li>\n  <li><a href=\"https://boards.greenhouse.io/nationalpublicradioinc/jobs/4310671005\">Associate producer, elections</a> (NYC)</li>\n</ul>"
  },
  "Airbnb": {
    "title": "Airbnb at KDD 2023",
    "xmlUrl": "https://medium.com/feed/airbnb-engineering",
    "htmlUrl": "https://medium.com/airbnb-engineering",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/airbnb-engineering",
      "value": "Airbnb at KDD 2023"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/airbnb-engineering/airbnb-at-kdd-2023-9084ad244d8c?source=rss----53c7c27702d5---4"
      }
    ],
    "link": "https://medium.com/airbnb-engineering/airbnb-at-kdd-2023-9084ad244d8c?source=rss----53c7c27702d5---4",
    "id": "https://medium.com/p/9084ad244d8c",
    "guidislink": false,
    "tags": [
      {
        "term": "ai",
        "scheme": null,
        "label": null
      },
      {
        "term": "data-science",
        "scheme": null,
        "label": null
      },
      {
        "term": "causal-inference",
        "scheme": null,
        "label": null
      },
      {
        "term": "a-b-testing",
        "scheme": null,
        "label": null
      },
      {
        "term": "machine-learning",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Alex Deng"
      }
    ],
    "author": "Alex Deng",
    "author_detail": {
      "name": "Alex Deng"
    },
    "published": "Fri, 22 Dec 2023 19:59:03 GMT",
    "published_parsed": [
      2023,
      12,
      22,
      19,
      59,
      3,
      4,
      356,
      0
    ],
    "updated": "2023-12-23T05:48:41.267Z",
    "updated_parsed": [
      2023,
      12,
      23,
      5,
      48,
      41,
      5,
      357,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/airbnb-engineering",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Hko3nVtsyBbe7Yk1\" /></figure><p>KDD (Knowledge and Data Mining) is a flagship conference in data science research. Hosted annually by a special interest group of the Association for Computing Machinery (ACM), it\u2019s where you\u2019ll learn about some of the most ground-breaking developments in data mining, knowledge discovery, and large-scale data analytics.</p><p>Airbnb had a significant presence at <a href=\"https://kdd.org/kdd2023/\">KDD 2023</a> with two papers accepted into the main conference proceedings and 11 talks and presentations. In this blog post, we\u2019ll summarize our team\u2019s contributions and share highlights from an exciting week of research talks, workshops, panel discussions, and\u00a0more.</p><h3>Deep learning and search\u00a0ranking</h3><p>Even though search ranking is a problem that researchers have been working on for decades, there are still many nuances to explore. For example, at Airbnb, guests are typically searching over a period of days or weeks, not minutes. And being a two-way marketplace, there are factors like the potential for hosts to cancel the booking that we\u2019d like to account for in\u00a0ranking.</p><p><a href=\"https://arxiv.org/abs/2305.18431\">Optimizing Airbnb Search Journey with Multi-task Learning</a>, our paper accepted at KDD 2023, presents Journey Ranker, a new multi-task deep learning model. The core insight here is that for this kind of long-term search task, we want to optimize for intermediate steps in the user\u00a0journey.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*kLAJ2bVBzKCyzpmg\" /></figure><p><em>The Journey Ranker base module assists guests in reaching positive milestones. There is also a Twiddler module that assists guests in avoiding negative milestones. The modules work off a shared feature representation of listing and guest context, and their output scores are combined.</em></p><p>Because of its modular design, Journey Ranker can be used whenever<em> </em>there are positive or negative milestones to consider. We\u2019ve implemented it in different Airbnb search and other products to drive improvements in business\u00a0metrics.</p><p>We also co-presented <a href=\"https://dcaitutorial.github.io/\">a tutorial on Data-Centric AI</a> (DCAI). DCAI is a fast-growing field in deep learning, because as model design matures, innovation is being driven by data. We shared DCAI best practices and trends for developing training data, developing inference data, maintaining data, and creating benchmarks, with many examples from working with\u00a0LLMs.</p><h3>Online experimentation and measurement</h3><p>Online experimentation (e.g., A/B testing) is a common way for organizations like Airbnb to make data-driven decisions. But high variance is frequently a challenge. For example, it\u2019s hard to prove that a change in our search UX will drive value when bookings are infrequent and depend on a large number of interactions over a long period of\u00a0time.</p><p>Our paper <a href=\"https://dl.acm.org/doi/pdf/10.1145/3580305.3599928\">Variance Reduction Using In-Experiment Data: Efficient and Targeted Online Measurement for Sparse and Delayed Outcomes</a> presents two new methods for variance reduction that rely exclusively on in-experiment data:</p><ol><li>A framework for a model-based leading indicator metric that continually estimates progress toward a delayed binary\u00a0outcome.</li><li>A counterfactual treatment exposure index that quantifies the amount a user is impacted by the treatment.</li></ol><p>In testing, both methods achieved a variance reduction of 50% or more. These techniques have greatly improved our experimentation efficiency and\u00a0impact.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*VLJeyMFXLGQAMQ_h\" /></figure><p><em>With more than 50% variance reduction, the new model-based leading indicator metric (listing-view utility, on the right) aligns with the target uncancelled booking metric much better than other indicators such as listing-view with dates (on the\u00a0left).</em></p><p>Another interesting challenge in online experimentation is avoiding interference bias, which can happen when you have competition between your A/B test subjects. Airbnb presented a keynote talk on this topic at KDD\u2019s <a href=\"https://sites.google.com/view/kdd23onlinemarketplaces/home\">2nd Workshop on Decision Intelligence and Analytics for Online Marketplaces</a>. As an example, if you ran an A/B test where group B saw lower booking prices, they might \u201ccannibalize\u201d the bookings from group A. There are two imperfect solutions: clustering (isolating the options for participants) and switchbacks (grouping participants by time intervals).</p><p>Also at the workshop, we presented the paper <a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/CIKM.pdf\">The Price is Right: Removing A/B Test Bias in a Marketplace of Expirable Goods</a>. This discusses the problem of lead-day bias: where items like concert tickets, air travel, and Airbnb bookings vary in price based on the distance from their expiration date. This can wreak havoc on A/B tests, and in the paper we present several mitigation techniques, such as limited rollout, smart overlapping of experiments, and Heterogeneous Treatment Effect (HTE) remixed estimator to correct for bias and accelerate R&amp;D\u00a0process.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*_BreW6LQyQTzs2XZ\" /></figure><p><em>Along with limited rollout and smart overlapping of experiments, HTE-remixed estimator can provide sufficiently robust estimation of the long-term experiment impact from the short-term result and significantly shorten the experiment run-time.</em></p><h3>Causal inference for marketing and user journey optimization</h3><p>In marketing, the million-dollar question is how much should you spend per channel? This can be reframed as a causal inference problem: how many incremental conversions does each channel\u00a0drive?</p><p>When we look at marketing activities across Nielsen\u2019s Designated Marketing Areas (DMAs) we find moderate to strong correlation across channels. This makes it hard to isolate the impact of one channel from another. In fact, when we include the correlated channels in the same regression, the coefficients flip signs for most channels, a clear sign of multicollinearity.</p><p>Existing solutions to multicollinearity, such as shrinkage estimators, principal component analysis, and partial linear regression, are particularly helpful for prediction problems but work less well for our use case where we need to maintain business interpretability while isolating causality. Our approach, described in the paper Hierarchical Clustering as <a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/31.KDD-Paper-Hierarchical-Clustering-As-a-Solution-to-Multicollinearity-\u2013-Marketing-Application-as-an-Example.pdf\">a Novel Solution to Multicollinearity</a>, is to hierarchically cluster DMAs based on their similarity in marketing impressions over time. With such clustering, cross-channel correlation dropped by up to 43% and the channel coefficients no longer flip\u00a0signs.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*xCf2MRTm27kOyaEj\" /></figure><p>Not only does our method provide an intuitive and effective solution to multicollinearity, it also circumvents the need for complex transformation and preserves the interpretability of the data and the results throughout, empowering broad applications to causal inference problems.</p><p>We presented this paper at the new KDD workshop, <a href=\"https://causal-machine-learning.github.io/kdd2023-workshop/\">Causal Inference and Machine Learning in Practice: Use cases for Product, Brand, Policy, and beyond</a>. Airbnb\u2019s Totte Harinen co-organized this workshop, which strongly resonated with KDD\u2019s audience\u200a\u2014\u200ait had 12 papers and four invited talks from 37 authors in 14 institutions.</p><p>In addition, we were invited to present two talks and one poster at KDD\u2019s <a href=\"https://sites.google.com/view/kdd-workshop-2023\">2nd Workshop on End-End Customer Journey Optimization</a>, and joined the workshop\u2019s panel discussion. One of these talks covered CLV (customer lifetime value) modeling. At Airbnb, we want to grow our brand and community by growing all users. Our CLV ecosystem applies two frameworks:</p><ol><li>The value of Airbnb customers. We use traditional ML approaches along with research into more customer-lifecycle-focused architectures (i.e. HMMs). We augment this with demand-supply incrementality modeling to properly account for guest and<em> </em>host contributions to\u00a0value.</li><li>The value growth that Airbnb delivers to customers. By accounting for long-term incremental effects of booking on Airbnb along with incremental contributions from marketing and attribution strategies, we can measure incremental changes in CLV and optimize towards\u00a0them.</li></ol><p>Causal inference can also be applied to search. At the CJ workshop, we presented our paper <a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/CameraReady-7-1.pdf\">Low Inventory State: Identifying Under-Served Queries for Airbnb Search</a>, which explored the problem of searches that return a low number of results. Whether or not that number is \u201ctoo low\u201d and will deter a guest from booking depends on search parameters and intent to book. For a given search query, we can use causal inference to determine the incremental effect of an additional result on the probability of booking. Our model outperforms non-causal methods and can assist with supply management as\u00a0well.</p><p>Finally, our poster discussed how we measure the effects of national TV advertising campaigns. We analyzed TV exposure data and demographic data with data on Airbnb onsite behavior using a third-party identity graph. We were able to resolve disparate datasets to a unique identifier and model individual households.</p><p>We use propensity score matching to estimate TV effects, and then scale these estimates to a nationally-representative population. We leverage this data to provide tactical insights for marketing and understand how long TV effects take to\u00a0decay.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/523/1*2550R2exF5NwZquO26vY9A.png\" /></figure><p>The plot above (from simulated study for illustration) shows the results of an analysis for a TV campaign from August\u200a\u2014\u200aOctober. We can see that the TV campaign was effective at increasing bookings for households that saw an Airbnb TV ad and was more effective for one subgroup (red line) than the other subgroup.</p><h3>Data science and analytics infra</h3><p>How can you achieve science at scale in a medium-to-large engineering organization? At the KDD\u2019s <a href=\"https://wamlm-kdd.github.io/wamlm/index.html\">2nd Workshop on Applied Machine Learning Management</a>, we shared Airbnb\u2019s solution for data science reproducibility and reuse, <a href=\"https://wamlm-kdd.github.io/wamlm/papers/wamlm-kdd23_paper_Daniel_Miller.pdf\">Onebrain</a>. The core of Onebrain is a coding standard for configuring data science projects entirely in YAML. Onebrain\u2019s backend abstracts away CI/CD, configuration/dependency management, and command-line parsing. Since it\u2019s \u201cjust code,\u201d Onebrain projects can be checked into a version-controlled repo, and any repo can be a Onebrain\u00a0repo.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Y0TXGcnp4lz40NVn\" /></figure><p>User interaction with Onebrain happens through a CLI. With a single command, anyone can use an existing project as a template for their own work, or generate a one-click URL to spin up a server and run the project. Usage is growing fast with over 200 distinct projects and over 500 users at Airbnb within just a\u00a0year.</p><p>While most of our research focuses on high-order data use-cases like models, data capture is essential as it\u2019s the starting point for any analysis. Event logging libraries typically capture <em>actions on</em> and <em>impressions of</em> app components (buttons, sections, pages). But with this level of granularity, it can be difficult to abstract out user behavior, measure the total time spent on a surface, or understand the context surrounding an\u00a0action.</p><p>At the <a href=\"https://sites.google.com/view/kdd-workshop-2023\">2nd Workshop on End-End Customer Journey Optimization</a>, we spoke about a new type of client-side event called Sessions. Part of Airbnb\u2019s client-side logging solution, Sessions provide a way to track user context and behaviors within the Airbnb product. Unlike traditional time-based sessions used in web analytics, these Sessions can be tied to various aspects of the Airbnb user experience. For example, they can be tied to specific surfaces like the checkout page, API calls used for observability, or even internal states of the app that abstract away complex UI components. The flexibility of Sessions allows us to capture a wide range of user interactions and better understand their journey throughout our platform.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/941/0*W0F1AhzPituZ1bfF\" /></figure><h3>Conclusion</h3><p>KDD is an amazing opportunity for data scientists from around the world, and across industry and academia, to come together and exchange learnings and discoveries. We were honored to be invited to share techniques we\u2019ve developed through applied research at Airbnb. The strategies and insights we presented at KDD have been essential to improving Airbnb\u2019s platform, business, and user experience. We\u2019re constantly motivated by innovations happening around us, and we\u2019re thrilled to give back to the community and eager to see what kinds of new applications and advancements may come about as a\u00a0result.</p><p>At the bottom of the page, you\u2019ll find a complete list of the talks and papers shared in this article along with the team members who contributed. If you can see yourself on our team, we encourage you to apply for an<a href=\"https://careers.airbnb.com/\"> open position</a>\u00a0today.</p><h3>List of papers and\u00a0talks</h3><p><strong>Optimizing Airbnb Search Journey with Multi-task Learning\u00a0[</strong><a href=\"https://arxiv.org/abs/2305.18431\"><strong>link</strong></a><strong>]</strong></p><p>Authors: <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tan,+C+H\">Chun How Tan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chan,+A\">Austin Chan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Haldar,+M\">Malay Haldar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tang,+J\">Jie Tang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+X\">Xin Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Abdool,+M\">Mustafa Abdool</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gao,+H\">Huiji Gao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+L\">Liwei He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Katariya,+S\">Sanjeev\u00a0Katariya</a></p><p><strong>Variance Reduction Using In-Experiment Data: Efficient and Targeted Online Measurement for Sparse and Delayed Outcomes\u00a0[</strong><a href=\"https://alexdeng.github.io/public/files/kdd2023-inexp.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Authors: Alex Deng, Michelle Du, Anna Matlin, Qing\u00a0Zhang</p><p><strong>Beyond the Simple A/B test: Mitigating Interference Bias at\u00a0Airbnb</strong></p><p>Speaker: Ruben\u00a0Lobel</p><p><strong>The Price is Right: Removing A/B Test Bias in a Marketplace of Expirable Goods\u00a0[</strong><a href=\"https://alexdeng.github.io/public/files/Smart_Pricing_CIKM.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Author: Thu Le, Alex\u00a0Deng</p><p><strong>Unveiling the Guest &amp; Host Journey: Session-Based Instrumentation on Airbnb\u00a0Platform</strong></p><p>Speaker: Shant\u00a0Torosean</p><p><strong>Devoted to Long-Term Adventure: Growing Airbnb Through Measuring Customer Lifetime\u00a0Value</strong></p><p>Speaker: Sean O\u2019Donell, Jason Cai, Linsha\u00a0Chen</p><p><strong>Low Inventory State: Identifying Under-Served Queries for Airbnb Search\u00a0[</strong><a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/CameraReady-7-1.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Author: Toma Gulea, Bradley\u00a0Turnbull</p><p><strong>Measuring TV Campaigns at\u00a0Airbnb</strong></p><p>Speaker: Adam Maidman, Sam\u00a0Barrows</p><p><strong>Tutorial: Data-Centric AI\u00a0[</strong><a href=\"https://dcaitutorial.github.io/index.html\"><strong>link</strong></a><strong>]</strong></p><p>Presenter: Daochen Zha, Huiji\u00a0Gao</p><p><strong>Hierarchical Clustering As a Novel Solution to the Notorious: Multicollinearity Problem in Observational Causal Inference [</strong><a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/31.KDD-Paper-Hierarchical-Clustering-As-a-Solution-to-Multicollinearity-\u2013-Marketing-Application-as-an-Example.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Authors: Yufei Wu, Zhiying Gu, Alex Deng, Jacob Zhu, Linsha\u00a0Chen</p><p><a href=\"https://wamlm-kdd.github.io/wamlm/papers/wamlm-kdd23_paper_Daniel_Miller.pdf\"><strong>Onebrain\u200a\u2014\u200aMicroprojects for Data Science</strong></a><strong>\u00a0[</strong><a href=\"https://wamlm-kdd.github.io/wamlm/papers/wamlm-kdd23_paper_Daniel_Miller.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Authors: Daniel Miller, Alex Deng, Narek Amirbekian, Navin Sivanandam, Rodolfo\u00a0Carboni</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9084ad244d8c\" width=\"1\" /><hr /><p><a href=\"https://medium.com/airbnb-engineering/airbnb-at-kdd-2023-9084ad244d8c\">Airbnb at KDD 2023</a> was originally published in <a href=\"https://medium.com/airbnb-engineering\">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Hko3nVtsyBbe7Yk1\" /></figure><p>KDD (Knowledge and Data Mining) is a flagship conference in data science research. Hosted annually by a special interest group of the Association for Computing Machinery (ACM), it\u2019s where you\u2019ll learn about some of the most ground-breaking developments in data mining, knowledge discovery, and large-scale data analytics.</p><p>Airbnb had a significant presence at <a href=\"https://kdd.org/kdd2023/\">KDD 2023</a> with two papers accepted into the main conference proceedings and 11 talks and presentations. In this blog post, we\u2019ll summarize our team\u2019s contributions and share highlights from an exciting week of research talks, workshops, panel discussions, and\u00a0more.</p><h3>Deep learning and search\u00a0ranking</h3><p>Even though search ranking is a problem that researchers have been working on for decades, there are still many nuances to explore. For example, at Airbnb, guests are typically searching over a period of days or weeks, not minutes. And being a two-way marketplace, there are factors like the potential for hosts to cancel the booking that we\u2019d like to account for in\u00a0ranking.</p><p><a href=\"https://arxiv.org/abs/2305.18431\">Optimizing Airbnb Search Journey with Multi-task Learning</a>, our paper accepted at KDD 2023, presents Journey Ranker, a new multi-task deep learning model. The core insight here is that for this kind of long-term search task, we want to optimize for intermediate steps in the user\u00a0journey.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*kLAJ2bVBzKCyzpmg\" /></figure><p><em>The Journey Ranker base module assists guests in reaching positive milestones. There is also a Twiddler module that assists guests in avoiding negative milestones. The modules work off a shared feature representation of listing and guest context, and their output scores are combined.</em></p><p>Because of its modular design, Journey Ranker can be used whenever<em> </em>there are positive or negative milestones to consider. We\u2019ve implemented it in different Airbnb search and other products to drive improvements in business\u00a0metrics.</p><p>We also co-presented <a href=\"https://dcaitutorial.github.io/\">a tutorial on Data-Centric AI</a> (DCAI). DCAI is a fast-growing field in deep learning, because as model design matures, innovation is being driven by data. We shared DCAI best practices and trends for developing training data, developing inference data, maintaining data, and creating benchmarks, with many examples from working with\u00a0LLMs.</p><h3>Online experimentation and measurement</h3><p>Online experimentation (e.g., A/B testing) is a common way for organizations like Airbnb to make data-driven decisions. But high variance is frequently a challenge. For example, it\u2019s hard to prove that a change in our search UX will drive value when bookings are infrequent and depend on a large number of interactions over a long period of\u00a0time.</p><p>Our paper <a href=\"https://dl.acm.org/doi/pdf/10.1145/3580305.3599928\">Variance Reduction Using In-Experiment Data: Efficient and Targeted Online Measurement for Sparse and Delayed Outcomes</a> presents two new methods for variance reduction that rely exclusively on in-experiment data:</p><ol><li>A framework for a model-based leading indicator metric that continually estimates progress toward a delayed binary\u00a0outcome.</li><li>A counterfactual treatment exposure index that quantifies the amount a user is impacted by the treatment.</li></ol><p>In testing, both methods achieved a variance reduction of 50% or more. These techniques have greatly improved our experimentation efficiency and\u00a0impact.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*VLJeyMFXLGQAMQ_h\" /></figure><p><em>With more than 50% variance reduction, the new model-based leading indicator metric (listing-view utility, on the right) aligns with the target uncancelled booking metric much better than other indicators such as listing-view with dates (on the\u00a0left).</em></p><p>Another interesting challenge in online experimentation is avoiding interference bias, which can happen when you have competition between your A/B test subjects. Airbnb presented a keynote talk on this topic at KDD\u2019s <a href=\"https://sites.google.com/view/kdd23onlinemarketplaces/home\">2nd Workshop on Decision Intelligence and Analytics for Online Marketplaces</a>. As an example, if you ran an A/B test where group B saw lower booking prices, they might \u201ccannibalize\u201d the bookings from group A. There are two imperfect solutions: clustering (isolating the options for participants) and switchbacks (grouping participants by time intervals).</p><p>Also at the workshop, we presented the paper <a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/CIKM.pdf\">The Price is Right: Removing A/B Test Bias in a Marketplace of Expirable Goods</a>. This discusses the problem of lead-day bias: where items like concert tickets, air travel, and Airbnb bookings vary in price based on the distance from their expiration date. This can wreak havoc on A/B tests, and in the paper we present several mitigation techniques, such as limited rollout, smart overlapping of experiments, and Heterogeneous Treatment Effect (HTE) remixed estimator to correct for bias and accelerate R&amp;D\u00a0process.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*_BreW6LQyQTzs2XZ\" /></figure><p><em>Along with limited rollout and smart overlapping of experiments, HTE-remixed estimator can provide sufficiently robust estimation of the long-term experiment impact from the short-term result and significantly shorten the experiment run-time.</em></p><h3>Causal inference for marketing and user journey optimization</h3><p>In marketing, the million-dollar question is how much should you spend per channel? This can be reframed as a causal inference problem: how many incremental conversions does each channel\u00a0drive?</p><p>When we look at marketing activities across Nielsen\u2019s Designated Marketing Areas (DMAs) we find moderate to strong correlation across channels. This makes it hard to isolate the impact of one channel from another. In fact, when we include the correlated channels in the same regression, the coefficients flip signs for most channels, a clear sign of multicollinearity.</p><p>Existing solutions to multicollinearity, such as shrinkage estimators, principal component analysis, and partial linear regression, are particularly helpful for prediction problems but work less well for our use case where we need to maintain business interpretability while isolating causality. Our approach, described in the paper Hierarchical Clustering as <a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/31.KDD-Paper-Hierarchical-Clustering-As-a-Solution-to-Multicollinearity-\u2013-Marketing-Application-as-an-Example.pdf\">a Novel Solution to Multicollinearity</a>, is to hierarchically cluster DMAs based on their similarity in marketing impressions over time. With such clustering, cross-channel correlation dropped by up to 43% and the channel coefficients no longer flip\u00a0signs.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*xCf2MRTm27kOyaEj\" /></figure><p>Not only does our method provide an intuitive and effective solution to multicollinearity, it also circumvents the need for complex transformation and preserves the interpretability of the data and the results throughout, empowering broad applications to causal inference problems.</p><p>We presented this paper at the new KDD workshop, <a href=\"https://causal-machine-learning.github.io/kdd2023-workshop/\">Causal Inference and Machine Learning in Practice: Use cases for Product, Brand, Policy, and beyond</a>. Airbnb\u2019s Totte Harinen co-organized this workshop, which strongly resonated with KDD\u2019s audience\u200a\u2014\u200ait had 12 papers and four invited talks from 37 authors in 14 institutions.</p><p>In addition, we were invited to present two talks and one poster at KDD\u2019s <a href=\"https://sites.google.com/view/kdd-workshop-2023\">2nd Workshop on End-End Customer Journey Optimization</a>, and joined the workshop\u2019s panel discussion. One of these talks covered CLV (customer lifetime value) modeling. At Airbnb, we want to grow our brand and community by growing all users. Our CLV ecosystem applies two frameworks:</p><ol><li>The value of Airbnb customers. We use traditional ML approaches along with research into more customer-lifecycle-focused architectures (i.e. HMMs). We augment this with demand-supply incrementality modeling to properly account for guest and<em> </em>host contributions to\u00a0value.</li><li>The value growth that Airbnb delivers to customers. By accounting for long-term incremental effects of booking on Airbnb along with incremental contributions from marketing and attribution strategies, we can measure incremental changes in CLV and optimize towards\u00a0them.</li></ol><p>Causal inference can also be applied to search. At the CJ workshop, we presented our paper <a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/CameraReady-7-1.pdf\">Low Inventory State: Identifying Under-Served Queries for Airbnb Search</a>, which explored the problem of searches that return a low number of results. Whether or not that number is \u201ctoo low\u201d and will deter a guest from booking depends on search parameters and intent to book. For a given search query, we can use causal inference to determine the incremental effect of an additional result on the probability of booking. Our model outperforms non-causal methods and can assist with supply management as\u00a0well.</p><p>Finally, our poster discussed how we measure the effects of national TV advertising campaigns. We analyzed TV exposure data and demographic data with data on Airbnb onsite behavior using a third-party identity graph. We were able to resolve disparate datasets to a unique identifier and model individual households.</p><p>We use propensity score matching to estimate TV effects, and then scale these estimates to a nationally-representative population. We leverage this data to provide tactical insights for marketing and understand how long TV effects take to\u00a0decay.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/523/1*2550R2exF5NwZquO26vY9A.png\" /></figure><p>The plot above (from simulated study for illustration) shows the results of an analysis for a TV campaign from August\u200a\u2014\u200aOctober. We can see that the TV campaign was effective at increasing bookings for households that saw an Airbnb TV ad and was more effective for one subgroup (red line) than the other subgroup.</p><h3>Data science and analytics infra</h3><p>How can you achieve science at scale in a medium-to-large engineering organization? At the KDD\u2019s <a href=\"https://wamlm-kdd.github.io/wamlm/index.html\">2nd Workshop on Applied Machine Learning Management</a>, we shared Airbnb\u2019s solution for data science reproducibility and reuse, <a href=\"https://wamlm-kdd.github.io/wamlm/papers/wamlm-kdd23_paper_Daniel_Miller.pdf\">Onebrain</a>. The core of Onebrain is a coding standard for configuring data science projects entirely in YAML. Onebrain\u2019s backend abstracts away CI/CD, configuration/dependency management, and command-line parsing. Since it\u2019s \u201cjust code,\u201d Onebrain projects can be checked into a version-controlled repo, and any repo can be a Onebrain\u00a0repo.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Y0TXGcnp4lz40NVn\" /></figure><p>User interaction with Onebrain happens through a CLI. With a single command, anyone can use an existing project as a template for their own work, or generate a one-click URL to spin up a server and run the project. Usage is growing fast with over 200 distinct projects and over 500 users at Airbnb within just a\u00a0year.</p><p>While most of our research focuses on high-order data use-cases like models, data capture is essential as it\u2019s the starting point for any analysis. Event logging libraries typically capture <em>actions on</em> and <em>impressions of</em> app components (buttons, sections, pages). But with this level of granularity, it can be difficult to abstract out user behavior, measure the total time spent on a surface, or understand the context surrounding an\u00a0action.</p><p>At the <a href=\"https://sites.google.com/view/kdd-workshop-2023\">2nd Workshop on End-End Customer Journey Optimization</a>, we spoke about a new type of client-side event called Sessions. Part of Airbnb\u2019s client-side logging solution, Sessions provide a way to track user context and behaviors within the Airbnb product. Unlike traditional time-based sessions used in web analytics, these Sessions can be tied to various aspects of the Airbnb user experience. For example, they can be tied to specific surfaces like the checkout page, API calls used for observability, or even internal states of the app that abstract away complex UI components. The flexibility of Sessions allows us to capture a wide range of user interactions and better understand their journey throughout our platform.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/941/0*W0F1AhzPituZ1bfF\" /></figure><h3>Conclusion</h3><p>KDD is an amazing opportunity for data scientists from around the world, and across industry and academia, to come together and exchange learnings and discoveries. We were honored to be invited to share techniques we\u2019ve developed through applied research at Airbnb. The strategies and insights we presented at KDD have been essential to improving Airbnb\u2019s platform, business, and user experience. We\u2019re constantly motivated by innovations happening around us, and we\u2019re thrilled to give back to the community and eager to see what kinds of new applications and advancements may come about as a\u00a0result.</p><p>At the bottom of the page, you\u2019ll find a complete list of the talks and papers shared in this article along with the team members who contributed. If you can see yourself on our team, we encourage you to apply for an<a href=\"https://careers.airbnb.com/\"> open position</a>\u00a0today.</p><h3>List of papers and\u00a0talks</h3><p><strong>Optimizing Airbnb Search Journey with Multi-task Learning\u00a0[</strong><a href=\"https://arxiv.org/abs/2305.18431\"><strong>link</strong></a><strong>]</strong></p><p>Authors: <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tan,+C+H\">Chun How Tan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chan,+A\">Austin Chan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Haldar,+M\">Malay Haldar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tang,+J\">Jie Tang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+X\">Xin Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Abdool,+M\">Mustafa Abdool</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gao,+H\">Huiji Gao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+L\">Liwei He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Katariya,+S\">Sanjeev\u00a0Katariya</a></p><p><strong>Variance Reduction Using In-Experiment Data: Efficient and Targeted Online Measurement for Sparse and Delayed Outcomes\u00a0[</strong><a href=\"https://alexdeng.github.io/public/files/kdd2023-inexp.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Authors: Alex Deng, Michelle Du, Anna Matlin, Qing\u00a0Zhang</p><p><strong>Beyond the Simple A/B test: Mitigating Interference Bias at\u00a0Airbnb</strong></p><p>Speaker: Ruben\u00a0Lobel</p><p><strong>The Price is Right: Removing A/B Test Bias in a Marketplace of Expirable Goods\u00a0[</strong><a href=\"https://alexdeng.github.io/public/files/Smart_Pricing_CIKM.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Author: Thu Le, Alex\u00a0Deng</p><p><strong>Unveiling the Guest &amp; Host Journey: Session-Based Instrumentation on Airbnb\u00a0Platform</strong></p><p>Speaker: Shant\u00a0Torosean</p><p><strong>Devoted to Long-Term Adventure: Growing Airbnb Through Measuring Customer Lifetime\u00a0Value</strong></p><p>Speaker: Sean O\u2019Donell, Jason Cai, Linsha\u00a0Chen</p><p><strong>Low Inventory State: Identifying Under-Served Queries for Airbnb Search\u00a0[</strong><a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/CameraReady-7-1.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Author: Toma Gulea, Bradley\u00a0Turnbull</p><p><strong>Measuring TV Campaigns at\u00a0Airbnb</strong></p><p>Speaker: Adam Maidman, Sam\u00a0Barrows</p><p><strong>Tutorial: Data-Centric AI\u00a0[</strong><a href=\"https://dcaitutorial.github.io/index.html\"><strong>link</strong></a><strong>]</strong></p><p>Presenter: Daochen Zha, Huiji\u00a0Gao</p><p><strong>Hierarchical Clustering As a Novel Solution to the Notorious: Multicollinearity Problem in Observational Causal Inference [</strong><a href=\"https://airbnb.tech/wp-content/uploads/sites/19/2023/12/31.KDD-Paper-Hierarchical-Clustering-As-a-Solution-to-Multicollinearity-\u2013-Marketing-Application-as-an-Example.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Authors: Yufei Wu, Zhiying Gu, Alex Deng, Jacob Zhu, Linsha\u00a0Chen</p><p><a href=\"https://wamlm-kdd.github.io/wamlm/papers/wamlm-kdd23_paper_Daniel_Miller.pdf\"><strong>Onebrain\u200a\u2014\u200aMicroprojects for Data Science</strong></a><strong>\u00a0[</strong><a href=\"https://wamlm-kdd.github.io/wamlm/papers/wamlm-kdd23_paper_Daniel_Miller.pdf\"><strong>link</strong></a><strong>]</strong></p><p>Authors: Daniel Miller, Alex Deng, Narek Amirbekian, Navin Sivanandam, Rodolfo\u00a0Carboni</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9084ad244d8c\" width=\"1\" /><hr /><p><a href=\"https://medium.com/airbnb-engineering/airbnb-at-kdd-2023-9084ad244d8c\">Airbnb at KDD 2023</a> was originally published in <a href=\"https://medium.com/airbnb-engineering\">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Microsoft Python Engineering": {
    "title": "Data Science Day Announcement and Call for Speaker Proposals",
    "xmlUrl": "http://blogs.msdn.microsoft.com/pythonengineering/feed/",
    "htmlUrl": "https://blogs.msdn.microsoft.com/pythonengineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://devblogs.microsoft.com/python/feed/",
      "value": "Data Science Day Announcement and Call for Speaker Proposals"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://devblogs.microsoft.com/python/python-data-science-day/"
      }
    ],
    "link": "https://devblogs.microsoft.com/python/python-data-science-day/",
    "comments": "https://devblogs.microsoft.com/python/python-data-science-day/#respond",
    "authors": [
      {
        "name": "Dawn Wages"
      }
    ],
    "author": "Dawn Wages",
    "author_detail": {
      "name": "Dawn Wages"
    },
    "published": "Sat, 13 Jan 2024 00:00:13 +0000",
    "published_parsed": [
      2024,
      1,
      13,
      0,
      0,
      13,
      5,
      13,
      0
    ],
    "tags": [
      {
        "term": "Python",
        "scheme": null,
        "label": null
      },
      {
        "term": "python",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://devblogs.microsoft.com/python/?p=9562",
    "guidislink": false,
    "summary": "<p>Python Data Science Day is a full day of 25 min and 5 min community contributed content March 14th, 2024 streaming on the VS Code YouTube channel. Submission deadline is January 25th AOE (Anywhere on Earth).</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/python/python-data-science-day/\">Data Science Day Announcement and Call for Speaker Proposals</a> appeared first on <a href=\"https://devblogs.microsoft.com/python\">Python</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://devblogs.microsoft.com/python/feed/",
      "value": "<p>Python Data Science Day is a full day of 25 min and 5 min community contributed content March 14th, 2024 streaming on the VS Code YouTube channel. Submission deadline is January 25th AOE (Anywhere on Earth).</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/python/python-data-science-day/\">Data Science Day Announcement and Call for Speaker Proposals</a> appeared first on <a href=\"https://devblogs.microsoft.com/python\">Python</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://devblogs.microsoft.com/python/feed/",
        "value": "<p>We are thrilled to announce Python Data Science Day will be taking place <strong>March 14th, 2024</strong>; a &#8220;PyDay&#8221; on Pi Day: 3.14 <img alt=\"\ud83e\udd67\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/1f967.png\" style=\"height: 1em;\" />. If you&#8217;re a Python developer, entrepreneur, data scientist, student, or researcher working on projects from hobbyist and start up to enterprise level, you&#8217;ll find solutions to modernize your data pipelines and answer complex queries with data.</p>\n<h2 id=\"were-looking-forward-to-your-content-submission\">We&#8217;re looking forward to your content submission!</h2>\n<p><a href=\"https://aka.ms/Python/DataScienceDay/CFP\">Submit a session or a lightning talk</a> proposal to join the list of amazing speakers for Data Science Day. The <strong>CFP opened January 11th, 2024</strong> and <strong>closes January 25th, 2024 AOE (Anywhere on Earth)</strong>. Full schedule will be announced early mid February.</p>\n<p>There are two types of submissions:</p>\n<ul>\n<li><img alt=\"\ud83d\udde3\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/1f5e3.png\" style=\"height: 1em;\" /><strong>Session (25 minutes, pre-recorded or live)</strong>\nSessions are delivered by no more than two people and can cover high level programming topics. Many times these talks are accompanied by slides, demonstrations or blog posts. This could cover a programming story, how it was approached and the solution; or it could dive deeper into a particular topic or using a suite of features.</li>\n<li><img alt=\"\u26a1\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/26a1.png\" style=\"height: 1em;\" /><strong>Lightning Talk (5 to 7 minutes, pre-recorded)</strong>\nA Lightning talk is a very short presentation. It is a great introduction to public speaking or a great way to present something short and sweet. These talks typically prioritize a singular idea in a digestible way that inspires further learning.</li>\n</ul>\n<p><strong>Good submissions will&#8230;</strong></p>\n<ul>\n<li>discuss a <img alt=\"\ud83d\udd25\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/1f525.png\" style=\"height: 1em;\" />hot or <img alt=\"\ud83e\uddca\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/1f9ca.png\" style=\"height: 1em;\" /> cool tool, product, or skill.</li>\n<li>include accessible content with slides, Notebook, repository, tutorial, or blog post.</li>\n<li>create a thoughtful, cohesive story for a Data Science audience.</li>\n</ul>\n<h2 id=\"special-guest-speakers-on-data-science-day\">Special Guest Speakers on Data Science Day</h2>\n<p>You could be among the speakers on Python Data Science Day.</p>\n<table style=\"width: 97.6341%; height: 240px;\">\n<thead>\n<tr style=\"height: 28px;\">\n<th style=\"height: 28px; text-align: center;\">Sarah Kaiser, PhD</th>\n<th style=\"height: 28px; text-align: center;\">Soojin Choi</th>\n<th style=\"height: 28px; text-align: center;\">You!</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"height: 28px;\">\n<td style=\"height: 28px;\"><a href=\"https://devblogs.microsoft.com/python/wp-content/uploads/sites/12/2024/01/SarahKaiserCircle.jpg\"><img alt=\"Image SarahKaiserCircle\" class=\"alignnone size-medium wp-image-9567\" height=\"300\" src=\"https://devblogs.microsoft.com/python/wp-content/uploads/sites/12/2024/01/SarahKaiserCircle-300x300.jpg\" width=\"300\" /></a></td>\n<td style=\"height: 28px;\"><a href=\"https://devblogs.microsoft.com/python/wp-content/uploads/sites/12/2024/01/SoojinChoiCircle.jpg\"><img alt=\"Image SoojinChoiCircle\" class=\"alignnone size-medium wp-image-9565\" height=\"300\" src=\"https://devblogs.microsoft.com/python/wp-content/uploads/sites/12/2024/01/SoojinChoiCircle-300x300.jpg\" width=\"300\" /></a></td>\n<td style=\"height: 28px;\"><a href=\"https://devblogs.microsoft.com/python/wp-content/uploads/sites/12/2024/01/DefaultAvatarCircle.jpg\"><img alt=\"Image DefaultAvatarCircle\" class=\"alignnone size-medium wp-image-9566\" height=\"298\" src=\"https://devblogs.microsoft.com/python/wp-content/uploads/sites/12/2024/01/DefaultAvatarCircle-300x298.jpg\" width=\"300\" /></a></td>\n</tr>\n<tr style=\"height: 28px;\">\n<td style=\"height: 28px; text-align: center;\">Python Cloud Developer Advocate</td>\n<td style=\"height: 28px; text-align: center;\">Jupyter Notebook Product Manager</td>\n<td style=\"height: 28px; text-align: center;\">Speaker at Python Data Science Day</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"\"></h1>\n<h1 id=\"submit-your-cfp\"><a href=\"https://aka.ms/Python/DataScienceDay/CFP\">Submit your CFP</a></h1>\n<p>&nbsp;</p>\n<h2 id=\"more-ways-to-engage-with-all-the-data-science-fun\">More ways to engage with all the Data Science fun:</h2>\n<ul>\n<li>Join the <a href=\"https://blog.fabric.microsoft.com/blog/hack-together-the-microsoft-fabric-global-ai-hack/\">Microsoft Fabric Global AI Hack Together</a> on <strong>February 15th to March 4th, 2024</strong>. Fabric is an end-to-end AI-powered analytics platform that unites your data and services, including data science and data lakes. Register for the event to participate in live streams every week and solve real-world problems with guidance and a community.</li>\n<li>Read our 14 Days of Python Data Science series where for fourteen days leading up to Python Data Science Day, we will drop cool articles and recipes for using Data Science on Microsoft tools. Link coming soon!</li>\n<li>Check out the <a href=\"https://aka.ms/python/DataScienceDay/CSC\">Data Science Cloud Skills Challenge</a> if you want to go through some self-paced learning! This challenge is active until <strong>April 15th, 2024</strong>.</li>\n<li>Join us on Discord at <a href=\"https://aka.ms/python-discord\">https://aka.ms/python-discord</a></li>\n</ul>\n<h3 id=\"more-data-science-at-microsoft\">More Data Science at Microsoft&#8230;</h3>\n<ul>\n<li><a href=\"https://learn.microsoft.com/credentials/certifications/roles/data-scientist\">Data Scientist Certifications</a></li>\n<li><a href=\"https://learn.microsoft.com/training/career-paths/data-scientist\">Data Scientist Training Path</a></li>\n<li><a href=\"https://github.com/microsoft/Data-Science-For-Beginners\">Data Science for Beginners &#8211; GitHub Repo</a></li>\n</ul>\n<p>The post <a href=\"https://devblogs.microsoft.com/python/python-data-science-day/\">Data Science Day Announcement and Call for Speaker Proposals</a> appeared first on <a href=\"https://devblogs.microsoft.com/python\">Python</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://devblogs.microsoft.com/python/python-data-science-day/feed/",
    "slash_comments": "0"
  },
  "ThoughtWorks": {
    "title": "Tackling the challenges of using event-driven architecture in a billing system",
    "xmlUrl": "https://www.thoughtworks.com/rss/insights.xml",
    "htmlUrl": "https://www.thoughtworks.com/insights",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.thoughtworks.com/rss/insights.xml",
      "value": "Tackling the challenges of using event-driven architecture in a billing system"
    },
    "published": "Fri Jan 12 00:00:00 UTC 2024",
    "published_parsed": [
      2024,
      1,
      12,
      0,
      0,
      0,
      4,
      12,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.thoughtworks.com/insights/blog/architecture/tackling-the-challenges-of-using-event-driven-architecture-in-a-billing-system"
      }
    ],
    "link": "https://www.thoughtworks.com/insights/blog/architecture/tackling-the-challenges-of-using-event-driven-architecture-in-a-billing-system",
    "authors": [
      {
        "name": "Hongxing Chen"
      }
    ],
    "author": "Hongxing Chen",
    "author_detail": {
      "name": "Hongxing Chen"
    },
    "summary": "<div><img class=\"type:primaryImage webfeedsFeaturedVisual\" src=\"https://www.thoughtworks.com/content/dam/thoughtworks/images/photography/abstract/insights/blog/abs_blogs_045.jpg\" /></div><p>Tackling the challenges of using event-driven architecture in a billing system</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.thoughtworks.com/rss/insights.xml",
      "value": "<div><img class=\"type:primaryImage webfeedsFeaturedVisual\" src=\"https://www.thoughtworks.com/content/dam/thoughtworks/images/photography/abstract/insights/blog/abs_blogs_045.jpg\" /></div><p>Tackling the challenges of using event-driven architecture in a billing system</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.thoughtworks.com/rss/insights.xml",
        "value": "<div><img class=\"type:primaryImage webfeedsFeaturedVisual\" src=\"https://www.thoughtworks.com/content/dam/thoughtworks/images/photography/abstract/insights/blog/abs_blogs_045.jpg\" /></div><p>Tackling the challenges of using event-driven architecture in a billing system</p>"
      }
    ],
    "id": "https://www.thoughtworks.com/insights/blog/architecture/tackling-the-challenges-of-using-event-driven-architecture-in-a-billing-system",
    "guidislink": false
  },
  "Facebook AI Research": {
    "title": "How Meta is advancing GenAI",
    "xmlUrl": "https://engineering.fb.com/feed/",
    "htmlUrl": "https://engineering.fb.com/category/ai-research/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.fb.com/feed/",
      "value": "How Meta is advancing GenAI"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/"
      }
    ],
    "link": "https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/",
    "authors": [
      {}
    ],
    "author": "",
    "published": "Thu, 11 Jan 2024 17:00:17 +0000",
    "published_parsed": [
      2024,
      1,
      11,
      17,
      0,
      17,
      3,
      11,
      0
    ],
    "tags": [
      {
        "term": "AI Research",
        "scheme": null,
        "label": null
      },
      {
        "term": "ML Applications",
        "scheme": null,
        "label": null
      },
      {
        "term": "meta tech podcast",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.fb.com/?p=20873",
    "guidislink": false,
    "summary": "<p>What\u2019s going on with generative AI (GenAI) at Meta? And what does the future have in store? In this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (@passy) speaks with\u00a0Devi Parikh, an AI research director at Meta.\u00a0They cover a wide range of topics, including the history and future of GenAI and the most [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\">Read More...</a></p>\n<p>The post <a href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\" rel=\"nofollow\">How Meta is advancing GenAI</a> appeared first on <a href=\"https://engineering.fb.com\" rel=\"nofollow\">Engineering at Meta</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.fb.com/feed/",
      "value": "<p>What\u2019s going on with generative AI (GenAI) at Meta? And what does the future have in store? In this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (@passy) speaks with\u00a0Devi Parikh, an AI research director at Meta.\u00a0They cover a wide range of topics, including the history and future of GenAI and the most [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\">Read More...</a></p>\n<p>The post <a href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\" rel=\"nofollow\">How Meta is advancing GenAI</a> appeared first on <a href=\"https://engineering.fb.com\" rel=\"nofollow\">Engineering at Meta</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.fb.com/feed/",
        "value": "<p>What\u2019s going on with generative AI (GenAI) at Meta? And what does the future have in store?</p>\n<p>In this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (<a href=\"https://www.threads.net/@passy_\">@passy</a>) speaks with\u00a0Devi Parikh, an AI research director at Meta.\u00a0They cover a wide range of topics, including the history and future of GenAI and the most interesting research papers that have come out recently.</p>\n<p>And, of course, they discuss some of Meta\u2019s latest GenAI innovations, including:</p>\n<ul>\n<li><a href=\"https://ai.meta.com/blog/audiobox-generating-audio-voice-natural-language-prompts/\" rel=\"noopener\" target=\"_blank\">Audiobox</a>, a foundational model for generating sound and soundscapes using natural language prompts.</li>\n<li><a href=\"https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/\" rel=\"noopener\" target=\"_blank\">Emu</a>, Meta\u2019s first foundational model for image generation.</li>\n<li><a href=\"https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/\" rel=\"noopener\" target=\"_blank\">Purple Llama</a>, a suite of tools to help developers safely and responsibly deploy GenAI models.</li>\n</ul>\n<p>Download or listen to the episode below:</p>\n<p></p>\n<p>You can also find the episode on various podcast platforms:</p>\n<p><a href=\"https://open.spotify.com/episode/417ZV5wibSU7rJYOofFANB\" rel=\"noopener\" target=\"_blank\">Spotify</a><br />\n<a href=\"https://pca.st/ot14urbh\" rel=\"noopener\" target=\"_blank\">PocketCasts</a><br />\n<a href=\"https://podcasts.apple.com/gb/podcast/advancing-genai-at-meta/id1370910331?i=1000639340717\" rel=\"noopener\" target=\"_blank\">Apple Podcasts</a><br />\n<a href=\"https://podcasts.google.com/feed/aHR0cHM6Ly9pbnNpZGVmYWNlYm9va21vYmlsZS5saWJzeW4uY29tL3Jzcw/episode/OGNiMTMwOTktYWY2Ny00YzkxLTgxNDgtMjZiMWM0OGQ1MWYx?sa=X&amp;ved=0CAgQuIEEahcKEwiA9NbNvL6DAxUAAAAAHQAAAAAQLA\" rel=\"noopener\" target=\"_blank\">Google\u00a0Podcasts</a></p>\n<p>The\u00a0<a href=\"https://insidefacebookmobile.libsyn.com/\" rel=\"noopener\" target=\"_blank\">Meta Tech Podcast</a>\u00a0is a podcast, brought to you by Meta, where we highlight the work Meta\u2019s engineers are doing at every level \u2013 from low-level frameworks to end-user features.</p>\n<p>Send us feedback on <a href=\"https://instagram.com/metatechpod\" rel=\"noopener\" target=\"_blank\">Instagram</a>, <a href=\"https://threads.net/@metatechpod\" rel=\"noopener\" target=\"_blank\">Threads</a>, or <a href=\"https://twitter.com/metatechpod\" rel=\"noopener\" target=\"_blank\">X</a>.</p>\n<p>And if you\u2019re interested in AI career opportunities at Meta visit the <a href=\"https://www.metacareers.com/\" rel=\"noopener\" target=\"_blank\">Meta Careers</a> page.</p>\n<p>The post <a href=\"https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/\" rel=\"nofollow\">How Meta is advancing GenAI</a> appeared first on <a href=\"https://engineering.fb.com\" rel=\"nofollow\">Engineering at Meta</a>.</p>"
      }
    ],
    "post-id": "20873"
  },
  "CSC - IT Center For Science - Cloud Team": {
    "title": "Docker Hub pull rate limits hit Rahti",
    "xmlUrl": "https://cloud.blog.csc.fi/feeds/posts/default",
    "htmlUrl": "https://cloud.blog.csc.fi/",
    "id": "tag:blogger.com,1999:blog-7868115878795534619.post-2057642436871017198",
    "guidislink": true,
    "link": "https://cloud.blog.csc.fi/2021/03/docker-hub-pull-rate-limits-hit-rahti.html",
    "published": "2021-03-04T00:59:00.000-08:00",
    "published_parsed": [
      2021,
      3,
      4,
      8,
      59,
      0,
      3,
      63,
      0
    ],
    "updated": "2021-03-04T00:59:41.816-08:00",
    "updated_parsed": [
      2021,
      3,
      4,
      8,
      59,
      41,
      3,
      63,
      0
    ],
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://cloud.blog.csc.fi/feeds/posts/default",
      "value": "Docker Hub pull rate limits hit Rahti"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://cloud.blog.csc.fi/feeds/posts/default",
        "value": "November 2020 was an eventful month for Rahti. Our backend storage had incident that affected our production clusters image repository for many weeks. That event is well described in <a href=\"https://cloud.blog.csc.fi/2020/12/allas-november-2020-incident-details.html\">Allas downtime November 2020 - technical deep-dive</a>.<br /><br />Just before our storage incident, 2nd of November, Docker applied<i> \"rate limiting for Docker container pulls for some users\"</i>. When we tried to prepare for this in advance, it was very hard to figure out what the exact effect would be for Rahti. It took longer to resolve than we anticipated.<br /><h2 style=\"text-align: left;\">Limits began</h2>We were relieved that the first day after pull rates were enforced was peaceful. Rahti was still up and running as it should. Users didn't complain about failing deployment in large amounts. Admins survived another upstream change.<br /><br />Eventually we received few tickets on failing builds. Our first approach was to instruct people to change their images away from Docker Hub to alternative repositories which do not have rate limiting enabled. Some users were able to migrate their images but this was not feasible solution for everyone. Still, it was a good opportunity to remind users to check what images they use.<br /><br />The error looks like this:<br /><br /><span style=\"font-family: courier;\">Pulling image \"docker.io/centos/python-38-centos7@sha256:da83741689a8d7fe1548fefe7e001c45bcc56a08bc03fd3b29a5636163ca0353\" ...<br />pulling image error : toomanyrequests: You have reached your pull rate limit. You may increase the limit by authenticating and upgrading: https://www.docker.com/increase-rate-limit</span><br /><h2 style=\"text-align: left;\">Cumulative issues cause exponential grief</h2>We gave our users instructions how to move their dependencies from public Docker Hub to Rahti image registry, <a href=\"https://docs.csc.fi/cloud/rahti/tutorials/docker_hub_manual_caching/\">How to manually cache images in Rahti's registry</a>. This was harder in practice, as we did have issues with our own registry due to our storage incident. There were days when users suffered from both Docker Hub and Rahti internal registry availability. Those days were hard for our Rahti admins, who struggled to meet customer expectations of highly available services.<br /><br />After our storage incident was resolved, using images from internal registry was again feasible and reliable alternative to public Docker registry.<br /><h2 style=\"text-align: left;\">Project-specific credentials</h2>Another approach we tried was to use project-specific credentials. We wrote a guide on it; <a href=\"https://docs.csc.fi/cloud/rahti/tutorials/docker_hub_login/\">How to add docker hub credentials to a project</a>.<br /><br />This method got mixed results. Some users were able to pull images and others complained they still got `toomanyrequests` errors. We never got the instructions fully working for all users (is this even possible in complex systems?). There are still some unknown image magic in OpenShift builds we haven't found yet. In any case, we now have instructions how to apply custom image credentials if users want to pull images from private repositories.<br /><h2 style=\"text-align: left;\">Should we buy Docker subscription?</h2>The root of this pull rate limiting issue is Docker used to provide free services for many many years and their usage has probably increased a lot over the years. We understand they must had pressure to change their free model and guide their users towards paid subscriptions.<br /><br />We did contact Docker sales to pursue better understanding of our choices. Thanks to their helpful salesperson, we got alternatives. We could either buy `Team` or `Large` subscription.<br /><br />Large subscription price was so high we would have to ask budget for it, so we decided to do some testing with Team subscription.<br /><h2 style=\"text-align: left;\">OpenShift cluster configuration</h2>Cluster-wide credentials/tokens can be applied during installation by setting variable `openshift_additional_registry_credentials`. We used this same approach to apply changes to our existing development clusters and verified they worked.<br /><h2 style=\"text-align: left;\">Rolling out changes</h2>Shared default credentials were tested in our development environment for a while until we were confident enough that they were stable and reliable. In February 2021 they were rolled out to production environments and you Rahti users can finally pull container images from Docker Hub without limits.<br /><h2 style=\"text-align: left;\">Afterthoughts</h2>These Docker Hub issues were hard to solve. Now that the core components of container cluster is stable again, we can look forward to develop our platform further.<br /><br />I believe the changes Docker made to their service policies mark some kind of change in container maturity. They sent a signal that it's no longer okay to use public images without limits. This may not change the behavior of small actors but having a limit forces larger operators to think their image usage. All users who use container images in \"production\" should review what containers they use.<br /><br />We hope Rahti users will be able to leverage our platform to enable their vision and solve their selected problems. For that we need the ability to pull images without daily limits. Rahti could also be the first container platform for students who use our services. We feel it's our duty to make that introduction to containers as smooth as possible. We hope you appreciate our efforts. Now go and use Rahti and create something amazing.<br /><br />"
      }
    ],
    "summary": "November 2020 was an eventful month for Rahti. Our backend storage had incident that affected our production clusters image repository for many weeks. That event is well described in <a href=\"https://cloud.blog.csc.fi/2020/12/allas-november-2020-incident-details.html\">Allas downtime November 2020 - technical deep-dive</a>.<br /><br />Just before our storage incident, 2nd of November, Docker applied<i> \"rate limiting for Docker container pulls for some users\"</i>. When we tried to prepare for this in advance, it was very hard to figure out what the exact effect would be for Rahti. It took longer to resolve than we anticipated.<br /><h2 style=\"text-align: left;\">Limits began</h2>We were relieved that the first day after pull rates were enforced was peaceful. Rahti was still up and running as it should. Users didn't complain about failing deployment in large amounts. Admins survived another upstream change.<br /><br />Eventually we received few tickets on failing builds. Our first approach was to instruct people to change their images away from Docker Hub to alternative repositories which do not have rate limiting enabled. Some users were able to migrate their images but this was not feasible solution for everyone. Still, it was a good opportunity to remind users to check what images they use.<br /><br />The error looks like this:<br /><br /><span style=\"font-family: courier;\">Pulling image \"docker.io/centos/python-38-centos7@sha256:da83741689a8d7fe1548fefe7e001c45bcc56a08bc03fd3b29a5636163ca0353\" ...<br />pulling image error : toomanyrequests: You have reached your pull rate limit. You may increase the limit by authenticating and upgrading: https://www.docker.com/increase-rate-limit</span><br /><h2 style=\"text-align: left;\">Cumulative issues cause exponential grief</h2>We gave our users instructions how to move their dependencies from public Docker Hub to Rahti image registry, <a href=\"https://docs.csc.fi/cloud/rahti/tutorials/docker_hub_manual_caching/\">How to manually cache images in Rahti's registry</a>. This was harder in practice, as we did have issues with our own registry due to our storage incident. There were days when users suffered from both Docker Hub and Rahti internal registry availability. Those days were hard for our Rahti admins, who struggled to meet customer expectations of highly available services.<br /><br />After our storage incident was resolved, using images from internal registry was again feasible and reliable alternative to public Docker registry.<br /><h2 style=\"text-align: left;\">Project-specific credentials</h2>Another approach we tried was to use project-specific credentials. We wrote a guide on it; <a href=\"https://docs.csc.fi/cloud/rahti/tutorials/docker_hub_login/\">How to add docker hub credentials to a project</a>.<br /><br />This method got mixed results. Some users were able to pull images and others complained they still got `toomanyrequests` errors. We never got the instructions fully working for all users (is this even possible in complex systems?). There are still some unknown image magic in OpenShift builds we haven't found yet. In any case, we now have instructions how to apply custom image credentials if users want to pull images from private repositories.<br /><h2 style=\"text-align: left;\">Should we buy Docker subscription?</h2>The root of this pull rate limiting issue is Docker used to provide free services for many many years and their usage has probably increased a lot over the years. We understand they must had pressure to change their free model and guide their users towards paid subscriptions.<br /><br />We did contact Docker sales to pursue better understanding of our choices. Thanks to their helpful salesperson, we got alternatives. We could either buy `Team` or `Large` subscription.<br /><br />Large subscription price was so high we would have to ask budget for it, so we decided to do some testing with Team subscription.<br /><h2 style=\"text-align: left;\">OpenShift cluster configuration</h2>Cluster-wide credentials/tokens can be applied during installation by setting variable `openshift_additional_registry_credentials`. We used this same approach to apply changes to our existing development clusters and verified they worked.<br /><h2 style=\"text-align: left;\">Rolling out changes</h2>Shared default credentials were tested in our development environment for a while until we were confident enough that they were stable and reliable. In February 2021 they were rolled out to production environments and you Rahti users can finally pull container images from Docker Hub without limits.<br /><h2 style=\"text-align: left;\">Afterthoughts</h2>These Docker Hub issues were hard to solve. Now that the core components of container cluster is stable again, we can look forward to develop our platform further.<br /><br />I believe the changes Docker made to their service policies mark some kind of change in container maturity. They sent a signal that it's no longer okay to use public images without limits. This may not change the behavior of small actors but having a limit forces larger operators to think their image usage. All users who use container images in \"production\" should review what containers they use.<br /><br />We hope Rahti users will be able to leverage our platform to enable their vision and solve their selected problems. For that we need the ability to pull images without daily limits. Rahti could also be the first container platform for students who use our services. We feel it's our duty to make that introduction to containers as smooth as possible. We hope you appreciate our efforts. Now go and use Rahti and create something amazing.<br /><br />",
    "links": [
      {
        "rel": "replies",
        "type": "application/atom+xml",
        "href": "https://cloud.blog.csc.fi/feeds/2057642436871017198/comments/default",
        "title": "Post Comments"
      },
      {
        "rel": "replies",
        "type": "text/html",
        "href": "https://cloud.blog.csc.fi/2021/03/docker-hub-pull-rate-limits-hit-rahti.html#comment-form",
        "title": "0 Comments"
      },
      {
        "rel": "edit",
        "type": "application/atom+xml",
        "href": "https://www.blogger.com/feeds/7868115878795534619/posts/default/2057642436871017198"
      },
      {
        "rel": "self",
        "type": "application/atom+xml",
        "href": "https://www.blogger.com/feeds/7868115878795534619/posts/default/2057642436871017198"
      },
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://cloud.blog.csc.fi/2021/03/docker-hub-pull-rate-limits-hit-rahti.html",
        "title": "Docker Hub pull rate limits hit Rahti"
      }
    ],
    "authors": [
      {
        "name": "Teemu F",
        "href": "http://www.blogger.com/profile/08415525450363605760",
        "email": "noreply@blogger.com"
      }
    ],
    "author_detail": {
      "name": "Teemu F",
      "href": "http://www.blogger.com/profile/08415525450363605760",
      "email": "noreply@blogger.com"
    },
    "href": "http://www.blogger.com/profile/08415525450363605760",
    "author": "Teemu F (noreply@blogger.com)",
    "gd_image": {
      "rel": "http://schemas.google.com/g/2005#thumbnail",
      "width": "16",
      "height": "16",
      "src": "https://img1.blogblog.com/img/b16-rounded.gif"
    },
    "thr_total": "0"
  },
  "Khan Academy": {
    "title": "Our Transition to React Native",
    "xmlUrl": "http://engineering.khanacademy.org/rss.xml",
    "htmlUrl": "http://engineering.khanacademy.org",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.khanacademy.org/rss.xml",
      "value": "Our Transition to React Native"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "http://engineering.khanacademy.org/posts/react-native-at-khan.htm"
      }
    ],
    "link": "http://engineering.khanacademy.org/posts/react-native-at-khan.htm",
    "published": "Thu, 09 Jul 2020 11:00:00 GMT-8",
    "published_parsed": null,
    "id": "http://engineering.khanacademy.org/posts/react-native-at-khan.htm",
    "guidislink": false
  },
  "AWS": {
    "title": "Amazon ECS supports a native integration with Amazon EBS volumes for data-intensive workloads",
    "xmlUrl": "https://aws.amazon.com/blogs/aws/feed/",
    "htmlUrl": "https://aws.amazon.com/blogs/aws/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://aws.amazon.com/blogs/aws/feed/",
      "value": "Amazon ECS supports a native integration with Amazon EBS volumes for data-intensive workloads"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://aws.amazon.com/blogs/aws/amazon-ecs-supports-a-native-integration-with-amazon-ebs-volumes-for-data-intensive-workloads/"
      }
    ],
    "link": "https://aws.amazon.com/blogs/aws/amazon-ecs-supports-a-native-integration-with-amazon-ebs-volumes-for-data-intensive-workloads/",
    "authors": [
      {
        "name": "Channy Yun"
      }
    ],
    "author": "Channy Yun",
    "author_detail": {
      "name": "Channy Yun"
    },
    "published": "Thu, 11 Jan 2024 22:36:13 +0000",
    "published_parsed": [
      2024,
      1,
      11,
      22,
      36,
      13,
      3,
      11,
      0
    ],
    "tags": [
      {
        "term": "Amazon Elastic Block Store (Amazon EBS)",
        "scheme": null,
        "label": null
      },
      {
        "term": "Amazon Elastic Container Service",
        "scheme": null,
        "label": null
      },
      {
        "term": "Compute",
        "scheme": null,
        "label": null
      },
      {
        "term": "Launch",
        "scheme": null,
        "label": null
      },
      {
        "term": "News",
        "scheme": null,
        "label": null
      },
      {
        "term": "Storage",
        "scheme": null,
        "label": null
      }
    ],
    "id": "aa651b9a68332fa0b11be808f87f4175a6e2ddba",
    "guidislink": false,
    "summary": "Today we are announcing that Amazon Elastic Container Service (Amazon ECS) supports an integration with Amazon Elastic Block Store (Amazon EBS), making it easier to run a wider range of data processing workloads. You can provision Amazon EBS storage for your ECS tasks running on AWS Fargate and Amazon Elastic Compute Cloud (Amazon EC2) without [\u2026]",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://aws.amazon.com/blogs/aws/feed/",
      "value": "Today we are announcing that Amazon Elastic Container Service (Amazon ECS) supports an integration with Amazon Elastic Block Store (Amazon EBS), making it easier to run a wider range of data processing workloads. You can provision Amazon EBS storage for your ECS tasks running on AWS Fargate and Amazon Elastic Compute Cloud (Amazon EC2) without [\u2026]"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://aws.amazon.com/blogs/aws/feed/",
        "value": "<p>Today we are announcing that <a href=\"https://aws.amazon.com/ecs\">Amazon Elastic Container Service (Amazon ECS)</a> supports an integration with <a href=\"https://aws.amazon.com/ebs\">Amazon Elastic Block Store (Amazon EBS)</a>, making it easier to run a wider range of data processing workloads. You can provision Amazon EBS storage for your ECS tasks running on <a href=\"https://aws.amazon.com/fargate\">AWS Fargate</a> and <a href=\"https://aws.amazon.com/ec2\">Amazon Elastic Compute Cloud (Amazon EC2)</a> without needing to manage storage or compute.</p> \n<p>Many organizations choose to deploy their applications as containerized packages, and with the introduction of Amazon ECS integration with Amazon EBS, organizations can now run more types of workloads than before.</p> \n<p>You can run data workloads requiring storage that supports high transaction volumes and throughput, such as extract, transform, and load (ETL) jobs for big data, which need to fetch existing data, perform processing, and store this processed data for downstream use. Because the storage lifecycle is fully managed by Amazon ECS, you don\u2019t need to build any additional scaffolding to manage infrastructure updates, and as a result, your data processing workloads are now more resilient while simultaneously requiring less effort to manage.</p> \n<p>Now you can choose from a variety of storage options for your containerized applications running on Amazon ECS:</p> \n<ul> \n <li>Your Fargate tasks get 20 GiB of <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-task-storage.html\">ephemeral storage</a> by default. For applications that need additional storage space to download large container images or for scratch work, you can configure up to 200 GiB of ephemeral storage for your Fargate tasks.</li> \n <li>For applications that span many tasks that need concurrent access to a shared dataset, you can configure Amazon ECS to mount the <a href=\"https://aws.amazon.com/efs\">Amazon Elastic File System (Amazon EFS)</a> file system to your ECS tasks running on both EC2 and Fargate. Common examples of such workloads include web applications such as content management systems, internal DevOps tools, and machine learning (ML) frameworks. Amazon EFS is designed to be available across a Region and can be simultaneously attached to many tasks.</li> \n <li>For applications that need high-performance, low-cost storage that does not need to be shared across tasks, you can configure Amazon ECS to provision and attach Amazon EBS storage to your tasks running on both Amazon EC2 and Fargate. Amazon EBS is designed to provide block storage with low latency and high performance within an Availability Zone.</li> \n</ul> \n<p>To learn more, see <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_data_volumes.html\">Using data volumes in Amazon ECS tasks</a> and <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/storage.html\">persistent storage best practices</a> in the AWS documentation.</p> \n<p><strong><u>Getting started with EBS volume integration to your ECS tasks</u></strong><br /> You can configure the volume mount point for your container in the task definition and pass Amazon EBS storage requirements for your Amazon ECS task at runtime. For most use cases, you can get started by simply providing the size of the volume needed for the task. Optionally, you can configure all EBS volume attributes and the file system you want the volume formatted with.</p> \n<p><strong> 1. Create a task definition</strong><br /> Go to the <a href=\"https://console.aws.amazon.com/ecs/v2/task-definitions\">Amazon ECS console</a>, navigate to <strong>Task definitions</strong>, and choose <strong>Create new task definition</strong>.</p> \n<p><img alt=\"\" class=\"aligncenter size-full wp-image-81881\" height=\"742\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/01/11/2024-ecs-integrations-with-ebs-1-ecs-home.jpg\" style=\"width: 100%; border: solid 1px #ccc;\" width=\"2100\" /></p> \n<p>In the <strong>Storage</strong> section, choose <strong>Configure at deployment</strong> to set EBS volume as a new configuration type. You can provision and attach one volume per task for Linux file systems.</p> \n<p><img alt=\"\" class=\"aligncenter size-full wp-image-81885\" height=\"1361\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/01/11/2024-ecs-integrations-with-ebs-2-task-definition.jpg\" style=\"width: 90%; border: solid 1px #ccc;\" width=\"1700\" /></p> \n<p>When you choose <strong>Configure at task definition creation</strong>, you can configure existing storage options such as bind mounts, Docker volumes, EFS volumes, <a href=\"https://aws.amazon.com/fsx/windows/\">Amazon FSx for Windows File Server</a> volumes, or Fargate ephemeral storage.</p> \n<p>Now you can select a container in the task definition, the source EBS volume, and provide a mount path where the volume will be mounted in the task.</p> \n<p><img alt=\"\" class=\"aligncenter size-full wp-image-81886\" height=\"647\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/01/11/2024-ecs-integrations-with-ebs-2-task-definition-2.jpg\" style=\"width: 90%;\" width=\"1700\" /></p> \n<p>You can also use <code>$aws ecs register-task-definition --cli-input-json file://example.json</code> command line to register a task definition to add an EBS volume. The following snippet is a sample, and task definitions are saved in JSON format.</p> \n<pre><code class=\"lang-json\">{\n    \"family\": \"nginx\"\n    ...\n    \"containerDefinitions\": [\n        {\n            ...\n            \"mountPoints\": [\n                \"containerPath\": \"/foo\",\n                \"sourceVolume\": \"new-ebs-volume\"\n            ],\n            \"name\": \"nginx\",\n            \"image\": \"nginx\"\n        }\n    ],\n    \"volumes\": [\n       {\n           \"name\": \"/foo\",\n           \"configuredAtRuntime\": true\n       }\n    ]\n}</code></pre> \n<p><strong>2. Deploy and run your task with EBS volume</strong><br /> Go to your ECS cluster and choose <strong>Run new task</strong>. Note that you can select the compute options, the launch type, and your task definition.</p> \n<p>Note: While this example goes through deploying a standalone task with an attached EBS volume, you can also configure a new or existing ECS service to use EBS volumes with the desired configuration.</p> \n<p><img alt=\"\" class=\"aligncenter size-full wp-image-81882\" height=\"1183\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/01/11/2024-ecs-integrations-with-ebs-3-tasks.jpg\" style=\"width: 100%; border: solid 1px #ccc;\" width=\"2100\" /></p> \n<p>You have a new <strong>Volume</strong> section where you can configure the additional storage. The volume name, type, and mount points are those that you defined in your task definition. Choose your <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html\">EBS volume types</a>, sizes (GiB), IOPS, and the desired throughput.</p> \n<p><img alt=\"\" class=\"aligncenter size-full wp-image-81884\" height=\"1612\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/01/11/2024-ecs-integrations-with-ebs-4-volumes-1.jpg\" style=\"width: 90%; border: solid 1px #ccc;\" width=\"1700\" /></p> \n<p>You cannot attach an existing EBS volume to an ECS task. But if you want to create a volume from an existing snapshot, you have the option to choose your snapshot ID. If you want to create a new volume, then you can leave this field empty. You can choose the file system type: ext3, ext4, or xfs file systems on Linux.</p> \n<p><img alt=\"\" class=\"aligncenter wp-image-81909 size-full\" height=\"883\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/01/12/2024-ecs-integrations-with-ebs-4-volumes-2-new.jpg\" style=\"width: 90%;\" width=\"1700\" /></p> \n<p>By default, when a task is terminated, Amazon ECS deletes the attached volume. If you need the data in the EBS volume to be retained after the task exits, uncheck <strong>Delete on termination</strong>. Also, you need to create an <a href=\"https://aws.amazon.com/iam/\">AWS Identity and Access Management (IAM)</a> role for volume management that contains the relevant permissions to allow Amazon ECS to make API calls on your behalf. For more information on this policy, see <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html\">infrastructure role</a> in the AWS documentation.</p> \n<p>You can also configure encryption by default on your EBS volumes using either Amazon managed keys and customer managed keys. To learn more about the options, see our <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html\">Amazon EBS encryption</a> in the AWS documentation.</p> \n<p>After configuring all task settings, choose <strong>Create</strong> to start your task.</p> \n<p><strong>3. Deploy and run your task with EBS volume</strong><br /> Once your task has started, you can see the volume information on the task details page. Choose a task and select the <strong>Volumes </strong>tab to find your created EBS volume details.</p> \n<p><img alt=\"\" class=\"aligncenter size-full wp-image-81887\" height=\"922\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/01/11/2024-ecs-integrations-with-ebs-5-tasks.jpg\" style=\"width: 90%; border: solid 1px #ccc;\" width=\"1716\" /></p> \n<p>Your team can organize the development and operations of EBS volumes more efficiently. For example, application developers can configure the path where your application expects storage to be available in the task definition, and DevOps engineers can configure the actual EBS volume attributes at runtime when the application is deployed.</p> \n<p>This allows DevOps engineers to deploy the same task definition to different environments with differing EBS volume configurations, for example, gp3 volumes in the development environments and io2 volumes in production.</p> \n<p><strong><u>Now available</u></strong><br /> Amazon ECS integration with Amazon EBS is available in nine AWS Regions: US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm). You only pay for what you use, including EBS volumes and snapshots. To learn more, see the <a href=\"https://aws.amazon.com/ebs/pricing/\">Amazon EBS pricing page</a> and <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-volumes.html\">Amazon EBS volumes in ECS</a> in the AWS documentation.</p> \n<p>Give it a try now and send feedback to <a href=\"https://github.com/aws/containers-roadmap/projects/1\">our public roadmap</a>, <a href=\"https://repost.aws/tags/TAefn4YSprR-uCBYmbofOpHw/amazon-elastic-container-service\">AWS re:Post for Amazon ECS</a>, or through your usual AWS Support contacts.</p> \n<p>\u2014 <a href=\"https://twitter.com/channyun\">Channy</a></p> \n<p><em>P.S. Special thanks to <a href=\"https://www.linkedin.com/in/maish/\">Maish Saidel-Keesing</a>, a senior enterprise developer advocate at AWS for his contribution in writing this blog post.</em></p> \n<p><strong>A correction was made on January 12, 2024</strong>: An earlier version of this post misstated: I changed 1) from \u201ceither ext3 or ext4\u201d to \u201cext3, ext4, or xfs\u201d, 2) from \u201ccheck Delete on termination\u201d to \u201cuncheck Delete on termination\u201d, 3) from \u201cconfigure encryption\u201d, \u201cby default configure encryption\u201d, and 4) from \u201ctask definition details page\u201d to \u201ctask details page\u201d.</p>"
      }
    ]
  },
  "Zoosk": {
    "title": "Customizing Tooltips with the Power of Sass Mixins",
    "xmlUrl": "https://medium.com/feed/zoosk-engineering",
    "htmlUrl": "https://about.zoosk.com/en/engineering-blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/zoosk-engineering",
      "value": "Customizing Tooltips with the Power of Sass Mixins"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/zoosk-engineering/customizing-tooltips-with-the-power-of-sass-mixins-78b6afb5bd8c?source=rss----95d50021e056---4"
      }
    ],
    "link": "https://medium.com/zoosk-engineering/customizing-tooltips-with-the-power-of-sass-mixins-78b6afb5bd8c?source=rss----95d50021e056---4",
    "id": "https://medium.com/p/78b6afb5bd8c",
    "guidislink": false,
    "tags": [
      {
        "term": "css",
        "scheme": null,
        "label": null
      },
      {
        "term": "browsers",
        "scheme": null,
        "label": null
      },
      {
        "term": "tooltips",
        "scheme": null,
        "label": null
      },
      {
        "term": "sass-mixin",
        "scheme": null,
        "label": null
      },
      {
        "term": "sass",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Sue Anna Joe"
      }
    ],
    "author": "Sue Anna Joe",
    "author_detail": {
      "name": "Sue Anna Joe"
    },
    "published": "Wed, 11 Mar 2020 23:17:59 GMT",
    "published_parsed": [
      2020,
      3,
      11,
      23,
      17,
      59,
      2,
      71,
      0
    ],
    "updated": "2020-03-11T23:17:59.815Z",
    "updated_parsed": [
      2020,
      3,
      11,
      23,
      17,
      59,
      2,
      71,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/zoosk-engineering",
        "value": "<figure><img alt=\"A collage of different tooltip designs\" src=\"https://cdn-images-1.medium.com/max/1024/1*3gJ2VKho0yW4vEovAMtrjg.png\" /></figure><p>At Zoosk we have a UI component called a tooltip. It resembles a speech bubble and provides helpful information to our users. It appears when you either click on, tap on, or hover over another\u00a0element.</p><p>We have many tooltips on our desktop and mobile websites, and they come in several variations. I discovered that each time I created a new one, I duplicated CSS properties that had been used for older tooltips. This inspired me to write some Sass mixins to speed up development and make it easier to customize our tooltip\u00a0designs.</p><h3>First iteration</h3><p>Initially I came up with the following mixin:</p><pre>@mixin tooltip($bg, $border, $border-radius, $bottom, $box-shadow, $color, $font-size, $left, $padding, $right, $top) {<br />    background: $bg;<br />    border: $border;<br />    border-radius: $border-radius;<br />    bottom: $bottom;<br />    box-shadow: $box-shadow;<br />    color: $color;<br />    font-size: $font-size;<br />    left: $left;<br />    line-height: 1.5;<br />    padding: $padding;<br />    position: absolute;<br />    right: $right;<br />    top: $top;<br />}</pre><p>I wasn\u2019t happy with this because it has too many parameters. It would be hard to keep them straight in my head, and I prefer tidier\u00a0code.</p><h3>Second iteration</h3><p>I grouped similar properties into separate mixins. My hope was that mixins with fewer parameters would be easier to manage and digest. Below is the first one which handles a tooltip\u2019s position.</p><pre>@mixin tooltip-position($top: false, $right: false, $bottom: false, $left: false) {<br />    position: absolute;</pre><pre>    @if $top != false {<br />        top: $top;<br />    }</pre><pre>    @if $right != false {<br />        right: $right;<br />    }</pre><pre>    @if $bottom != false {<br />        bottom: $bottom;<br />    }</pre><pre>    @if $left != false {<br />        left: $left;<br />    }</pre><pre>    @if $left == $right {<br />        margin-left: auto;<br />        margin-right: auto;<br />    }<br />}</pre><p>All parameters are optional so they aren\u2019t compiled unless a value is specified.</p><p>With that done, I needed mixins to handle a tooltip\u2019s visual aspects. For the pointer arrow I wanted to use a rotated\u00a0::after pseudo-element. <a href=\"https://www.tutorialspoint.com/css/css_pseudo_elements.htm\">Pseudo-elements</a> allow you to style special parts of DOM elements.\u00a0::after is a great candidate here because it can be styled much like a span. The following snippet shows the mixins for creating the pointer and other tooltip\u00a0styles.</p><pre>// CREATE THE POINTER<br />@mixin pointer-base-styles {<br />    &amp;::after {<br />        content: &quot;&quot;;<br />        position: absolute;<br />        transform: rotate(45deg);<br />    }<br />}</pre><pre>// BACKGROUND COLOR FOR THE TOOLTIP AND POINTER ARROW<br />@mixin tooltip-backgrounds($bg) {<br />    &amp;, &amp;::after {<br />        background: $bg;<br />    }<br />}</pre><pre>// FONT STYLES<br />@mixin tooltip-text($color: false, $font-size: false, $line-height: false) {<br />    color: $color;<br />    font-size: $font-size;<br />    line-height: $line-height;<br />}</pre><pre>// OTHER VISUAL TREATMENTS<br />@mixin tooltip-framing($padding: false, $border-radius: false, $shadow: false) {<br />    @if $padding != false {<br />        padding: $padding;<br />    } </pre><pre>    @if $border-radius != false {<br />        border-radius: $border-radius;<br />    }</pre><pre>    @if $shadow != false {<br />        box-shadow: $shadow;<br />    }<br />}</pre><p>So far so good. These mixins would be added to my tooltip\u2019s CSS declaration block via @include.</p><h3>Borders for the tooltip and\u00a0pointer</h3><p>You might have noticed that I haven\u2019t addressed border styles. This was intentional; borders on the pointer affect how the pointer is positioned on a tooltip\u2019s edge. Therefore, I needed a mixin that handles both the pointer\u2019s position and any\u00a0borders.</p><p>Before I get to that, I\u2019d like to demonstrate how a pointer\u2019s borders affect its position. Let\u2019s say I have a tooltip design in which the pointer points left. I can use position: absolute; and left on the pointer to move its center to the tooltip\u2019s left edge. If there are no borders, I can do some simple math in the left value to achieve this position.</p><figure><img alt=\"A graphic of a tooltip with the CSS code that properly positions its pointer without borders\" src=\"https://cdn-images-1.medium.com/max/1024/1*zgiGRNFvqnILfzYlocpfDQ.png\" /><figcaption>Pointer Example 1: Pointer is 50% black so you can easily see its center. It lines up with the tooltip\u2019s left\u00a0edge.</figcaption></figure><p>If, however, there are borders, the code above won\u2019t work because left doesn\u2019t factor in the border\u00a0width.</p><figure><img alt=\"A graphic of a tooltip with the CSS code that unsatisfactorily positions its pointer with borders\" src=\"https://cdn-images-1.medium.com/max/1024/1*78ZzEz58yWwFsUCM62YrHQ.png\" /><figcaption>Pointer Example 2: The pointer\u2019s borders jut into the tooltip\u2019s body.</figcaption></figure><p>To fix this, I must include the border\u2019s width in the left calculation. In addition it\u2019s best to apply the same border on the pointer\u2019s internal sides but with transparent as the color. This trick makes the new left calculation work consistently regardless of border\u00a0width.</p><figure><img alt=\"A graphic of a tooltip with the CSS code that properly positions its pointer with borders\" src=\"https://cdn-images-1.medium.com/max/1024/1*xxDIWTmF-77kYoL6900AwA.png\" /><figcaption>Pointer Example\u00a03</figcaption></figure><p>This is better, but while testing the code, I found a visual issue if the design required a drop shadow. Any shadow would be applied to both the tooltip and pointer. Because the pointer is above the tooltip in the DOM stacking order, the pointer\u2019s shadow unfortunately appeared over the\u00a0tooltip.</p><figure><img alt=\"A graphic of a tooltip with its CSS code demonstrating how a shadow on the pointer appears undesirably on the tooltip\" src=\"https://cdn-images-1.medium.com/max/1024/1*WeqftanYKBXo6R2QVd65fQ.png\" /><figcaption>Pointer Example\u00a04</figcaption></figure><p>Because of this I decided to try the\u00a0::before pseudo-element to render the pointer\u2019s shadow. Like its counterpart\u00a0::after,\u00a0::before can function as a separate element. I can manipulate its stacking order in the DOM with the goal of positioning it under the tooltip. With this in mind I started working on the next\u00a0mixin.</p><h3>Positioning the\u00a0pointer</h3><p>To position the pointer and its shadow (::after and\u00a0::before respectively), my next mixin must take into account the following factors:</p><ul><li>the tooltip side on which the pointer is aligned (left, right, top, or\u00a0bottom)</li><li>the pointer\u2019s size</li><li>the pointer\u2019s border\u00a0width</li></ul><p>After much tinkering I came up with the mixin below. It accepts an additional parameter cross-position that moves the pointer and shadow along the tooltip side. Visual examples of pointer positions follow the\u00a0snippet.</p><pre>@mixin pointer-position($size, $side, $cross-position, $border-width) {<br />    $half-size: $size / 2;</pre><pre>    height: $size;<br />    width: $size;<br /><br />    // MOVE PSEUDO-ELEMENTS OUTSIDE OF TOOLTIP BODY<br />    @if $border-width != 0<strong> </strong>{<br />        #{$side}: calc(#{-$half-size} - #{$border-width});<br />    } @else {<br />        #{$side}: -$half-size;<br />    }<br /><br />    // MOVE PSEUDO-ELEMENTS ALONG TOOLTIP SIDE<br />    @if $side == &quot;left&quot; or $side == &quot;right&quot; {<br />        @if $cross-position == &quot;middle&quot; {<br />            top: calc(50% - (#{$half-size} + #{$border-width}));<br />        } @else {<br />            top: $cross-position;<br />        }<br />    } @elseif $side == &quot;bottom&quot; or $side == &quot;top&quot; {<br />        @if $cross-position == &quot;middle&quot; {<br />            left: 0;<br />            margin: auto;<br />            right: 0;<br />        } @else {<br />            left: $cross-position;<br />        }<br />    }<br />}</pre><figure><img alt=\"A graphic showing two tooltips, each with a pointer sitting on the bottom edge but with different cross positions\" src=\"https://cdn-images-1.medium.com/max/1024/1*DhP995cGe_PS6on369_yOw.png\" /><figcaption>Pointers sitting on the bottom tooltip side with different cross positions</figcaption></figure><h3>Styling the pseudo-elements</h3><p>Now I needed to apply visual treatments to the pseudo-elements. Since the pointer-position mixin takes an argument for side, I can leverage it within a new mixin to manage the pointer\u2019s border display. How? I can rotate the\u00a0::after element differently based on the tooltip side. This will result in the pointer\u2019s visible borders pointing in the correct direction. Below is the last mixin that does just that and also sets box-shadow.</p><pre>// ADD TO TOOLTIP'S MAIN DIV DECLARATION BLOCK VIA @include<br />@mixin pointer-framing($size, $side, $cross-position, $border-width: 0, $border-style: false, $shadow: false) {<br />    &amp;::before {<br />        z-index: -1; // Puts the shadow behind the tooltip</pre><pre>        @if $shadow != false {<br />            box-shadow: $shadow;<br />        }<br />    }</pre><pre>    &amp;::after, &amp;::before {<br />        @include pointer-position($size, $side, $cross-position, $border-width);<br />    }</pre><pre>    @if $border-width != 0 {<br />        border: $border-width $border-style; // For the tooltip; including it in this mixin allows us to pass border arguments once for both tooltip and ::after.</pre><pre>        &amp;::after, &amp;::before {<br />            border: $border-width solid transparent;<br />        }</pre><pre>        &amp;::after {<br />            border-bottom: $border-width $border-style;<br />            border-left: $border-width $border-style;</pre><pre>            @if $side == &quot;right&quot; {<br />                transform: rotate(225deg);<br />            } @elseif $side == &quot;bottom&quot; {<br />                transform: rotate(-45deg);<br />            } @elseif $side == &quot;top&quot; {<br />                transform: rotate(135deg);<br />            }<br />        }<br />    }<br />}</pre><p>I noticed that $shadow is a parameter here and in the mixin tooltip-framing I made earlier. The $shadow argument would likely be the same for both the tooltip and\u00a0::before, so I removed it from pointer-framing and updated the @if $shadow block in tooltip-framing.</p><pre>@mixin tooltip-framing($padding: false, $border-radius: false, $shadow: false) {<br />    @if $padding != false {<br />        padding: $padding;<br />    } </pre><pre>    @if $border-radius != false {<br />        border-radius: $border-radius;<br />    }</pre><pre>    @if $shadow != false {<br />        &amp;, &amp;::before {<br />            box-shadow: $shadow;<br />        }<br />    }<br />}</pre><pre>@mixin pointer-framing($size, $side, $cross-position, $border-width: 0, $border-style: false, $shadow: false) {<br />    &amp;::before {<br />        z-index: -1; // Puts the shadow behind the tooltip<br />    }</pre><pre>    &amp;::after, &amp;::before {<br />        @include pointer-position($size, $side, $cross-position, $border-width);<br />    }</pre><pre>    @if $border-width != 0 {<br />        border: $border-width $border-style; // For the tooltip; including it in this mixin allows us to pass border arguments once for both tooltip and ::after.</pre><pre>        &amp;::after, &amp;::before {<br />            border: $border-width solid transparent;<br />        }</pre><pre>        &amp;::after {<br />            border-bottom: $border-width $border-style;<br />            border-left: $border-width $border-style;</pre><pre>            @if $side == &quot;right&quot; {<br />                transform: rotate(225deg);<br />            } @elseif $side == &quot;bottom&quot; {<br />                transform: rotate(-45deg);<br />            } @elseif $side == &quot;top&quot; {<br />                transform: rotate(135deg);<br />            }<br />        }<br />    }<br />}</pre><p>I also updated the pointer-base-styles mixin so it includes the\u00a0::before\u00a0element.</p><pre>@mixin pointer-base-styles {<br />    &amp;::after, &amp;::before {<br />        content: &quot;&quot;;<br />        position: absolute;<br />        transform: rotate(45deg);<br />    }<br />}</pre><h3>Putting it all\u00a0together</h3><p>Below is a sample snippet using the mixins plus a screenshot of the resulting UI. You can also see <a href=\"https://codepen.io/sueannaj/pen/EMGOZx\">live tooltips</a> on CodePen. (Scroll down for an embedded\u00a0demo.)</p><pre>$denim: #A5C5EB;<br />$pointer-size: 1.6rem;<br />$shadow: .2rem .2rem .2rem rgba(0, 0, 0, .2);</pre><pre>.tooltip--button-info {<br />    @include pointer-base-styles;<br />    @include pointer-framing($pointer-size, bottom, middle, .3rem, solid darken($denim, 12%));<br />    @include tooltip-backgrounds($denim);<br />    @include tooltip-framing(1em, .4rem, $shadow);<br />    @include tooltip-position(-7.5rem, 0, false, 0);<br />    @include tooltip-text(darken($denim, 50%), 1.5rem, 1.25);<br />    box-sizing: border-box;<br />    text-align: center;<br />    width: 90%;<br />}</pre><pre>&lt;div class=&quot;tooltip--button-info&quot;&gt;<br />    &lt;p&gt;Vote for the candidates by clicking a button.&lt;/p&gt;<br />&lt;/div&gt;</pre><figure><img alt=\"A screenshot of three buttons and a tooltip above them\" src=\"https://cdn-images-1.medium.com/max/1024/1*vcchhQtEtQDvKjnVFWp7KA.png\" /></figure><a href=\"https://medium.com/media/69f7d5291b4b221fd8007cff77d56c63/href\">https://medium.com/media/69f7d5291b4b221fd8007cff77d56c63/href</a><h3>But there\u2019s a gotcha (and a workaround)</h3><p>If your main tooltip div has a shadow plus the transform property, the shadow on the\u00a0::before will overlap the\u00a0tooltip.</p><figure><img alt=\"A screenshot of an alert tooltip in which its pointer\u2019s shadow is overlapping the tooltip\" src=\"https://cdn-images-1.medium.com/max/1024/1*Y01GPPmlvv6tMPSX7nbEOA.png\" /></figure><p>This looks very much like figure \u201cPointer Example 4\u201d from earlier. With the transform property, the div becomes the new stacking context for its pseudo-elements. Therefore, the\u00a0::before can\u2019t fall behind the tooltip, even with z-index: -1. You can get around this by wrapping your tooltip\u2019s child elements in a new div then applying the following changes:</p><ul><li>Move all tooltip and pointer mixins from the main div to the new wrapper div except for tooltip-position.</li><li>If the main div has width, move that to the new div as\u00a0well.</li><li>Add position: relative; to the new div so it\u2019s still the positioning context for the pseudo-elements.</li></ul><p>Below is an example of the workaround. My new div has the CSS class tooltip__body. Be aware that other scenarios can set your main div as a new stacking context, including position: fixed. Check out Mozilla\u2019s <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context\">article</a> on stacking order for a list of these scenarios.</p><pre>$alert: #EACBE4;<br />$pointer-size: 1.6rem;<br />$shadow: .2rem .2rem .2rem rgba(0, 0, 0, .2);</pre><pre>.tooltip--alert {<br />    @include tooltip-position(-3.3rem, false, false, 0);<br />    transform: translateX(calc(-100% - #{$pointer-size}));<br />        <br />    .tooltip__body {<br />        @include pointer-base-styles;<br />        @include pointer-framing($pointer-size, right, 3.7rem);<br />        @include tooltip-backgrounds($alert);<br />        @include tooltip-framing(1em, .6rem, $shadow);<br />        @include tooltip-text(darken($alert, 50%), 1.5rem, 1.25);  <br />        position: relative;<br />        width: 25rem;<br />    }<br />}</pre><pre>&lt;div class=&quot;tooltip--alert tooltip&quot;&gt;<br />    &lt;div class=&quot;tooltip__body&quot;&gt;<br />        &lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;&lt;/p&gt;<br />        &lt;p&gt;This might cause an allergic reaction.&lt;/p&gt;<br />    &lt;/div&gt;<br />&lt;/div&gt;</pre><figure><img alt=\"A screenshot of an alert tooltip in which its pointer\u2019s shadow is no longer overlapping the tooltip\" src=\"https://cdn-images-1.medium.com/max/1024/1*jhPKNPbi-UqVR6kTEb0qPQ.png\" /></figure><h3>Last thoughts</h3><p>The mixins in this article allow you to customize your tooltips, but they also rely on a few assumptions:</p><ul><li>The light source for the drop shadow is the same for all your tooltips.</li><li>The pointer is square with no border-radius.</li><li>The portion of the pointer that sticks out past the tooltip\u2019s edge is the same for\u00a0all.</li></ul><p>You should, of course, make your own customizations as needed. If your tooltips share common styles (such as pointer size, padding, and rounded corners), you can declare those once under a base CSS class for all of them. If you work with designers, you should advocate for standardized designs. If it\u2019s out of your hands, I hope these mixins will help you create manageable and tidier tooltip styles. Below is a <a href=\"https://gist.github.com/sueannaj/5730d2dbb57d9eb1776ca2b1ceae9bd2\">GitHub gist</a> with all the\u00a0code.</p><a href=\"https://medium.com/media/2980eacbf17ecbb3bb3c3cd6f8fe49d1/href\">https://medium.com/media/2980eacbf17ecbb3bb3c3cd6f8fe49d1/href</a><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=78b6afb5bd8c\" width=\"1\" /><hr /><p><a href=\"https://medium.com/zoosk-engineering/customizing-tooltips-with-the-power-of-sass-mixins-78b6afb5bd8c\">Customizing Tooltips with the Power of Sass Mixins</a> was originally published in <a href=\"https://medium.com/zoosk-engineering\">Zoosk Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"A collage of different tooltip designs\" src=\"https://cdn-images-1.medium.com/max/1024/1*3gJ2VKho0yW4vEovAMtrjg.png\" /></figure><p>At Zoosk we have a UI component called a tooltip. It resembles a speech bubble and provides helpful information to our users. It appears when you either click on, tap on, or hover over another\u00a0element.</p><p>We have many tooltips on our desktop and mobile websites, and they come in several variations. I discovered that each time I created a new one, I duplicated CSS properties that had been used for older tooltips. This inspired me to write some Sass mixins to speed up development and make it easier to customize our tooltip\u00a0designs.</p><h3>First iteration</h3><p>Initially I came up with the following mixin:</p><pre>@mixin tooltip($bg, $border, $border-radius, $bottom, $box-shadow, $color, $font-size, $left, $padding, $right, $top) {<br />    background: $bg;<br />    border: $border;<br />    border-radius: $border-radius;<br />    bottom: $bottom;<br />    box-shadow: $box-shadow;<br />    color: $color;<br />    font-size: $font-size;<br />    left: $left;<br />    line-height: 1.5;<br />    padding: $padding;<br />    position: absolute;<br />    right: $right;<br />    top: $top;<br />}</pre><p>I wasn\u2019t happy with this because it has too many parameters. It would be hard to keep them straight in my head, and I prefer tidier\u00a0code.</p><h3>Second iteration</h3><p>I grouped similar properties into separate mixins. My hope was that mixins with fewer parameters would be easier to manage and digest. Below is the first one which handles a tooltip\u2019s position.</p><pre>@mixin tooltip-position($top: false, $right: false, $bottom: false, $left: false) {<br />    position: absolute;</pre><pre>    @if $top != false {<br />        top: $top;<br />    }</pre><pre>    @if $right != false {<br />        right: $right;<br />    }</pre><pre>    @if $bottom != false {<br />        bottom: $bottom;<br />    }</pre><pre>    @if $left != false {<br />        left: $left;<br />    }</pre><pre>    @if $left == $right {<br />        margin-left: auto;<br />        margin-right: auto;<br />    }<br />}</pre><p>All parameters are optional so they aren\u2019t compiled unless a value is specified.</p><p>With that done, I needed mixins to handle a tooltip\u2019s visual aspects. For the pointer arrow I wanted to use a rotated\u00a0::after pseudo-element. <a href=\"https://www.tutorialspoint.com/css/css_pseudo_elements.htm\">Pseudo-elements</a> allow you to style special parts of DOM elements.\u00a0::after is a great candidate here because it can be styled much like a span. The following snippet shows the mixins for creating the pointer and other tooltip\u00a0styles.</p><pre>// CREATE THE POINTER<br />@mixin pointer-base-styles {<br />    &amp;::after {<br />        content: &quot;&quot;;<br />        position: absolute;<br />        transform: rotate(45deg);<br />    }<br />}</pre><pre>// BACKGROUND COLOR FOR THE TOOLTIP AND POINTER ARROW<br />@mixin tooltip-backgrounds($bg) {<br />    &amp;, &amp;::after {<br />        background: $bg;<br />    }<br />}</pre><pre>// FONT STYLES<br />@mixin tooltip-text($color: false, $font-size: false, $line-height: false) {<br />    color: $color;<br />    font-size: $font-size;<br />    line-height: $line-height;<br />}</pre><pre>// OTHER VISUAL TREATMENTS<br />@mixin tooltip-framing($padding: false, $border-radius: false, $shadow: false) {<br />    @if $padding != false {<br />        padding: $padding;<br />    } </pre><pre>    @if $border-radius != false {<br />        border-radius: $border-radius;<br />    }</pre><pre>    @if $shadow != false {<br />        box-shadow: $shadow;<br />    }<br />}</pre><p>So far so good. These mixins would be added to my tooltip\u2019s CSS declaration block via @include.</p><h3>Borders for the tooltip and\u00a0pointer</h3><p>You might have noticed that I haven\u2019t addressed border styles. This was intentional; borders on the pointer affect how the pointer is positioned on a tooltip\u2019s edge. Therefore, I needed a mixin that handles both the pointer\u2019s position and any\u00a0borders.</p><p>Before I get to that, I\u2019d like to demonstrate how a pointer\u2019s borders affect its position. Let\u2019s say I have a tooltip design in which the pointer points left. I can use position: absolute; and left on the pointer to move its center to the tooltip\u2019s left edge. If there are no borders, I can do some simple math in the left value to achieve this position.</p><figure><img alt=\"A graphic of a tooltip with the CSS code that properly positions its pointer without borders\" src=\"https://cdn-images-1.medium.com/max/1024/1*zgiGRNFvqnILfzYlocpfDQ.png\" /><figcaption>Pointer Example 1: Pointer is 50% black so you can easily see its center. It lines up with the tooltip\u2019s left\u00a0edge.</figcaption></figure><p>If, however, there are borders, the code above won\u2019t work because left doesn\u2019t factor in the border\u00a0width.</p><figure><img alt=\"A graphic of a tooltip with the CSS code that unsatisfactorily positions its pointer with borders\" src=\"https://cdn-images-1.medium.com/max/1024/1*78ZzEz58yWwFsUCM62YrHQ.png\" /><figcaption>Pointer Example 2: The pointer\u2019s borders jut into the tooltip\u2019s body.</figcaption></figure><p>To fix this, I must include the border\u2019s width in the left calculation. In addition it\u2019s best to apply the same border on the pointer\u2019s internal sides but with transparent as the color. This trick makes the new left calculation work consistently regardless of border\u00a0width.</p><figure><img alt=\"A graphic of a tooltip with the CSS code that properly positions its pointer with borders\" src=\"https://cdn-images-1.medium.com/max/1024/1*xxDIWTmF-77kYoL6900AwA.png\" /><figcaption>Pointer Example\u00a03</figcaption></figure><p>This is better, but while testing the code, I found a visual issue if the design required a drop shadow. Any shadow would be applied to both the tooltip and pointer. Because the pointer is above the tooltip in the DOM stacking order, the pointer\u2019s shadow unfortunately appeared over the\u00a0tooltip.</p><figure><img alt=\"A graphic of a tooltip with its CSS code demonstrating how a shadow on the pointer appears undesirably on the tooltip\" src=\"https://cdn-images-1.medium.com/max/1024/1*WeqftanYKBXo6R2QVd65fQ.png\" /><figcaption>Pointer Example\u00a04</figcaption></figure><p>Because of this I decided to try the\u00a0::before pseudo-element to render the pointer\u2019s shadow. Like its counterpart\u00a0::after,\u00a0::before can function as a separate element. I can manipulate its stacking order in the DOM with the goal of positioning it under the tooltip. With this in mind I started working on the next\u00a0mixin.</p><h3>Positioning the\u00a0pointer</h3><p>To position the pointer and its shadow (::after and\u00a0::before respectively), my next mixin must take into account the following factors:</p><ul><li>the tooltip side on which the pointer is aligned (left, right, top, or\u00a0bottom)</li><li>the pointer\u2019s size</li><li>the pointer\u2019s border\u00a0width</li></ul><p>After much tinkering I came up with the mixin below. It accepts an additional parameter cross-position that moves the pointer and shadow along the tooltip side. Visual examples of pointer positions follow the\u00a0snippet.</p><pre>@mixin pointer-position($size, $side, $cross-position, $border-width) {<br />    $half-size: $size / 2;</pre><pre>    height: $size;<br />    width: $size;<br /><br />    // MOVE PSEUDO-ELEMENTS OUTSIDE OF TOOLTIP BODY<br />    @if $border-width != 0<strong> </strong>{<br />        #{$side}: calc(#{-$half-size} - #{$border-width});<br />    } @else {<br />        #{$side}: -$half-size;<br />    }<br /><br />    // MOVE PSEUDO-ELEMENTS ALONG TOOLTIP SIDE<br />    @if $side == &quot;left&quot; or $side == &quot;right&quot; {<br />        @if $cross-position == &quot;middle&quot; {<br />            top: calc(50% - (#{$half-size} + #{$border-width}));<br />        } @else {<br />            top: $cross-position;<br />        }<br />    } @elseif $side == &quot;bottom&quot; or $side == &quot;top&quot; {<br />        @if $cross-position == &quot;middle&quot; {<br />            left: 0;<br />            margin: auto;<br />            right: 0;<br />        } @else {<br />            left: $cross-position;<br />        }<br />    }<br />}</pre><figure><img alt=\"A graphic showing two tooltips, each with a pointer sitting on the bottom edge but with different cross positions\" src=\"https://cdn-images-1.medium.com/max/1024/1*DhP995cGe_PS6on369_yOw.png\" /><figcaption>Pointers sitting on the bottom tooltip side with different cross positions</figcaption></figure><h3>Styling the pseudo-elements</h3><p>Now I needed to apply visual treatments to the pseudo-elements. Since the pointer-position mixin takes an argument for side, I can leverage it within a new mixin to manage the pointer\u2019s border display. How? I can rotate the\u00a0::after element differently based on the tooltip side. This will result in the pointer\u2019s visible borders pointing in the correct direction. Below is the last mixin that does just that and also sets box-shadow.</p><pre>// ADD TO TOOLTIP'S MAIN DIV DECLARATION BLOCK VIA @include<br />@mixin pointer-framing($size, $side, $cross-position, $border-width: 0, $border-style: false, $shadow: false) {<br />    &amp;::before {<br />        z-index: -1; // Puts the shadow behind the tooltip</pre><pre>        @if $shadow != false {<br />            box-shadow: $shadow;<br />        }<br />    }</pre><pre>    &amp;::after, &amp;::before {<br />        @include pointer-position($size, $side, $cross-position, $border-width);<br />    }</pre><pre>    @if $border-width != 0 {<br />        border: $border-width $border-style; // For the tooltip; including it in this mixin allows us to pass border arguments once for both tooltip and ::after.</pre><pre>        &amp;::after, &amp;::before {<br />            border: $border-width solid transparent;<br />        }</pre><pre>        &amp;::after {<br />            border-bottom: $border-width $border-style;<br />            border-left: $border-width $border-style;</pre><pre>            @if $side == &quot;right&quot; {<br />                transform: rotate(225deg);<br />            } @elseif $side == &quot;bottom&quot; {<br />                transform: rotate(-45deg);<br />            } @elseif $side == &quot;top&quot; {<br />                transform: rotate(135deg);<br />            }<br />        }<br />    }<br />}</pre><p>I noticed that $shadow is a parameter here and in the mixin tooltip-framing I made earlier. The $shadow argument would likely be the same for both the tooltip and\u00a0::before, so I removed it from pointer-framing and updated the @if $shadow block in tooltip-framing.</p><pre>@mixin tooltip-framing($padding: false, $border-radius: false, $shadow: false) {<br />    @if $padding != false {<br />        padding: $padding;<br />    } </pre><pre>    @if $border-radius != false {<br />        border-radius: $border-radius;<br />    }</pre><pre>    @if $shadow != false {<br />        &amp;, &amp;::before {<br />            box-shadow: $shadow;<br />        }<br />    }<br />}</pre><pre>@mixin pointer-framing($size, $side, $cross-position, $border-width: 0, $border-style: false, $shadow: false) {<br />    &amp;::before {<br />        z-index: -1; // Puts the shadow behind the tooltip<br />    }</pre><pre>    &amp;::after, &amp;::before {<br />        @include pointer-position($size, $side, $cross-position, $border-width);<br />    }</pre><pre>    @if $border-width != 0 {<br />        border: $border-width $border-style; // For the tooltip; including it in this mixin allows us to pass border arguments once for both tooltip and ::after.</pre><pre>        &amp;::after, &amp;::before {<br />            border: $border-width solid transparent;<br />        }</pre><pre>        &amp;::after {<br />            border-bottom: $border-width $border-style;<br />            border-left: $border-width $border-style;</pre><pre>            @if $side == &quot;right&quot; {<br />                transform: rotate(225deg);<br />            } @elseif $side == &quot;bottom&quot; {<br />                transform: rotate(-45deg);<br />            } @elseif $side == &quot;top&quot; {<br />                transform: rotate(135deg);<br />            }<br />        }<br />    }<br />}</pre><p>I also updated the pointer-base-styles mixin so it includes the\u00a0::before\u00a0element.</p><pre>@mixin pointer-base-styles {<br />    &amp;::after, &amp;::before {<br />        content: &quot;&quot;;<br />        position: absolute;<br />        transform: rotate(45deg);<br />    }<br />}</pre><h3>Putting it all\u00a0together</h3><p>Below is a sample snippet using the mixins plus a screenshot of the resulting UI. You can also see <a href=\"https://codepen.io/sueannaj/pen/EMGOZx\">live tooltips</a> on CodePen. (Scroll down for an embedded\u00a0demo.)</p><pre>$denim: #A5C5EB;<br />$pointer-size: 1.6rem;<br />$shadow: .2rem .2rem .2rem rgba(0, 0, 0, .2);</pre><pre>.tooltip--button-info {<br />    @include pointer-base-styles;<br />    @include pointer-framing($pointer-size, bottom, middle, .3rem, solid darken($denim, 12%));<br />    @include tooltip-backgrounds($denim);<br />    @include tooltip-framing(1em, .4rem, $shadow);<br />    @include tooltip-position(-7.5rem, 0, false, 0);<br />    @include tooltip-text(darken($denim, 50%), 1.5rem, 1.25);<br />    box-sizing: border-box;<br />    text-align: center;<br />    width: 90%;<br />}</pre><pre>&lt;div class=&quot;tooltip--button-info&quot;&gt;<br />    &lt;p&gt;Vote for the candidates by clicking a button.&lt;/p&gt;<br />&lt;/div&gt;</pre><figure><img alt=\"A screenshot of three buttons and a tooltip above them\" src=\"https://cdn-images-1.medium.com/max/1024/1*vcchhQtEtQDvKjnVFWp7KA.png\" /></figure><a href=\"https://medium.com/media/69f7d5291b4b221fd8007cff77d56c63/href\">https://medium.com/media/69f7d5291b4b221fd8007cff77d56c63/href</a><h3>But there\u2019s a gotcha (and a workaround)</h3><p>If your main tooltip div has a shadow plus the transform property, the shadow on the\u00a0::before will overlap the\u00a0tooltip.</p><figure><img alt=\"A screenshot of an alert tooltip in which its pointer\u2019s shadow is overlapping the tooltip\" src=\"https://cdn-images-1.medium.com/max/1024/1*Y01GPPmlvv6tMPSX7nbEOA.png\" /></figure><p>This looks very much like figure \u201cPointer Example 4\u201d from earlier. With the transform property, the div becomes the new stacking context for its pseudo-elements. Therefore, the\u00a0::before can\u2019t fall behind the tooltip, even with z-index: -1. You can get around this by wrapping your tooltip\u2019s child elements in a new div then applying the following changes:</p><ul><li>Move all tooltip and pointer mixins from the main div to the new wrapper div except for tooltip-position.</li><li>If the main div has width, move that to the new div as\u00a0well.</li><li>Add position: relative; to the new div so it\u2019s still the positioning context for the pseudo-elements.</li></ul><p>Below is an example of the workaround. My new div has the CSS class tooltip__body. Be aware that other scenarios can set your main div as a new stacking context, including position: fixed. Check out Mozilla\u2019s <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context\">article</a> on stacking order for a list of these scenarios.</p><pre>$alert: #EACBE4;<br />$pointer-size: 1.6rem;<br />$shadow: .2rem .2rem .2rem rgba(0, 0, 0, .2);</pre><pre>.tooltip--alert {<br />    @include tooltip-position(-3.3rem, false, false, 0);<br />    transform: translateX(calc(-100% - #{$pointer-size}));<br />        <br />    .tooltip__body {<br />        @include pointer-base-styles;<br />        @include pointer-framing($pointer-size, right, 3.7rem);<br />        @include tooltip-backgrounds($alert);<br />        @include tooltip-framing(1em, .6rem, $shadow);<br />        @include tooltip-text(darken($alert, 50%), 1.5rem, 1.25);  <br />        position: relative;<br />        width: 25rem;<br />    }<br />}</pre><pre>&lt;div class=&quot;tooltip--alert tooltip&quot;&gt;<br />    &lt;div class=&quot;tooltip__body&quot;&gt;<br />        &lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;&lt;/p&gt;<br />        &lt;p&gt;This might cause an allergic reaction.&lt;/p&gt;<br />    &lt;/div&gt;<br />&lt;/div&gt;</pre><figure><img alt=\"A screenshot of an alert tooltip in which its pointer\u2019s shadow is no longer overlapping the tooltip\" src=\"https://cdn-images-1.medium.com/max/1024/1*jhPKNPbi-UqVR6kTEb0qPQ.png\" /></figure><h3>Last thoughts</h3><p>The mixins in this article allow you to customize your tooltips, but they also rely on a few assumptions:</p><ul><li>The light source for the drop shadow is the same for all your tooltips.</li><li>The pointer is square with no border-radius.</li><li>The portion of the pointer that sticks out past the tooltip\u2019s edge is the same for\u00a0all.</li></ul><p>You should, of course, make your own customizations as needed. If your tooltips share common styles (such as pointer size, padding, and rounded corners), you can declare those once under a base CSS class for all of them. If you work with designers, you should advocate for standardized designs. If it\u2019s out of your hands, I hope these mixins will help you create manageable and tidier tooltip styles. Below is a <a href=\"https://gist.github.com/sueannaj/5730d2dbb57d9eb1776ca2b1ceae9bd2\">GitHub gist</a> with all the\u00a0code.</p><a href=\"https://medium.com/media/2980eacbf17ecbb3bb3c3cd6f8fe49d1/href\">https://medium.com/media/2980eacbf17ecbb3bb3c3cd6f8fe49d1/href</a><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=78b6afb5bd8c\" width=\"1\" /><hr /><p><a href=\"https://medium.com/zoosk-engineering/customizing-tooltips-with-the-power-of-sass-mixins-78b6afb5bd8c\">Customizing Tooltips with the Power of Sass Mixins</a> was originally published in <a href=\"https://medium.com/zoosk-engineering\">Zoosk Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Mozilla Hacks": {
    "title": "Puppeteer Support for the Cross-Browser WebDriver BiDi Standard",
    "xmlUrl": "https://hacks.mozilla.org/feed/",
    "htmlUrl": "https://hacks.mozilla.org/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://hacks.mozilla.org/feed/",
      "value": "Puppeteer Support for the Cross-Browser WebDriver BiDi Standard"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://hacks.mozilla.org/2023/12/puppeteer-webdriver-bidi/"
      }
    ],
    "link": "https://hacks.mozilla.org/2023/12/puppeteer-webdriver-bidi/",
    "authors": [
      {
        "name": "James Graham"
      }
    ],
    "author": "James Graham",
    "author_detail": {
      "name": "James Graham"
    },
    "published": "Tue, 12 Dec 2023 16:14:03 +0000",
    "published_parsed": [
      2023,
      12,
      12,
      16,
      14,
      3,
      1,
      346,
      0
    ],
    "tags": [
      {
        "term": "Developer Tools",
        "scheme": null,
        "label": null
      },
      {
        "term": "Featured Article",
        "scheme": null,
        "label": null
      },
      {
        "term": "Firefox",
        "scheme": null,
        "label": null
      },
      {
        "term": "firefox",
        "scheme": null,
        "label": null
      },
      {
        "term": "Standards",
        "scheme": null,
        "label": null
      },
      {
        "term": "Testing",
        "scheme": null,
        "label": null
      },
      {
        "term": "Tools",
        "scheme": null,
        "label": null
      },
      {
        "term": "webDriver",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://hacks.mozilla.org/?p=48070",
    "guidislink": false,
    "summary": "<p>Puppeteer now supports the next-generation, cross-browser WebDriver BiDi standard. This new protocol makes it easy for web developers to write automated tests that work across multiple browser engines.</p>\n<p>The post <a href=\"https://hacks.mozilla.org/2023/12/puppeteer-webdriver-bidi/\">Puppeteer Support for the Cross-Browser WebDriver BiDi Standard</a> appeared first on <a href=\"https://hacks.mozilla.org\">Mozilla Hacks - the Web developer blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://hacks.mozilla.org/feed/",
      "value": "<p>Puppeteer now supports the next-generation, cross-browser WebDriver BiDi standard. This new protocol makes it easy for web developers to write automated tests that work across multiple browser engines.</p>\n<p>The post <a href=\"https://hacks.mozilla.org/2023/12/puppeteer-webdriver-bidi/\">Puppeteer Support for the Cross-Browser WebDriver BiDi Standard</a> appeared first on <a href=\"https://hacks.mozilla.org\">Mozilla Hacks - the Web developer blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://hacks.mozilla.org/feed/",
        "value": "<p>We are pleased to share that <a href=\"https://pptr.dev/\">Puppeteer</a> now supports the next-generation, cross-browser <a href=\"https://w3c.github.io/webdriver-bidi/\">WebDriver BiDi standard</a>. This new protocol makes it easy for web developers to write automated tests that work across multiple browser engines.</p>\n<h2>How Do I Use Puppeteer With Firefox?</h2>\n<p>The WebDriver BiDi protocol is supported starting with <a href=\"https://pptr.dev/webdriver-bidi\">Puppeteer v21.6.0</a>. When calling <code>puppeteer.launch</code> pass in <code>\"firefox\"</code> as the product option, and <code>\"webDriverBiDi\"</code> as the protocol option:</p>\n<pre><code class=\"hljs javascript\">const browser = await puppeteer.launch({\n\u00a0\u00a0product: 'firefox',\n\u00a0\u00a0protocol: 'webDriverBiDi',\n})</code></pre>\n<p>You can also use the <code>\"webDriverBiDi\"</code> protocol when testing in Chrome, reflecting the fact that WebDriver BiDi offers a single standard for modern cross-browser automation.</p>\n<p>In the future we expect <code>\"webDriverBiDi\"</code> to become the default protocol when using Firefox in Puppeteer.</p>\n<h2>Doesn&#8217;t Puppeteer Already Support Firefox?</h2>\n<p>Puppeteer has had experimental support for Firefox based on a partial re-implementation of the proprietary <a href=\"https://chromedevtools.github.io/devtools-protocol/\">Chrome DevTools Protocol</a> (CDP). This approach had the advantage that it worked without significant changes to the existing Puppeteer code. However the CDP implementation in Firefox is incomplete and has significant technical limitations. In addition, the CDP protocol itself is not designed to be cross browser, and undergoes frequent breaking changes, making it unsuitable as a long-term solution for cross-browser automation.</p>\n<p>To overcome these problems, we&#8217;ve worked with the WebDriver Working Group at the W3C to create a standard automation protocol that meets the needs of modern browser automation clients: this is WebDriver BiDi. For more details on the protocol design and how it compares to the classic HTTP-based WebDriver protocol, see our <a href=\"https://hacks.mozilla.org/2020/12/cross-browser-testing-part-1-web-app-testing-today/\">earlier</a> <a href=\"https://hacks.mozilla.org/2021/01/improving-cross-browser-testing-part-2-new-automation-features-in-firefox-nightly/\">posts</a>.</p>\n<p>As the standardization process has progressed, the Puppeteer team has added a WebDriver BiDi backend in Puppeteer, and provided feedback on the specification to ensure that it meets the needs of Puppeteer users, and that the protocol design enables existing CDP-based tooling to easily transition to WebDriver BiDi. The result is a single protocol based on open standards that can drive both Chrome and Firefox in Puppeteer.</p>\n<h2>Are All Puppeteer Features Supported?</h2>\n<p>Not <a href=\"https://puppeteer.github.io/ispuppeteerwebdriverbidiready/\">yet</a>; WebDriver BiDi is still a work in progress, and doesn&#8217;t yet cover the full feature set of Puppeteer.</p>\n<p>Compared to the Chrome+CDP implementation, there are some feature gaps, including support for accessing the cookie store, network request interception, some emulation features, and permissions. These features are actively being standardized and will be integrated as soon as they become available. For Firefox, the only missing feature compared to the Firefox+CDP implementation is cookie access. In addition, WebDriver BiDi already offers improvements, including better support for multi-process Firefox, which is essential for testing some websites. More information on the complete set of supported APIs can be found in the <a href=\"https://pptr.dev/webdriver-bidi\">Puppeteer documentation</a>, and as new WebDriver-BiDi features are enabled in Gecko we&#8217;ll publish details on the <a href=\"https://fxdx.dev/\">Firefox Developer Experience blog</a>.</p>\n<p>Nevertheless, we believe that the WebDriver-based Firefox support in Puppeteer has reached a level of quality which makes it suitable for many real automation scenarios. For example at Mozilla we have successfully <a href=\"https://github.com/mozilla/pdf.js/pull/17172\">ported</a> our Puppeteer tests for <a href=\"https://mozilla.github.io/pdf.js/\">pdf.js</a> from Firefox+CDP to Firefox+WebDriver BiDi.</p>\n<h2>Is Firefox&#8217;s CDP Support Going Away?</h2>\n<p>We currently don&#8217;t have a specific timeline for removing CDP support. However, maintaining multiple protocols is not a good use of our resources, and we expect WebDriver BiDi to be the future of remote automation in Firefox. If you are using the CDP support outside of the context of Puppeteer, we&#8217;d love to hear from you (see below), so that we can understand your use cases, and help transition to WebDriver BiDi.</p>\n<h2>Where Can I Provide Feedback?</h2>\n<p>For any issues you experience when porting Puppeteer tests to BiDi, please open issues in the <a href=\"https://github.com/puppeteer/puppeteer/issues/new/choose\">Puppeteer issue tracker</a>, unless you can verify the bug is in the Firefox implementation, in which case please <a href=\"https://bugzilla.mozilla.org/enter_bug.cgi?product=Remote%20Protocol&amp;component=WebDriver%20BiDi\">file a bug on Bugzilla</a>.</p>\n<p>If you are currently using CDP with Firefox, please join the <a href=\"https://matrix.to/#/#webdriver:mozilla.org\">#webdriver matrix channel</a> so that we can discuss your use case and requirements, and help you solve any problems you encounter porting your code to WebDriver BiDi.</p>\n<p>The post <a href=\"https://hacks.mozilla.org/2023/12/puppeteer-webdriver-bidi/\">Puppeteer Support for the Cross-Browser WebDriver BiDi Standard</a> appeared first on <a href=\"https://hacks.mozilla.org\">Mozilla Hacks - the Web developer blog</a>.</p>"
      }
    ]
  },
  "Evil Martians": {
    "title": "How to cultivate capital: 6 tips from developer tools founders and VCs",
    "xmlUrl": "https://evilmartians.com/chronicles.atom",
    "htmlUrl": "https://evilmartians.com/chronicles/",
    "title_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://evilmartians.com/chronicles.atom",
      "value": "How to cultivate capital: 6 tips from developer tools founders and VCs"
    },
    "id": "https://evilmartians.com/chronicles/how-to-cultivate-capital-6-tips-from-developer-tools-founders-and-vcs",
    "guidislink": true,
    "link": "https://evilmartians.com/chronicles/how-to-cultivate-capital-6-tips-from-developer-tools-founders-and-vcs",
    "links": [
      {
        "href": "https://evilmartians.com/chronicles/how-to-cultivate-capital-6-tips-from-developer-tools-founders-and-vcs",
        "rel": "alternate",
        "type": "text/html"
      }
    ],
    "updated": "2024-01-10T00:00:00.000Z",
    "updated_parsed": [
      2024,
      1,
      10,
      0,
      0,
      0,
      2,
      10,
      0
    ],
    "summary": "A quick guide on the crossroads of bootstrapping and fundraising with experience-backed tips that provides a roadmap to successful fundraising for developer tool founders.",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://evilmartians.com/chronicles.atom",
      "value": "A quick guide on the crossroads of bootstrapping and fundraising with experience-backed tips that provides a roadmap to successful fundraising for developer tool founders."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://evilmartians.com/chronicles.atom",
        "value": "<article><section><strong>Authors: </strong>Victoria Melnikova, Head of New&nbsp;Business, and Travis Turner, Tech Editor</section><section><strong>Topic: </strong>Business</section><a href=\"https://evilmartians.com/chronicles/how-to-cultivate-capital-6-tips-from-developer-tools-founders-and-vcs\"><img class=\"webfeedsFeaturedVisual\" src=\"https://evilmartians.com/static/cover-c7831e1ebc4f2d5016bcc0bcdec1b0a2.png\" /></a><section><p><em>A quick guide on the crossroads of bootstrapping and fundraising with experience-backed tips that provides a roadmap to successful fundraising for developer tool founders.</em></p><p></p><p>In the complex landscape of startup financing, many founders find themselves at the pivotal crossroad between bootstrapping and fundraising. So, we\u2019ve made a quick guide with handpicked, experience-backed tips (inspired by a number of industry rockstars) which provides a roadmap to successful fundraising for developer tool founders.</p><p></p></section><a href=\"https://evilmartians.com/chronicles/how-to-cultivate-capital-6-tips-from-developer-tools-founders-and-vcs\">Read more</a></article>"
      }
    ],
    "media_thumbnail": [
      {
        "url": "https://evilmartians.com/static/cover-c7831e1ebc4f2d5016bcc0bcdec1b0a2.png"
      }
    ],
    "href": "https://twitter.com/_Travis_Turner",
    "authors": [
      {
        "name": "Victoria Melnikova",
        "email": "vicamelnikova@evilmartians.com",
        "href": "https://twitter.com/vmelnikova_en"
      },
      {
        "name": "Travis Turner",
        "email": "richardturner@evilmartians.com",
        "href": "https://twitter.com/_Travis_Turner"
      }
    ],
    "author_detail": {
      "name": "Travis Turner",
      "email": "richardturner@evilmartians.com",
      "href": "https://twitter.com/_Travis_Turner"
    },
    "author": "Travis Turner (richardturner@evilmartians.com)",
    "tags": [
      {
        "term": "Business",
        "scheme": null,
        "label": "Business"
      }
    ],
    "published": "2024-01-10T00:00:00.000Z",
    "published_parsed": [
      2024,
      1,
      10,
      0,
      0,
      0,
      2,
      10,
      0
    ]
  },
  "Indeed": {
    "title": "SHAP Plots: The Crystal Ball for UI Test Ideas",
    "xmlUrl": "http://engineering.indeedblog.com/feed/",
    "htmlUrl": "http://engineering.indeedblog.com/blog/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://engineering.indeedblog.com/feed/",
      "value": "SHAP Plots: The Crystal Ball for UI Test Ideas"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.indeedblog.com/blog/2022/04/shap-plot/"
      }
    ],
    "link": "https://engineering.indeedblog.com/blog/2022/04/shap-plot/",
    "authors": [
      {
        "name": "Vicky Zhang"
      }
    ],
    "author": "Vicky Zhang",
    "author_detail": {
      "name": "Vicky Zhang"
    },
    "published": "Thu, 28 Apr 2022 15:40:29 +0000",
    "published_parsed": [
      2022,
      4,
      28,
      15,
      40,
      29,
      3,
      118,
      0
    ],
    "tags": [
      {
        "term": "A/B Testing",
        "scheme": null,
        "label": null
      },
      {
        "term": "Analytics",
        "scheme": null,
        "label": null
      },
      {
        "term": "Unsorted",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.indeedblog.com/?p=4564",
    "guidislink": false,
    "summary": "<p>&#160; Have you ever wanted a crystal ball that would predict the best A/B test to boost your product\u2019s growth, or identify which part of your UI drives a target metric? With a statistical model and a SHAP decision plot, you can identify impactful A/B test ideas in bulk. The Indeed Interview team used this [&#8230;]</p>\n<p>\u2002</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "http://engineering.indeedblog.com/feed/",
      "value": "<p>&#160; Have you ever wanted a crystal ball that would predict the best A/B test to boost your product\u2019s growth, or identify which part of your UI drives a target metric? With a statistical model and a SHAP decision plot, you can identify impactful A/B test ideas in bulk. The Indeed Interview team used this [&#8230;]</p>\n<p>\u2002</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "http://engineering.indeedblog.com/feed/",
        "value": "<div class=\"wp-caption aligncenter\" id=\"attachment_4573\" style=\"width: 250px;\"><img alt=\"\" class=\"wp-image-4573 size-medium\" height=\"300\" src=\"https://engineering.indeedblog.com/wp-content/uploads/2022/04/crystal-ball-240x300.png\" width=\"240\" /><p class=\"wp-caption-text\" id=\"caption-attachment-4573\"><em>Photo by <a href=\"https://unsplash.com/@shambam\">Sam</a> on <a href=\"https://unsplash.com/photos/SaFjBsJASOQ\">Unsplash</a></em></p></div>\n<p>&nbsp;</p>\n<p>Have you ever wanted a crystal ball that would predict the best A/B test to boost your product\u2019s growth, or identify which part of your UI drives a target metric?</p>\n<p>With a statistical model and a <a href=\"https://towardsdatascience.com/introducing-shap-decision-plots-52ed3b4a1cba\">SHAP decision plot</a>, you can identify impactful A/B test ideas in bulk. The Indeed Interview team used this methodology to generate optimal A/B tests, leading to a 5-10% increase in key business metrics.</p>\n<h2 style=\"text-align: left;\">Case study: Increasing interview invites</h2>\n<p><a href=\"https://www.indeed.com/employers/interview?hl=en&amp;co=US\">Indeed Interview</a> aims to make interviewing as seamless as possible for job seekers and employers. The Indeed Interview team has one goal: to increase the number of interviews happening on the platform. For this case study, we wanted UI test ideas that would help us boost the number of invitations sent by employers. To do this, we needed to analyze their behavior on the employer dashboard, and try to predict interview invitations.</p>\n<h3><img alt=\"Employer using Indeed Interview to virtually interview a candidate.\" class=\"alignnone wp-image-4565 size-full\" height=\"1130\" src=\"https://engineering.indeedblog.com/wp-content/uploads/2022/04/Employer-using-Indeed-Interview-to-virtually-interview-a-candidate..png\" width=\"1600\" /></h3>\n<h3>Convert UI elements into features</h3>\n<p>The first step of understanding employer behavior was to create a dataset. We needed to predict the probability of sending interview invitations based on an employer\u2019s clicks in the dashboard.</p>\n<p>We organized the dataset so each cell represented the number of times an employer clicked a specific UI element. We then used these features to predict our targeted action: clicking the <strong>Set up interview</strong> button vs. not clicking on the button.</p>\n<p><img alt=\"Set up interview button on the employer dashboard\" class=\"alignnone wp-image-4569 size-full\" height=\"175\" src=\"https://engineering.indeedblog.com/wp-content/uploads/2022/04/Set-up-interview-button.png\" width=\"631\" /></p>\n<h3>Train the model on the target variable</h3>\n<p>The next step was to train a model to make predictions based on the dataset. We selected a tree-based model, <a href=\"https://catboost.ai/\">CatBoost</a>, due to its overall superior performance and ability to detect interactions among features. And, just like any model, it works effectively with our interpretation tool \u2013 <a href=\"https://github.com/slundberg/shap\">SHAP plot</a>.</p>\n<p>We could have used correlation or logistic regression coefficients, but we chose SHAP plot combined with a tree-based model because it provides unique advantages for model interpretation tasks. Two features with similar correlation coefficients could have dramatically different interpretations in SHAP plot, which factors in feature importance. In addition, a tree-based model usually has better performance than logistic regression, leading to a more accurate model. Using SHAP plot combined with a tree-based model provides both performance and interpretability.</p>\n<h3>Interpret SHAP results into positive and negative predictors</h3>\n<p>Now that we have a dataset and trained model, we can interpret the SHAP plot generated from it. SHAP works by showing how much a certain feature can change the prediction value. In the SHAP plot below, each row is a feature, and the features are ranked based on descending importance: the ones at the top are the most important and have the highest influence (positive or negative) on our targeted action of clicking <strong>Set up interview</strong>.</p>\n<p>The data for each feature is displayed with colors representing the scale of the feature. A red dot on the plot means the employer clicked a given UI element many times, and a blue dot means the employer clicked it only a few times. Each dot also has a SHAP value on the X axis, which signifies the type of influence, positive or negative, that the feature has on the target and the strength of its impact. The farther a dot is from the center, the stronger the influence.</p>\n<p><a href=\"https://engineering.indeedblog.com/wp-content/uploads/2022/04/SHAP-plot.png\"><img alt=\"SHAP plot displaying features A-O ranked by descending influence on the model (regardless of positive or negative). Each feature has red and blue dots (feature value) organized by SHAP value (impact on model output). Features outlined in red: A, B, D, F, H, I, K, L, and N. Features outlined in blue: E, G, M, and O.\" class=\"alignleft wp-image-4571 size-large\" height=\"643\" src=\"https://engineering.indeedblog.com/wp-content/uploads/2022/04/SHAP-plot-1024x643.png\" width=\"1024\" /></a></p>\n<p class=\"image-caption\" style=\"font-style: italic; text-align: center;\">SHAP plot with features outlined in red for positive predictors, and blue for negative predictors</p>\n<p>Based on the color and location of the dots, we categorized the features as positive or negative predictors.</p>\n<ul>\n<li><strong>Positive Predictor</strong> &#8211; A feature where red dots are to the right of the center.\n<ul>\n<li>They have positive SHAP value: usage of this feature predicts the employer will <strong>send</strong> an interview invitation.</li>\n<li>In the SHAP plot above, Feature B is a good example.</li>\n</ul>\n</li>\n<li><strong>Negative Predictor</strong> &#8211; A feature where red dots are to the left of the center.\n<ul>\n<li>They have negative SHAP value: usage of this feature predicts the employer will <strong>not send</strong> an interview invitation.</li>\n<li>Feature G is a good example of this.</li>\n</ul>\n</li>\n</ul>\n<p>Red dots on both sides of the center are more complex and need further investigation, using tools such as dependency plots (also in SHAP package).</p>\n<p>Note that this relationship between feature and target is not causal yet. A model can only claim causality when it assumes all confounding variables have been included, which is a strong assumption. While the relationships <em>could</em> be causal, we don\u2019t know for certain until they are verified in A/B tests.</p>\n<h3>Generate test ideas</h3>\n<p>Our SHAP plot contains 9 positive predictors and 4 negative predictors, and <strong>each one is a potential A/B test hypothesis</strong> of the relationship between the UI element and the target. We hypothesize that positive predictors boost target usage, and negative predictors hinder target usage.</p>\n<p>To verify these hypotheses, we can test ways to <strong>make positive predictors more prominent</strong>, and direct the employer\u2019s attention to them. After the employer clicks on the feature, we can direct attention to the target, in order to boost its usage. Another option is to test ways to <strong>divert the employer&#8217;s attention away from negative predictors</strong>. We can add good friction, making them less easy to access and see if usage of the target increases.</p>\n<h4>Boost positive predictors</h4>\n<p>We tested changes to the positive predictors from our SHAP plot to make them more prominent in our UI. We made Feature B more prominent on the dashboard, and directed the employer\u2019s attention to it. After the employer clicked Feature B, we showed a redesigned UI with improved visuals to make the <strong>Set up interview</strong> button more attractive.</p>\n<p>The results were a 6% increase in clicking to set up an interview.</p>\n<h4>Divert away from negative predictors</h4>\n<p>We also tested changes to the negative predictors from our SHAP plot in the hopes of increasing usage of the target. We ran a test to divert employer attention away from Feature G by placing it close to the <strong>Set up interview</strong> button on the dashboard. This way it was easier for the employer to choose setting up an interview instead.</p>\n<p>This change boosted clicks to send interview invitations by 5%.</p>\n<h2>Gaze into your own crystal ball</h2>\n<p>A SHAP plot may not be an actual crystal ball. When used with a statistical model, however, it can generate UI A/B test ideas in bulk and boost target metrics for many products. You might find it especially suitable for products with a complex and nonlinear UI, such as user dashboards. The methodology also provides a glimpse of which UI elements drive the target metrics the most, allowing you to focus on testing features that have the most impact. So, what are you waiting for? Start using this method and good fortune will follow.</p>\n<p>&nbsp;</p>\n<p>Cross-posted on <a href=\"https://medium.com/indeed-engineering/shap-plots-the-crystal-ball-for-ui-test-ideas-121838d917f5\">Medium</a></p>\n<p>\u2002</p>"
      }
    ]
  },
  "Nextdoor": {
    "title": "Let AI Entertain You: Increasing User Engagement with Generative AI and Rejection Sampling",
    "xmlUrl": "https://engblog.nextdoor.com/feed",
    "htmlUrl": "https://engblog.nextdoor.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engblog.nextdoor.com/feed",
      "value": "Let AI Entertain You: Increasing User Engagement with Generative AI and Rejection Sampling"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engblog.nextdoor.com/let-ai-entertain-you-increasing-user-engagement-with-generative-ai-and-rejection-sampling-50a402264f56?source=rss----5e54f11cdfdf---4"
      }
    ],
    "link": "https://engblog.nextdoor.com/let-ai-entertain-you-increasing-user-engagement-with-generative-ai-and-rejection-sampling-50a402264f56?source=rss----5e54f11cdfdf---4",
    "id": "https://medium.com/p/50a402264f56",
    "guidislink": false,
    "tags": [
      {
        "term": "notifications",
        "scheme": null,
        "label": null
      },
      {
        "term": "generative-ai",
        "scheme": null,
        "label": null
      },
      {
        "term": "a-b-testing",
        "scheme": null,
        "label": null
      },
      {
        "term": "model-training",
        "scheme": null,
        "label": null
      },
      {
        "term": "chatgpt",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Jaewon Yang"
      }
    ],
    "author": "Jaewon Yang",
    "author_detail": {
      "name": "Jaewon Yang"
    },
    "published": "Mon, 16 Oct 2023 17:03:52 GMT",
    "published_parsed": [
      2023,
      10,
      16,
      17,
      3,
      52,
      0,
      289,
      0
    ],
    "updated": "2023-10-16T17:03:52.706Z",
    "updated_parsed": [
      2023,
      10,
      16,
      17,
      3,
      52,
      0,
      289,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engblog.nextdoor.com/feed",
        "value": "<p>Generative AI (Gen AI) has demonstrated proficiency in content generation but does not consistently guarantee user engagement, mainly for two reasons. First, Gen AI generates content without considering user engagement feedback. While the content may be informative and well-written, it does not always translate to increased user engagement such as clicks. Second, Gen AI-produced content often remains generic and may not always provide the specific information that users\u00a0seek.</p><p>Nextdoor is the neighborhood network where neighbors, businesses, and public agencies connect with each other. Nextdoor is building innovative solutions to enhance the user engagement with AI-Generated Content (AIGC). This post outlines our approach to improving user engagement through user feedback, specifically focusing on Notification email subject lines. Our solutions employ Rejection sampling [1], a technique used in reinforcement learning, to boost the engagement metrics. We believe our work presents a general framework to drive user engagement with AIGC, particularly when off-the-shelf Generative AI falls short in producing engaging content. To the best of our knowledge, this marks an early milestone in the industry\u2019s successful use of AIGC to enhance user engagement.</p><h3>Introduction</h3><p>At Nextdoor, one of the ways to drive user growth and engagement on platform is through emails. One of the emails we have is called New and Trending <a href=\"https://engblog.nextdoor.com/nextdoor-notifications-how-we-use-ml-to-keep-neighbors-informed-57d8f707aab0\">notifications</a>, where we send a single post that we think the user might be interested in and want to engage with. As part of sending an email, we need to determine a subject line of the email for the email audiences. Historically, we simply pick the first few words of the post being sent to be the subject line. However, in certain posts, these initial words are often greetings or introductory remarks and may not provide valuable information to the user. In the provided image example below, we observe a simple greeting, \u201cHello!\u201d</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/707/0*1bUjaLCj0AOjUIe0\" /><figcaption>Figure 1. New and Trending email where we show a single post. Prior to the Gen AI systems we build, we use the first words of the post as the subject line (Life and Mother Nature always find a\u00a0way!)</figcaption></figure><p>In this work, we aim to use Generative AI technologies to improve the subject line. With Generative AI, we aim to generate informative and interesting subject lines that will lead to more email opens, clicks and eventually more sessions.</p><p>Writing a good subject line with Generative AI is challenging because the subject line needs to satisfy the following criteria. First and foremost, the subject line needs to be engaging so that the users want to open the email. To see if ChatGPT API can write engaging subject lines, we tried generating subject lines with ChatGPT API with a small traffic A/B test, and found that the users are less likely to click on emails if we use subject lines made by ChatGPT API (e.g. Table 1). As we show later, we tried to improve the prompts (prompt engineering) but the results were still inferior to the user-generated subjects. This finding implies that Generative AI models are not trained to write the content that is particularly engaging to our users, and we need to guide Generative AI models to increase user engagement.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/991/1*L4Uumzj8svXajgd07AUOtQ.png\" /><figcaption>Table 1. Subject line made by ChatGPT API and its CTR. ChatGPT API\u2019s subject line is more informative but looks like a marketing phrase, and produced only 56% clicks compared to the user-generated subject\u00a0line.</figcaption></figure><p>Second challenge is that the subject line needs to be authentic. If it reads like a marketing phrase, the email will look like spam. The example in Table 1 \u201cSupport backyard chickens in Papillion, NE!\u201d shows this\u00a0issue.</p><p>Third, the subject line should not contain hallucinations (a response that is nonsensical or not accurate). And it is well known that Generative AI is vulnerable to hallucinations [2]. For example, given a very short post saying \u201cSun bathing \u2600\ufe0f\u201d, ChatGPT API in Table 1 generated the subject line \u201cSoak Up the Sun: Tips for Relaxing Sun Bathing Sessions\u201d, which had nothing to do with the post\u00a0content.</p><p>We developed a novel Generative AI method to overcome the three challenges faced by the ChatGPT API mentioned above. We made three contributions:</p><ul><li><strong>Prompt engineering to generate authentic subject lines with no hallucination:</strong> Given a post, ChatGPT API creates a subject line by extracting the most interesting phrases of the post without any rewriting. By extracting the user\u2019s original writing, we are able to prevent marketing phrases and hallucinations.</li><li><strong>Rejection sampling with a reward model: </strong>To find the most interesting subject line, we develop a reward model whose job is to predict if the users would prefer a given subject line over other subject lines. After ChatGPT API writes a subject line, we evaluate it by the reward model and accept it only if its reward model score is higher than the user-written subject line\u2019s score. This technique is called Rejection Sampling and recently introduced to Reinforcement Learning for Large Language Model training\u00a0[1].</li><li><strong>Cost optimization and model accuracy maintenance</strong>: We added engineering components to minimize the serving cost and stabilize the model performance. By using caching, we reduced our cost to 1/600 compared to the brute-force way. By daily performance monitoring, we can catch if reward models fail to predict which subject is more engaging due to external factors such as user preference drift and address it by retraining.</li></ul><p>We believe that this framework is generally applicable when off-the-shelf Generative AI fails to improve user engagement. We also analyzed the importance of each component in our design. Even with the aforementioned prompt engineering, ChatGPT API did not necessarily produce more engaging content. This highlights the necessity of the rejection sampling component: in such cases, we can develop another AI model as a reward model and use the Generative AI\u2019s output only if the reward model approves\u00a0[1].</p><h3>Proposed Method</h3><p>For every post, we employ the following system to create a subject line. It\u2019s important to mention that we generate a single subject line for each post, without personalization. This decision was made to minimize computational cost. Exploring cost-effective methods for implementing personalized subject lines will be an interesting future\u00a0work.</p><h4>Model Overview</h4><p>Figure 2 illustrates our approach. We develop two different AI\u00a0models.</p><ul><li>Subject line generator: This model generates a subject line given a post\u00a0content.</li><li>Reward model (Evaluator): Given a subject line and the post content, this model predicts if the given subject line would be the better subject line than the user-generated subject\u00a0line.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/893/1*ejkWUk9i9BBrI74iU7g1XA.png\" /><figcaption>Figure 2. Overview of our approach.</figcaption></figure><p>Given a post, the Subject line generator produces subjects in Figure 2 (green boxes). The reward model compares the OpenAI API subject line (green) with the user-generated subject line (red), and selects the more engaging one. For the top post, the OpenAI API subject line contains more relevant information and is selected. For the bottom post which was about a health alert, the reward model selects the user-generated subject. While the OpenAI API subject line shows the main content of the alert, the reward model picks the user-generated subject because it shows the importance of the post and thus is more engaging.</p><h4>Developing Subject Line Generator</h4><p>We use OpenAI API without fine-tuning. In the prompt, we require that OpenAI API extracts the most interesting part of the post without making any change. This way of extracting user content provides multiple benefits: First, it removes hallucinations. Second, it keeps the subject line authentic as OpenAI API does not rewrite the original content. To test the prompt engineering, we A/B tested generator outputs without reward models. We found that asking OpenAI API to extract in the prompt improves Sessions by 3% relatively compared to asking OpenAI API to rewrite the subject line from scratch (See the Results section for the details).</p><h4>Developing Reward\u00a0Model</h4><p>We fine-tune OpenAI API to develop a reward model. This is the main innovation we applied on\u00a0top.</p><p><strong>Training data collection: </strong>The challenge is to collect training data on which subject line was more engaging. Manual annotation is not possible because there are no rules deciding what subject line is more engaging. We found that the subject lines that we thought to be more engaging than the user-generated ones turned out to be less engaging (Table\u00a02).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/956/1*WgqJAkjrCROtF0SfXCz4qA.png\" /><figcaption>Table 2. Emails with a user-generated subject (left) generated 3x as many clicks as the emails with OpenAI API-generated subjects on the\u00a0right.</figcaption></figure><p>To tackle this issue, we collect training data via experimentation. For each post, we generate subject lines in two ways. One way is to use user-generated ones and the other is to use the OpenAI API generator described above. Then we serve 2\u20133% users (~20k) that are randomly selected with each subject line. The goal is to learn which subject line was more engaging through click\u00a0data.</p><p><strong>Model training:</strong> We used OpenAI API to fine-tune with the labels we collected. We used ~50k examples and 40% of examples had the OpenAI API subject as the winning subject and the rest had the user subject as the winner. Given a subject line and post content, our model is fine-tuned to predict if the subject line would generate more engagement (clicks) than the user-generated subject line. The model is asked to predict if the subject line is more engaging and output \u201cYes\u201d or\u00a0\u201cNo\u201d.</p><p><strong>Training details:</strong> We used the smallest OpenAI API model \u201cada\u201d for fine-tuning. We found that larger models did not improve the predictive performance despite higher cost. We added <a href=\"https://help.openai.com/en/articles/5247780-using-logit-bias-to-define-token-probability\">a logit bias</a> of 100 for \u201cYes\u201d and \u201cNo\u201d. These biases boost the probability for the model to output \u201cYes\u201d or \u201cNo\u201d. We tried to change the number of epochs and selected the model with 4 epochs, but we did not see much difference in offline performance after 2\u20133\u00a0epochs.</p><p><strong>Engineering details:</strong> We added the following components for optimization and safeguarding.</p><ul><li><strong>Caching: </strong>For each post, we cache the outputs of our model. By processing each post only once, we reduced the cost to 1/600. In other words, each post gets sent 600 times on average and we process the post only once instead of 600 times. Caching also optimizes the OpenAI API usages (the number of tokens and the number of requests).</li><li><strong>Reward model performance maintenance</strong>: We monitor the reward model\u2019s predictive performance daily, using the next day\u2019s user clicks after the training phase as the ground truth to compare with the model\u2019s output. Model\u2019s predictive performance can change because our users\u2019 preference may change and the content in Nextdoor can shift in the writing styles or topics.<br />For monitoring purposes, we collect the engagement performance of different subject lines in the following way. We created a \u201ccontrol\u201d user bucket where we always send emails with the user-generated subject and a \u201calways OpenAI API\u201d bucket where we always send with the OpenAI API subject, regardless of the reward model\u2019s output. From these two buckets, we know the ground-truth on which subject line was more engaging, and measure the reward model\u2019s accuracy. If the accuracy goes down by 10+%, we retrain the reward model with new\u00a0data.</li><li><strong>Retries with Fallback: </strong>Since OpenAI API may return an error due to the rate limit or transient issues, we added retries with<a href=\"https://tenacity.readthedocs.io/en/latest/\"> exponential backoffs with Tenacity</a>. If we fail after a certain number of retries, we fallback to the user-generated subject.</li><li><strong>Controlling the length of output: </strong>We found that the Subject line generator would write a subject line longer than our desired length (10 words). This happened even if we specified the 10 word limit in the instruction and added examples. We post-processed the generator output by cutting the first 10 words from the generator\u2019s output. We A/B tested different word limits and found that 10 is the optimal\u00a0value.</li></ul><h3>Results</h3><p>We did A/B tests with different versions of the subject line generator, and with and without the reward model. For the generator, we tested the following options</p><ul><li>Writing with OpenAI API: We ask OpenAI API to \u201cwrite an engaging subject line for a given post\u201d. This was the first version we tested without much prompt engineering.</li><li>Extracting with OpenAI API: We ask OpenAI API to extract the most interesting part and provide 5 examples. We also add requirements in a numbered list such as \u201cDo not insert or remove any word.\u201d, \u201cDo not change capitalization\u201d, \u201cIf the first 10 words are interesting, use them as a subject line\u201d. We tried 4 different versions of prompts and picked the best version by A/B test\u00a0metrics.</li></ul><p>For the A/B test metrics, we primarily focus on Sessions. A session is an activity sequence made by the same user within a certain timeframe, and sessions quantify the number of unique user\u00a0visits.</p><p>Table 3 shows the results on Session lift compared to the \u201ccontrol\u201d bucket where we use user-generated subject lines. In addition to the session metrics, our final model (last row) increased Weekly Active Users by 0.4% and Ads revenue by\u00a01%.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/955/1*60AFxqFwmZ39d8g2h5NQUw.png\" /><figcaption>Table 3. Session lift compared to the user-generated subject lines from A/B tests. The final model (last row) achieved 1% lift in sessions.</figcaption></figure><p>Here is what we learned from A/B\u00a0tests:</p><ul><li>Prompt engineering improves the performance but has a ceiling. After a few iterations, the A/B test metrics showed only marginal improvements, failing to beat the\u00a0control.</li><li>Finding the \u201coptimal\u201d prompt is an elusive task, as the space of potential prompts is boundless, making it difficult to explore. Moreover, there is no established algorithmic or systematic method for enhancing prompts. Instead, the task relies on human judgment and intuition to update the\u00a0prompt.</li><li>Reward model was the key factor in improving sessions.</li><li>Predicting popular content is challenging, as is the reward model\u2019s task of forecasting popular subject lines, which currently achieves about 65% accuracy. Enhancing the reward model\u2019s performance by leveraging real-time signals like the current engagement numbers for the subject can be an interesting future\u00a0work.</li></ul><h3>Conclusions</h3><p>We developed a novel Generative AI system to increase user engagement by combining the reward model and prompt engineering. Our systems have engineering components for cost saving and monitoring. A/B tests showed that our systems can deliver more engaging subject lines than the user-generated subject\u00a0lines.</p><p>There are many avenues for future work. First is to fine-tune the subject line generator. In this work, we used vanilla ChatGPT API as the generator. Instead, we can fine tune OpenAI API with the most engaging titles that the reward model identifies. For each post, we generate multiple subject lines and use the reward model to pick the winner. Then we use the winner subject to fine tune the subject line generator. This approach is called Reinforcement Learning by Rejection Sampling\u00a0[1].</p><p>Second is to rescore the same post daily. Currently, we pick the best subject line with a reward model once and never rescore. However, as time goes on, we may be able to see which of the OpenAI API subject line or user-generated subject line is getting more engagement, and our reward model can predict more accurately. Third is to add personalization without significantly escalating computational costs.</p><h3>Acknowledgments</h3><p>The post was written by <a href=\"https://www.linkedin.com/in/jaewonyang/\">Jaewon Yang</a> and <a href=\"https://www.linkedin.com/in/qi-he/\">Qi\u00a0He</a>.</p><p>This work was led by the Generative AI team with cross-org collaboration between Notification team and ML teams. We would like to give a shout out to all the contributors:</p><p><a href=\"https://www.linkedin.com/in/joyzengjy/\">Jingying Zeng</a>, <a href=\"https://www.linkedin.com/in/malikwaleed/\">Waleed Malik</a>, <a href=\"https://www.linkedin.com/in/xiaoyan2/\">Xiao Yan</a>, <a href=\"https://www.linkedin.com/in/hao-ming-fu/\">Hao-Ming Fu</a>, <a href=\"https://www.linkedin.com/in/carolyn-tran-4904759b/\">Carolyn Tran</a>, <a href=\"https://www.linkedin.com/in/ssuresh2/\">Sameer Suresh</a>, <a href=\"https://www.linkedin.com/in/annabgoncharova/\">Anna Goncharova</a>, <a href=\"https://www.linkedin.com/in/richardhuang11/\">Richard Huang</a>, <a href=\"https://www.linkedin.com/in/jaewonyang/\">Jaewon Yang</a>, <a href=\"https://www.linkedin.com/in/qi-he/\">Qi\u00a0He</a></p><p>Please reach out to us if you are interested to learn more\u200a\u2014\u200awe are\u00a0hiring!</p><h3>References</h3><p>[1] Touvron et al. Llama 2: Open Foundation and Fine-Tuned Chat Models, Arxiv preprint, 2023</p><p>[2] Ji et al. Survey of Hallucination in Natural Language Generation, ACM Computing Surveys,\u00a02022</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=50a402264f56\" width=\"1\" /><hr /><p><a href=\"https://engblog.nextdoor.com/let-ai-entertain-you-increasing-user-engagement-with-generative-ai-and-rejection-sampling-50a402264f56\">Let AI Entertain You: Increasing User Engagement with Generative AI and Rejection Sampling</a> was originally published in <a href=\"https://engblog.nextdoor.com\">Nextdoor Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>Generative AI (Gen AI) has demonstrated proficiency in content generation but does not consistently guarantee user engagement, mainly for two reasons. First, Gen AI generates content without considering user engagement feedback. While the content may be informative and well-written, it does not always translate to increased user engagement such as clicks. Second, Gen AI-produced content often remains generic and may not always provide the specific information that users\u00a0seek.</p><p>Nextdoor is the neighborhood network where neighbors, businesses, and public agencies connect with each other. Nextdoor is building innovative solutions to enhance the user engagement with AI-Generated Content (AIGC). This post outlines our approach to improving user engagement through user feedback, specifically focusing on Notification email subject lines. Our solutions employ Rejection sampling [1], a technique used in reinforcement learning, to boost the engagement metrics. We believe our work presents a general framework to drive user engagement with AIGC, particularly when off-the-shelf Generative AI falls short in producing engaging content. To the best of our knowledge, this marks an early milestone in the industry\u2019s successful use of AIGC to enhance user engagement.</p><h3>Introduction</h3><p>At Nextdoor, one of the ways to drive user growth and engagement on platform is through emails. One of the emails we have is called New and Trending <a href=\"https://engblog.nextdoor.com/nextdoor-notifications-how-we-use-ml-to-keep-neighbors-informed-57d8f707aab0\">notifications</a>, where we send a single post that we think the user might be interested in and want to engage with. As part of sending an email, we need to determine a subject line of the email for the email audiences. Historically, we simply pick the first few words of the post being sent to be the subject line. However, in certain posts, these initial words are often greetings or introductory remarks and may not provide valuable information to the user. In the provided image example below, we observe a simple greeting, \u201cHello!\u201d</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/707/0*1bUjaLCj0AOjUIe0\" /><figcaption>Figure 1. New and Trending email where we show a single post. Prior to the Gen AI systems we build, we use the first words of the post as the subject line (Life and Mother Nature always find a\u00a0way!)</figcaption></figure><p>In this work, we aim to use Generative AI technologies to improve the subject line. With Generative AI, we aim to generate informative and interesting subject lines that will lead to more email opens, clicks and eventually more sessions.</p><p>Writing a good subject line with Generative AI is challenging because the subject line needs to satisfy the following criteria. First and foremost, the subject line needs to be engaging so that the users want to open the email. To see if ChatGPT API can write engaging subject lines, we tried generating subject lines with ChatGPT API with a small traffic A/B test, and found that the users are less likely to click on emails if we use subject lines made by ChatGPT API (e.g. Table 1). As we show later, we tried to improve the prompts (prompt engineering) but the results were still inferior to the user-generated subjects. This finding implies that Generative AI models are not trained to write the content that is particularly engaging to our users, and we need to guide Generative AI models to increase user engagement.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/991/1*L4Uumzj8svXajgd07AUOtQ.png\" /><figcaption>Table 1. Subject line made by ChatGPT API and its CTR. ChatGPT API\u2019s subject line is more informative but looks like a marketing phrase, and produced only 56% clicks compared to the user-generated subject\u00a0line.</figcaption></figure><p>Second challenge is that the subject line needs to be authentic. If it reads like a marketing phrase, the email will look like spam. The example in Table 1 \u201cSupport backyard chickens in Papillion, NE!\u201d shows this\u00a0issue.</p><p>Third, the subject line should not contain hallucinations (a response that is nonsensical or not accurate). And it is well known that Generative AI is vulnerable to hallucinations [2]. For example, given a very short post saying \u201cSun bathing \u2600\ufe0f\u201d, ChatGPT API in Table 1 generated the subject line \u201cSoak Up the Sun: Tips for Relaxing Sun Bathing Sessions\u201d, which had nothing to do with the post\u00a0content.</p><p>We developed a novel Generative AI method to overcome the three challenges faced by the ChatGPT API mentioned above. We made three contributions:</p><ul><li><strong>Prompt engineering to generate authentic subject lines with no hallucination:</strong> Given a post, ChatGPT API creates a subject line by extracting the most interesting phrases of the post without any rewriting. By extracting the user\u2019s original writing, we are able to prevent marketing phrases and hallucinations.</li><li><strong>Rejection sampling with a reward model: </strong>To find the most interesting subject line, we develop a reward model whose job is to predict if the users would prefer a given subject line over other subject lines. After ChatGPT API writes a subject line, we evaluate it by the reward model and accept it only if its reward model score is higher than the user-written subject line\u2019s score. This technique is called Rejection Sampling and recently introduced to Reinforcement Learning for Large Language Model training\u00a0[1].</li><li><strong>Cost optimization and model accuracy maintenance</strong>: We added engineering components to minimize the serving cost and stabilize the model performance. By using caching, we reduced our cost to 1/600 compared to the brute-force way. By daily performance monitoring, we can catch if reward models fail to predict which subject is more engaging due to external factors such as user preference drift and address it by retraining.</li></ul><p>We believe that this framework is generally applicable when off-the-shelf Generative AI fails to improve user engagement. We also analyzed the importance of each component in our design. Even with the aforementioned prompt engineering, ChatGPT API did not necessarily produce more engaging content. This highlights the necessity of the rejection sampling component: in such cases, we can develop another AI model as a reward model and use the Generative AI\u2019s output only if the reward model approves\u00a0[1].</p><h3>Proposed Method</h3><p>For every post, we employ the following system to create a subject line. It\u2019s important to mention that we generate a single subject line for each post, without personalization. This decision was made to minimize computational cost. Exploring cost-effective methods for implementing personalized subject lines will be an interesting future\u00a0work.</p><h4>Model Overview</h4><p>Figure 2 illustrates our approach. We develop two different AI\u00a0models.</p><ul><li>Subject line generator: This model generates a subject line given a post\u00a0content.</li><li>Reward model (Evaluator): Given a subject line and the post content, this model predicts if the given subject line would be the better subject line than the user-generated subject\u00a0line.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/893/1*ejkWUk9i9BBrI74iU7g1XA.png\" /><figcaption>Figure 2. Overview of our approach.</figcaption></figure><p>Given a post, the Subject line generator produces subjects in Figure 2 (green boxes). The reward model compares the OpenAI API subject line (green) with the user-generated subject line (red), and selects the more engaging one. For the top post, the OpenAI API subject line contains more relevant information and is selected. For the bottom post which was about a health alert, the reward model selects the user-generated subject. While the OpenAI API subject line shows the main content of the alert, the reward model picks the user-generated subject because it shows the importance of the post and thus is more engaging.</p><h4>Developing Subject Line Generator</h4><p>We use OpenAI API without fine-tuning. In the prompt, we require that OpenAI API extracts the most interesting part of the post without making any change. This way of extracting user content provides multiple benefits: First, it removes hallucinations. Second, it keeps the subject line authentic as OpenAI API does not rewrite the original content. To test the prompt engineering, we A/B tested generator outputs without reward models. We found that asking OpenAI API to extract in the prompt improves Sessions by 3% relatively compared to asking OpenAI API to rewrite the subject line from scratch (See the Results section for the details).</p><h4>Developing Reward\u00a0Model</h4><p>We fine-tune OpenAI API to develop a reward model. This is the main innovation we applied on\u00a0top.</p><p><strong>Training data collection: </strong>The challenge is to collect training data on which subject line was more engaging. Manual annotation is not possible because there are no rules deciding what subject line is more engaging. We found that the subject lines that we thought to be more engaging than the user-generated ones turned out to be less engaging (Table\u00a02).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/956/1*WgqJAkjrCROtF0SfXCz4qA.png\" /><figcaption>Table 2. Emails with a user-generated subject (left) generated 3x as many clicks as the emails with OpenAI API-generated subjects on the\u00a0right.</figcaption></figure><p>To tackle this issue, we collect training data via experimentation. For each post, we generate subject lines in two ways. One way is to use user-generated ones and the other is to use the OpenAI API generator described above. Then we serve 2\u20133% users (~20k) that are randomly selected with each subject line. The goal is to learn which subject line was more engaging through click\u00a0data.</p><p><strong>Model training:</strong> We used OpenAI API to fine-tune with the labels we collected. We used ~50k examples and 40% of examples had the OpenAI API subject as the winning subject and the rest had the user subject as the winner. Given a subject line and post content, our model is fine-tuned to predict if the subject line would generate more engagement (clicks) than the user-generated subject line. The model is asked to predict if the subject line is more engaging and output \u201cYes\u201d or\u00a0\u201cNo\u201d.</p><p><strong>Training details:</strong> We used the smallest OpenAI API model \u201cada\u201d for fine-tuning. We found that larger models did not improve the predictive performance despite higher cost. We added <a href=\"https://help.openai.com/en/articles/5247780-using-logit-bias-to-define-token-probability\">a logit bias</a> of 100 for \u201cYes\u201d and \u201cNo\u201d. These biases boost the probability for the model to output \u201cYes\u201d or \u201cNo\u201d. We tried to change the number of epochs and selected the model with 4 epochs, but we did not see much difference in offline performance after 2\u20133\u00a0epochs.</p><p><strong>Engineering details:</strong> We added the following components for optimization and safeguarding.</p><ul><li><strong>Caching: </strong>For each post, we cache the outputs of our model. By processing each post only once, we reduced the cost to 1/600. In other words, each post gets sent 600 times on average and we process the post only once instead of 600 times. Caching also optimizes the OpenAI API usages (the number of tokens and the number of requests).</li><li><strong>Reward model performance maintenance</strong>: We monitor the reward model\u2019s predictive performance daily, using the next day\u2019s user clicks after the training phase as the ground truth to compare with the model\u2019s output. Model\u2019s predictive performance can change because our users\u2019 preference may change and the content in Nextdoor can shift in the writing styles or topics.<br />For monitoring purposes, we collect the engagement performance of different subject lines in the following way. We created a \u201ccontrol\u201d user bucket where we always send emails with the user-generated subject and a \u201calways OpenAI API\u201d bucket where we always send with the OpenAI API subject, regardless of the reward model\u2019s output. From these two buckets, we know the ground-truth on which subject line was more engaging, and measure the reward model\u2019s accuracy. If the accuracy goes down by 10+%, we retrain the reward model with new\u00a0data.</li><li><strong>Retries with Fallback: </strong>Since OpenAI API may return an error due to the rate limit or transient issues, we added retries with<a href=\"https://tenacity.readthedocs.io/en/latest/\"> exponential backoffs with Tenacity</a>. If we fail after a certain number of retries, we fallback to the user-generated subject.</li><li><strong>Controlling the length of output: </strong>We found that the Subject line generator would write a subject line longer than our desired length (10 words). This happened even if we specified the 10 word limit in the instruction and added examples. We post-processed the generator output by cutting the first 10 words from the generator\u2019s output. We A/B tested different word limits and found that 10 is the optimal\u00a0value.</li></ul><h3>Results</h3><p>We did A/B tests with different versions of the subject line generator, and with and without the reward model. For the generator, we tested the following options</p><ul><li>Writing with OpenAI API: We ask OpenAI API to \u201cwrite an engaging subject line for a given post\u201d. This was the first version we tested without much prompt engineering.</li><li>Extracting with OpenAI API: We ask OpenAI API to extract the most interesting part and provide 5 examples. We also add requirements in a numbered list such as \u201cDo not insert or remove any word.\u201d, \u201cDo not change capitalization\u201d, \u201cIf the first 10 words are interesting, use them as a subject line\u201d. We tried 4 different versions of prompts and picked the best version by A/B test\u00a0metrics.</li></ul><p>For the A/B test metrics, we primarily focus on Sessions. A session is an activity sequence made by the same user within a certain timeframe, and sessions quantify the number of unique user\u00a0visits.</p><p>Table 3 shows the results on Session lift compared to the \u201ccontrol\u201d bucket where we use user-generated subject lines. In addition to the session metrics, our final model (last row) increased Weekly Active Users by 0.4% and Ads revenue by\u00a01%.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/955/1*60AFxqFwmZ39d8g2h5NQUw.png\" /><figcaption>Table 3. Session lift compared to the user-generated subject lines from A/B tests. The final model (last row) achieved 1% lift in sessions.</figcaption></figure><p>Here is what we learned from A/B\u00a0tests:</p><ul><li>Prompt engineering improves the performance but has a ceiling. After a few iterations, the A/B test metrics showed only marginal improvements, failing to beat the\u00a0control.</li><li>Finding the \u201coptimal\u201d prompt is an elusive task, as the space of potential prompts is boundless, making it difficult to explore. Moreover, there is no established algorithmic or systematic method for enhancing prompts. Instead, the task relies on human judgment and intuition to update the\u00a0prompt.</li><li>Reward model was the key factor in improving sessions.</li><li>Predicting popular content is challenging, as is the reward model\u2019s task of forecasting popular subject lines, which currently achieves about 65% accuracy. Enhancing the reward model\u2019s performance by leveraging real-time signals like the current engagement numbers for the subject can be an interesting future\u00a0work.</li></ul><h3>Conclusions</h3><p>We developed a novel Generative AI system to increase user engagement by combining the reward model and prompt engineering. Our systems have engineering components for cost saving and monitoring. A/B tests showed that our systems can deliver more engaging subject lines than the user-generated subject\u00a0lines.</p><p>There are many avenues for future work. First is to fine-tune the subject line generator. In this work, we used vanilla ChatGPT API as the generator. Instead, we can fine tune OpenAI API with the most engaging titles that the reward model identifies. For each post, we generate multiple subject lines and use the reward model to pick the winner. Then we use the winner subject to fine tune the subject line generator. This approach is called Reinforcement Learning by Rejection Sampling\u00a0[1].</p><p>Second is to rescore the same post daily. Currently, we pick the best subject line with a reward model once and never rescore. However, as time goes on, we may be able to see which of the OpenAI API subject line or user-generated subject line is getting more engagement, and our reward model can predict more accurately. Third is to add personalization without significantly escalating computational costs.</p><h3>Acknowledgments</h3><p>The post was written by <a href=\"https://www.linkedin.com/in/jaewonyang/\">Jaewon Yang</a> and <a href=\"https://www.linkedin.com/in/qi-he/\">Qi\u00a0He</a>.</p><p>This work was led by the Generative AI team with cross-org collaboration between Notification team and ML teams. We would like to give a shout out to all the contributors:</p><p><a href=\"https://www.linkedin.com/in/joyzengjy/\">Jingying Zeng</a>, <a href=\"https://www.linkedin.com/in/malikwaleed/\">Waleed Malik</a>, <a href=\"https://www.linkedin.com/in/xiaoyan2/\">Xiao Yan</a>, <a href=\"https://www.linkedin.com/in/hao-ming-fu/\">Hao-Ming Fu</a>, <a href=\"https://www.linkedin.com/in/carolyn-tran-4904759b/\">Carolyn Tran</a>, <a href=\"https://www.linkedin.com/in/ssuresh2/\">Sameer Suresh</a>, <a href=\"https://www.linkedin.com/in/annabgoncharova/\">Anna Goncharova</a>, <a href=\"https://www.linkedin.com/in/richardhuang11/\">Richard Huang</a>, <a href=\"https://www.linkedin.com/in/jaewonyang/\">Jaewon Yang</a>, <a href=\"https://www.linkedin.com/in/qi-he/\">Qi\u00a0He</a></p><p>Please reach out to us if you are interested to learn more\u200a\u2014\u200awe are\u00a0hiring!</p><h3>References</h3><p>[1] Touvron et al. Llama 2: Open Foundation and Fine-Tuned Chat Models, Arxiv preprint, 2023</p><p>[2] Ji et al. Survey of Hallucination in Natural Language Generation, ACM Computing Surveys,\u00a02022</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=50a402264f56\" width=\"1\" /><hr /><p><a href=\"https://engblog.nextdoor.com/let-ai-entertain-you-increasing-user-engagement-with-generative-ai-and-rejection-sampling-50a402264f56\">Let AI Entertain You: Increasing User Engagement with Generative AI and Rejection Sampling</a> was originally published in <a href=\"https://engblog.nextdoor.com\">Nextdoor Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Made Tech": {
    "title": "Online housing repairs: why no login is the right fix",
    "xmlUrl": "http://www.madetech.com/feed",
    "htmlUrl": "https://www.madetech.com/blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.madetech.com/feed/",
      "value": "Online housing repairs: why no login is the right fix"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.madetech.com/blog/online-housing-repairs-no-login/"
      }
    ],
    "link": "https://www.madetech.com/blog/online-housing-repairs-no-login/",
    "authors": [
      {
        "name": "Fraser Trickett"
      }
    ],
    "author": "Fraser Trickett",
    "author_detail": {
      "name": "Fraser Trickett"
    },
    "published": "Wed, 15 Nov 2023 14:15:45 +0000",
    "published_parsed": [
      2023,
      11,
      15,
      14,
      15,
      45,
      2,
      319,
      0
    ],
    "tags": [
      {
        "term": "Housing",
        "scheme": null,
        "label": null
      },
      {
        "term": "Housing Repairs SaaS product",
        "scheme": null,
        "label": null
      },
      {
        "term": "Local government",
        "scheme": null,
        "label": null
      },
      {
        "term": "SaaS products",
        "scheme": null,
        "label": null
      },
      {
        "term": "Evidence SaaS product",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://www.madetech.com/?p=13378",
    "guidislink": false,
    "summary": "<p>If you\u2019re thinking of putting in place an online housing repair service, it's time to weigh up the pros and cons of having a login. </p>\n<p>The post <a href=\"https://www.madetech.com/blog/online-housing-repairs-no-login/\">Online housing repairs: why no login is the right fix</a> appeared first on <a href=\"https://www.madetech.com\">Made Tech</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.madetech.com/feed/",
      "value": "<p>If you\u2019re thinking of putting in place an online housing repair service, it's time to weigh up the pros and cons of having a login. </p>\n<p>The post <a href=\"https://www.madetech.com/blog/online-housing-repairs-no-login/\">Online housing repairs: why no login is the right fix</a> appeared first on <a href=\"https://www.madetech.com\">Made Tech</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.madetech.com/feed/",
        "value": "<p>Imagine you\u2019re a resident with low digital literacy, your kitchen tap has been leaking and you can\u2019t find the number to log a repair. A family member visits and wants to help. They find the council\u2019s online portal where you can log a repair in minutes. Sounds great. However, there\u2019s a problem: you need to login and they don&#8217;t have an account\u2026</p>\n\n\n\n<p>This is a familiar situation from our conversations and research with over 100 residents across multiple councils in the North and South of England. When we asked residents why they don\u2019t use existing report-a-repair online services, it was often down to one thing &#8211; having to remember and enter a username and password.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Better and quicker resolution for everyone</strong></h2>\n\n\n\n<p>Logging housing repairs is an emotive subject. That leaking tap? You want it fixed quickly so that it\u2019s one less thing to worry about. Having a login is a barrier and that barrier implies it\u2019s easier and quicker to call. However, when a digital service is well designed it&#8217;s easier to report online and quickly triage it to offer the resident an appointment slot that best suits them &#8211; all in minutes. I\u2019ll throw another number into the mix &#8211; calling isn\u2019t quicker, it takes an average of 18 minutes to report by phone (with a 9 minute waiting time) and is often only available 9-5. And we know taps have a habit of leaking outside these hours.</p>\n\n\n\n<p>Some of the most vulnerable people in society live in social housing. They\u2019re reliant on others, like family members, wardens or other support networks. Removing the login opens the door for that support network to report repairs on their behalf.&nbsp;</p>\n\n\n\n<p>There\u2019s another inclusivity aspect that came out of the research and testing we did and that\u2019s people who have accessibility needs or those for whom English isn\u2019t their first language.&nbsp; It\u2019s easier to log something online with accessibility tools such as screen readers, increased font size and built-in translators, especially if the wording and journey has been road-tested with these user groups in mind.&nbsp;&nbsp;</p>\n\n\n\n<p>Compare this to having to ring up. It\u2019s more time, more hassle and more frustration. Of course there are benefits in telephone conversations and this should remain an option.&nbsp;Offering an online option frees up these channels and reduces wait time for those that need it most. I\u2019m not suggesting that there isn\u2019t a time and a place to use the phone but in the above example it wouldn\u2019t be the easiest or most user-friendly first point of contact.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Misconception 1: Will users abuse the service?</strong></h3>\n\n\n\n<p>A common barrier to no login is that residents will want to report multiple issues, including non-repairs related ones. So as well as the leaky tap they\u2019ll also ask who their councillor is, when the bins are being emptied and so on. Yet during our research we found that over 95% calls were related to a single repair issue.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Misconception 2: We need a login for security</strong></h3>\n\n\n\n<p>Then there\u2019s security, another reason cited for needing a login. We\u2019ve worked with several councils without a login process and there hasn\u2019t been a single rogue repair logged. The idea that someone will sit there and log fictitious faults is one that hasn\u2019t materialised.&nbsp;</p>\n\n\n\n<p>One perception is that there will be less misuse and security risks if people have to ring in and speak to a customer service agent versus logging things online. When listening to hundreds of calls, most council agents only asked for an address as verification. Meaning that without psychic powers there\u2019s no additional checks via the phone reporting route.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Login or no login &#8211; can the 2 live side-by-side?</strong></h2>\n\n\n\n<p>Of course there is another point to consider when it comes to login or no login. And this takes me back to one of my earlier points around considering user needs. There will be people who live in social housing who simply want to log a repair and get visibility of this one thing.&nbsp;&nbsp;</p>\n\n\n\n<p>There\u2019s also residents who need to regularly check their rent balances and other council information that from a user experience and trust perspective needs to sit behind a login. This doesn\u2019t mean that if they need to quickly log a repair they can\u2019t access this via the route with no login. The two options can co-exist.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Support people to use the service &#8211; promote it!</strong></h2>\n\n\n\n<p>The final piece in this applies whether you put your repairs behind a login or not. And this is making sure your tenants are aware of the online service. How can you encourage them to use it? What information and help do they need?&nbsp;&nbsp;</p>\n\n\n\n<p>Look at all the usual touch points, like rent statements, tenant sign up, IVR messaging and use these to promote the online service. From user research, I\u2019ve seen that people are more likely to trust a phone call over using an online tool. So explain how this tool can be trusted to get things logged and fixed. Promote the services to others in the community, like the sheltered housing wardens &#8211; can they show residents how to use it or be encouraged to use it on their residents\u2019 behalf?&nbsp;&nbsp;</p>\n\n\n\n<p>Also consider the complete journey. If your existing online repairs service results in a phone call to agree an appointment time, this only encourages the tenant to ring up next time. Confidence in an authority&#8217;s own digital maturity is built by showing the resident a complete online journey that leaves them informed of what&#8217;s happening next.</p>\n\n\n\n<p>If you\u2019re thinking of putting in place an online repair service it&#8217;s time to weigh up the pros and cons of having a login. The best way to do this is to get out and speak to the people who matter the most: those who\u2019ll be using it.&nbsp;</p>\n<p>The post <a href=\"https://www.madetech.com/blog/online-housing-repairs-no-login/\">Online housing repairs: why no login is the right fix</a> appeared first on <a href=\"https://www.madetech.com\">Made Tech</a>.</p>"
      }
    ]
  },
  "Universe": {
    "title": "Improving Browser Performance 10x",
    "xmlUrl": "https://engineering.universe.com/feed",
    "htmlUrl": "https://engineering.universe.com",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.universe.com/feed",
      "value": "Improving Browser Performance 10x"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.universe.com/improving-browser-performance-10x-f9551927dcff?source=rss----a1cd8e0d60b2---4"
      }
    ],
    "link": "https://engineering.universe.com/improving-browser-performance-10x-f9551927dcff?source=rss----a1cd8e0d60b2---4",
    "id": "https://medium.com/p/f9551927dcff",
    "guidislink": false,
    "tags": [
      {
        "term": "javascript",
        "scheme": null,
        "label": null
      },
      {
        "term": "react",
        "scheme": null,
        "label": null
      },
      {
        "term": "graphql",
        "scheme": null,
        "label": null
      },
      {
        "term": "puppeteer",
        "scheme": null,
        "label": null
      },
      {
        "term": "elixir",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "exAspArk"
      }
    ],
    "author": "exAspArk",
    "author_detail": {
      "name": "exAspArk"
    },
    "published": "Thu, 06 Jun 2019 15:08:10 GMT",
    "published_parsed": [
      2019,
      6,
      6,
      15,
      8,
      10,
      3,
      157,
      0
    ],
    "updated": "2019-07-12T13:57:03.417Z",
    "updated_parsed": [
      2019,
      7,
      12,
      13,
      57,
      3,
      4,
      193,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.universe.com/feed",
        "value": "<p>We recently improved the performance of the <a href=\"https://www.universe.com\">Universe.com</a> homepage by more than ten times. Let\u2019s explore the techniques we used to achieve this\u00a0result.</p><p><em>Here is a translated </em><a href=\"https://www.infoq.cn/article/XSKxPByXUVu1-O3OQsxD\"><em>Chinese version</em></a><em> of the blog post on\u00a0InfoQ.</em></p><p>But first, let\u2019s find out why website performance is important (there are links to the case studies at the end of the blog\u00a0post):</p><ul><li><strong>User experience</strong>: poor performance leads to unresponsiveness, which may be frustrating for users from a UI and UX perspective.</li><li><strong>Conversion and revenue</strong>: very often slow websites can lead to lost customers and have a negative impact on conversion rates and\u00a0revenue.</li><li><strong>SEO</strong>: Starting <a href=\"https://developers.google.com/search/mobile-sites/mobile-first-indexing\">July 1, 2019</a>, Google will enable mobile-first indexing by default for all new websites. Websites will be ranked lower if they are slow on mobile devices, and don\u2019t have mobile-friendly content.</li></ul><p>In this blog post, we will briefly cover these main areas, which helped us to improve the performance on our\u00a0pages:</p><ul><li><strong>Performance measurement</strong>:<strong> </strong>lab and field instruments.</li><li><strong>Rendering</strong>: client-side and server-side rendering, pre-rendering, and hybrid rendering approaches.</li><li><strong>Network</strong>: CDN, caching, GraphQL caching, encoding, HTTP/2 and Server\u00a0Push.</li><li><strong>JavaScript in the browser</strong>: bundle size budget, code-splitting, async and defer scripts, image optimizations (WebP, lazy loading, progressive), and resource hints (preload, prefetch, preconnect).</li></ul><p>For some context, our homepage is built with React (TypeScript), Phoenix (Elixir), Puppeteer (headless Chrome), and <a href=\"https://engineering.universe.com/why-were-betting-on-graphql-233ddf1a0779\">GraphQL API</a> (Ruby on Rails). This is how it looks like on\u00a0mobile:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*tVIdR8S8QOox_oMjFzNFdQ.png\" /><figcaption>Universe <a href=\"https://www.universe.com\">homepage</a> and\u00a0<a href=\"https://www.universe.com/explore\">explore</a></figcaption></figure><h3>Performance measurement</h3><blockquote>Without data, you\u2019re just another person with an opinion. \u2015 W. Edwards\u00a0Deming</blockquote><h4>Lab instruments</h4><p>Lab instruments allow collecting data within a controlled environment with the predefined device and network settings. With these instruments, it is much simpler to debug any performance issues and have well-reproducible tests.</p><p><a href=\"https://developers.google.com/web/tools/lighthouse/\">Lighthouse</a> is an excellent tool for auditing webpages in Chrome on a local computer. It also provides some useful tips on how to improve performance, accessibility, SEO, etc. Here are some Lighthouse performance audit reports with a Simulated Fast 3G and 4x CPU Slowdown:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2k4GOCN8mGhXGD8amp3Tvw.png\" /><figcaption>Before and after: 10x improvement for the <a href=\"https://developers.google.com/web/tools/lighthouse/audits/first-contentful-paint\">First Contentful Paint</a>\u00a0(FCP)</figcaption></figure><p>There is, however, a disadvantage of using just lab instruments: they don\u2019t necessarily capture real-world bottlenecks which may depend on the end-users\u2019 devices, network, location, and many other factors. That is why it is also important to use field instruments.</p><h4>Field instruments</h4><p>Field instruments allow to simulate and measure real user page loads. There are multiple services which can help to get real performance data from the actual\u00a0devices:</p><ul><li><a href=\"https://www.webpagetest.org/\">WebPageTest</a>\u200a\u2014\u200aallows performing tests from different browsers on real devices from various locations.</li><li><a href=\"https://www.thinkwithgoogle.com/feature/testmysite\">Test My Site</a>\u200a\u2014\u200auses Chrome User Experience Report (<a href=\"https://developers.google.com/web/tools/chrome-user-experience-report/\">CrUX</a>) which is based on Chrome usage statistics; it is publicly available and updated\u00a0monthly.</li><li><a href=\"https://developers.google.com/speed/pagespeed/insights/\">PageSpeed Insights</a>\u200a\u2014\u200acombines both lab (Lighthouse) and field (CrUX)\u00a0data.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4I--Fz3Rd9qy8_3QJv4cNg.png\" /><figcaption>WebPageTest report</figcaption></figure><h3>Rendering</h3><p>There are multiple approaches for rendering content, and each has its pros and\u00a0cons:</p><ul><li><strong>Server-side rendering</strong> (SSR) is a process of getting the final HTML documents for browsers on the server-side. <em>Pros</em>: search engines can crawl the website without executing JavaScript (SEO), fast initial page load, code lives only on the server-side. <em>Cons</em>: non-rich website interactions, the full page reloads, limited access to the browser features.</li><li><strong>Client-side rendering</strong> is a process of rendering content in the browser by using JavaScript. <em>Pros</em>: rich website interactions, fast rendering on route changes after the initial load, access to modern browser features (e.g. offline support with <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers\">Service Workers</a>). <em>Cons</em>: not SEO-friendly, slow initial page load, usually requires implementing a Single Page Application (SPA) and an API on the server-side.</li><li><strong>Pre-rendering</strong> is similar to server-side rendering but happens during buildtime in advance instead of runtime. <em>Pros</em>: serving built static files is usually simpler than running a server, SEO-friendly, fast initial page load. <em>Cons</em>: requires pre-rendering all possible pages in advance on any code changes, the full page reloads, non-rich website interactions, limited access to the browser features.</li></ul><h4>Client-side rendering</h4><p>Previously, we had our homepage implemented with Ember.js framework as a SPA with client-side rendering. One issue we had was a big bundle size of our Ember.js application. It means that users see just a blank screen while the browser downloads JavaScript files, parses, compiles, and executes\u00a0them:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EuN5a83NwTLEJZEek3ccjg.png\" /><figcaption>White screen of\u00a0death</figcaption></figure><p>We decided to rebuild some parts of the app by using\u00a0<a href=\"https://reactjs.org/\">React</a>.</p><ul><li>Our developers are already familiar with building React applications (e.g. <a href=\"https://www.universe.com/sell-on-your-site\">embedded widgets</a>).</li><li>We already have a few React component libraries which can be shared across multiple projects.</li><li>The <a href=\"https://www.universe.com/explore\">new pages</a> have some interactive UI elements.</li><li>There is a huge React ecosystem with lots of\u00a0tools.</li><li>With JavaScript in the browser, it is possible to build a <a href=\"https://developers.google.com/web/progressive-web-apps/\">Progressive Web App</a> with lots of nice features.</li></ul><h4>Pre-rendering and server-side rendering</h4><p>The issue with client-side rendered applications built, for example, with <a href=\"https://reacttraining.com/react-router/web/guides/quick-start\">React Router DOM</a> is still the same as with Ember.js. JavaScript is expensive, and it takes a while to see the First Contentful Paint in the\u00a0browser.</p><p>Once we decided on using React, we started experimenting with other potential rendering options to allow browsers to render the content\u00a0faster.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7dboVK-29_p73R9rp88CaQ.png\" /><figcaption>Conventional rendering options with\u00a0React</figcaption></figure><ul><li><a href=\"https://www.gatsbyjs.org\">Gatsby.js</a> allows pre-rendering pages with React and GraphQL. Gatsby.js is a great tool which supports many performance optimizations out of the box. However, using pre-rendering doesn\u2019t work for us since we have a potentially unlimited number of pages with user-generated content.</li><li><a href=\"https://nextjs.org\">Next.js</a> is a popular Node.js framework which allows server-side rendering with React. However, Next.js is very opinionated, requires to use its router, CSS solution, and so on. And our existing component libraries were built for browsers and are not compatible with\u00a0Node.js.</li></ul><p>That is why we decided to experiment with some <a href=\"https://www.youtube.com/watch?v=k-A2VfuUROg\">hybrid approaches</a>, which try taking the best from each rendering option.</p><h4>Runtime pre-rendering</h4><p><a href=\"https://github.com/GoogleChrome/puppeteer\">Puppeteer</a> is a Node.js library allows working with a headless Chrome. We wanted to give Puppeteer a try for pre-rendering in runtime. That enables using an interesting hybrid approach: server-side rendering with Puppeteer and client-side rendering with the <a href=\"https://reactjs.org/docs/react-dom.html#hydrate\">hydration</a>. Here are some useful tips by Google on <a href=\"https://developers.google.com/web/tools/puppeteer/articles/ssr\">how to use a headless browser</a> for server-side rendering.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZxsknHfPnPWPBF5s2Q0QwQ.png\" /><figcaption>Puppeteer for runtime pre-rendering a React application</figcaption></figure><p>Using this approach has some\u00a0pros:</p><ul><li>Allows SSR, which is good for SEO. Crawlers don\u2019t need to execute JavaScript to be able to see the\u00a0content.</li><li>Allows building a simple browser React application once, and using it both on the server-side and in browsers. Making the browser app faster automatically makes SSR faster,\u00a0win-win.</li><li>Rendering pages with Puppeteer on a server is usually faster than on end-users\u2019 mobile devices (better connection, better hardware).</li><li>Hydration allows building rich SPAs with access to the JavaScript browser features.</li><li>We don\u2019t need to know about all possible pages in advance in order to pre-render them.</li></ul><p>However, we faced a few challenges with this approach:</p><ul><li><strong>Throughput </strong>is the main issue. Having each request executed in a separate headless browser process uses up a lot of resources. It is possible to use a single headless browser process and run multiple requests in separate tabs. However, using multiple tabs decreases the performance of the whole\u00a0process.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jhXxF-C5U3bYARpv2ylgqg.png\" /><figcaption>The architecture of server-side rendering with Puppeteer</figcaption></figure><ul><li><strong>Stability</strong>. It is challenging to scale up or scale down many headless browsers, keep the processes \u201cwarm\u201d and balance the workload. We tried different hosting approaches: from being self-hosted in a Kubernetes cluster to serverless with AWS Lambda and Google Cloud Functions. We noticed that the latter had some performance <a href=\"https://github.com/GoogleChrome/puppeteer/issues/3120\">issues with Puppeteer</a>:</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*6QKWg6cnoMIyxwyVj7vrQA.png\" /><figcaption>Puppeteer response time on AWS Lambdas and GCP Functions</figcaption></figure><p>As we\u2019ve become more familiar with Puppeteer, we\u2019ve iterated our initial approach (read below). We also have some interesting ongoing experiments with rendering PDFs through a headless browser. It is also possible to use Puppeteer for automated end-to-end testing, even <a href=\"https://github.com/checkly/puppeteer-recorder\">without writing any code</a>. It now supports <a href=\"https://github.com/GoogleChrome/puppeteer/tree/master/experimental/puppeteer-firefox\">Firefox</a> in addition to\u00a0Chrome.</p><h4>Hybrid rendering approach</h4><p>Using Puppeteer in runtime is quite challenging. That\u2019s why we decided to use it in buildtime with the help of a tool which could return an actual user-generated content in runtime from the server-side. Something which is more stable and has a better throughput than Puppeteer.</p><p>We decided to try the Elixir programming language. Elixir looks like Ruby but runs on top of BEAM (Erlang VM), which was created to allow building fault-tolerant and stable\u00a0systems.</p><p>Elixir uses the <a href=\"https://engineering.universe.com/introduction-to-concurrency-models-with-ruby-part-ii-c39c7e612bed\">Actor concurrency model</a>. Each \u201cActor\u201d (Elixir process) has a tiny memory footprint of about around 1\u20132KB. That allows for running many thousands of isolated processes concurrently. <a href=\"https://phoenixframework.org\">Phoenix</a> is an Elixir web framework which enables high throughput and allows handling each HTTP request in a separate Elixir\u00a0process.</p><p>We combined these approaches by taking the best from each world, which satisfies our\u00a0needs:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1xL_bMidK0I-_llAkqDzow.png\" /><figcaption>Puppeteer for pre-rendering and Phoenix for server-side rendering</figcaption></figure><ul><li><strong>Puppeteer</strong> pre-renders React pages the way we want during buildtime and saves them in HTML files (app shell from the <a href=\"https://developers.google.com/web/fundamentals/performance/prpl-pattern/\">PRPL pattern</a>).</li></ul><p>We can keep building a simple browser React application and have a fast initial page load without waiting for JavaScript on end-users\u2019 devices.</p><ul><li>Our <strong>Phoenix</strong> application serves these pre-rendered pages and dynamically injects the actual content to the\u00a0HTML.</li></ul><p>That makes the content SEO friendly, allows processing a huge number of various pages on demand and scaling more\u00a0easily.</p><ul><li>Clients receive and start showing the HTML immediately, then hydrate the <strong>React DOM</strong> state to continue as a regular\u00a0SPA.</li></ul><p>That way, we can build highly interactive applications and have access to the JavaScript browser features.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*DUo0OJU_R1MoisQWdx5DIg.png\" /><figcaption>The architecture of pre-rendering with Puppeteer, server-side rendering with Phoenix, and hydration on the client-side with\u00a0React</figcaption></figure><h3>Network</h3><h4>Content delivery network\u00a0(CDN)</h4><p>Using a CDN enables content caching and allows to speed up its delivery across the world. We use <a href=\"https://www.fastly.com/\">Fastly.com</a>, which serves over 10% of all internet requests and is used by companies such as GitHub, Stripe, Airbnb, Twitter, and many\u00a0others.</p><p>Fastly allows us to write custom caching and routing logic by using the configuration language called <a href=\"https://varnish-cache.org/intro/index.html#intro\">VCL</a>. Here is how a basic request flow works where each step can be customized depending on the route, request headers, and so\u00a0on:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*n9ikPrah4AVBcFSkfHK9Ag.png\" /><figcaption><a href=\"https://book.varnish-software.com/3.0/VCL_Basics.html\">VCL request\u00a0flow</a></figcaption></figure><p>Another option to improve performance is to use WebAssembly (WASM) at the edge with <a href=\"https://wasm.fastlylabs.com/\">Fastly</a>. Think of it like using serverless but at the edge with such programming languages as C, Rust, Go, TypeScript, etc. Cloudflare has a similar project to support WASM on\u00a0<a href=\"https://blog.cloudflare.com/webassembly-on-cloudflare-workers/\">Workers</a>.</p><h4>Caching</h4><p>It is important to cache as many requests as possible to improve performance. Caching on a CDN level allows delivering responses faster for new users. Caching by sending a <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control\">Cache-Control</a> header allows speeding up response time for the repeated requests in the\u00a0browser.</p><p>Most of the build tools such as <a href=\"https://webpack.js.org/guides/caching/\">Webpack</a> allow adding a hash to the filename. These files can be safely cached since changing the files will create a new output filename.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZHCCu0P_YJk4cjb9oIo6rg.png\" /><figcaption>Cached and encoded files through\u00a0HTTP/2</figcaption></figure><h4>GraphQL caching</h4><p>One of the most common ways of sending GraphQL requests is to use the POST HTTP method. One approach we use is to cache some GraphQL requests on Fastly\u00a0level:</p><ul><li>Our React app annotates the GraphQL queries which can be\u00a0cached.</li><li>Before sending an HTTP request, we append a URL argument by building a hash from a request body, which includes the GraphQL query and variables (we use custom fetch with <a href=\"https://www.apollographql.com/docs/link/links/http/\">Apollo\u00a0Client</a>).</li><li>Varnish (and Fastly) by default uses the full URL as part of the <a href=\"https://varnish-cache.org/docs/trunk/users-guide/vcl-hashing.html\">cache\u00a0key</a>.</li><li>That allows us to keep sending POST requests with GraphQL query in the request body and cache at the edge without hitting our\u00a0servers.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HZUWoW17DrxddIfgPffbBA.png\" /><figcaption>Sending POST GraphQL requests with a SHA256 URL\u00a0argument</figcaption></figure><p>Here are some other potential GraphQL cache strategies to consider:</p><ul><li>Cache on the server-side: the whole GraphQL requests, on the resolver level or declaratively by annotating the\u00a0schema.</li><li>Using persisted GraphQL queries and sending GET /graphql/:queryId to be able to rely on HTTP\u00a0caching.</li><li>Integrate with CDNs by using automated tools (e.g. <a href=\"https://blog.apollographql.com/automatic-persisted-queries-and-cdn-caching-with-apollo-server-2-0-bf42b3a313de\">Apollo Server 2.0</a>) or use GraphQL-specific CDNs (e.g.\u00a0<a href=\"https://fastql.io\">FastQL</a>).</li></ul><h4>Encoding</h4><p>All major browsers support gzip with the <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding#Compressing_with_gzip\">Content-Encoding</a> header to compress data. That allows sending fewer bytes to browsers, which usually means faster content delivery. It is also possible to use a more effective <a href=\"https://caniuse.com/#search=brotli\">brotli</a> compression algorithm in supported browsers.</p><h4>HTTP/2 protocol</h4><p><a href=\"https://http2.github.io/faq/\">HTTP/2</a> is a new version of the HTTP network protocol (h2 in DevConsole). Switching to HTTP/2 may improve performance, thanks to these differences compared to HTTP/1.x:</p><ul><li>HTTP/2 is binary, not textual. It is more efficient to parse, more\u00a0compact.</li><li>HTTP/2 is multiplexed, which means that that HTTP/2 can send multiple requests in parallel over a single TCP connection. It allows us not to worry about browser <a href=\"https://www.browserscope.org/?category=network&amp;v=top\">connections per host limits</a> and domain sharding.</li><li>It uses header compression to reduce request / response size overhead.</li><li>Allows servers to push responses proactively. This feature is particularly interesting.</li></ul><h4>HTTP/2 Server\u00a0Push</h4><p>There are a lot of programming languages and libraries which don\u2019t fully support all HTTP/2 features because they introduce breaking changes for existing tools and the ecosystem (e.g. <a href=\"https://github.com/tenderlove/the_metal/issues/5\">rack</a>). But even in this case, it is still possible to use HTTP/2, at least partially. For\u00a0example:</p><ul><li>Set up a proxy server such as <a href=\"https://h2o.examp1e.net\">h2o</a> or <a href=\"https://www.nginx.com/\">nginx</a> with HTTP/2 in front of a regular HTTP/1.x server. E.g. Puma and Ruby on Rails can send <a href=\"https://eileencodes.com/posts/http2-early-hints/\">Early Hints</a>, which can enable HTTP/2 Server Push with some <a href=\"https://tools.ietf.org/html/draft-ietf-httpbis-early-hints-05\">limitations</a>.</li><li>Use a CDN which support HTTP/2 to serve static assets. For instance, we use this approach to push fonts and some JavaScript files to the\u00a0clients.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CWybQ36g0z0jGr2eBKaIWg.png\" /><figcaption>HTTP/2 Push\u00a0fonts</figcaption></figure><p>Pushing critical JavaScript and CSS can also be very useful. Just don\u2019t over-push and be aware of some\u00a0<a href=\"https://jakearchibald.com/2017/h2-push-tougher-than-i-thought/\">gotchas</a>.</p><h3>JavaScript in the\u00a0browser</h3><h4>Bundle size\u00a0budget</h4><blockquote>The #1 JavaScript performance rule is not to use JavaScript. \u2015\u00a0me</blockquote><p>If you already have an existing JavaScript application, setting a budget can improve visibility of the bundle size and keep everybody on the same page. Exceeding the budget forces developers to think twice about the changes and to minimize the size increase. These are some examples of how to set a\u00a0budget:</p><ul><li>Use numbers based on your needs or some recommended values. For instance, <a href=\"https://infrequently.org/2017/10/can-you-afford-it-real-world-web-performance-budgets/\">&lt; 170KB</a> minified and compressed JavaScript.</li><li>Use the current bundle size as a baseline or try to reduce it by, for example,\u00a010%.</li><li>Try to have the fastest website among your competitors and set the budget accordingly.</li></ul><p>You could use the <a href=\"https://github.com/siddharthkp/bundlesize\">bundlesize</a> package or Webpack performance <a href=\"https://webpack.js.org/configuration/performance/\">hints and limits</a> to keep track of the\u00a0budget:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0ZB70_gEdwiRejXOY1GerA.png\" /><figcaption>Webpack performance hints and\u00a0limits</figcaption></figure><h4>Kill your dependencies</h4><p>That\u2019s the title of the popular <a href=\"https://www.mikeperham.com/2016/02/09/kill-your-dependencies/\">blog post </a>written by the author of\u00a0Sidekiq.</p><blockquote>No code runs faster than no code. No code has fewer bugs than no code. No code uses less memory than no code. No code is easier to understand than no\u00a0code.</blockquote><p>Unfortunately, the reality with JavaScript dependencies is that your project most probably uses many hundreds of dependencies. Just try ls node_modules | wc\u00a0-l.</p><p>In some cases adding a dependency is necessary. In this case, the dependency bundle size should be one of the criteria when <a href=\"https://engineering.universe.com/building-a-google-map-in-react-b103b4ee97f1\">choosing between multiple packages</a>. I highly recommend using <a href=\"https://bundlephobia.com\">BundlePhobia</a>:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Zih5TOhOO3cmvif0-cqTOQ.png\" /><figcaption>BundlePhobia finds the cost of adding an npm package to your\u00a0bundle</figcaption></figure><h4>Code-splitting</h4><p>Using code-splitting is perhaps the best way to significantly improve JavaScript performance. It allows splitting the code and shipping only the part which a user needs at the moment. Here are some examples of code-splitting:</p><ul><li>Routes are loaded separately in separate JavaScript chunks.</li><li>Components on a page which are not visible immediately. E.g. modals, footer which is below the\u00a0fold.</li><li><a href=\"https://en.wikipedia.org/wiki/Polyfill_(programming)\">Polyfills</a> and <a href=\"https://github.com/sindresorhus/ponyfill\">ponyfills</a> to support the latest browser features in all major browsers.</li><li>Prevent code duplication by using Webpack\u2019s <a href=\"https://webpack.js.org/guides/code-splitting/#prevent-duplication\">SplitChunksPlugin</a>.</li><li>Locales files on demand to avoid shipping all our supported languages at\u00a0once.</li></ul><p>You can use code-splitting with Webpack <a href=\"https://webpack.js.org/guides/code-splitting/#dynamic-imports\">dynamic imports</a> and <a href=\"https://reactjs.org/docs/code-splitting.html\">React.lazy with </a><a href=\"https://reactjs.org/docs/code-splitting.html\">Suspense</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Zhc6IuCP83J0b_VsU2r2GQ.png\" /><figcaption>Code-splitting with dynamic import and React.lazy with\u00a0Suspense</figcaption></figure><p>We built a function instead of React.lazy to support named exports rather than <a href=\"https://humanwhocodes.com/blog/2019/01/stop-using-default-exports-javascript-module/\">default\u00a0exports</a>.</p><h4>Async and defer\u00a0scripts</h4><p>All major browsers support async and defer attributes on script\u00a0tags:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*DWQMEjjJOtUckpzxfPnU5Q.png\" /><figcaption>Different ways of loading JavaScript</figcaption></figure><ul><li>Inline scripts are useful for loading small critical JavaScript code.</li><li>Using a script with async is useful for fetching JavaScript without blocking HTML parsing when the script is not required for your users or any other scripts (e.g. analytics scripts).</li><li>Using scripts with defer is probably the best way from a performance point of view for fetching and executing non-critical JavaScript without blocking HTML parsing. Additionally, it guarantees the execution order as the scripts are called, which is useful if one script depends on\u00a0another.</li></ul><p>Here is a visualized difference between the scripts in a head\u00a0tag:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Cv943YbZsYv3ca1j9mugeg.png\" /><figcaption>Different ways of script fetching and execution</figcaption></figure><h4>Image optimizations</h4><p>Although 100 KB of JavaScript has a very different performance cost compared to 100 KB of images, it is in general important to keep the images as light as possible.</p><p>One way of reducing the image size is to use a more lightweight <a href=\"https://caniuse.com/#search=webp\">WebP</a> image format in supported browsers. For browsers which don\u2019t support WebP, it is possible to use one of the following strategies:</p><ul><li>Fallback to regular JPEG or PNG formats (some CDNs do it automatically based on a browser\u2019s Accept request\u00a0header).</li><li>Loading and using <a href=\"https://webpjs.appspot.com/\">WebP polyfill</a> after <a href=\"https://github.com/Modernizr/Modernizr/blob/7231dd32a3e30b4c2ec337bebcd822e3397ae9b6/feature-detects/img/webp.js\">detecting</a> browser\u00a0support.</li><li>Using Service Workers to listen to fetch requests and the changing actual URLs to use WebP if it is supported.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2-ctSFlE7tn3E3r2gkWD0w.png\" /><figcaption>WebP images</figcaption></figure><p>Loading the images lazily only when they are in or near the viewport is one of the most significant performance improvements for initial page loads with lots of images. You can either use the <a href=\"https://developers.google.com/web/fundamentals/performance/lazy-loading-guidance/images-and-video/\">IntersectionObserver</a> feature in supported browsers or use some alternative tools to achieve the same result, for example, <a href=\"https://github.com/twobin/react-lazyload\">react-lazyload</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HnO4pIDXGh2Y_z4Ylw88TQ.gif\" /><figcaption>Lazy loading images during the\u00a0scroll</figcaption></figure><p>Some other image optimizations may\u00a0include:</p><ul><li>Reducing the quality of images to reduce the\u00a0size.</li><li>Resizing and loading the smallest possible\u00a0images.</li><li>Using the <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Element/img#attr-srcset\">srcset</a> image attribute for automatically loading high-quality images for high-resolution retina displays.</li><li>Using progressive images to show a blurry image immediately.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*R2BsJEZDYxcyZ4lxff8S5g.png\" /><figcaption>Loading regular vs progressive images</figcaption></figure><p>You can consider using some generic CDNs or specialized image CDNs which usually implement most of these image optimizations.</p><h4>Resource hints</h4><p><a href=\"https://www.w3.org/TR/resource-hints/\">Resource hints</a> allow us to optimize the delivery of resources, reduce round trips, and fetch resources to deliver content faster while a user is browsing a\u00a0page.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gBecKBYO3iWwZkoxZN1eaQ.png\" /><figcaption>Resource hints with link\u00a0tags</figcaption></figure><ul><li><a href=\"https://caniuse.com/#search=preload\">Preload</a> downloads resources in the background for the current page load before they are actually used on the current page (high priority).</li><li><a href=\"https://caniuse.com/#search=prefetch\">Prefetch</a> works similarly to preload to fetch the resources and cache them but for future user\u2019s navigations (low priority).</li><li><a href=\"https://caniuse.com/#search=preconnect\">Preconnect</a> allows to set up early connections before an HTTP request is actually sent to the\u00a0server.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vWY-CYuzPei-KsAD3ajAzQ.png\" /><figcaption>Preconnect in advance to avoid DNS, TCP, TLS roundtrip latencies</figcaption></figure><p>There are also some other resource hints such as <a href=\"https://caniuse.com/#search=prerender\">prerender</a> or <a href=\"https://caniuse.com/#search=dns-prefetch\">dns-prefetch</a>. Some of these resource hints can be specified in response headers. Just be careful when using resource hints. It is quite simple to start making too many unnecessary requests and downloading too much data, especially if users use a <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Network_Information_API\">cellular connection</a>.</p><h3>Conclusion</h3><p>Performance in a growing application is a neverending process which usually requires constant changes across the whole\u00a0stack.</p><blockquote>This video reminds me of you wanting to decrease the app bundle size.\u200a\u2014\u200aMy colleague</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TKFLqi1OlFIm32wdZAhGXg.gif\" /><figcaption>Strip everything out of this plane you don\u2019t need now! \u2013 <a href=\"https://en.wikipedia.org/wiki/Pearl_Harbor_(film)\">Pearl Harbor</a>\u00a0movie</figcaption></figure><p>Here is a list of other potential performance improvements we use or are planning to try which were not mentioned previously:</p><ul><li>Using Service Workers for caching, offline support, and offloading the main\u00a0thread.</li><li>Inlining critical CSS or using functional CSS to decrease the size over the long-term.</li><li>Using font formats such as WOFF2 instead of WOFF (up to 50%+ compression).</li><li>Keeping the <a href=\"https://github.com/browserslist/browserslist\">browserslist</a> up to\u00a0date.</li><li>Using the <a href=\"https://github.com/webpack-contrib/webpack-bundle-analyzer\">webpack-bundle-analyzer</a> to analyze build chunks visually.</li><li>Preferring smaller packages (e.g. <a href=\"https://github.com/date-fns/date-fns\">date-fns</a>) and plugins which allow reducing the size (e.g. <a href=\"https://github.com/lodash/lodash-webpack-plugin\">lodash-webpack-plugin</a>).</li><li>Trying <a href=\"https://github.com/preactjs/preact\">preact</a>, <a href=\"https://github.com/Polymer/lit-html\">lit-html</a> or\u00a0<a href=\"https://github.com/sveltejs/svelte\">svelte</a>.</li><li>Running <a href=\"https://github.com/GoogleChromeLabs/lighthousebot\">Lighthouse in\u00a0CI</a>.</li><li><a href=\"https://github.com/GoogleChromeLabs/progressive-rendering-frameworks-samples\">Progressive hydration</a> and <a href=\"https://twitter.com/dan_abramov/status/1079352276433715200?lang=en\">streaming with\u00a0React</a>.</li></ul><p>There is an endless number of exciting ideas to try. I hope this information and some of these case studies will inspire you to think about performance in your application:</p><blockquote><a href=\"https://www.fastcompany.com/1825005/how-one-second-could-cost-amazon-16-billion-sales\">Amazon has calculated</a> that a page load slowdown of just 1 second could cost it $1.6 billion in sales each\u00a0year.</blockquote><blockquote><a href=\"https://wpostats.com/2015/11/04/walmart-revenue.html\">Walmart saw</a> up to a 2% increase in conversions for every 1 second of improvement in load time. Every 100ms improvement also resulted in up to a 1% increase in\u00a0revenue.</blockquote><blockquote><a href=\"https://www.fastcompany.com/1825005/how-one-second-could-cost-amazon-16-billion-sales\">Google has calculated</a> that by slowing its search results by just 0.4 of a second, they could lose 8 million searches per\u00a0day.</blockquote><blockquote><a href=\"https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7\">Rebuilding Pinterest pages</a> for performance resulted in a 40% decrease in wait time, a 15% increase in SEO traffic, and a 15% increase in conversion rate to\u00a0signup.</blockquote><blockquote><a href=\"https://www.creativebloq.com/features/how-the-bbc-builds-websites-that-scale\">BBC has seen</a> that they lose an additional 10% of users for every additional second it takes for their site to\u00a0load.</blockquote><blockquote>Tests of the new faster <a href=\"https://www.wsj.com/articles/financial-times-hopes-speedy-new-website-will-boost-subscribers-1475553602\">FT.com showed</a> users were up to 30% more engaged\u200a\u2014\u200ameaning more visits and more content being consumed.</blockquote><blockquote><a href=\"https://instagram-engineering.com/performance-usage-at-instagram-d2ba0347e442\">Instagram increased</a> impressions and user profile scroll interactions by 33% for the median by decreasing the response size of the JSON needed for displaying comments.</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/478/1*2hpMzRgc8T4BoUcevMdC1g.png\" /></figure><blockquote>Universe.com increased the number of crawled pages 10 times by improving browser performance 10\u00a0times.</blockquote><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f9551927dcff\" width=\"1\" /><hr /><p><a href=\"https://engineering.universe.com/improving-browser-performance-10x-f9551927dcff\">Improving Browser Performance 10x</a> was originally published in <a href=\"https://engineering.universe.com\">Universe Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p>We recently improved the performance of the <a href=\"https://www.universe.com\">Universe.com</a> homepage by more than ten times. Let\u2019s explore the techniques we used to achieve this\u00a0result.</p><p><em>Here is a translated </em><a href=\"https://www.infoq.cn/article/XSKxPByXUVu1-O3OQsxD\"><em>Chinese version</em></a><em> of the blog post on\u00a0InfoQ.</em></p><p>But first, let\u2019s find out why website performance is important (there are links to the case studies at the end of the blog\u00a0post):</p><ul><li><strong>User experience</strong>: poor performance leads to unresponsiveness, which may be frustrating for users from a UI and UX perspective.</li><li><strong>Conversion and revenue</strong>: very often slow websites can lead to lost customers and have a negative impact on conversion rates and\u00a0revenue.</li><li><strong>SEO</strong>: Starting <a href=\"https://developers.google.com/search/mobile-sites/mobile-first-indexing\">July 1, 2019</a>, Google will enable mobile-first indexing by default for all new websites. Websites will be ranked lower if they are slow on mobile devices, and don\u2019t have mobile-friendly content.</li></ul><p>In this blog post, we will briefly cover these main areas, which helped us to improve the performance on our\u00a0pages:</p><ul><li><strong>Performance measurement</strong>:<strong> </strong>lab and field instruments.</li><li><strong>Rendering</strong>: client-side and server-side rendering, pre-rendering, and hybrid rendering approaches.</li><li><strong>Network</strong>: CDN, caching, GraphQL caching, encoding, HTTP/2 and Server\u00a0Push.</li><li><strong>JavaScript in the browser</strong>: bundle size budget, code-splitting, async and defer scripts, image optimizations (WebP, lazy loading, progressive), and resource hints (preload, prefetch, preconnect).</li></ul><p>For some context, our homepage is built with React (TypeScript), Phoenix (Elixir), Puppeteer (headless Chrome), and <a href=\"https://engineering.universe.com/why-were-betting-on-graphql-233ddf1a0779\">GraphQL API</a> (Ruby on Rails). This is how it looks like on\u00a0mobile:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*tVIdR8S8QOox_oMjFzNFdQ.png\" /><figcaption>Universe <a href=\"https://www.universe.com\">homepage</a> and\u00a0<a href=\"https://www.universe.com/explore\">explore</a></figcaption></figure><h3>Performance measurement</h3><blockquote>Without data, you\u2019re just another person with an opinion. \u2015 W. Edwards\u00a0Deming</blockquote><h4>Lab instruments</h4><p>Lab instruments allow collecting data within a controlled environment with the predefined device and network settings. With these instruments, it is much simpler to debug any performance issues and have well-reproducible tests.</p><p><a href=\"https://developers.google.com/web/tools/lighthouse/\">Lighthouse</a> is an excellent tool for auditing webpages in Chrome on a local computer. It also provides some useful tips on how to improve performance, accessibility, SEO, etc. Here are some Lighthouse performance audit reports with a Simulated Fast 3G and 4x CPU Slowdown:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2k4GOCN8mGhXGD8amp3Tvw.png\" /><figcaption>Before and after: 10x improvement for the <a href=\"https://developers.google.com/web/tools/lighthouse/audits/first-contentful-paint\">First Contentful Paint</a>\u00a0(FCP)</figcaption></figure><p>There is, however, a disadvantage of using just lab instruments: they don\u2019t necessarily capture real-world bottlenecks which may depend on the end-users\u2019 devices, network, location, and many other factors. That is why it is also important to use field instruments.</p><h4>Field instruments</h4><p>Field instruments allow to simulate and measure real user page loads. There are multiple services which can help to get real performance data from the actual\u00a0devices:</p><ul><li><a href=\"https://www.webpagetest.org/\">WebPageTest</a>\u200a\u2014\u200aallows performing tests from different browsers on real devices from various locations.</li><li><a href=\"https://www.thinkwithgoogle.com/feature/testmysite\">Test My Site</a>\u200a\u2014\u200auses Chrome User Experience Report (<a href=\"https://developers.google.com/web/tools/chrome-user-experience-report/\">CrUX</a>) which is based on Chrome usage statistics; it is publicly available and updated\u00a0monthly.</li><li><a href=\"https://developers.google.com/speed/pagespeed/insights/\">PageSpeed Insights</a>\u200a\u2014\u200acombines both lab (Lighthouse) and field (CrUX)\u00a0data.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4I--Fz3Rd9qy8_3QJv4cNg.png\" /><figcaption>WebPageTest report</figcaption></figure><h3>Rendering</h3><p>There are multiple approaches for rendering content, and each has its pros and\u00a0cons:</p><ul><li><strong>Server-side rendering</strong> (SSR) is a process of getting the final HTML documents for browsers on the server-side. <em>Pros</em>: search engines can crawl the website without executing JavaScript (SEO), fast initial page load, code lives only on the server-side. <em>Cons</em>: non-rich website interactions, the full page reloads, limited access to the browser features.</li><li><strong>Client-side rendering</strong> is a process of rendering content in the browser by using JavaScript. <em>Pros</em>: rich website interactions, fast rendering on route changes after the initial load, access to modern browser features (e.g. offline support with <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers\">Service Workers</a>). <em>Cons</em>: not SEO-friendly, slow initial page load, usually requires implementing a Single Page Application (SPA) and an API on the server-side.</li><li><strong>Pre-rendering</strong> is similar to server-side rendering but happens during buildtime in advance instead of runtime. <em>Pros</em>: serving built static files is usually simpler than running a server, SEO-friendly, fast initial page load. <em>Cons</em>: requires pre-rendering all possible pages in advance on any code changes, the full page reloads, non-rich website interactions, limited access to the browser features.</li></ul><h4>Client-side rendering</h4><p>Previously, we had our homepage implemented with Ember.js framework as a SPA with client-side rendering. One issue we had was a big bundle size of our Ember.js application. It means that users see just a blank screen while the browser downloads JavaScript files, parses, compiles, and executes\u00a0them:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EuN5a83NwTLEJZEek3ccjg.png\" /><figcaption>White screen of\u00a0death</figcaption></figure><p>We decided to rebuild some parts of the app by using\u00a0<a href=\"https://reactjs.org/\">React</a>.</p><ul><li>Our developers are already familiar with building React applications (e.g. <a href=\"https://www.universe.com/sell-on-your-site\">embedded widgets</a>).</li><li>We already have a few React component libraries which can be shared across multiple projects.</li><li>The <a href=\"https://www.universe.com/explore\">new pages</a> have some interactive UI elements.</li><li>There is a huge React ecosystem with lots of\u00a0tools.</li><li>With JavaScript in the browser, it is possible to build a <a href=\"https://developers.google.com/web/progressive-web-apps/\">Progressive Web App</a> with lots of nice features.</li></ul><h4>Pre-rendering and server-side rendering</h4><p>The issue with client-side rendered applications built, for example, with <a href=\"https://reacttraining.com/react-router/web/guides/quick-start\">React Router DOM</a> is still the same as with Ember.js. JavaScript is expensive, and it takes a while to see the First Contentful Paint in the\u00a0browser.</p><p>Once we decided on using React, we started experimenting with other potential rendering options to allow browsers to render the content\u00a0faster.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7dboVK-29_p73R9rp88CaQ.png\" /><figcaption>Conventional rendering options with\u00a0React</figcaption></figure><ul><li><a href=\"https://www.gatsbyjs.org\">Gatsby.js</a> allows pre-rendering pages with React and GraphQL. Gatsby.js is a great tool which supports many performance optimizations out of the box. However, using pre-rendering doesn\u2019t work for us since we have a potentially unlimited number of pages with user-generated content.</li><li><a href=\"https://nextjs.org\">Next.js</a> is a popular Node.js framework which allows server-side rendering with React. However, Next.js is very opinionated, requires to use its router, CSS solution, and so on. And our existing component libraries were built for browsers and are not compatible with\u00a0Node.js.</li></ul><p>That is why we decided to experiment with some <a href=\"https://www.youtube.com/watch?v=k-A2VfuUROg\">hybrid approaches</a>, which try taking the best from each rendering option.</p><h4>Runtime pre-rendering</h4><p><a href=\"https://github.com/GoogleChrome/puppeteer\">Puppeteer</a> is a Node.js library allows working with a headless Chrome. We wanted to give Puppeteer a try for pre-rendering in runtime. That enables using an interesting hybrid approach: server-side rendering with Puppeteer and client-side rendering with the <a href=\"https://reactjs.org/docs/react-dom.html#hydrate\">hydration</a>. Here are some useful tips by Google on <a href=\"https://developers.google.com/web/tools/puppeteer/articles/ssr\">how to use a headless browser</a> for server-side rendering.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZxsknHfPnPWPBF5s2Q0QwQ.png\" /><figcaption>Puppeteer for runtime pre-rendering a React application</figcaption></figure><p>Using this approach has some\u00a0pros:</p><ul><li>Allows SSR, which is good for SEO. Crawlers don\u2019t need to execute JavaScript to be able to see the\u00a0content.</li><li>Allows building a simple browser React application once, and using it both on the server-side and in browsers. Making the browser app faster automatically makes SSR faster,\u00a0win-win.</li><li>Rendering pages with Puppeteer on a server is usually faster than on end-users\u2019 mobile devices (better connection, better hardware).</li><li>Hydration allows building rich SPAs with access to the JavaScript browser features.</li><li>We don\u2019t need to know about all possible pages in advance in order to pre-render them.</li></ul><p>However, we faced a few challenges with this approach:</p><ul><li><strong>Throughput </strong>is the main issue. Having each request executed in a separate headless browser process uses up a lot of resources. It is possible to use a single headless browser process and run multiple requests in separate tabs. However, using multiple tabs decreases the performance of the whole\u00a0process.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jhXxF-C5U3bYARpv2ylgqg.png\" /><figcaption>The architecture of server-side rendering with Puppeteer</figcaption></figure><ul><li><strong>Stability</strong>. It is challenging to scale up or scale down many headless browsers, keep the processes \u201cwarm\u201d and balance the workload. We tried different hosting approaches: from being self-hosted in a Kubernetes cluster to serverless with AWS Lambda and Google Cloud Functions. We noticed that the latter had some performance <a href=\"https://github.com/GoogleChrome/puppeteer/issues/3120\">issues with Puppeteer</a>:</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*6QKWg6cnoMIyxwyVj7vrQA.png\" /><figcaption>Puppeteer response time on AWS Lambdas and GCP Functions</figcaption></figure><p>As we\u2019ve become more familiar with Puppeteer, we\u2019ve iterated our initial approach (read below). We also have some interesting ongoing experiments with rendering PDFs through a headless browser. It is also possible to use Puppeteer for automated end-to-end testing, even <a href=\"https://github.com/checkly/puppeteer-recorder\">without writing any code</a>. It now supports <a href=\"https://github.com/GoogleChrome/puppeteer/tree/master/experimental/puppeteer-firefox\">Firefox</a> in addition to\u00a0Chrome.</p><h4>Hybrid rendering approach</h4><p>Using Puppeteer in runtime is quite challenging. That\u2019s why we decided to use it in buildtime with the help of a tool which could return an actual user-generated content in runtime from the server-side. Something which is more stable and has a better throughput than Puppeteer.</p><p>We decided to try the Elixir programming language. Elixir looks like Ruby but runs on top of BEAM (Erlang VM), which was created to allow building fault-tolerant and stable\u00a0systems.</p><p>Elixir uses the <a href=\"https://engineering.universe.com/introduction-to-concurrency-models-with-ruby-part-ii-c39c7e612bed\">Actor concurrency model</a>. Each \u201cActor\u201d (Elixir process) has a tiny memory footprint of about around 1\u20132KB. That allows for running many thousands of isolated processes concurrently. <a href=\"https://phoenixframework.org\">Phoenix</a> is an Elixir web framework which enables high throughput and allows handling each HTTP request in a separate Elixir\u00a0process.</p><p>We combined these approaches by taking the best from each world, which satisfies our\u00a0needs:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1xL_bMidK0I-_llAkqDzow.png\" /><figcaption>Puppeteer for pre-rendering and Phoenix for server-side rendering</figcaption></figure><ul><li><strong>Puppeteer</strong> pre-renders React pages the way we want during buildtime and saves them in HTML files (app shell from the <a href=\"https://developers.google.com/web/fundamentals/performance/prpl-pattern/\">PRPL pattern</a>).</li></ul><p>We can keep building a simple browser React application and have a fast initial page load without waiting for JavaScript on end-users\u2019 devices.</p><ul><li>Our <strong>Phoenix</strong> application serves these pre-rendered pages and dynamically injects the actual content to the\u00a0HTML.</li></ul><p>That makes the content SEO friendly, allows processing a huge number of various pages on demand and scaling more\u00a0easily.</p><ul><li>Clients receive and start showing the HTML immediately, then hydrate the <strong>React DOM</strong> state to continue as a regular\u00a0SPA.</li></ul><p>That way, we can build highly interactive applications and have access to the JavaScript browser features.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*DUo0OJU_R1MoisQWdx5DIg.png\" /><figcaption>The architecture of pre-rendering with Puppeteer, server-side rendering with Phoenix, and hydration on the client-side with\u00a0React</figcaption></figure><h3>Network</h3><h4>Content delivery network\u00a0(CDN)</h4><p>Using a CDN enables content caching and allows to speed up its delivery across the world. We use <a href=\"https://www.fastly.com/\">Fastly.com</a>, which serves over 10% of all internet requests and is used by companies such as GitHub, Stripe, Airbnb, Twitter, and many\u00a0others.</p><p>Fastly allows us to write custom caching and routing logic by using the configuration language called <a href=\"https://varnish-cache.org/intro/index.html#intro\">VCL</a>. Here is how a basic request flow works where each step can be customized depending on the route, request headers, and so\u00a0on:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*n9ikPrah4AVBcFSkfHK9Ag.png\" /><figcaption><a href=\"https://book.varnish-software.com/3.0/VCL_Basics.html\">VCL request\u00a0flow</a></figcaption></figure><p>Another option to improve performance is to use WebAssembly (WASM) at the edge with <a href=\"https://wasm.fastlylabs.com/\">Fastly</a>. Think of it like using serverless but at the edge with such programming languages as C, Rust, Go, TypeScript, etc. Cloudflare has a similar project to support WASM on\u00a0<a href=\"https://blog.cloudflare.com/webassembly-on-cloudflare-workers/\">Workers</a>.</p><h4>Caching</h4><p>It is important to cache as many requests as possible to improve performance. Caching on a CDN level allows delivering responses faster for new users. Caching by sending a <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control\">Cache-Control</a> header allows speeding up response time for the repeated requests in the\u00a0browser.</p><p>Most of the build tools such as <a href=\"https://webpack.js.org/guides/caching/\">Webpack</a> allow adding a hash to the filename. These files can be safely cached since changing the files will create a new output filename.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZHCCu0P_YJk4cjb9oIo6rg.png\" /><figcaption>Cached and encoded files through\u00a0HTTP/2</figcaption></figure><h4>GraphQL caching</h4><p>One of the most common ways of sending GraphQL requests is to use the POST HTTP method. One approach we use is to cache some GraphQL requests on Fastly\u00a0level:</p><ul><li>Our React app annotates the GraphQL queries which can be\u00a0cached.</li><li>Before sending an HTTP request, we append a URL argument by building a hash from a request body, which includes the GraphQL query and variables (we use custom fetch with <a href=\"https://www.apollographql.com/docs/link/links/http/\">Apollo\u00a0Client</a>).</li><li>Varnish (and Fastly) by default uses the full URL as part of the <a href=\"https://varnish-cache.org/docs/trunk/users-guide/vcl-hashing.html\">cache\u00a0key</a>.</li><li>That allows us to keep sending POST requests with GraphQL query in the request body and cache at the edge without hitting our\u00a0servers.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HZUWoW17DrxddIfgPffbBA.png\" /><figcaption>Sending POST GraphQL requests with a SHA256 URL\u00a0argument</figcaption></figure><p>Here are some other potential GraphQL cache strategies to consider:</p><ul><li>Cache on the server-side: the whole GraphQL requests, on the resolver level or declaratively by annotating the\u00a0schema.</li><li>Using persisted GraphQL queries and sending GET /graphql/:queryId to be able to rely on HTTP\u00a0caching.</li><li>Integrate with CDNs by using automated tools (e.g. <a href=\"https://blog.apollographql.com/automatic-persisted-queries-and-cdn-caching-with-apollo-server-2-0-bf42b3a313de\">Apollo Server 2.0</a>) or use GraphQL-specific CDNs (e.g.\u00a0<a href=\"https://fastql.io\">FastQL</a>).</li></ul><h4>Encoding</h4><p>All major browsers support gzip with the <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding#Compressing_with_gzip\">Content-Encoding</a> header to compress data. That allows sending fewer bytes to browsers, which usually means faster content delivery. It is also possible to use a more effective <a href=\"https://caniuse.com/#search=brotli\">brotli</a> compression algorithm in supported browsers.</p><h4>HTTP/2 protocol</h4><p><a href=\"https://http2.github.io/faq/\">HTTP/2</a> is a new version of the HTTP network protocol (h2 in DevConsole). Switching to HTTP/2 may improve performance, thanks to these differences compared to HTTP/1.x:</p><ul><li>HTTP/2 is binary, not textual. It is more efficient to parse, more\u00a0compact.</li><li>HTTP/2 is multiplexed, which means that that HTTP/2 can send multiple requests in parallel over a single TCP connection. It allows us not to worry about browser <a href=\"https://www.browserscope.org/?category=network&amp;v=top\">connections per host limits</a> and domain sharding.</li><li>It uses header compression to reduce request / response size overhead.</li><li>Allows servers to push responses proactively. This feature is particularly interesting.</li></ul><h4>HTTP/2 Server\u00a0Push</h4><p>There are a lot of programming languages and libraries which don\u2019t fully support all HTTP/2 features because they introduce breaking changes for existing tools and the ecosystem (e.g. <a href=\"https://github.com/tenderlove/the_metal/issues/5\">rack</a>). But even in this case, it is still possible to use HTTP/2, at least partially. For\u00a0example:</p><ul><li>Set up a proxy server such as <a href=\"https://h2o.examp1e.net\">h2o</a> or <a href=\"https://www.nginx.com/\">nginx</a> with HTTP/2 in front of a regular HTTP/1.x server. E.g. Puma and Ruby on Rails can send <a href=\"https://eileencodes.com/posts/http2-early-hints/\">Early Hints</a>, which can enable HTTP/2 Server Push with some <a href=\"https://tools.ietf.org/html/draft-ietf-httpbis-early-hints-05\">limitations</a>.</li><li>Use a CDN which support HTTP/2 to serve static assets. For instance, we use this approach to push fonts and some JavaScript files to the\u00a0clients.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CWybQ36g0z0jGr2eBKaIWg.png\" /><figcaption>HTTP/2 Push\u00a0fonts</figcaption></figure><p>Pushing critical JavaScript and CSS can also be very useful. Just don\u2019t over-push and be aware of some\u00a0<a href=\"https://jakearchibald.com/2017/h2-push-tougher-than-i-thought/\">gotchas</a>.</p><h3>JavaScript in the\u00a0browser</h3><h4>Bundle size\u00a0budget</h4><blockquote>The #1 JavaScript performance rule is not to use JavaScript. \u2015\u00a0me</blockquote><p>If you already have an existing JavaScript application, setting a budget can improve visibility of the bundle size and keep everybody on the same page. Exceeding the budget forces developers to think twice about the changes and to minimize the size increase. These are some examples of how to set a\u00a0budget:</p><ul><li>Use numbers based on your needs or some recommended values. For instance, <a href=\"https://infrequently.org/2017/10/can-you-afford-it-real-world-web-performance-budgets/\">&lt; 170KB</a> minified and compressed JavaScript.</li><li>Use the current bundle size as a baseline or try to reduce it by, for example,\u00a010%.</li><li>Try to have the fastest website among your competitors and set the budget accordingly.</li></ul><p>You could use the <a href=\"https://github.com/siddharthkp/bundlesize\">bundlesize</a> package or Webpack performance <a href=\"https://webpack.js.org/configuration/performance/\">hints and limits</a> to keep track of the\u00a0budget:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0ZB70_gEdwiRejXOY1GerA.png\" /><figcaption>Webpack performance hints and\u00a0limits</figcaption></figure><h4>Kill your dependencies</h4><p>That\u2019s the title of the popular <a href=\"https://www.mikeperham.com/2016/02/09/kill-your-dependencies/\">blog post </a>written by the author of\u00a0Sidekiq.</p><blockquote>No code runs faster than no code. No code has fewer bugs than no code. No code uses less memory than no code. No code is easier to understand than no\u00a0code.</blockquote><p>Unfortunately, the reality with JavaScript dependencies is that your project most probably uses many hundreds of dependencies. Just try ls node_modules | wc\u00a0-l.</p><p>In some cases adding a dependency is necessary. In this case, the dependency bundle size should be one of the criteria when <a href=\"https://engineering.universe.com/building-a-google-map-in-react-b103b4ee97f1\">choosing between multiple packages</a>. I highly recommend using <a href=\"https://bundlephobia.com\">BundlePhobia</a>:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Zih5TOhOO3cmvif0-cqTOQ.png\" /><figcaption>BundlePhobia finds the cost of adding an npm package to your\u00a0bundle</figcaption></figure><h4>Code-splitting</h4><p>Using code-splitting is perhaps the best way to significantly improve JavaScript performance. It allows splitting the code and shipping only the part which a user needs at the moment. Here are some examples of code-splitting:</p><ul><li>Routes are loaded separately in separate JavaScript chunks.</li><li>Components on a page which are not visible immediately. E.g. modals, footer which is below the\u00a0fold.</li><li><a href=\"https://en.wikipedia.org/wiki/Polyfill_(programming)\">Polyfills</a> and <a href=\"https://github.com/sindresorhus/ponyfill\">ponyfills</a> to support the latest browser features in all major browsers.</li><li>Prevent code duplication by using Webpack\u2019s <a href=\"https://webpack.js.org/guides/code-splitting/#prevent-duplication\">SplitChunksPlugin</a>.</li><li>Locales files on demand to avoid shipping all our supported languages at\u00a0once.</li></ul><p>You can use code-splitting with Webpack <a href=\"https://webpack.js.org/guides/code-splitting/#dynamic-imports\">dynamic imports</a> and <a href=\"https://reactjs.org/docs/code-splitting.html\">React.lazy with </a><a href=\"https://reactjs.org/docs/code-splitting.html\">Suspense</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Zhc6IuCP83J0b_VsU2r2GQ.png\" /><figcaption>Code-splitting with dynamic import and React.lazy with\u00a0Suspense</figcaption></figure><p>We built a function instead of React.lazy to support named exports rather than <a href=\"https://humanwhocodes.com/blog/2019/01/stop-using-default-exports-javascript-module/\">default\u00a0exports</a>.</p><h4>Async and defer\u00a0scripts</h4><p>All major browsers support async and defer attributes on script\u00a0tags:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*DWQMEjjJOtUckpzxfPnU5Q.png\" /><figcaption>Different ways of loading JavaScript</figcaption></figure><ul><li>Inline scripts are useful for loading small critical JavaScript code.</li><li>Using a script with async is useful for fetching JavaScript without blocking HTML parsing when the script is not required for your users or any other scripts (e.g. analytics scripts).</li><li>Using scripts with defer is probably the best way from a performance point of view for fetching and executing non-critical JavaScript without blocking HTML parsing. Additionally, it guarantees the execution order as the scripts are called, which is useful if one script depends on\u00a0another.</li></ul><p>Here is a visualized difference between the scripts in a head\u00a0tag:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Cv943YbZsYv3ca1j9mugeg.png\" /><figcaption>Different ways of script fetching and execution</figcaption></figure><h4>Image optimizations</h4><p>Although 100 KB of JavaScript has a very different performance cost compared to 100 KB of images, it is in general important to keep the images as light as possible.</p><p>One way of reducing the image size is to use a more lightweight <a href=\"https://caniuse.com/#search=webp\">WebP</a> image format in supported browsers. For browsers which don\u2019t support WebP, it is possible to use one of the following strategies:</p><ul><li>Fallback to regular JPEG or PNG formats (some CDNs do it automatically based on a browser\u2019s Accept request\u00a0header).</li><li>Loading and using <a href=\"https://webpjs.appspot.com/\">WebP polyfill</a> after <a href=\"https://github.com/Modernizr/Modernizr/blob/7231dd32a3e30b4c2ec337bebcd822e3397ae9b6/feature-detects/img/webp.js\">detecting</a> browser\u00a0support.</li><li>Using Service Workers to listen to fetch requests and the changing actual URLs to use WebP if it is supported.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2-ctSFlE7tn3E3r2gkWD0w.png\" /><figcaption>WebP images</figcaption></figure><p>Loading the images lazily only when they are in or near the viewport is one of the most significant performance improvements for initial page loads with lots of images. You can either use the <a href=\"https://developers.google.com/web/fundamentals/performance/lazy-loading-guidance/images-and-video/\">IntersectionObserver</a> feature in supported browsers or use some alternative tools to achieve the same result, for example, <a href=\"https://github.com/twobin/react-lazyload\">react-lazyload</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HnO4pIDXGh2Y_z4Ylw88TQ.gif\" /><figcaption>Lazy loading images during the\u00a0scroll</figcaption></figure><p>Some other image optimizations may\u00a0include:</p><ul><li>Reducing the quality of images to reduce the\u00a0size.</li><li>Resizing and loading the smallest possible\u00a0images.</li><li>Using the <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Element/img#attr-srcset\">srcset</a> image attribute for automatically loading high-quality images for high-resolution retina displays.</li><li>Using progressive images to show a blurry image immediately.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*R2BsJEZDYxcyZ4lxff8S5g.png\" /><figcaption>Loading regular vs progressive images</figcaption></figure><p>You can consider using some generic CDNs or specialized image CDNs which usually implement most of these image optimizations.</p><h4>Resource hints</h4><p><a href=\"https://www.w3.org/TR/resource-hints/\">Resource hints</a> allow us to optimize the delivery of resources, reduce round trips, and fetch resources to deliver content faster while a user is browsing a\u00a0page.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gBecKBYO3iWwZkoxZN1eaQ.png\" /><figcaption>Resource hints with link\u00a0tags</figcaption></figure><ul><li><a href=\"https://caniuse.com/#search=preload\">Preload</a> downloads resources in the background for the current page load before they are actually used on the current page (high priority).</li><li><a href=\"https://caniuse.com/#search=prefetch\">Prefetch</a> works similarly to preload to fetch the resources and cache them but for future user\u2019s navigations (low priority).</li><li><a href=\"https://caniuse.com/#search=preconnect\">Preconnect</a> allows to set up early connections before an HTTP request is actually sent to the\u00a0server.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vWY-CYuzPei-KsAD3ajAzQ.png\" /><figcaption>Preconnect in advance to avoid DNS, TCP, TLS roundtrip latencies</figcaption></figure><p>There are also some other resource hints such as <a href=\"https://caniuse.com/#search=prerender\">prerender</a> or <a href=\"https://caniuse.com/#search=dns-prefetch\">dns-prefetch</a>. Some of these resource hints can be specified in response headers. Just be careful when using resource hints. It is quite simple to start making too many unnecessary requests and downloading too much data, especially if users use a <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Network_Information_API\">cellular connection</a>.</p><h3>Conclusion</h3><p>Performance in a growing application is a neverending process which usually requires constant changes across the whole\u00a0stack.</p><blockquote>This video reminds me of you wanting to decrease the app bundle size.\u200a\u2014\u200aMy colleague</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TKFLqi1OlFIm32wdZAhGXg.gif\" /><figcaption>Strip everything out of this plane you don\u2019t need now! \u2013 <a href=\"https://en.wikipedia.org/wiki/Pearl_Harbor_(film)\">Pearl Harbor</a>\u00a0movie</figcaption></figure><p>Here is a list of other potential performance improvements we use or are planning to try which were not mentioned previously:</p><ul><li>Using Service Workers for caching, offline support, and offloading the main\u00a0thread.</li><li>Inlining critical CSS or using functional CSS to decrease the size over the long-term.</li><li>Using font formats such as WOFF2 instead of WOFF (up to 50%+ compression).</li><li>Keeping the <a href=\"https://github.com/browserslist/browserslist\">browserslist</a> up to\u00a0date.</li><li>Using the <a href=\"https://github.com/webpack-contrib/webpack-bundle-analyzer\">webpack-bundle-analyzer</a> to analyze build chunks visually.</li><li>Preferring smaller packages (e.g. <a href=\"https://github.com/date-fns/date-fns\">date-fns</a>) and plugins which allow reducing the size (e.g. <a href=\"https://github.com/lodash/lodash-webpack-plugin\">lodash-webpack-plugin</a>).</li><li>Trying <a href=\"https://github.com/preactjs/preact\">preact</a>, <a href=\"https://github.com/Polymer/lit-html\">lit-html</a> or\u00a0<a href=\"https://github.com/sveltejs/svelte\">svelte</a>.</li><li>Running <a href=\"https://github.com/GoogleChromeLabs/lighthousebot\">Lighthouse in\u00a0CI</a>.</li><li><a href=\"https://github.com/GoogleChromeLabs/progressive-rendering-frameworks-samples\">Progressive hydration</a> and <a href=\"https://twitter.com/dan_abramov/status/1079352276433715200?lang=en\">streaming with\u00a0React</a>.</li></ul><p>There is an endless number of exciting ideas to try. I hope this information and some of these case studies will inspire you to think about performance in your application:</p><blockquote><a href=\"https://www.fastcompany.com/1825005/how-one-second-could-cost-amazon-16-billion-sales\">Amazon has calculated</a> that a page load slowdown of just 1 second could cost it $1.6 billion in sales each\u00a0year.</blockquote><blockquote><a href=\"https://wpostats.com/2015/11/04/walmart-revenue.html\">Walmart saw</a> up to a 2% increase in conversions for every 1 second of improvement in load time. Every 100ms improvement also resulted in up to a 1% increase in\u00a0revenue.</blockquote><blockquote><a href=\"https://www.fastcompany.com/1825005/how-one-second-could-cost-amazon-16-billion-sales\">Google has calculated</a> that by slowing its search results by just 0.4 of a second, they could lose 8 million searches per\u00a0day.</blockquote><blockquote><a href=\"https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7\">Rebuilding Pinterest pages</a> for performance resulted in a 40% decrease in wait time, a 15% increase in SEO traffic, and a 15% increase in conversion rate to\u00a0signup.</blockquote><blockquote><a href=\"https://www.creativebloq.com/features/how-the-bbc-builds-websites-that-scale\">BBC has seen</a> that they lose an additional 10% of users for every additional second it takes for their site to\u00a0load.</blockquote><blockquote>Tests of the new faster <a href=\"https://www.wsj.com/articles/financial-times-hopes-speedy-new-website-will-boost-subscribers-1475553602\">FT.com showed</a> users were up to 30% more engaged\u200a\u2014\u200ameaning more visits and more content being consumed.</blockquote><blockquote><a href=\"https://instagram-engineering.com/performance-usage-at-instagram-d2ba0347e442\">Instagram increased</a> impressions and user profile scroll interactions by 33% for the median by decreasing the response size of the JSON needed for displaying comments.</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/478/1*2hpMzRgc8T4BoUcevMdC1g.png\" /></figure><blockquote>Universe.com increased the number of crawled pages 10 times by improving browser performance 10\u00a0times.</blockquote><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f9551927dcff\" width=\"1\" /><hr /><p><a href=\"https://engineering.universe.com/improving-browser-performance-10x-f9551927dcff\">Improving Browser Performance 10x</a> was originally published in <a href=\"https://engineering.universe.com\">Universe Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Asana": {
    "title": "Scaling a Mature iOS Codebase with\u00a0Tuist",
    "xmlUrl": "https://blog.asana.com/feed/",
    "htmlUrl": "https://blog.asana.com/category/eng/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blog.asana.com/feed/",
      "value": "Scaling a Mature iOS Codebase with\u00a0Tuist"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blog.asana.com/2023/02/scaling-a-mature-ios-codebase-with-tuist/"
      }
    ],
    "link": "https://blog.asana.com/2023/02/scaling-a-mature-ios-codebase-with-tuist/",
    "comments": "https://blog.asana.com/2023/02/scaling-a-mature-ios-codebase-with-tuist/#respond",
    "authors": [
      {
        "name": "Steve Landey"
      }
    ],
    "author": "Steve Landey",
    "author_detail": {
      "name": "Steve Landey"
    },
    "published": "Tue, 21 Feb 2023 19:53:23 +0000",
    "published_parsed": [
      2023,
      2,
      21,
      19,
      53,
      23,
      1,
      52,
      0
    ],
    "tags": [
      {
        "term": "Engineering",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://blog.asana.com/?p=14352",
    "guidislink": false,
    "summary": "<p>Six months ago, it usually took 45 seconds to make a change to a feature in the Asana iOS app and rebuild it. Today, it usually takes 15 seconds. The Mobile Foundations team achieved this by migrating our Xcode project to Tuist and splitting the code into several modules, enabled by some modest refactors. In [&#8230;]</p>\n<p>The post <a href=\"https://blog.asana.com/2023/02/scaling-a-mature-ios-codebase-with-tuist/\" rel=\"nofollow\">Scaling a Mature iOS Codebase with&nbsp;Tuist</a> appeared first on <a href=\"https://blog.asana.com\" rel=\"nofollow\">The Asana Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blog.asana.com/feed/",
      "value": "<p>Six months ago, it usually took 45 seconds to make a change to a feature in the Asana iOS app and rebuild it. Today, it usually takes 15 seconds. The Mobile Foundations team achieved this by migrating our Xcode project to Tuist and splitting the code into several modules, enabled by some modest refactors. In [&#8230;]</p>\n<p>The post <a href=\"https://blog.asana.com/2023/02/scaling-a-mature-ios-codebase-with-tuist/\" rel=\"nofollow\">Scaling a Mature iOS Codebase with&nbsp;Tuist</a> appeared first on <a href=\"https://blog.asana.com\" rel=\"nofollow\">The Asana Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://blog.asana.com/feed/",
        "value": "<div class=\"wpcollab-hello-emoji\">\n<p>Six months ago, it usually took 45 seconds to make a change to a feature in the Asana iOS app and rebuild it. Today, it usually takes 15 seconds.</p>\n\n\n\n<p>The Mobile Foundations team achieved this by migrating our Xcode project to <a href=\"https://tuist.io\">Tuist</a> and splitting the code into several modules, enabled by some modest refactors. In this article, I&#8217;ll describe how we decided what path to take, and how you can make similar changes in your own codebase.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Where we were</strong></h2>\n\n\n\n<p>Coming into 2022, we had about ten engineers maintaining about 300,000 lines of Swift code. Almost all of it was compiled into a single build target, Asana. The Swift compiler was doing a decent job of building it all; if you made a change, you could see it reflected in the simulator in just 45 seconds or so. (Unless you were using an Intel Mac, in which case it would be more like 90 seconds.)</p>\n\n\n\n<p>Once in a while, two people would make changes to the Xcode project file that would cause a merge conflict. It would take time to sort these out each time they occurred, but we learned to live with it.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>The decision to make a change</strong></h2>\n\n\n\n<p>We expected to add more people to the team. Build times would affect more people, and we knew we&#8217;d keep writing more code, so the builds would get slower.</p>\n\n\n\n<p>One way to make builds faster is to build less stuff each time, which in the Swift world means splitting code into modules. If code in module A depends on module B, and module A changes but module B does not, then module B does not need to be recompiled in order to get a working app binary.</p>\n\n\n\n<p>Splitting the code into modules came with two challenges: the developer experience of creating the modules, and refactoring our code to allow different types to exist in different modules.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Choosing to use Tuist to make module creation trivial</strong></h2>\n\n\n\n<p>Splitting the codebase into modules required either adopting a new tool, or choosing to deal with the native Xcode workflow. We spent time investigating four options.</p>\n\n\n\n<p>While looking at these options, our most important criterion was the developer experience. We knew modules would make the build faster, but if we sacrificed developer experience in other ways, the gains would be useless. However, we also looked at the adoption cost of each tool, and whether they support remote build caching and selective test execution.</p>\n\n\n\n<p>The option with the lowest starting cost was to use Xcode&#8217;s built-in GUI to manually add new build targets. While this approach is cheap to prototype and doesn&#8217;t require new dependencies, we&#8217;d have needed to write a graphical runbook to help people make new modules, and it would have still been error-prone and tedious. We wouldn&#8217;t be able to automate adding files to the project, or defining dependencies.</p>\n\n\n\n<p>Another option was to use Xcode&#8217;s native Swift Package Manager support, and create local Swift packages. We prototyped this, but the developer experience still wasn&#8217;t very good, especially tracking down the root causes of compiler errors. Additionally, writing Package.swift files by hand was just about as error-prone and tedious as working with the Xcode GUI. The local modules we tried to create all had very similar and repetitive Package.swift files, and those files couldn&#8217;t share code.</p>\n\n\n\n<p>Many companies use <a href=\"https://github.com/bazelbuild/rules_apple/blob/master/doc/tutorials/ios-app.md\">Bazel</a> to manage their iOS builds. We investigated Bazel, but found serious issues with its developer experience. Bazel is a very heavyweight set of tools that requires new mental models, and we ran into workflow-breaking issues with breakpoints.</p>\n\n\n\n<p>The last thing we looked at was <a href=\"https://tuist.io\">Tuist</a>, a relatively new project which generates Xcode projects from Swift source code. We found almost no downsides.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Tuist\u2019s advantages</strong></h2>\n\n\n\n<p>Tuist is a command-line tool that automates the creation of Xcode projects and workspaces. Swift code in a Tuist manifest has full access to the Foundation framework. With this power, we believed we could write a Tuist manifest that would automate nearly every task to be based on the filesystem, not manual configuration. There would be an onboarding process for people who did need to make changes for special cases, but the day-to-day experience of an iOS engineer would be that things just work, and they could use Xcode without thinking about Tuist. This all came true, with the help of&nbsp; some light Python scripting to automate creating new modules.</p>\n\n\n\n<p>A few aspects of Tuist reduce the risk of a migration going wrong. Tuist&#8217;s output is an Xcode project, so we could always go back to checking the project into source control and stop generating it with Tuist. Also, Tuist&#8217;s documentation is really good, so we wouldn&#8217;t need to do as much work writing our own internal docs. Finally, being written in Swift, we felt we could contribute code back to the project if we needed to fix a bug.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Migrating to Tuist</strong></h2>\n\n\n\n<p>Tuist has one limitation we needed to overcome: lack of first-party support for CocoaPods. So first, we needed to migrate all our CocoaPods dependencies to Swift Package Manager or Carthage. Fortunately, all our dependencies supported one or the other.</p>\n\n\n\n<p>Then, we needed to migrate all our build settings to .xcconfig files using <code><a href=\"https://docs.tuist.io/guides/adopting-tuist\">tuist migration settings-to-xcconfig</a></code>. This was straightforward.</p>\n\n\n\n<p>With the prep work done, we were able to write a Tuist &#8220;manifest&#8221; (project definition) from scratch. This part took a couple weeks, and we did need to keep tweaking this for months as we made new modules and discovered subtle errors we had made during the migration, but none of those were really Tuist&#8217;s fault.</p>\n\n\n\n<p>Finally, once the Tuist manifest was in a state where engineers could reasonably be asked to use its output, we wrote git hooks to run <code>tuist generate</code> on every <code>git checkout</code>, and removed the old Xcode project from source control.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Refactoring to support modules</strong></h2>\n\n\n\n<p>When all our code was in a single module, we had never needed the <code>public</code> keyword, so we never used it. Thousands of classes, methods, and properties needed to be made public. We eventually resolved this by writing a Python script that could parse Swift code and mark every internal symbol in a file as <code>public</code>, and running it on various files as needed.</p>\n\n\n\n<p>Our other big problem was circular dependencies. Consider Asana&#8217;s project view and task view: a project needs to open a task, and you can then open a project from within that task. We needed a way for <code>ProjectViewController</code> and <code>TaskDetailsViewController</code> to instantiate each other. We solved this problem using something resembling Tuist&#8217;s <a href=\"https://docs.tuist.io/building-at-scale/microfeatures\">\u00b5Features architecture</a>, which puts a feature&#8217;s public interface in its own module. Refactoring code to use this pattern was the most arduous and manual step, because in most cases we were cutting dependency boundaries for the first time, often in very old code.</p>\n\n\n\n<p>Both of these changes were applied to different parts of the codebase at different times over months. Just a little at first, then a lot as we broke out new modules, then just a little again when the dust settled.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Actually making the modules</strong></h2>\n\n\n\n<p>The first thing we did after making the Tuist manifest was to put almost all of the code except <code>AppDelegate</code> into a big module called <code>AsanaCore</code>. We wanted to discover and fix workflow issues as soon as possible. We chose to use static libraries.</p>\n\n\n\n<p>The main workflow issues we encountered after creating AsanaCore were:</p>\n\n\n\n<ol>\n<li>We use <code>NSKeyed[Un]Archiver</code> to store unsynced user actions. We needed to tell <code>NSKeyedUnarchiver</code> <a href=\"https://developer.apple.com/documentation/foundation/nskeyedunarchiver/1409718-setclass\">how to find types</a> that had been saved using a different module name so user data wasn&#8217;t lost.</li>\n\n\n\n<li>Our XLIFF string exports from Xcode had different metadata, which made a huge diff in our translation backend. We fixed this and other issues by writing Python code to patch the XLIFF files after export and before import.</li>\n\n\n\n<li>Importing XLIFFs back into Xcode didn&#8217;t work at first, because although Xcode was happy to export strings in <code>AsanaCore</code>, it didn&#8217;t recognize them for some reason on import, so it would discard all of them. We fixed this in a really silly way: manually generate a Swift file containing all strings, add it to the app target (using Tuist of course), and then delete it after import. String lookups continue to work just fine.</li>\n</ol>\n\n\n\n<p>The localization stuff was hairy, but the challenges were within our reach and the solutions didn&#8217;t need to be touched after being written. Teams that use different approaches to localization than we do might have an easier time. And the localization challenges weren&#8217;t Tuist&#8217;s fault\u2014after all, it was just generating projects the way we asked it to.</p>\n\n\n\n<p>With the workflow issues fixed, our build graph still looked pretty simple. We had a &#8220;module,&#8221; but no build time savings. Really the worst possible world to be in, though it wasn&#8217;t perceptibly worse than before.</p>\n\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh4.googleusercontent.com/OrvGNQq8bWpTbBqebqzStMcKR7iuU0pk8tCBI-DxLPcoucsO3YJkxx88-HT_IR2XR1G_aCYGTJPGd1db4RnpN7EI1dyeKbMFJM-2PxozOJXljbQZnMkYYV5nwLXeVSWjMLvf2AQD9l0k1Ew6lOT9JRw\" /></figure>\n\n\n\n<p>From here, our approach was to &#8220;lift&#8221; features upward out of <code>AsanaCore</code>, and &#8220;push&#8221; non-feature code downward out of <code>AsanaCore</code> into more granular frameworks. The first big feature module we pulled out of <code>AsanaCore</code> was <code>Inbox</code>:</p>\n\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh3.googleusercontent.com/Xb6a3pgo-1R2VqdqYEw-Mfc4g-2KOAsUwPRjgPO5ZYRdqOALBtavoK3SDkpykZWCgh-Mf5qmHDQeeVJnTpL_vEVQhM28VUWBKD9TaDur_tvDE67pElB8sCfAgunSHQ0lAGZ1n4rAS2iyZkrO020Hb3E\" /></figure>\n\n\n\n<p>The reason we chose Inbox is because Inbox calls other code a lot, but not much other code calls Inbox.&nbsp; It was a perfect test of whether our modules-make-good-build-times hypothesis was correct.</p>\n\n\n\n<p>Well, it was correct. Incremental build times for changing a line of Inbox code went from 30-50 seconds to 4 seconds.</p>\n\n\n\n<p>Once we had our first feature module, we began creating more, ranging from 5,000 to 30,000 lines of code. At the same time, we found ways to carve other parts of <code>AsanaCore</code> out into framework-level modules. Eventually, <code>AsanaCore</code> contained just 21% of the code in the app. Pushing code up from <code>AsanaCore</code> into feature modules reduced time spent rebuilding feature code an engineer wasn&#8217;t actively working on, while pushing code &#8220;down&#8221; from <code>AsanaCore</code> into a framework reduced time spent rebuilding code that rarely changed at all during feature development.</p>\n\n\n\n<p>We spent about 3 months incrementally moving code into modules. We&#8217;d establish a beachhead with just a few files, then migrate code into the new module a bit at a time. We also wrote a command line script that could both move files between modules and update their imports.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Where we are now</strong></h2>\n\n\n\n<p>Our Tuist manifest is about 1,400 lines. A lot of this is intrinsic complexity, doing different things depending on environment variables related to different build types (debug, TestFlight, nightly, etc). Some of it is automation, so it just takes a few lines to add a new module. There&#8217;s very little code that doesn&#8217;t have a critical role in the project definition.</p>\n\n\n\n<p>Our median build time is 15 seconds. We do wish it were even lower, and we expect to get there eventually using build caching, but for now we&#8217;re very happy with our progress. We log all our build times to Scalyr, so I can show you the distribution:</p>\n\n\n\n<figure class=\"wp-block-image\"><img alt=\"Distribution of build times, evenly distributed on a log scale between zero and 200 seconds, with a spike at 15 seconds.\" src=\"https://lh6.googleusercontent.com/swDFoMBuIY-7OnTiOtdq3DdBLJYiF4X_2tmej_eWlq_C-UwhNDf9_S9aSRuT4QfHq63Yo6Tgo1Mn-YrQcGAVXixLFayGxzmaOFzFfnSW1tjhg8QPxmrrZRZRLMZyfNBXL4rATgTTMOPmCJDWU603xC0\" /><figcaption class=\"wp-element-caption\">X axis: seconds to build on a log scale. Y axis: number of builds during the period.</figcaption></figure>\n\n\n\n<p>We&#8217;d love to know whether the type of module modified in a given build affects that build&#8217;s duration, but unfortunately we haven&#8217;t been able to get trustworthy data out of Xcode build logs to find out.</p>\n\n\n\n<p>Our module graph now looks something like this:</p>\n\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh6.googleusercontent.com/FMRxlzFz_6JIrpQWkIu6WmgK3J1r04gULk4kju8r0UTO1kaFncFphzZ6zUGmZpwUl_7HM9GygekN9tNsihUnHZuKytcEqQPWlEqOQMfHdtSFYeOQhf2io0Hdf5hGssayp0shRS52OIN47GJ0C10HiTY\" /></figure>\n\n\n\n<p>Splitting the frameworks below <code>AsanaCore</code> like this doesn&#8217;t affect build times much, but down the road, we expect it will let us skip running test suites for code that changes rarely unless that code has been changed.</p>\n\n\n\n<p>Here&#8217;s the breakdown of module size. We&#8217;re roughly where we expected to be, although we hope to get even more code out of <code>AsanaCore</code>, since it mostly represents old features we haven&#8217;t chosen to refactor yet, or code that doesn&#8217;t have a clear home at the moment.</p>\n\n\n\n<figure class=\"wp-block-image\"><img alt=\"Pie chart showing the percentage of code that each module represents. AsanaCore is 21%, CommonUI is 15%, AsanaData is 14%, and then about ten smaller modules take up the other half.\" src=\"https://lh6.googleusercontent.com/HTHzhXr3K0Muu0lAGCQZTiSuzPaFyFxyW3rc77Ffh5HAec665wF12QA0tYFC-ML0NCVaZl22RZ7Lilq1khifwLXKzCemU2L7BEya6CgSx7G44KVdzEr4EZdJfQ1GL5PSTFC-9e2om51iq2nGkcT6020\" /></figure>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Was it worth it? Should you do the same?</strong></h2>\n\n\n\n<p>With the benefit of hindsight, everyone on the team agrees Tuist has been a hugely positive change. While the migration brought new issues, the benefits are well worth the cost of dealing with those issues.</p>\n\n\n\n<h3 class=\"wp-block-heading\">New problems</h3>\n\n\n\n<p>Tuist is a complex new tool that only a minority of our iOS engineers are comfortable with. We&#8217;ve found that having 3+ Tuist experts is fine in practice, but we&#8217;re always working to help everyone become comfortable with <code>tuist edit</code>. On the bright side, it&#8217;s very rare for anyone to need to edit the Tuist manifest unless they&#8217;re working on some build performance or developer experience improvement.</p>\n\n\n\n<p><code>git checkout</code> takes 5-15 seconds longer than it used to. We wish this were faster, but we also appreciate that we don&#8217;t need to deal with project file merge conflicts at all anymore.</p>\n\n\n\n<p>Using modules has forced us to write a bit more boilerplate code to separate interfaces from implementations. However, in some ways this was a positive change, forcing us to be more explicit about API boundaries between objects.</p>\n\n\n\n<h3 class=\"wp-block-heading\">New benefits</h3>\n\n\n\n<ol>\n<li>Autocomplete works better with modules. Xcode seems much more capable of dealing with many small modules rather than a single big one, perhaps because it can cache its index per target instead of constantly having the current target&#8217;s index invalidated by trivial changes.</li>\n\n\n\n<li>Treating project configuration as code makes sense when your app is complex. It&#8217;s easy to leave comments on changes to the Tuist manifest on a GitHub pull request or in the code, which wasn&#8217;t true at all when we&#8217;d change the Xcode project in the GUI. Project-file-related merge conflicts are all gone.</li>\n\n\n\n<li>Repetitive changes are easy to make. Making a new module requires running one command on the command line and then adding the implementation.</li>\n\n\n\n<li>Being able to completely rely on the filesystem as the arbiter of a file&#8217;s target membership has prevented many errors and drastically reduced the number of clicks it takes to move a group of files between targets. Xcode often guesses wrong which target a new file should belong to, but our handwritten Tuist rules are always right.</li>\n\n\n\n<li>I&#8217;ve said it many times in this article, but it&#8217;s worth saying again: builds are much faster!</li>\n</ol>\n\n\n\n<p>There are additional benefits we haven&#8217;t yet reached for, particularly in the realm of CI. We&#8217;re looking forward to running our tests in parallel, caching build artifacts more aggressively, and running only tests affected by changed code in a PR, rather than running all tests on every PR.</p>\n\n\n\n<p>Personally, if I were starting a new iOS project today, even as a solo developer, I&#8217;d use Tuist from day one. Any team that can deal with the extra complexity should make the switch. Building your own Project.swift from scratch will teach you enough to understand and maintain it.</p>\n\n\n\n<p>We love Tuist so much that we sponsored the project this year. The maintainers have always been responsive and helpful. Thank you for everything, Tuist maintainers!</p>\n</div><p>The post <a href=\"https://blog.asana.com/2023/02/scaling-a-mature-ios-codebase-with-tuist/\" rel=\"nofollow\">Scaling a Mature iOS Codebase with&nbsp;Tuist</a> appeared first on <a href=\"https://blog.asana.com\" rel=\"nofollow\">The Asana Blog</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://blog.asana.com/2023/02/scaling-a-mature-ios-codebase-with-tuist/feed/",
    "slash_comments": "0"
  },
  "Shopify": {
    "title": "Getting Started with React Native Skia",
    "xmlUrl": "https://shopify.engineering/blog.atom",
    "htmlUrl": "https://shopify.engineering/",
    "id": "https://shopify.engineering/getting-started-with-react-native-skia",
    "guidislink": true,
    "link": "https://shopify.engineering/getting-started-with-react-native-skia",
    "published": "2023-12-04T10:00:03-05:00",
    "published_parsed": [
      2023,
      12,
      4,
      15,
      0,
      3,
      0,
      338,
      0
    ],
    "updated": "2023-12-04T10:00:03-05:00",
    "updated_parsed": [
      2023,
      12,
      4,
      15,
      0,
      3,
      0,
      338,
      0
    ],
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://shopify.engineering/getting-started-with-react-native-skia"
      }
    ],
    "title_detail": {
      "type": "text/plain",
      "language": "en",
      "base": "https://shopify.engineering/blog.atom",
      "value": "Getting Started with React Native Skia"
    },
    "authors": [
      {
        "name": "Daniel Friyia"
      }
    ],
    "author_detail": {
      "name": "Daniel Friyia"
    },
    "author": "Daniel Friyia"
  },
  "Netflix": {
    "title": "Rebuilding Netflix Video Processing Pipeline with Microservices",
    "xmlUrl": "https://medium.com/feed/netflix-techblog",
    "htmlUrl": "https://medium.com/netflix-techblog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/netflix-techblog",
      "value": "Rebuilding Netflix Video Processing Pipeline with Microservices"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://netflixtechblog.com/rebuilding-netflix-video-processing-pipeline-with-microservices-4e5e6310e359?source=rss----2615bd06b42e---4"
      }
    ],
    "link": "https://netflixtechblog.com/rebuilding-netflix-video-processing-pipeline-with-microservices-4e5e6310e359?source=rss----2615bd06b42e---4",
    "id": "https://medium.com/p/4e5e6310e359",
    "guidislink": false,
    "tags": [
      {
        "term": "video-encoding",
        "scheme": null,
        "label": null
      },
      {
        "term": "microservices",
        "scheme": null,
        "label": null
      },
      {
        "term": "netflix",
        "scheme": null,
        "label": null
      },
      {
        "term": "streaming",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Netflix Technology Blog"
      }
    ],
    "author": "Netflix Technology Blog",
    "author_detail": {
      "name": "Netflix Technology Blog"
    },
    "published": "Wed, 10 Jan 2024 23:20:40 GMT",
    "published_parsed": [
      2024,
      1,
      10,
      23,
      20,
      40,
      2,
      10,
      0
    ],
    "updated": "2024-01-10T23:34:46.402Z",
    "updated_parsed": [
      2024,
      1,
      10,
      23,
      34,
      46,
      2,
      10,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/netflix-techblog",
        "value": "<p><a href=\"https://www.linkedin.com/in/liwei-guo-a5aa6311/\">Liwei Guo</a>, <a href=\"https://www.linkedin.com/in/anush-moorthy-b8451142/\">Anush Moorthy</a>, <a href=\"https://www.linkedin.com/in/li-heng-chen-a75458a2/\">Li-Heng Chen</a>, <a href=\"https://www.linkedin.com/in/carvalhovinicius/\">Vinicius Carvalho</a>, <a href=\"https://www.linkedin.com/in/aditya-mavlankar-7139791/\">Aditya Mavlankar</a>, <a href=\"https://www.linkedin.com/in/agataopalach/\">Agata Opalach</a>, <a href=\"https://www.linkedin.com/in/adithyaprakash/\">Adithya Prakash</a>, Kyle Swanson, <a href=\"https://www.linkedin.com/in/jessicatweneboah/\">Jessica Tweneboah</a>, <a href=\"https://www.linkedin.com/in/subbu-venkatrav-126172a/\">Subbu Venkatrav</a>, <a href=\"https://www.linkedin.com/in/lishan-z-51302abb/\">Lishan\u00a0Zhu</a></p><p><em>This is the first blog in a multi-part series on how Netflix rebuilt its video processing pipeline with microservices, so we can maintain our rapid pace of innovation and continuously improve the system for member streaming and studio operations. This introductory blog focuses on an overview of our journey. Future blogs will provide deeper dives into each service, sharing insights and lessons learned from this\u00a0process.</em></p><p>The Netflix video processing pipeline went live with the launch of our streaming service in 2007. Since then, the video pipeline has undergone substantial improvements and broad expansions:</p><ul><li>Starting with Standard Dynamic Range (SDR) at <a href=\"https://en.wikipedia.org/wiki/Display_resolution\">Standard-Definitions</a>, we expanded the encoding pipeline to 4K and High Dynamic Range (HDR) which enabled support for our premium offering.</li><li>We moved from centralized linear encoding to <a href=\"https://netflixtechblog.com/high-quality-video-encoding-at-scale-d159db052746\">distributed chunk-based encoding</a>. This architecture shift greatly reduced the processing latency and increased system resiliency.</li><li>Moving away from the use of dedicated instances that were constrained in quantity, we tapped into Netflix\u2019s <a href=\"https://netflixtechblog.com/creating-your-own-ec2-spot-market-6dd001875f5\">internal trough</a> created due to autoscaling microservices, leading to significant improvements in computation elasticity as well as resource utilization efficiency.</li><li>We rolled out encoding innovations such as <a href=\"https://medium.com/netflix-techblog/per-title-encode-optimization-7e99442b62a2\">per-title</a> and <a href=\"https://netflixtechblog.com/optimized-shot-based-encodes-now-streaming-4b9464204830\">per-shot</a> optimizations, which provided significant quality-of-experience (QoE) improvement to Netflix\u00a0members.</li><li>By integrating with studio content systems, we enabled the pipeline to leverage rich metadata from the creative side and create more engaging member experiences like <a href=\"https://en.wikipedia.org/wiki/Black_Mirror:_Bandersnatch\">interactive storytelling</a>.</li><li>We expanded pipeline support to serve our studio/content-development use cases, which had different latency and resiliency requirements as compared to the traditional streaming use\u00a0case.</li></ul><p>Our experience of the last decade-and-a-half has reinforced our conviction that an efficient, flexible video processing pipeline that allows us to innovate and support our streaming service, as well as our studio partners, is critical to the continued success of Netflix. To that end, the Video and Image Encoding team in Encoding Technologies (ET) has spent the last few years rebuilding the video processing pipeline on our next-generation microservice-based computing platform\u00a0<a href=\"https://netflixtechblog.com/the-netflix-cosmos-platform-35c14d9351ad\">Cosmos</a>.</p><h3>From Reloaded to\u00a0Cosmos</h3><h4>Reloaded</h4><p>Starting in 2014, we developed and operated the video processing pipeline on our third-generation platform <a href=\"https://www.youtube.com/watch?v=JouA10QJiNc\">Reloaded</a>. Reloaded was well-architected, providing good stability, scalability, and a reasonable level of flexibility. It served as the foundation for numerous encoding innovations developed by our\u00a0team.</p><p>When Reloaded was designed, we focused on a single use case: converting high-quality media files (also known as mezzanines) received from studios into compressed assets for Netflix streaming. Reloaded was created as a single monolithic system, where developers from various media teams in ET and our platform partner team Content Infrastructure and Solutions (CIS)\u00b9 worked on the same codebase, building a single system that handled all media assets. Over the years, the system expanded to support various new use cases. This led to a significant increase in system complexity, and the limitations of Reloaded began to\u00a0show:</p><ul><li><em>Coupled functionality:</em> Reloaded was composed of a number of worker modules and an orchestration module. The setup of a new Reloaded module and its integration with the orchestration required a non-trivial amount of effort, which led to a bias towards augmentation rather than creation when developing new functionalities. For example, in Reloaded <a href=\"https://netflixtechblog.com/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113\">the video quality calculation was implemented inside the video encoder module</a>. With this implementation, it was extremely difficult to recalculate video quality without re-encoding.</li><li><em>Monolithic structure</em>: Since Reloaded modules were often co-located in the same repository, it was easy to overlook code-isolation rules and there was quite a bit of unintended reuse of code across what should have been strong boundaries. Such reuse created tight coupling and reduced development velocity. The tight coupling among modules further forced us to deploy all modules together.</li><li><em>Long release cycles</em>: The joint deployment meant that there was increased fear of unintended production outages as debugging and rollback can be difficult for a deployment of this size. This drove the approach of the \u201crelease train\u201d. Every two weeks, a \u201csnapshot\u201d of all modules was taken, and promoted to be a \u201crelease candidate\u201d. This release candidate then went through exhaustive testing which attempted to cover as large a surface area as possible. This testing stage took about two weeks. Thus, depending on when the code change was merged, it could take anywhere between two and four weeks to reach production.</li></ul><p>As time progressed and functionalities grew, the rate of new feature contributions in Reloaded dropped. Several promising ideas were abandoned owing to the outsized work needed to overcome architectural limitations. The platform that had once served us well was now becoming a drag on development.</p><h4>Cosmos</h4><p>As a response, in 2018 the CIS and ET teams started developing the next-generation platform, Cosmos. In addition to the scalability and the stability that the developers already enjoyed in Reloaded, Cosmos aimed to significantly increase system flexibility and feature development velocity. To achieve this, Cosmos was developed as a computing platform for workflow-driven, media-centric microservices.</p><p>The microservice architecture provides strong decoupling between services. Per-microservice workflow support eases the burden of implementing complex media workflow logic. Finally, relevant abstractions allow media algorithm developers to focus on the manipulation of video and audio signals rather than on infrastructural concerns. A comprehensive list of benefits offered by Cosmos can be found in the linked\u00a0<a href=\"https://netflixtechblog.com/the-netflix-cosmos-platform-35c14d9351ad\">blog</a>.</p><h3>Building the Video Processing Pipeline in\u00a0Cosmos</h3><h4>Service Boundaries</h4><p>In the microservice architecture, a system is composed of a number of fine-grained services, with each service focusing on a single functionality. So the first (and arguably the most important) thing is to identify boundaries and define services.</p><p>In our pipeline, as media assets travel through creation to ingest to delivery, they go through a number of processing steps such as analyses and transformations. We analyzed these processing steps to identify \u201cboundaries\u201d and grouped them into different domains, which in turn became the building blocks of the microservices we engineered.</p><p>As an example, in Reloaded, the video encoding module bundles 5\u00a0steps:</p><p>1. divide the input video into small\u00a0chunks</p><p>2. encode each chunk independently</p><p>3. calculate the quality score (<a href=\"https://netflixtechblog.com/vmaf-the-journey-continues-44b51ee9ed12\">VMAF</a>) of each\u00a0chunk</p><p>4. assemble all the encoded chunks into a single encoded\u00a0video</p><p>5. aggregate quality scores from all\u00a0chunks</p><p>From a system perspective, the assembled encoded video is of primary concern while the internal chunking and separate chunk encodings exist in order to fulfill certain latency and resiliency requirements. Further, as alluded to above, the video quality calculation provides a totally separate functionality as compared to the encoding\u00a0service.</p><p>Thus, in Cosmos, we created two independent microservices: Video Encoding Service (VES) and <a href=\"https://netflixtechblog.com/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113\">Video Quality Service (VQS)</a>, each of which serves a clear, decoupled function. As implementation details, the chunked encoding and the assembling were abstracted away into the\u00a0VES.</p><h4>Video Services</h4><p>The approach outlined above was applied to the rest of the video processing pipeline to identify functionalities and hence service boundaries, leading to the creation of the following video services\u00b2.</p><ol><li>Video Inspection Service (VIS): This service takes a mezzanine as the input and performs various inspections. It extracts metadata from different layers of the mezzanine for downstream services. In addition, the inspection service flags issues if invalid or unexpected metadata is observed and provides actionable feedback to the upstream\u00a0team.</li><li>Complexity Analysis Service (CAS): The optimal encoding recipe is highly content-dependent. This service takes a mezzanine as the input and performs analysis to understand the content complexity. It calls Video Encoding Service for <a href=\"https://netflixtechblog.com/dynamic-optimizer-a-perceptual-video-encoding-optimization-framework-e19f1e3a277f\">pre-encoding</a> and Video Quality Service for quality evaluation. The results are saved to a database so they can be\u00a0reused.</li><li>Ladder Generation Service (LGS): This service creates an entire bitrate ladder for a given encoding family (H.264, AV1, etc.). It fetches the complexity data from CAS and runs the optimization algorithm to create encoding recipes. The CAS and LGS cover much of the innovations that we have previously presented in our tech blogs (<a href=\"http://techblog.netflix.com/2015/12/per-title-encode-optimization.html\">per-title</a>, <a href=\"http://techblog.netflix.com/2016/12/more-efficient-mobile-encodes-for.html\">mobile encodes</a>, <a href=\"https://netflixtechblog.com/optimized-shot-based-encodes-now-streaming-4b9464204830\">per-shot</a>, <a href=\"https://netflixtechblog.com/optimized-shot-based-encodes-for-4k-now-streaming-47b516b10bbb\">optimized 4K encoding</a>, etc.). By wrapping ladder generation into a separate microservice (LGS), we decouple the ladder optimization algorithms from the creation and management of complexity analysis data (which resides in CAS). We expect this to give us greater freedom for experimentation and a faster rate of innovation.</li><li>Video Encoding Service (VES): This service takes a mezzanine and an encoding recipe and creates an encoded video. The recipe includes the desired encoding format and properties of the output, such as resolution, bitrate, etc. The service also provides options that allow fine-tuning latency, throughput, etc., depending on the use\u00a0case.</li><li>Video Validation Service (VVS): This service takes an encoded video and a list of expectations about the encode. These expectations include attributes specified in the encoding recipe as well as conformance requirements from the codec specification. VVS analyzes the encoded video and compares the results against the indicated expectations. Any discrepancy is flagged in the response to alert the\u00a0caller.</li><li><a href=\"https://netflixtechblog.com/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113\">Video Quality Service (VQS)</a>: This service takes the mezzanine and the encoded video as input, and calculates the quality score (VMAF) of the encoded\u00a0video.</li></ol><h4>Service Orchestration</h4><p>Each video service provides a dedicated functionality and they work together to generate the needed video assets. Currently, the two main use cases of the Netflix video pipeline are producing assets for member streaming and for studio operations. For each use case, we created a dedicated workflow orchestrator so the service orchestration can be customized to best meet the corresponding business\u00a0needs.</p><p>For the streaming use case, the generated videos are deployed to our content delivery network (CDN) for Netflix members to consume. These videos can easily be watched millions of times. The Streaming Workflow Orchestrator utilizes almost all video services to create streams for an impeccable member experience. It leverages VIS to detect and reject non-conformant or low-quality mezzanines, invokes LGS for encoding recipe optimization, encodes video using VES, and calls VQS for quality measurement where the quality data is further fed to Netflix\u2019s data pipeline for analytics and monitoring purposes. In addition to video services, the Streaming Workflow Orchestrator uses audio and timed text services to generate audio and text assets, and packaging services to \u201ccontainerize\u201d assets for streaming.</p><p>For the studio use case, some example video assets are marketing clips and daily production editorial proxies. The requests from the studio side are generally latency-sensitive. For example, someone from the production team may be waiting for the video to review so they can decide the shooting plan for the next day. Because of this, the Studio Workflow Orchestrator optimizes for fast turnaround and focuses on core media processing services. At this time, the Studio Workflow Orchestrator calls VIS to extract metadata of the ingested assets and calls VES with predefined recipes. Compared to member streaming, studio operations have different and unique requirements for video processing. Therefore, the Studio Workflow Orchestrator is the exclusive user of some encoding features like forensic watermarking and timecode/text burn-in.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Wen2M8BgqhC7Hacc1O2Nqg.png\" /></figure><h3>Where we are\u00a0now</h3><p>We have had the new video pipeline running alongside Reloaded in production for a few years now. During this time, we completed the migration of all necessary functionalities from Reloaded, began gradually shifting over traffic one use case at a time, and completed the switchover in September of\u00a02023.</p><p>While it is still early days, we have already seen the benefits of the new platform, specifically the ease of feature delivery. Notably, Netflix launched the <a href=\"https://netflixtechblog.com/ensuring-the-successful-launch-of-ads-on-netflix-f99490fdf1ba\">Advertising-supported plan</a> in November 2022. Processing Ad creatives posed some new challenges: media formats of Ads are quite different from movie and TV mezzanines that the team was familiar with, and there was a new set of media processing requirements related to the business needs of Ads. With the modularity and developer productivity benefits of Cosmos, we were able to quickly iterate the pipeline to keep up with the changing requirements and support a successful product\u00a0launch.</p><h3>Summary</h3><p>Rebuilding the video pipeline was a huge undertaking for the team. We are very proud of what we have achieved, and also eager to share our journey with the technical community. This blog has focused on providing an overview: a brief history of our pipeline and the platforms, why the rebuilding was necessary, what these new services look like, and how they are being used for Netflix businesses. In the next blog, we are going to delve into the details of the Video Encoding Service (VES), explaining step-by-step the service creation, and sharing lessons learned (we have A LOT!). We also plan to cover other video services in future tech blogs. Follow the<a href=\"https://netflixtechblog.com/\"> Netflix Tech Blog</a> to stay up to\u00a0date.</p><h3><strong>Acknowledgments</strong></h3><p>A big shout out to the CIS team for their outstanding work in building the Cosmos platform and their receptiveness to feedback from service developers.</p><p>We want to express our appreciation to our users, the Streaming Encoding Pipeline team, and the Video Engineering team. Just like our feedback helps iron out the platform, the feedback from our users has been instrumental in building high-quality services.</p><p>We also want to thank Christos Bampis and Zhi Li for their significant contributions to video services, and our two former team members, Chao Chen and Megha Manohara for contributing to the early development of this\u00a0project.</p><h4>Footnotes</h4><ol><li>Formerly known as Media Cloud Engineering/MCE team.</li><li>The actual number of video services is more than listed here. Some of them are Netflix-specific and thus omitted from this\u00a0blog.</li></ol><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4e5e6310e359\" width=\"1\" /><hr /><p><a href=\"https://netflixtechblog.com/rebuilding-netflix-video-processing-pipeline-with-microservices-4e5e6310e359\">Rebuilding Netflix Video Processing Pipeline with Microservices</a> was originally published in <a href=\"https://netflixtechblog.com\">Netflix TechBlog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<p><a href=\"https://www.linkedin.com/in/liwei-guo-a5aa6311/\">Liwei Guo</a>, <a href=\"https://www.linkedin.com/in/anush-moorthy-b8451142/\">Anush Moorthy</a>, <a href=\"https://www.linkedin.com/in/li-heng-chen-a75458a2/\">Li-Heng Chen</a>, <a href=\"https://www.linkedin.com/in/carvalhovinicius/\">Vinicius Carvalho</a>, <a href=\"https://www.linkedin.com/in/aditya-mavlankar-7139791/\">Aditya Mavlankar</a>, <a href=\"https://www.linkedin.com/in/agataopalach/\">Agata Opalach</a>, <a href=\"https://www.linkedin.com/in/adithyaprakash/\">Adithya Prakash</a>, Kyle Swanson, <a href=\"https://www.linkedin.com/in/jessicatweneboah/\">Jessica Tweneboah</a>, <a href=\"https://www.linkedin.com/in/subbu-venkatrav-126172a/\">Subbu Venkatrav</a>, <a href=\"https://www.linkedin.com/in/lishan-z-51302abb/\">Lishan\u00a0Zhu</a></p><p><em>This is the first blog in a multi-part series on how Netflix rebuilt its video processing pipeline with microservices, so we can maintain our rapid pace of innovation and continuously improve the system for member streaming and studio operations. This introductory blog focuses on an overview of our journey. Future blogs will provide deeper dives into each service, sharing insights and lessons learned from this\u00a0process.</em></p><p>The Netflix video processing pipeline went live with the launch of our streaming service in 2007. Since then, the video pipeline has undergone substantial improvements and broad expansions:</p><ul><li>Starting with Standard Dynamic Range (SDR) at <a href=\"https://en.wikipedia.org/wiki/Display_resolution\">Standard-Definitions</a>, we expanded the encoding pipeline to 4K and High Dynamic Range (HDR) which enabled support for our premium offering.</li><li>We moved from centralized linear encoding to <a href=\"https://netflixtechblog.com/high-quality-video-encoding-at-scale-d159db052746\">distributed chunk-based encoding</a>. This architecture shift greatly reduced the processing latency and increased system resiliency.</li><li>Moving away from the use of dedicated instances that were constrained in quantity, we tapped into Netflix\u2019s <a href=\"https://netflixtechblog.com/creating-your-own-ec2-spot-market-6dd001875f5\">internal trough</a> created due to autoscaling microservices, leading to significant improvements in computation elasticity as well as resource utilization efficiency.</li><li>We rolled out encoding innovations such as <a href=\"https://medium.com/netflix-techblog/per-title-encode-optimization-7e99442b62a2\">per-title</a> and <a href=\"https://netflixtechblog.com/optimized-shot-based-encodes-now-streaming-4b9464204830\">per-shot</a> optimizations, which provided significant quality-of-experience (QoE) improvement to Netflix\u00a0members.</li><li>By integrating with studio content systems, we enabled the pipeline to leverage rich metadata from the creative side and create more engaging member experiences like <a href=\"https://en.wikipedia.org/wiki/Black_Mirror:_Bandersnatch\">interactive storytelling</a>.</li><li>We expanded pipeline support to serve our studio/content-development use cases, which had different latency and resiliency requirements as compared to the traditional streaming use\u00a0case.</li></ul><p>Our experience of the last decade-and-a-half has reinforced our conviction that an efficient, flexible video processing pipeline that allows us to innovate and support our streaming service, as well as our studio partners, is critical to the continued success of Netflix. To that end, the Video and Image Encoding team in Encoding Technologies (ET) has spent the last few years rebuilding the video processing pipeline on our next-generation microservice-based computing platform\u00a0<a href=\"https://netflixtechblog.com/the-netflix-cosmos-platform-35c14d9351ad\">Cosmos</a>.</p><h3>From Reloaded to\u00a0Cosmos</h3><h4>Reloaded</h4><p>Starting in 2014, we developed and operated the video processing pipeline on our third-generation platform <a href=\"https://www.youtube.com/watch?v=JouA10QJiNc\">Reloaded</a>. Reloaded was well-architected, providing good stability, scalability, and a reasonable level of flexibility. It served as the foundation for numerous encoding innovations developed by our\u00a0team.</p><p>When Reloaded was designed, we focused on a single use case: converting high-quality media files (also known as mezzanines) received from studios into compressed assets for Netflix streaming. Reloaded was created as a single monolithic system, where developers from various media teams in ET and our platform partner team Content Infrastructure and Solutions (CIS)\u00b9 worked on the same codebase, building a single system that handled all media assets. Over the years, the system expanded to support various new use cases. This led to a significant increase in system complexity, and the limitations of Reloaded began to\u00a0show:</p><ul><li><em>Coupled functionality:</em> Reloaded was composed of a number of worker modules and an orchestration module. The setup of a new Reloaded module and its integration with the orchestration required a non-trivial amount of effort, which led to a bias towards augmentation rather than creation when developing new functionalities. For example, in Reloaded <a href=\"https://netflixtechblog.com/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113\">the video quality calculation was implemented inside the video encoder module</a>. With this implementation, it was extremely difficult to recalculate video quality without re-encoding.</li><li><em>Monolithic structure</em>: Since Reloaded modules were often co-located in the same repository, it was easy to overlook code-isolation rules and there was quite a bit of unintended reuse of code across what should have been strong boundaries. Such reuse created tight coupling and reduced development velocity. The tight coupling among modules further forced us to deploy all modules together.</li><li><em>Long release cycles</em>: The joint deployment meant that there was increased fear of unintended production outages as debugging and rollback can be difficult for a deployment of this size. This drove the approach of the \u201crelease train\u201d. Every two weeks, a \u201csnapshot\u201d of all modules was taken, and promoted to be a \u201crelease candidate\u201d. This release candidate then went through exhaustive testing which attempted to cover as large a surface area as possible. This testing stage took about two weeks. Thus, depending on when the code change was merged, it could take anywhere between two and four weeks to reach production.</li></ul><p>As time progressed and functionalities grew, the rate of new feature contributions in Reloaded dropped. Several promising ideas were abandoned owing to the outsized work needed to overcome architectural limitations. The platform that had once served us well was now becoming a drag on development.</p><h4>Cosmos</h4><p>As a response, in 2018 the CIS and ET teams started developing the next-generation platform, Cosmos. In addition to the scalability and the stability that the developers already enjoyed in Reloaded, Cosmos aimed to significantly increase system flexibility and feature development velocity. To achieve this, Cosmos was developed as a computing platform for workflow-driven, media-centric microservices.</p><p>The microservice architecture provides strong decoupling between services. Per-microservice workflow support eases the burden of implementing complex media workflow logic. Finally, relevant abstractions allow media algorithm developers to focus on the manipulation of video and audio signals rather than on infrastructural concerns. A comprehensive list of benefits offered by Cosmos can be found in the linked\u00a0<a href=\"https://netflixtechblog.com/the-netflix-cosmos-platform-35c14d9351ad\">blog</a>.</p><h3>Building the Video Processing Pipeline in\u00a0Cosmos</h3><h4>Service Boundaries</h4><p>In the microservice architecture, a system is composed of a number of fine-grained services, with each service focusing on a single functionality. So the first (and arguably the most important) thing is to identify boundaries and define services.</p><p>In our pipeline, as media assets travel through creation to ingest to delivery, they go through a number of processing steps such as analyses and transformations. We analyzed these processing steps to identify \u201cboundaries\u201d and grouped them into different domains, which in turn became the building blocks of the microservices we engineered.</p><p>As an example, in Reloaded, the video encoding module bundles 5\u00a0steps:</p><p>1. divide the input video into small\u00a0chunks</p><p>2. encode each chunk independently</p><p>3. calculate the quality score (<a href=\"https://netflixtechblog.com/vmaf-the-journey-continues-44b51ee9ed12\">VMAF</a>) of each\u00a0chunk</p><p>4. assemble all the encoded chunks into a single encoded\u00a0video</p><p>5. aggregate quality scores from all\u00a0chunks</p><p>From a system perspective, the assembled encoded video is of primary concern while the internal chunking and separate chunk encodings exist in order to fulfill certain latency and resiliency requirements. Further, as alluded to above, the video quality calculation provides a totally separate functionality as compared to the encoding\u00a0service.</p><p>Thus, in Cosmos, we created two independent microservices: Video Encoding Service (VES) and <a href=\"https://netflixtechblog.com/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113\">Video Quality Service (VQS)</a>, each of which serves a clear, decoupled function. As implementation details, the chunked encoding and the assembling were abstracted away into the\u00a0VES.</p><h4>Video Services</h4><p>The approach outlined above was applied to the rest of the video processing pipeline to identify functionalities and hence service boundaries, leading to the creation of the following video services\u00b2.</p><ol><li>Video Inspection Service (VIS): This service takes a mezzanine as the input and performs various inspections. It extracts metadata from different layers of the mezzanine for downstream services. In addition, the inspection service flags issues if invalid or unexpected metadata is observed and provides actionable feedback to the upstream\u00a0team.</li><li>Complexity Analysis Service (CAS): The optimal encoding recipe is highly content-dependent. This service takes a mezzanine as the input and performs analysis to understand the content complexity. It calls Video Encoding Service for <a href=\"https://netflixtechblog.com/dynamic-optimizer-a-perceptual-video-encoding-optimization-framework-e19f1e3a277f\">pre-encoding</a> and Video Quality Service for quality evaluation. The results are saved to a database so they can be\u00a0reused.</li><li>Ladder Generation Service (LGS): This service creates an entire bitrate ladder for a given encoding family (H.264, AV1, etc.). It fetches the complexity data from CAS and runs the optimization algorithm to create encoding recipes. The CAS and LGS cover much of the innovations that we have previously presented in our tech blogs (<a href=\"http://techblog.netflix.com/2015/12/per-title-encode-optimization.html\">per-title</a>, <a href=\"http://techblog.netflix.com/2016/12/more-efficient-mobile-encodes-for.html\">mobile encodes</a>, <a href=\"https://netflixtechblog.com/optimized-shot-based-encodes-now-streaming-4b9464204830\">per-shot</a>, <a href=\"https://netflixtechblog.com/optimized-shot-based-encodes-for-4k-now-streaming-47b516b10bbb\">optimized 4K encoding</a>, etc.). By wrapping ladder generation into a separate microservice (LGS), we decouple the ladder optimization algorithms from the creation and management of complexity analysis data (which resides in CAS). We expect this to give us greater freedom for experimentation and a faster rate of innovation.</li><li>Video Encoding Service (VES): This service takes a mezzanine and an encoding recipe and creates an encoded video. The recipe includes the desired encoding format and properties of the output, such as resolution, bitrate, etc. The service also provides options that allow fine-tuning latency, throughput, etc., depending on the use\u00a0case.</li><li>Video Validation Service (VVS): This service takes an encoded video and a list of expectations about the encode. These expectations include attributes specified in the encoding recipe as well as conformance requirements from the codec specification. VVS analyzes the encoded video and compares the results against the indicated expectations. Any discrepancy is flagged in the response to alert the\u00a0caller.</li><li><a href=\"https://netflixtechblog.com/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113\">Video Quality Service (VQS)</a>: This service takes the mezzanine and the encoded video as input, and calculates the quality score (VMAF) of the encoded\u00a0video.</li></ol><h4>Service Orchestration</h4><p>Each video service provides a dedicated functionality and they work together to generate the needed video assets. Currently, the two main use cases of the Netflix video pipeline are producing assets for member streaming and for studio operations. For each use case, we created a dedicated workflow orchestrator so the service orchestration can be customized to best meet the corresponding business\u00a0needs.</p><p>For the streaming use case, the generated videos are deployed to our content delivery network (CDN) for Netflix members to consume. These videos can easily be watched millions of times. The Streaming Workflow Orchestrator utilizes almost all video services to create streams for an impeccable member experience. It leverages VIS to detect and reject non-conformant or low-quality mezzanines, invokes LGS for encoding recipe optimization, encodes video using VES, and calls VQS for quality measurement where the quality data is further fed to Netflix\u2019s data pipeline for analytics and monitoring purposes. In addition to video services, the Streaming Workflow Orchestrator uses audio and timed text services to generate audio and text assets, and packaging services to \u201ccontainerize\u201d assets for streaming.</p><p>For the studio use case, some example video assets are marketing clips and daily production editorial proxies. The requests from the studio side are generally latency-sensitive. For example, someone from the production team may be waiting for the video to review so they can decide the shooting plan for the next day. Because of this, the Studio Workflow Orchestrator optimizes for fast turnaround and focuses on core media processing services. At this time, the Studio Workflow Orchestrator calls VIS to extract metadata of the ingested assets and calls VES with predefined recipes. Compared to member streaming, studio operations have different and unique requirements for video processing. Therefore, the Studio Workflow Orchestrator is the exclusive user of some encoding features like forensic watermarking and timecode/text burn-in.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Wen2M8BgqhC7Hacc1O2Nqg.png\" /></figure><h3>Where we are\u00a0now</h3><p>We have had the new video pipeline running alongside Reloaded in production for a few years now. During this time, we completed the migration of all necessary functionalities from Reloaded, began gradually shifting over traffic one use case at a time, and completed the switchover in September of\u00a02023.</p><p>While it is still early days, we have already seen the benefits of the new platform, specifically the ease of feature delivery. Notably, Netflix launched the <a href=\"https://netflixtechblog.com/ensuring-the-successful-launch-of-ads-on-netflix-f99490fdf1ba\">Advertising-supported plan</a> in November 2022. Processing Ad creatives posed some new challenges: media formats of Ads are quite different from movie and TV mezzanines that the team was familiar with, and there was a new set of media processing requirements related to the business needs of Ads. With the modularity and developer productivity benefits of Cosmos, we were able to quickly iterate the pipeline to keep up with the changing requirements and support a successful product\u00a0launch.</p><h3>Summary</h3><p>Rebuilding the video pipeline was a huge undertaking for the team. We are very proud of what we have achieved, and also eager to share our journey with the technical community. This blog has focused on providing an overview: a brief history of our pipeline and the platforms, why the rebuilding was necessary, what these new services look like, and how they are being used for Netflix businesses. In the next blog, we are going to delve into the details of the Video Encoding Service (VES), explaining step-by-step the service creation, and sharing lessons learned (we have A LOT!). We also plan to cover other video services in future tech blogs. Follow the<a href=\"https://netflixtechblog.com/\"> Netflix Tech Blog</a> to stay up to\u00a0date.</p><h3><strong>Acknowledgments</strong></h3><p>A big shout out to the CIS team for their outstanding work in building the Cosmos platform and their receptiveness to feedback from service developers.</p><p>We want to express our appreciation to our users, the Streaming Encoding Pipeline team, and the Video Engineering team. Just like our feedback helps iron out the platform, the feedback from our users has been instrumental in building high-quality services.</p><p>We also want to thank Christos Bampis and Zhi Li for their significant contributions to video services, and our two former team members, Chao Chen and Megha Manohara for contributing to the early development of this\u00a0project.</p><h4>Footnotes</h4><ol><li>Formerly known as Media Cloud Engineering/MCE team.</li><li>The actual number of video services is more than listed here. Some of them are Netflix-specific and thus omitted from this\u00a0blog.</li></ol><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4e5e6310e359\" width=\"1\" /><hr /><p><a href=\"https://netflixtechblog.com/rebuilding-netflix-video-processing-pipeline-with-microservices-4e5e6310e359\">Rebuilding Netflix Video Processing Pipeline with Microservices</a> was originally published in <a href=\"https://netflixtechblog.com\">Netflix TechBlog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "Sky Betting & Gaming": {
    "title": "FireDrill GameDays at Sky Betting &amp; Gaming",
    "xmlUrl": "https://technology.skybettingandgaming.com/feed.xml",
    "htmlUrl": "http://engineering.skybettingandgaming.com/",
    "title_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://sbg.technology/feed.xml",
      "value": "FireDrill GameDays at Sky Betting &amp; Gaming"
    },
    "links": [
      {
        "href": "https://sbg.technology/2023/10/16/firedrill-gamedays/",
        "rel": "alternate",
        "type": "text/html",
        "title": "FireDrill GameDays at Sky Betting &amp; Gaming"
      }
    ],
    "link": "https://sbg.technology/2023/10/16/firedrill-gamedays/",
    "published": "2023-10-16T00:00:00+00:00",
    "published_parsed": [
      2023,
      10,
      16,
      0,
      0,
      0,
      0,
      289,
      0
    ],
    "updated": "2023-10-16T00:00:00+00:00",
    "updated_parsed": [
      2023,
      10,
      16,
      0,
      0,
      0,
      0,
      289,
      0
    ],
    "id": "https://sbg.technology/2023/10/16/firedrill-gamedays",
    "guidislink": false,
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://sbg.technology/2023/10/16/firedrill-gamedays/",
        "value": "<h2 id=\"the-firedrill-gameday\">The FireDrill GameDay</h2>\n\n<p>Here at Sky Betting &amp; Gaming, we\u2019ve had great success running <a href=\"https://sbg.technology/2018/05/04/firedrills-in-core/\">fire drills</a> against our production systems. By running these failure scenarios we\u2019ve been able to increase confidence in our ability to support live service, enhance the knowledge of support staff and highlight weaknesses - be that with the services themselves or our support processes.</p>\n\n<p>Looking to build on this success, I put forward the idea of running similarly structured events pre-go-live in the form of a GameDay. The aim was to gain similar learnings but by doing it before the system went live we sort capture issues in their infancy, before they have a chance to impact customers, and help make a judgement call on the service\u2019s readiness to go live - thus the \u201cFireDrill GameDay\u201d was born. In this post, I\u2019ll summarise some of the key elements that made these events a success and highlight some of the lessons learned from running these over the last two years.</p>\n\n<p>A FireDrill GameDay brings together two activities in Chaos Engineering :</p>\n\n<ul>\n  <li>GameDay: purposefully creating major failures with the goal of increasing reliability. Typically, they last between 2-4 hours and involve a team of engineers who either develop an application or support it.\n\u00a0\u00a0</li>\n  <li>Fire drill: routine and random testing of the failure modes of systems you build and the processes you use to support and secure what you have built. Deliberately disrupt part of a functioning system to see whether, and how, it recovers.</li>\n</ul>\n\n<p>A Firedrill GameDay is essentially a GameDay run using the tried and tested format we\u2019ve developed for fire drills; as such, I\u2019ll refer to them as GameDays for the remainder of this post. What makes the format slightly different from our standard fire drills is that they are less formal, have multiple scenarios, and in our case performed on pre-live systems.</p>\n\n<p>In regards to planning and execution, we found it useful to include the following elements:</p>\n\n<h3 id=\"scope\">Scope</h3>\n<p>By clearly defining the scope of the GameDay we can ensure that we focus on the correct areas of the service with the appropriate participants. The scope would generally cover all components of a given service but you may choose to focus on areas of a service where the risk of failure is high or the state of readiness (to go live) is questionable.</p>\n\n<h3 id=\"participants\">Participants</h3>\n<p>Those involved in the GameDay should be notified at the earliest opportunity to ensure they are available and preparation can start at the earliest oppotunity. Generally, involvement would be limited to those who are to be responsible for supporting the service and those involved in its development. The support team would primarily be involved in the investigation and resolution of incidents and the development team involved in planning and reviewing outcomes.</p>\n\n<p>One or more Excon\u2019s (exercise coordinator) will be required to run the incidents and it\u2019s also useful to assign someone to the roles of SLM (Service Lifecycle Manager) and IC (Incident Commander).</p>\n\n<h3 id=\"timetable\">Timetable</h3>\n<p>In advance of the GameDay publish a timeline of how the day will be broken down. Ensure that sufficient time is provided to investigate each issues, attempt to find a solution, and confirm that everything is back to normal. It is also advisable to have a break in between each scenario to reset the environment and give those running the GameDay a break as well as time to prep for the next scenario.</p>\n\n<p><img alt=\"Time Table\" src=\"https://sbg.technology/images/gameday_image1.png\" /></p>\n\n<h3 id=\"intro--overview\">Intro / Overview</h3>\n<p>Kick off the GameDay by providing a run down of the day\u2019s plans and an overview of the system architecture. This is particularly useful where the target system is yet to go live and the support personnel are unfamiliar with it. Having the architect or lead developer provide this overview may be particularly beneficial as is the provision of links to useful resources such as runbooks and monitoring.</p>\n\n<h3 id=\"scenarios\">Scenarios</h3>\n<p>Multiple failure scenarios to be devised and and tested well in advance, while ensuring they are kept hidden from those resposible for resolving the problem on the day. Devising the scenarios should be a team effort involving analysis of the system architecture and failure mode. Issues experienced during development should be used to pinpoint potential problem areas. Ultimately, a list of scenarios should be broken down and detailed as shown here:</p>\n\n<p><img alt=\"Scenarios\" src=\"https://sbg.technology/images/gameday_image2.png\" /></p>\n\n<p>The selected scenarios should be thoroughly tested to obtain a clear understanding of how the simulated incident will play out and the best candidates taken forward to the GameDay.</p>\n\n<p>Certain scenarios may benefit from simulated transactions being run against the service. This adds to the realism, with logs being populated with associated errors/warns, while also helping sign-posting the issue and its consequences.</p>\n\n<h3 id=\"execution\">Execution</h3>\n<p>During execution be clear on any rules that might apply e.g :</p>\n\n<ul>\n  <li>This GameDay will take place in the DR environment and be treated as if a live incident though all participants will be aware it is just a test exercise.\u00a0</li>\n  <li>Responders will be called out using Slack, assuming nothing automatically calls them out.</li>\n  <li>The Excon may drop hints where necessary and produce updates on the time remaining.</li>\n</ul>\n\n<p>During the exercise, it is good to keep reminding the participants of the questions we are seeking answers to :</p>\n\n<ul>\n  <li>Is system behaviour as expected?</li>\n  <li>Do you have the required access to services to investigate the issue?</li>\n  <li>Is the monitoring sufficient to detect the problem?</li>\n  <li>Do the monitoring dashboards aid insight and investigation?</li>\n  <li>Do alerts trigger as required and resolve following the incident?</li>\n  <li>Do you have visibility of the logs and did they help highlight the issue?</li>\n  <li>How good is the supporting documentation e.g architectural, support, etc?</li>\n  <li>Are there any issues with the incident management process?</li>\n  <li>Are there any areas we can change to improve the supportability of the service(s)?</li>\n  <li>Is there a clear understanding of the impact of the incident esp on the customer?</li>\n  <li>Does the service recover gracefully with acceptable impact?</li>\n</ul>\n\n<h3 id=\"retrospective\">Retrospective</h3>\n<p>Once all the scenarios have been executed those involved should be given time to take a break and consider any issues encountered especially in response to the questions asked in the previous section.\u00a0</p>\n\n<p>A retro board similar to the following may be used to decide which issues are to be fixed now and those which can be left until later:</p>\n\n<p><img alt=\"Retrospective\" src=\"https://sbg.technology/images/gameday_image3.png\" /></p>\n\n<p>We also made use of a Readiness-O-Meter to get a quick view of where people thought we were in regard to our ability to support the service.</p>\n\n<p><img alt=\"Readiness\" src=\"https://sbg.technology/images/gameday_image4.png\" /></p>\n\n<h2 id=\"lessons-learned\">Lessons Learned</h2>\n\n<p>Having now run several of these events - here are some of the key lessons learned:</p>\n\n<ul>\n  <li>\n    <p>Early involvement is key - start early in the project and get people involved from the outset. The GameDay should be treated as a project deliverable in its own right.</p>\n  </li>\n  <li>\n    <p>Choose scenarios wisely for maximum learnings on incidents that are likely to occur. This ensures you provide valuable insights into the service and how it is supported.</p>\n  </li>\n  <li>\n    <p>Devise multiple scenarios - not only will you need backups but the more scenarios, the more you\u2019ll learn about the service and the greater the potential for uncovering issues.</p>\n  </li>\n  <li>\n    <p>Resist efforts to include tests that should be done elsewhere; the GameDay is a complement not a substitute for more traditional forms of Operations Acceptance Testing like failure testing, backup recovery, and DR testing.</p>\n  </li>\n  <li>\n    <p>During the exercise do not lose sight of the end goal - keep reminding the participants of the questions we are seeking answers to e.g. Is system behaviour as expected? Are there any areas we can change to improve the supportability of the service(s)?</p>\n  </li>\n  <li>\n    <p>Make time for a closure-type event and associated activities ensuring that nothing gets left unresolved and without an owner.</p>\n  </li>\n  <li>\n    <p>Finally, the day of the GameDay is just a part of it - as important are the conversation, analysis and testing that happen in the lead-up.</p>\n  </li>\n</ul>"
      }
    ],
    "summary": "The FireDrill GameDay",
    "authors": [
      {
        "name": "paul_whitehead"
      }
    ],
    "author_detail": {
      "name": "paul_whitehead"
    },
    "author": "paul_whitehead",
    "tags": [
      {
        "term": "Operations",
        "scheme": null,
        "label": null
      },
      {
        "term": "devops,",
        "scheme": null,
        "label": null
      },
      {
        "term": "chaos",
        "scheme": null,
        "label": null
      },
      {
        "term": "engineering,",
        "scheme": null,
        "label": null
      },
      {
        "term": "fire",
        "scheme": null,
        "label": null
      },
      {
        "term": "drill,",
        "scheme": null,
        "label": null
      },
      {
        "term": "testing",
        "scheme": null,
        "label": null
      }
    ],
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://sbg.technology/feed.xml",
      "value": "The FireDrill GameDay"
    }
  },
  "Zendesk(old)": {
    "title": "Simplifying Complex Workflows with Custom Objects",
    "xmlUrl": "https://developerblog.zendesk.com/feed",
    "htmlUrl": "https://developer.zendesk.com/blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://developerblog.zendesk.com/feed",
      "value": "Simplifying Complex Workflows with Custom Objects"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://developerblog.zendesk.com/simplifying-complex-workflows-with-custom-objects-1c6a8cc57ba7?source=rss----ed5bf5519696---4"
      }
    ],
    "link": "https://developerblog.zendesk.com/simplifying-complex-workflows-with-custom-objects-1c6a8cc57ba7?source=rss----ed5bf5519696---4",
    "id": "https://medium.com/p/1c6a8cc57ba7",
    "guidislink": false,
    "authors": [
      {
        "name": "Chris Kennedy"
      }
    ],
    "author": "Chris Kennedy",
    "author_detail": {
      "name": "Chris Kennedy"
    },
    "published": "Tue, 09 May 2023 20:11:50 GMT",
    "published_parsed": [
      2023,
      5,
      9,
      20,
      11,
      50,
      1,
      129,
      0
    ],
    "updated": "2023-05-09T20:11:50.834Z",
    "updated_parsed": [
      2023,
      5,
      9,
      20,
      11,
      50,
      1,
      129,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://developerblog.zendesk.com/feed",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3DwLYMRB0FNetLaTHZtE8A.jpeg\" /></figure><p>With <a href=\"https://developer.zendesk.com/documentation/custom-data/custom-objects/getting-started-with-custom-objects/\">Custom Objects</a>, customer data that doesn\u2019t fit neatly within native Zendesk objects (organizations, users, tickets, etc.) can be stored in Zendesk to enhance your workflow. This is particularly useful for organizations that have multiple factors to account for within their support workflow. When things like job function, agent location, customer location, and evolving business processes all matter to the day-to-day operations, handling tickets with just Zendesk objects and business rules alone can get overly complicated.</p><p>Let\u2019s follow an example of how to smooth those complexities out with custom\u00a0objects:</p><p>Facilities Management Company (FMC) has customers that send service requests for their facilities to Zendesk Support agents to take action on. FMC serves large customers who have many facilities across different regions. So for the most efficient, customer-friendly workflow, teams of agents only focus on requests from specific regions that they\u2019re assigned to cover. FMC is also growing fast. Flexibility must exist for teams\u2019 coverage area assignments to shift based on\u00a0need.</p><h4>Challenges</h4><p>At first glance, there are a few challenges with implementing a clean workflow for the agents within\u00a0Support:</p><p>Agents only service requests for regions in their coverage area. It\u2019s tempting to represent this coverage area assignment with an agent group. But there needs to be the flexibility to change the assignments, which could complicate group management for admins. It could also limit the ability to organize agents into groups based on job function (Maintenance, Janitorial Services, IT,\u00a0etc.)</p><p>Customers also have individual facilities, each with unique details relevant to the service agent. For customers with dozens of facilities, it\u2019s difficult to work with all of this info from a single organization profile. And they often have service locations across many\u00a0regions.</p><p>To reduce complexity for teams, let\u2019s add custom objects to the mix to create more meaningful relationships between key operational data, tickets and the groups of agents that support customers in them. This will help FMC\u2019s workflow stay effective and scalable.</p><h4>Modeling</h4><p>There are a number of ways to try to structure data for this workflow. But for the custom data we add to Zendesk, let\u2019s focus on only what is relevant to agents handling the requests. Agents\u00a0need:</p><ul><li>Access to external data about the individual facility in the\u00a0request</li><li>The service coverage region the facility is\u00a0in</li><li>The service coverage regions they are assigned\u00a0to</li></ul><p>To represent the facility and region data that will be stored in Zendesk, we\u2019ll set FMC up with two custom object\u00a0types:</p><ul><li><em>Location</em> for the facility\u00a0location</li><li><em>Region</em> for the service coverage\u00a0area</li></ul><p>To tie these together, we\u2019ll design a few one-to-many relationship types that describe how the location or region interacts with the other relevant objects in the workflow.</p><ul><li>The <em>Location Region</em> relationship represents the set of locations within a\u00a0region.</li><li>The <em>Ticket Location</em> relationship represents the possible service request tickets that may reference a location.</li><li>The <em>Coverage Group</em> relationship represents the set of regions that an agent group supports.</li><li>The <em>Org Location</em> relationship represents the set of locations that an organization has.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*X7W0ETEcl628XkVhyZPFoA.png\" /></figure><h4>Implementation</h4><p><strong>Legacy Custom\u00a0Objects</strong></p><p>With Legacy Custom Objects, FMC will need to create the objects, relationships and records via\u00a0API.</p><p>To start, add the <a href=\"https://developer.zendesk.com/documentation/custom-data/custom-objects/getting-started-with-custom-objects/#defining-a-legacy-custom-object-type\">object types</a>. Location will have name (required), address, and notes properties. Region will have a required coverage area property.</p><p>Location:</p><pre>{<br />  &quot;data&quot;: {<br />    &quot;key&quot;: &quot;location&quot;,<br />    &quot;schema&quot;: {<br />      &quot;properties&quot;: {<br />        &quot;name&quot;: {<br />          &quot;type&quot;: &quot;string&quot;,<br />          &quot;description&quot;: &quot;Facility Name&quot;<br />        },<br />        &quot;address&quot;: {<br />          &quot;type&quot;: &quot;string&quot;,<br />          &quot;description&quot;: &quot;Facility Address&quot;<br />        },<br />        &quot;notes&quot;: {<br />          &quot;type&quot;: &quot;sting&quot;,<br />          &quot;description&quot;: &quot;Key Property Notes&quot;<br />        }<br />      },<br />      &quot;required&quot;: [&quot;name&quot;]<br />    }<br />  }<br />}</pre><p>Region:</p><pre>{<br />  &quot;data&quot;: {<br />    &quot;key&quot;: &quot;region&quot;,<br />    &quot;schema&quot;: {<br />      &quot;properties&quot;: {<br />        &quot;coverage_area&quot;: {<br />          &quot;type&quot;: &quot;string&quot;,<br />          &quot;description&quot;: &quot;Coverage Region Name&quot;<br />        }<br />      },<br />      &quot;required&quot;: [&quot;coverage_area&quot;]<br />    }<br />  }<br />}</pre><p>Next, add the set of one-to-many <a href=\"https://developer.zendesk.com/documentation/custom-data/custom-objects/getting-started-with-custom-objects/#modeling-your-data\">relationship types</a> that will be\u00a0used.</p><pre>|  Source Object Type  |  Target Object Type  |<br />|----------------------|----------------------|<br />|  region              |  location            |<br />|  location            |  zen:ticket          |<br />|  zen:group           |  region              |<br />|  zen:organization    |  location            |</pre><p>Once this is done, FMC can start creating location and region records from their property management system and coverage group records from their workforce management system.</p><p><strong>New Custom\u00a0Objects</strong></p><p>We have an exciting <a href=\"https://support.zendesk.com/hc/en-us/community/posts/5359269969178-What-is-the-new-Custom-Objects-EAP-\">New Custom Objects</a> experience that simplifies creating the objects, relationships and records. With this new experience, FMC can build the objects and add records directly from <a href=\"https://support.zendesk.com/hc/en-us/articles/5392409465370\">Admin\u00a0Center</a>.</p><p>It also introduces <a href=\"https://support.zendesk.com/hc/en-us/articles/4591924111770\">Lookup relationship fields</a> to simplify establishing relationships. With this powerful addition, FMC can create Org Location, Location Region, and Ticket Location lookup fields for easy relationship management between these objects that can be done from the agent interface.</p><h4>Using an app to display the custom data to\u00a0agents</h4><p>To give the agents the ability to interact with this new data directly from a ticket, create a <a href=\"https://developer.zendesk.com/documentation/apps/build-an-app/build-your-first-support-app/part-1-laying-the-groundwork/\">Support app</a>. Depending on the specifics of the support flow for the customer, this app will give the agent the info they need to route the ticket in the sidebar. For example, if the customer submits requests with their building\u2019s facility ID, we can store this ID on the location record when adding locations. Then the ticket sidebar app can fetch the location and related region/coverage groups.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ufsc9cn0ylKYuoxWPrwlPw.png\" /></figure><p>There\u2019s also flexibility to add other features as the workflow evolves\u200a\u2014\u200alike using the organization to fetch all locations and give the agent the ability to manually select the ticket\u2019s location. Or <a href=\"https://developer.zendesk.com/api-reference/apps/apps-support-api/ticket_sidebar/#ticketassignee\">automatically</a> selecting a group in the agent interface. This gives triaging agents the necessary context about the service request and the groups that are best suited for serving\u00a0it.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1c6a8cc57ba7\" width=\"1\" /><hr /><p><a href=\"https://developerblog.zendesk.com/simplifying-complex-workflows-with-custom-objects-1c6a8cc57ba7\">Simplifying Complex Workflows with Custom Objects</a> was originally published in <a href=\"https://developerblog.zendesk.com\">Zendesk Developer Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3DwLYMRB0FNetLaTHZtE8A.jpeg\" /></figure><p>With <a href=\"https://developer.zendesk.com/documentation/custom-data/custom-objects/getting-started-with-custom-objects/\">Custom Objects</a>, customer data that doesn\u2019t fit neatly within native Zendesk objects (organizations, users, tickets, etc.) can be stored in Zendesk to enhance your workflow. This is particularly useful for organizations that have multiple factors to account for within their support workflow. When things like job function, agent location, customer location, and evolving business processes all matter to the day-to-day operations, handling tickets with just Zendesk objects and business rules alone can get overly complicated.</p><p>Let\u2019s follow an example of how to smooth those complexities out with custom\u00a0objects:</p><p>Facilities Management Company (FMC) has customers that send service requests for their facilities to Zendesk Support agents to take action on. FMC serves large customers who have many facilities across different regions. So for the most efficient, customer-friendly workflow, teams of agents only focus on requests from specific regions that they\u2019re assigned to cover. FMC is also growing fast. Flexibility must exist for teams\u2019 coverage area assignments to shift based on\u00a0need.</p><h4>Challenges</h4><p>At first glance, there are a few challenges with implementing a clean workflow for the agents within\u00a0Support:</p><p>Agents only service requests for regions in their coverage area. It\u2019s tempting to represent this coverage area assignment with an agent group. But there needs to be the flexibility to change the assignments, which could complicate group management for admins. It could also limit the ability to organize agents into groups based on job function (Maintenance, Janitorial Services, IT,\u00a0etc.)</p><p>Customers also have individual facilities, each with unique details relevant to the service agent. For customers with dozens of facilities, it\u2019s difficult to work with all of this info from a single organization profile. And they often have service locations across many\u00a0regions.</p><p>To reduce complexity for teams, let\u2019s add custom objects to the mix to create more meaningful relationships between key operational data, tickets and the groups of agents that support customers in them. This will help FMC\u2019s workflow stay effective and scalable.</p><h4>Modeling</h4><p>There are a number of ways to try to structure data for this workflow. But for the custom data we add to Zendesk, let\u2019s focus on only what is relevant to agents handling the requests. Agents\u00a0need:</p><ul><li>Access to external data about the individual facility in the\u00a0request</li><li>The service coverage region the facility is\u00a0in</li><li>The service coverage regions they are assigned\u00a0to</li></ul><p>To represent the facility and region data that will be stored in Zendesk, we\u2019ll set FMC up with two custom object\u00a0types:</p><ul><li><em>Location</em> for the facility\u00a0location</li><li><em>Region</em> for the service coverage\u00a0area</li></ul><p>To tie these together, we\u2019ll design a few one-to-many relationship types that describe how the location or region interacts with the other relevant objects in the workflow.</p><ul><li>The <em>Location Region</em> relationship represents the set of locations within a\u00a0region.</li><li>The <em>Ticket Location</em> relationship represents the possible service request tickets that may reference a location.</li><li>The <em>Coverage Group</em> relationship represents the set of regions that an agent group supports.</li><li>The <em>Org Location</em> relationship represents the set of locations that an organization has.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*X7W0ETEcl628XkVhyZPFoA.png\" /></figure><h4>Implementation</h4><p><strong>Legacy Custom\u00a0Objects</strong></p><p>With Legacy Custom Objects, FMC will need to create the objects, relationships and records via\u00a0API.</p><p>To start, add the <a href=\"https://developer.zendesk.com/documentation/custom-data/custom-objects/getting-started-with-custom-objects/#defining-a-legacy-custom-object-type\">object types</a>. Location will have name (required), address, and notes properties. Region will have a required coverage area property.</p><p>Location:</p><pre>{<br />  &quot;data&quot;: {<br />    &quot;key&quot;: &quot;location&quot;,<br />    &quot;schema&quot;: {<br />      &quot;properties&quot;: {<br />        &quot;name&quot;: {<br />          &quot;type&quot;: &quot;string&quot;,<br />          &quot;description&quot;: &quot;Facility Name&quot;<br />        },<br />        &quot;address&quot;: {<br />          &quot;type&quot;: &quot;string&quot;,<br />          &quot;description&quot;: &quot;Facility Address&quot;<br />        },<br />        &quot;notes&quot;: {<br />          &quot;type&quot;: &quot;sting&quot;,<br />          &quot;description&quot;: &quot;Key Property Notes&quot;<br />        }<br />      },<br />      &quot;required&quot;: [&quot;name&quot;]<br />    }<br />  }<br />}</pre><p>Region:</p><pre>{<br />  &quot;data&quot;: {<br />    &quot;key&quot;: &quot;region&quot;,<br />    &quot;schema&quot;: {<br />      &quot;properties&quot;: {<br />        &quot;coverage_area&quot;: {<br />          &quot;type&quot;: &quot;string&quot;,<br />          &quot;description&quot;: &quot;Coverage Region Name&quot;<br />        }<br />      },<br />      &quot;required&quot;: [&quot;coverage_area&quot;]<br />    }<br />  }<br />}</pre><p>Next, add the set of one-to-many <a href=\"https://developer.zendesk.com/documentation/custom-data/custom-objects/getting-started-with-custom-objects/#modeling-your-data\">relationship types</a> that will be\u00a0used.</p><pre>|  Source Object Type  |  Target Object Type  |<br />|----------------------|----------------------|<br />|  region              |  location            |<br />|  location            |  zen:ticket          |<br />|  zen:group           |  region              |<br />|  zen:organization    |  location            |</pre><p>Once this is done, FMC can start creating location and region records from their property management system and coverage group records from their workforce management system.</p><p><strong>New Custom\u00a0Objects</strong></p><p>We have an exciting <a href=\"https://support.zendesk.com/hc/en-us/community/posts/5359269969178-What-is-the-new-Custom-Objects-EAP-\">New Custom Objects</a> experience that simplifies creating the objects, relationships and records. With this new experience, FMC can build the objects and add records directly from <a href=\"https://support.zendesk.com/hc/en-us/articles/5392409465370\">Admin\u00a0Center</a>.</p><p>It also introduces <a href=\"https://support.zendesk.com/hc/en-us/articles/4591924111770\">Lookup relationship fields</a> to simplify establishing relationships. With this powerful addition, FMC can create Org Location, Location Region, and Ticket Location lookup fields for easy relationship management between these objects that can be done from the agent interface.</p><h4>Using an app to display the custom data to\u00a0agents</h4><p>To give the agents the ability to interact with this new data directly from a ticket, create a <a href=\"https://developer.zendesk.com/documentation/apps/build-an-app/build-your-first-support-app/part-1-laying-the-groundwork/\">Support app</a>. Depending on the specifics of the support flow for the customer, this app will give the agent the info they need to route the ticket in the sidebar. For example, if the customer submits requests with their building\u2019s facility ID, we can store this ID on the location record when adding locations. Then the ticket sidebar app can fetch the location and related region/coverage groups.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ufsc9cn0ylKYuoxWPrwlPw.png\" /></figure><p>There\u2019s also flexibility to add other features as the workflow evolves\u200a\u2014\u200alike using the organization to fetch all locations and give the agent the ability to manually select the ticket\u2019s location. Or <a href=\"https://developer.zendesk.com/api-reference/apps/apps-support-api/ticket_sidebar/#ticketassignee\">automatically</a> selecting a group in the agent interface. This gives triaging agents the necessary context about the service request and the groups that are best suited for serving\u00a0it.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1c6a8cc57ba7\" width=\"1\" /><hr /><p><a href=\"https://developerblog.zendesk.com/simplifying-complex-workflows-with-custom-objects-1c6a8cc57ba7\">Simplifying Complex Workflows with Custom Objects</a> was originally published in <a href=\"https://developerblog.zendesk.com\">Zendesk Developer Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  },
  "CodeName One": {
    "title": "Codename One Shared Files Library",
    "xmlUrl": "http://www.codenameone.com/feed.xml",
    "htmlUrl": "http://www.codenameone.com/blog.html",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.codenameone.com/blog/feed",
      "value": "Codename One Shared Files Library"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.codenameone.com/blog/codename-one-shared-files-library.html"
      }
    ],
    "link": "https://www.codenameone.com/blog/codename-one-shared-files-library.html",
    "comments": "https://www.codenameone.com/blog/codename-one-shared-files-library.html#comments",
    "authors": [
      {
        "name": "Steve Hannah"
      }
    ],
    "author": "Steve Hannah",
    "author_detail": {
      "name": "Steve Hannah"
    },
    "published": "Wed, 26 Jul 2023 13:07:28 +0000",
    "published_parsed": [
      2023,
      7,
      26,
      13,
      7,
      28,
      2,
      207,
      0
    ],
    "id": "https://www.codenameone.com/?post_type=blogs&p=36538",
    "guidislink": false,
    "summary": "This library provides a wrapper over the Android shared files API to allow your Codename One apps to read and write shared files (i.e. files accessible to other apps).",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.codenameone.com/blog/feed",
      "value": "This library provides a wrapper over the Android shared files API to allow your Codename One apps to read and write shared files (i.e. files accessible to other apps)."
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://www.codenameone.com/blog/feed",
        "value": "<div class=\"elementor elementor-36538\">\n\t\t\t\t\t\t<div class=\"elementor-inner\">\n\t\t\t\t<div class=\"elementor-section-wrap\">\n\t\t\t\t\t\t\t\t\t<section class=\"elementor-section elementor-top-section elementor-element elementor-element-77b4d9b0 elementor-section-boxed elementor-section-height-default elementor-section-height-default\">\n\t\t\t\t\t\t<div class=\"elementor-container elementor-column-gap-default\">\n\t\t\t\t\t\t\t<div class=\"elementor-row\">\n\t\t\t\t\t<div class=\"elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-16d2ade6\">\n\t\t\t<div class=\"elementor-column-wrap elementor-element-populated\">\n\t\t\t\t\t\t\t<div class=\"elementor-widget-wrap\">\n\t\t\t\t\t\t<div class=\"elementor-element elementor-element-aff6217 elementor-widget elementor-widget-theme-post-excerpt\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\tThis library provides a wrapper over the Android shared files API to allow your Codename One apps to read and write shared files (i.e. files accessible to other apps).\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-63632c3f elementor-widget elementor-widget-theme-post-featured-image elementor-widget-image\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-image\">\n\t\t\t\t\t\t\t\t\t\t\t\t<img alt=\"codename-one-shared-files-library\" class=\"attachment-large size-large wp-image-36559\" height=\"536\" src=\"https://www.codenameone.com/wp-content/uploads/2023/07/Shared-Files-Library-1024x536.jpg\" width=\"1024\" />\t\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-219ee491 elementor-toc--minimized-on-tablet elementor-widget elementor-widget-table-of-contents\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-toc__header\">\n\t\t\t<h3 class=\"elementor-toc__header-title\">\n\t\t\t\tJump To Topic\t\t\t</h3>\n\t\t\t\t\t\t\t<div class=\"elementor-toc__toggle-button elementor-toc__toggle-button--expand\" tabindex=\"0\"><i class=\"fas fa-chevron-down\"></i></div>\n\t\t\t\t<div class=\"elementor-toc__toggle-button elementor-toc__toggle-button--collapse\" tabindex=\"0\"><i class=\"fas fa-chevron-up\"></i></div>\n\t\t\t\t\t</div>\n\t\t<div class=\"elementor-toc__body\">\n\t\t\t<div class=\"elementor-toc__spinner-container\">\n\t\t\t\t<i class=\"elementor-toc__spinner eicon-animation-spin eicon-loading\"></i>\t\t\t</div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-536929a5 elementor-widget elementor-widget-spacer\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"></div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t</div>\n\t\t</section>\n\t\t\t\t<section class=\"elementor-section elementor-top-section elementor-element elementor-element-e4489c7 elementor-section-boxed elementor-section-height-default elementor-section-height-default\">\n\t\t\t\t\t\t<div class=\"elementor-container elementor-column-gap-default\">\n\t\t\t\t\t\t\t<div class=\"elementor-row\">\n\t\t\t\t\t<div class=\"elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-3032ce8c\">\n\t\t\t<div class=\"elementor-column-wrap elementor-element-populated\">\n\t\t\t\t\t\t\t<div class=\"elementor-widget-wrap\">\n\t\t\t\t\t\t<div class=\"elementor-element elementor-element-5fb08767 elementor-blockquote--skin-border elementor-blockquote--button-color-official elementor-widget elementor-widget-blockquote\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<blockquote class=\"elementor-blockquote\">\n\t\t\t<p class=\"elementor-blockquote__content\">\n\t\t\t\t<li>See this on <a href=\"https://github.com/shannah/cn1-shared-files-lib\" rel=\"noopener\" target=\"_blank\">GitHub.</a>\n<br />\n<li>See example app using this API <a href=\"https://github.com/shannah/cn1-shared-files-lib-demo/tree/master/common/src/main/java/com/codename1/shfltest\" rel=\"noopener\" target=\"_blank\">here.</a>\n<br />\n<li>See use cases for accessing documents and other files <a href=\"https://developer.android.com/training/data-storage/shared/documents-files#use-cases\" rel=\"noopener\" target=\"_blank\">here.</a>\t\t\t</p>\n\t\t\t\t\t</blockquote>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-4dab3ef elementor-widget elementor-widget-spacer\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"></div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-edcc14b elementor-widget elementor-widget-heading\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h3 class=\"elementor-heading-title elementor-size-default\">Background</h3>\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-7cb014f elementor-widget elementor-widget-heading\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h4 class=\"elementor-heading-title elementor-size-default\">Accessing documents and other files from shared storage (including external and cloud storage).</h4>\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-d7eb4b1 elementor-widget elementor-widget-text-editor\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-text-editor elementor-clearfix\">\n\t\t\t\t<p>In the past, we used to be able to access files on external storage directly using <strong>FileSystemStorage</strong>, but more recent android versions block this, requiring you to use their<a class=\"c-link\" href=\"https://developer.android.com/training/data-storage/shared/documents-files\" rel=\"noopener noreferrer\" target=\"_blank\">\u00a0Shared Document APIs</a>. a.k.a Share Files API and Storage Access Framework.</p><p>On Android devices from version 4.4 and above, apps can use the <strong>Storage Access Framework</strong> to let users choose documents and files for the app without needing special permissions. This enhances user privacy and control, and the accessed files remain on the device even after uninstalling the app.</p>\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-bc84c6f elementor-widget elementor-widget-text-editor\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-text-editor elementor-clearfix\">\n\t\t\t\t<p>The new Codename One Shared Files Library provides a wrapper over the Android shared files API to allow your Codename One apps to read and write shared files (i.e. files accessible to other apps).</p><p>This is a clean, secure and well-supported way to save and open files that could also be accessed by other applications.</p>\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-4fd245c elementor-widget elementor-widget-spacer\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"></div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-2ad5cfd6 elementor-widget elementor-widget-heading\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h3 class=\"elementor-heading-title elementor-size-default\">Basic Usage\n</h3>\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-58b63690 elementor-widget elementor-widget-text-editor\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-text-editor elementor-clearfix\">\n\t\t\t\t<p>This API provides two abstractions:</p><p>1. <code>SharedFile</code> &#8211; Represents a single file or directory.</p><p>2. <code>SharedFileManager</code> &#8211; Provides access to the shared file system. Includes UI abstractions to select directories and files.</p><p>First step is to request access to a file:</p>\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-2d2c035 elementor-widget elementor-widget-code-highlight\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"prismjs-default copy-to-clipboard word-wrap\">\n\t\t\t<pre class=\"highlight-height language-java \">\n\t\t\t\t<code class=\"language-java\" readonly=\"true\">\n\t\t\t\t\t// Open a directory\n// Will open a file chooser for user to access a directory\nSharedFileManager.getInstance().openDirectory().ready(sharedDirectory -> {\n    // sharedDirectory is a SharedFile object\n});\n\n// Open a file\nSharedFileManager.getInstance().openFile().ready(sharedFile -> {\n    // sharedFile is a SharedFile object\n});\n\n// Open file of specific type\nSharedFileManager.getInstance().openFile(\"text/plain\").ready(sharedFile -> {\n    // sharedFile is a SharedFile object\n});\n\t\t\t\t</code>\n\t\t\t</pre>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-ed7692f elementor-widget elementor-widget-spacer\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"></div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-4720fb83 elementor-widget elementor-widget-heading\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h3 class=\"elementor-heading-title elementor-size-default\">Reading and Writing Files</h3>\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-79a6a032 elementor-widget elementor-widget-text-editor\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-text-editor elementor-clearfix\">\n\t\t\t\t<p>Use <code>SharedFile.openInputStream()</code> and <code>SharedFile.openOutputStream(String mimetype)</code> for reading and writing files.</p><p>E.g.</p>\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-c03af6a elementor-widget elementor-widget-code-highlight\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"prismjs-default copy-to-clipboard word-wrap\">\n\t\t\t<pre class=\"highlight-height language-java \">\n\t\t\t\t<code class=\"language-java\" readonly=\"true\">\n\t\t\t\t\tString textContents = Util.readToString(sharedFile.openInputStream());\n\ntextContents += \"Modified\";\ntry (OutputStream output = sharedFile.openOutputStream(sharedFile.getMimetype())) {\n    output.write(textContents.getBytes(\"UTF-8\"));\n}\n\t\t\t\t</code>\n\t\t\t</pre>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-2c07fa2 elementor-widget elementor-widget-spacer\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"></div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-406fd81 elementor-widget elementor-widget-heading\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h3 class=\"elementor-heading-title elementor-size-default\">Creating New Files</h3>\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-bdc2c9a elementor-widget elementor-widget-text-editor\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-text-editor elementor-clearfix\">\n\t\t\t\t<p>1. Open a directory</p><p>2. Call <code>directory.getChild(relativePath)</code> to get reference to file.</p><p>3. Call <code>child.openOutputStream(mimetype)</code></p>\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-22413ae elementor-widget elementor-widget-spacer\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"></div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-35db37cf elementor-widget elementor-widget-heading\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h3 class=\"elementor-heading-title elementor-size-default\">Bookmarking For Later Use</h3>\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-59d4afc elementor-widget elementor-widget-text-editor\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-text-editor elementor-clearfix\">\n\t\t\t\t<p>By default, the files you obtain will no be accessible the next time you load the app. You need to create a bookmarked file which will provide you with a persistent path that you can use to access the file.</p><p>1. Use <code>SharedFile.createBookmark()</code> to create a bookmark.</p><p>2. Use <code>SharedFile.deleteBookmark()</code> do remove a bookmark.</p><p>3. Use <code>SharedFile.isBookmark()</code> to check if the file is a bookmarked file.</p><p>4. Use <code>SharedFileManager.openBookmark(String)</code> to open a file given its bookmarked path. (i.e. bookmarkedFile.getPath())</p><p>5. Use <code>SharedFileManager.getBookmarks()</code> for a list of all current bookmarks.</p>\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-595920b elementor-widget elementor-widget-spacer\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"></div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-c603451 elementor-widget elementor-widget-heading\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h3 class=\"elementor-heading-title elementor-size-default\">Installation</h3>\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-aa6df4d elementor-widget elementor-widget-text-editor\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-text-editor elementor-clearfix\">\n\t\t\t\t<div dir=\"auto\"><p dir=\"auto\">Add the following maven dependency to your common/pom.xml file</p></div>\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-df5a3cd elementor-widget elementor-widget-code-highlight\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"prismjs-default copy-to-clipboard word-wrap\">\n\t\t\t<pre class=\"highlight-height language-xml \">\n\t\t\t\t<code class=\"language-xml\" readonly=\"true\">\n\t\t\t\t\t\n    com.codenameone\n    sharedfiles-lib\n    0.1.0\n    pom\n\n\t\t\t\t</code>\n\t\t\t</pre>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"elementor-element elementor-element-2bfafca3 elementor-widget elementor-widget-spacer\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"></div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t</div>\n\t\t</section>\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t\t\t</div>"
      }
    ],
    "wfw_commentrss": "https://www.codenameone.com/blog/codename-one-shared-files-library.html/feed",
    "slash_comments": "2"
  },
  "Atomic Object": {
    "title": "Let These Design Accounts Inspire You to Up Your Game",
    "xmlUrl": "https://spin.atomicobject.com/feed/",
    "htmlUrl": "https://spin.atomicobject.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://spin.atomicobject.com/feed/",
      "value": "Let These Design Accounts Inspire You to Up Your Game"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://spin.atomicobject.com/design-accounts/"
      }
    ],
    "link": "https://spin.atomicobject.com/design-accounts/",
    "comments": "https://spin.atomicobject.com/design-accounts/#respond",
    "authors": [
      {
        "name": "Justin Interino"
      }
    ],
    "author": "Justin Interino",
    "author_detail": {
      "name": "Justin Interino"
    },
    "published": "Sun, 14 Jan 2024 13:00:53 +0000",
    "published_parsed": [
      2024,
      1,
      14,
      13,
      0,
      53,
      6,
      14,
      0
    ],
    "tags": [
      {
        "term": "UX & Design",
        "scheme": null,
        "label": null
      },
      {
        "term": "UX",
        "scheme": null,
        "label": null
      },
      {
        "term": "Design",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://spin.atomicobject.com/?p=3658324",
    "guidislink": false,
    "summary": "<p>In a digital world filled with selfies and memes, design accounts often slip under the radar. It&#8217;s simple to miss these hidden gems that can provide a burst of creativity or offer valuable guidance when you find yourself stuck in a design rut. Fortunately, there&#8217;s no shortage of accounts ready to serve as delightful resources [&#8230;]</p>\n<p>The post <a href=\"https://spin.atomicobject.com/design-accounts/\">Let These Design Accounts Inspire You to Up Your Game</a> appeared first on <a href=\"https://spin.atomicobject.com\">Atomic Spin</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://spin.atomicobject.com/feed/",
      "value": "<p>In a digital world filled with selfies and memes, design accounts often slip under the radar. It&#8217;s simple to miss these hidden gems that can provide a burst of creativity or offer valuable guidance when you find yourself stuck in a design rut. Fortunately, there&#8217;s no shortage of accounts ready to serve as delightful resources [&#8230;]</p>\n<p>The post <a href=\"https://spin.atomicobject.com/design-accounts/\">Let These Design Accounts Inspire You to Up Your Game</a> appeared first on <a href=\"https://spin.atomicobject.com\">Atomic Spin</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://spin.atomicobject.com/feed/",
        "value": "<p class=\"p1\">In a digital world filled with selfies and memes, design accounts often slip under the radar. It&#8217;s simple to miss these hidden gems that can provide a burst of creativity or offer valuable guidance when you find yourself stuck in a design rut. Fortunately, there&#8217;s no shortage of accounts ready to serve as delightful resources to elevate your design game. Here are a few accounts I often leverage for helpful reminders and <a href=\"https://spin.atomicobject.com/inspiration-teach-someone/\">inspiration</a>.</p>\n<h2>@UI_UX_Idea</h2>\n<p>&nbsp;</p>\n<p><img alt=\"\" class=\"alignleft wp-image-3658367 size-full\" height=\"1080\" src=\"https://spin.atomicobject.com/wp-content/uploads/UIUXIdea.png\" width=\"1920\" /></p>\n<p>&nbsp;</p>\n<p class=\"p1\"><strong>Account</strong>: <a href=\"https://www.instagram.com/ui_ux_idea/?hl=en\">@ui_ux_idea</a><br />\n<strong>Platform</strong>: Instagram<br />\n<strong>Great for</strong>: Inspiration | Mood Boards | Components &amp; Layouts</p>\n<p class=\"p1\">Ui_ux_idea keeps it simple. When you need a stream of stunning designs and layouts to spark inspiration for your next project, Ui_ux_idea is your one-stop shop. With a mix of both mobile and desktop designs, it&#8217;s the perfect place to envision the groundwork for your design or give it that extra boost it may need.</p>\n<p>&nbsp;</p>\n<h2>@Pixelacademy</h2>\n<p>&nbsp;</p>\n<p><img alt=\"\" class=\"aligncenter wp-image-3658365 size-full\" height=\"1080\" src=\"https://spin.atomicobject.com/wp-content/uploads/Pixelacademy.png\" width=\"1920\" /></p>\n<p>&nbsp;</p>\n<p class=\"p1\"><strong>Account</strong>: <a href=\"https://www.instagram.com/pixelacademy.in/\">@pixelacademy</a><br />\n<strong>Platform</strong>: Instagram<br />\n<strong>Great for</strong>: UX/UI Standards | Free Design Tools | Design Tips</p>\n<p class=\"p1\">If you&#8217;re seeking valuable reminders on design best practices or insightful recommendations for visual styling, pixelacademy proves to be an excellent resource. Their content, such as &#8220;5 Important Laws of UX Design&#8221; and \u201cThe Rule Of Balance In Design,\u201d offers crucial insights that every designer immersed in their project should consider. Pixelacademy also delivers content that can enhance any visual designer&#8217;s toolkit. Examples like &#8220;Colors To Use Instead Of Pure White,&#8221; &#8220;Design Better Gradients With These Awesome Tips,&#8221; and &#8220;Why You Should Stop Using Black In UI Design&#8221; present fresh perspectives that can invigorate your visual designs.</p>\n<p>&nbsp;</p>\n<h2>@CreativeWebElements</h2>\n<p>&nbsp;</p>\n<p><img alt=\"\" class=\"aligncenter wp-image-3658364 size-full\" height=\"1080\" src=\"https://spin.atomicobject.com/wp-content/uploads/creativewebelements.png\" width=\"1920\" /></p>\n<p>&nbsp;</p>\n<p class=\"p1\"><strong>Account</strong>: <a href=\"https://www.instagram.com/creativewebelements/?hl=en\">@creativewebelements</a><br />\n<strong>Platform</strong>: Instagram<br />\n<strong>Great for</strong>: Design Tips | Industry Insights | Design How To\u2019s</p>\n<p class=\"p1\">Creativewebelements serves as an excellent resource for valuable insights on thriving in the design profession. Their content caters to both novice and experienced designers, offering guidance on entering the design space and refining established processes. Noteworthy content includes <em>&#8220;How To Get Your First Client as a UX/UI Designer,\u201d</em>\u00a0<em>&#8220;Stand Out In The AI Era,\u201d</em>\u00a0and <em>&#8220;Helpful Soft Skills for UX/UI Designers</em>.&#8221; Additionally, the platform provides content aimed at enhancing the skills in your design toolkit. Pieces like <em>&#8220;Conversation Tips For User Interviews&#8221;</em> offer subtle yet impactful reminders suitable for both your initial research session and your hundredth.</p>\n<p>&nbsp;</p>\n<h2>@UI_Gradient</h2>\n<p>&nbsp;</p>\n<p><img alt=\"\" class=\"aligncenter wp-image-3658366 size-full\" height=\"1080\" src=\"https://spin.atomicobject.com/wp-content/uploads/UIGradient.png\" width=\"1920\" /></p>\n<p><strong>Account</strong>: <a href=\"https://www.instagram.com/ui_gradient/?hl=en\">@ui_gradient</a><br />\n<strong>Platform</strong>: Instagram<br />\n<strong>Great for</strong>: UI Inspiration | Visual Eye Candy | Design How To\u2019s</p>\n<p class=\"p1\">When faced with a creative block, ui_gradient is your go-to for breaking through that barrier. Whether you&#8217;re working on striking product landing pages or crafting elegantly simple components, ui_gradient offers content that caters to diverse design needs. It comes in handy when you&#8217;re moving from wireframes to visual design, helping you craft the perfect look and feel.</p>\n<p class=\"p1\">What sets this account apart is its collection of step-by-step tutorials. This will allow you to replicate specific components and animations. I found it a key resource in my design toolkit.</p>\n<p class=\"p1\">While these accounts may not be perfect and not all offer groundbreaking insights, they do play a crucial role by providing reminders on best practices. And, they serve as a reliable source for inspiration and overcoming creative blocks.</p>\n<p>The post <a href=\"https://spin.atomicobject.com/design-accounts/\">Let These Design Accounts Inspire You to Up Your Game</a> appeared first on <a href=\"https://spin.atomicobject.com\">Atomic Spin</a>.</p>"
      }
    ],
    "wfw_commentrss": "https://spin.atomicobject.com/design-accounts/feed/",
    "slash_comments": "0",
    "post-id": "3658324"
  },
  "Clever": {
    "title": "SAML Protocol",
    "xmlUrl": "https://engineering.clever.com/rss",
    "htmlUrl": "https://engineering.clever.com/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://engineering.clever.com/feed/",
      "value": "SAML Protocol"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://engineering.clever.com/2023/11/29/saml-protocol/"
      }
    ],
    "link": "https://engineering.clever.com/2023/11/29/saml-protocol/",
    "authors": [
      {
        "name": "Keith Richards"
      }
    ],
    "author": "Keith Richards",
    "author_detail": {
      "name": "Keith Richards"
    },
    "published": "Wed, 29 Nov 2023 17:55:03 +0000",
    "published_parsed": [
      2023,
      11,
      29,
      17,
      55,
      3,
      2,
      333,
      0
    ],
    "tags": [
      {
        "term": "authentication",
        "scheme": null,
        "label": null
      },
      {
        "term": "authorization",
        "scheme": null,
        "label": null
      },
      {
        "term": "protocol",
        "scheme": null,
        "label": null
      },
      {
        "term": "saml",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://engineering.clever.com/?p=221",
    "guidislink": false,
    "summary": "<p>A tool for Identity Federation Security Assertion Markup Language, or SAML, is an open standard for exchanging authentication and authorization data between two parties. It&#8217;s a common strategy for single sign-on (SSO), allowing users to sign in once and authenticate with multiple third party applications. Similar to OAuth2.0, SAML promotes data security by preventing direct [&#8230;]</p>\n<p>The post <a href=\"https://engineering.clever.com/2023/11/29/saml-protocol/\">SAML Protocol</a> appeared first on <a href=\"https://engineering.clever.com\">Clever Engineering Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://engineering.clever.com/feed/",
      "value": "<p>A tool for Identity Federation Security Assertion Markup Language, or SAML, is an open standard for exchanging authentication and authorization data between two parties. It&#8217;s a common strategy for single sign-on (SSO), allowing users to sign in once and authenticate with multiple third party applications. Similar to OAuth2.0, SAML promotes data security by preventing direct [&#8230;]</p>\n<p>The post <a href=\"https://engineering.clever.com/2023/11/29/saml-protocol/\">SAML Protocol</a> appeared first on <a href=\"https://engineering.clever.com\">Clever Engineering Blog</a>.</p>"
    },
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://engineering.clever.com/feed/",
        "value": "<h2 class=\"wp-block-heading\">A tool for Identity Federation</h2>\n\n\n\n<p>Security Assertion Markup Language, or SAML, is an open standard for exchanging authentication and authorization data between two parties. It&#8217;s a common strategy for single sign-on (SSO), allowing users to sign in once and authenticate with multiple third party applications. Similar to OAuth2.0, SAML promotes data security by preventing direct access to sensitive user information. It also means users can track a single set of login credentials rather than managing one set per application.</p>\n\n\n\n<h2 class=\"wp-block-heading\">History Lesson</h2>\n\n\n\n<p>SAML was first developed in the early 2000s by the Security Services Technical Committee of the Organization for the Advancement of Structured Information Standards (OASIS). It was developed in response to the growing trend of web applications and the need for users to access multiple applications with a single set of credentials. Before SAML, each application would typically have its own authentication system, requiring users to enter their username and password for each application separately. This was not only inconvenient for users but also made it difficult for organizations to manage user access and permissions across multiple applications. SAML was designed to address these issues by providing a standard protocol for exchanging authentication and authorization data between parties.&nbsp;</p>\n\n\n\n<p>The first version of SAML, SAML 1.0, was released in 2002. It provided a basic framework for authentication and authorization. SAML 1.1 was released in 2003 and addressed some limitations identified in the earlier version, but it was still limited in its capabilities. SAML 2.0, which was released in 2005, represented a major overhaul of the protocol. It introduced a number of new features, such as support for metadata, improved support for single sign-on, and improved support for attribute exchange. Since its release, SAML 2.0 has seen wide adoption as an authentication standard.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Attendance</h2>\n\n\n\n<p>There are two primary roles in a SAML exchange, the Service Providers (SP) and Identity Provider (IdP).</p>\n\n\n\n<ul>\n<li><strong>Service Providers</strong> are the services or applications users wish to use. They coordinate with Identity Providers to authorize users and grant access to protected resources.</li>\n\n\n\n<li><strong>Identity Providers</strong> are responsible for authenticating the user and sharing authorization information to SPs. Identity Providers package the users information into a well-known format known as a SAML Assertion.</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\">How SAML Works</h2>\n\n\n\n<p>Both SP and IdP can initiate authorization into an application. If a user visits the application first, the application (or SP in SAML terms) will ask the Identity Provider for information about the user, then use that information to process the login. This is known as an SP-initiated authorization. If the user first visits their SSO application (or IdP) then navigates to an application from a list of approved applications, the IdP will simply forward information to the Service Provider. The application can then use this information to proceed. This is known as an IdP-initiated authorization.</p>\n\n\n\n<p>Crucially, IdPs and SPs must establish a trust relationship before any exchange can happen. That is, IdPs will only share information with SPs that it knows. The trust relationship prevents sensitive data from being released to bad actors.</p>\n\n\n\n<h2 class=\"wp-block-heading\">SP-Initiated Authentication</h2>\n\n\n\n<p class=\"has-text-align-center\"><strong><img height=\"407\" src=\"https://lh7-us.googleusercontent.com/Lg-D54W2SUf-5fBcykNpZAMwBsWycmi9zsWcx36JIhxQtni_AkQa-OLAgWoFsygQQEq4g9GQf3meBzp_21FIF_mP4YRY00aKy0qkgguHff4Hz_RFGO3g5Cmy92e4EehlKn49OxP8ML0J3J_81yDJNac\" width=\"624\" /></strong></p>\n\n\n\n<h2 class=\"wp-block-heading\">IdP-Initiated Authentication</h2>\n\n\n\n<p class=\"has-text-align-center\"><strong><img height=\"353\" src=\"https://lh7-us.googleusercontent.com/lA4sqLJ7ms5FyJfmIOwvQWCUjy1KvZe63TrjNhvbiWfA6WM2eAKROXoXCgm-3PZi7JW-p_0-jz1-c9Y6DrYhfUjNb6wLjShvj5uC_StgwgDS0dkKgkdoqIB0TSN7rnprRzW3TxacNJvpC1cl18Tc0X4\" width=\"624\" /></strong></p>\n\n\n\n<h2 class=\"wp-block-heading\">Real World Scenario</h2>\n\n\n\n<p>In previous installments of this series, we talked about an educators conference. The conference limited seminar attendance based on attendees&#8217; roles. Some sessions were specific to school administrators, while others were tailored toward specific subjects. All attendees wore a color-coded lanyard that granted access to sessions relevant to their role in the district.</p>\n\n\n\n<p>Conference attendees can get their badges and lanyards in one of two ways. Checking in to the event involves contacting the event coordinators who then verify registration and out together the attendees packet with a badge and lanyard. Attendees can either check-in early with the event coordinators and have their packet ready for them at the venue, or they can check-in at the venue, who then contacts the event coordinators. Regardless of the check-in method, the end result remains the same- the attendee&#8217;s registration is verified and they have the necessary badges and lanyards to participate in seminars.</p>\n\n\n\n<p>In this scenario, the event coordinator acts as the Identity Provider while the venue acts as the Service Provider. The packet put together by the event coordinator is similar to the SAML assertion. Attendees have two options for checking in. The first method, early check-in, is similar to IdP-initiated flow. The second method, checking in at the venue, is similar to the SP-initiated flow.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" />\n\n\n\n<p>SAML is a crucial technology for organizations that need to manage user access to multiple applications. It provides a secure, centralized way to manage user authentication and authorization, and it enables organizations to improve the user experience and enhance security. The bidirectional system supports logins from applications as well as SSO organizations. Clever uses the SAML protocol both as a service provider (sign into Clever through a third party SSO) and an identity provider (sign into application partners through Clever).</p>\n<p>The post <a href=\"https://engineering.clever.com/2023/11/29/saml-protocol/\">SAML Protocol</a> appeared first on <a href=\"https://engineering.clever.com\">Clever Engineering Blog</a>.</p>"
      }
    ]
  },
  "Eventbrite": {
    "title": "The Power of Collaboration in Product Development",
    "xmlUrl": "https://www.eventbrite.com/engineering/feed/",
    "htmlUrl": "https://www.eventbrite.com/engineering/",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://www.eventbrite.com/engineering/feed/",
      "value": "The Power of Collaboration in Product Development"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://www.eventbrite.com/engineering/product-development-process/"
      }
    ],
    "link": "https://www.eventbrite.com/engineering/product-development-process/",
    "comments": "https://www.eventbrite.com/engineering/product-development-process/#respond",
    "authors": [
      {
        "name": "Kyle Ludvik"
      }
    ],
    "author": "Kyle Ludvik",
    "author_detail": {
      "name": "Kyle Ludvik"
    },
    "published": "Fri, 13 Jan 2023 01:46:59 +0000",
    "published_parsed": [
      2023,
      1,
      13,
      1,
      46,
      59,
      4,
      13,
      0
    ],
    "tags": [
      {
        "term": "Product",
        "scheme": null,
        "label": null
      }
    ],
    "id": "https://www.eventbrite.com/engineering/?p=9782",
    "guidislink": false,
    "summary": "<p>Product development at Eventbrite is a practice centered around understanding what our customers need, so we can enhance current features or build new products. In order to achieve this, our product team collaborates across multiple disciplines throughout the company to ensure we\u2019re thinking about customer needs from all angles. Who is involved in product development? &#8230; </p>\n<p class=\"link-more\"><a class=\"more-link\" href=\"https://www.eventbrite.com/engineering/product-development-process/\">Continue reading<span class=\"screen-reader-text\"> \"The Power of Collaboration in Product Development\"</span></a></p>\n<p>The post <a href=\"https://www.eventbrite.com/engineering/product-development-process/\">The Power of Collaboration in Product Development</a> appeared first on <a href=\"https://www.eventbrite.com/engineering\">Engineering Blog</a>.</p>",
    "summary_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://www.eventbrite.com/engineering/feed/",
      "value": "<p>Product development at Eventbrite is a practice centered around understanding what our customers need, so we can enhance current features or build new products. In order to achieve this, our product team collaborates across multiple disciplines throughout the company to ensure we\u2019re thinking about customer needs from all angles. Who is involved in product development? &#8230; </p>\n<p class=\"link-more\"><a class=\"more-link\" href=\"https://www.eventbrite.com/engineering/product-development-process/\">Continue reading<span class=\"screen-reader-text\"> \"The Power of Collaboration in Product Development\"</span></a></p>\n<p>The post <a href=\"https://www.eventbrite.com/engineering/product-development-process/\">The Power of Collaboration in Product Development</a> appeared first on <a href=\"https://www.eventbrite.com/engineering\">Engineering Blog</a>.</p>"
    },
    "wfw_commentrss": "https://www.eventbrite.com/engineering/product-development-process/feed/",
    "slash_comments": "0"
  },
  "eFounders": {
    "title": "The (perfect) startup story of Wit.ai, acquired by Facebook in 21 months",
    "xmlUrl": "https://medium.com/feed/unexpected-token",
    "htmlUrl": "https://medium.com/unexpected-token",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://medium.com/feed/unexpected-token",
      "value": "The (perfect) startup story of Wit.ai, acquired by Facebook in 21 months"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://medium.com/unexpected-token/the-perfect-startup-story-of-wit-ai-acquired-by-facebook-in-21-months-1bf35b996808?source=rss----2d2624499d2---4"
      }
    ],
    "link": "https://medium.com/unexpected-token/the-perfect-startup-story-of-wit-ai-acquired-by-facebook-in-21-months-1bf35b996808?source=rss----2d2624499d2---4",
    "id": "https://medium.com/p/1bf35b996808",
    "guidislink": false,
    "tags": [
      {
        "term": "entrepreneurship",
        "scheme": null,
        "label": null
      },
      {
        "term": "startup",
        "scheme": null,
        "label": null
      },
      {
        "term": "facebook",
        "scheme": null,
        "label": null
      }
    ],
    "authors": [
      {
        "name": "Rachel Vanier"
      }
    ],
    "author": "Rachel Vanier",
    "author_detail": {
      "name": "Rachel Vanier"
    },
    "published": "Fri, 06 Nov 2015 14:59:50 GMT",
    "published_parsed": [
      2015,
      11,
      6,
      14,
      59,
      50,
      4,
      310,
      0
    ],
    "updated": "2015-12-08T11:13:33.205Z",
    "updated_parsed": [
      2015,
      12,
      8,
      11,
      13,
      33,
      1,
      342,
      0
    ],
    "content": [
      {
        "type": "text/html",
        "language": null,
        "base": "https://medium.com/feed/unexpected-token",
        "value": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/1*oiEb0ddcQdNrPkv7wt58Bg.png\" /></figure><p>You don\u2019t often get to meet a co-founder of a startup that follows, by all means, the \u201cperfect successful startup\u201d path. And by \u201cperfect startup\u201d, I mean the kind of startup that goes by the book. And by \u201cthe book\u201d, I mostly mean Paul Graham\u2019s\u00a0essays.</p><p>I met <a href=\"https://twitter.com/lxbrun\">Alexandre Lebrun</a>, co-founder of <a href=\"https://wit.ai/\">Wit.ai</a>, an AI platform that makes it easy for developers to create apps that users can talk to. He holds a degree from a top engineering school. He started his startup while he was living in Palo Alto. He had previous experience in the field. He built the app and launched it early on Hacker News. The app got traction. The team got into <a href=\"http://www.ycombinator.com/\">Y Combinator</a>. They raised $3M after the Demo Day, with one of the most prestigious VCs (<a href=\"http://a16z.com/\">Andreessen Horowitz</a>). 9 months later, they got acquired by Facebook.</p><p>Here you go. Perfect startup story. What is even more surprising is that when I asked Alexandre: <strong>\u201cYour startup seems to be super successful from day 1, is that so?\u201d</strong> his answer\u00a0was:</p><p><strong><em>\u201cWell\u2026 yes\u201d.</em></strong></p><h4>Don\u2019t worry, there is a\u00a0\u201cbut\u201d</h4><p>I was more looking for a \u201cdon\u2019t be desperate, there are downsides behind all this, success <em>never</em> comes without struggle\u201d kind of testimony. In reality, Wit.ai does indeed follow the success path from day 1, but it\u2019s only because Wit.ai is Alexandre\u2019s <em>second</em> startup. The story of his first venture, VirtuOz, involves many more mistakes that he learned\u00a0from.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/601/1*5NCWr_yenKqlf2wl9S08QQ.jpeg\" /><figcaption>Founders Alex Lebrun, Laurent Landowski and Willy\u00a0Blandin</figcaption></figure><h3>Doing things right the second time\u00a0around</h3><p>The story of Alex as an entrepreneur started in 2002, when he decided to launch <a href=\"https://www.crunchbase.com/organization/virtuoz\">VirtuOz</a> in Paris. As an engineer passionate with voice recognition and artificial intelligence, his dream had always been to make robots understand human language. Inspired by chatterbots\u2019 pioneers like Joseph Weizenbaum\u200a\u2014\u200awho created <a href=\"https://en.wikipedia.org/wiki/ELIZA\">ELIZA</a> in 1966\u200a\u2014\u200ahe imagined a solution much similar to Siri. Back in 2002, building Siri was impossible, both from the technological and business perspective. Right after the Internet bubble burst, he decided he would focus on a more profitable venture, and started VirtuOz as a virtual assistant technology for businesses\u2019 customer\u00a0service.</p><h3>Alex Lebrun\u2019s first startup VirtuOz\u2019s story (and struggle)</h3><p>It took VirtuOz\u2019s team 3 whole years before landing their first client, in 2005: VoyagesSncf.com, the biggest online travel agency in France. It was their lucky year: they also raised $1,6M. In 2007, they decided to move to the U.S to explore business opportunities as they realized the French market was too small\u200a\u2014\u200athe tech team remained in France. They soon realized that selling a product to AOL, Ebay, and other big players required much more than a nice product: you need to have a local data center, a 24h/24 customer support, huge sales teams,\u00a0etc.</p><p>Nevertheless, VirtuOz managed to raise a round of funding of $12M in August 2008\u200a\u2014\u200aliterally days before the fall of Lehman Brothers\u200a\u2014\u200awith Silicon Valley investors. Because the new company\u2019s scale required more structured operations and financial reporting to investors, and because Alex felt more like focusing on the product, he decided it would be wiser to hire a \u201cprofessional\u201d CEO.</p><p>His feeling was that the \u201cEric-Schmidt model\u201d at Google was a smart one and that they could make it work at VirtuOz. He ended up realizing that what works at Google doesn\u2019t necessary elsewhere. There was a huge mismatch between the newly appointed CEO\u200a\u2014\u200aand the VPs brought along\u200a\u2014\u200aand the rest of the team, in terms of culture and product understanding. As VP of Advanced Technology, Alex realized that he was no longer in power and did not feel he belonged within his own company\u200a\u2014\u200ahe took a year-long sabbatical, after which the board re-appointed him as CEO, in June\u00a02012.</p><p>In the meantime, the culture had already changed and what he left a \u201cstartup\u201d had turned into a 70-people company selling enterprise software. Alex decided to reorganize the team and launch a new product which ultimately lead him to sell VirtuOz to Nuance Communications in January\u00a02013.</p><p>After the acquisition, and after he made sure the transition went smoothly, Alex went back on track and decided to launch a new venture, focusing on an issue he witnessed: <strong>on the one hand, there was a huge demand for machines\u2019 comprehension of human language (written and spoken), on the other hand, there were only custom solutions made for big companies (with big costs)</strong>. What is there were an API for developers that could give them the capacity to understand human language?</p><blockquote>\u201cAfter selling VirtuOz, I felt nostalgic of the \u201cgarage\u201d period and decided to launch a new\u00a0startup\u201d</blockquote><p>After spending ten years building and growing VirtuOz, Alex launched Wit.ai\u200a\u2014\u200aa fully open API for voice recognition and language understanding, based on machine learning, and inspired by open models like Stripe and Twilio. He started coding it with his co-founder <a href=\"https://twitter.com/blandw\">Willy Blandin</a> in April 2013. Wit.ai was acquired by Facebook in January 2015. Here are a few things that helped making things right the second time\u00a0around.</p><h3>Spending time in non-important stuff VS building a\u00a0product</h3><p>The first thing that Alex did completely differently is that he did not spend a second on unnecessary tasks. He and his co-founder spent 6 months coding, period. Their company was not incorporated, had no office and no money, even when they applied to Y Combinator.</p><p>In his previous venture, Alex had lost an incredible amount of time in paperwork, renting offices, trying to raise funds before even having a single client\u200a\u2014\u200aa mistake he would not replicate.</p><p>Similarly, he had waited much too long for a perfect product before looking for his first users. With Wit.ai, he forced himself\u200a\u2014\u200aand his co-founder\u200a\u2014\u200ato launch the product as soon as possible on HackerNews. It was an alpha version, far from what they would be satisfied with, but it was operational.</p><blockquote>\u201cIt was a struggle to overcome the feeling that our product wasn\u2019t ready before launching on HackerNews, but I knew we needed to confirm there was a need for our solution as early as possible\u201d.</blockquote><p>Wit.ai remained on HN\u2019s homepage #1 position for 24 hours and they became a small phenomenon in the Valley. By the time they applied to Y Combinator, they already had 3,000 developers using the\u00a0API.</p><h3>Doing Enterprise Sales from the start VS Focusing on\u00a0SaaS</h3><p>When building a SaaS product, it is very tempting to sign major contracts with big players early on: it gives financial comfort, you <em>feel</em> it gives you business legitimacy, and it\u2019s kind of flattering. That\u2019s what Alex did with VirtuOz, and he learned not to do it again: when your SaaS startup is still young, you need to focus on building your own product. Larger accounts will ask for many custom features, a fully dedicated account manager, and ultimately distract you from building a scalable product that can be used by\u00a0anyone.</p><p>That\u2019s why when Wit.ai launched and Alex got meeting requests from big players, he refused in order to focus on building his product. With VirtuOz, he spent entire days with tech consulting firms without making a single dollar. With Wit.ai, he would rather debug 1 indie developer on the other end of the world for hours if it meant making the product better, than working with a multi-national.</p><blockquote>\u201cIf you can afford to say \u201cno\u201d to big clients and partnerships, i.e. if you don\u2019t have investors\u2019 pressure or huge costs, and if you want your product to be used by the many, I\u2019d say don\u2019t sign the big contracts and focus on building a scalable startup.\u201d</blockquote><p>Alex was so convinced of his vision that he wanted to build a startup truly used by millions that he would rather fail than becoming a consulting business for big customers. According to him, <em>time</em> is an entrepreneur\u2019s most important asset: if you develop fast, you can take greater risks\u200a\u2014\u200afunnily enough, \u201cFail fast\u201d is one of Facebook\u2019s mantras.</p><h3>Launching a startup in France VS San Francisco</h3><p>Surprisingly\u200a\u2014\u200afor me!\u200a\u2014\u200aAlex remains pretty certain that you can start your startup from anywhere and do not need to be in the Valley from day 1. According to him, it\u2019s all a matter of personal context. He could never have started VirtuOz in the U.S in 2002, and launching in France had its advantage at the time: he was able to raise \u20ac100k with family and friends, which would have been impossible in the Valley. The recruitment was made much easier, especially for tech profiles.</p><p>When he launched Wit.ai, he already was in Palo Alto, which of course, also had its advantages. For instance, when he launched on HN, he asked in the comments if anyone could welcome him and his co-founder to their office, as they were working from home. 10 min later, the founder of Pebble offered them 2 desks, to use Pebble\u2019s office, network, snacks, meeting rooms etc. for free, and Wit.ai stayed there for 6 months, up until it was a 6-engineer company!</p><p>There are many tactical mistakes you can make when your startup has offices both in the US and France, says Alex. For instance, having a modern, powerful teleconference system in every meeting room is key. It\u2019s also important to have people from both offices travel to the other office from time to time, in order to build personal relationship that will prove important in stressful times. But these tactical mistakes don\u2019t impact the broader\u00a0vision.</p><p>From those lessons learned, Wit.ai followed an impressive path of growth and ultimately got acquired by Facebook. While Alex was constantly refusing meetings with the corporate development teams of potential acquirers, when David Marcus (i.e Facebook Messenger lead and previously CEO of Paypal) contacted him, he accepted the meeting, which led to the deal. For Wit.ai, Facebook was a great opportunity to work with an incredible A.I research team, great resources, and a much larger scale, says Alex. The acquisition was announced on January 5, 2015, and Alex has since remained head of Wit.ai which still exists inside Facebook, with a team of 10 engineers. They strongly contributed to the debut <a href=\"https://www.facebook.com/Davemarcus/posts/10156070660595195\">of \u201cM\u201d</a> last August, and will continue to work on Facebook\u2019s A.I projects.</p><p>When you look at the story of Wit.ai in hindsight, the crazy 21-months startup success took Alex a decade of entrepreneur experience\u200a\u2014\u200aand a great co-founder, he adds\u200a\u2014\u200ato build. It is because Wit.ai is a product built by expert founders, passionate about their fields, who put their product in the hands of users very early on, and solved a real issue, that it was so successful.</p><p>Thanks Alex for this great lesson of humility and hard\u00a0work!</p><p><em>This article is part of the publication </em><a href=\"https://medium.com/unexpected-token\"><em>Unexpected Token</em></a><em> powered by </em><a href=\"http://efounders.co/\"><em>eFounders</em></a><em>\u200a\u2014\u200astartup studio building SaaS startups. We have a very cool Hacker Program, learn more and apply\u00a0</em><a href=\"http://efounders.co/hackers\"><em>here</em></a><em>.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1bf35b996808\" width=\"1\" /><hr /><p><a href=\"https://medium.com/unexpected-token/the-perfect-startup-story-of-wit-ai-acquired-by-facebook-in-21-months-1bf35b996808\">The (perfect) startup story of Wit.ai, acquired by Facebook in 21 months</a> was originally published in <a href=\"https://medium.com/unexpected-token\">Unexpected Token</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
      }
    ],
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/1*oiEb0ddcQdNrPkv7wt58Bg.png\" /></figure><p>You don\u2019t often get to meet a co-founder of a startup that follows, by all means, the \u201cperfect successful startup\u201d path. And by \u201cperfect startup\u201d, I mean the kind of startup that goes by the book. And by \u201cthe book\u201d, I mostly mean Paul Graham\u2019s\u00a0essays.</p><p>I met <a href=\"https://twitter.com/lxbrun\">Alexandre Lebrun</a>, co-founder of <a href=\"https://wit.ai/\">Wit.ai</a>, an AI platform that makes it easy for developers to create apps that users can talk to. He holds a degree from a top engineering school. He started his startup while he was living in Palo Alto. He had previous experience in the field. He built the app and launched it early on Hacker News. The app got traction. The team got into <a href=\"http://www.ycombinator.com/\">Y Combinator</a>. They raised $3M after the Demo Day, with one of the most prestigious VCs (<a href=\"http://a16z.com/\">Andreessen Horowitz</a>). 9 months later, they got acquired by Facebook.</p><p>Here you go. Perfect startup story. What is even more surprising is that when I asked Alexandre: <strong>\u201cYour startup seems to be super successful from day 1, is that so?\u201d</strong> his answer\u00a0was:</p><p><strong><em>\u201cWell\u2026 yes\u201d.</em></strong></p><h4>Don\u2019t worry, there is a\u00a0\u201cbut\u201d</h4><p>I was more looking for a \u201cdon\u2019t be desperate, there are downsides behind all this, success <em>never</em> comes without struggle\u201d kind of testimony. In reality, Wit.ai does indeed follow the success path from day 1, but it\u2019s only because Wit.ai is Alexandre\u2019s <em>second</em> startup. The story of his first venture, VirtuOz, involves many more mistakes that he learned\u00a0from.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/601/1*5NCWr_yenKqlf2wl9S08QQ.jpeg\" /><figcaption>Founders Alex Lebrun, Laurent Landowski and Willy\u00a0Blandin</figcaption></figure><h3>Doing things right the second time\u00a0around</h3><p>The story of Alex as an entrepreneur started in 2002, when he decided to launch <a href=\"https://www.crunchbase.com/organization/virtuoz\">VirtuOz</a> in Paris. As an engineer passionate with voice recognition and artificial intelligence, his dream had always been to make robots understand human language. Inspired by chatterbots\u2019 pioneers like Joseph Weizenbaum\u200a\u2014\u200awho created <a href=\"https://en.wikipedia.org/wiki/ELIZA\">ELIZA</a> in 1966\u200a\u2014\u200ahe imagined a solution much similar to Siri. Back in 2002, building Siri was impossible, both from the technological and business perspective. Right after the Internet bubble burst, he decided he would focus on a more profitable venture, and started VirtuOz as a virtual assistant technology for businesses\u2019 customer\u00a0service.</p><h3>Alex Lebrun\u2019s first startup VirtuOz\u2019s story (and struggle)</h3><p>It took VirtuOz\u2019s team 3 whole years before landing their first client, in 2005: VoyagesSncf.com, the biggest online travel agency in France. It was their lucky year: they also raised $1,6M. In 2007, they decided to move to the U.S to explore business opportunities as they realized the French market was too small\u200a\u2014\u200athe tech team remained in France. They soon realized that selling a product to AOL, Ebay, and other big players required much more than a nice product: you need to have a local data center, a 24h/24 customer support, huge sales teams,\u00a0etc.</p><p>Nevertheless, VirtuOz managed to raise a round of funding of $12M in August 2008\u200a\u2014\u200aliterally days before the fall of Lehman Brothers\u200a\u2014\u200awith Silicon Valley investors. Because the new company\u2019s scale required more structured operations and financial reporting to investors, and because Alex felt more like focusing on the product, he decided it would be wiser to hire a \u201cprofessional\u201d CEO.</p><p>His feeling was that the \u201cEric-Schmidt model\u201d at Google was a smart one and that they could make it work at VirtuOz. He ended up realizing that what works at Google doesn\u2019t necessary elsewhere. There was a huge mismatch between the newly appointed CEO\u200a\u2014\u200aand the VPs brought along\u200a\u2014\u200aand the rest of the team, in terms of culture and product understanding. As VP of Advanced Technology, Alex realized that he was no longer in power and did not feel he belonged within his own company\u200a\u2014\u200ahe took a year-long sabbatical, after which the board re-appointed him as CEO, in June\u00a02012.</p><p>In the meantime, the culture had already changed and what he left a \u201cstartup\u201d had turned into a 70-people company selling enterprise software. Alex decided to reorganize the team and launch a new product which ultimately lead him to sell VirtuOz to Nuance Communications in January\u00a02013.</p><p>After the acquisition, and after he made sure the transition went smoothly, Alex went back on track and decided to launch a new venture, focusing on an issue he witnessed: <strong>on the one hand, there was a huge demand for machines\u2019 comprehension of human language (written and spoken), on the other hand, there were only custom solutions made for big companies (with big costs)</strong>. What is there were an API for developers that could give them the capacity to understand human language?</p><blockquote>\u201cAfter selling VirtuOz, I felt nostalgic of the \u201cgarage\u201d period and decided to launch a new\u00a0startup\u201d</blockquote><p>After spending ten years building and growing VirtuOz, Alex launched Wit.ai\u200a\u2014\u200aa fully open API for voice recognition and language understanding, based on machine learning, and inspired by open models like Stripe and Twilio. He started coding it with his co-founder <a href=\"https://twitter.com/blandw\">Willy Blandin</a> in April 2013. Wit.ai was acquired by Facebook in January 2015. Here are a few things that helped making things right the second time\u00a0around.</p><h3>Spending time in non-important stuff VS building a\u00a0product</h3><p>The first thing that Alex did completely differently is that he did not spend a second on unnecessary tasks. He and his co-founder spent 6 months coding, period. Their company was not incorporated, had no office and no money, even when they applied to Y Combinator.</p><p>In his previous venture, Alex had lost an incredible amount of time in paperwork, renting offices, trying to raise funds before even having a single client\u200a\u2014\u200aa mistake he would not replicate.</p><p>Similarly, he had waited much too long for a perfect product before looking for his first users. With Wit.ai, he forced himself\u200a\u2014\u200aand his co-founder\u200a\u2014\u200ato launch the product as soon as possible on HackerNews. It was an alpha version, far from what they would be satisfied with, but it was operational.</p><blockquote>\u201cIt was a struggle to overcome the feeling that our product wasn\u2019t ready before launching on HackerNews, but I knew we needed to confirm there was a need for our solution as early as possible\u201d.</blockquote><p>Wit.ai remained on HN\u2019s homepage #1 position for 24 hours and they became a small phenomenon in the Valley. By the time they applied to Y Combinator, they already had 3,000 developers using the\u00a0API.</p><h3>Doing Enterprise Sales from the start VS Focusing on\u00a0SaaS</h3><p>When building a SaaS product, it is very tempting to sign major contracts with big players early on: it gives financial comfort, you <em>feel</em> it gives you business legitimacy, and it\u2019s kind of flattering. That\u2019s what Alex did with VirtuOz, and he learned not to do it again: when your SaaS startup is still young, you need to focus on building your own product. Larger accounts will ask for many custom features, a fully dedicated account manager, and ultimately distract you from building a scalable product that can be used by\u00a0anyone.</p><p>That\u2019s why when Wit.ai launched and Alex got meeting requests from big players, he refused in order to focus on building his product. With VirtuOz, he spent entire days with tech consulting firms without making a single dollar. With Wit.ai, he would rather debug 1 indie developer on the other end of the world for hours if it meant making the product better, than working with a multi-national.</p><blockquote>\u201cIf you can afford to say \u201cno\u201d to big clients and partnerships, i.e. if you don\u2019t have investors\u2019 pressure or huge costs, and if you want your product to be used by the many, I\u2019d say don\u2019t sign the big contracts and focus on building a scalable startup.\u201d</blockquote><p>Alex was so convinced of his vision that he wanted to build a startup truly used by millions that he would rather fail than becoming a consulting business for big customers. According to him, <em>time</em> is an entrepreneur\u2019s most important asset: if you develop fast, you can take greater risks\u200a\u2014\u200afunnily enough, \u201cFail fast\u201d is one of Facebook\u2019s mantras.</p><h3>Launching a startup in France VS San Francisco</h3><p>Surprisingly\u200a\u2014\u200afor me!\u200a\u2014\u200aAlex remains pretty certain that you can start your startup from anywhere and do not need to be in the Valley from day 1. According to him, it\u2019s all a matter of personal context. He could never have started VirtuOz in the U.S in 2002, and launching in France had its advantage at the time: he was able to raise \u20ac100k with family and friends, which would have been impossible in the Valley. The recruitment was made much easier, especially for tech profiles.</p><p>When he launched Wit.ai, he already was in Palo Alto, which of course, also had its advantages. For instance, when he launched on HN, he asked in the comments if anyone could welcome him and his co-founder to their office, as they were working from home. 10 min later, the founder of Pebble offered them 2 desks, to use Pebble\u2019s office, network, snacks, meeting rooms etc. for free, and Wit.ai stayed there for 6 months, up until it was a 6-engineer company!</p><p>There are many tactical mistakes you can make when your startup has offices both in the US and France, says Alex. For instance, having a modern, powerful teleconference system in every meeting room is key. It\u2019s also important to have people from both offices travel to the other office from time to time, in order to build personal relationship that will prove important in stressful times. But these tactical mistakes don\u2019t impact the broader\u00a0vision.</p><p>From those lessons learned, Wit.ai followed an impressive path of growth and ultimately got acquired by Facebook. While Alex was constantly refusing meetings with the corporate development teams of potential acquirers, when David Marcus (i.e Facebook Messenger lead and previously CEO of Paypal) contacted him, he accepted the meeting, which led to the deal. For Wit.ai, Facebook was a great opportunity to work with an incredible A.I research team, great resources, and a much larger scale, says Alex. The acquisition was announced on January 5, 2015, and Alex has since remained head of Wit.ai which still exists inside Facebook, with a team of 10 engineers. They strongly contributed to the debut <a href=\"https://www.facebook.com/Davemarcus/posts/10156070660595195\">of \u201cM\u201d</a> last August, and will continue to work on Facebook\u2019s A.I projects.</p><p>When you look at the story of Wit.ai in hindsight, the crazy 21-months startup success took Alex a decade of entrepreneur experience\u200a\u2014\u200aand a great co-founder, he adds\u200a\u2014\u200ato build. It is because Wit.ai is a product built by expert founders, passionate about their fields, who put their product in the hands of users very early on, and solved a real issue, that it was so successful.</p><p>Thanks Alex for this great lesson of humility and hard\u00a0work!</p><p><em>This article is part of the publication </em><a href=\"https://medium.com/unexpected-token\"><em>Unexpected Token</em></a><em> powered by </em><a href=\"http://efounders.co/\"><em>eFounders</em></a><em>\u200a\u2014\u200astartup studio building SaaS startups. We have a very cool Hacker Program, learn more and apply\u00a0</em><a href=\"http://efounders.co/hackers\"><em>here</em></a><em>.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1bf35b996808\" width=\"1\" /><hr /><p><a href=\"https://medium.com/unexpected-token/the-perfect-startup-story-of-wit-ai-acquired-by-facebook-in-21-months-1bf35b996808\">The (perfect) startup story of Wit.ai, acquired by Facebook in 21 months</a> was originally published in <a href=\"https://medium.com/unexpected-token\">Unexpected Token</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
  }
}